[
{"file_id": "d41586-017-08527-4", "url": "https://www.nature.com/articles/d41586-017-08527-4", "year": 2017, "authors": [], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08837-7", "url": "https://www.nature.com/articles/d41586-017-08837-7", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08722-3", "url": "https://www.nature.com/articles/d41586-017-08722-3", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08795-0", "url": "https://www.nature.com/articles/d41586-017-08795-0", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08473-1", "url": "https://www.nature.com/articles/d41586-017-08473-1", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08307-0", "url": "https://www.nature.com/articles/d41586-017-08307-0", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08925-8", "url": "https://www.nature.com/articles/d41586-017-08925-8", "year": 2017, "authors": [{"name": "Barbara Fraser"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08428-6", "url": "https://www.nature.com/articles/d41586-017-08428-6", "year": 2017, "authors": [{"name": "April Reese"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08329-8", "url": "https://www.nature.com/articles/d41586-017-08329-8", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08325-y", "url": "https://www.nature.com/articles/d41586-017-08325-y", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08581-y", "url": "https://www.nature.com/articles/d41586-017-08581-y", "year": 2017, "authors": [{"name": "Michele Catanzaro"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08476-y", "url": "https://www.nature.com/articles/d41586-017-08476-y", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08625-3", "url": "https://www.nature.com/articles/d41586-017-08625-3", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08575-w", "url": "https://www.nature.com/articles/d41586-017-08575-w", "year": 2017, "authors": [{"name": "Barbara Casassus"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08617-3", "url": "https://www.nature.com/articles/d41586-017-08617-3", "year": 2017, "authors": [{"name": "Emma Young"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08719-y", "url": "https://www.nature.com/articles/d41586-017-08719-y", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08664-w", "url": "https://www.nature.com/articles/d41586-017-08664-w", "year": 2017, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08493-x", "url": "https://www.nature.com/articles/d41586-017-08493-x", "year": 2017, "authors": [{"name": "Ewen Callaway"}, {"name": "Davide Castelvecchi"}, {"name": "David Cyranoski"}, {"name": "Elizabeth Gibney"}, {"name": "Heidi Ledford"}, {"name": "Jane J. Lee"}, {"name": "Lauren Morello"}, {"name": "Nicky Phillips"}, {"name": "Quirin Schiermeier"}, {"name": "Jeff Tollefson"}, {"name": "Richard Van Noorden"}, {"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "nature.2017.23038", "url": "https://www.nature.com/articles/nature.2017.23038", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Scientists fear plans to abandon clinical trials of centuries-old remedies will put people at risk. Support for traditional medicine in China goes right to the top. President Xi Jinping has called this type of medicine a \u201cgem\u201d of the country\u2019s scientific heritage and promised to give alternative therapies and Western drugs equal government support. Now the country is taking dramatic steps to promote these cures even as researchers raise concerns about such treatments. From early next year, traditional Chinese medicines may no longer be required to pass safety and efficacy trials in humans in China. Draft regulations announced in October by the China Food and Drug Administration (CFDA) mean traditional medicines can skip such costly and time-consuming trials as long as manufacturers prepare ingredients using essentially the same method as in classic Chinese formulations. The State Administration of Traditional Chinese Medicine and the CFDA will compose a list of the approved methods. The Chinese government has been forcefully promoting traditional Chinese medicines (TCMs) as an alternative to expensive Western drugs. Doctors of Chinese medicine have welcomed the new policy, saying that it will make it easier for companies who produce such medicines to get drugs approved and make them available to patients. Lixing Lao, director of Hong Kong University\u2019s School of Chinese Medicine, says that although traditional medicines will no longer need to go through clinical trials, the CFDA will still require remedies to undergo preclinical pharmacological testing and drug-toxicity studies in animals or cells to gain approval. \n               Safety concerns \n             But scientists say that safety concerns continue to plague the industry, and that minimizing clinical-trial requirements could put more patients at risk. On 23 September, the CFDA recalled batches of two injectable TCMs after about ten people fell ill with fevers and chills. Less than a month later, on 18 October, researchers in Singapore and Taiwan published a study in  Science Translational Medicine  linking liver cancer to aristolochic acid, an ingredient widely used in traditional remedies 1 . Lead author Steven Rozen, a cancer-genomics researcher at Duke-NUS Medical School in Singapore, is convinced that aristolochic acid contributed to the mutations, but says it\u2019s harder to determine to what extent it caused the tumours. Aristolochic acid has also been linked to cancers of the urinary tract and can cause fatal kidney damage 2 , 3 . Rozen says it is still in common use, despite warnings from the US Food and Drug Administration that it is associated with kidney disease. \u201cIt would be a good time to reassess regulations\u201d of aristolochic acid, he says. Lao sees people take remedies containing aristolochic acid every day, and says it should not cause problems if taken \u201cmoderately and to treat diseases\u201d rather than as a regular supplement. He says more research is needed into how to ensure the safe use of the potentially toxic substance. Overall, Lao is not concerned about safety issues with traditional medicines because, \u201cunlike Western drug development, these herbal formulas have been used for hundreds and thousands of years,\u201d he says. But Li Qingchen, a paediatric surgeon at the Harbin Children\u2019s Hospital and a well-known critic of TCMs, says the recent recalls of remedies show that current safety measures aren\u2019t adequate. He says doctors need to inform the public about some of the dangers associated with traditional medicines, but that most are unwilling to speak out against them. \u201cFew doctors would dare to publicly criticize TCMs,\u201d he says. Li thinks that the government\u2019s promotion of TCMs will make it harder for scientists to criticize the drugs \u201cbecause the matter gets escalated to a political level and open discussions become restricted\u201d. \n               Criticism muted \n             With strong government support for the alternative medicines industry, Chinese censors have been quick to remove posts from the Internet that question its efficacy. On 23 October, an article on a medical news site that called for closer attention to the risks of aristolochic acid was removed from social media site WeChat. The story had been viewed more than 700,000 times in three days. Debate over TCMs has been silenced before in China. Last year, a Beijing think tank \u2014 the Development Research Center of the State Council \u2014 proposed banning the practice of extracting Asiatic black bear bile, another common ingredient in TCMs. The think tank\u2019s report questioned the remedy\u2019s efficacy and suggested using synthetic alternatives. It was removed from the think tank's website after the Chinese Association of Traditional Chinese Medicine, which supports the development of TCM, called it biased and demanded an apology. As well as reducing regulations for TCMs, the Chinese government has made it easier to become a doctor of traditional medicine and to open hospitals that use the approach. Since July 2017, students studying traditional medicine no longer need to pass the national medical exams based on Western medicine. Instead, traditional medicine students can attend apprenticeship training and pass a skills test. And practitioners who want to open a clinic no longer need approval from the CFDA. They need only register with the authority. The government\u2019s ultimate goal is to have all Chinese health-care institutions provide a basic level of TCMs by 2020. A roadmap released in February 2016 by the State Council, China\u2019s highest administrative body, plans to increase the number of TCM-licensed doctors to 4 per 10,000 people, an increase from less than 3 practitioners per 10,000 people. The government also wants to push TCMs\u2019 share of pharmaceutical sales from 26% to 30% by the end of the decade. \n                     Screen uncovers hidden ingredients of Chinese medicine 2012-Apr-12 \n                   \n                     Traditional medicine: A culture in the balance 2007-Jul-11 \n                   \n                     China plans to modernize traditional medicine 2007-Apr-04 \n                   \n                     Trading on traditional medicines 2004-Mar-01 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.23045", "url": "https://www.nature.com/articles/nature.2017.23045", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "The trick lies in capturing the weak gravitational shifts in the ground. Gravity signals that race through the ground at the speed of light could help seismologists get a better handle on the size of large, devastating quakes soon after they hit, a study suggests. The tiny changes in Earth's gravitational field, created when the ground shifts, arrive at seismic-monitoring stations well before seismic waves. \u201cThe good thing we can do with these signals is  have quick information on the magnitude of the quake ,\u201d says Martin Vall\u00e9e, a seismologist at the Paris Institute of Earth Physics. Seismometers in China and South Korea picked up gravity signals immediately after  the magnitude-9.1 Tohoku earthquake that devastated parts of Japan in 2011 , Vall\u00e9e and his colleagues report in  Science  on 1 December 1 . The signals appear as tiny accelerations on seismic-recording equipment, more than a minute before the seismic waves show up. \u201cWe can look before the seismic waves arrive,\u201d says Vall\u00e9e. \u201cIf we see nothing, we can say that the quake that made these was maybe large, but not huge. If we see the signals, it means we really have a very big quake.\u201d Had seismologists been monitoring for gravity changes, they might have realized sooner just how big the Tohoku earthquake was. It took the US Geological Survey (USGS) 40 minutes to update its initial estimate of magnitude 7.9 to 8.8, much closer to the quake\u2019s true size, and 3 hours for the Japan Meteorological Agency to do the same. A small increase in an earthquake\u2019s magnitude means a large change in the energy released by the quake \u2014 and the devastation expected. That information is crucial for emergency responders as they decide what resources to deploy. \u201cIt\u2019ll be a major contribution if gravitational waves can beat down the time needed to know that a big earthquake is big,\u201d says Susan Hough, a USGS seismologist in Pasadena, California. But much work remains before gravity signals can be considered a reliable tool in the crucial minutes after a big quake, says Gavin Hayes, a USGS seismologist in Golden, Colorado. \u201cI don\u2019t see it being a game changer,\u201d he says. \n             First wave \n           The latest work arose when a group of European and US researchers began exploring how vibrations from small earthquakes affect  gravitational-wave detectors such as the European Virgo and the US Laser Interferometer Gravitational-Wave Observatory  (LIGO). Many of the scientists also worked on earthquake early-warning systems, and they began to think about whether earthquakes created gravitational perturbations and how those might be detected 2 . The challenge is in picking up the gravitational shaking, which is much weaker than that from seismic waves. In 2016, the scientists published 3  a proof-of-concept study showing that a gravity-measuring instrument in Japan\u2019s underground Kamioka Observatory had detected signals from the 2011 quake, which happened about 500 kilometres away. But others questioned how strong and reliable the signals might be 4 . In the latest paper, Vall\u00e9e and his colleagues report many more observations of gravity signals immediately after the Tohoku quake. The signal was most apparent at monitoring stations between about 1,000 and 2,000 kilometres from the quake\u2019s epicentre. At that distance, the fast-as-light signals had enough time to arrive and be clearly recorded before the seismic waves swamped them. Modelling suggests that the method should work for gauging quakes of magnitude 8.5 or greater, which are large enough to generate detectable gravity signals. The team is now hunting for signals that might have been recorded after other great quakes, including the magnitude-9.1 event in Sumatra in 2004 and the magnitude-8.8 one in Chile in 2010. A few extra minutes of warning can save lives, particularly in coastal areas where people can evacuate ahead of an incoming tsunami, says Jean-Paul Ampuero, a seismologist at the California Institute of Technology in Pasadena. \u201cThat\u2019s low-hanging fruit.\u201d  \n                   Moon\u2019s pull can trigger big earthquakes 2016-Sep-12 \n                 \n                   The 24/7 search for killer quakes 2015-Jul-08 \n                 \n                   Killer qualities of Japanese fault revealed 2013-Dec-05 \n                 \n                   Earthquake detected from space 2013-Mar-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.23040", "url": "https://www.nature.com/articles/nature.2017.23040", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Expanded genetic alphabet could allow for the production of new protein-based drugs. Life has spent the past few billion years working with a narrow vocabulary. Now researchers have broken those rules, adding extra letters to biology's limited lexicon. Chemist Floyd Romesberg of the Scripps Research Institute in La Jolla, California, and his colleagues manipulated  Escherichia coli  bacterial cells to incorporate two types of foreign chemical bases, or letters, into their DNA. The cells then used that information to insert unnatural amino acids into a fluorescent protein 1 . Organisms naturally encode heritable information using just four bases: adenine (A), thymine (T), cytosine (C) and guanine (G). These form pairs that hold together DNA\u2019s double helix, and different three-letter sequences code for each of the 20 amino acids that make up the proteins in living cells. The new work is the first to show that unnatural bases can be used to make proteins within a living cell. The achievement, Romesberg says, shows that synthetic biology \u2014 a field focused on imbuing organisms with new traits \u2014 can accomplish its goals by reinventing the most basic facets of life. \u201cThere is no biological system so fundamental and more intimately related to what we are than information storage and retrieval,\u201d he says. \u201cWhat we\u2019ve done is design a new part that functions right alongside the existing parts and can do everything they do.\u201d \n               Alphabet extensions \n             Several teams are attempting to  expand the genetic code . The four natural DNA bases can be arranged in 64 different three-letter combinations, called codons, that specify amino acids. But redundancy in this code \u2014 for instance, CGC, CGA, CGG and CGT all stand for the amino acid arginine \u2014 means that nearly all proteins needed for life are made of just 20 amino acids. Researchers including geneticist George Church of Harvard Medical School in Boston, Massachusetts, are working on repurposing redundant codons to specify new amino acids. Romesberg\u2019s group is exploring a different strategy: adding an entirely new base pair into DNA. That would vastly increase the number of possible codons, in theory giving cells the ability to exploit more than 100 extra amino acids. Although Church still believes that his own approach is more practical for most applications, he describes the new work as a \u201cmilestone in exploring the fundamental building blocks of life\u201d. Researchers first imagined an expanded genetic alphabet in the early 1960s. The first big success came in 1989, when a team led by chemist Steven Benner, then at the Swiss Federal Institute of Technology in Zurich, forged DNA molecules containing modified forms of cytosine and guanine 2 . These \u201cfunny\u201d DNA letters, as Benner has called them, could replicate and make RNA and proteins in test-tube reactions. \n               Funnier DNA \n             Over the past two decades, Romesberg\u2019s team has made hundreds of even  funnier DNA molecules . Unlike conventional base pairs in DNA and those made by Benner\u2019s team \u2014 which are bound together by shared hydrogen atoms \u2014 these foreign bases stick together because of their insolubility in water, largely mimicking how grease droplets clump in water. To function in living cells, though, the foreign base pairs need to sit alongside natural bases without disturbing the shape of DNA or disrupting essential tasks, such as the processes that faithfully copy DNA and transcribe it into messenger RNA \u2014 an intermediary molecule between DNA and proteins. In 2014, Romesberg\u2019s lab reported  a breakthrough : a strain of  E. coli  with a loop of DNA containing a single, unnatural base pair 3 . The \u2018alien DNA\u2019 was made of chemicals called dNaM and d5SICS (dubbed X and Y, respectively). But the cells divided sluggishly, and tended to lose their foreign DNA over time. In a paper published earlier this year 4 , Romesberg\u2019s team created a healthier, semi-synthetic  E. coli  that didn\u2019t so readily reject its foreign DNA (in this version, d5SICS was replaced with a similarly shaped chemical called dTPT3). Yet this strain, as did the one reported in 2014, lacked the ability to use its new codons. In the latest research 1 , reported in  Nature  on 29 November, the team created healthy cells that can finally wield their foreign DNA. In separate experiments, the cells incorporated two unnatural amino acids (called PrK and pAzF) into a protein that emits a soft, green glow. Both the foreign bases and amino acids were fed to the cells, and any organism that somehow escaped the lab would not be able to produce them. To allow the cells to use these new components, the researchers created modified versions of molecules called tRNAs, which function to read codons and ferry the appropriate amino acids to the cells' protein factories \u2014 ribosomes. The new amino acids did not change the shape or function of the green fluorescent protein. But \u201cnow that we can store and retrieve information\u201d, says Romesberg, \u201clet\u2019s do something with it.\u201d In unpublished work, his team has inserted a foreign base pair into a key site in the gene implicated in antibiotic resistance. Bacteria that shed their foreign DNA become sensitive to penicillin-related drugs. \n               Candy store \n             Romesberg has started a biotechnology company, called Synthorx, also in La Jolla, that is attempting to incorporate unnatural amino acids into protein-based drugs such as IL-2, a protein that regulates numbers of white blood cells. The approach could be used to design drugs that are taken up by cells more easily, for example, or that are less toxic or break down more quickly. Proteins could also be designed to have properties that conventional amino acids lack, such as the ability to strongly attract electrons. \u201cIt\u2019s like being a kid in a candy store,\u201d says Romesberg. But in this case, \"the kid spent 20 years fantasizing about getting into that candy store. All of sudden I\u2019m thinking what kind of candy can I get.\u201d Teams led by Benner and Ichiro Hirao, a biological chemist at the Institute of Bioengineering and Nanotechnology in Singapore, have already developed test-tube systems for using foreign DNA to encode unnatural amino acids. But Hirao sees advantages to moving into living cells. Proteins containing unnatural amino acids could be made at larger scale and more cheaply using bacterial cells, he says. Bringing the technology to eukaryotic cells would allow for the development of new antibody drugs, too. However, Benner, who is now based at the Foundation for Applied Molecular Evolution near Gainesville, Florida, suggests that because Romesberg\u2019s system relies on relatively weak hydrophobic forces to hold foreign base pairs together, its potential for industrial applications might be limited. Cells may tolerate the rare foreign base, Benner says, but \u201cone simply cannot build an entire genetic system from them\u201d. Romesberg and his colleagues are now working on expanding their genetic alphabet further. So far, the team has identified 12 more codons containing X and Y that are functional, says Romesberg, but \u201cthere\u2019s a lot yet to do\u201d.\n \n                     First life with 'alien' DNA 2014-May-07 \n                   \n                     Chemical biology: DNA's new alphabet 2012-Nov-21 \n                   \n                     DNA gets a fake fifth base 2005-Mar-16 \n                   \n                     Augmenting the alphabet 2000-Aug-30 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.23043", "url": "https://www.nature.com/articles/nature.2017.23043", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Long-awaited industrial strategy pins hopes on commercial gains from research. The United Kingdom has laid out how it will pour money into research to boost its economy \u2014 including cash for artificial intelligence and other high-tech industries \u2014 as the country prepares to leave the European Union in 2019. Science does not usually sit at the forefront of British economic-policy documents. But the UK government\u2019s new  industrial strategy , released on 27 November, is sprinkled liberally with references to research and development (R&D) throughout, emphasizing the government\u2019s increasing focus on research as a remedy for economic woes. \u201cIt feels like science permeates this strategy,\u201d says Graeme Reid, a science-policy researcher at University College London. The shift in emphasis is positive, but it will come with expectations, says Paul Nightingale, deputy director of the Science Policy Research Unit at the University of Sussex in Brighton, UK. Historically, commercializing research has not been seen as a strength of the UK universities system. But in return for more R&D cash, universities will now be expected to improve how they interact with local businesses and people, and to increase their commercial focus, he says. \u201cThis isn\u2019t \u2018strings attached\u2019, this is ropes. My impression from talking to lots of academics is that they don\u2019t understand how big this is,\u201d he says.The industrial strategy is an effort to boost the United Kingdom\u2019s levels of worker productivity \u2014 the output per hour worked in the economy \u2014 which has remained stagnant since the financial crisis and lags behind those of other industrialized nations. In part to counter that trend, the  Conservative government has promised  to massively boost the country\u2019s R&D spending over the next decade: from 1.7% of gross domestic product (GDP) in 2015 to 2.4% by 2027. (By comparison, Germany already spends 2.9% of GDP on research; the United States, 2.8%). UK scientists have already been promised boosts in public spending. Last year, politicians committed to  yearly increases in research funding until 2020\u201321 , and  last week, they announced  that they would continue that increase in 2021\u201322, raising public research funds by a further \u00a3500 million (US$667 million), to \u00a312.5 billion. To raise private spending, the government promises to work with industry to produce a road map in the coming months; UK chancellor Philip Hammond made a start by announcing a rise in R&D tax credits (from 11% to 12%) in last week\u2019s budget. \n               Top targets \n             The industrial strategy has now picked out some specific areas on which to splash the cash. In particular, it identifies four \u2018grand challenges\u2019 in high-tech fields, which were agreed on after consultation with scientists: artificial intelligence (AI) and big data; clean growth; the future of mobility; and meeting the needs of an ageing society. These areas will benefit from an additional \u00a3725 million to be spent over the next 4 years from the  Industrial Strategy Challenge Fund (ISCF)  \u2014 a cash pot that has allocated \u00a31 billion since its launch last year. Meanwhile, some \u00a345 million will be spent to support more PhD students in AI and related disciplines, the strategy adds, increasing numbers by at least 200 places a year by 2020\u201321. And as parts of its efforts to address regional inequality, the government will launch a \u00a3115 million \u2018Strength in Places Fund\u2019 to support local pockets of excellence in science and innovation. Other measures likely to directly affect academic scientists include a promised boost to a stream of funding that is allocated directly to universities, and spent at their discretion. This \u2018quality-related\u2019 funding (so named because it is allocated according to an audit of the quality of university research) is crucial for blue-skies and basic research, but has remained largely unchanged since 2010. An unspecified stream of money is also promised for a competitive fund designed to support multi- and interdisciplinary research that was proposed in  a 2015 review by Nobel laureate Paul Nurse . The strategy mentions a plethora of technology-based schemes, including unspecified \u2018sector deals\u2019 with industry to drive productivity in areas such as life sciences and automotive industries. It is likely that the government will not have enough capacity to manage them all internally, says Kieron Flanagan, a science-policy researcher at the Alliance Manchester Business School, UK. Flanagan thinks that this will ultimately put greater responsibility into the hands of  UK Research and Innovation  (UKRI), an overarching organization that from 2018 will consolidate and oversee the activities of nine existing UK funding agencies, including both basic funding and commercially-focused innovation. If the organization ends up steering the direction of more industrial R&D, \"it makes UKRI a uniquely powerful beast\u201d, he says. \n                     UK government announces research-spending hike ahead of budget 2017-Nov-20 \n                   \n                     The most powerful man in UK science on his new role 2017-Feb-08 \n                   \n                     UK scientists excited by surprise \u00a32-billion government windfall 2016-Nov-23 \n                   \n                     UK Industrial Strategy \n                   Reprints and Permissions"},
{"file_id": "nature.2017.23031", "url": "https://www.nature.com/articles/nature.2017.23031", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Researchers funded by the US military are developing appliances to record neural activity and automatically stimulate the brain to treat mental illness. Brain implants that deliver electrical pulses tuned to a person\u2019s feelings and behaviour are being tested in people for the first time. Two teams funded by the US military\u2019s research arm, the Defense Advanced Research Projects Agency (DARPA), have begun preliminary trials of \u2018closed-loop\u2019 brain implants that use algorithms to detect patterns associated with mood disorders. These devices can shock the brain back to a healthy state without input from a physician. The work, presented last week at the Society for Neuroscience (SfN) meeting in Washington DC, could eventually provide a way to treat severe mental illnesses that resist current therapies. It also raises thorny ethical concerns, not least because the technique could give researchers a degree of access to a person\u2019s inner feelings in real time. The general approach \u2014  using a brain implant to deliver electric pulses that alter neural activity  \u2014 is known as deep-brain stimulation. It is used to treat movement disorders such as Parkinson\u2019s disease, but has been less successful when tested against mood disorders. Early evidence suggested that constant stimulation of certain brain regions could ease chronic depression, but a major study involving 90 people with depression found no improvement after a year of treatment. 1 The scientists behind the DARPA-funded projects say that their work might succeed where earlier attempts failed, because they have designed their brain implants specifically to treat mental illness \u2014 and to switch on only when needed. \u201cWe\u2019ve learned a lot about the limitations of our current technology,\u201d says Edward Chang, a neuroscientist at the University of California, San Francisco (UCSF), who is leading one of the projects. DARPA is supporting Chang\u2019s group and another at Massachusetts General Hospital (MGH) in Boston,  with the eventual goal of treating soldiers and veterans who have depression and post-traumatic stress disorder . Each team hopes to create a system of implanted electrodes to track activity across the brain as they stimulate the organ. The groups are developing their technologies in experiments with people with epilepsy who already have electrodes implanted in their brains to track their seizures. The researchers can use these electrodes to record what happens as they stimulate the brain intermittently \u2015 rather than constantly, as with older implants. \n               Mood map \n             At the SfN meeting, electrical engineer Omid Sani of the University of Southern California in Los Angeles \u2014 who is working with Chang\u2019s team \u2014 showed the first map of how mood is encoded in the brain over time. He and his colleagues worked with six people with epilepsy who had implanted electrodes, tracking their brain activity and moods in detail over the course of one to three weeks. By comparing the two types of information, the researchers could create an algorithm to \u2018decode\u2019 that person\u2019s changing moods from their brain activity. Some broad patterns emerged, particularly in brain areas that have previously been associated with mood. Chang and his team are ready to test their new single closed-loop system in a person as soon as they find an appropriate volunteer, Sani says. Chang adds that the group has already tested some closed-loop stimulation in people, but he declined to provide details because the work is preliminary. The MGH team is taking a different approach. Rather than detecting a particular mood or mental illness, they want to map the brain activity associated with behaviours that are present in multiple disorders \u2014 such as difficulties with concentration and empathy. At the SfN meeting, they reported on tests of algorithms they developed to stimulate the brain when a person is distracted from a set task, such as matching images of numbers or identifying emotions on faces. The researchers found that delivering electrical pulses to areas of the brain involved in decision-making and emotion significantly improved the performance of test participants. The team also mapped the brain activity that occurred when a person began failing or slowing at a set task because they were forgetful or distracted, and found they were able to reverse it with stimulation. They are now beginning to test algorithms that use specific patterns of brain activity as a trigger to automatically stimulate the brain. \n               Personalized treatment \n             Wayne Goodman, a psychiatrist at Baylor College of Medicine in Houston, Texas, hopes that closed-loop stimulation will prove a better long-term treatment for mood disorders than previous attempts at deep-brain stimulation \u2014 partly because the latest generation of algorithms is more personalized and based on physiological signals, rather than a doctor's judgement. \u201cYou have to do a lot of tuning to get it right,\u201d says Goodman, who is about to launch a small trial of closed-loop stimulation to treat obsessive\u2013compulsive disorder. One challenge with stimulating areas of the brain associated with mood, he says, is the possibility of overcorrecting emotions to create extreme happiness that overwhelms all other feelings. Other ethical considerations arise from the fact that the algorithms used in closed-loop stimulation can tell the researchers about the person\u2019s mood, beyond what may be visible from behaviour or facial expressions. While researchers won't be able to read people's minds, \u201cwe will have access to activity that encodes their feelings,\u201d says Alik Widge, a neuroengineer and psychiatrist at Harvard University in Cambridge, Massachusetts, and engineering director of the MGH team. Like Chang and Goodman\u2019s teams, Widge\u2019s group is working with neuroethicists to address the complex ethical concerns surrounding its work. Still, Chang says, the stimulation technologies that his team and others are developing are only a first step towards better treatment for mood disorders. He predicts that data from trials of brain implants could help researchers to develop non-invasive therapies for mental illnesses that stimulate the brain through the skull. \u201cThe exciting thing about these technologies,\u201d he says, \u201cis that for the first time we\u2019re going to have a window on the brain where we know what\u2019s happening in the brain when someone relapses.\u201d \n                     External brain stimulation goes deep 2016-Nov-22 \n                   \n                     Memory-boosting devices tested in humans 2015-Nov-03 \n                   \n                     The Pentagon\u2019s gamble on brain implants, bionic limbs and combat exoskeletons 2015-Jun-10 \n                   \n                     Memory-saving devices snag US research funds 2014-Jul-10 \n                   \n                     Neuroscience: Tuning the brain 2014-Mar-19 \n                   Related external links Reprints and Permissions"},
{"file_id": "d41586-017-07766-9", "url": "https://www.nature.com/articles/d41586-017-07766-9", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-07808-2", "url": "https://www.nature.com/articles/d41586-017-07808-2", "year": 2017, "authors": [{"name": "Nisha Gaind"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-07759-8", "url": "https://www.nature.com/articles/d41586-017-07759-8", "year": 2017, "authors": [{"name": "Zeeya Merali"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-07794-5", "url": "https://www.nature.com/articles/d41586-017-07794-5", "year": 2017, "authors": [{"name": "Cally Carswell"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-07869-3", "url": "https://www.nature.com/articles/d41586-017-07869-3", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-07817-1", "url": "https://www.nature.com/articles/d41586-017-07817-1", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-07879-1", "url": "https://www.nature.com/articles/d41586-017-07879-1", "year": 2017, "authors": [{"name": "Helen Shen"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08236-y", "url": "https://www.nature.com/articles/d41586-017-08236-y", "year": 2017, "authors": [{"name": "Jeff Tollefson"}, {"name": "Emiliano Rodr\u00edguez Mega"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08244-y", "url": "https://www.nature.com/articles/d41586-017-08244-y", "year": 2017, "authors": [{"name": "Emma Young"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "nature.2017.23049", "url": "https://www.nature.com/articles/nature.2017.23049", "year": 2017, "authors": [{"name": "John Pickrell"}], "parsed_as_year": "2006_or_before", "body": "Embryos found in some fossil eggs suggest that hatchlings struggled to fly. A remarkable fossil slab containing hundreds of pterosaur eggs and some embryos has been discovered in China 1 . The find looks set to transform palaeontologists\u2019 understanding of these enigmatic creatures. The early life of pterosaurs \u2014 the first vertebrates to evolve powered flight \u2014 has been a mystery. It was only in 2004 that scientists even confirmed that they laid eggs, and until now, only a handful of eggs had been found. The newly discovered trove, belonging to a species called  Hamipterus tianshanensis  that lived around 120 million years ago, offers clues into the development and anatomy of freshly hatched pterosaurs. It also provides the first solid evidence that, like many dinosaur species, these animals nested in groups 2 , 3 . The fossils, reported in the 1 December issue of  Science 1 , were discovered in the Turpan-Hami Basin in Xinjiang, northwestern China. From 2006 to 2016, Wang Xiaolin of the Chinese Academy of Sciences' Institute of Vertebrate Paleontology and Paleoanthropology in Beijing and his colleagues excavated a 3-square-metre sandstone block to reveal at least 215 squashed and cracked eggs among jumbled pterosaur bones. They think that up to 300 eggs could be present, some buried below the upper layers of fossils. The team used computed tomography scanning to peer inside 42 eggs, and found 16 that contained the remains of embryos at various stages of development, with partial skulls and limb bones. Other experts say that the find will be significant for understanding pterosaur reproduction. It\u2019s \u201ca crucial advance\u201d, writes Charles Deeming, who studies bird and reptile reproduction at the University of Lincoln, UK, in a commentary also published in  Science 4 . Mark Witton, who researches the reptiles at the University of Portsmouth, UK, says that  Hamipterus  now \u201chas the potential to be one of the most completely known pterosaurs of all\u201d.  \n               Group nesting \n             Although the eggs are not in their original nest positions \u2014 they were probably washed together by a storm event \u2014 the authors argue that the series of embryos and juveniles at different developmental stages strongly suggests that they nested as a group. \u201cThis is something we\u2019ve long suspected might happen, but it\u2019s neat to see it confirmed with fossils,\u201d says Witton. Further examination of the microscopic structure of the embryonic bones also revealed a surprise, says Wang. Until now, the consensus has been that hatchling pterosaurs could fly almost from birth. The team found well-developed femur (thigh) bones, which are important for walking \u2014 but the animals\u2019 forelimbs, which are necessary for flight, were underdeveloped. \u201cWe conclude that [baby] pterosaurs, at least  Hamipterus , can walk on the ground, but not fly in the sky,\u201d says Wang. But Witton isn't convinced. He thinks that most pterosaurs probably had well-developed wings upon hatching, but that some features were made of cartilage, which is less likely to fossilize. \u201cThese animals would weigh just a few grams when hatched, and almost certainly didn\u2019t need crisply sculpted, well-ossified wing bones to fly,\u201d he says. \u201cCartilage would be strong enough.\u201d His own team\u2019s work,  presented in September  at the Symposium on Vertebrate Palaeontology and Comparative Anatomy in Birmingham, UK, has found that hatchling fossils of two other pterosaur species do look flight-ready, with bones that appear robust and have high bending strength 5 . Deeming also cautions against inferring too much from what remains a limited data set \u2014 perhaps the  Hamipterus  embryos studied by Wang weren\u2019t close to hatching after all, he suggests. Palaeontologist and co-author of the  Science  paper 1  Alexander Kellner, of Brazil\u2019s National Museum at the Federal University of Rio de Janeiro, hopes that other eggs already being unearthed from the Xinjiang site will fill some gaps. \u201cWe hope to find embryos in different stages,\u201d he says, \u201cto have a complete embryological sequence.\u201d \n                     Tiny pterosaur claims new perch on reptile family tree 2016-Aug-31 \n                   \n                     Earliest known dino relative found 2012-Dec-05 \n                   \n                     Dinosaur predators hunted in the dark 2011-Apr-14 \n                   \n                     Perfect pterosaur found in fossil egg 2004-Jun-10 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22976", "url": "https://www.nature.com/articles/nature.2017.22976", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Beam generator puts country in elite company for doing experiments in materials science and other fields. China is revving up its next-generation neutron generator and will soon start experiments there. That will lift the country into a select group of nations with facilities that produce intense neutron beams to study the structure of materials. The China Spallation Neutron Source (CSNS) in Dongguan, a 2.2-billion-yuan (US$331-million) centre, will allow the country\u2019s growing pool of top-notch physicists and material scientists, along with international collaborators, to compete in multiple physics and engineering fields. Its designers also hope that the facility will lead to commercial products and applications ranging from batteries and bridges to aeroplane engines and cancer therapy. \u201cIt is not only a big step forward for Chinese scientists, but also a significant event for the international scientist community,\u201d says Wang Xun-Li, a physicist at the City University of Hong Kong who has been involved in planning the facility. \n               Beam bombardment \n             Spallation neutron sources produce neutrons by slamming protons onto a metal target \u2014 CSNS uses tungsten. They are more cost effective and safer than other methods, which use nuclear reactors to produce neutron beams. As neutrons have no charge, they can penetrate materials more easily than some other probing methods, and they are more sensitive to light elements such as hydrogen, making them useful for evaluating candidate materials for fuel cells. Similar facilities exist only in the United Kingdom, United States, Japan and Switzerland, and one is under construction in Sweden. Fujio Maekawa, a specialist in neutron sources at the Japan Proton Accelerator Research Complex in Tokaimura, says that although the CSNS delivers neutrons at a lower density than other spallation sources \u2014 which means that experiments will take longer \u2014 a planned upgrade will bring it in line with other facilities. And given their scarcity, \u201cneutron users around the world always welcome new sources\u201d, he say s. The CSNS will have capacity to host 20 beam lines, supplying as many instruments. Preliminary tests of its first three instruments began on 1 November. \u201cNeutrons arrived at the samples as expected,\u201d says Wang Fangwei, head of the neutron-science division at CSNS. Although debugging might take a couple of years, he expects the instruments to be calibrated and ready for initial experiments by the end of 2017.\u00a0 Chinese physicists are eager to use the facility to analyse the underlying magnetic properties of materials, an area in which the country has significant experience. Wang Xun-Li says that several planned instruments will give scientists the chance to move to the forefront of fields such as the physics of skyrmions \u2014 vortex-like excitations in magnetic materials \u2014 and high-temperature superconductivity. \u201cThere are a whole bunch of early- to mid-career scientists who are hungry to use the facility for studying magnetism,\u201d says Wang Xun-Li. \n               Global appeal \n             Wang Xun-Li thinks that the latest facility will encourage Chinese researchers to remain in the country instead of pursuing careers elsewhere. \u201cIn the past, it was common to see Chinese scientists go abroad for these kinds of studies,\u201d he says. The facility\u2019s first instruments are also attracting international researchers. German material scientist Frank Klose says that the CSNS was a major factor when he and material scientist Christine Rehm, his wife, decided to join the new Guangdong Technion Israel Institute of Technology in Shantou, 400 kilometres east of Dongguan. Klose\u2019s research focuses on designing data-storage devices and sensors that could be used in hydrogen-powered cars. He helped design one of the facility's instruments to investigate the magnetic properties of spintronic devices, which take advantage of the spin of electrons to store data. But scientists contacted by  Nature  have raised concerns about CSNS\u2019s location, saying that Dongguan lacks services and infrastructure, such as schools and universities, that will persuade top scientists and their families to move there. \u201cI believe CSNS is suffering from a lack of first-grade scientists who actually are based in Dongguan,\u201d says a researcher familiar with the facility, who asked for anonymity because of the sensitivity of the issue. Potential users have also expressed some frustration that only 3 instruments will be ready this year, despite the facility\u2019s capacity to host 20. But more instruments are already being built. Shenzhen's government is funding two that are expected to be ready by the end of 2019, including one designed to model high-pressure environments, such as the Earth's core. Mao Ho-Kwang, a geophysicist at the Carnegie Institution for Science in Washington DC, is keen to use it to simulate what happens to materials in high-pressure conditions. \u201cThe CSNS instruments will be a great asset for Earth, environmental and energy science, as well as physics, chemistry and material science,\u201d says Mao. \u201cI am very excited, and the whole neutron community is getting very excited too\u201d. \n                     Policy: Crystallography needs a governing body 2014-Jan-29 \n                   \n                     Sweden likely winner for neutron source 2009-Jun-03 \n                   \n                     Beamline bonanza for Japanese researchers 2008-Nov-26 \n                   \n                     Neutron science: Back on track? 2005-Dec-07 \n                   \n                     China Spallation Neutron Source \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22995", "url": "https://www.nature.com/articles/nature.2017.22995", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Increased coal use in China appears to be driving the first increase in global greenhouse-gas output since 2014. Humanity\u2019s carbon emissions are likely to surge by 2% in 2017, driven mainly by increased coal consumption in China, scientists reported on 13 November 1 , 2 , 3 . The unexpected rise would end a three-year period in which emissions have remained flat despite a growing global economy. Researchers with the Global Carbon Project, an international research consortium, presented their findings at the United Nations climate talks in Bonn, Germany. Countries there are ironing out details of how to implement the 2015 Paris climate accord,  which calls for limiting global warming to a rise of 1.5\u20132 \u00b0C . The projected jump in the world\u2019s greenhouse-gas output underlines the challenges ahead; if the latest analysis proves correct, global carbon dioxide emissions will reach a record-breaking 41 billion tonnes in 2017. \u201cWe were not particularly surprised that emissions are up again, but we were surprised at the size of the growth,\u201d says Corinne Le Qu\u00e9r\u00e9, a climate scientist at the University of East Anglia in Norwich, UK, and co-author of the work, which was published in the journals  Nature Climate Change ,  Environmental Research Letters  and  Earth System Science Data Discussions . To Le Qu\u00e9r\u00e9, the question now is whether 2017 is a temporary blip or a return to business as usual. \u201cIf 2018 is as big as 2017, then I will be very discouraged,\u201d she says. Several factors  caused the world\u2019s CO 2  emissions to level out from 2014 to 2016 , including an economic slowdown in China, the world\u2019s largest emitter; a shift from coal to gas in the United States; and global growth in the use of renewable energies such as solar and wind. Many climate scientists and policymakers had hoped that the pause in emissions growth represented a shift in energy use that would eventually cause global greenhouse-gas emissions to peak \u2014 and then decline. The latest analysis projects that CO 2  emissions in the United States and the European Union will continue to decline \u2014 by 0.4% and 0.2%, respectively, in 2017 \u2014 although at a slower pace than in recent years. And emissions growth in India is set to slow, rising by just 2% this year, compared with an average of 6% per year over the past decade. But the picture is very different in China, which produces nearly 26% of the world\u2019s output of CO 2 . This year, the country\u2019s emissions of the greenhouse gas are expected to surge by 3.5%, to 10.5 billion tonnes. The main causes are increased activity at the country\u2019s factories and reduced hydroelectric-energy production, the Global Carbon Project analysis finds. The effort highlights nagging uncertainties about greenhouse-gas emissions trends, particularly in China, India and other countries with economies that are rapidly growing and changing, says David Victor, a political scientist at the University of California, San Diego. He is not convinced that government actions \u2014 at the national or international level \u2014 have driven the recent levelling of emissions. And although emissions are projected to grow this year, Victor says that China is still  on a trajectory that would see its emissions peak well before its 2030 target . Taken together, the projections for 2017 reinforce the notion that the world has far to go before it solves the climate problem, says Glen Peters, a climate-policy researcher at the CICERO Center for International Climate Research in Oslo and a co-author of the Global Carbon Project\u2019s 2017 analysis. \u201cThis is basically saying that we are not safe yet,\u201d Peters says. \u201cWe can\u2019t be complacent.\u201d \n                     Trump pulls United States out of Paris climate agreement 2017-Jun-01 \n                   \n                     China\u2019s carbon emissions could peak sooner than forecast 2016-Mar-21 \n                   \n                     Global greenhouse-gas emissions set to fall in 2015 2015-Dec-07 \n                   \n                     China to launch cap-and-trade system 2015-Sep-25 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.23019", "url": "https://www.nature.com/articles/nature.2017.23019", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Club of physics funding agencies pushes for projects including a neutrino observatory in the Mediterranean Sea. Neutrinos, dark matter and \u03b3-rays top European physicists\u2019 wish list for the next decade of efforts to catch high-energy particles from space. The priorities are laid out in a roadmap for 2017\u201326, posted online last month by a group of funding agencies from fourteen European countries, ahead of being officially unveiled in January. Twenty years ago, the field of astroparticle physics barely existed. But some of the major discoveries in particle physics \u2014 including neutrino research that earned Nobel prizes in  2002  and  2015  \u2014 are now coming from space-focused detectors, rather than through the more conventional venue of atom smashers. It's a field that ties together the largest and smallest scales of physics, says Antonio Masiero, a physicist at the University of Padua, Italy, from the expansion of the Universe to exotic types of nuclear decay: \u201cThe beauty of astroparticle physics is that it has no borders.\u201d The roadmap is the second such exercise by the Astroparticle Physics European Consortium (APPEC), which aims to coordinate funding plans for this fast-growing field. (CERN \u2014 Europe\u2019s physics lab near Geneva, Switzerland \u2014 the European Southern Observatory and the European Space Agency do this for the continent\u2019s particle-physics, astronomy and space-based facilities, respectively.) APPEC requested input from across the community, and held an open \u2018town meeting\u2019 in Paris in April 2016 before a panel of experts, chaired by Masiero, compiled the final document. \n             Infrastructure ideals \n           The resulting strategy covers huge observatories all the way down to tabletop experiments. At smaller scales, it urges funding agencies to be open to innovative proposals. But when it comes to the largest facilities, the strategy is to be \u201cresource aware\u201d, says Masiero: focusing on only a few projects and requiring only a modest increase over current funding levels. It\u2019s not a \u201cSanta Claus list\u201d, agrees Frank Linde, a particle physicist at the Dutch National Institute for Subatomic Physics in Amsterdam and former APPEC chair. Among the big projects endorsed by APPEC is the Cubic Kilometre Neutrino Telescope (KM3NeT), a double array of deep-sea light sensors being built by a primarily Dutch, French and Italian collaboration. One site, off the coast of Toulon, France, is designed to detect relatively low-energy neutrinos produced by cosmic rays hitting the atmosphere, whereas the other, off the southern tip of Sicily, Italy, will aim to catch the signature of the highest-energy neutrinos coming from outer space, after they have travelled through Earth. Researchers hope to figure out where these particles come from. So far, KM3NeT has received one third of the approximately \u20ac150 million (US$177 million) in funding it would need for building the full-size detector, says spokesperson Mauro Taiuti, a physicist at the University of Genoa, Italy. The APPEC stamp of approval could help it to win the rest. Another major piece of infrastructure that garnered support was the  Cherenkov Array Telescope , a \u20ac300-million \u03b3-ray observatory to be split between Spain\u2019s La Palma Island and Paranal, in Chile\u2019s Atacama Desert. The two arrays of optical telescopes will seek flashes of blue light produced in the atmosphere when a high-energy photon collides with a molecule of air, creating a cascade of secondary particles across the sky. In the nascent field of gravitational-wave astronomy, which APPEC also covers, the big priority is the Einstein Telescope (ET), a next-generation triple interferometer that will have light beams running along three 10-kilometre arms in an equilateral triangle, instead of the two perpendicular arms that current detectors use. Like the Japanese interferometer KAGRA \u2014 now under construction \u2014 the proposed ET would be built underground, to protect it from vibrations ranging from footsteps to falling leaves, says B. S. Sathyaprakash, a physicist at Pennsylvania State University in University Park, who helped to design it. \n             Dark-matter dash \n           APPEC also wants Europe to double-down on existing efforts to spot dark matter, calling for a dramatic scale-up of experiments that use tanks of liquid argon and xenon, to look for traces of collisions between these mysterious particles and atoms of ordinary matter. The largest such detectors now contain more than three tonnes of the noble gases, but according to the roadmap they need to be ten times larger. These searches bet on the theory that dark matter is composed of  weakly interacting massive particles, or WIMPs . Some physicists have called for more investment in \u2018alternative\u2019 searches for dark matter, for example, looking for particles known as axions. The road map is a \u201cvanilla document, clearly redacted not to ruffle any feathers\u201d, says Juan Collar, a physicist at the University of Chicago in Illinois. \u201cIf European programme managers follow this roadmap to the letter, they will turn the dark-matter field into a desert of ideas.\u201d But Mario Livio, an astrophysicist at the University of Nevada in Las Vegas who has also called for broadening the search for dark matter, counters that concentrating efforts on WIMPs will allow Europe \u201cto build on existing experience and facilities\u201d. Overall, the roadmap is \u201cvery reasonable\u201d, he adds. \u201cThe programme, if executed as envisioned, will address some of the most exciting questions in astroparticle physics.\u201d \n                   Dark-matter hunt fails to find the elusive particles 2017-Nov-08 \n                 \n                   Colliding stars spark rush to solve cosmic mysteries 2017-Oct-16 \n                 \n                   Icy telescope throws cold water on sterile neutrino theory 2016-Aug-08 \n                 \n                   Spain and Chile chosen to host \u03b3-ray telescope 2015-Jul-16 \n                 \n                   APPEC European Astroparticle Physics Strategy 2017-2026 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22974", "url": "https://www.nature.com/articles/nature.2017.22974", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Effort aims to help scientists understand how generations of inbreeding have altered the genetics of research rodents. Adam and Eve, a pair of black mice, lived for less than two years and never left their home at the Jackson Laboratory (JAX) in Bar Harbor, Maine. But since they were bred in 2005, their progeny have spread around the globe: the pair\u2019s living descendants, which likely number in the hundreds of thousands. They are members of the most popular strain of mice used in biomedical research, which was created nearly a century ago. Now, researchers at JAX are reconstructing Eve\u2019s genome in the hopes of better understanding \u2014 and compensating for \u2014 the natural mutations that occur in lab mice over the course of generations. These genetic changes can cause unanticipated physiological effects that can confound experiments. Related substrains of lab mice can differ in their taste for alcohol or their sensitivity to insulin, for example, and researchers suspect that such differences between supposedly identical mice lines  have hampered some areas of research . The scientists who founded JAX  created Adam and Eve\u2019s breed, which is called C57BL/6, in 1921. To keep the mice as genetically similar as possible,  researchers have repeatedly bred brothers with sisters  for nearly a century \u2014 and sold the resulting offspring to customers around the world. But this strategy created a genetic bottleneck: every generation, between 10 and 30 new mutations pop up and are passed down to offspring. This \u2018genetic drift\u2019 quickly accumulates over the years, says Laura Reinholdt, a geneticist at JAX. The genomes of the C57BL/6 mice that the lab sells today have thousands of genetic differences from the mouse reference genome, which was created in 2002 from three mice from the substrain C57BL/6J. The genome is used as a template for researchers developing genetically modified mice. Other suppliers have inadvertently created divergent substrains of C57BL/6 mice when they\u2019ve bought rodents from JAX and bred them over several generations. Although most mutations go unnoticed, some occur in genes that affect a mouse's appearance or physiology. In 2016, mouse supplier Envigo in Somerset, New Jersey, found that C57BL/6 mice at 6 of its 19 breeding facilities around the world had acquired a mutation in a gene related to the immune system. The company notified the researchers that bought these mice, and asked customers to specify which location they preferred to source mice from in the future, given that the company\u2019s stocks were no longer identical. \n               Hidden changes \n             And although it is easy to spot a mutation that changes fur from black to white, for instance, some changes are discovered only if researchers are investigating a particular trait. A substrain of C57BL/6 mice that the US National Institutes of Health bred for 50 generations are uninterested in alcohol, whereas those bred at JAX\u2019s facility display a preference for alcoholic beverages. In 2005, a team at JAX decided to reset the genetic clock by selling only C57BL/6J mice descended from two chosen mice: Adam and Eve. The researchers froze hundreds of embryos of the duo's grandchildren, enough to last for 25-30 years. Every five generations, the company thaws some of these embryos and raises them to adulthood as new breeding pairs. \u201cIn some ways, the changes that are acquired are insidious and unstoppable,\u201d says Michael Wiles, the lab\u2019s senior director of technology evaluation and development, who led the project. \u201cWe\u2019ve not stopped general drift, but we\u2019ve slowed it considerably.\u201d Once the stockpiled embryos run out, however, JAX will have to start over with new breeding pairs from a much later generation. Yet Eve's genome is very different from the 2002 mouse reference genome. In a presentation last month at the American Society for Human Genetics\u2019 meeting in Orlando, Florida, JAX computational scientist Anuj Srivastava spoke about the company\u2019s effort to reconstruct Eve\u2019s genome in high detail, using three different sequencing methods. Wiles says that the genome will be finished by the end of November, and that JAX plans to publish it early in 2018. \n               Mouse trap \n             Other mouse breeders have started their own efforts to account for genetic drift. Taconic Biosciences, a mouse distributor in Hudson, New York, restarts its C57BL/6 line every ten generations from its stash of frozen embryos. Because Taconic has bred its line separately from the JAX line for decades, the Eve genome won\u2019t necessarily reflect the genetic make-up of Taconic\u2019s mice any more than the current mouse reference genome does. Ana Perez, Taconic\u2019s global director of genetic sciences and compliance, says that the company plans to publish the genome of its own Eve. \u201cFrom my perspective, each particular breeder should have their own reference genome to follow,\u201d she says. Buying mice from different breeders and expecting them to be the same is a fallacy, she adds. But most researchers don\u2019t think about the differences between the various substrains of C57BL/6 mice and how those disparities can affect reproducibility in research, says Cory Brayton, a pathobiologist at Johns Hopkins University in Baltimore, Maryland. \u201cThe vendors are pretty good about making the information available, but the awareness is still pretty low,\u201d she says. It is impossible to quantify how often experiments or entire research programmes are wasted when researchers realize that their supposedly identical mice have genetically diverged from the ancestor they bought from a vendor, but Brayton suspects it is common.The Eve genome will be a useful addition for researchers who use animals from JAX, says Brayton, although it won\u2019t solve all the reproducibility problems inherent to inbred mouse lines. \u201cIf you use [inbred mice] wisely, they can be highly informative,\u201d she says. \u201cIf you use them stupidly, they may really confound your studies.\u201d \n                     A mouse\u2019s house may ruin experiments 2016-Feb-12 \n                   \n                     Misleading mouse studies waste medical resources 2014-Mar-26 \n                   \n                     How to build a better mouse 2011-Jul-19 \n                   \n                     Mice make medical history 2002-Dec-05 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.23001", "url": "https://www.nature.com/articles/nature.2017.23001", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Analyses of governing documents from 194 countries could help people fighting for human and environmental rights. Timing can be everything when it comes to successfully expanding constitutional rights. Now, a study 1  looking at how constitutions around the world have evolved has revealed patterns that could help people predict the best moment to introduce such changes. Amendments are generally introduced into a country\u2019s constitution in a certain sequence, the authors report in a paper on the preprint server arXiv, and now under review at a journal. In addition, their computer analyses corroborate previously proposed ideas that the addition of some provisions is heavily influenced by the zeitgeist \u2014 the dominant social mores of the time \u2014 whereas the adoption of others reflects a country\u2019s colonial history. The study validates computational techniques that could be applied to pressing questions about how constitutions reflect and affect societies, says Mila Versteeg, a legal scholar at the University of Virginia in Charlottesville. \u201cThese methods might be able to move the ball if applied to the right questions,\u201d she says. Organizations and advocates could use the results to push for policies in a more strategic way, say the paper\u2019s authors. \u201cThis can be seen as a road map to help get you to where you want to be,\u201d says lead researcher Alex Rutherford, a data scientist who was working at the United Nations children\u2019s agency UNICEF in New York City when the study was conducted. \n             The ties that bind \n           Rutherford and his colleagues used two kinds of computer analyses to look for patterns in provisions from the constitutions of 194 countries. In one, using hand-coded text, they found that the number of provisions increased over time (see \u2018Evolution of constitutions\u2019). Moreover, the team found that provisions generally appeared in a particular order. Making education compulsory, for example, was usually preceded by the establishment of a right to a free education. Some of the sequences were less straightforward: the right to form trade unions preceded laws against child labour, for example. This progression probably reflects the identities of the people who have traditionally scripted constitutions, says Rutherford. Adult men, for instance, seem to have considered their own protections before thinking about others, including those who were unable to push for their own rights, he says. \u201cI think we should protect the most vulnerable first, but this paper says this is not how laws have progressed historically.\u201d The team then performed a network analysis to identify words that the constitutions had in common and to detect how they grouped together. In some cases, with fundamental provisions such as freedom of religion, clusters included countries that had the same former colonizers. Meanwhile, amendments such as those prohibiting torture or protecting the environment tended to emerge at specific points in time, regardless of a country\u2019s colonial history. \u201cIf you draft a constitution now, you\u2019d be more likely to include a clause on the environment than you would 20 years ago, since we didn\u2019t know much about what was going on back then,\u201d says Rutherford. \n             Seeds of the future \n           Constitutional specialists say the team\u2019s timeline of provisions seems to be new. \u201cIt makes intuitive sense, but I don\u2019t think anyone had tried to show it empirically,\u201d says David Law, a political scientist at Washington University in St Louis, Missouri. The indexed data that Rutherford and his colleagues used came from the Comparative Constitutions Project, a US-based non-profit organization partnered with Google. The project hand-codes constitutional texts by turning the words into zeroes and ones. The credibility of the network approach is boosted by the fact that the analysis of constitutional language came to similar conclusions as previous, less-automated studies. Versteeg suggests that network analysis might next be applied to questions such as what sorts of rights are not well enforced, and whether constitutions can yield subtle clues signalling that a democracy is in decline. To get at the latter query, Versteeg suggests analysing constitutional texts from  democratic countries  that have altered their constitutions and become increasingly authoritarian \u2014 such as Hungary and Turkey \u2014 to find language that gives a ruler more power. Next, researchers could search for these signatures in other countries, such as the United States. \u201cCould we tell when added rights are actually red flags bearing the signs of authoritarianism?\u201d Versteeg asks. \n                   The mathematicians who want to save democracy 2017-Jun-07 \n                 \n                   Researchers baffled by nationalist surge 2016-Dec-06 \n                 \n                   Social science: Web of war 2011-Mar-30 \n                 \n                   Comparative Constitutions Project \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22994", "url": "https://www.nature.com/articles/nature.2017.22994", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "National Science Foundation will look for partners to provide extra financial support for Puerto Rico facility. Nearly two months after Hurricane Maria devastated Puerto Rico, the people who operate one of the world\u2019s pre-eminent radio telescopes \u2014 at the Arecibo Observatory, on the northwestern part of the island \u2014 are still without reliable water, electricity and phone service at their homes. But their jobs seem to be safe. The US National Science Foundation (NSF), which funds about two-thirds of the observatory\u2019s annual US$12-million budget,  has decided to continue operating it  in collaboration with as-yet-to-be-decided partners. Over the next 5 years, the agency will  reduce its annual contribution  from $8.2 million to $2 million, with the rest coming from the unspecified partner institutions. \u201cThis is very good news for the Arecibo Observatory and a huge win for the scientific community in general,\u201d says Francisco C\u00f3rdova, the observatory's director. \u201cThere is definitely a sense of relief in the air.\u201d The decision comes as part of  the NSF\u2019s years-long effort to offload several of its astronomical research facilities  to free up millions of dollars each year for future projects, such as the Large Synoptic Survey Telescope that is under construction in Chile. \u201cWe have worked very hard to help bring Arecibo to a state where we still have cutting-edge research there, but with NSF not having to make the same investment that we've made historically,\u201d says James Ulvestad, acting assistant director for the agency\u2019s mathematical- and physical-sciences directorate. The current management contract at the observatory will expire on 31 March 2018. Earlier this year, the NSF asked potential partners to come forward with ideas and funding offers to keep science operations going. Now, having made its commitment to continue funding the observatory official, the NSF can move forward with negotiating a collaboration agreement and revealing who its partners will be. \u201cI\u2019m so happy they made the right decision,\u201d says Edgard Rivera-Valent\u00edn, a planetary scientist who works jointly at the observatory and the Lunar and Planetary Institute in Houston, Texas. \u201cI\u2019m so happy the observatory stays alive.\u201d \n             Slow recovery \n           The agency\u2019s decision is a welcome reprieve for the roughly 120 Arecibo staff who have suffered and rallied in Maria\u2019s wake.  Hurricane-force winds blasted Puerto Rico on 20 September , downing power lines and damaging buildings across the island. Torrential rains washed out roads and knocked out water supplies. At the observatory, which is nestled into the limestone mountains above the city of Arecibo, some of the staff sheltered in place during the worst of Maria. The observatory\u2019s concrete bunkers, built by the US government in 1963, weathered the storm with little problem. Still, Maria\u2019s winds tore down the 29-metre-long \u2018line feed\u2019 antenna that stretched across the observatory\u2019s 305-metre-wide dish, puncturing its aluminium skin in places. Staff went to work helping to clear roads around the region, and government officials used the observatory\u2019s helipad as a distribution point for supplies. The facility\u2019s deep well supplied hundreds of local residents who had no other source of clean drinking water. Within weeks, the Arecibo dish was cleaned up and back to doing science. On 29 September, it resumed taking observations, in a low-power mode that lets the sky drift across the field of view; on 7 November, it resumed pointing the dish at specific areas of the sky. The telescope has already observed a fast radio burst, one of a new class of astronomical phenomena that Arecibo is well suited to study with its enormous dish. Last week, the observing schedule expanded to include work at additional radio frequencies, C\u00f3rdova says. But telescope operations are still running off generators, and diesel is a precious commodity on the island, says Nicholas White, senior vice-president for science at the Universities Space Research Association in Columbia, Maryland, which helps to manage the observatory. \u201cThat\u2019s the biggest constraint \u2014 just getting back on the grid,\u201d he says. Without a reliable power supply, the observatory cannot restart its planetary radar, which tracks and characterizes near-Earth asteroids. NASA supplies $3.7 million \u2014 about one-third of Arecibo\u2019s budget \u2014 for this work. The NSF estimates that it will take between $4 million and $8 million to fix the hurricane damage at the observatory, Ulvestad says. The agency \u201cintends to repair Arecibo to its pre-hurricane condition\u201d, he says. \n             A long history \n           The NSF decision makes Arecibo the first of the agency's astronomical facilities to have completed a full environmental-impact review of its operations, with an eye towards divestment. The agency is working through a similar process to potentially divorce itself from the Green Bank Observatory in West Virginia, home to the world\u2019s premiere single-dish radio telescope, and several other observatories. Arecibo occupies a unique place in the history of radio astronomy. On 16 November 1974, it beamed the most powerful intentional message ever sent in the hope of contacting extraterrestrial life. In the same year, it was used in the discovery of the first known binary pulsar, whose change in orbital period provided the first indirect evidence for gravitational waves \u2014 the ripples in space-time predicted by Albert Einstein. \u201cPeople have been telling us for five years: \u2018You guys are just out to close Arecibo,\u2019\u201d says Ulvestad. \u201cThis is a demonstration that that was not what we were ever out to do.\u201d \n                   Puerto Rico struggles to assess hurricane\u2019s health effects 2017-Nov-15 \n                 \n                   Legendary radio telescope hangs in the balance 2017-Jan-10 \n                 \n                   Daring Chinese telescope is poised to transform astronomy 2016-Sep-26 \n                 \n                   Arecibo Observatory director quits after funding row 2015-Nov-09 \n                 \n                   US struggles to offload telescopes 2014-Jan-28 \n                 \n                   Arecibo Observatory \n                 \n                   NSF decision \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22973", "url": "https://www.nature.com/articles/nature.2017.22973", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "While dealing with their own losses, public-health researchers are regrouping to study the aftermath of Hurricane Maria. Nightfall sets a hard deadline for a team of public-health researchers in Puerto Rico. Since Hurricane Maria hit on 20 September, leaving large swathes of the island without a reliable power supply, the scientists have rushed home each night to avoid being in the streets after dark. Many lack running water, and most have limited telephone access. Yet the team \u2013\u2014 co-led by Jos\u00e9 Cordero of the University of Georgia in Athens \u2014 has managed to contact several hundred women to begin assessing whether Hurricane Maria has worsened drinking-water contamination, stress and infectious disease that could harm developing fetuses. This wasn\u2019t what the researchers set out to study six years ago when they started a project to assess the impact of pollution on pre-term births. But Cordero's team is one of several research groups have scrambled to quantify Hurricane Maria\u2019s immediate health impacts, even as team members struggle to fulfil their own basic needs. The devastation that Cordero saw on a recent visit to Puerto Rico, his birthplace, shocked him. \u201cI thought I was prepared, but I wasn\u2019t,\u201d he says. Even before the hurricane, the island\u2019s 18 \u2018Superfund\u2019 sites \u2014 areas so polluted that the US Environmental Protection Agency deems them hazardous to human health or the environment \u2014 posed a potential risk to pregnant women, says Ingrid Padilla, an environmental engineer at the University of Puerto Rico at Mayag\u00fcez. Twelve of these sites sit on karst, a type of porous terrain that allows toxic chemicals to flow down from the surface into groundwater. Padilla\u2019s previous research suggests that flooding and other disturbances can quickly bring toxic substances in groundwater back to the surface, and carry them into the water supply. Now, she and her colleagues are collecting hair and blood samples from the research cohort to determine whether pregnant women are being exposed to hazardous chemicals, such as phthalates and chloroform. Since the hurricane hit, the researchers have begun to collect and test groundwater from karst regions and tap water from the homes of people living there. Other research teams are worried that water that has pooled in hurricane debris could provide a breeding ground for disease-carrying mosquitoes. At the height of the Zika epidemic in 2016, experts debated whether a massive hurricane would destroy mosquito habitat or enhance it, says Carmen Zorrilla, an obstetrician and gynaecologist at the University of Puerto Rico in San Juan. The evidence is still unclear, she says, and logistical problems may make it impossible for researchers to gather enough data to provide answers. In some areas where hospitals faced extensive storm damage, the only medical care available is emergency treatment. Screening for the Zika virus is a low priority, and infected adults rarely experience severe symptoms and are unlikely to seek medical treatment. There are also few labs on the island that can test samples for Zika and other mosquito-borne diseases. Like many Puerto Rican facilities, the US Centers for Disease Control and Prevention (CDC) dengue lab in San Juan lost power during the hurricane and was closed for a week. Diesel generators kept its freezers running to preserve blood and other biological samples, but the lab is still running on generator power and is behind on testing some samples. Shipping delays destroyed reagents that the lab had ordered, since the chemicals were not kept consistently cold during transport. Lab director Stephen Waterman says that the CDC is collecting data on the incidence of mosquito-borne disease and other hurricane impacts. But its priority is to help US government workers and local communities recognize mosquito breeding grounds, and to provide technical help on efforts to control the spread of the insects. Agency staff would also like to verify reports that leptospirosis \u2014 a waterborne bacterial disease that is spread by rats \u2014 has sickened dozens of people. \u201cWe\u2019re focused on preventing disease,\u201d Waterman says. Yet the ruined facilities and lack of power continue to tax public-health workers\u2019 ability to know where hazards lie. Take the numerous diesel generators running on the island, which produce visible plumes of grey smoke. Benjamin Bola\u00f1os, a microbiologist at the University of Puerto Rico in San Juan, worries that these emissions could harm people with respiratory illnesses, but that the effect will be difficult to quantify. \u201cWe are blind because probably the [air quality] monitors were destroyed by the hurricane,\u201d he says. This makes the prospect of more months without reliable power even more frightening. \"The kind of work we\u2019re doing is not because it would be interesting to do,\u201d Cordero says. \u201cIt has to be done now because a few years from now, it\u2019s too late.\u201d \n                     Hurricanes Harvey and Irma send scientists scrambling for data 2017-Sep-27 \n                   \n                     How labs are coping with Hurricane Harvey's devastating floods 2017-Aug-31 \n                   \n                     US biomedical-research facilities unprepared for attacks and natural disasters 2017-Aug-10 \n                   \n                     Hurricane Katrina\u2019s psychological scars revealed 2015-Aug-24 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22984", "url": "https://www.nature.com/articles/nature.2017.22984", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Bizarre tale of theft and suspicious packages casts doubt on claims for early-human occupation in northern Europe. Serious concerns have surfaced about three research papers claiming evidence for one of the earliest human occupations of Europe. In an extraordinary letter  posted to the bioRxiv.org preprint server  on 31 October 1 , archaeologists allege that the papers, published in 2013, 2016 and 2017, included material of questionable provenance, and that results reported in the 2016 paper were based on at least one stolen bone. Editors at the journals concerned have now published expressions of concern about the papers. There is no suggestion that the authors of those papers were involved in theft, but the researchers behind the letter say they are concerned that appropriate questions regarding the provenance of the material appear not to have been asked. They also reject the authors\u2019 conclusion that a German site known for animal remains was also home to hominins, ancient relatives of humans, 1 million years ago. The authors have denied the allegations and say they stand by their conclusion. The letter was initiated by archaeologist Wil Roebroeks at Leiden University in the Netherlands, and Ralf-Dietrich Kahlke, a palaeontologist and head of the Senckenberg Research Station of Quaternary Palaeontology in Weimar, Germany, who leads excavations at Untermassfeld, a fossil site about 150 kilometres northeast of Frankfurt. Their preprint describes repeated disappearances of bones from Untermassfeld, as well as fossils delivered in anonymous packages. The authors of the disputed papers insist, however, that they analysed independent collections of bones and stones, and reject the suggestion that any of it was stolen. Untermassfeld, which has yielded more than 14,000 large animal fossils dating from between 900,000 and 1.2 million years ago, holds the most complete record of northern European wildlife from this time period. But since yearly excavations began in the late 1970s, no hominin bones or signs of occupation have been found, says Kahlke. Hominins first settled in southern Europe around 800,000 to 1 million years ago, most archaeologists agree, and expanded farther north only sporadically until around 500,000 years ago. \n               Uncertain origins \n             One of the first claims that hominins lived near Untermassfeld more than 1 million years ago appeared in a 2013 paper in the journal  Quaternary International , which contended that rocks from the site resembled stone tools 2 . In a 2016  Journal of Human Evolution  paper 3 , two of the original paper's authors, G\u00fcnter Landeck at the North Hessian Society of Prehistory and Archeology of the Medieval in Bad Hersfeld, Germany, and Joan Garcia Garriga at  the Universitat Oberta de Catalunya in Barcelona , concluded that marks on animal bones from Untermassfeld were made by humans. In 2017, Landeck and Garcia Garriga published further analysis of the bones in another  Quaternary International  paper 4 . There is no suggestion that the other co-authors of the 2013 paper had any connection with the material from Untermassfeld. And after this article was published, Garcia Garriga contacted  Nature  to say that he, also, did not have connections with the material; he said that Landeck had done the analysis, while he himself helped in discussing data and writing up its archaeological implications. In their papers, Landeck and Garcia Garriga attributed the material, along with hundreds of rock fragments of limestone and chert, to \u201cthe Schleusingen collection\u201d, which they stated was recovered by a biology teacher in the late 1970s and early 1980s. Kahlke says he is personally unaware of a Schleusingen collection and questions whether the material was collected at this time. Rocks like those described in the papers can be found in the vicinity of the site, but he says that animal fossils are concentrated in a small area that has been under excavation since 1978. No other research teams had permission to excavate the site during that time, Kahlke says. But he says that material was routinely stolen from the site \u2014 which he reported to the police, most recently in 2012 \u2014 until the site and fossil bed were better secured. There is no suggestion that Landeck and Garcia Garriga were involved in these thefts. One fossil that Kahlke considers suspicious is a right limb-bone fragment from an extinct species of fallow deer, described in Landeck and Garcia Garriga\u2019s 2016  Journal of Human Evolution  paper. Kahlke says that the bone in the paper seems to match a piece of deer bone that thieves broke from a larger chunk of sediment at Untermassfeld, leaving part of the bone behind. The bone fragment is present in a photograph taken on 28 May 2009, and missing in a photograph taken several days later. A rhinoceros limb fragment that disappeared from the site in 2012 also closely resembles a fossil described in the 2016 paper, Kahlke says. \n               Case unsolved \n             Deepening the mystery, a deer bone fragment was among a jumble of bones and rocks in two packages sent anonymously to a museum near Untermassfeld in March 2014. Ralf Werneburg, a palaeontologist and director of the Natural History Museum Schloss Bertholdsburg in Schleusingen, Germany, recognized the material as originating from Untermassfeld and contacted Kahlke. In Kahlke's opinion, the returned deer bone fragment is the one described in the 2016 paper, and matches up with the piece left behind after the 2009 theft. He says that the sixty-three other bone fragments in the packages also closely resemble some of the fossils described in the 2016 paper (the rhinoceros limb bone was not among them), and 11 rock fragments resemble artefacts in the 2013  Quaternary International  paper. Roebroeks and Kahlke\u2019s team analysed the material in the returned packages, and concluded that it does not support a hominin occupation at Untermassfeld. They argue that the claimed cut-marks on the animal bones, including the deer bone, were probably caused by rodents or other natural wear, they say, and the rock fragments lack telltale marks typical of hominin tools. They say that it wasn't possible to analyse other material from Landeck and Garcia Garriga\u2019s paper because its location is unclear. Nature  exchanged multiple e-mails with Landeck and Garcia Garriga about this mystery and asking for comment on the contents of this article. The researchers responded that most of the material they examined, including the deer bone fragment, was from two private collections amassed in the 1970s and early 1980s, and that much of it came from the same geological layer as Untermassfeld, but not within the site itself. They said that they presumed that some of this material was returned to the Natural History Museum Schloss Bertholdsburg in 2014 by the individual who had loaned it to them. They would not name the individual, but insisted: \u201cWe have nothing to do with a stolen bone\u201d. They added that they are planning to publish a detailed response to Roebroeks and Kahlke's allegations. The regional prosecutor\u2019s office in Meiningen that investigated the 2009 theft told  Nature  the case had been closed unsolved later that year. A 5-year statute of limitation prevents it from being reopened. The case involving the 2012 theft of the rhinoceros bone was reopened early this year after the  Journal of Human Evolution  paper was published. The prosecutor\u2019s office said that an individual, whom it declined to name because of data protection laws, had been found guilty and fined. \n               Ongoing inquiry \n             Expressions of concern published on each of the three papers note that the location of the Untermassfeld material \u201cwas not stated accurately in the publication\u201d, and that the authors have been unable to adequately clarify where it is now. Landeck and Garcia Garriga declined to comment to  Nature  on the specific details of the notes but said that they plan to publish a response. Sarah Elton, an anthropologist at the University of Durham, UK, and an editor at the  Journal of Human Evolution,  says that an investigation into the accusations is ongoing. She adds that, as a result of the case, the journal now asks prospective authors to supply complete information about the location of material included in a study, as well as how it was accessed. Other experts have been shocked by the revelations. \u201cThis paper should be retracted, of course,\u201d says Jean-Jacques Hublin, an anthropologist and a director at the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany, about the 2016 paper. But the concerns go beyond questions of provenance. Hublin says that, like Roebroeks and Kahlke, he does not accept the claim that Untermassfeld contains signs of hominin presence, and he worries that its appearance in prominent journals will cause others to accept the idea, despite the lack of evidence for it. The debate around Untermassfeld, Roebroeks and his colleagues say, underscores the importance of providing accurate descriptions of the provenance of published material, which is needed to verify claims. The desire to set the record straight about the arrival of hominins to Europe was the primary motivation for the team\u2019s letter, he says. Based on his analysis, Roebroeks argues: \u201cThese bones and stones are not indicative of hominin presence.\u201d \n               With additional reporting by Alison Abbott \n             \n                     Oldest ancient-human DNA details dawn of Neanderthals 2016-Mar-14 \n                   \n                     Teeth from China reveal early human trek out of Africa 2015-Oct-14 \n                   \n                     Human ancestors in Eurasia earlier than thought 2011-Jun-06 \n                   \n                     Fossil find is oldest European yet 2008-Mar-26 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22956", "url": "https://www.nature.com/articles/nature.2017.22956", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "A former pharmaceutical boss will help navigate the UK\u2019s exit from the European Union. Patrick Vallance, president of research and development at the pharmaceutical giant GlaxoSmithKline, has been appointed as chief scientific adviser, the UK government announced on 8 November. Vallance, a clinical pharmacologist who previously led the medical division at University College London, will replace Mark Walport in April 2018. Walport has left the government to become  head of a powerful new funding body called UK Research and Innovation . As chief scientific adviser, Vallance will advise the prime minister and her cabinet, the government\u2019s most senior decision-making body. He will also lead the Government Office for Science, which promotes the use of scientific evidence in policymaking across government. A major part of his role will be to ensure that high-quality advice is available across government departments as they deal with the legal and regulatory consequences of the UK\u2019s decision to leave the European Union, says Graeme Reid, a science-policy researcher at University College London. The United Kingdom needs to manage the impact of Brexit on the  regulation of the nuclear industry and the UK\u2019s role in fusion research , as well as on  environment policy  and other science-related issues. \u201cPatrick Vallance\u2019s experience in both business and universities will be of huge value,\u201d says Reid. Brexit is likely to boost the day-to-day importance of chief scientific advisor's role, but Vallance will also have to reinvent other, more informal aspects of the position, says Kieron Flanagan, a science-policy researcher at the Alliance Manchester Business School. The creation of UK Research and Innovation,  intended to increase the power of UK research-funding bodies , means Walport will continue to wield great influence over science in government. The chief scientific adviser has traditionally been the voice of science in government, Flanagan says. The relationship between Vallance and Walport will be an interesting dynamic to watch, says James Wilsdon, a research-policy specialist based at the University of Sheffield, UK. He says he hopes that Vallance will act as a bridge between the science community and policymakers, and will be open to a wide range of people and perspectives. The network of chief scientific advisers  is not yet operating at full strength , he says, \u201cso re-energising the collegiality and connectivity of that network though Whitehall is a really important thing\u201d. The role is less well-paid than Vallance\u2019s present position. His base salary at GlaxoSmithKline is \u00a3780,000 (US$1.02 million), but the science-adviser job was advertised in the salary range of \u00a3160,000\u2013\u00a3180,000. Vallance will be the third successive chief scientific adviser to come from the biomedical sciences. He follows Walport, who is a former director of the Wellcome Trust, and John Beddington, a population biologist now at the Oxford Martin School and the University of Oxford, UK. In a separate announcement, GlaxoSmithKline announced that it had appointed Hal Barron, current president of research and development at Alphabet-funded California Life Sciences, to replace Vallance. \n                     Delay in hiring science advisers intensifies Brexit worries 2017-Feb-20 \n                   \n                     The most powerful man in UK science on his new role 2017-Feb-08 \n                   \n                     Britain names next chief science adviser 2012-Jul-03 \n                   \n                     Experimental project gives big pharma its youth back 2012-Feb-07 \n                   \n                     Deep future of drug discovery 2011-Mar-02 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.23022", "url": "https://www.nature.com/articles/nature.2017.23022", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Ketamine lifts rodents' mood only if administered by male researchers. Mouse experiments with the popular club drug ketamine may be skewed by the sex of the researcher performing them, a study suggests. The findings, presented on 14 November at the Society for Neuroscience (SfN) meeting in Washington\u00a0DC, only  deepen the mystery  of how ketamine, which has powerful mood-lifting properties, interacts with the brain. They also raise questions about the reproducibility of behavioural experiments in mice. Ketamine is best known as a psychoactive recreational drug. But it has caught psychiatrists\u2019 interest because of its  potential to treat depression  within hours. It\u2019s unclear exactly how the drug works, however, and many researchers are using animal models to suss out the mechanism. Polymnia Georgiou, a neuroscientist at the University of Maryland in Baltimore, is one of them. In 2015, a male colleague asked her to run some experiments for him while he was out of town, including a standard way of testing antidepressants called the forced-swim test. In this assay, researchers inject healthy mice with a drug, place them into a tank of water and measure how long they swim before they give up and wait for someone to rescue them. Antidepressants can cause healthy mice to swim for longer than their untreated counterparts, which is what Georgiou\u2019s male colleague found during his experiments using ketamine. \n             Scents and the brain \n           But although Georgiou followed his protocol exactly, she found that treated mice did not swim for any longer than mice injected with a placebo. When she and three female and four male researchers investigated this disconnect by performing the experiments, they discovered that the ketamine acted as an antidepressant only when it was administered by men. Suspecting that scent was involved, the researchers put the animals inside a fume hood so that the mice couldn\u2019t smell who was injecting them. This completely eliminated the effect of the ketamine, regardless of the experimenter\u2019s sex. When Georgiou and her colleagues placed a t-shirt worn by a man next to the mice in the fume hood, mice injected with ketamine swam for longer than those injected with a placebo. This suggested that male odour was necessary for the drug to work. The head of Georgiou\u2019s lab, neuroscientist Todd Gould, learned that antidepressant researcher Ronald Duman at Yale University in New Haven, Connecticut, was seeing similar effects with female researchers in his lab that were working on ketamine experiments. So Gould asked Duman to repeat Georgiou's swim-test experiment in his own lab. When eight male and eight female researchers injected mice with ketamine, they saw the same results: mice injected by women did not respond to the drug. Georgiou and her colleagues repeated the experiments with other antidepressants, but the researchers\u2019 sex didn\u2019t seem to matter. She and Gould suspect that the antidepressant effect is the result of a specific interaction between ketamine and the male odour in the mouse brain . But other evidence suggests that the sex of the researcher can affect other types of behavioural experiment, not just those involving ketamine. A 2014 paper 1  in  Nature Methods  found that  mice were more stressed  and less likely to respond to pain when handled by a male researcher. And behavioural neuroscientist Silvana Chiavegatto of the University of S\u00e3o Paulo in Brazil, who was at Georgiou's SfN presentation, says that she has seen the same phenomenon in her lab, where she studies depression but doesn\u2019t use ketamine. \n             Rethinking the model \n           \u201cI think it\u2019s really fascinating, with wide implications for our field,\u201d says Adrienne Betz, a behavioural neuroscientist at Quinnipiac University in Hamden, Connecticut. But she cautions that the results are preliminary, and it remains to be seen whether the effect is specific to ketamine and to mice. Others disagree about the potential implications. Hundreds of papers with female experimenters demonstrate the effects of antidepressants \u2014 including ketamine \u2014 in mice, says Lisa Monteggia, a neuroscientist at the University of Texas Southwestern in Dallas. Other factors, such as whether the researcher is stressed when he or she injects the mice, might affect the animals\u2019 behaviour, she says.\u00a0 Gould and Georgiou say that their results don\u2019t necessarily invalidate previous studies; they simply show that ketamine experiments in their lab work only when men inject the mice. There is overwhelming evidence that ketamine is a powerful antidepressant in humans. Gould doubts that the sex of the person administering the drug affects how well it works in a depressed patient, but it's never been tested.  He adds that the findings suggest that researchers studying drugs' effects on mouse behaviour should report the sex of the experimenter in their publications to ensure that other labs can replicate the results. \u201cThere are a number of factors that influence replicability and are unrecognized \u2014 this is one of them,\u201d Gould says. \u201cFor us, it is an inconvenient truth.\u201d \n                   Party drug\u2019s power to fight depression puzzles scientists\u200b 2017-May-02 \n                 \n                   Rave drug holds promise for treating depression fast 2015-Jan-07 \n                 \n                   Male researchers stress out rodents 2014-Apr-28 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.23025", "url": "https://www.nature.com/articles/nature.2017.23025", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "The European Union\u2019s drug regulatory body will leave London because of the United Kingdom\u2019s Brexit plans. After more than a year of uncertainty, the new home of the European Medicines Agency (EMA) is finally clear. The European Union member states chose Amsterdam from among 19 candidates, after a secret ballot on 20 November. The transition is expected to be relatively smooth because more than 80% of staff indicated in a survey earlier this year that they would be prepared to relocate to Amsterdam with the agency. Slovakian capital Bratislava had also been a hot favourite among commentators, most particularly because Slovakia does not yet host any EU agency. However, only 14% of the staff said they would be prepared to go there. In an interview with  Nature  last month, EMA executive director Guido Rasi said that a catastrophic loss of staff on such a scale  might have crippled the agency . The EMA, with its 900 or so employees, is responsible for determining the safety and efficacy of therapies and licensing them for marketing in the EU. It also monitors adverse reactions to marketed treatments. And it has been fundamental to the development of harmonized EU-wide regulations on \u2018advanced therapies\u2019 for serious diseases such as cancer \u2014 including treatments involving biological molecules, stem cells or cells that have been genetically manipulated. In an analysis of the various bids in September, the EMA said that any transfer could result in delays to the approval of new medicines and a slowing down of some public-health initiatives such as those to tackle antimicrobial resistance. But full recovery could be expected in two to three years, it said. \n                   European Medicines Agency chief raises alarm at forced relocation 2017-Oct-12 \n                 \n                   European drug regulation at risk of stalling as agency prepares to leave London 2017-Oct-12 \n                 \n                   Europe must find a new home for its drug regulator \u2014 and a way to keep using English 2017-Apr-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.23028", "url": "https://www.nature.com/articles/nature.2017.23028", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Pledge would raise country\u2019s public research funding to \u00a312.5 billion in 2021\u201322. The UK government seems to be making good on its promises to increase research spending significantly over the next decade. In  an announcement  on 20 November, the government said that it would boost public spending on research and development (R&D) to \u00a312.5 billion (US$16.5 billion) in 2021\u201322, an increase of \u00a3500 million on what is planned for the year before. The hike builds on  a surprise announcement made last year , when politicians promised yearly  increases in research funding until 2020 . According to the London-based Campaign for Science and Engineering (CASE), the increase puts the United Kingdom on track to hit a government target to raise combined public and private spending on R&D to 2.4% of gross domestic product (GDP) by 2027. That would be a huge uptick in spending for Britain: the most recent figures show that the country spent just 1.7% of its GDP on R&D in 2015, compared with 2.9% in Germany and 2.8% in the United States. Hitting the target will also require private investment in R&D to rise, and some researchers had wondered whether the United Kingdom would rely on private spending to boost its budget past 2020. But writing in the  Times  newspaper to accompany the announcement \u2014 which came two days before the release of Britain\u2019s annual budget \u2014 Prime Minister Theresa May confirmed that the government planned to increase its public spending on R&D year on year.\u201cThis gives confidence that the government\u2019s plan is to keep rising public R&D investment on target over the next ten years to reach parity with our international competitors,\u201d said Sarah Main, director of CASE. \u201cWe seem to have turned a corner. Government is matching its long-term ambition with concrete investment.\u201dThe latest money forms part of the government\u2019s Industrial Strategy, a range of policies aimed at boosting the economy across the country. Full details of the strategy will be published on 27\u00a0November, but May added in her article that it would include ways to encourage UK leadership in artificial intelligence, big data, clean energy and self-driving cars. \n                   UK election: science spending pledges overshadowed by Brexit 2017-May-31 \n                 \n                   UK scientists excited by surprise \u00a32-billion government windfall 2016-Nov-23 \n                 \n                   Cautious welcome for UK government's vague \u00a32-billion research pledge 2016-Nov-21 \n                 \n                   Brexit chancellor\u2019s annual address is a science nail-biter 2016-Nov-09 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.23027", "url": "https://www.nature.com/articles/nature.2017.23027", "year": 2017, "authors": [{"name": "Emma Young"}], "parsed_as_year": "2006_or_before", "body": "Waxy and hairy covering enables flies to dive underwater without getting wet. More than 150 years ago, American writer Mark Twain described how flies enter Mono Lake in California then \u201cpop up to the surface as dry as a patent office report\u201d. Now scientists have identified how they do so. The alkali fly  Ephydra hians  can crawl down the side of the lake to depths of 8 metres and remain submerged for 15 minutes before emerging unscathed. Not only can it achieve this unusual feat, it does so in a lake whose waters are so alkaline and so salty that they support only algae, bacteria and brine shrimps. \n             Diving bubble \n           Now two biologists at the California Institute of Technology in Pasadena have worked out how the fly creates the bubble of air that surrounds it during the dive. Floris van Breugel and Michael Dickinson filmed flies entering a solution that mimics the sodium-carbonate-rich conditions of the lake. The flies are covered in hairs that are coated in a waxy substance that repels water. As they enter the water, an air bubble forms around their entire bodies, apart from their eyes. Not only is this bubble protective, it also provides the flies with breathable oxygen. The scientists found that the flies had a denser coat of hairs than other species that were unable to stay dry underwater. They also found that the waxy substance that coats these hairs contained smaller hydrocarbons than those of other species. They think that these two traits combine to help prevent  E. hians  from getting wet, in particular as it emerges to the surface through the negatively electrically charged air-water interface created by the conditions in the lake. The researchers report their findings in the  Proceedings of the National Academy of Sciences 1 . There are other shore flies of the same family (Ephydridae) that crawl underwater to lay eggs, but not in such hostile conditions, says van Breugel. He hopes to compare alkali flies from different lakes around the world. During the annual autumn migration, there can be as many as 2 million birds at Mono Lake at any given time, says van Breugel, and the flies are an important source of food. \u201cThis story is a beautiful example of how tiny interactions can have global ecological effects, because Mono Lake is such an important habitat for migratory birds,\u201d he says. \u201cVan Breugel and Dickinson's paper not only provides an insightful and detailed explanation of underlying mechanisms for this behaviour, it is also an elegant bit of insect natural history,\u201d says Stephen Marshall, an entomologist at the University of Guelph in Canada. Reprints and Permissions"},
{"file_id": "nature.2017.23030", "url": "https://www.nature.com/articles/nature.2017.23030", "year": 2017, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Legacy of apartheid means academia has remained largely white. There will soon be more black academics in South Africa than white ones, a study of demographic data suggests. Although more than 80% of the country\u2019s population is black, its academic sector has remained disproportionately white \u2014 a legacy of the apartheid era. But over the past decade, the proportion of black South African researchers has risen steadily: from 26% in 2005 to 35% in 2015, according to the  study , which was published 1  in  Higher Education  last month. The proportion of white academics decreased by more than 10 percentage points over the same period, to 49% in 2015 (see 'South African shift'). \u201cOur research shows that transformation is taking place and there are strong indications that it will accelerate in the future, particularly in the next decade,\u201d says David Hedding, a geomorphologist at the University of South Africa in Florida, Johannesburg, and co-author of the paper. The authors suggest that in the next decade, more than 4,000 researchers \u2014 about 27% of the country\u2019s academics, and most of them white men \u2014 will retire, which should create opportunities for younger researchers. Black researchers could outnumber white ones some time between 2020 and 2025, they say. Hedding says that it\u2019s not possible to attribute the change to a specific policy, but that the government should keep doing what it is currently doing. However, he thinks the country should focus more on nurturing PhD candidates and enticing them into academia. He and his co-author, geoinformatics specialist Greg Breetzke at the University of Pretoria, also note that black women, the country\u2019s largest demographic, remain significantly under-represented in universities, accounting for just 14% of academics in 2015. Charles Sheppard, director of management information at Nelson Mandela University in Port Elizabeth, agrees that South Africa must focus on generating local PhDs. At the moment, it produces more doctorate-holders who hail from other African countries than from the home nation, he says. \u201cWe need to work harder on getting this right,\u201d he adds. The latest study is the most well thought out, most evidenced-based and least anecdotal to address this complex problem yet, says Zeblon Vilakazi, deputy vice-chancellor at the University of the Witwatersrand in Johannesburg. \u201cThis is a step in the right direction,\u201d says Vilakazi. \n                   Giant telescope\u2019s mobile-phone \u2018dead zones\u2019 rile South African residents 2017-Nov-17 \n                 \n                   South Africa tackles crime at sea with ship-spotting satellites 2017-Nov-10 \n                 \n                   South African researchers bemoan slashed funds 2017-Oct-11 \n                 \n                   South Africa\u2019s San people issue ethics code to scientists 2017-Mar-20 \n                 \n                   Violence escalates at South African universities 2016-Oct-24 \n                 \n                   Collaboration: Strength in diversity 2014-Sep-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.23033", "url": "https://www.nature.com/articles/nature.2017.23033", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Physicists show that thunderstorms trigger nuclear reactions in the atmosphere. A streak of lightning in the skies over Japan has generated positrons \u2014 the antimatter equivalents of electrons \u2014 and radioactive carbon-14, confirming a theoretical prediction, according to a paper published in  Nature  on 22\u00a0November 1 . Since the 1990s, orbiting observatories designed to observe the heavens have also detected flashes of \u03b3-rays coming from the Earth that could have been caused when a positron meets an electron and the pair annihilate. Physicists thought these flashes originated from atmospheric phenomenon but, until now, had been unable to test the theory. To investigate, Teruaki Enoto, an astrophysicist at Kyoto University in Japan, and his collaborators set up several \u03b3-ray detectors close to the Kashiwazaki-Kariwa nuclear power plant. Winter thunderstorms in Japan are famous for their spectacular lightning, he says, and the low clouds make these relatively easy to observe. On 6 February, the detectors sensed an unusual event. A lightning bolt just off the coast shot out an initial, one-millisecond spike of \u03b3-rays, with relatively high energies of up to 10\u00a0megaelectronvolts. This was followed by a \u03b3-ray afterglow of less than half a second. Then there was a telltale signal \u2014 \u03b3-rays concentrated at 511 kiloelectronvolts of energy, which lasted for about a minute. Physicists say this is the unmistakable signature of positrons annihilating in a puff of energy as they hit electrons in the surrounding matter. Together, the three waves of \u03b3-rays point to a photonuclear reaction first proposed 2  a decade ago by Leonid Babich, a physicist at the Russian Federal Nuclear Center in Sarov. Lightning can accelerate some electrons to almost the speed of light, and the electrons can then produce \u03b3-rays. Babich proposed that when one of these \u03b3-rays hits the nucleus of a nitrogen atom in the atmosphere, the collision can dislodge a neutron. After briefly bouncing around, most of the neutrons get absorbed by another nitrogen nucleus. This adds energy to the receiving nucleus and puts it in an excited state. As the receiving nucleus relaxes to its original state, it emits another \u03b3-ray \u2014 contributing to the giveaway afterglow. Meanwhile, the nitrogen nucleus that has lost one neutron is extremely unstable. It decays radioactively over the next minute or so, emiting a positron, which almost immediately encounters an electron and the duo annihilate, producing two 511-keV photons. This was the third signal, Enoto says. He suspects that his detectors were able to see it only because the briefly radioactive cloud was low, and moving towards the detectors. This combination of circumstances might help to explain why the photonuclear signature has been seen so rarely. Enoto says that his team has observed a few similar events, but that the one described in the paper is the only clear-cut event so far. Babich also predicted that not all of the neutrons dislodged from nitrogen by a \u03b3-ray are absorbed. Some of them instead will trigger the transmutation of another nitrogen nucleus into carbon-14, a radioactive isotope that has two more neutrons than ordinary carbon. This isotope can be absorbed by organisms; it then decays at a predictable rate long after the organism\u2019s death, which makes it a useful clock for archaeologists. The main source of the carbon-14 in the atmosphere has generally been considered to be cosmic rays. In principle, lightning could also contribute to the supply. But it is not clear yet how much of the isotope is produced in this way, says Enoto, in part because it\u2019s possible that not all bolts initiate photonuclear reactions. \"I agree with their interpretation of their data,\u201d says physicist Joseph Dwyer of the University of New Hampshire in Durham. But, he adds, puzzles related to positrons in the atmosphere still remain. In particular, the photonuclear reaction seen by Enoto's team does not seem to match an event Dwyer observed in 2009 from a research aeroplane. His detector spotted a signature of positrons only for a fraction of a second \u2014 too short to originate from nuclear decay, he says. Also, his detector saw no initial flash in that case. \"If it was there, it should have been very obvious.\" See the related News & Views article, \u2018 Thunderous nuclear reactions \u2019. Reprints and Permissions"},
{"file_id": "nature.2017.23039", "url": "https://www.nature.com/articles/nature.2017.23039", "year": 2017, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Academics optimistic that the end of Robert Mugabe\u2019s authoritarian rule could boost research and international collaboration. Scientists in Zimbabwe say they are hopeful that the sudden change of political power in their country could spell a new era for its beleaguered research system. Those working in the nation hope that the shift will unlock and attract research funds from overseas, while Zimbabwean researchers abroad say that the potential for new order in their country could encourage them to return home. The authoritarian regime of Robert Mugabe, the 93-year-old who had been president of Zimbabwe for 37 years, ended abruptly on 21 November when he resigned following military and political pressure. Emmerson Mnangagwa, the former vice-president whose firing by Mugabe this month set off the revolt, was sworn in as the country's leader this morning. Elections are expected to be organized next year. The ructions have been widely celebrated both inside and outside Zimbabwe. The southern African country\u2019s economy has been in free fall for almost two decades since Mugabe fast-tracked a programme of land expropriation, which destroyed investment in its agricultural sector and undermined confidence in the economy. The turmoil led millions \u2014 including scientists \u2014 to flee the country, many into neighbouring South Africa. \n             Research roots \n           Traditionally, much of the country's research has come from ties between Zimbabwe's universities and the agriculture industry, where research and development was  considered central to its productivity . Major study areas included maize, land-management and veterinary research. But science became difficult as government funding for research dried up. Last year, the  Zimbabwe Academy of Sciences' situation became so desperate  that it implored the country\u2019s large diaspora to support the organization. International sanctions against Zimbabwe have also penalized the country\u2019s students and academics, who have not been able to access international grants, scholarships or buy equipment from foreign companies prohibited from trading with Zimbabwe, says Dexter Tagwireyi, a pharmacist at the University of Zimbabwe in Harare and head of the Zimbabwe Young Academy of Science. If the incoming government has better relationships with Western countries, such as the United Kingdom and the United States, it could mean that researchers are able to access new sources of funds, he says. At his inauguration, Mnangagwa said that Zimbabwe was ready to engage with other countries and urged the international community to reconsider their economic embargoes. The African Union, a continental group of nations including Zimbabwe, has been  pushing science, technology and innovation  as a way for African countries to achieve economic and social development. The promise of a more democratic government could also attract researchers who have left to return and swell the country\u2019s academic ranks. \u201cThis change of leader interests me to go back and serve in Zimbabwe as an academic,\u201d says a Zimbabwean researcher at the University of Johannesburg in South Africa, who asked to remain anonymous because he was concerned about what his employer might think. The prospect of order in his home country would tempt him to return \u201cat the speed of light\u201d, he says, in part because Zimbabwe is not as crime-ridden as South Africa. The sentiment was echoed by several other early-career Zimbabwean scientists in South Africa contacted by  Nature . Zimbabwe does not keep official figures on academics, but a 2012 report by the United Nations Educational, Scientific and Cultural Organization said that 1,300 researchers were working there at the time. And despite chronic underfunding, Zimbabwe has consistently produced around 400 peer-reviewed papers a year. (By comparison, South Africa produced 17,246 research publications in 2015.) \u201cI just hope the new regime will resuscitate the economy and generate significant research funding for higher-education institutions,\u201d says Rudo Gaidzanwa, a sociologist at the University of Zimbabwe. \u201cThat would boost the research output of academics in state universities.\u201d \n             Key collaborator \n           South Africa, with its comparatively strong research system , is a major destination for students from around Africa, and a key collaborator for Zimbabwean scientists. A Web of Science search shows that since 2013, roughly one-third of 1,689 research articles authored by Zimbabwe-affiliated researchers had a collaborator who was based in South Africa. A strengthened science system in Zimbabwe would benefit the entire region, open the door to greater collaboration and offer a destination for students trained in South Africa, says Valerie Mizrahi, director of the Institute of Infectious Disease and Molecular Medicine at the University of Cape Town in South Africa. South Africa takes scholars from across the continent, and in many cases the idea of them going home is a pipe dream, because there is often not much to go back to, Mizrahi says. \u201cZimbabwe has a chance to change that.\u201d Mizrahi, who was born in Zimbabwe but has lived in South Africa for decades, says that the situation is reminiscent of South Africa when apartheid was being dismantled in the 1990s and sanctions were lifted. \u201cFunding flowed into the country,\u201d she says. Despite the celebrations in Zimbabwe, there are concerns that Mnangagwa\u2019s presidency will not bring enough change. The new leader was a close associate of Mugabe and served in various positions in his government, which was characterized by nepotism and the silencing of opposition voices. \u201cSo we are not sure whether they will do things differently or all they wanted was just power to also suppress citizens and loot resources in the country,\" says Farayi Moyana, a PhD candidate at South Africa's University of the Witwatersrand who is based in Zimbabwe.  The uncertainty means that academics aren't making plans just yet: \u201cThere is no hurry to return home,\u201d says a Zimbabwean scientist at Witwatersrand in Johannesburg, who also spoke on the condition of anonymity. Rather, he says, he will let the situation stabilize before making any decisions. \n                   Zimbabwean scientists fight to preserve national academy 2016-Sep-27 \n                 \n                   South Africa\u2019s political turmoil endangers research 2016-Jul-13 \n                 \n                   South Africa ushers in a new era for HIV 2016-Jul-13 \n                 \n                   Africa science plan attacked 2014-Jun-25 \n                 \n                   South Africa's research spending slows down 2013-May-17 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22939", "url": "https://www.nature.com/articles/nature.2017.22939", "year": 2017, "authors": [{"name": "Jo Marchant"}], "parsed_as_year": "2006_or_before", "body": "Researchers have used muon detectors to discover a mysterious, 30-metre-long space \u2014 which could help to reveal how the 4,500-year-old monument was built. Physicists have used the by-products of cosmic rays to reveal a large, previously unidentified chamber inside the 4,500-year-old Great Pyramid in Giza, Egypt. The find is the first discovery since the nineteenth century of a major new space inside the pyramid. Egyptologists have been quick to dismiss any idea of finding lost treasure in the 30-metre-long void. \u201cThere\u2019s zero chance of hidden burial chambers,\u201d says Aidan Dodson, an Egyptologist at the University of Bristol, UK, who studies ancient Egyptian tombs. But experts hope that the finding will lead to significant insights into how this spectacular pyramid was built. The Great Pyramid was constructed by the pharaoh Khufu (also known as Cheops), who reigned from 2509\u20132483  bc . Constructed from limestone and granite blocks, and rising to 139 metres, it is the oldest and largest of the Giza pyramids and one of the most impressive structures to survive from the ancient world. \n             Chamber layout \n           Whereas other pyramids from this period sit above underground burial chambers, Khufu\u2019s Pyramid contains several large rooms inside the body of the structure itself. These include the King\u2019s chamber, which still holds a stone sarcophagus, the smaller Queen\u2019s chamber and a sloping passageway known as the Grand Gallery. These large chambers were discovered in the ninth century  ad  and explored extensively by Western archaeologists in the nineteenth century. But enthusiasts have wondered ever since whether there might be more hidden chambers inside the pyramid, or even whether the king\u2019s real burial chamber is yet to be found. \u201cThere are so many theories \u2014 nice ones but also crazy ones,\u201d says Mehdi Tayoubi, president of the Heritage Innovation Preservation institute in Paris. So, he co-founded an international collaboration called Scan Pyramids to find out; the project was supervised by the Egyptian Ministry of Antiquities. The group is \u201cagnostic\u201d about particular theories, he says, but is using non-invasive technologies to search for hidden chambers. To see through the Great Pyramid, the researchers used a technique developed in high-energy particle physics: they tracked  particles called muons , which are produced when  cosmic rays  strike atoms in the upper atmosphere. Around 10,000 muons rain down on each square metre of Earth\u2019s surface every minute. Sensitive muon detectors have been developed for use in particle accelerators, but they have also been used in the past decade or so to determine the inner structures of volcanoes and to study the damaged nuclear reactor at Fukushima, Japan. \n             Muon maps \n           In December 2015, physicist Kunihiro Morishima of Nagoya University, Japan, and his colleagues placed a series of detectors inside the Queen\u2019s chamber, where they would detect muons passing through the pyramid from above. The particles are partially absorbed by stone, so any large holes in the pyramid would result in more muons than expected hitting the detectors. After several months, \u201cwe had an unexpected line\u201d, says Tayoubi. To check the result, two other teams of physicists, from the Japanese High Energy Accelerator Research Organization in Tsukuba and the French Alternative Energies and Atomic Energy Commision in Paris, then used different types of muon detector placed in other locations both inside and outside the pyramid. All three teams observed a large, unexpected void in the same location above the Grand Gallery (see 'The Great Pyramid's big secret'). Their results were reported in  Nature 1  on 2 November. The space is at least 30 metres long, with a similar cross section to the Grand Gallery. \u201cIt was a big surprise,\u201d says Tayoubi. \u201cWe\u2019re really excited.\u201d The chamber could be either horizontal or inclined, the researchers say, and might be made up of two or more smaller spaces. The purpose of the space is unknown, but Tayoubi suggests that it could be \u201ca second Grand Gallery\u201d. With high, corbelled \u2014 or stepped \u2014 ceilings and mysterious stone benches, the Grand Gallery is \u201cone of the most fantastic rooms constructed in the ancient world\u201d, says Bob Brier, an Egyptologist at Long Island University in Brookville, New York, who co-wrote the 2008 book  The Secret of the Great Pyramid  (Smithsonian). \u201cIf there\u2019s another one, that\u2019s real news.\u201d \n             Theories abound \n           The newly discovered space is unlikely to contain any artefacts relating to the king\u2019s burial, says Dodson, because there\u2019s already a burial chamber with a sarcophagus in it. Instead he speculates that the space might be a \u201crelieving chamber\u201d, intended to reduce the weight of masonry pressing down on the Grand Gallery. Similar relieving chambers are seen above the King\u2019s chamber and in the pyramid of Khufu\u2019s father, Sneferu, at Meidum, another pyramid site in Egypt. But Colin Reader, an independent geologist and engineer based in Liverpool, UK, who has studied Egyptian pyramids, suggests that the new chamber is too far from the Grand Gallery to serve this purpose. He wonders whether, just as the Grand Gallery leads to the King\u2019s chamber, the void might lead to another, higher chamber. \u201cYou would want to investigate and rule that out,\u201d he says. Brier has a third theory. In 2007, he and French architect Jean-Pierre Houdin suggested that the Grand Gallery formed part of a huge counterweight\u00a0system. Weights sliding down the floor of the Grand Gallery could have raised the hefty, granite blocks that comprise the King\u2019s chamber, he says. He speculates that the new space could be part of a second counterweight system higher up. The results also seem to reject the theory, put forward by Houdin and Brier, that the builders of the Great Pyramid used an internal ramp to raise blocks up to the highest levels. \u201cThese data suggest that the ramp is not there,\u201d says Brier. \u201cI think we\u2019ve lost.\u201d Tayoubi says that he next wants to scan Khafre\u2019s (also known as Chephren\u2019s) Pyramid, Egypt\u2019s second largest pyramid. A team led by Nobel-prizewinning physicist Luis Alvarez carried out muon imaging in this pyramid in the late 1960s, using spark chambers as detectors and recording the cosmic-ray data on magnetic tape. They reported no new chambers in the areas scanned 2 . But technology has improved dramatically since then, points out Tayoubi. \u201cI think Alvarez was a real visionary guy,\u201d says Tayoubi. \u201cHe had the right idea, maybe too early. Our dream would be to give a tribute to Alvarez and redo the Khafre experiment, to see if he was right.\u201d \n                   Archaeology: The wonder of the pyramids 2017-Oct-18 \n                 \n                   Mummy DNA unravels ancient Egyptians\u2019 ancestry 2017-May-30 \n                 \n                   Astronomy: To catch a cosmic ray 2014-Oct-01 \n                 \n                   Researchers lament destruction of ancient Peruvian pyramid 2013-Jul-09 \n                 \n                   Archaeology meets politics: Spring comes to ancient Egypt 2011-Nov-23 \n                 \n                   ScanPyramids \n                 \n                   Heritage Innovation Preservation Institute \n                 \n                   Aidan Dodson \n                 \n                   Bob Brier \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22914", "url": "https://www.nature.com/articles/nature.2017.22914", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Hints emerge that past environments could have influenced psychiatric disorders. Psychiatric disorders can be debilitating and often involve a genetic component, yet, evolution hasn\u2019t weeded them out. Now, recent work is beginning to reveal the role of natural selection \u2014 offering a peek at how the genetic underpinnings of mental illness has changed over time. Many psychiatric disorders are polygenic: they can involve hundreds or thousands of genes and DNA mutations. It can be difficult to track how so many genetic regions evolved, and such studies require large genome data sets. But the advent of massive human genome databases is enabling researchers to look for possible connections between mental illnesses and the environmental and societal conditions that might have driven their emergence and development. Others are looking to Neanderthal genetic sequences to help inform the picture of these disorders, as well as cognitive abilities, in humans. Several of these teams presented their findings at the American Society of Human Genetics (ASHG) meeting in Orlando, Florida, in late October. One project found that evolution selected for DNA variants thought to protect against schizophrenia. The study, led by population geneticist Barbara Stranger of the University of Chicago in Illinois, looked at hundreds of thousands of human genomes using a statistical method that identified signals of selection over the past 2,000 years 1 . There were no signs of selection in genetic regions associated with any other mental illness. Many of schizophrenia's symptoms, such as auditory hallucinations and jumbling sentences, involve brain regions tied to speech, says Bernard Crespi, an evolutionary biologist at Simon Fraser University in Burnaby, Canada. Over the course of hominid evolution, he says, the ability to speak could have outweighed the small, but unavoidable risk that the genes involved in language could malfunction and result in schizophrenia in a small percentage of the population. \n               A quest for context \n             Another team, lead by human geneticist Renato Polimanti at Yale University in New Haven, Connecticut, is trying to tease out links between environmental factors, mental illnesses and behavioural traits. Polimanti and his colleagues looked at 2,455 DNA samples from individuals at 23 sites across Europe and quantified each person\u2019s overall genetic risk for mental disorders, such as autism, and personality traits, such as extraversion. They then calculated whether that risk was associated with certain environmental factors, such as rainfall, winter temperatures or the prevalence of infectious disease \u2014 exploring the idea that these factors might have been involved in selecting for the human traits. People who live in European regions with relatively lower winter temperatures, they found, were slightly more genetically prone to schizophrenia. Polimanti suggests that if genes that helped people tolerate cold were located close to variants that promote schizophrenia in the genome, then the latter could have been inadvertently carried along during evolution as a \u201cfellow traveller\u201d. \u201cThis was a nice first attempt to put some environmental context\u201d on the polygenic variants associated with mental illness, says Tony Capra, an evolutionary geneticist at Vanderbilt University in Nashville, Tennessee. Polimanti now plans to repeat the study in other parts of the world. \n               For and against \n             Untangling the roles of genetics and the environment will be difficult, however, because unknown environmental conditions in the past could have selected for traits that were advantageous then, but considered negative today. And other evolutionary factors could contribute to mental illness indirectly. An overactive immune system is thought to be involved in many psychiatric disorders, such as depression 2 , but a stronger immune system would have made human ancestors more resistant to diseases, says Stranger. Some researchers are exploring the evolution of mental illness through a different lens: by looking at possible differences in gene activity in tissues of Neanderthals and humans. A group lead by Capra and Vanderbilt human geneticist Laura Colbran used databases of modern human genomes to find DNA markers that suggest a gene is differently regulated in various tissues in the body. They then looked for these markers in two Neanderthal genomes. The team found that genes associated with neurological development were regulated differently in the Neanderthal brain compared with that of humans. So while the DNA sequence of a gene such as  FOXP2  \u2014 which is associated with language \u2014 is identical 3  in humans and Neanderthals, human brains might have produced more of the associated protein, accounting for increased language ability. The results could eventually lead to a better understanding of how Neanderthal brains functioned, if they were similar to human brains and whether they might have suffered from similar psychiatric disorders. Studying how mental illness evolved is still at an early stage, but the ability to use massive human genome databases is an exciting step forward, says Capra. He and his colleagues plan to take advantage of this with a survey of genetic areas that differ between Neanderthals and humans, searching for differences in how the genes are expressed. \n                     Neanderthals had outsize effect on human biology 2015-Jul-29 \n                   \n                     Human brain shaped by duplicate genes 2012-May-03 \n                   \n                     Modern speech gene found in Neanderthals 2007-Oct-18 \n                   \n                     Schizophrenia genes 'favoured by evolution' 2007-Sep-05 \n                   Reprints and Permissions"},
{"file_id": "551015a", "url": "https://www.nature.com/articles/551015a", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Critics say selection process for high-stakes funding programme is flawed. Germany\u2019s latest programme to boost research at its universities and make them more competitive inter\u00adnationally risks missing its goals, according to observers.\u00a0 The Excellence Initiative was launched in 2005 with \u20ac4.6 billion (US$5.4\u00a0billion) in funding and the aim of creating a handful of elite universities. Researchers across Germany are now preparing for the programme\u2019s next round, dubbed the Excellence Strategy, which starts in 2019.\u00a0 Earlier this year, almost 200 groups of scientists submitted proposals to form Clusters of Excellence\u00a0\u2014\u00a0large collaborations of research groups at one or more universities that form the core element of the strategy. And last month, an international committee invited 88 of the groups to submit full project proposals by late February. Up to 50 such clusters will from 2019 receive top-up funding of about \u20ac8 million per year for seven years. But observers question whether the 88\u00a0selected projects represent Germany\u2019s best science, particularly because the focus for selection has shifted away from basic science and towards applied research. Unsuccessful applicants say that the rules for submitting proposals for the initiative were not clearly defined and communicated. Several high-profile groups came away empty-handed, including biology teams in Frankfurt, Heidelberg and Munich involving dozens of scientists funded by the prestigious European Research Council.  \u201cThe Excellence Initiative has brought German science some welcome structural change,\u201d says Dieter Imboden, a Swiss environmental physicist who chaired a 2016 review of the initiative. \u201cBut its achievements must not obscure the view of its flaws.\u201d The competition to form clusters should be run independently of that for elite-university status, he says. Otherwise, second-tier universities could outperform those with a much stronger overall research portfolio and gain the sought-after title, which is currently held by 11 universities. Critics also say that the geographic spread of positively reviewed applications for future excellence clusters\u00a0\u2014 across 41\u00a0universities in 13 of Germany\u2019s 16 states\u00a0\u2014 hints at a political desire to distribute the funds more evenly across the country. But Peter Strohschneider, president of Germany\u2019s main research-funding agency, the DFG, which runs the programme, says the selection panels chose the projects strictly on the basis of scientific quality, without any regional or political considerations. Scientists will figure strongly on the Excellence Commission, which will make the final selection in September 2018 and will also include federal and state science ministers, he says. Until 2005, responsibility for funding universities in Germany lay exclusively with the states. The Excellence Initiative was created to allow central government to inject federal money into research, a move now guaranteed by a change to the German constitution. But many say the changes have not gone far enough. \u201cThe initiative has quite lost sight of its goal,\u201d says a former president of a large German university, speaking on condition of anonymity. \u201cUniversities here remain trapped in a federal political system that is unable to create a power\u00adhouse like Yale or Harvard.\u201d  \n                     What Germany\u2019s election results mean for science 2017-Sep-25 \n                   \n                     Academic excellence: Golden Germany 2017-Sep-06 \n                   \n                     The secret to Germany\u2019s scientific excellence 2017-Sep-06 \n                   \n                     Germany\u2019s science hubs win in major research revamp 2016-Feb-02 \n                   \n                     Germany claims success for elite universities drive 2015-Sep-04 \n                   \n                     Federal boost for German science 2014-Jun-04 \n                   \n                     Excellence Strategy \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22958", "url": "https://www.nature.com/articles/nature.2017.22958", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Conclusions of climate-change science analysis are at odds with US President Donald Trump\u2019s policies. From warmer temperatures to more extreme weather, melting glaciers and rising sea levels, humanity is fundamentally changing the planet by pumping greenhouse gases into the atmosphere, US government scientists said on 3 November in their latest assessment of climate science. The average global temperature has increased by 1 \u00b0C since the pre-industrial era,  the 477-page report  says \u2014 adding that the past 115 years comprise the warmest period \u201cin the history of modern civilization\u201d. The analysis warns that temperatures could increase by another 4 \u00b0C by the end of the century, with dramatic consequences for humans and natural ecosystems. The findings are at odds with the policies of US President Donald Trump, who has questioned well-established tenets of climate science and vowed to protect and promote the US fossil-fuel industry. Trump\u2019s stances led many scientists to worry that his administration  would try to block or tamper with the climate-change assessmen t, but several scientists who helped to write the document reported no problems. \u201cWe weren\u2019t interfered with, and we ended up producing something that I think is of tremendous value,\u201d says David Fahey, an atmospheric scientist with the National Oceanic and Atmospheric Administration in Boulder, Colorado, and a coordinating lead author of the analysis. The climate-science report is the first volume of the fourth National Climate Assessment, a legally mandated analysis of the causes and impacts of global warming that is due in 2018. The second volume focuses on how climate change is affecting life in the United States, from crop yields to property damage from extreme weather. That document was released in draft form, along with a report on the carbon cycle. The US National Academy of Sciences is set to review the latter two documents. \u201cThe science speaks for itself,\u201d says Don Wuebbles, a climate scientist at the University of Illinois at Urbana-Champaign and a coordinating lead author of the climate-science report. \u201cIt\u2019s hard to counteract the basic observations and the truth of the science with any kind of political playing around.\u201d The trio of documents paints a dramatic picture of how global warming is affecting people and communities across the United States. Tidal flooding is accelerating in more than 25 cities along the coasts of the Atlantic Ocean and the Gulf of Mexico. Large forest fires have become more frequent in the western part of the country, and warmer spring temperatures combined with shrinking mountain snowpack are reducing the amount of water available to the region\u2019s cities and farms. As a result, the draft climate-impacts report warns, \u201cchronic, long-duration hydrological drought is increasingly possible before the end of the century\u201d. The climate-science report was released just days before the latest United Nations climate talks kick off in Bonn, Germany. The summit will be the first major meeting of its kind since Trump vowed to pull the United States out of the 2015 Paris climate pact. Few observers expect the US government\u2019s latest set of climate-change analyses to affect how the Trump administration approaches energy and environmental issues. In August,  the National Oceanic and Atmospheric Administration disbanded an advisory committee  that was intended to help the nation prepare for a warmer climate by translating the findings of the coming climate assessment into guidance for cities, states and industry. Nor is it clear whether senior Trump administration officials will accept the reports\u2019 core scientific conclusions. As recently as March, US Environmental Protection Agency administrator Scott Pruitt said he did not believe that carbon dioxide is a major driver of global warming. Nonetheless, many scientists and environmentalists lauded the new reports for bolstering the case for more-aggressive action against climate change. \u201cThe full assessment, when it gets published, is going to show that there are palpable impacts that are going to hit every part of the country,\u201d says Andrew Light, a senior fellow at the World Resources Institute, an environmental think-tank based in Washington DC. \u201cIt\u2019s the responsibility of leaders to take note of that and act accordingly.\u201d \n                   US government disbands climate-science advisory committee 2017-Aug-20 \n                 \n                   Fears rise for US climate report as Trump officials take reins 2017-Aug-01 \n                 \n                   Blog post: Climate change is present danger, US warns \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22959", "url": "https://www.nature.com/articles/nature.2017.22959", "year": 2017, "authors": [{"name": "Emily Waltz"}], "parsed_as_year": "2006_or_before", "body": "US Environmental Protection Agency will allow release of insects in 20 states and Washington DC. The US Environmental Protection Agency (EPA) has approved the use of a common bacterium to kill wild mosquitoes that transmit viruses such as dengue, yellow fever and Zika,  Nature \u2019s news team has learned. On 3 November, the agency told  biotechnology start-up MosquitoMate  that it could release the bacterium  Wolbachia pipientis  into the environment as a tool against the Asian tiger mosquito ( Aedes albopictus ). Lab-reared mosquitoes will deliver the bacterium to wild mosquito populations. The decision \u2014 which the EPA has not formally announced \u2014 allows the company, which is based in Lexington, Kentucky, to release the bacteria-infected mosquitoes in 20 US states and Washington DC. \u201cIt\u2019s a non-chemical way of dealing with mosquitoes, so from that perspective, you\u2019d think it would have a lot of appeal,\u201d says David O\u2019Brochta, an entomologist at the University of Maryland in Rockville.\u201cI\u2019m glad to see it pushed forward, as I think it could be potentially really important.\u201d MosquitoMate will rear the  Wolbachia -infected  A. albopictus  mosquitoes in its laboratories, and then sort males from females. Then the laboratory males, which don\u2019t bite, will be released at treatment sites. When these males mate with wild females, which do not carry the same strain of  Wolbachia , the resulting fertilized eggs don\u2019t hatch because the paternal chromosomes do not form properly. The company says that over time, as more of the  Wolbachia -infected males are released and breed with the wild partners, the pest population of  A. albopictus  mosquitoes dwindles. Other insects, including other species of mosquito, are not harmed by the practice, says Stephen Dobson, an entomologist at the University of Kentucky in Lexington and founder of MosquitoMate. \n             Production challenges \n           The EPA restricted the release of MosquitoMate\u2019s product, called ZAP males, to 20 states and Washington DC. The agency has previously said that those places \u201care similar in temperature and precipitation to areas where efficacy of the ZAP males was tested\u201d \u2014 Kentucky, New York and California. The EPA decision excludes much of the southeastern United States, which is home to dense populations of mosquitoes and a long mosquito season, because MosquitoMate did not conduct field trials there. MosquitoMate plans to begin selling its mosquitoes locally, in Lexington, and will expand from there to nearby cities such as Louisville, Kentucky, and Cincinnati, Ohio. The company will work with homeowners, golf courses, hotels and other customers to deploy its insects, according to Dobson. \u201cNow the work starts,\u201d he says. The company will have to start small. Suppressing the mosquito population of an entire city is likely to require the weekly production of millions of these mosquitoes. To reach that level, Dobson\u2019s company must find a way to efficiently separate male mosquitoes from females. The company\u2019s technicians now separate them both by hand and mechanically, Dobson says. Another group that is also developing mosquitoes infected with  Wolbachia  to control wild populations has succeeded in producing large quantities of their insects. Researchers from Sun Yat-sen University in Guangzhou, China, and Michigan State University in East Lansing say they are releasing 5 million  Wolbachia -infected  A. albopictus  each week in Guangzhou. The scientists use mechanical sorters to separate males from females, on the basis of size differences at the pupal stage, at more than 99% efficiency, says Zhiyong Xi, a medical entomologist and microbiologist at Michigan State University, who leads the project. They expose the remaining mosquitoes to X-ray radiation at a dose that sterilizes any remaining females, but is too low to affect the males. \n             Looking ahead \n           Using lab-grown mosquitoes to kill mosquito pests  has been tested extensively in Brazil in recent years . The country has allowed large-scale releases of such mosquitoes in response to an epidemic of the Zika virus that began in 2015. Zika is a mosquito-borne virus that has been linked to severe birth defects, such as abnormally small heads \u2014 a condition known as microcephaly.  Aedes aegypti  mosquitoes are thought to be the primary vector for the virus. One type of mosquito being tested in Brazil is a genetically modified variety of  A. aegypti  developed by Oxitec in Milton, UK. When the modified male mosquitoes mate with wild females, they pass a lethal gene on to any progeny. Oxitec has run into challenges when attempting to test its GM mosquitoes in the United States, however. A community in the Florida Keys voted last year against allowing Oxitec to conduct field trials there, although the rest of the county in which the community is located voted in favour of the plans. By contrast, MosquitoMate has developed and tested a variety of  Wolbachia -carrying  A. aegypti  mosquitoes in the Florida Keys and Fresno, California, without drawing much public attention. The EPA received only 14 comments during the public-comment period for the Florida trials, and most of them were positive. The company plans to submit an application to the EPA for nationwide release of that species, says Dobson.\u00a0 \n                   Bacteria could be key to freeing South Pacific of mosquitoes 2017-Aug-01 \n                 \n                   Rio fights Zika with biggest release yet of bacteria-infected mosquitoes 2016-Oct-26 \n                 \n                   US reviews plan to infect mosquitoes with bacteria to stop disease 2016-May-24 \n                 \n                   'Gene drive' mosquitoes engineered to fight malaria 2015-Nov-23 \n                 \n                   Sickly mosquitoes stymie malaria\u2019s spread 2013-May-09 \n                 \n                   Modified mosquitoes set to quash dengue fever 2012-Jan-10 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22964", "url": "https://www.nature.com/articles/nature.2017.22964", "year": 2017, "authors": [{"name": "Jo Marchant"}], "parsed_as_year": "2006_or_before", "body": "Volunteers' use of certain words predicted stress-related changes in gene expression better than their self-reported feelings. Subtleties in the language people use may reveal physiological stress. Psychologists found that tracking certain words used by volunteers in randomly collected audio clips reflected stress-related changes in their gene expression. The speech patterns predicted those physiological changes more accurately than speakers\u2019 own ratings of their stress levels. The research, which is published on 6 November in  Proceedings of the National Academy of Science s 1  suggests that changes in language may track the biological effects of stress better than how we consciously feel. It\u2019s a new approach to studying stress, says David Creswell, a psychologist at Carnegie Mellon University in Pittsburgh, Pennsylvania, and one that \u201cholds tremendous promise\u201d for understanding how psychological adversity affects physical health. Adverse life circumstances \u2014 such as poverty, trauma or social isolation \u2014 can have devastating effects on health, increasing the risk of a variety of chronic disorders ranging from heart disease to dementia. Researchers trying to pin down the biological mechanisms involved have found that people who experience these circumstances also undergo broad changes in gene expression in the cells of their immune system. Genes involved in inflammation become more active, for example, and antiviral genes are turned down. These biological changes seem to represent the body\u2019s evolutionary response to threat, says Steve Cole, a genomicist at the University of California, Los Angeles, and a co-author on the paper. But he was always troubled by a \u201cnagging observation\u201d: they don\u2019t tally well with how stressed people say they are. Cole wondered whether stress biology is triggered instead by an automatic assessment of threat in the brain, which doesn\u2019t necessarily reach conscious awareness. To find out, he and his colleagues teamed up with Matthias Mehl, a psychologist at the University of Arizona, Tucson, who studies how stress affects language. \n             Stress on speech \n           The researchers asked 143 adult volunteers in the United States to wear audio recorders, which switched on every few minutes for two days, capturing a total of 22,627 clips. Mehl transcribed any words spoken by the volunteers, and analysed the language they used. He was particularly interested in what psychologists call 'function' words, such as pronouns and adjectives. \u201cBy themselves they don\u2019t have any meaning, but they clarify what\u2019s going on,\u201d says Mehl. Whereas we consciously choose 'meaning' words such as nouns and verbs, researchers believe that function words \u201care produced more automatically and they betray a bit more about what\u2019s going on with the speaker\u201d. Mehl and others have found, for example, that people\u2019s use of function words changes when they face a personal crisis or following terrorist attacks. The researchers compared the language used by each volunteer with the expression in their white blood cells of 50 genes known to be influenced by adversity. They found that the volunteers\u2019 use of function words predicted gene expression significantly better than self-reports of stress, depression and anxiety. People with more stressed-out gene-expression signatures tended to talk less overall. But they used more adverbs such as 'really' or 'incredibly'. These words may act as \u201cemotional intensifiers\u201d, says Mehl, signifying a higher state of arousal. They were also less likely to use third-person plural pronouns, such as 'they' or 'their'. That makes sense too, he says, because when people are under threat, they may focus less on others and the outside world. He cautions that more research is needed to test these specific effects, and to assess whether stress influences language, or vice versa. But he suggests that the approach could ultimately help to identify people at risk of developing stress-related disease. Doctors may need to \u201clisten beyond the content\u201d of what patients tell them, he says, \u201cto the way it is expressed\u201d. Cole suggests that assessing language use could help to test whether interventions aimed at reducing stress really work. Perhaps \u201cyou could even ditch self-report stress measures\u201d, he says, and instead listen passively to how trial participants speak. \u201cLanguage reflects how people connect with their world, but who would ever have thought that gene expression would be related to language?\u201d says James Pennebaker, a psychologist at the University of Texas, Austin, who has pioneered research on language and social processes (and has previously worked with Mehl). \u201cIt\u2019s such an exciting new way of thinking,\u201d he adds. \u201cI was blown away.\u201d \n                   Poverty linked to epigenetic changes and mental illness 2016-May-24 \n                 \n                   Immunology: The pursuit of happiness 2013-Nov-27 \n                 \n                   Matthias Mehl \n                 \n                   Steve Cole \n                 \n                   David Creswell \n                 \n                   James Pennebaker \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22971", "url": "https://www.nature.com/articles/nature.2017.22971", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "American Chemical Society wins lawsuit against the site, and could seek to block access to the portal in the United States. The American Chemical Society (ACS) has won a lawsuit against the pirate research-paper website Sci-Hub, over the site\u2019s illicit use and dissemination of ACS articles. On 3 November, a US court ordered Sci-Hub's operators to pay the ACS US$4.8 million in damages for copyright infringement and trademark violation. Sci-Hub\u2019s owners did not appear in court to present their case. The judge also ordered that any party \u201cin active concert or participation\u201d with Sci-Hub should \u201ccease facilitating\u201d access to the repository. This means that the ACS could request Internet services including web providers, search engines and domain-name registrars to stop linking or to block access to Sci-Hub and the various domains it is hosted under. Which services might be approached by the ACS isn\u2019t yet clear: the meaning of the phrase \u201cin active concert or participation with\u201d is open to legal interpretation, says Michael Carroll, an information-justice and intellectual-property specialist at the American University Washington College of Law in Washington, DC. There are no clear standards as to when an Internet service is in \u201cactive concert\u201d with a pirate website, says Carroll. A user merely resolving a domain-name request to such a site, for example, does not yet qualify as active participation, he adds. Such an order by a US court is exceptional, Carroll says. \u201cIn general, our federal courts do not have the power to issue orders against people or entities that were not part of the lawsuit.\u201d But he adds that US federal rules for civil procedures such as this do sometimes allow injunctions against persons who are in \u2018active participation\u2019 with an enjoined party. The current lawsuit is an example of that, he says. The ruling is another legal blow for Sci-Hub, which provides free access to millions of paywalled research papers and is popular with researchers around the world. In June, a New York court  granted the Dutch publisher Elsevier $15 million  in damages from the site for large-scale copyright infringement. But publishers are unlikely to see any money from Sci-Hub because its chief operator lives outside the United States.  Alexandra Elbakyan , a former neuroscientist who created the portal in 2011, says the court order is an example of censorship. The ACS,  which filed its lawsuit in June in a Virginia court , said in a  statement on 6 November  that the ruling was \u201ca victory for copyright law and the entire publishing enterprise\u201d. An  analysis published in August  estimated that as of March 2017, Sci-Hub\u2019s database contained 69% of the world\u2019s roughly 81.6 million scholarly articles \u2014 and 98.8% of the ACS\u2019s journal content. The ACS says that it will now seek to enforce the court\u2019s order. Asked for comment, the society referred  Nature \u2019s news team to its statement. But Internet service providers are expected to resist what they may perceive as undue censorship. Attempts to stop people visiting Sci-Hub face another hurdle, too: the site has an alternative address that can be reached by users of the Tor network, a group of servers that encrypts Internet traffic and disguises its origins. No Internet provider can easily block access to such sites. \n                   Publishers threaten to remove millions of papers from ResearchGate 2017-Oct-10 \n                 \n                   US court grants Elsevier millions in damages from Sci-Hub 2017-Jun-22 \n                 \n                   Science publishers try new tack to combat unauthorized paper sharing 2017-May-10 \n                 \n                   Pirate research-paper sites play hide-and-seek with publishers 2015-Dec-04 \n                 \n                   American Chemical Society \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22957", "url": "https://www.nature.com/articles/nature.2017.22957", "year": 2017, "authors": [{"name": "T.V  Padma"}], "parsed_as_year": "2006_or_before", "body": "Cancelled astrology workshop prompts calls for researchers to be vigilant about stamping out unscientific beliefs. A leading Indian science-advocacy group is urging the country\u2019s researchers to speak out against pseudoscience, which it fears has gained a foothold in the past few years, partly through support from some agencies of the Indian government. The call to arms, made by the non-profit Breakthrough Science Society, comes after some members of an alumni association of the prestigious Indian Institute of Science (IISc), Bangalore, planned a workshop on astrology at the IISc for 25\u201326November. Strong backlash from scientists resulted in the event being cancelled on 28 October. The society\u2019s general secretary, Soumitro Banerjee, says that it would be \u201cdetrimental to Indian science\u201d for researchers to remain neutral on such issues. \u201cIndia\u2019s scientific community must be proactive in propagating a scientific bent of mind,\u201d says Banerjee, a physicist at the Indian Institute of Science Education and Research Kolkata. \n             Timeline of events \n           Two days before the alumni association cancelled the workshop, dozens of scientists signed letters to the IISc director, Anurag Kumar, objecting to the workshop. The IISc director and the faculty were not involved in organizing the workshop. Muthya Ravindra, a computer scientist and president of the alumni association, says that the event, organized by one of its members, was still under discussion when \u201cdue to some miscommunications\u201d, e-mails promoting the event were sent out. But Ravindra says that despite criticism from scientists and other academics, people widely believe in astrology and seek its advice in newspapers, magazines and on television. He is unsure what role scientists should play in educating society on the dangers such practices may have. \u201cIt is very confusing to me whether we as\u00a0scientists [should] criticize\u00a0or take some part in finding a solution,\u201d he says. India\u2019s ruling party, the conservative Bharatiya Janata Party (BJP) has shown support for giving astrology a place in universities. In 2001, then-science minister of the BJP-led coalition government Murli Manohar Joshi took steps to allow public universities to include astrology classes in curricula. However, the Indian government and science ministry did not have a role in the IISc alumni association\u2019s planned astrology workshop. \n             Pseudoscience debate \n           Alarm in the Indian scientific community over anti-science policies and programmes has been brewing for some time. Several scientists who spoke with  Nature  are reluctant to comment publicly about it for fear of jeopardizing their jobs. Others  took part in the March for Science  organized by the 7,000-member Breakthrough Science Society in August in around 40 Indian cities, in part to protest the government\u2019s support for ideas not yet backed by science. One area of concern, says Banerjee, is the government\u2019s push for a national research programme on the health and other benefits of a combination of five cow products, known as panchgavya. The Indian Institute of Technology (IIT), Delhi, hosted a two-day workshop last December to discuss ways to validate research on panchgavya, which was supported by India\u2019s Department of Science and Technology, Department of Biotechnology, and Council of Scientific and Industrial research (CSIR), and inaugurated by India\u2019s science minister Harsh Vardhan. According to IIT Delhi\u2019s website, Vardhan, who is a physician, \u201cemphasised that use of panchgavya in practice and in daily routines will help to address the pressing global issues like climate change, resistance development, malnourishment, global health etc\u201d. Following the workshop, India\u2019s science ministry formed a national steering committee to initiate a national programme on the topic. Supporters of this research say that cow products should be considered part of India\u2019s vast traditional knowledge base.But critics say that such unverified theories are pseudoscience, and that singling out the benefits of cow products is part of a larger political agenda by Hindus, for whom the cow is a sacred animal. They also argue that research on topics such as panchgavya should be handled in a neutral manner rather than as a way of promoting traditional knowledge. Rahul Siddharthan, a computation biologist at the Institute of Mathematical Sciences in Chennai, says that the government must accept that any research involving traditional hypotheses about health could potentially refute those hypotheses. \u201cRefutability is the essence of science,\u201d he says. \n                   Thousands across India march in support of science 2017-Aug-09 \n                 \n                   Indian scientists join protests over killings of prominent secularists 2015-Oct-30 \n                 \n                   India's 'yoga ministry' stirs doubts among scientists 2014-Nov-19 \n                 \n                   Angry researchers pour scorn on astrology classes 2001-May-17 \n                 Reprints and Permissions"},
{"file_id": "551149a", "url": "https://www.nature.com/articles/551149a", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Success for the \u2018Arctic apple\u2019 could herald a new wave of lab-grown foods. This month, bags of sliced apples will hit grocery-store shelves in the midwestern United States for the first time. Shoppers who purchase the apples can leave the slices out for snacking, because of a feat of genetic engineering that prevents their flesh from browning when exposed to air.\u00a0 The \u2018Arctic apple\u2019 is one of the first foods to be given a trait intended to please consumers rather than farmers, and it joins a small number of genetically modified organisms (GMOs) to be sold as a whole product, not an ingredient. Since Okanagan Specialty Fruits in Summer\u00adland, Canada, planted its first test apples in 2003, the array of foods modified in labs has expanded to include meatless burgers, made with soya protein produced by recombinant yeast, fish fillets grown from seafood stem cells, and  mushrooms whose genomes have been edited with CRISPR  technology. Most of these items have not yet reached the market. Now, many small biotechnology companies developing such foods are watching the Arctic apple\u2019s launch, eager for clues to how consumers will perceive the fruits of their labour.\u00a0 \u201cIf the apple sells, it will pave the way for others,\u201d says Yinong Yang, a plant pathologist at Pennsylvania State University in University Park, who used CRISPR to engineer a mushroom that resists browning. He hopes one day to license his mushroom to commercial growers. Mary Maxon, who oversees biosciences programmes at Lawrence Berkeley National Laboratory in California, agrees. \u201cThe apple is not the first GMO that people would eat, but it\u2019s the first one that consumers may value,\u201d she says. When Okanagan co-founder Neal Carter bought an orchard in 1995, he thought hard about how to win over the US snack market. He found his answer in Australia, where researchers at the Commonwealth Scientific and Industrial Research Organisation had figured out how to delete a gene encoding an enzyme that causes plant cells to brown when exposed to oxygen. Carter realized that suppressing production of the enzyme in apples might allow him to sell them in snackable slices without preservatives. Only later did he realize that if consumers were to be enticed to buy, Americans\u2019 distrust of GMOs would need to be overcome. Okanagan\u2019s subsequent surveys of people in America\u2019s top apple-growing states \u2014 New York and Washington \u2014 revealed that about 20% were wary of GMOs. But the company also found that many people changed their minds when told that the apples were engineered to silence browning genes, and then tested for safety.  Mike Selden, the co-founder of Finless Foods, a firm in San Francisco, California, that is developing fish fillets from fish stem cells, agrees that providing more information helps to win over consumers. \u201cWe\u2019re not going to repeat the mistakes of the GMO industries in the past, and just put foods on the market without public conversation,\u201d he says. \u201cIf we do, you can expect a backlash \u2014 and that\u2019s warranted.\u201d Selden sees a parallel between the Arctic apple and his fillets: both were created with attributes to please consumers. Finless Foods, which has made prototypes of bluefin-tuna fillets, hopes that people will be won over by the idea of eating fish without worrying about overfishing, animal slaughter or environmental pollution. But others say that Okanagan hasn\u2019t gone far enough in telling consumers how its apple was made. The company does not mention GMOs on the apples\u2019 bags; instead, the bags have a QR code\u00a0\u2014 which links to online information when it is scanned by a smartphone. \u201cNot everyone has a smartphone, and even if you have one, are you going to check every item with it?\u201d says Bill Freese, a science-policy analyst at the Center for Food Safety, an advocacy group in Washington DC. He wants the apples to be clearly labelled as GMOs. Consumer reaction isn\u2019t the only concern for developers of genetically engineered or other lab-made foods who want to sell their wares in the United States. One major stumbling block is the US regulatory process,  which involves a complicated tangle of federal agencies  \u2014 and, for many companies, an unclear path forward. US regulators assessed the Arctic apple for five years before approving it for sale, but spent just two years reviewing a non-browning GM potato developed by agricultural firm J. R. Simplot of Boise, Idaho. Then there is the case of the CRISPR mushroom. The US Department of Agriculture (USDA) said in 2016 that it would not evaluate the mushroom, which was created by using CRISPR to delete a gene. That seemed to clear the fungus\u2019s path to the market. But Yang says that,  after  Nature \u2019s news team reported on the USDA\u2019s decision , the US Food and Drug Administration contacted him to ask whether it could review the mushroom. \u201cI agreed to that since it would give consumers a peace of mind,\u201d he says. As far as investors are concerned, regulatory uncertainty may be less of a barrier to the success of engineered foods than customer uncertainty. James Hardiman, a partner at the venture-capital fund Data Collective in San\u00a0Francisco, California, says that companies developing such foods can always build a few extra years into their long-term plans, to account for twists in the regulatory process. \u201cThe public narrative is much more difficult to control,\u201d he says. \u201cWe know the public can be irrational.\u201d Still, Carter is optimistic about how his Arctic apple will be received. \u201cWe rarely get e-mails saying we are Satan any more,\u201d he says of his company. \u201cNow we have people asking where they can buy the apples.\u201d \n                     Gene-edited animals face US regulatory crackdown 2017-Jan-19 \n                   \n                     Gene-edited CRISPR mushroom escapes US regulation 2016-Apr-14 \n                   \n                     Gene-editing surges as US rethinks regulations 2016-Apr-12 \n                   \n                     Policy: Reboot the debate on genetic engineering 2016-Mar-09 \n                   \n                     Nonbrowning GM apple cleared for market 2015-Apr-07 \n                   \n                     Okanagan Specialty Fruits \n                   Reprints and Permissions"},
{"file_id": "551153a", "url": "https://www.nature.com/articles/551153a", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Physicists begin to embrace alternative explanations for the missing material. Physicists are growing ever more frustrated in their hunt for dark matter\u00a0\u2014\u00a0the massive but hard-to-detect substance that is thought to comprise 85% of the material Universe. Teams working with the world\u2019s most sensitive dark-matter detectors report that they have failed to find the particles, and that the ongoing drought has challenged theorists\u2019 prevailing views. The latest results from an experiment called XENON1T at the Gran Sasso National Laboratory in Italy, published on 30 October 1 , continue a dry spell stretching back 30 years in the quest to nab dark-matter particles. An attempt by a Chinese team to detect the elusive stuff, the results of which were published on the same day 2 , also came up empty-handed. Ongoing attempts by space-based telescopes, as well as at CERN, the European particle-physics laboratory near Geneva, Switzerland, have also not spotted any hints of dark-matter particles. The findings have left researchers struggling for answers. \u201cWe do not understand how the Universe works at a deeper and more profound level than most of us care to admit,\u201d says Stacy McGaugh, an astrophysicist at Case Western Reserve University in Cleveland, Ohio. Physicists have widely accepted the existence of dark matter since the 1980s as an explanation for why galaxies remain intact rather than flying apart, which would be expected given the amount of observable mass they contain and how fast they rotate. Researchers surmised that halos of invisible dark matter surround galaxies and stabilize them. Physicists grew more confident when dark-matter models  successfully predicted the fluctuations detected in an observable echo of the Big Bang , known as the cosmic microwave background. These observations became the most dramatic evidence for a proposal in the 1980s that dark matter might be formed of weakly interacting massive particles, known as WIMPs. The existence of such particles fits with how physicists think that the Universe evolved, and with the relative abundance of matter. Moreover, the properties of WIMPs would match those predicted by a branch of particle physics called supersymmetry. The latest round of results seems to rule out the simplest and most elegant super\u00adsymmetry theories, casting doubt on the idea that the still-undetected particles are the missing dark matter. If simple supersymmetry theories are no longer viable, scientists say, any WIMP particle has to interact with matter much more feebly than physicists once thought. \u201cIt\u2019s not a wholesale retreat from the WIMP paradigm, but it is definitely a change in emphasis,\u201d says Dan Hooper, a physicist at the Fermi National Accelerator Laboratory in Batavia, Illinois.\u00a0 Attitudes are shifting, and physicists are increasingly embracing other possible explanations for dark matter, says David Spergel, a theoretical astrophysicist at Princeton University in New Jersey, who was an early proponent of WIMP models. \u201cThese experiments haven\u2019t completely closed the window. However, we also need to be thinking about other types of dark matter and new experiments,\u201d he says.\u00a0 \n               Dedicated detectors \n             It has taken decades to build experiments capable of detecting the minuscule rate at which WIMPs were thought to interact with matter. Only in the past ten years have experiments, carried out at about a dozen laboratories, reached the level of sensitivity needed to detect them. The most sensitive detector in the world is Gran Sasso\u2019s XENON1T, which looks for flashes of light created when dark matter interacts with atoms in its 3.5-tonne tank of extremely pure liquid xenon. But the team reported no dark matter from its first run. Neither was there any signal in data collected over two years during the second iteration of China\u2019s PandaX experiment, based in Jinping in Sichuan province. Hunts in space have also failed to find WIMPs, and hopes are fading that a once-promising \u03b3-ray signal detected by NASA\u2019s Fermi telescope  from the centre of the Milky Way  was due to dark matter \u2014 more-conventional sources seem to explain the observation. There has been only one major report 3  of a dark-matter detection, made by the DAMA collaboration at Gran Sasso, but no group has succeeded in replicating that highly controversial result;  renewed attempts to match it are under way . Future generations of detectors based on the same principle as XENON1T are already in the works, and will be needed if physicists are to finally close the window on WIMPs. But the particles\u2019 continuing no-show is making theorists more open-minded and has allowed other theories to gain prominence, says Hooper. Perhaps dark matter consists of  exotic axion particles,  which are akin to strange, massive photons. Theorists are also looking at whether dark matter might not interact with known particles at all, but exist in a \u201chidden sector\u201d, he says. The looming rejection of the WIMP hypothesis is encouraging for the few physicists who claim that dark matter itself is a red herring. \u201cI hope people will become even more open-minded,\u201d says McGaugh, who has studied  modified versions of gravity  that negate the need for dark matter. However, Hooper stresses that the fading support for WIMPs does not weaken the case for dark matter, which he thinks will eventually be found. \u201cI\u2019m not worried about the never possibility, but it could be very, very difficult,\u201d he says. \n                     Astronomy: Dark-matter evidence weakens 2016-Aug-24 \n                   \n                     Controversial dark-matter claim faces ultimate test 2016-Apr-05 \n                   \n                     Mysterious galactic signal points LHC to dark matter 2015-May-05 \n                   \n                     Space probe backs up dark view of the Universe 2006-Mar-17 \n                   \n                     Nature  blogpost: Alternate theory poses dark matter challenge \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22983", "url": "https://www.nature.com/articles/nature.2017.22983", "year": 2017, "authors": [{"name": "Edwin Cartlidge"}], "parsed_as_year": "2006_or_before", "body": "Large Hadron Collider\u2019s failure to detect new particles beyond the Higgs has eroded the case for Japan\u2019s proposed linear accelerator. Limited funding and a dearth of newly discovered particles are forcing physicists to cut back plans for their  next major accelerator project : a multibillion-dollar facility known as the International Linear Collider (ILC) in Japan. On 7 November, the International Committee for Future Accelerators (ICFA), which oversees work on the ILC, endorsed halving the machine\u2019s planned energy from 500 to 250 gigaelectronvolts (GeV), and shortening its proposed 33.5-kilometre-long tunnel by as much as 13 kilometres. The scaled-down version would have to forego some of its planned research such as studies of the \u2018top\u2019 flavour of quark, which is produced only at higher energies. Instead, the collider would focus on studying the particle that endows all others with mass \u2014 the Higgs boson, which was  detected in 2012  by the Large Hadron Collider (LHC) at CERN, Europe\u2019s particle-physics lab near Geneva, Switzerland.Leading particle physicists nevertheless remain upbeat. A 250-GeV machine still has \u201ca convincing physics case\u201d, says Hugh Montgomery at the Thomas Jefferson National Accelerator Facility in Newport News, Virginia. He says that it could be upgraded to higher energies in future. High-energy physicists have been planning a future linear collider for 25 years, but the ILC is now unlikely to see the light of day until at least 2030. They viewed the linear collider as complementary to the LHC, allowing physicists to scrutinize in detail any particles discovered at CERN. \n             Linear design \n           The circular LHC smashes together protons, which allows it to reach very high energies (13 teraelectronvolts). But, as composite particles (made of quarks), protons create messy collisions with clouds of debris. By contrast, the ILC would collide electrons and positrons head on after accelerating them in thousands of superconducting cavities joined end to end. Although yielding lower energies, its collisions \u2014 between fundamental particles \u2014 would be cleaner and more precise than those in a proton\u2013proton machine. The international physics community had hoped that Japan would foot much of the estimated US$10 billion needed to realize the original design, after researchers there  put forward a proposal to host the facility  in October 2012, just after the Higgs discovery. But the Japanese government \u2014 deterred by the project\u2019s huge price tag, according to Tatsuya Nakada, a physicist at the Swiss Federal Institute of Technology (EPFL) in Lausanne, Switzerland \u2014 has not yet made any offer of funding. That fact, coupled with an absence of any other new particle discoveries at the LHC beyond the Higgs, led the Japan Association of High Energy Physicists in July  to propose capping  the ILC\u2019s energy at 250 GeV. Aiming for a higher energy, the association explained, made less sense after data collected by the LHC in 2015 and 2016 showed that any particles outside physicists\u2019 standard model are unlikely to weigh less than 1,000 GeV, and therefore would be out of reach even for a full-scale version of the ILC. However, 250 GeV is high enough to produce large numbers of Higgs bosons, which, the association said, could yield indirect signs of new physics through measurements of their interactions with other known particles.\u00a0 \n             Energy debate \n           This proposed \u2018Higgs factory\u2019 has also been endorsed by an international working group responsible for formulating the ILC\u2019s science case, in a paper uploaded to the preprint server arXiv last month 1 . The ICFA then gave the pared-down collider its thumbs up at a meeting held in Ottawa, Canada, this week.Not all physicists are enthusiastic, however. John Ellis, a theorist at King\u2019s College London and CERN, maintains that only when operating at around 1,000 GeV will a linear collider provide \u201ca more complete picture of the Higgs\u201d. He acknowledges that costs need to be reined in, but says that in limiting the ILC to 250 GeV, \u201cyou are making significant scientific compromises\u201d. A report  uploaded to arXiv last week 2  describes three possible layouts for the 250 GeV model (a technical design for the higher-energy ILC was published in 2013). Each requires halving the length of the superconducting electron\u2013positron accelerators, but two of the options retain extra tunnel space to accommodate future upgrades. Taking into account projected savings from ongoing research into accelerators, the report estimates that the collider\u2019s core construction cost could be reduced by as much as 40% \u2014 bringing it down to around $5 billion in 2012 prices. Manpower and detectors would then raise the total to about $7 billion, according to Lyn Evans, an accelerator physicist at CERN who is directing research on the ILC. Michael Peskin, a theoretical partical physicist at the SLAC National Accelerator Laboratory in Menlo Park, California, and a member of the ILC working group, has no doubt about the value of a Higgs factory. He says that theoretical studies of the Higgs boson and the weak nuclear force \u2014 one of the four known fundamental forces \u2014 done over the past year have strengthened the case for experimental probes of the Higgs\u2019 interaction strength (the Higgs is required to give the carriers of the weak force finite mass). \u201cThe 250-GeV stage is actually more interesting scientifically than we thought,\u201d he says.The ILC decision now rests with Japan. Evans describes the Japanese government\u2019s ongoing assessment of the linear-collider project as \u201cvery long and very frustrating\u201d. But other countries won\u2019t commit money until the host country makes its plans known, he says. \u201cThe rest of the world is waiting for the Japanese government to decide,\u201d he says. \n                   Quantum machine goes in search of the Higgs boson 2017-Oct-19 \n                 \n                   China, Japan, CERN: Who will host the next LHC? 2016-Aug-19 \n                 \n                   LHC sees hint of boson heavier than Higgs 2015-Dec-15 \n                 \n                   Billion-dollar particle collider gets thumbs up 2015-May-19 \n                 \n                   After the Higgs: The new particle landscape 2012-Aug-29 \n                 \n                   Physicists find new particle, but is it the Higgs? 2012-Jul-02 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22934", "url": "https://www.nature.com/articles/nature.2017.22934", "year": 2017, "authors": [{"name": "April Reese"}], "parsed_as_year": "2006_or_before", "body": "The first new species of great ape described in more than eight decades faces threats to its habitat. Almost a century after scientists first heard rumours of its existence, an isolated population of orangutans on the Indonesian island of Sumatra has been confirmed as a new species \u2014 just as its habitat faces imminent threats. The population, estimated at fewer than 800 individuals, inhabits the Batang Toru forest in western Sumatra. A researcher exploring the area in the 1930s wrote of reports of an isolated orangutan population. But it wasn\u2019t until biological anthropologist Erik Meijaard, the founder of conservation group Borneo Futures in Jakarta, discovered the paper in the mid-1990s that scientists went looking for the Batang Toru group. Local villagers showed researchers the remains of a female orangutan, and nests in the area confirmed the presence of a population. A male orangutan killed by locals in 2013 provided key evidence: intact tissue and bone. From the start, scientists noticed that these apes looked different from other orangutans. They had smaller heads, with flatter faces, and their hair was frizzier than that of their cousins living farther north on Sumatra or on the nearby island of Borneo. \n               Gene gap \n             Now, genetic tests, field observationsand a comparison of the male skeleton against 33 orangutan specimens in museums have revealed that the Batang Toru group is, in fact, a distinct species. Named  Pongo tapanuliensis , the newly identified great ape is described in  Current Biology 1 on 2 November by a team that included most of the world\u2019s orangutan experts. \u201cIt\u2019s taken 20 years to come to the realization of what this is,\u201d Meijaard says. Although the genetic analysis of  P. tapanuliensis  relies on a single skeleton, Meijaard says that\u2019s not unusual in taxonomy. Many studies, including others he\u2019s contributed to, rely on a single piece of evidence, and typically consider only morphology. The latest study shows that the group is distinct not only in morphology, but also in genetics and behaviour, he says. Russ Mittermeier, executive vice-chair of Washington, DC-based Conservation International and chair of the primate-specialist group at the International Union for Conservation of Nature (IUCN), describes the evidence as \u201cunquestionably\u201d sufficient to support the new species designation. \u201cAlthough we have had 87 new species of primates described since 2000, this is the first new great ape species since 1929.\u201d Birut\u00e9 Mary Galdikas, an orangutan specialist in Los Angeles who founded Orangutan Foundation International, says that the study confirms what she and other orangutan researchers have suspected for decades. \u201cI am not surprised that there is a new species or subspecies of orangutan described from Sumatra,\u201d she says. \n               Ancestral ties \n             Key to the determination was tracing the population\u2019s ancestry. Surprisingly, Meijaard says, genetic testing of the Batang Toru skeleton revealed that the population is more closely related to Bornean orangutans, despite living on the same island as the other Sumatran group. That\u2019s probably because of how orangutans migrated to the region, he says. All orangutans trace their origins to ancestors that lived on the Asian mainland about 8 million years ago. Those great apes migrated to what is now Sumatra, when sea levels were lower and the lands were connected. Genetic data suggest the Batang Toru species is the closest descendant of those first arrivals. The other Sumatran orangutans, which live in the island\u2019s far north, split off from the Batang Toru group about 3.4 million years ago, modelling based on genetic data suggests. The Bornean orangutans also split from the Batang Toru group, but much later \u2014 about 674,000 years ago \u2014 which explains why those two populations are more similar, Meijaard says. Even as Batang Toru's orangutans are named a new species, the animals\u2019 long-term survival is uncertain. Previous population analyses suggest there are fewer than 800 individuals, making it the most endangered of the great apes. Although much of its habitat is protected by the Indonesian government, a proposed hydroelectric dam on the Batang Toru river would flood part of the area and divide the population into two, isolating the groups on either side of the river. That\u2019s likely to further shrink the gene pool in the already inbred population, Meijaard says. The dam would also bring more people to the area, potentially increasing hunting pressure. Conservation groups are working with government officials to find an alternative site for the project, says Meijaard.\u00a0\u201cThere is no doubt that conservation efforts are needed immediately,\u201d Mittermeier says. The IUCN primate-specialist group has recently recommended that the species be included on the IUCN Red List of Threatened Species. A decision is expected in December.\u00a0\"It would be bitterly ironic if it goes extinct as a biologically viable population just as it is described as a new species,\u201d says Galdikas. \n                     Indonesia blazes threaten endangered orangutans 2015-Nov-03 \n                   \n                     Orang-utans join the genome gang 2011-Jan-26 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22944", "url": "https://www.nature.com/articles/nature.2017.22944", "year": 2017, "authors": [{"name": "Chris Woolston"}], "parsed_as_year": "2006_or_before", "body": "Rare move stems from a conflict over two journal articles about renewable energy. A scientific dispute about the future of alternative energy has ended up in a US court. Mark Jacobson, an environmental and civil engineer at Stanford University in California, has filed a libel lawsuit against the US National Academy of Sciences (NAS) and a researcher who published a study in the academy\u2019s journal that criticized Jacobson\u2019s work. Jacobson, who filed suit in a superior court in Washington DC in late September, is seeking damages of US$10 million. He also wants the  Proceedings of the National Academy of Sciences  ( PNAS ) to retract a 2017 article, whose lead author was mathematician Christopher Clack. The NAS and Clack have until late November to respond, according to court documents. Some experts are worried that the lawsuit could dampen scientific progress on renewable energies. But others defend the move, saying researchers should be able to take advantage of all civil avenues in defence of their work. Jacobson was the lead author of a high-profile  PNAS  paper 1  published in December 2015 making the case that the continental United States could meet nearly 100% of its energy needs using wind, water and solar sources as early as 2050. A rebuttal 2  written by Clack \u2014 then at the University of Colorado Boulder \u2014 and 20 co-authors, published in  PNAS  in June 2017, questioned Jacobson's methodology and challenged his conclusions. The authors argued, among other things, that Jacobson\u2019s paper overestimated the maximum outputs from hydroelectric facilities and the nation\u2019s capacity to store energy produced by renewable sources. In the lawsuit, Jacobson says that he alerted  PNAS  to 30 falsehoods and five \u201cmaterially misleading statements\u201d in Clack\u2019s paper before its publication. The complaint states that almost all of those inaccuracies remained in the published version. Jacobson also argues that \u201cthe decision by NAS to publish the Clack Paper in PNAS has had grave ramifications\u201d for his reputation and career. In a letter 3  accompanying Clack\u2019s paper in  PNAS , Jacobson and three co-authors wrote that Clack\u2019s criticisms are \u201cdemonstrably false\u201d. They maintained that their projections regarding hydroelectric power were based on an assumed increase in the number of turbines and were not a \u201cmodeling mistake\u201d. \n               Conflict resolution \n             Some observers are disappointed to see the conflict play out in court. The diversity of engineering models that form the basis of long-term energy projections should be celebrated, not litigated, says chemical engineer Daniel Schwartz, director of the Clean Energy Institute at the University of Washington in Seattle. \u201cBringing this dispute\u00a0into the court of law, regardless of outcome, is a step towards devaluing\u00a0the\u00a0debate of underlying engineering\u00a0assumptions,\u201d he says. \u201c This dispute is likely to be most harmful to the scientific community, which has already been subject to lawsuits from groups sceptical of climate change,\u201d says David Adelman, who studies environmental law at the University of Texas in Austin. Suing a journal over a scientific disagreement is a rare move, says Adil Shamoo, a biochemist at the University of Maryland School of Medicine in Baltimore and editor-in-chief of the journal  Accountability in Research , which is published by Taylor & Francis. But Shamoo thinks that scientists should be able to sue if they feel that a paper is \u201creckless\u201d or \u201cmalicious\u201d. \u201cI\u2019m a great believer in using all of the avenues of a civil society,\u201d he says. Shamoo does think that Clack\u2019s paper was \u201cunduly harsh and personal\u201d. He says that \u201cit was not written as if it was part of a scientific dialogue\u201d. Clack declined to respond to Shamoo\u2019s characterization of his paper, but says that he is disappointed that Jacobson filed the lawsuit. Clack \u2014 now chief executive of Vibrant Clean Energy LLC in Boulder \u2014 says that his rebuttal paper \u201cunderwent very vigorous peer review\u201d, and that the  PNAS  editors had considered Jacobson\u2019s criticisms but found them to be \u201cwithout merit\u201d. Jacobson says that he \u201ccannot comment\u201d on the lawsuit. And a spokesperson for the NAS says that \u201cwe do not comment on pending litigation\u201d. \n                     US court grants Elsevier millions in damages from Sci-Hub 2017-Jun-22 \n                   \n                     Danish neuroscientist challenges fraud findings 2012-Aug-08 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22932", "url": "https://www.nature.com/articles/nature.2017.22932", "year": 2017, "authors": [{"name": "Chris Woolston"}], "parsed_as_year": "2006_or_before", "body": "Analysis of universities' salary data suggests major disparities in pay for early-career researchers. Some postdoctoral researchers at public universities in the United States apparently work for fast-food wages whereas others make more than US$100,000 a year,  an analysis of postdoc pay  has revealed. The salary data, which a science-advocacy group released on 1 November after a year-long investigation, are incomplete and \u2014 in some cases \u2014 appear to be incorrect. Some researchers are listed as earning nothing, and another study underway suggests a higher overall rate of pay for US postdocs. But the latest analysis underscores the challenges of getting basic information about  an under-recognized and misunderstood segment of the academic workforce . Gary McDowell, a former developmental biologist and executive director of Future of Research, an advocacy group in Boston, Massachusetts, used the US Freedom of Information Act to gather salary reports for nearly 13,000 postdocs at 51 public universities. Through personal connections, he also received salary information from one private institution, Boston University in Massachusetts. Most universities made a good-faith effort to provide salary information, McDowell says, but few had the numbers at hand when he contacted them. McDowell says that he had to spend considerable time on the phone explaining to university employees what 'postdoc' means. \u201cI asked a basic question \u2014 'How much do your postdocs get paid?' \u2014 but there was a lot of confusion,\u201d he says. \u201cIt points to how much interest there is in postdocs at these institutions.\u201d \n               Multiply by zero? \n             Some universities still provided improbable numbers. They include the University of Utah in Salt Lake City, which reported that 50 postdocs each made $0 per year. McDowell says it is unlikely that these researchers were unpaid volunteers. Instead, he suspects that some institutions \u2014 including the University of Utah \u2014 reported only the money that postdocs received from the institution's payroll, and overlooked fellowships and other external sources of income. \u201cUniversity of Utah postdoctoral scholars are being paid for their work,\u201d a university spokesman said. While compiling data, McDowell opted to disregard the 411 reported salaries that were less than $23,660 a year. That is the threshold below which many postdocs would be eligible for overtime pay  under a federal law called the Fair Labor Standards Act . \u201cI gave them the benefit of the doubt,\u201d McDowell says of those entries. \u201cThose are likely reporting errors.\u201d The remaining 12,554 salary reports ranged from $23,660 to $114,600 a year (see 'Rags to riches'). McDowell suspects that some institutions mistakenly included pay data for staff scientists or other employees in their reports, which could explain some of the highest salaries. Even with that caveat, his survey suggests that postdoc salaries range widely. At any given institution, McDowell says, \u201cIt\u2019s not uncommon for there to be fourfold differences between the highest and the lowest paid.\u201d Overall, 61% of reported salaries were between $40,000 and $49,999, and about 31% were reported at $50,000 or more. (The $50,000 figure is the minimum postdoctoral salary recommended in 2014 by the US National Academies of Sciences, Engineering, and Medicine.) The University of Illinois at Urbana-Champaign reported the lowest median salary at $27,515. The University of Maryland at College Park reported the highest median figure \u2014 $56,000. \n               Emerging trends \n             McDowell notes that the data set is still incomplete. Some institutions reported salaries for only a small fraction of their workforce, and the University of California (UC) system denied his request outright. The university system\u2019s public-records office told  Nature  in a statement that it lacks the capacity to do \u201cthe programming required to create the custom data report that Mr McDowell requested\u201d. The University of California, Santa Barbara, had already provided numbers to McDowell when the broader UC system denied his request for data. Other attempts to gather information on postdoctoral salaries have met with less resistance. The National Postdoctoral Association (NPA) in Rockville, Maryland, solicited salary information from its more than 200 member institutions for a forthcoming report. \u201cWe\u2019ve worked with these institutions for over a decade, and when we ask for information they readily give it,\u201d says Kate Sleeth, chairwoman of the NPA\u2019s board of directors. \u201cWe didn\u2019t have to explain to anyone what a postdoc is.\u201d Of the 127 NPA member institutions that participated in the survey, 85% reported paying all postdocs at least $47,484 \u2014 the minimum salary established by the US National Institutes of Health for the 2017 fiscal year. The NPA is set to publish the full results of its poll in January 2018. In the meantime, McDowell is still combing through his data set. Throughout November, he plans to publish daily analyses on the Future of Research website,  futureofresearch.org , that will examine salaries at individual institutions and university systems. In doing so, he hopes to promote conversation about the treatment of early-career researchers. \u201cIn academia, we\u2019re not supposed to talk about money and we\u2019re not supposed to aspire to having money,\u201d McDowell says. \u201cI think scientists should value scientists.\u201d  \n                     US postdocs face steep challenges when starting families 2017-Jun-29 \n                   \n                     Battle over US overtime pay rules leaves many postdocs in limbo 2016-Dec-01 \n                   \n                     Young, talented and fed-up: scientists tell their stories 2016-Oct-26 \n                   \n                     Science\u2019s 1%: How income inequality is getting worse in research 2016-Sep-21 \n                   \n                     The future of the postdoc 2015-Apr-07 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22929", "url": "https://www.nature.com/articles/nature.2017.22929", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Humanity is fundamentally changing the planet by pumping greenhouse gases into the atmosphere, US government scientists said on 3 November in their latest assessment of climate science. The average global temperature has increased by 1 \u00b0C since the pre-industrial era, the 477-page report says \u2014 adding that the past 115 years comprise the warmest period \u201cin the history of modern civilization\u201d (see go.nature.com/2hpj3bo). The analysis warns that temperatures could increase by another 4 \u00b0C by the end of the century, with dramatic consequences for people and ecosystems. The findings are at odds with the policies of US President Donald Trump, who has questioned established climate science and vowed to protect and promote the country\u2019s fossil-fuel industry. Trump\u2019s stances led many scientists to worry that his administration would try to block or tamper with the climate-change assessment, but several scientists who helped to write the document reported that they experienced no problems. \u201cWe weren\u2019t interfered with, and we ended up producing something that I think is of tremendous value,\u201d says David Fahey, an atmospheric scientist with the National Oceanic and Atmospheric Administration in Boulder, Colorado, and a coordinating lead author. The climate-science report is the first volume of the next National Climate Assessment, a legally mandated analysis of the causes and impacts of global warming that is due in 2018. The second volume, released in draft form on 3 November, focuses on how climate change is affecting life in the United States, from crop yields to property damage caused by extreme weather. Another report, on the carbon cycle, was released in draft form on the same day. The US National Academy of Sciences is set to review the draft documents. \u201cThe science speaks for itself,\u201d says Don Wuebbles, a climate scientist at the University of Illinois at Urbana-Champaign and a coordinating lead author of the climate-science report. \u201cIt\u2019s hard to counteract the basic observations and the truth of the science with any kind of political playing around.\u201d \n                     Trump EPA begins push to overturn Obama-era climate regulation 2017-Oct-10 \n                   \n                     US government disbands climate-science advisory committee 2017-Aug-20 \n                   \n                     Fears rise for US climate report as Trump officials take reins 2017-Aug-01 \n                   \n                     Trump officials act to tilt federal science boards toward industry 2017-May-16 \n                   \n                     Trump and Republicans take aim at environmental agency 2017-Mar-10 \n                   \n                     Trump\u2019s pick for environment agency chief sued government over climate rules 2016-Dec-07 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22977", "url": "https://www.nature.com/articles/nature.2017.22977", "year": 2017, "authors": [{"name": "Linda Nordling"}], "parsed_as_year": "2006_or_before", "body": "Automated vessel-tracking system aims to spy poachers and smugglers. In October last year, a fishing boat set out from Velddrif, a small town on South Africa\u2019s west coast. It sailed northwest for about 25 nautical miles (46 kilometres), then turned sharply and headed back the way it had come. Staying clear of coastal settlements, it entered the West Coast National Park marine protected area \u2014 a strictly no-fishing zone \u2014 where it slowed down and began to sail in a zigzag pattern. \u201cIt was obvious what they were doing,\u201d says Niel Malan, a marine biologist who works in South Africa\u2019s Department of Environmental Affairs in Cape Town. \u201cThey were poaching.\u201d On any other day, the transgression would probably have passed undetected. But Malan and his colleagues were testing a new vessel-tracking system that \u2014 when fully operational \u2014 will send out alerts when ships are acting suspiciously anywhere in South African waters. A test version of the Integrated Vessel Tracking Decision Support Tool was launched on 7 November by the South African Oceans and Coastal Information Management System (OCIMS), at its annual meeting in Cape Town. The tracking system, which has taken US$1 million and 5 years to develop, combines data from satellites, vessel transponders and radar to monitor ships in real time and spot any that might be engaged in criminal activities, such as illegal fishing or smuggling. Similar remote-sensing systems have been developed over the last decade or so by countries including the United States, Australia and India. But South Africa is a particularly crucial area for maritime crime-fighting, because of its geographical location at the joining of three oceans \u2014 the Atlantic, Indian and Southern \u2014 and because of the sheer extent of its waters. The country\u2019s Exclusive Economic Zone, which extends 200 miles off the coastline and includes an additional 400-mile-diameter circle around the Prince Edward Islands, exceeds its land area by 25%. \u201cBecause of the vastness of our EEZ, we see this as a critical technology,\u201d says Waldo Kleynhans, the system\u2019s lead developer based in Pretoria. South Africa's coast is also a busy shipping lane and an area rich in natural resources. Cold, nutrient-rich waters sustain extensive commercial fishing on South Africa's west coast and to the south, while every year billions of sardines migrate down the east coast, attracting flocks of birds, as well as dolphins, sharks and whales. South Africa has a well-documented problem with coastal poaching of high-value species such as abalone and rock lobster, whereas the extent of illegal fishing in its open oceans is largely unknown. The area around the Prince Edward Islands \u2014 home to the prized Patagonian toothfish ( Dissostichus eleginoides ) \u2014 is particularly vulnerable, says Timothy Walker, a researcher focusing on maritime and water security at the Institute for Security Studies in Pretoria. South African authorities are also concerned about human trafficking and the smuggling of drugs or banned wildlife items, such as rhino horn and ivory. Yet the navy has scant physical resources to monitor illegal activities, says Mark Blaine, a captain in the South African Navy and a part-time researcher in nautical science at Stellenbosch University \u2014 four frigates, three submarines and a handful of patrol vessels and aircraft \u2014 which he describes as equivalent to \u201ca country the size of Algeria using around six police cars to patrol the entire country\u201d. \n             Satellite spotting \n           The satellite data used by the new system includes information from automated identification system (AIS) trackers, which all ships above a certain size are required to carry. South Africa currently buys this data from third-party suppliers, but plans to launch its own constellation of AIS nano-satellites in 2018 to collect the information. Meanwhile, satellites using synthetic-aperture radar, which can spot vessels in the dark or through thick cloud, will help to detect \u2018dark targets\u2019 that are not carrying trackers or that have turned them off. Malan says that the tracking system can be set to flag up different suspicious behaviours. Users such as the fisheries department or the South African navy might create a digital fence around a marine reserve or other sensitive area, for example, and ask to receive alerts when ships enter it. Or they could request to be alerted if two ships meet in the open ocean for an extended time. Ultimately, Malan says, the system\u2019s success will depend on the end-users, who will have to monitor incoming data, set up appropriate alerts and decide how to respond. Enforcement will also be a challenge. Malan says that details of the suspicious boat he spotted in October 2016 were relayed to the fisheries department. \u201cBut we're not sure if they finished the investigation,\u201d he says. He hopes that once a few miscreants have been caught using the tracking system, however, its existence will act as a deterrent: \u201cI think once we start prosecuting a few people, then the word will spread quickly \u2014 and we hope that will lead to better behaviour.\u201d \n                   Brazilian Amazon still plagued by illegal use of natural resources 2017-Oct-17 \n                 \n                   Home-grown scientists step up to save Africa\u2019s primates 2017-Aug-08 \n                 \n                   Satellite alerts track deforestation in real time 2016-Feb-23 \n                 \n                   OCIMS \n                 \n                   Niel Malan \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22925", "url": "https://www.nature.com/articles/nature.2017.22925", "year": 2017, "authors": [{"name": "Ken Croswell"}], "parsed_as_year": "2006_or_before", "body": "Wonky orbit confirms that this visitor isn\u2019t from around here. Scientists are trying to learn everything that they can from the first  interstellar  asteroid they have ever observed crossing into our Solar System. Spotted less than two weeks ago, the object is now whizzing across the constellation Pisces and, in a couple of months, will be too faint and far away for even the largest telescopes to see. \u201cIt\u2019s fascinating,\u201d says astronomer David Jewitt of the University of California, Los Angeles. \u201cWe are seeing a body from elsewhere in the Galaxy passing through our Solar System. It\u2019s the first time we\u2019ve seen such a thing.\u201d Unfortunately, the asteroid, dubbed A/2017 U1, is dashing away, never to return. \u201cIt\u2019s going really fast,\u201d says Jewitt. \u201cSo we have a limited time to get any measurements at all.\u201d Astronomers would love to know what it\u2019s made of, but it\u2019s so dim that spectra \u2014 light that observers use to determine the compositions of celestial objects \u2014 have so far revealed little information 1 . Nor can anyone say what solar system it came from, or how old it is. \n             A curious path \n           Researchers with the Pan-STARRS1 telescope atop Haleakala in Maui, Hawaii, spied the first images of the intruder, made during the new Moon, in mid-October. \u201cIt didn\u2019t move like comets or asteroids normally do,\u201d says astronomer Rob Weryk at the University of Hawaii at Manoa, who first noticed the object on the morning of 19 October. Comets  and asteroids usually move on elliptical orbits around the Sun. These orbits have an eccentricity \u2014 a measure used to describe orbital shape \u2014 of less than 1. But an object zipping through the Solar System from beyond should instead follow a hyperbolic orbit, whose eccentricity exceeds 1.The latest observations of the asteroid\u2019s changing position indicate that its orbital eccentricity is a whopping 1.20. \u201cIt is virtually certain that the object moves in a hyperbolic trajectory,\u201d says Carlos de la Fuente Marcos, an astronomer at the Complutense University of Madrid.The asteroid skirted the Sun on 9 September, when it was inside Mercury\u2019s orbit, and then passed by Earth at a distance of 24 million kilometres on 14 October. \n             On the lookout \n           Astronomers know little else about the exotic visitor. It\u2019s faint, which means that it\u2019s small: fewer than 400 metres across. And despite its excursion near the Sun, it did not develop a tail \u2014 as a comet would \u2014 and so astronomers are currently classifying it as an asteroid. Researchers have anticipated interstellar visitors for years. \u201cWe have waited a long time,\u201d says planetary scientist Alan Stern at the Southwest Research Institute in Boulder, Colorado, who studied the matter in the 1990s. That expectation is based on the knowledge that the gravitational pulls of the giant planets Jupiter, Saturn, Uranus and Neptune catapulted trillions of comets and asteroids from the young Solar System into interstellar space.\u00a0Planets in other solar systems presumably did the same, littering interstellar space with rogue objects. \u201cBy measuring how many there are sweeping through our Solar System, we can get a gauge of how many are in the entire Galaxy, and how many solar systems have contributed to that population,\u201d says Stern.\u201cIf one hadn\u2019t been discovered fairly soon, that would start to worry me a bit,\u201d says astronomer David Hughes, emeritus professor at the University of Sheffield, UK. The asteroid came from the direction of the constellation Lyra, which is roughly where our Solar System is heading. Given this trajectory, researchers are expecting to see more objects coming from this direction than from elsewhere, just as runners heading into the rain encounter more drops on their chests than their backs.A/2017 U1 is the first of many such objects, predicts Jewitt. \n                   NASA sets sights on asteroid exploration 2017-Jan-04 \n                 \n                   Solar System\u2019s biggest asteroid is an ancient ocean world 2016-Dec-15 \n                 \n                   Five Solar System sights NASA should visit 2015-Mar-16 \n                 \n                   Voyager 1 has reached interstellar space 2013-Sep-12 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22907", "url": "https://www.nature.com/articles/nature.2017.22907", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Scientists scramble to avert disruption to data set that has tracked polar ice since the late 1970s. One of the most important  continuous records of climate change  \u2014 nearly four decades of satellite measurements of Arctic and Antarctic  sea ice  \u2014 might soon be interrupted. Scientists all over the world rely on the sea-ice record compiled by the US National Snow and Ice Data Center (NSIDC) in Boulder, Colorado. But the US military satellites that collect the data, by measuring ice extent using microwave sensors, are approaching the end of their lives. Three are still working but ageing, and their intended successor started experiencing glitches in 2016, before conking out for good this month. The next possible replacement won't launch until at least the early 2020s (see 'Seeing ice'). That means the most complete and most scientifically significant sea-ice record is at risk of breaking. Any gap in satellite coverage is not just a short-term problem: it would compromise future research, because scientists would not be able to accurately compare observations made before the gap with those from afterward. \u201cSea ice is the canary in the coal mine, and the canary\u2019s about to fall off its perch,\u201d says David Gallaher, an expert in satellite remote sensing at the NSIDC. Centre analysts have begun testing the inclusion of sea-ice data from a Japanese satellite, but that spacecraft \u2014 designed to last five years \u2014 is now five years old. Experts looking to avert the looming gap will gather to debate other options, including the potential use of data from a Chinese satellite, in December, at a meeting of the American Geophysical Union in New Orleans, Louisiana. \n               Eyes in the sky \n             In addition to tracking Arctic change, the sea-ice record is also important for climate modellers. Knowing that sea ice formed at a particular location at a particular time gives the air and ocean temperature for that spot, allowing researchers to test simulations of the atmosphere and the ocean. The data to assess sea-ice coverage come from polar-orbiting satellites carrying passive-microwave sensors that can see through clouds. The sensors detect the brightness of the surface below and translate those measurements into how much ice and water are present. NASA began taking passive-microwave measurements of sea ice in 1972, using an instrument aboard its Nimbus-5 satellite. That sensor's failure four years later interrupted observations of phenomena such as an Oregon-sized hole that opened in the Antarctic sea ice in successive winters during the mid-1970s. By the time NASA restarted its passive-microwave measurements in 1978, the hole had vanished. Mysteriously, a large patch of open water appeared in the same region last month \u2014 the biggest spotted in four decades. Gallaher says that scientists cannot accurately compare the patch from 2017 to those seen in the 1970s, because the break in the satellite record makes it hard to calibrate Nimbus-5 observations against later ones. \u201cThat\u2019s why it's so critical that you have overlap\u201d from one sea-ice satellite to the next, he says. NSIDC analysts continued using NASA sea-ice data until 1987, when they switched to information collected by the Defense Meteorological Satellite Program (DMSP). The military uses the microwave information to detect ocean wind speeds to feed into weather models, among other uses, but the data happen to be nearly perfect for sensing sea ice, says Walt Meier, a sea-ice specialist with the NSIDC. The centre has been using DMSP data ever since. Today, the centre uses data from three DMSP satellites that are more than 8, 11 and 14 years old \u2014 and designed to last five. A newer satellite, known as F-19, was launched in 2014 but experienced sensor problems in 2016. It became inoperable this month after tumbling out of control. The final probe in the series, the unlaunched F-20, was dismantled last year after Congress stopped funding the programme. \u201cEveryone kept saying we got F-20, but then it became obvious 20 wouldn\u2019t go up,\u201d says Gallaher. \u201cThe science community was caught kind of flat-footed.\u201d \n               Tenuous times \n             The US military is developing another set of weather satellites to replace the DMSP series, but the one carrying a microwave sensor will not launch before 2022. That means that when the current three ageing satellites die, the United States will be without a reliable, long-term source of sea-ice data. \u201cEvery day it\u2019s more and more risk,\u201d says Meier. \u201cIf one of those goes it will get to be nail-biting time, and certainly if two of them go.\u201d\u2028 For now, the centre is preparing for those scenarios by incorporating data from Japan\u2019s AMSR2 microwave sensor into its sea-ice record. Another, more politically fraught option is to pull in data from the China Meteorological Administration\u2019s Fengyun satellite series. Their data are already being incorporated into European weather-prediction modelling, and they carry passive-microwave sensors that are appropriate for studying sea ice. Since 2011 Congress has banned NASA scientists from working with Chinese scientists \u2014 but not necessarily from using Chinese data. One final possibility is finding a way to launch the passive-microwave sensor that scientists at the US Naval Research Laboratory salvaged from the dismantled DMSP satellite. The sensor currently sits at the Aerospace Corporation in El Segundo, California, where researchers are trying to find a way to get it into orbit. \u201cIt\u2019s a beautiful instrument,\u201d says Donald Boucher, a principal scientist and engineer with Aerospace. \u201cIt must fly.\u201d But the military might ultimately opt to launch the sensor on something such as the International Space Station, which travels over the Earth\u2019s low and middle latitudes. That would fulfil US troops' weather-prediction needs, but would not provide the polar orbit needed to study sea ice. Other planned military or commercial satellites might be able to provide some information about sea-ice cover, but not with the level of detail and continuity that researchers desire. \u201cIt\u2019s kind of frightening that you can have a record as rich and continuous as what this is, and just not a real good way of continuing it,\u201d says Molly Hardman, a remote-sensing specialist at the NSIDC. \u201cIt\u2019s depressing.\u201d \n                     Arctic 2.0: What happens after all the ice goes? 2017-Feb-08 \n                   \n                     Incredibly thin Arctic sea ice shocks researchers 2016-Dec-14 \n                   \n                     Speedier Arctic data as warm winter shrinks sea ice 2016-Mar-01 \n                   \n                     Ice loss shifts Arctic cycles 2012-Sep-12 \n                   \n                     US National Snow and Ice Data Center \n                   \n                     Defense Meteorological Satellite Program \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22923", "url": "https://www.nature.com/articles/nature.2017.22923", "year": 2017, "authors": [], "parsed_as_year": "2006_or_before", "body": "October\u2019s sharpest science shots, selected by  Nature \u2019s photo team. \n             Small beauties \n           \n             From tragic to touching \n           \n             Syrian seeds \n           \n             Capturing sunlight \n           \n             Sponge spikes \n           \n             Spinal surgery \n           \n             A cosmic collision\u2019s aftermath \n           \n             Sun block \n           \n                   Xenon view, butterfly wings and a strange squid 2017-Oct-03 \n                 \n                   Volcanic views, stalking storks and the ephemeral eclipse 2017-Sep-01 \n                 \n                   An icy break up, Higgs history and a very messy eater 2017-Jul-31 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22913", "url": "https://www.nature.com/articles/nature.2017.22913", "year": 2017, "authors": [{"name": "April Reese"}], "parsed_as_year": "2006_or_before", "body": "Negotiations to conserve unique ecosystems fail for the sixth year running. Hobart, Australia A huge area off the coast of East Antarctica rich in cold-water corals and penguin foraging grounds will remain unprotected for at least another year. Conservation advocates had hoped that the region, covering one million square kilometres, would become the continent\u2019s newest marine protected area (MPA). But the international body that oversees Antarctic waters failed to reach agreement before the end of its annual meeting on 27 October in Hobart, Australia. At last year\u2019s meeting, after years of unsuccessful talks, the Commission for the Conservation of Antarctic Marine Living Resources (CCAMLR) agreed to create the world\u2019s largest marine park, the Ross Sea MPA. Buoyed by that success, representatives from Australia, France and the wider European Union had hoped that East Antarctica would follow this year. But for the sixth year in a row, CCAMLR was unable to agree on the details. Conservationists did have some good news, however, with a decision to extend protection for waters exposed when a massive iceberg split from the Larsen C ice shelf this year; a new proposal for a marine protected area in the waters around the Antarctic Peninsula; and the approval of a research and monitoring plan for the Ross Sea MPA. After the move to protect the Ross Sea, \u201cit is disappointing that CCAMLR could not agree to protect more of the vast and biologically diverse Southern Ocean\u201d, said Andrea Kavanagh, director of Antarctic and Southern Ocean work at the Pew Charitable Trusts in Washington DC, in a statement issued after the meeting. \u201cPeople aren\u2019t feeling great,\u201d Chris Johnson, senior manager of the Antarctic programme for global wildlife charity WWF, told  Nature  just after the meeting\u2019s conclusion close to midnight. \u201cThis was a polarizing year. But these things take a long time to get consensus.\u201d \n             Fighting over fishing \n           The proposal to protect three large blocks of ocean and sea floor along East Antarctica has been endorsed by the commission\u2019s scientific committee three times. But opposition from China and Russia has blocked the proposal each year. Both have current or historical fishing interests in the region. China began fishing in the area last year and trawlers from the Soviet Union once plied East Antarctic waters; Russia has expressed interest in returning. Under CCAMLR rules, all 25 commission members \u2014 24 countries and the European Union \u2014 must agree for a proposal to be adopted. Negotiations in recent years halved the size of the proposed reserve from 1.9 million square kilometres divided into seven areas to one million square kilometres divided into three and added a 30-year expiration date. On the other side of the ledger, the talks also yielded extra protections for underwater recesses in the ice along the coastline that harbour fish. Fishing for krill, small crustaceans that are a fundamental part of the Antarctic marine food web, would be allowed in much of the reserve. But one area would be completely off limits, in part to provide a control for researchers studying the impacts of fishing on the region. Neither China\u2019s nor Russia\u2019s delegates responded to requests for comment on the nature of their opposition to the latest proposal. But the high-level talks between parties including Russia, the United States and China that smoothed the way for the Ross Sea reserve were absent from this year\u2019s meeting, according to several attendees interviewed by  Nature . \n             Unique ecosystems \n           Although only two-thirds the size of the Ross Sea MPA, the East Antarctic reserve would protect unique ecosystems and features. Included within its boundaries are sites where Antarctic bottom water is formed; this very cold, dense, oxygen-rich slug of water drives global ocean circulation. Churning on the sea floor creates a range of important habitats on the ice shelf and slope that support marine food webs, a nursery for Antarctic silverfish ( Pleuragramma antarcticum ) and the foraging ranges of marine mammals and birds including Ad\u00e9lie penguins ( Pygoscelis adeliae ) and emperor penguins ( Aptenodytes forsteri ). Antarctic marine reserves offer a rare opportunity to conserve and study largely untouched natural areas, says Keith Reid, science manager for CCAMLR in Hobart and a former research scientist with the British Antarctic Survey. By contrast, \u201cMPAs in many parts of the world are implemented usually in response to something that\u2019s gone wrong\u201d. And although MPA status does little to ward off the effects of climate change, it can help \u201censure the other activities don\u2019t exacerbate the impacts\u201d, he says. Antarctic marine parks are part of a larger international effort to protect 10% of the world\u2019s oceans in MPAs. Gillian Slocum, who represents the Australian Antarctic Division at CCAMLR, is optimistic that the negotiating challenges can be overcome: \u201cWe\u2019re hoping CCAMLR can keep building on the momentum of creating the Ross MPA.\u201d \n                   Giant iceberg\u2019s split exposes hidden ecosystem 2017-Sep-26 \n                 \n                   World\u2019s largest marine reserve hailed as diplomatic breakthrough 2016-Oct-28 \n                 \n                   Third time unlucky for Antarctic protection bid 2013-Nov-01 \n                 \n                   Commission for the Conservation of Antarctic Marine Living Resources (CCAMLR) \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22908", "url": "https://www.nature.com/articles/nature.2017.22908", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Reconstructions of single cells highlight how far they can reach into the brain. The 70 million neurons in the  mouse brain  look like a tangled mess, but researchers are beginning to unravel the individual threads that carry messages across the organ. A 3D brain map released on 27 October, called MouseLight, allows researchers to trace the paths of single neurons and could eventually reveal how the mind assembles information. The map contains 300 neurons and researchers plan to add another 700 in the next year. \u201cA thousand is just beginning to scratch the surface,\u201d says Nelson Spruston, a neuroscientist at the Howard Hughes Medical Institute (HHMI) Janelia Research Campus in Ashburn, Virginia. To create the maps, Spruston and HHMI neuroscientist Jayaram Chandrashekar injected mouse brains with viruses that infect only a few cells at a time, prompting them to produce fluorescent proteins 1 . The team made the organs transparent using a sugar-alcohol treatment to obtain an unobstructed view of the glowing neurons, and then scanned each brain with a high-resolution microscope. Computer programs created 3D models of the glowing neurons and their projections, called axons, which can be half a metre long and branch like a tree. MouseLight has already revealed new information, including the surprisingly extensive number of brain regions that a single axon can reach. For instance, four neurons associated with taste stretch into the region that controls movement and another area related to touch. Chandrashekar says the group is now working on identifying which genes each neuron expresses, which will help to pin down their function. \u201cThis is a tremendous project,\u201d says Hongkui Zeng, a molecular biologist at the Allen Institute for Brain Science in Seattle, Washington, who plans to collaborate with the Janelia group on MouseLight. The Janelia technique is similar to one that Zeng and her colleagues developed using a  line of mice genetically engineered  so that a certain drug activates glowing proteins in a handful of their neurons. MouseLight is just one of  several methods  being used to reconstruct individual neurons, says Rafael Yuste, a neurobiologist at Columbia University in New York City. Accurately labelling neurons with markers such as fluorescence, he says, will probably be the key challenge in the eventual goal of creating a \u201ccensus\u201d of different cell types in the brain. But to achieve that goal, Zeng says, researchers may need to reconstruct hundreds of thousands of neurons. \u201cNow it\u2019s a numbers game.\u201d \n                   China launches brain-imaging factory 2017-Aug-16 \n                 \n                   A giant neuron found wrapped around entire mouse brain 2017-Feb-24 \n                 \n                   Crumb of mouse brain reconstructed in full detail 2015-Jul-30 \n                 \n                   MouseLight \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22924", "url": "https://www.nature.com/articles/nature.2017.22924", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Just six scientists conquer one of the most complicated genomes ever read. The wheat genome is finally complete. A giant international consortium of academics and companies has been trying to finish the challenging DNA sequence for more than a decade, but in the end, it was a small US-led team that scooped the prize. Researchers hope that the genome of bread wheat ( Triticum aestivum ) \u2014 described in the journal  GigaScience  this month[1] \u2014 will aid efforts to study and improve a staple crop on which around 2 billion people rely. The wheat genome is crop geneticists' Mount Everest. It is huge \u2014 more than five times the size of a single copy of the human genome \u2014 and harbours six copies of each chromosome, adding up to between 16 billion and 17 billion letters of DNA. And more than 80% of it is made of repetitive sequences. These stretches are especially vexing for scientists trying to assemble the short DNA segments generated by sequencing machines into much longer chromosome sequences. It\u2019s like putting together a jigsaw puzzle filled with pieces of blue sky, says Steven Salzberg, a genomicist at Johns Hopkins University in Baltimore, Maryland, who led the latest sequencing effort. \u201cThe wheat genome is full of blue sky. All these pieces look like a lot of other pieces, but they\u2019re not exactly alike.\u201d As a result, previous wheat-genome sequences contained gaps that made it hard for scientists to locate and examine any particular gene, says Klaus Mayer, a plant genomicist at the Helmholtz Center in Munich, Germany, and one of 1,800 members of the International Wheat Genome Sequencing Consortium (IWGSC) that have been tackling the genome since 2005. A sequence  released by the consortium in 2014  covered about two-thirds of the genome, but it was highly fragmented and lacked details about the sequences between genes 2 . Improved versions were released in 2016 and 2017, but the use of these data is restricted until the IWGSC publishes its analysis (Mayer says the team is preparing to submit its report to a journal). The sequence was also produced using proprietary software from a company called NRGene, preventing other scientists from reproducing the effort. \n             Puzzle pieces \n           Salzberg, who specializes in assembling genome sequences, and his five colleagues decided to tackle the problem themselves. To overcome the challenge of ordering repetitive DNA \u2014 the puzzle pieces of blue sky \u2014 the researchers used a sequencing technology that generates very long DNA stretches (often in excess of 10,000 DNA letters). They also created much shorter, but highly accurate sequences, using another technology. Stitching these \u2018reads\u2019 together \u2014 which amounted to 1.5 trillion DNA letters and consumed 880,000 hours of processor time on a cluster of parallel computers \u2014 resulted in nearly continuous chromosome sequences that encompassed 15.3 billion letters of the wheat genome. Mayer calls the new sequence \u201ca major leap forward\u201d. Postdocs can spend whole fellowships locating a single wheat gene of interest, he says. \u201cThose genes which took 10 man- or woman-years to clone, this will melt down to a couple of months, hopefully.\u201d The results of such research should help breeders to develop strains of wheat that are better able to tolerate climate change,  disease and other stresses . Some scientists are already using the new wheat genome \u2014 including, Salzberg says, members of the IWGSC working on one particular chromosome. But if it is to be of widespread use, all of the genes and sequences will need to be identified and labelled, a laborious process known as annotation. Salzberg says that a collaborator of his is planning to do this, \u201cunless someone does it sooner\u201d. Neil Hall, a genomicist and director of the Earlham Institute, a genomics research centre in Norwich, UK, sees Salzberg\u2019s approach as a sign of the times. If the wheat genome \u2014 considered one of the most complicated to be tackled by scientists \u2014 can be sequenced by a small team using the latest technology, almost any genome could. \u201cI think we\u2019ve moved beyond the era where genome projects have to be these monolithic international cooperations,\u201d Hall says. \u201cGenomics is more like the gig economy now.\u201d \n                   Devastating wheat fungus appears in Asia for first time 2016-Apr-27 \n                 \n                   Ancient DNA reveals how wheat came to prehistoric Britain 2015-Feb-26 \n                 \n                   Fiendish wheat genome reveals grain's history 2014-Jul-17 \n                 \n                   Wheat lag 2014-Mar-26 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22920", "url": "https://www.nature.com/articles/nature.2017.22920", "year": 2017, "authors": [{"name": "Edwin Cartlidge"}], "parsed_as_year": "2006_or_before", "body": "Multi-telescope project has ambitious goals and a big price tag. US researchers have drafted plans to study the faint afterglow of the Big Bang using a new facility. They hope it will be sensitive enough to confirm whether or not the infant Universe underwent a brief period of explosive expansion known as inflation. The Cosmic Microwave Background Stage-4 experiment (CMB-S4) would comprise three 6-metre and 14 half-metre telescopes distributed across two sites in Antarctica and Chile, according to a preliminary design due to be made public this week. Potentially up and running within a decade, the facility would be nearly 100 times as sensitive as existing ground-based CMB experiments. It won\u2019t be cheap, however. Construction will cost a little over US$400 million, according to the expert task force commissioned by the US Department of Energy (DOE) and National Science Foundation (NSF) to produce the design. That is at least twice as much as envisioned in a less-detailed review 3 years ago, and 30 times the cost of existing experiments. The price tag is \u201cnot necessarily\u201d a showstopper, says Richard Barvainis, who directs the NSF\u2019s extragalactic astronomy and cosmology programme. But CMB-S4 will have to compete for limited funding with other large proposed facilities. \n             Primordial ripples \n           The CMB provides an image of the Universe as it was just 380,000 years after the Big Bang. Discovered in 1964, the radiation has since been observed by experiments on the ground, on balloons and in space, yielding increasingly precise insights into the Universe\u2019s geometry, contents and age \u2014 currently calculated at a little under 14 billion years. But physiciststhink that the CMB has more to offer. In particular, distinctive patterns in its polarization known as B\u00a0modes could reveal the existence of primordial gravitational waves. Gravitational waves \u2014 ripples in space-time \u2014 were first observed directly in 2015, but their detection in the very early Universe would be a major breakthrough, providing the strongest evidence yetfor inflation, according to Charles Lawrence, an astrophysicist at NASA\u2019s Jet Propulsion Laboratory in Pasadena, California, who chairs the CMB-S4 task force. Current ground-based CMB experiments typically detect microwaves using a few thousand pixels and are based either near the South Pole or in Chile\u2019s Atacama Desert, where very dry conditions make the atmosphere nearly transparent to microwave radiation. None of the experiments has so far spotted the telltale B mode. One group did make a well-publicized claim in 2014, but it transpired that the sighting was actually caused by emissions from Galactic dust. Researchers are now building several more experiments that will be ten times as sensitive. But Lawrence says that detecting the gravitational waves predicted by many of today\u2019s models of inflation would require sensitivity boosted by a further order of magnitude. Hence CMB-S4, which would comprise nearly 400,000 pixels. If it, too, came up empty-handed, the task force writes, it might be necessary \u201cto give up on inflation\u201d. \n             Fight for funding \n           CMB-S4 is too large for any single group to build, so researchers across the US started collaborating on the design in 2013. Their initial plans were approved a year later by a panel advising the DOE on particle physics. But they must wait until 2020 to see how they fare in the next round of the once-per-decade survey of astronomy and astrophysics that the NSF uses to assess funding priorities. Barvainis says that the agency will support CMB-S4 only if it gets \u201ca very high priority\u201d in the decadal survey, which is also likely to include a proposed upgrade to the National Radio Astronomy Observatory\u2019s Very Large Array in New Mexico, along with the development of one or more large optical telescopes. Even if the project does prevail, he adds, further agency reviews could delay the envisaged start of operations \u2014 due in 2026 \u2014 by at least two years. The task force suggests that instead, CMB-S4 could be started by adding DOE detectors to existing telescopes in Chile while installing a few of the smaller telescopes at the South Pole. Under that strategy, the NSF would initially fund only operations. However, officials at the DOE also foresee snags. James Siegrist, the agency\u2019s associate director for high-energy physics, says budgetary disagreements between the White House and Congress are creating \u201ca lot of uncertainty\u201d in Washington DC. A delay until 2027 or 2028 \u201ccould easily happen\u201d, he predicts. Reprints and Permissions"},
{"file_id": "nature.2017.22922", "url": "https://www.nature.com/articles/nature.2017.22922", "year": 2017, "authors": [{"name": "Cristina Gallardo"}], "parsed_as_year": "2006_or_before", "body": "Madrid will oversee the finances of the region's research centres and seven public universities. The Spanish government has taken over responsibility for higher education and research in Catalonia, following the region\u2019s unilateral declaration of independence on 27 October. It will retain control of spending on research centres and universities, which the League of European Research Universities says threatens institutional autonomy. The Catalonia region of north-east Spain has been in political turmoil ever since a highly controversial vote on independence was taken on 1 October. For the past 32 years the Catalan government has set and financed the budgets of universities, which were allocated \u20ac700 million (US$814 million) of the nearly \u20ac1-billion Catalan budget for science and universities in 2017. The region is strong in science: between 2007 and 2015, its universities won a 210 grants from the European Research Council, totalling \u20ac334 million. In the most recent round, 10 of the 22 ERC starting grants awarded to researchers in Spain were won by researchers based at Catalan institutions. The Ministry of Education, Culture and Sport in Madrid will run Catalan universities and the Ministry of Economy, Industry and Competitiveness will oversee the region\u2019s research policy with immediate effect. The changes mean that the Spanish government will be able to make decisions affecting research centres and universities in Catalonia, after it dismissed all the members of the Catalan government. Carmen Vela, Spain\u2019s secretary of state for research, development and innovation, says that the government hopes the difficulties will be resolved shortly. \u201cToday\u2019s situation is a bit different, but it has a very clear goal: restoring normality and tranquility. We are going to work to ensure that there are no negative impacts on research and innovation in Catalonia.\u201d She says that the Spanish government will manage but not devise science policy in Catalonia ahead of regional elections due in December. \n             University connections \n           Santi Vila, minister of business and knowledge in the Catalan government, stepped down a day before the independence declaration. Arcadi Navarro, secretary of state for universities and research in the Catalan government and a geneticist at Pompeu Fabra University in Barcelona, who used to report to Vila, might yet remain in his job. Vela says that she would like him to continue. \u201cArcadi is an excellent researcher and someone with whom we have always had an excellent relationship,\u201d Vela says. \u201cWe want to keep working with him.\u201d Jaume Casals, rector of Pompeu Fabra University, says that he does not expect the Spanish government to interfere directly in universities\u2019 affairs. \u201cThe relationship between Madrid and Barcelona when it comes to science and universities has always been fluid, and I hope that will not change,\u201d says Casals, who also leads the Alliance 4 Universities, a group of research-intensive universities consisting of two based in Madrid and another two in Catalonia. Enric Banda, senior adviser at the Barcelona Supercomputing Centre and former president of the grass-roots association EuroScience, agrees. \u201cThis is the first time these type of measures, stipulated in the Spanish constitution, are applied. The uncertainty is high because nobody knows exactly how they will be implemented. But I don\u2019t expect any additional disruption in the daily activities of the Catalan universities,\u201d he says. \n             Financial ties \n           The League of European Research Universities, headquartered in Leuven, Belgium, has criticized the financial arrangements on the grounds that they undermine institutional autonomy. In a statement issued on 23 October, the group\u2019s secretary-general, Kurt Deketelaere, wrote: \u201cJust like academic freedom, institutional autonomy is key for the academic world and society at large. It cannot be limited on the basis of political considerations, or to serve political goals.\u201d Ahead of the Catalan elections in December, both Casals and Banda are calling on the Spanish government to lift the financial controls and to minimise the impact of the political upheaval on the region's international image. \u201cCatalonia has done very well at attracting international researchers and students and we would like that to continue,\u201d says Casals. Reprints and Permissions"},
{"file_id": "nature.2017.23003", "url": "https://www.nature.com/articles/nature.2017.23003", "year": 2017, "authors": [{"name": "Nicky Phillips"}], "parsed_as_year": "2006_or_before", "body": "Tool to scrutinize research papers identifies mistakes in gene sequences. Two scientists have rolled out a program that spots incorrect gene sequences reported in experiments \u2014 and have used it to identify flaws in more than 60 papers, almost all of them studies of cancer. Jennifer Byrne, a cancer researcher at the Kids Research Institute of the Children\u2019s Hospital at Westmead in Sydney, Australia, and Cyril Labb\u00e9, a computer scientist at the University of Grenoble Alpes in Grenoble, France, made public an early version of the program, called  Seek & Blastn , in October and now they want other researchers to test the program and help to improve it. They then plan to offer it to journal editors and publishers as an addition to the tools that most already use to check papers, such as software to detect plagiarism. Byrne has been working on identifying errors in human cancer papers since 2015, when she noticed problems with five papers on gene function in cancer cells. The authors of the papers described performing a common experiment in which they inactivated a gene using a short targeted nucleotide sequence, to observe its effects on tumour cells. Byrne was familiar with the gene because she was part of the team that reported it in 1998. And she realized that the papers reported using the wrong nucleotide sequences for the experiment they claimed to conduct. Two of these papers have since been retracted. Another two are expected to be retracted on 21 November. \n               Experimental errors \n             After noticing similar errors in another 25 papers, Byrne and Labb\u00e9 developed the Seek & Blastn tool to discover more papers with incorrectly identified nucleotide fragments. The software extracts nucleotide sequences from uploaded papers and cross-checks them against a public database of nucleotides, called the Nucleotide Basic Local Alignment Search Tool (Blastn). \u201cSeek & Blastn tries to find mismatches between the claimed status of a sequence \u2014 what the paper says it does \u2014 and what the sequence actually is,\u201d says Byrne. A mismatch is flagged, for instance, when a sequence described as targeting a human gene doesn\u2019t find a match in the Blastn database. Sequences described as non-targeting that do have a match in the Blastn database are also detected. So far, the program detects only misidentified human sequences, says Labb\u00e9, but the pair hope to develop it to check sequences from other species, such as mice. The program also struggles to pick up misidentified sequences if the description is unclear in the original paper. This can cause the program to miss some mistakes and to flag papers that have no errors, so all papers put through the software should also be checked manually, he says. The pair say that they used Seek & Blastn to detect mismatched sequences in another 60 papers. Many of these manuscripts have other problems, such as poor-quality images, graphs and large chunks of overlapping text, all of which make some of the papers \u201cstrikingly similar\u201d to each other, says Byrne. With the help of colleagues, they are now manually checking the papers. Although some errors are minor or accidental, Byrne says the majority of the mismatches they have detected in papers may invalidate the results and conclusions. When you see these incorrectly identified sequences, she says, \u201cyou do get concerned about how the results were produced and whether the results in the paper actually reflect the experiments that were done\u201d. In a 2016 study 1  in  Scientometrics , Byrne and Labb\u00e9 reported 48 problematic papers, including the 30 papers that had incorrectly identified nucleotide fragments. These were all written by authors from China. The duo did not publicly identify the papers, apart from the five papers from 2015, but privately contacted journal editors, Byrne says. Many of the editors have not responded, she says. But three more papers have been retracted. In total, the pair have identified incorrect sequences in more than 90 papers. Automated tools such as Seek & Blastn are most valuable if they are used to promote good scientific practice and encourage scientists to avoid errors in the first place, rather than just catch people out, says statistician David Allison at Indiana University in Bloomington, who has  spotted many papers with substantial errors.  Such tools could also help to quantify error rates in particular journals and fields, he says. Matt Hodgkinson, head of research integrity for open-access publisher Hindawi in London, which retracted two of the papers from its journal  BioMed Research International , says he could see publishers using Seek & Blastn as part of the article-screening process. \u201cIt would depend on the cost and ease of use, whether it can be used and interpreted at scale,\u201d says Hodgkinson. Staff or academic editors would also need to check the output, given the risk for false positives, he says. \n                     Stat-checking software stirs up psychology 2016-Nov-25 \n                   \n                     Reproducibility: A tragedy of errors 2016-Feb-03 \n                   \n                     Smart software spots statistical errors in psychology papers 2015-Oct-28 \n                   \n                     Publishers withdraw more than 120 gibberish papers 2014-Feb-24 \n                   \n                     Seek & Blastn \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22926", "url": "https://www.nature.com/articles/nature.2017.22926", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Mothers aren\u2019t the only ones with influence over what the young mammals learn. It takes a village to teach a bat how to communicate. Baby Egyptian fruit bats learn calls from their mothers, but research now shows that they also pick up their dialect, or the pitch of their vocalizations, from the colony members around them. Learning to communicate  by repeating the noises that others make is something only a few mammal groups \u2014 including humans, bats, whales and  dolphins  \u2014 are known do. Researchers call this vocal learning. But findings published on 31 October in  PLOS Biology 1  show that bats can also pick things up from the group around them, a process that scientists dub crowd vocal learning. Bats are becoming the best organism to use in studies of how mammals learn to vocalize, because they\u2019re more easily manipulated in the lab than whales or dolphins. The latest research underscores their importance, says neuroscientist Michael Yartsev of the University of California, Berkeley, who was not involved with the work. Songbirds demonstrate vocal learning beautifully, but their brains are organized differently from human brains. Pinning down a mammalian model to explore how this function develops is important for neurologists studying vocal learning, says Yartsev. \n             The call of the colony \n           Egyptian fruit bats (Rousettus aegyptiacus) are highly social  and live in colonies with dozens to thousands of other bats. To see how the pups learn dialects, researchers led by neuroecologist Yossi Yovel of Tel Aviv University in Israel caught 15 pregnant Egyptian fruit bats and took them into the lab. To control for potential genetic effects, they ensured that the mothers weren't closely related. The team then split the mothers into three groups of five and put each group into one of three chambers, where the mothers gave birth to their young. The scientists altered recordings from wild Egyptian fruit bat colonies so that the pitches were low, high or intermediate, and then piped one pitch into each chamber. The team released the mothers back into the wild after 14 weeks, around the time the young would naturally embark on their own. After an additional 17 weeks in the enclosures, the young bats were mimicking the pitch of the recordings they had grown up with: bats in the low-frequency chamber made low-frequency calls rather than the calls their mothers made. The findings make sense, says Yovel. Baby bats grow up in the dark, surrounded by noisy neighbours, so it would be odd if they didn\u2019t pick things up from the animals around them. \u201cIt\u2019s perhaps not surprising, but it was never demonstrated before now.\u201d Yovel and his team plan to release the young bats into the wild and observe whether their dialect changes to match that of the wild bats, or whether the colony members pick up the experimental bats\u2019 dialect. It\u2019s important to find out how other animals learn language socially just like humans do, says Sonja Vernes, a neurogeneticist at the Max Planck Institute for Psycholinguistics in Nijmegen, the Netherlands. \u201cIf we can understand how bats do it, I think we can learn something about how humans do it.\u201d \n                   Bats slam into buildings because they can't 'see' them 2017-Sep-07 \n                 \n                   Bat banter is surprisingly nuanced 2016-Dec-22 \n                 \n                   Geneticists hope to unlock secrets of bats\u2019 complex sounds 2016-Nov-18 \n                 \n                   Babies learn to babble like birds learn to sing 2013-May-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.23023", "url": "https://www.nature.com/articles/nature.2017.23023", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Astronomers expand ideas of how chemistry and geology could affect chances for life on other worlds. Laramie, Wyoming Steve Desch can see the future of exoplanet research, and it\u2019s not pretty. Imagine, he says, that astronomers use NASA\u2019s upcoming James Webb Space Telescope to  scour the atmosphere of an Earth-mass world for signs of life . Then imagine that they chase hints of atmospheric oxygen for years \u2014 before realizing that those were false positives produced by geological activity instead of living things. Desch, an astrophysicist at Arizona State University in Tempe, and other planet hunters met from 13-17 November in Laramie, Wyoming, to plot better ways to scout for life beyond Earth. Many are starting to argue that the standard definition of habitability \u2014 having liquid water on a planet\u2019s surface \u2014 is not the factor that should guide exoplanet exploration. Instead, the scientists say, the field should focus on  the chances of detecting alien life , should it exist. \u201cPlanets can be habitable and not have life with any impact,\u201d Desch told researchers at the meeting. It turns out that water worlds may be some of the worst places to look for living things. One study presented at the meeting shows how a planet covered in oceans could be starved of phosphorus, a nutrient without which earthly life cannot thrive. Other work concludes that a planet swamped in even deeper water would be geologically dead, lacking any of the planetary processes that nurture life on Earth. \u201cHabitability is not only about finding the signature of an alien life form taking a deep breath,\u201d says Elizabeth Tasker, an astronomer and exoplanet researcher at the Japan Aerospace Exploration Agency's Institute for Space and Aeronautical Sciences in Sagamihara. It\u2019s also about how a planet\u2019s geology and chemistry interconnect to create a welcoming or hostile environment, she says \u2014 complicating the search for extraterrestrial life. \n               Surf and turf \n             Astronomers have catalogued thousands of exoplanets, of which more than a dozen are potentially habitable. The most recent, announced on 15 November, is Ross 128b, which is 3.4 parsecs (11 light years) away from Earth. It resembles the target that scientists have spent decades hunting: an Earth-sized planet orbiting a nearby star, probably at the right distance to allow liquid water. Most of these planets have some qualities that stop them from being true Earth twins. Ross 128b orbits a cool dwarf star rather than a Sun-like host, for instance. But Tasker says the usual metrics that scientists use to rank how habitable a world is, such as its location relative to its star or how closely it resembles Earth, are misguided 1 . To figure out how to parcel out valuable observing time, some scientists suggest targeting planets that, like Earth, are thought to have a mix of ocean and land. That's because worlds with nothing but water on their surfaces may not have key nutrients available in forms that can support life \u2014 if it is based on the same chemistry as life on Earth. \u201cWe have this stereotype that if we have oceans, we have life,\u201d says Tessa Fisher, a microbial ecologist at Arizona State. But her recent work contradicts this idea. Fisher and her colleagues studied what would happen on an \u201caqua planet\u201d with a surface that is almost or completely covered by enough water to fill Earth\u2019s oceans five times. On Earth, rainwater hitting rocks washes phosphorus and other nutrients into the oceans. But without any exposed land, there is no way for phosphorus to enrich water on an aqua planet over time, Fisher reported at the Laramie meeting. There would be no ocean organisms, such as plankton, to build up oxygen in the planet\u2019s atmosphere, she says \u2014 making this type of world a terrible place to find life. \n               Wet blanket \n             The wettest planets would run into a different sort of trouble, says Cayman Unterborn, a geologist at Arizona State who analysed the planet-wide effects of having as much as 50 Earth oceans\u2019 worth of water. The sheer weight of all that liquid would exert so much pressure on the sea floor that the planet\u2019s interior would not melt at all, Unterborn found. Planets need at least some internal melting to sustain geological activity, such as plate tectonics, and to provide the right geochemical environment for life. In this case, Unterborn says, \u201ctoo much water is too much of a good thing.\u201d Water-rich worlds are easy to make. Many planets are likely to have formed far from their parent star, Tasker says, in chilly temperatures where they could have coalesced from fragments of rock and lots of ice. If such a planet later migrated closer to its star, the ice would melt and cover the surface in vast oceans. Some of  the seven small planets orbiting the star TRAPPIST-1 , which is 12.6 parsecs (41 light years) from Earth, are thought to have substantial water on their surfaces 2 . Instead of instinctively studying such water worlds, Tasker says, astronomers need to think more deeply about how planets have evolved through time. \u201cWe need to look carefully at picking the right planet,\u201d she says. The James Webb Space Telescope is set to launch in 2019. Once in space,  the telescope will spend much of its time studying potentially Earth-like worlds . Researchers have already begun to analyse how oxygen, methane or other \u2018biosignature\u2019 gases in exoplanet atmospheres might appear to the telescope\u2019s view 3 . Towards the end of the Laramie meeting, attendees voted on whether scientists will find evidence of life on an exoplanet by 2040. They were not optimistic: 47 said no and 29 said yes. But a greater share was willing to bet that life would be found on another world in the 2050s or 2060s. That's presumably enough time to work through the debate over which worlds are the best to target. \n                     These seven alien worlds could help explain how planets form 2017-Feb-22 \n                   \n                     Earth-sized planet around nearby star is astronomy dream come true 2016-Aug-24 \n                   \n                     Planet hunters seek new ways to detect alien life 2016-Jul-27 \n                   \n                     The truth about exoplanets 2016-Feb-17 \n                   \n                     The exoplanet files 2015-Nov-18 \n                   \n                     Climate scientists join search for alien Earths 2015-Apr-17 \n                   \n                     Nexus for Exoplanet System Science \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22998", "url": "https://www.nature.com/articles/nature.2017.22998", "year": 2017, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Sensitive radio dishes of the Square Kilometre Array will affect phone reception \u2014 and could harm local economies, say farmers. A map showing how mobile-phone use might be restricted because of a giant radio telescope in South Africa has angered people who will live near the instrument \u2014 deepening a rift between the local farming community and those backing the project. The row has arisen over the South African portion of  the Square Kilometre Array (SKA) , which will eventually consist of thousands of radio dishes in Africa and up to a million antennas in Australia. The array, which begins construction in 2019 for completion in the 2030s, will have a total signal-collecting area of more than 1 square kilometre, making it the world\u2019s largest radio telescope. The telescope\u2019s first phase in South Africa involves 194 radio dishes, to be laid out like a galaxy with three arms spiralling out from a core cluster. Local residents in the Northern Cape province, where the government has acquired nearly 1,400 square kilometres of land for the initial phase, have already  expressed concerns about the telescope . Some are angry that the SKA won\u2019t boost the region\u2019s economy as much as they had expected; others fear the land acquisition will damage local agricultural activity \u2014 in particular, sheep farming. But the map of projected mobile-phone coverage around the project, uploaded to Facebook on 2 November, has brought to light another problem facing the local community. It shows the area around the SKA\u2019s radio dishes where the use of electronic devices will eventually be restricted, because their signals would interfere with the relatively weak radio signals that the dishes will try to pick up from the distant Universe. \n               Communications problem \n             Nearby residents had been aware that mobile-reception \u2018dead zones\u2019 could be a side effect of the SKA. But Eric Torr, a light-aircraft-business owner who uploaded the map, says it shows the area affected is \u201clarger than we were led to believe\u201d. The map suggests that six towns fall into the dead zone, he says, and that this could have serious implications for their farming economies. The map was produced by the South African Radio Astronomy Observatory (SARAO), which is leading the SKA project in South Africa. Lorenzo Raynard, head of communications at the SARAO, says it shows areas where mobile-phone coverage could be reduced by 20% or more (see \u2018Telescope side effect\u2019). The chart was part of a presentation calling on businesses to submit alternative communications solutions for affected areas, he says. An informal collection of farming organizations has already been working with the observatory to find alternative communications technologies, such as satellite phones, that can be used around the antennas, according to Henning Myburgh, a farmer in the area. \u201cAdequate electronic communications, especially for children, are a basic human right,\u201d he says. Myburgh says that the cooperative\u2019s search has now moved to finding cell-phone technologies that can co-exist with the SKA and replicate the phone facilities the farmers currently have. \u201cThis is a major shift and if possible will be a huge step forward,\u201d he says. Still, says Myburgh, there are farmers who are unhappy. \u201cI don't think that anybody will ever be happy with the situation, taking into account the massively intrusive nature of the project in the region,\u201d he says. Nicol Jacobs, who farms in the spiral arms, says the SKA was originally going to affect only two farms. He says he found out about the full extent of the telescope when the government began buying more farms. \u201cWe\u2019re going to be eaten piece by piece,\u201d he says. Jacobs says he would like the government to return the bought farms to the agricultural community: \u201cI will fight as long as I can,\u201d he adds. Despite residents\u2019 annoyance, South African law says that the country\u2019s science and technology minister can preserve the area of the SKA\u2019s land for astronomy. The department of science and technology, which oversees astronomy in the country, is responsible for finalizing regulations about areas that will lose mobile-phone coverage, and to define radio-wave frequencies that will be protected for astronomy. Asked when they would be finalized, the department\u2019s astronomy-management authority declined to give a firm date. \n               Environmental assessment \n             Although resident\u2019s complaints may not affect the SKA\u2019s layout, an environmental assessment \u2014 due to be finalized next year \u2014 could change matters. Earlier this month, the SARAO tasked the South African Environmental Observation Network to implement an environmental assessment of the telescope site, and made 3 million rand (US$209,000) available for the work. \u201cThe relative position of the dishes determines the quality of the telescope beam,\u201d says Robert Braun, science director at SKA Organisation, which is designing the telescope. The organization has drawn up an ideal map of dish positions, says Braun. But it might have to shift them if the environmental assessment finds that local habitats or biomes are affected, says Casper Crous, an ecologist who is part of the assessment collaboration. The overarching plan is to turn South Africa\u2019s SKA site into a nature reserve and a site for long-term environmental research once the telescope is operational, says Crous. So a no-go zone for dishes, for example, \u201cwould be kokerboom [quiver tree] populations or ephemeral wetlands \u2014 areas that if impacted are unlikely to ever recover,\u201d he says. \n                     Giant radio telescope scaled back to contain costs 2017-Jul-24 \n                   \n                     Giant SKA telescope rattles South African community 2016-Jun-22 \n                   \n                     An array of problems 2015-Mar-10 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22891", "url": "https://www.nature.com/articles/nature.2017.22891", "year": 2017, "authors": [{"name": "John  Pickrell"}], "parsed_as_year": "2006_or_before", "body": "Feathered carnivore was dark on top and light underneath, with a raccoon-like face. In 1996, a small, fluffy carnivore called  Sinosauropteryx  became the first dinosaur known to have had feathers. In 2010, it entered the ranks of the first dinosaurs to have their  colour elucidated , when analysis 1  suggested that it had a fetching tail of ginger-and-white stripes. Now, UK researchers have reconstructed the colour pattern across its entire body. Their findings reveal that  Sinosauropteryx  was countershaded \u2014 dark on top and light underneath. It also sported a \u2018bandit\u2019 mask on its face, resembling that of a raccoon. \u201cIt\u2019s a very common pattern in living birds and mammals,\u201d says Jakob Vinther, a palaeobiologist at the University of Bristol, UK, who led the work. Dinosaurs evolved this pattern independently of living groups of birds and mammals, says Vinther, but the same evolutionary drivers were likely at work. The results, published in  Current Biology 2  on 26 October, were based on three fossils of the 124-million-year-old species on which impressions of feathers and traces of pigmentation had been preserved. The specimens were found in China\u2019s northeastern Liaoning Province. \n               Colour photographs \n             The team used cross-polarized light, which reduces glare, and high-resolution photography to reveal details of  Sinosauropteryx \u2019sfeathering and colouration that aren\u2019t clearly visible to the naked eye. The researchers then created 3D models of the abdomen, and photographed them under different lighting conditions. Under direct light, the shadows that formed on the models more closely matched the dinosaur\u2019s plumage patterns, when compared to shadows that formed under diffuse light, such as that found in a forested environment. In living species, countershading masks the shape of the body to make animals less conspicuous to predators, but the specific pattern depends on the environment. By looking to living animals \u2014 such as some types of antelope \u2014 whose dark\u2013light transition occurs relatively high on their flanks, the scientists determined that  Sinosauropteryx  probably lived in open habitat \u2014 perhaps a savannah rather than a forest, as has been previously suggested. This pattern better cancels out the \u2018self-shadowing\u2019 on the body that occurs in open environments with direct sunlight. Similarly to modern birds, dinosaurs in the early Cretaceous period, when  Sinosauropteryx  lived, probably had tetrachromatic vision, meaning that they could see four colours. This might have given them a significant advantage over today\u2019s mammalian predators, which tend to have poorer vision. \u201cPredators back then had excellent vision, and to camouflage yourself against such a predator, you had to have really good camouflage,\u201d says Vinther. \u201cAnd we can see some really intricate camouflage solutions in this little theropod dinosaur.\u201d Researchers were also curious about what purpose the  Sinosauropteryx 'sbandit mask and striped tail might have served. In living species, multiple functions for bandit masks have been proposed, such as reducing glare \u2014 something that may have been useful to a species such as  Sinosauropteryx , whose fossils were deposited in lakeside environments. The banded tail could have served to confuse predators, by drawing eyes away from more-vital parts of the animal.\u00a0 \n               A new era of imaging \n             Palaeontologist Xing Lida of the China University of Geosciences in Beijing, says that advanced microscope and photography techniques and 3D-imaging technologies are revolutionizing palaeontology. The latest paper \u201ccompletely unravels [ Sinosauropteryx \u2019s] colour pattern\u201d, revealing surprising variation across its body, he says. This study and others are helping scientists to develop a much more complete picture of the Jehol Biota, the ecosystems of northeastern China in the early Cretaceous, around 133\u2013120 million years ago, Xing adds. Michael Pittman, a vertebrate palaeontologist at the University of Hong Kong, says that the team\u2019s countershading hypothesis is intriguing and provides a lot of information about the ecology of the animal. \u201cBut it will be nice to see if it holds up with more specimens of  Sinosauropteryx  and across other theropods,\u201d he says. Vinther has been involved in two studies published in the past 18 months that revealed similar countershading in a small herbivore called  Psittacosaurus 3  and in the 1.3-tonne armoured ankylosaur  Borealopelta 4 . Together with the latest paper, these studies have taken research into dinosaur colouration beyond simple assessments of appearance, to asking bigger questions about the ecology of Cretaceous ecosystems. Already, Vinther\u2019s team is looking to determine the colouration of other species. The Jehol Biota had many different theropods, he says. \u201cIt makes sense to try and look at a good number of them to paint a picture of how many were living in different habitats.\u201d Dinosaurs that appear similar might in fact have been living in more-distinct habitats, which could explain the unusually high diversity of carnivorous species in the fossil record from that time and region, he says. \n                     Amber inclusions showcase prehistoric feathers 2011-Sep-15 \n                   \n                     Fossil feathers reveal dinosaurs' true colours 2010-Jan-27 \n                   \n                     Oldest feathered dinosaur found 2009-Sep-25 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22930", "url": "https://www.nature.com/articles/nature.2017.22930", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "The first controlled human trial of whether blood from young donors rejuvenates old tissue has reported. The first controlled, but controversial and small, clinical trial of giving young blood to people with dementia has reported that the procedure appears safe. It has also hinted that it may even produce modest improvements in the daily lives of people who have Alzheimer\u2019s disease. Researchers who conducted the trial and others caution that the results are based on just 18 people and therefore are only a first step in exploring this type of treatment. \u201cThis is a really very small trial and the results should not be over-interpreted,\u201d says Tony Wyss-Coray, a neuroscientist at Stanford University in California. The trial was conducted by his start-up company Alkahest, which is based in San Carlos, California, and was led by Stanford neurologist Sharon Sha. The results suggest the procedure is safe and hint that it could even boost the ability of people with dementia to undertake everyday skills, such as shopping or preparing a meal. The team announced the results on 1 November and plans to present them on 4 November at  the 10th Clinical Trials on Alzheimer\u2019s Disease conference  in Boston, Massachusetts. The team tested people aged between 54 and 86 with mild to moderate Alzheimer\u2019s disease. The team gave the 18 subjects weekly infusions for four weeks. They received either a saline placebo or plasma \u2014 blood from which the red cells have been removed \u2014 from blood donors aged 18\u201330. During the study, the team monitored the patients to assess their cognitive skills, mood and general abilities to manage their lives independently. The study detected no serious adverse reactions. It saw no significant effect on cognition, but two different batteries of tests assessing daily living skills both showed significant improvement. The human trial grew out of earlier \u2018parabiosis\u2019 experiments, in which the blood systems of two rodents are surgically joined together to see what happens when molecules circulating in one animal enter another animal. Alkahest now plans to conduct a second, larger trial using plasma from which many proteins and other molecules have been removed. Wyss-Coray, whose group did most of the mouse studies that inspired the clinical trial 1  told  Nature  that his experiments suggest that such a treatment could be more effective than using whole plasma. \n             Transfusion confusion \n           Blood-transfusion trials are controversial because the active molecules in plasma that seem to lead to  the purported effects are unknown . Irina Conboy, a neurologist at the University of California, Berkeley, and her colleagues have performed extensive parabiosis experiments stitching together young and old mice that have been genetically matched. She has found that young blood clearly rejuvenates mouse tissues such as the heart and the brain 2 . But she says that the effects are probably coordinated by a complex orchestration of factors in the blood that needs to be understood more fully before moving to the clinic. \u201cThe scientific basis for the trial is simply not there,\u201d she says. \u201cThe effects of young blood on cognition have not been replicated by an independent group, and there has never been a test with a mouse model of Alzheimer\u2019s.\u201d She says that frequently exposing older people to foreign plasma may be unsafe, because hyperactivation of their immune systems could lead to autoimmune or inflammatory disease. But, Wyss-Coray says, \u201cAlzheimer\u2019s patients don\u2019t want to wait until the exact mode of action is discovered.\u201d He says that it is the first new approach for Alzheimer\u2019s disease that is not based on the prevailing theory that the disease is caused by rogue amyloid-\u03b2 or tau molecules in the brain, which has so far failed to result in any treatments. Blood transfusions used for this purpose do not require approval by the US Food and Drug Administration, and some American companies are already charging hefty fees for transfusions of blood from young people. Reprints and Permissions"},
{"file_id": "nature.2017.22911", "url": "https://www.nature.com/articles/nature.2017.22911", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Pilot projects aim to pinpoint how benign tumours turn into lung, breast, prostate and pancreatic cancers. After years of studying advanced cancers, researchers are now training their DNA sequencers on  precancerous growths  to learn more about how they develop into the full-blown disease. A three-year pilot project funded this month by the US National Cancer Institute (NCI) as part of the  National Cancer Moonshot Initiative , will take this approach with lung, breast, prostate and pancreatic cancer. Investigators hope to create a 'pre-cancer genome atlas' by sequencing DNA from precancerous growths, in addition to sequencing RNA from individual tumour cells and identifying the immune cells that have infiltrated the lesions. Another project \u2014 a four-year US$5-million effort funded by the charities Stand Up To Cancer, the American Lung Association and LUNGevity announced on 26 October \u2014 will bolster the study in lung cancer by sequencing DNA from precancerous growths in the airway. Doctors sometimes monitor such lesions, taking periodic biopsies to determine if and when they become malignant. One component of this project will track the genetic changes in these biopsies over time.\u00a0 The aim is to find ways to intervene in cancer earlier, when it may be easier to rein in the disease. \u201cThere\u2019s a tremendous sense that the rate-limiting step for new approaches for either preventing cancers or detecting them early, is the fundamental lack of knowledge about the earliest molecular events,\u201d says pulmonologist Avrum Spira at Boston University in Massachusetts, a leader on both projects. \u201cWe just don\u2019t understand what\u2019s going on very early.\u201d \n               Making maps \n             The desire to map those earliest events has been growing, fuelled in part by frustration with the limited success of therapies in patients with advanced cancers. Meanwhile, technological advances in DNA sequencing have made it possible for researchers to glean useful data from tiny tissue samples \u2014 a crucial development because physicians tend to take small biopsies of precancerous growths, and there is often little tissue left after the pathologists have analysed them. However, even with advances in sequencing, sceptics have questioned whether those minuscule amounts of tissue would suffice, says Spira. The Moonshot-funded project is set to last for three years, but Spira and his colleagues have been asked to report back in 12 months so that the NCI can decide whether the approach is feasible and warrants expansion, Spira says. \u201cThis is the beginning of a much bigger initiative,\u201d he says. It\u2019s a short timeline, but the team has a head start, Spira says. Several institutions have already been collecting these small tissue samples in biobanks, so investigators can begin their analyses immediately. This will be particularly important for pancreatic cancer, a relatively rare condition that is often caught only when it has become advanced and difficult to treat, he says. But it is worth the extra effort to study pancreatic cancer, which is among the most lethal ones, says Elizabeth Jaffee, who studies the disease at Johns Hopkins University in Baltimore, Maryland. Many pancreatic tumours seem to be driven by mutations in the same genes \u2014 and that commonality may make the disease more predictable, and therefore easier to detect and target at an early stage. \u201cYou can look at it as, \u2018Let\u2019s pick the easiest ones\u2019, but will that have the biggest impact?\u201d Jaffee says. \u201cOr let\u2019s pick some of the harder ones and maybe we can, longer term, have this plan of just preventing them entirely.\u201d If successful, the projects could herald a change in how researchers approach cancer prevention, says Spira. \u201cThe field has been stagnant and people are frustrated,\u201d he says. \u201cPeople want to really transform that space, and the feeling is that the atlas is the next thing to do to change that.\u201d \n                     Hunt for cancer 'tipping point' heats up 2017-Apr-03 \n                   \n                     US Cancer Moonshot must strike a balance between research and prevention 2016-Nov-22 \n                   \n                     Change the cancer conversation 2015-Apr-01 \n                   \n                     Massive animals may hold secrets of cancer suppression 2013-Jan-21 \n                   \n                     Nature  Outlook: Cancer prevention \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22938", "url": "https://www.nature.com/articles/nature.2017.22938", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Studies find that species diversity and antibiotics influence cutting-edge treaments. Cancer immunotherapies unleash the body\u2019s immune system to fight cancer, but microbes living in a patient\u2019s gut can affect the outcome of those treatments, two research teams have found. Their studies, published on 2 November in  Science 1 , 2 , are the latest in a wave of results linking two of the hottest fields in biomedical research:  cancer immunotherapy  and the role in disease of the body\u2019s resident microbes, referred to collectively as the  microbiome . They also raise questions about the impact of antibiotics on cancer immunotherapies, particularly on a class of drugs that block either of two related proteins called PD-1 and PD-L1. One of the studies found that people treated with antibiotics for unrelated infections had a reduced response to these immunotherapies. \u201cIt raises important questions,\u201d says cancer researcher Jennifer Wargo of the University of Texas MD Anderson Cancer Center in Houston, and an author of one of the studies. \u201cShould we be limiting or tightly monitoring antibiotic use in these patients? And can we actually change the microbiome to enhance responses to therapy?\u201d The composition and diversity of the microbiome has been linked to everything from  mental-health disorders  to some  side effects of cancer chemotherapy . In 2015, researchers working on mice reported that a specific genus of bacterium in the gut enhanced anti-tumour responses to drugs that target PD-L1 3 . Wargo saw a presentation about the work at a cancer meeting several years ago. \u201cI was floored,\u201d she says, and saw an opportunity to expand the work to humans through her access to clinical samples at MD Anderson. \n             Community action \n           Wargo teamed up with epidemiologist Vancheswaran Gopalakrishnan and other researchers to collect faecal samples from more than 100 people with advanced melanoma before they began treatment with anti-PD-1 immunotherapy drugs. The scientists found that those who had the most diverse gut microbes were most likely to respond to the immunotherapy 1 . And tumour growth was reduced in mice that received faecal transplants from people who responded to immunotherapy. The type of microbe also affected responses to treatment, the researchers discovered. For example, people whose guts contained a lot of bacteria from an order called Clostridiales were more likely to respond to treatment, whereas those who had more Bacteroidales bacteria were less likely to respond. A second study 2  showed that people who received antibiotics to treat infections shortly before or after starting immunotherapy had a reduced response to PD-1-blocking therapies. The researchers \u2014 led by cancer immunologist Laurence Zitvogel and cancer biologist Guido Kroemer, both of the Gustave Roussy Cancer Campus in Villejuif, France \u2014 also found that in both humans and mice, the presence of the bacterium  Akkermansia muciniphila  was linked to improved responses to immunotherapy. Although it\u2019s too early for clinicians to change how they use antibiotics in people with cancer, the work is a step beyond previous studies that relied mainly on mouse models of cancer, says immunologist Romina Goldszmid of the National Institutes of Health in Bethesda, Maryland. \u201cThat was an important advance,\u201d she says. \u201cIt was definitely a much-needed one.\u201d Now, she says, researchers need to learn more about how those microbes exert their influence on the immune system. \u201cWhat\u2019s really missing in the field, rather than knowing who is there and who isn\u2019t there, is knowing what the bugs are doing,\u201d she says. \u201cWe need more information about that.\u201d \n                   Gut bacteria can stop cancer drugs from working 2017-Jun-06 \n                 \n                   The curious case of the caterpillar's missing microbes 2017-May-18 \n                 \n                   Use antimicrobials wisely 2016-Sep-07 \n                 \n                   Use antimicrobials wisely 2016-Sep-07 \n                 \n                   White House goes big on microbiome research 2016-May-13 \n                 \n                   Nature  special: Human microbiota \n                 Reprints and Permissions"},
{"file_id": "nature.2017.23000", "url": "https://www.nature.com/articles/nature.2017.23000", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "TB remains a big killer despite the development of a better test for detecting the disease. Seven years ago, the global community of researchers, health-care workers and activists battling tuberculosis was euphoric. A  landmark 2010 trial  showed that a new genetic test was highly effective at diagnosing TB, prompting hopes that countries could soon finally control the disease, which killed 1.45 million that year. The World Health Organization (WHO), promptly endorsed the test, called GeneXpert, and promoted its roll-out around the globe to replace a microscope-based test that missed half of all cases. But the high hopes have since crashed as rates of tuberculosis rates have not fallen dramatically, and nations are now looking to address the problems that cause so many TB cases to be missed and the difficulties in treating those who are diagnosed. In an attempt to turn the tide, health ministers and officials from 100 countries are meeting in Moscow on 16\u201317 November. And a United Nations General Assembly devoted to TB is scheduled for September 2018. Experts say that the rollout of GeneXpert offers a cautionary lesson \u2014 although, in hindsight, an obvious one \u2014 in the battle against TB. The tale is a familiar one in global health care: a solution that seems extraordinarily promising in the lab or clinical trials falters when deployed in the struggling health-care systems of developing and middle-income countries. \u201cWhat GeneXpert has taught us in TB is that inserting one new tool into a system that isn\u2019t working overall is not going to by itself be a game changer. We need more investment in health systems,\u201d says Erica Lessem, deputy executive director at the Treatment Action Group, an activist organization in New York City. \n               No game changer \n             Some 10.4 million people were infected with TB last year, according to a WHO report published on 30 October. More than half of the cases occurred in China, India, Indonesia, Pakistan and the Philippines. The infection, which causes coughing, weight loss and chest pain, often goes undiagnosed for months or years, spurring transmission. The US government and others spent more than US$100 million developing GeneXpert. Yet despite the WHO\u2019s ringing 2010 endorsement of the test, the roll-out of GeneXpert, which is manufactured by Cepheid, a company based in Sunnyvale, California (and bought by Danaher, headquartered in Washington DC, earlier this year), was initially slow. The machines cost $17,000 each and require constant electricity and air-conditioning \u2014 infrastructure that is not widely available in the TB clinics of countries with a high incidence of the disease, requiring the machines to be placed in central facilities. Until the US government together with the Bill & Melinda Gates Foundation and UNITAID, an international organization that aims to lower drug prices, began subsidizing tests in 2012, each cost $16.86 (the price fell to $9.98), compared with a few dollars for a microscope TB test. \n               Weak health systems \n             The WHO says that more than 23 million GeneXpert tests have now been purchased in the public sector in 130 countries that are eligible for the discount. But Madhukar Pai, an epidemiologist at McGill University in Montreal, Canada, says that this still represents a relatively small proportion of people suspected of having TB. Most countries use the tests on selected group of people, Pai says. India, for example, offers the test only to people co-infected with HIV. Even countries that fully embraced GeneXpert are not seeing the returns they had hoped for. After a countrywide roll-out begun in 2011, the test is available for all suspected TB cases in South Africa. But a randomized clinical trial conducted in 2015 during the roll-out found that people diagnosed using GeneXpert were just as likely to die from TB as those diagnosed at labs still using the microscope test 1 . \u201cJust intuitively one would think that finding TB cases earlier would avert TB deaths. The fact that we didn\u2019t find that was surprising,\u201d says Gavin Churchyard, a physician specializing in TB at the Aurum Institute in Johannesburg, South Africa, who led the study. Similar studies in other countries have come to much the same conclusion about GeneXpert. Churchyard suspects that doctors have been giving people with TB-like symptoms drugs, even if their microscope test was negative or missing, and that this helps to explain why his team found no benefit from implementing the GeneXpert test. Others have speculated that, by being involved in a clinical trial, patients in both arms of the trial received better care than they would otherwise have done, obfuscating any differences between the groups. Either way, Churchyard says, his team\u2019s study illustrates how broken South Africa\u2019s TB treatment system is, a problem echoed across other countries with high incidences of TB. Even with accurate tests, cases are still being missed. Results from the GeneXpert tests take just as long to deliver as microscope tests, and many people never return to the clinic to get their results and drugs; those who begin antibiotics often do not complete the regimen. \u201cWhat the study really unmasked was that it\u2019s not enough to have new technology and introduce it into a weak health system,\u201d Churchyard says. Reprints and Permissions"},
{"file_id": "nature.2017.23018", "url": "https://www.nature.com/articles/nature.2017.23018", "year": 2017, "authors": [{"name": "Linda Nordling"}], "parsed_as_year": "2006_or_before", "body": "Venture will launch next year and seeks to strengthen continent\u2019s science by helping academics share work more quickly. Africa\u2019s academy of science has announced that it will launch an open-access publishing platform early next year \u2014 the first of its kind aimed exclusively at scientists on the continent. The platform, called  AAS Open Research  and announced by the  African Academy of Sciences  (AAS) in Nairobi on 15 November, is being created with the London-based open-access publisher F1000, adopting the model of its  F1000Research  publishing platform.  AAS Open Research  will publish articles, research protocols, data sets and code, usually within days of submission and before peer review. F1000 staff will arrange post-publication peer review: the reviews and the names of their authors will be published alongside the papers. The papers will be indexed in abstract databases such as PubMed only after they pass review. The AAS says that the platform will be especially useful for young African academics, who can face difficulties publishing in overseas journals. Some studies suggest 1  that research from low-income countries is perceived differently from that done in high-income ones, for instance. The portal will cut the time and effort scientists have to put into finding homes for their work, and will make the review process more transparent, the academy says. Although there are already open-access publishers that focus on Africa, such as AOSIS Publishing, based in South Africa,  AAS Open Research  will be the first to adopt open peer review. The new platform does carry a caveat, however: it will initially take submissions only from AAS fellows and affiliates (who together number around 400), as well as researchers funded through programmes managed by the  Alliance for Accelerating Excellence in Africa . The Nairobi-based body manages grants for African research programmes that come from international funders, mostly targeting health research but also areas such as climate change. Limiting eligibility to the platform is critical to ensure that submissions are of high quality, says AAS executive director Nelson Torto. Researchers who meet the initial criteria have already been vetted and selected through a rigorous grant-review process, he says. In future, to open up the platform to more researchers, the academy wants to partner with other African research funders whose selection processes are similarly rigorous, Torto adds. \n             Following a trend \n           The African venture follows a series of open publishing portals launched with F1000 in the past 18 months, including those set up by the  Wellcome Trust  in London and the  Bill & Melinda Gates Foundation  in Seattle, Washington \u2014 both large charities that fund scientific research. Research centres including the  UCL Great Ormond Street Institute of Child Health  and the  Montreal Neurological Institute and Hospital  in Canada have also teamed up with the firm; the European Commission is considering creating its own open publishing platform for outputs from its main Horizon 2020 research programme. The AAS will not itself be covering the costs of publishing on the platform. Rather, the academy says, African researchers\u2019 grant funders will pay publishing fees directly to F1000: \u00a3120\u00ad\u2013800 (US$160\u20131,100) per article, depending on length. Some scientists have raised concerns that publishing on open-research platforms might stop African academics from getting the recognition needed for career advancement that they receive for publishing in conventional journals. In South Africa, for instance, academics are rewarded for publishing in a list of titles maintained by the country\u2019s higher-education department. \u201cFor open publishing to be successful, it will need to be accompanied by changes in the criteria for academic recognition and promotion within African institutions of higher learning,\u201d says Salim Abdool Karim, an HIV researcher and AAS fellow in Durban, South Africa. The risk of publishing on little-known platforms is a concern, agrees Gordon Awandare, a biochemist at the University of Ghana in Accra who will be eligible to publish on  AAS Open Research . However, the AAS platform will help to chip away at the grip of the big journals, says Awandare, which will be good for African science. \u201cOur approach has always been to spread our research across several platforms, so we will continue to do that.\u201d \n                   Gates Foundation announces open-access publishing venture 2017-Mar-23 \n                 \n                   Science journals permit open-access publishing for Gates Foundation scholars 2017-Feb-14 \n                 \n                   Gates Foundation research can\u2019t be published in top journals 2017-Jan-13 \n                 \n                   Wellcome Trust launches open-access publishing venture 2016-Jul-06 \n                 \n                   F1000 \n                 \n                   African Academy of Sciences \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22981", "url": "https://www.nature.com/articles/nature.2017.22981", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Machines could get themselves out of a sticky spot, thanks to an insect that can right itself without using its legs. A beetle that can launch itself spectacularly into the air after falling on its back \u2014 flipping right side up without having to use its legs \u2014 could inspire a new generation of smart robots. Imagine  a rescue robot vaulting its way through a disaster zone  riddled with obstacles, or a planetary robot extricating itself from an unexpected tumble on Mars. Each might use a trick or two learnt from the click beetles, a family of insects with the unique ability to catapult themselves out of trouble. \u201cA lot of robots out there jump using their legs,\u201d says Aimy Wissa, a mechanical engineer at the University of Illinois in Urbana-Champaign. \u201cWhat\u2019s unique about this is if something breaks, you can still jump without legs and get out of the situation.\u201d Wissa and her Illinois colleagues, led by mechanical-engineering graduate student Ophelia Bolmin, described the mechanics of jumping click beetles on 7 November at a meeting of the Entomological Society of America in Denver, Colorado. They published early results in the proceedings of a bio-inspired robotics conference in July 1 . So far, the scientists have studied how click beetles manage to store and hold the energy needed to launch themselves into the air. They hope to soon start building prototype machines designed after the beetles. \n             Snap to it \n           There are about 10,000 species of click beetles around the world. The insect\u2019s head and body are connected by a hinge that the beetle can slowly arch and then suddenly snap in the opposite direction, jack-knifing its body and sending it into the air with an audible \u2018click\u2019. Earlier work has shown that the beetles launch nearly vertically before somersaulting through the air 2 . If the beetle lands on its back, it just does the same manoeuvre again. Compare that to an upended ladybird \u2014 also known as a ladybug \u2014 which has to wiggle around on its back until it manages to roll over far enough and get traction with its legs to flip itself over. The Illinois team wanted to analyse how the click beetles pull off their acrobatic feat. \u201cWe thought we could look at, how do they really jump, how is that energy being released?\u201d says Marianne Alleyne, an entomologist on the team. Students measured the dimensions of dozens of beetles of four species ( Alaus oculatus ,  Ampedus nigricollis ,  Ampedus linteus  and  Melanotus  spp.), videotaped their jumps with high-speed cameras and analysed the energy required for the beetles to pull the hinge back and then release it. Muscles alone are not enough, because they contract relatively slowly, and so other body parts such as tendons must also be involved, the team says. \n             How high? \n           The researchers also measured the force drop as the hinge snapped shut, confirming that it corresponded to the click as the beetle begin to soar skyward. They are now analysing the energies involved as beetles of different sizes make the jump. Click beetles can range from just a few millimetres to a few centimetres long; early results suggest that the bigger the beetle, the higher it can jump, Wissa says. Other engineers have developed a range of agile robots that can jump using their legs \u2014 including one inspired by the Senegal bushbaby ( Galago senegalensis ), which has the highest vertical jumping ability of any animal 3 . Compared with crawling,  jumping is a fast and efficient way  for small robots to get around obstacles, says Mark Cutkosky, a mechanical engineer at Stanford University in California. The advantage of the beetle approach is that something could go wrong with the robot\u2019s legs, and it could still get out of its predicament, Wissa says. \u201cIt simplifies the design a lot.\u201d Any robots inspired by the click beetle would probably have to be quite small \u2014 perhaps a few tens of grams, says Gal Ribak, a biomechanics specialist at Tel Aviv University who has studied the beetles\u2019 jumps 4 . \u201cOtherwise, the jumping mechanism will require too much energy to lift the body into the air, and the repeated impacts at take-off and landing would result in mechanical damage,\u201d he says. But those constraints might not apply to robots exploring planets other than Earth. On worlds with lower gravity, beetle-like robots could fly high. \n                   Meet the soft, cuddly robots of the future 2016-Feb-03 \n                 \n                   Origami robot folds itself in 4 minutes 2014-Aug-07 \n                 \n                   Explosive power makes silicone robot jump 2013-Feb-08 \n                 \n                   Team website at the University of Illinois \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22982", "url": "https://www.nature.com/articles/nature.2017.22982", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Pre-emptively treating kids for malaria is working, despite logistical challenges. In a sea of high-tech malaria fixes \u2014 everything from drug-delivery by drone to gene-edited mosquitoes \u2014 an old-fashioned approach is saving thousands of children in West Africa, according to studies presented this week at the American Society of Tropical Medicine and Hygiene (ASTMH) meeting in Baltimore, Maryland. The measure, called seasonal malaria chemoprevention, involves giving children a dose of antimalarial drugs once each month in the rainy season to prevent the disease in hard-hit regions. Researchers have previously demonstrated this strategy in large clinical trials but they had feared that their positive results wouldn\u2019t be replicated in the messy, real world, because chemoprevention requires thousands of local health workers to deliver drugs to children in villages far from hospitals, pharmacies and paved roads. \u201cPeople were doubtful this intervention would work, because it\u2019s so demanding,\u201d says Brian Greenwood, an infectious disease specialist at the London School of Hygiene and Tropical Medicine who helped to conduct trials that showed reductions in malaria prevalence up to 84% 1 . As a result of those studies, more than 6.4 million children in nine countries in sub-Saharan Africa (Burkina Faso, Cameroon, Chad, Gambia, Guinea, Mali, Niger, Nigeria, Senegal) received the drugs in 2016. It seems to be working, according to data presented at the ASTMH meeting. \u201cThey are seeing the same level of efficacy against malaria that we saw in clinical trials and reducing hospital admissions,\u201d says Greenwood. \u201cI am very happy.\u201d But researchers are also finding signs that this approach may not work for long. \n             Data driven \n           Malaria researchers deployed chemoprevention in the 1950s, but it fell out of favour when the widespread use of malaria drugs led to drug resistance. Yet by 2000, more than 830,000 people were dying of the disease each year \u2014 mainly children in Africa \u2014 and there were no blockbuster vaccines on the horizon. So malariologists revisited the approach. Between 2002 and 2012, clinical trials conducted in West Africa suggested that combinations of older malaria drugs had the power to  prevent 8.8 million cases and 80,000 deaths every year if implemented  solely during the rainy season, when the disease spikes. In 2012, the World Health Organization recommended the strategy with three old drugs \u2014 sulphadoxine, pyrimethamine and amodiaquine \u2014 so that the only sure-fire cure for malaria, artemisinin, would remain effective. Alassane Dicko, a malariologist at the University of Bamako in Mali, says that he did not take the intervention for granted when it launched in Mali in 2013, because he knew that funds were limited and drug resistance inevitable. \u201cResearch is essential,\u201d he says. His lab began assessing chemoprevention\u2019s efficacy, cost and effects on drug resistance. In August, Dicko and his colleagues reported 2  that malaria prevalence was reduced by 65% in children under age 5 who were treated with chemoprevention in the Malian district of Kita, compared to a similar number of children in a neighbouring district that lacked the funds to roll out the intervention. \n             Race against resistance \n           On the basis of results such as these, malaria researchers at the meeting estimate that chemoprevention has averted roughly 6 million cases and 40,000 deaths in 2015 and 2016 in the countries where it is practised. \u201cThis intervention has been extremely well documented over three or four years,\u201d says Erin Eckert, an epidemiologist at the US Agency for International Development\u2019s President\u2019s Malaria Initiative, based in Washington DC. As a result, the agency plans to help fund chemoprevention in eight countries next year. Also at the ASTMH meeting, Dicko reported a 80-person trial showing that adding another old malaria drug, primaquine, to the regimen combo blocks the transfer of the malaria parasite,  Plasmodium falciparum , from humans into mosquitoes. This would further reduce the amount of the parasite in circulation. Dicko aims to hit the disease hard and fast \u2014 with multiple drugs, as soon as possible \u2014 because he and his colleagues are already detecting genetic signs of drug resistance in parasites 3 . New chemoprevention drugs in the pipeline might not be ready before existing drugs fail because of resistance, Greenwood says. This year, he helped to launch a trial combining chemoprevention and a less effective malaria vaccine in Burkina Faso and Mali. The vaccine was previously shown to reduce the number of malaria cases by less than 36% in children 4 , but Greenwood hopes the combined tools, together with bed nets, can suppress malaria enough to stop it from bouncing back once today\u2019s drugs fail. By that time, he says, genetically engineered mosquitoes might be ready to fly. Reprints and Permissions"},
{"file_id": "nature.2017.23044", "url": "https://www.nature.com/articles/nature.2017.23044", "year": 2017, "authors": [{"name": "Barbara Casassus"}], "parsed_as_year": "2006_or_before", "body": "One agency has linked the widely used herbicide to cancer. In a long-awaited decision, the European Union has voted to allow for another five years the sale and use of the controversial herbicide glyphosate. The resolution comes amid arguments over whether the widely used weedkiller poses a cancer risk to people: one scientific body says it does, but others disagree. The binding vote, taken on 27 November, came just before the product\u2019s current licence expires on 15 December, and ends two years of fierce divisions among the 28 EU nations. International regulatory agencies, including the European Food Safety Authority (EFSA) and the European Chemicals Agency, have concluded that there is little evidence that the chemical causes cancer in people. But in March 2015, the International Agency for Research on Cancer (IARC), which is part of the World Health Organization, said that the substance was  \u201cprobably carcinogenic\u201d to humans , and that there was \u201cconvincing evidence\u201d that glyphosate\u00a0can cause cancer in laboratory animals. On 25 October, the European Commission proposed a ten-year extension for the substance, which is used in broad-spectrum herbicides and was launched in 1974 by US agrochemical giant Monsanto as the active ingredient in Roundup. But France and other countries rejected the idea because of safety concerns. Eighteen countries eventually voted in favour of a five-year extension, nine voted against and one abstained. \n             Mass protest \n           The compromise seems to have left both sides disappointed. \u201cEuropean governments failed European citizens and future generations today,\u201d said G\u00e9non Jensen, executive director of the Health and Environment Alliance, a non-governmental organization in Brussels that had campaigned for a ban on glyphosate. French President Emmanuel Macron responded to the vote by tweeting that glyphosate will be banned in France as soon as alternatives can be found, and within three years at the latest. A European Citizens' Initiative petition to stop the use of glyphosate in Europe had gathered more than 1.3 million signatures by 27 November. Meanwhile, the Glyphosate Task Force, which is based in Darmstadt, Germany, and represents 22 glyphosate manufacturers in the EU, complained that the vote \u201ccategorically ignored scientific advice (and was) mainly influenced by public opinion and driven by politics\u201d. Scientific conclusions on both sides have been criticized. Reuters reported in June that IARC members had not considered a large study showing no link between glyphosate and cancer in humans, because at the time, it had not yet been published. That study, which tracked the health of tens of thousands of farmers, agricultural workers and their families in Iowa and North Carolina starting in the 1990s, was published earlier this month 1 . What\u2019s needed now is a \u201ccompletely unbiased review of the evidence against glyphosate\u201d, Christopher Connolly, a neurobiologist at the University of Dundee, UK, said in a statement. \u201cWe must make the next five years count.\u201d \n                   Interstellar visitor, Arctic shipwrecks and a retraction recommendation 2017-Nov-01 \n                 \n                   Debate rages over herbicide's cancer risk 2015-Nov-13 \n                 \n                   Widely used herbicide linked to cancer 2015-Mar-24 \n                 \n                   A growing problem 2014-Jun-11 \n                 \n                   Case studies: A hard look at GM crops 2013-May-01 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.23037", "url": "https://www.nature.com/articles/nature.2017.23037", "year": 2017, "authors": [{"name": "Michele Catanzaro"}], "parsed_as_year": "2006_or_before", "body": "Letter from Nobel prizewinners denounces plight of Ahmadreza Djalali. Some 75 Nobel prizewinners have called on the Iranian government to release Ahmadreza Djalali, a researcher in disaster medicine who was sentenced to death last month. The letter is the latest and most powerful protest against the ruling by the scientific community so far. The group wrote to Gholamali Khoshroo, the Iranian ambassador to the United Nations, on 17 November, and the letter was made public on 21 November. The Nobel laureates express their concern for the conditions of Djalali\u2019s detention; they deem his trial \u201cunfair\u201d and \u201cflawed\u201d, and they urge the Iranian authorities to let him return to Sweden, where he lived. The list includes prominent names such as Harold Varmus, a former director of the US National Institutes of Health, now at the Weill Cornell Medicine institute in New York, and Andre Geim, a physicist based at the University of Manchester, UK. They wrote: \u201cAs members of a group of people and organizations who, according to the will of Alfred Nobel are deeply committed to the greatest benefit to mankind, we cannot stay silent, when the life and work of a similarly devoted researcher as Iranian disaster medicine scholar Ahmadreza Djalali is threatened by a death sentence.\u201d \n             Spying conviction \n           Djalali carried out research on emergency medicine \u2014 specifically, on the response of hospitals to terrorist attacks \u2014 while based at the University of Eastern Piedmont in Novara, Italy, and at the Karolinska Institute in Stockholm. He was arrested in Tehran in April 2016 and accused of collaboration with a hostile government. On 21 October this year, Djalali was convicted of espionage and sentenced to death, according to Djalali\u2019s wife Vida Mehrannia and Italian diplomatic sources. Tehran\u2019s prosecutor linked Djalali to the murder of several Iranian nuclear physicists. But a document thought to have been written by Djalali has claimed that he was sentenced after refusing to spy for Iran. Djalali\u2019s lawyer has appealed against the death sentence and is awaiting the court\u2019s decision. Since the death sentence became public, many organisations have protested against Djalali\u2019s treatment. They include: Amnesty International, the human rights group; senators in the Italian government; the directors of the European institutions at which Djalali worked; and academic groups including the Committee of Concerned Scientists and Scholars at Risk. \n                   Iranian scholar sentenced to death 2017-Oct-23 \n                 \n                   Iranian scientist to go on trial for espionage 2017-Aug-02 \n                 \n                   Jailed Iranian researcher\u2019s health worsening rapidly 2017-Mar-20 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22954", "url": "https://www.nature.com/articles/nature.2017.22954", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Representative Lamar Smith, a Republican from Texas, will not run for re-election in 2018. Representative Lamar Smith,  the controversial chair of the US House of Representatives\u2019 science committee , will retire when his term expires late next year. Smith, a Texas Republican, has repeatedly questioned the science behind climate change, has  sought to pare back the research portfolio of the US National Science Foundation (NSF)  and has launched dozens of probes into alleged wrongdoing by individual scientists and US government science agencies. Since taking the helm of the science committee in 2013, he has transformed it from a relatively deliberative panel into an investigative weapon. Under the rules of the House of Representatives, which limit committee chairs to six years in the role, Smith would have been forced to relinquish his post on the science panel in 2019. That is one of the reasons he decided against running for re-election, according to news reports; the other is the upcoming birth of his second grandchild. As the news of his retirement made the rounds, many scientists and environmentalists celebrated. \u201cIt is a relief,\u201d says Katharine Hayhoe, director of the Climate Science Center at Texas Tech University in Lubbock. Although many politicians have rejected the conclusions of climate science out of political expediency, she says, Smith has been more aggressive than most. The congressman has repeatedly tried to reshape the NSF, sponsoring multiple pieces of legislation that would require the agency to justify its grants  and explain how they serve the \u201cnational interest\u201d . He has also pushed unsuccessfully to scale back programmes in geoscience and social sciences, among other fields. Smith has notably scrutinized the work of climate scientists. In 2015, he attempted to compel the US National Oceanic and Atmospheric Administration (NOAA)  to hand over internal documents related to a climate-change study . The research, published in  Science  in 2015 1 , sought to dispel the idea that the rate of global warming had slowed down around the turn of the century. Smith went so far as to accuse a NOAA official \u2014 Thomas Karl, who has since retired \u2014 of manipulating data to advance an \u201cextreme climate change agenda\u201d. In 2016, Smith came to the defence of oil giant Exxon Mobil when it was being investigated by the attorneys-general of New York and Massachusetts, who wanted to know whether the firm had misled investors about the financial implications of global warming. Smith issued subpoenas to the attorneys-general as part of a broader probe, which also targeted environmental groups that have accused Exxon Mobil of suppressing internal research and spreading false information about climate change. \u201cI think [Smith\u2019s] position on peer review, on the NSF and climate science put him at odds with the science community,\u201d says physicist Neal Lane, a former NSF director who served as science adviser to former president Bill Clinton. \u201cBut it was consistent with that of the leadership in the House, which can hardly be described as pro-science.\u201d Additional reporting by Rachael Lallensack. \n                   How Republicans reshaped the House science committee 2016-Oct-19 \n                 \n                   US lawmakers expand probe of climate study 2016-Feb-26 \n                 \n                   US science agency refuses request for climate records 2015-Oct-28 \n                 \n                   Mistrust and meddling unsettles US science agency 2015-Mar-10 \n                 \n                   Social scientists hit back at grant rules 2013-Nov-12 \n                 \n                   Republicans put 'national interest' requirement on US science agency 2013-Nov-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22909", "url": "https://www.nature.com/articles/nature.2017.22909", "year": 2017, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "A group of volunteers claims that the organization that spearheaded global protests in April has been unduly secretive about its management practices. The US group that sparked the  global March for Science movement  is facing complaints about its management practices as it files for non-profit status and signals its intent to continue as \u201ca movement to advance science and its role in public life\u201d. On 23 October, a group of current and former volunteers  posted an open letter  to the central March for Science organization in New York City, alleging that it is secretive, insensitive to the concerns of its volunteers, and unwilling to share power or information with organizers of its many affiliated \u2018satellite\u2019 groups around the world. The volunteers also claim that the organization sidelined and stonewalled experienced activists who wanted the movement to focus on how science can be used in ways that perpetuate racism, sexism and other forms of discrimination. In a statement to  Nature , the March for Science said that it welcomed the \u201cconcrete feedback and suggestions\u201d. But volunteers have already walked away from the group, and at least one major satellite group, in New York, has severed ties. The turmoil comes at a time of renewed political activism by US scientists, much of it in protest against the policies of US President Donald Trump. Aaron Huertas, the former communications director for March for Science and an author of the letter, says that the organization is acting in a hierarchical fashion, and not as the grassroots movement that many volunteers wanted. He adds that experienced activists in the group, many of whom focussed on issues of social justice, were the first to raise the alarm about lack of transparency \u2014 and with good reason. \u201cTransparency prevents marginalized people from having their work and labour undervalued or thrown away,\u201d Huertas says. He and his letter co-signatories are concerned that the group has not published a detailed accounting of its finances, including the US$1.3 million it raised between 1 February and 30 April. They are uncomfortable with the group\u2019s decision to ask some volunteers and board members to sign non-disclosure or confidentiality agreements, and to hire one of the group\u2019s original co-chairs, Caroline Weinberg, as its paid interim director without advertising the job. Weinberg says that the board hired her in August as the part-time interim executive director at a salary of $67,000 per year, with no benefits. She adds that a public search for a permanent director will begin in December, and that the March for Science will release more detailed financial information \u201cat the end of this week or early next.\u201d In the meantime, the disclosure on 24 October that Weinberg and her two co-chairs received some money for their services is also coming under scrutiny. Terry Kush, the March for Science\u2019s chief operating officer, revealed the payments in a memo to the March for Science's satellite groups. \u201cIn May and June, 12 national team members were paid for their work those months, including the former co-chairs,\u201d Kush wrote. She added: \u201cWe\u2019d like to reaffirm our commitment to increasing transparency within the org and the larger grassroots movement.\u201d The group's three original co-chairs \u2014 Weinberg, Jonathan Berman and Valorie Aquino \u2014 resigned their positions in late April and signed a confidential agreement with the organization in late August, Weinberg says. She adds that while she \"cannot comment on the clauses therein\", that does not prevent her from being open about \"the march, our work, accounting, governance, or legal structures\u201d. Aquino and Weinberg also signed what Weinberg calls \"standard\" confidentiality agreements with the board. In a 25 October post on Twitter, former co-chair Jonathan Berman confirmed that he had been paid $6,500. \u201cI didn't feel great about it at the time, and I'm still not sure accepting it was the right thing to do,\u201d he wrote. Huertas calls these payments \u201csecret\u201d, and argues that not disclosing the information publicly undermined the effectives of the March for Science group. Weinberg says that the payments were made in July, but \u201cnot publicly released\u201d until now only because they took place in the middle of the fiscal year. \u201cThe accusation that we are in this to enrich ourselves and make money is deeply offensive and something I am sadly not surprised to see aimed at women in leadership as it devalues our work and commitment to the cause,\u201d Weinberg says. \u201cMost people do not have the luxury of volunteering full time in perpetuity, and need \u2014 and deserve \u2014 to be paid for this work.\u201d \n                     What happened at March for Science events around the world 2017-Apr-21 \n                   \n                     How the March for Science splits researchers 2017-Apr-18 \n                   \n                     Nature supports the March for Science 2017-Apr-11 \n                   Reprints and Permissions"},
{"file_id": "551425a", "url": "https://www.nature.com/articles/551425a", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Some top researchers prosper in Hungary as country tries to improve its international standing in science. Earlier this year, cell biologist Attila Rem\u00e9nyi was facing his toughest decision since returning to his native Hungary a decade ago. With his generous start-up funding about to run out, should he downsize his lab? Then, in June, the government\u2019s National Research, Development and Innovation Office (NRDIO) put out a call for five-year basic-research grants of up to 300 million Hungarian forints (US$1.18 million) each for highly cited scientists such as Rem\u00e9nyi. \u201cIt came out of the blue,\u201d says Rem\u00e9nyi at the Hungarian Academy of Sciences (HAS) Research Centre for Natural Sciences, Budapest, who learnt on 13 November that he was among 12 winners. But for NRDIO president J\u00f3zsef P\u00e1link\u00e1s, the Frontline Research Excellence grants are the result of years of work. They are part of a plan to create a long-term, systematic plan of grants and rewards to encourage researchers in all fields to strive for world-class publications and to tempt Hungarian scientists working abroad to return. In a country whose leaders are coming under increasing criticism for autocratic and xenophobic tendencies, scientists say that the situation for science has never been rosier. Under Viktor Orb\u00e1n\u2019s nationalist government, this small, post-communist country has been steadily falling on  The Economist  magazine\u2019s Democracy Index. Last year, several foreign members of the HAS resigned, citing the failure of the academy to protest against what they saw as anti-democratic moves by the government. HAS president, mathematician L\u00e1szl\u00f3 Lov\u00e1sz, responded that the academy is not a political organization. Scientists in the country are noticeably reluctant to comment publicly on politics, and several young researchers told  Nature  they fear that criticizing the government might compromise their careers. Yet within this troubled political environment, P\u00e1link\u00e1s, a physicist, has spent the past few years quietly persuading the government that basic science matters as much as product-focused research. Shortly after becoming president of the HAS in 2008, he created the Momentum system of start-up funding\u00a0\u2014 one-time, five-year grants of up\u00a0to 50\u00a0million forints per year\u00a0\u2014 to encourage Hungarian scientists to set up independent labs back home. Rem\u00e9nyi was a Momentum recipient in 2013.  Without such serious selection science won\u2019t work well.  In 2015, P\u00e1link\u00e1s left HAS to become the founding director of the NRDIO, where he designed a system of regular grants to help ensure that returnees stay after the start-up money runs out. The frontline grants are a key part of this, giving the recipients salaries equivalent to the European Union average, which is two-and-a-half times higher than the salary that a scientist would normally earn in Hungary. Around 50 of these grants will eventually run each year. The programme is modelled on European Research Council grants, but with a twist: only those who have published a paper in the past five years that counted among the top 10% most-cited papers in their discipline are eligible to apply. This approach \u201ccreates a lot of tension in the community, but without such serious selection science won\u2019t work well,\u201d says P\u00e1link\u00e1s. To further encourage scientists to aim for quality over quantity, last year he introduced another reward for high-impact publication: researchers who within two years have a paper among the top 5% most highly cited in their field automatically receive a one-off payment of 20 million forints. Hungary has a long tradition of research and outperforms other former communist countries in the EU on many measures. It has won more European Research Council grants and was the only country this year to win two Teaming grants: prestigious EU awards to create centres of excellence in 15 mostly eastern European countries in partnership with a western European research organization. It has also made some large investments, most generously in the Hungarian Brain Research Programme, launched in 2014, which has received 18.5 billion forints up to 2021 and enabled many principal investigators to start their own labs. A 3-billion-forints programme has just been agreed in quantum technology. Five new programmes in areas including artificial intelligence and water research will be added next year, thanks to a 3% increase in the NRDIO budget, agreed in principle this month. Hungary\u2019s research performance still lags behind that of science-strong western European countries, however, and at 1.2% of gross domestic product, its research investment is well below the EU average of 2%. To support its scientific ambitions, Hungary has heavily invested its EU structural funds\u00a0\u2014 subsidies to poorer regions \u2014\u00a0in expanding research infrastructure. The country\u2019s scientists fear that when the current round of these funds runs out in 2019, these major investments may go to waste. P\u00e1link\u00e1s says that to avoid this, he will request a doubling of the national research budget in 2019. And despite the political challenges, Hungarian scientists seem optimistic: \u201cThe situation for science is better than it has been before,\u201d says Rem\u00e9nyi. Immunologist Adam D\u00e9nes returned from the United Kingdom in 2012 to start his own lab at the HAS Institute of Experimental Medicine in Budapest, a move he describes as a \u201cpolitical, philosophical and career challenge\u201d. But for now, he says, \u201cthe pluses are more than the minuses.\u201d \n                     Efforts to save leading Hungarian university hit hurdle 2017-Oct-18 \n                   \n                     After the Berlin Wall: Central Europe up close 2014-Nov-05 \n                   \n                     Rhapsody for Hungarian science 2011-Dec-12 \n                   \n                     http://www.nature.com/news/specials/easterneurope/index.html \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22996", "url": "https://www.nature.com/articles/nature.2017.22996", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Complex chemistry in the dwarf planet\u2019s upper atmosphere may explain one of its biggest mysteries. Pluto\u2019s atmosphere is even more bone-chillingly cold than one might expect 5 billion kilometres from the Sun. New research suggests that\u2019s because of  the smog that envelops the dwarf planet . \u201cHaze is responsible for all the atmospheric cooling,\u201d says Xi Zhang, a planetary scientist at the University of California in Santa Cruz. He and his colleagues describe the findings in the 16 November issue of  Nature 1 . When NASA\u2019s  New Horizons spacecraft flew past Pluto in July 2015 , it discovered that the atmosphere was about -203 \u00baC, just 70 degrees above absolute zero 2 . That\u2019s around 30 degrees colder than predicted \u2014 and a big mystery to planetary scientists. Figuring out how Pluto\u2019s atmosphere works is crucial for understanding atmospheres on other large icy worlds in the Solar System and beyond. \u201cUntil we know the reason for the cold temperatures, we can\u2019t extrapolate to other seasons on Pluto, much less other bodies,\u201d says Leslie Young, a planetary scientist at the Southwest Research Institute in Boulder, Colorado, who was not involved in the study. \n             Smog blanket \n           Pluto\u2019s atmosphere is made mostly of nitrogen, with smaller amounts of compounds such as methane. High in the atmosphere \u2014 between 500 and 1,000 kilometres above the surface \u2014 sunlight triggers chemical reactions that transform some of these gases into solid hydrocarbon particles. The particles then drift downward and, at around 350 kilometres above Pluto\u2019s surface, clump with others to form long chemical chains. By the time they reach 200 kilometres\u2019 altitude, the particles have transformed into thick layers of haze, which the New Horizons spacecraft saw dramatically blanketing Pluto. Zhang and his colleagues compared the heating and cooling effects of the atmosphere\u2019s gas molecules to those of its haze particles. Earlier studies have suggested that the presence of gas molecules, such as hydrogen cyanide, could help explain why Pluto\u2019s atmosphere is so cold 3 . But Zhang\u2019s team found that including haze was the only way to get their model to match the temperatures that New Horizons measured as it flew by the dwarf planet. \u201cThe fundamental difference is the size,\u201d Zhang says. Molecules are typically less than a nanometre across, whereas the haze particles are several hundred nanometres across. That means that the gas and the haze behave very differently in the way they absorb and re-radiate energy from the Sun. Haze turns out to both heat up and cool down more efficiently than gas, Zhang says. \u201cIt is a neat idea,\u201d says Sarah H\u00f6rst, a planetary scientist at Johns Hopkins University in Baltimore, Maryland. Scientists probably hadn't thought about haze as the cooling culprit before because the haze layers do not block light, says Tanguy Bertrand, a planetary scientist at the Laboratory for Dynamic Meteorology in Paris who has studied Pluto's atmosphere with his colleague Fran\u00e7ois Forget 4 . \u201cI find this study very convincing,\u201d Bertrand says. \n             Competing ideas \n           But other researchers have proposed different ideas about why Pluto\u2019s atmosphere is so cold. Roger Yelle, a planetary scientist at the University of Arizona in Tucson, reported one such approach at a conference in Latvia in September. His team\u2019s model suggests that a combination of hydrogen cyanide, acetylene and ethane gas can cool things down. All three gases are known to exist in Pluto\u2019s atmosphere. Zhang\u2019s team and Yelle\u2019s team have yet to reconcile their contradictory conclusions. But after it launches in 2019, NASA\u2019s James Webb Space Telescope could test Zhang's proposal. If the haze particles are indeed the main factor cooling Pluto\u2019s atmosphere, they would make the dwarf planet appear relatively bright in mid-infrared wavelengths. Zhang hopes to observe Pluto with the Webb telescope to see if his team is right. \n                   Icy heart could be key to Pluto\u2019s strange geology 2016-Oct-21 \n                 \n                   Pluto snow forecast poses atmospheric conundrum 2015-Sep-01 \n                 \n                   Nitrogen glaciers flow on Pluto 2015-Jul-24 \n                 \n                   Vibrant Pluto stuns scientists 2015-Jul-21 \n                 \n                   New Horizons mission \n                 Reprints and Permissions"},
{"file_id": "nature.2017.23046", "url": "https://www.nature.com/articles/nature.2017.23046", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Progress in the fight against a curable disease that kills hundreds of thousands of children has stalled, according to the World Health Organization. The number of malaria cases rose in many countries in 2016, suggesting that progress has halted in the global fight against the disease, the World Health Organization (WHO) said in a report on 29 November 1 . Globally, malaria infections increased by about 5 million from 2015 to 2016, for a total of 216 million, with apparent jumps in parts of Asia, Africa and South America. The number of people who died from the disease remained relatively steady, at around 445,000, the WHO found. Although data on malaria is often inexact in countries with weak health-care systems, many researchers are concerned by the trends described in the WHO report, which the agency attributes to flat funding levels for anti-malaria programmes. \u201cFor the first time, we can confidently say that we have stopped making progress,\u201d says Pedro Alonso, the director of the Global Malaria Programme at the WHO in Geneva, Switzerland. Alonso worries that governments and donors have become complacent about malaria, given that deaths from the disease fell by an estimated 62% between 2000 and 2015. \u201cWe know what happens when we stop applying pressure,\u201d Alonso says. \u201cMalaria comes back with a vengeance.\u201d \n             Access to treatment \n           When governments listed malaria reduction as one of the United Nations\u2019 Millennium Development Goals in 2000, billions of dollars in funding flowed in from the Global Fund to Fight AIDS, Tuberculosis and Malaria and other donors, and death rates began to drop. One of the strongest pushes involved getting the gold-standard cure for the disease \u2014 pills called artemisinin-combination therapies (ACTs) \u2014 to remote regions. Children are at particularly high risk of death if malarial fevers are not treated within a couple of weeks. Strategies for lowering the cost of ACTs to less than a few dollars per treatment course and to distribute the drugs to health workers have been relatively successful over the past decade. The Global Fund estimates that the malaria-control programmes it has helped to fund have provided 668 million malaria treatments. And the spread of rapid diagnostic tests for malaria have likely helped to delay the development of drug resistance, by limiting the number of children who are treated for suspected, but not confirmed, cases of the disease. The percentage of suspected cases tested in sub-Saharan Africa \u2014 the region hit hardest by malaria \u2014 increased from 36% in 2010 to 87% in 2016. That does not mean that everyone who needs treatment is getting it. Between 2014 and 2016, 39% of African children under the age of five who developed fevers were not taken to a trained health-care provider, the WHO report says, citing household surveys. The percentage of children receiving care for fevers is often used as an indication of how many may have sought treatment for malaria, although it is an imperfect measure. \u201cIf you ask me, the number-one priority must be to ensure that people stop dying of a disease that is entirely curable,\u201d says Alonso. \n             Resistance fears \n           The spread of drug-resistant malaria is also a worry. Strains of  Plasmodium falciparum , the parasite that causes the most deadly form of the disease, have become resistant to artemisinin in Thailand, Cambodia, Myanmar, Laos and Vietnam. Southeast Asia accounts for just 3% of the world's malaria cases. But if drug-resistant malaria spreads from Asia to Africa, where 90% of  P. falciparum  cases occur, it would wreak havoc, says Nick White, a malariologist at the Mahidol Oxford Tropical Medicine Research Unit in Bangkok, Thailand. \u201cThere is a narrow window of opportunity to eliminate malaria in southeast Asia before we lose the drugs, and it\u2019s shutting,\u201d White says. \u201cTime is running out.\u201d Next week at a meeting in Nay Pyi Taw, Myanmar, researchers and government officials from across southeast Asia will discuss how to accelerate malaria elimination. Achieving that goal by 2030 in a 22-nation area stretching from Afghanistan to Vanuatu would cost around US$29 billion, according to an analysis by the Global Health Group, a think-tank at the University of California, San Francisco. But it would also save roughly $90 billion over that period from reduced health-care costs and gains in productivity, the group found. Nonetheless, the money available for malaria-elimination programmes has been dropping 2 . A review of 75 malaria resurgences between 1930 and 2011 found that most upticks in the disease followed funding disruptions that weakened malaria-control programmes 3 . Other causes included conflict and natural disaster. However, Fran\u00e7ois Nosten, a malariologist at the Mahidol Oxford Tropical Medicine Research Unit facility in Mae Sot, Thailand, would like to see more data. \u201cWe need to have a clear understanding of what needs to be done,\u201d he says. \u201cThe solution is not just about money.\u201d Reprints and Permissions"},
{"file_id": "nature.2017.22860", "url": "https://www.nature.com/articles/nature.2017.22860", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "D-Wave system shows quantum computers can learn to detect particle signatures in mountains of data, but doesn\u2019t outpace conventional methods \u2014 yet. A rudimentary quantum computer has rediscovered the Higgs boson. Sort of. Physicists have been working hard to develop machines that can use quantum mechanical tricks to speed up computation. But they also hope that such quantum computers can return the favour and help them to discover new laws of nature. Now, a team has shown that a quantum circuit can learn to sift through reams of data from atom-smashing experiments in search of a new particle. Their proof-of-principle study \u2014 performed using a machine built by  quantum-computing company D-Wave  working on the now-familiar case of the Higgs boson \u2014 does not yet provide a clear advantage over conventional techniques. But the authors say that quantum machine learning could make a difference in future experiments, when the amounts data will grow even larger. Their research was published on 18 October in  Nature 1 . Kyle Cranmer, a physicist at New York University who wasn't involved in the work, says that it\u2019s refreshing to see a quantum machine applied to a practical physics problem \u2014 instead of the usual mathematical questions such as factoring whole numbers into primes. \u201cBefore this point, people were aware that this maybe some day will be relevant,\u201d he says. \u201cThis makes it looks like maybe it is.\u201d \n             Optimal solutions \n           In 2012, two experiments at the Large Hadron Collider (LHC) at CERN, Europe\u2019s high-energy physics lab near Geneva, Switzerland,  announced that they had proof of the existence of the Higgs boson , the last missing piece in the standard model of particle physics. The two experiments, called CMS and ATLAS, found evidence of the boson created in proton collisions from the way in which the Higgs decayed into more-common ones, such as pairs of high-energy photons. But each time the LHC collides two protons, hundreds of other particles are created, some of which can be misinterpreted as photons when they hit the detectors. To help speed up their search for the Higgs, ATLAS and CMS physicists used simulated data to train machine-learning algorithms to tell wheat from chaff \u2014 photons from impostors. More recently, particle physicist Maria Spiropulu, who helped lead the Higgs search at CMS, wanted to know whether a quantum computer could help to make the training process more efficient, in particular by reducing the amount of simulated data required to train the system. \u201cI wanted to see if it can solve the Higgs problem, because I know the Higgs problem,\u201d says Spiropulu, who is at the California Institute of Technology in Pasadena. Her collaborator Alex Mott, a physicist who is now at DeepMind in London, translated the learning process into something that could be calculated by a \u2018quantum annealing\u2019 computer built by D-Wave, which is based in Burnaby, Canada. This type of machine finds the optimal solutions to certain problems by allowing superconducting loops, which encode quantum information, to fall into their lowest-energy state. The idea was to have the quantum machine find the optimal criteria that an ordinary computer could then use to look for the photon signatures of the Higgs in real data. To test their theory, the team gained access to a D-Wave machine at the University of Southern California in Los Angeles. The experiment was successful, Spiropulu says: \u201cWe can train with small data sets and find the optimal solution.\u201d The researchers didn\u2019t use those criteria to rediscover the Higgs \u2014 because they didn't need to. Showing that it is possible was \u201cthe coolest part\u201d of their work, says Cranmer, who is a data-analysis specialist and helped lead the Higgs search in the ATLAS collaboration. \n             Beyond physics \n           Don\u2019t expect physicists to switch to quantum computers just yet: so far, the machine hasn\u2019t performed better than a virtual version of itself that Spiropolu and her team ran on a conventional computer. And there is a long way to go to demonstrate that these techniques are more efficient than some existing machine-learning algorithms that are able to train on relatively small data sets, Cranmer says. Spiropulu agrees, adding that it will be necessary to test the various approaches against one another to see which is best. But the results could have an impact in fields beyond physics. Davide Venturelli, a physicist working for the non-profit Universities Space Research Association and at the NASA Ames Research Center in Mountain View, California, manages a programme that makes a D-Wave machine at Ames (jointly run by Google and NASA) available to experimenters around the world. Researchers in fields ranging from Earth science to bioinformatics  are interested  in using quantum annealers, in particular for machine-learning applications, he says.\u201cThe interesting thing is that this whole thing works,\u201d Mott says. Read the  related News & Views . \n                   IBM's quantum cloud computer goes commercial 2017-Mar-06 \n                 \n                   Commercialize quantum technologies in five years 2017-Mar-03 \n                 \n                   D-Wave upgrade: How scientists are using the world\u2019s most controversial quantum computer 2017-Jan-24 \n                 \n                   Quantum computer makes first high-energy physics simulation 2016-Jun-22 \n                 \n                   Artificial intelligence called in to tackle LHC data deluge 2015-Dec-01 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22813", "url": "https://www.nature.com/articles/nature.2017.22813", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "The agency's plan to reverse limits on greenhouse-gas emissions is likely to draw legal challenges. The US Environmental Protection Agency (EPA) is moving to repeal former  president Barack Obama's landmark regulations to reduce greenhouse-gas emissions  from power plants. The plan, introduced on 10 October, is a step towards fulfilling  President Donald Trump's promises to reverse Obama-era climate regulations  and end the \u201cwar on coal\u201d. But any attempt to repeal the power-plant rule is certain to face lawsuits from environmental groups and many states that support Obama's climate policies. \u201cThe Trump Administration\u2019s persistent and indefensible denial of climate change \u2014 and their continued assault on actions essential to stemming its increasing devastation \u2014 is reprehensible,\u201d said Eric Schneiderman, attorney general for the state of New York, in a prepared statement. \u201cI will use every available legal tool to fight their dangerous agenda.\u201d US emissions from electricity generation have been falling in recent years as energy utilities have shifted away from coal, and towards cheap natural gas and renewables. The Obama administration established the power-plant regulations to hasten that progress, and to help the United States to meet its commitments under the 2015 Paris climate accord. The power-plant rule would reduce greenhouse-gas emissions to 32% below 2005 levels by 2030 \u2014 but it is mired in legal challenges. In 2016, the US Supreme Court blocked the regulations from taking effect. Legal challenges from 27 state governments are still pending, although a federal appeals court has put the case on hold while the Trump administration reviews the rule. Trump has shown no fear of challenging environmentalists on climate issues: he has  already announced plans to pull the United States out of 2015 Paris climate pac t. But his administration's attempts to roll back various environmental regulations have faced legal setbacks. One of the latest rebukes came on 4 October, when a federal court rejected an effort by the Department of the Interior to delay implementing curbs on methane emissions from oil and gas operations on public lands. \n               A long fight \n             The power-plant rule that Trump's administration plans to challenge was made possible by the Supreme Court's decision in 2007 that carbon dioxide and other greenhouse gases are pollutants under the terms of the Clean Air Act. Two years later, the EPA ruled that these gases  are a threat to human health and the environment  \u2014 a decision known as an 'endangerment finding'. That allowed the agency to draft regulations to limit greenhouse-gas output from various sources. EPA administrator Scott Pruitt sued to overturn the endangerment finding in his former role as Oklahoma's attorney general, before Trump took office. More recently, as EPA's chief, he has questioned his own agency's authority to regulate CO 2 . Environmentalists fear that he will attempt to repeal the endangerment finding, which would inevitably prompt a flurry of lawsuits. The legal fight over the EPA's new plan to repeal the Obama power-plant regulations will almost certainly focus on whether the Clean Air Act allows the agency to require that utilities alter their energy portfolios to reduce emissions. The Obama administration set limits on emissions and then allowed states and utilities to decide how to meet those limits, with options that included expanding efforts to reduce energy consumption and developing new sources of renewable energy. The Trump administration's proposal says that the EPA overstepped its legal authority when it finalized the Obama-era rules. The administration argues that the Clean Air Act limits the EPA to crafting regulations that can be implemented at power plants themselves. The proposal also says that the EPA is still considering whether and how to craft alternative regulations for power-plant emissions. Jonathan Adler, who heads the Center for Business Law and Regulation at Case Western Reserve University School of Law in Cleveland, Ohio, says the Trump administration can reasonably argue \u2014 as many states have \u2014 that the Clean Air Act was not designed to regulate greenhouse gases. Courts often give a certain amount of deference to federal agencies on regulatory matters, he says, but only if the agencies show that they have followed all legal and procedural requirements for finalizing new rules. \u201cSome of the same legal doctrines that helped the Obama administration defend its regulatory decisions will now help the Trump administration defend its decisions going in the opposite direction,\u201d Adler says. \u201cThis will certainly be a test for whether this administration is capable of engaging in this sort of heavy lift.\u201d \n                     US government disbands climate-science advisory committee 2017-Aug-20 \n                   \n                     Fears rise for US climate report as Trump officials take reins 2017-Aug-01 \n                   \n                     How Trump plans to wipe out Obama-era climate rules 2017-Mar-28 \n                   \n                     Trump\u2019s pick for environment agency chief sued government over climate rules 2016-Dec-07 \n                   Reprints and Permissions"},
{"file_id": "550309a", "url": "https://www.nature.com/articles/550309a", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Stellar collision confirms theoretical predictions about the periodic table. Gold, platinum, uranium and many of the rare-earth elements that are crucial to today\u2019s high-tech gadgets are generated during the formation of black holes, astronomers have said. The collision of two small but dense stars simultaneously solved several cosmic mysteries, researchers announced at a press conference in Washington DC on 16 October. More than 30 papers have been published so far in five journals \u2014  Physical Review Letters, Science, Nature, Nature Astronomy  and  Astrophysical Journal Letters. Astronomers watched as two neutron stars \u2014 small but very dense objects formed after the collapse of stars bigger than the Sun \u2014 collided and merged, forming a black hole, in a galaxy 40 million parsecs (130 million light years) away, according to two dozen researchers interviewed by  Nature \u2019s News team. The collision generated the strongest and longest-lasting gravitational-wave signal ever seen on Earth. And the visible-light signal generated during the collision closely matches predictions made in recent years by theoretical astrophysicists, who hold that many elements of the periodic table that are heavier than iron are formed as a result of such stellar collisions. Neutron-star mergers are also thought to trigger previously mysterious short \u03b3-ray bursts, a hypothesis that now also seems to have been confirmed. Astronomers have good reasons to believe that they are looking at the same source of both the gravitational waves and the short \u03b3-ray bursts, says Cole Miller, an astronomer at the University of Maryland in College Park, who was not involved in the research but who  has seen some of the papers ahead of their publication . \n               Bright object \n             The event  was detected on Earth on 17 August , and triggered weeks of febrile, round-the-clock activity on all 7 continents, as more than 70 teams of researchers scrambled to observe the aftermath. The collision was felt first as a space-time tremor by the Laser Interferometer Gravitational-wave Observatory (LIGO) in the United States and by its Italy-based counterpart Virgo, and seen seconds afterwards as a smattering of high-energy photons by NASA\u2019s Fermi Gamma-ray Space Telescope. Alerted by the LIGO\u2013Virgo team, astronomers then raced to find and study what was seen as a bright object in the sky using telescopes big and small, famous and obscure, on land and in orbit, and spanning the spectrum of electromagnetic radiation, from radio waves to X-rays. Cody Messick was at his home at 08:41 local time (12:41  ut ) on 17 August when he first found out about the event. \u201cI remember standing on my stairs and looking at my phone, thinking: \u2018Wow!\u201d he says. Messick, who is a physicist at Pennsylvania State University in University Park, belongs to a small team of LIGO first-responders who receive frequent automated alerts from the two interferometers, which are based in Livingston, Louisiana, and Hanford, Washington. Normally, LIGO\u2019s algorithms flag a potential signal in real time only if both interferometers detect it. Messick was surprised, because the message on his smartphone mentioned a strong signal \u2014 but one seen only at the Hanford site. Messick quickly got on a conference call with his team leader, Chad Hanna, also at Pennsylvania State, and other colleagues. Together, they examined the data online. The Hanford signal looked like a textbook example of the waveform of the gravitational waves emitted by two compact objects, each slightly more massive than the Sun, as they spiral into each other, he says. In particular, the waves lasted much longer \u2014 about 100 seconds \u2014 and had a higher pitch than the signals from the much more massive black-hole mergers that LIGO had previously detected. When they looked at the data stream coming from Livingston, the LIGO researchers found a similar signal there as well, but one with a loud, spurious glitch towards the end. It was that anomaly that had caused the real-time-analysis software to ignore the signal, says David Shoemaker, a physicist at the Massachusetts Institute of Technology in Cambridge who is LIGO\u2019s spokesperson. Meanwhile, researchers received another alert: Fermi had detected a short \u03b3-ray burst that had occurred 1.7 seconds after the gravitational waves had ended. Called GRB170817A, it was unusually faint for such a burst. \n               Second signal \n             In Italy, another technical glitch had suspended the continuous stream of data normally sent out by Virgo. So it took another 40 minutes for researchers to realize that they, too, had a signal \u2014 albeit a faint one. It transpired that the waves had travelled close to one of the interferometer\u2019s four blind spots, says Jo van den Brand, a physicist at the Vrije Universiteit Amsterdam and spokesperson for the Virgo Collaboration. By 13:21  ut , 40 minutes after the event, the LIGO\u2013Virgo team had decided to notify its roughly 70 follow-up partners \u2014 teams of astronomers on standby to look for related events using conventional telescopes. Four and a half hours later, the team sent a second, much more useful alert. The timing of Virgo\u2019s feeble signal had been sufficient for the LIGO-Virgo team to identify the source of the waves. It pointed to a region of the sky spanning an angle of just a few degrees, in the southern sky. They called the event GW170817, after the date it was detected. Virgo had joined LIGO\u2019s observation campaign only on 1 August, after a five-year shutdown for upgrades. And just three days before the event\u2019s detection, on 14 August,  LIGO and Virgo had made their first joint detection . It enabled them to rehearse the more precise identification of the patch of sky of interest. The event on 17 August enabled them to narrow it down even further. And the estimated distance was ten times closer to Earth than in the previous events. They could tell this because of how loud and persistent the waves were: it was the strongest signal LIGO had ever sensed. After the fact, Hanna\u2019s team was able to extract a signal that lasted a full six minutes. Together, the alerts from LIGO\u2013Virgo and Fermi sent astronomers into a frenzied rush. Each team wanted to be first to spot the fireworks produced by a neutron-star merger. It was daytime on most of the world\u2019s land mass, so teams began to formulate strategies for their nocturnal observations. They knew that, at that time of the year, the region to search was not far from the Sun. That left a window of observation of a couple of hours after dusk, before the region of sky would set below the horizon. \u201cWe had a complicated, choreographed dance of telescopes that night,\u201d says Iair Arcavi, an astrophysicist at the University of California, Santa Barbara, whose team made non-stop observations using the Las Cumbres Observatory, a worldwide  network of robotic telescopes . It began by activating a number of telescopes in Chile. \n               Three messengers \n             The first person to see the event may have been Charles Kilpatrick, an astronomer at the University of California, Santa Cruz. He was part of a team that was scanning the sky with the more modest means of the single one-metre Swope Telescope in Chile. Like his competitors, Kilpatrick was closely watching the exposures one by one as they came out, comparing them with archival images of the same patch of sky. By the ninth exposure, he saw something very conspicuous in a galaxy called NGC 4993. \u201cIt looked exactly like a point source in this image that wasn\u2019t in the reference image,\u201d Kilpatrick says. The team named it SSS17a. At least two other groups say they spotted the bright dot independently. They and other teams also made sure that there were no other plausible candidates within the search region. GW170817, GRB170817A and SSS17a really seemed to be three different messengers from the same source. LIGO and Virgo lacked a sufficiently detailed signal of the final instants of the collision to be certain that the objects were neutron stars, Shoemaker says. From gravitational-wave data alone, they could have been two unusually small black holes. But the presence of visible light strongly suggested that at least one of the objects in the merger was a neutron star, he and other researchers say. The group at the University of California, Santa Cruz, was also the first to measure the optical spectrum of SSS17a. On the first night, the dot was bright blue, says astronomer Ryan Foley, who led that effort. NASA\u2019s Swift telescope also detected blue, as well as ultraviolet, light. But during the next few nights of observation, those colours faded away, and the object became more red, according to multiple teams. Colliding neutron stars should spread debris \u2014 a mix of neutrons, but also some protons \u2014 in three ways, says Brian Metzger, a theoretical astrophysicist at Columbia University in New York City. First, they fling matter out from their outer layers during the final orbits. Then some matter gets squeezed out in the actual collision. Finally, as the two stars begin to collapse into a black hole, it forms an accretion disk of matter, some of which flies out instead of falling in. Over the past decade or so, astrophysicists had come to believe that this was the most plausible mechanism to explain the abundance of the heavier elements of the periodic table 1 . The theory held that, overall, about 2% of the combined mass of the stars would escape the fate of the rest. Within one second of the collision, this material would have expanded to become a cloud tens of thousands of kilometres across, but still about as dense as the Sun. In this cauldron, protons and neutrons would immediately clump together to form neutron-heavy nuclei, which would then begin to decay radioactively. This radioactivity would keep the cloud glowing hot for several days, even as it reached the size of the Solar System. Within a million years, it would spread across an entire galaxy. \n               As predicted \n             Metzger says that the switch from blue to red was just what he expected to see. His models suggest that nuclei in this early cloud would reach the masses of many of the elements beyond iron, although not the heaviest ones. This chemical composition would cause the cloud to glow blue. But the real smoking gun for this model, the signatures of the formation of the heaviest elements, would be a cloud that glowed in the red and infrared. These would be elements forged in a separate wave of the explosion, probably the one coming from the accretion disk, says Metzger. \u201cWe had predicted exactly what kind of red,\u201d says Daniel Kasen, a theoretical astrophysicist at the University of California in Berkeley. Jennifer Barnes, another theorist then in Kasen\u2019s team who is now at Columbia University, had run the supercomputer simulations that predicted the experimental signatures in 2013 2 . \u201cI had just finished my PhD thesis predicting what these things would look like,\u201d she says. Eleonora Troja, an astronomer at NASA Goddard Space Flight Center in Greenbelt, Maryland, was part of one of the first teams to use the Hubble Space Telescope to view the event. \u201cThe spectra were phenomenal,\u201d she adds, and almost indistinguishable from the theoretical predictions. \u201cYou could clearly see the fingerprints of the metals that had formed.\u201d But Troja and other observers were also puzzled, because they couldn't find any signal in the X-ray and radio regions of the spectrum. These would be expected during the formation of a black hole, which is thought to shoot jets of out of its poles at close to the speed of light. Nine days later, Troja\u2019s team was the first to find the X-rays. Alessandra Corsi, an astronomer at Texas Tech University in Lubbock, and her collaborators kept looking for radio emissions using the Very Large Array in New Mexico. Day after day, the dishes recorded nothing. \u201cIt turned out we had to wait 16 very long days in order to see the first radio glow,\u201d she says. The late onset of the radio and X-ray signals, together with the weakness of the initial \u03b3-rays, suggest that the jets were pointed away from the line of sight to Earth. Gamma-ray bursts that happen to be pointed in the right direction can look very bright even from billions of parsecs away. After a few weeks, most observatories had to stop looking at the object, because that part of the sky had got too close to the Sun. But radio telescopes are still tracking it to this day, Corsi says. More discoveries might yet be made. \u201cThe idea that all this stuff has happened, it\u2019s too much. It is just hard to process,\u201d says Daniel Holz at the University of Chicago in Illinois. \u201cIt\u2019s unreasonable that we have done so much with just one event of its kind.\u201d \u201cAll our hopes and dreams have basically come true,\u201d says Jocelyn Read, an astrophysicist at California State University, Fullerton. \u201cAll this time we have been saying, look at this amazing thing we are going to be able to see. And it is still hard to believe when it actually happens.\u201d Additional reporting by Alexandra Witze. Also see the  related News & Views . \n                     Global networks of small telescopes will chase companion signals of gravitational waves 2017-Oct-13 \n                   \n                     Gravitational wave detection wins physics Nobel 2017-Oct-03 \n                   \n                     European detector spots its first gravitational wave 2017-Sep-27 \n                   \n                     Rumours swell over new kind of gravitational-wave sighting 2017-Aug-24 \n                   \n                     Nature Special: Gravitational waves \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22861", "url": "https://www.nature.com/articles/nature.2017.22861", "year": 2017, "authors": [{"name": "Rachael  Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Ancient-DNA analysis also suggests a surprising connection with sabretooths in North America. Sabre-toothed cats existed in Europe for hundreds of thousands of years longer than previously thought, according to a study 1  that settles a long-running debate among palaeontologists. The authors also found evidence that  Homotherium latidens , a Eurasian sabretooth, and  H   omotherium    serum  from North America are genetically almost indistinguishable. The findings are part of a project that used partial genome reconstructions to examine the evolutionary history of  Homotherium  sabre-toothed cats, which had smaller, more serrated fangs than  Smilodon  \u2014  the sabretooth most people think of, with its long fangs . The latest results, published on 19 October in  Current Biology 1 , upend ideas of how  Homotherium  moved between continents and when it went extinct. When a trawler dredged up an ancient  H. latidens  jawbone while fishing in the North Sea off the Netherlands in 2000, it sparked controversy. Radiocarbon dating showed that the specimen was just 28,000 years old 2 , shocking palaeontologists: the youngest  Homotherium  fossil found in Eurasia up to that point was about 300,000 years old. The analysis of ancient DNA in the latest study confirms the age of the North Sea specimen. The team also constructed partial genomes of two  H.\u00a0serum  fossils from the Yukon Territory in Canada and the North Sea  H.\u00a0latidens  specimen. The two species were so similar genetically that they should probably be combined under the  H.\u00a0latidens  name, says Johanna Paijmans, a palaeogeneticist at the University of Potsdam in Germany and lead author of the study. But combining the species might be a bit premature until researchers find more sabretooth specimens in Europe, says Julie Meachen, a palaeontologist at Des Moines University in Iowa. \n             Mind the gap \n           Until then, researchers can only speculate as to why there\u2019s such a huge gap in the Eurasian sabretooth fossil record and how animals on two different continents could be so genetically similar. Migration between  Homotherium  populations in Eurasia and North America could explain the species\u2019 similarities, Meachen says. It could also explain why sabretooths seem to pop back into existence in the fossil record hundreds of thousands of years after researchers thought they died out in Europe. The North Sea specimen could be evidence that the cats migrated back into Western Europe from Asia or over the Bering land bridge from North America. Or it could be that the Eurasian  H. latidens  population dwindled to such low numbers that the animals just don\u2019t show up in the fossil record, says Paijmans. \u201cThere\u2019s no reason it can\u2019t be both,\u201d says Margaret Lewis, a palaeontologist at Stockton University in Galloway, New Jersey. She adds that the species was probably very mobile, and that carnivores in general are always rarer in the fossil record than prey animals because there aren't as many predators. Some answers certainly lie in the DNA of the older European fossils, says Lewis. But the technology to obtain those answers simply doesn\u2019t exist yet, says Paijmans. As DNA ages, it degrades and becomes harder to extract. Right now, researchers can obtain DNA from the mitochondria \u2014 a cell\u2019s battery pack \u2014 of younger specimens such as the North Sea  Homotherium , but not from older fossils. However, Paijmans remains hopeful that the technology will eventually catch up. \n                   Will we kill off today's animals if we revive extinct ones? 2013-Mar-20 \n                 \n                   How mammoths lost the extinction lottery 2011-Nov-02 \n                 \n                   Sabre-toothed cats were weak in the jaw 2007-Oct-01 \n                 Reprints and Permissions"},
{"file_id": "550312a", "url": "https://www.nature.com/articles/550312a", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Metrologists are poised to change how scientists measure the Universe. Revamped definitions of scientific units are on their way. In the biggest overhaul of the international system of units (SI) since its inception in 1960, a committee is set to redefine four basic units \u2014 the ampere, the kilogram, the kelvin and the mole \u2014 using relationships to fundamental constants, rather than abstract or arbitrary definitions. The International Bureau of Weights and Measures is reviewing the plans at a meeting near Paris from 16 to 20 October. Its recommendations will then go before the General Conference on Weights and Measures, which oversees the SI system, in November 2018. The changes would take effect in May 2019.\u00a0 The kilogram is currently defined as the mass of a chunk of metal in a vault in Paris. And an imaginary experiment involving the force between two infinite wires defines the ampere, the unit of electrical current. The mole, meanwhile, is the amount of substance in a system with as many elementary entities as there are atoms in 0.012 kilograms of carbon-12, while the kelvin relates to the temperature and pressure at which water, ice and water vapour co-exist in equilibrium, known as the triple point of water. In the future, these units will be calculated in relation to constants \u2014 for example, the ampere will be based on the charge of an electron.\u00a0 Redefinition might not affect everyday measurements, but it will enable scientists working at the highest level of precision to do so in multiple ways, at any place or time and on any scale, without losing accuracy. \n               The problem \n             For measurements on conventional scales, existing definitions of SI units suffice. But they are poor tools for modern science at the extremes. And basing units on specific points or materials can be troublesome and inelegant, say metrologists.\u00a0 \n               The techniques \n             Under the revamped SI system, researchers will be able to use various experiments to relate constants to each of the units measured. \n                     The new system of units 2016-Jan-07 \n                   \n                     Kilogram conflict resolved at last 2015-Oct-14 \n                   \n                     Hyper-precise atomic clocks face off to redefine time 2015-Jun-02 \n                   \n                     Gravity rivals join forces to nail down Big G 2014-Oct-08 \n                   \n                     Ampere to get rational redefinition 2014-Jan-14 \n                   \n                     Metrology: The new and improved kelvin 2009-Jun-17 \n                   \n                     International Bureau of Weights and Measures \n                   Reprints and Permissions"},
{"file_id": "550310a", "url": "https://www.nature.com/articles/550310a", "year": 2017, "authors": [{"name": "Nicky Phillips"}], "parsed_as_year": "2006_or_before", "body": "Concern mounts over budget cuts and other changes that undermine basic science. As Japan heads towards a national election on 22 October, scientific leaders worry that the outcome will do little to address long-standing concerns about the country\u2019s deteriorating research landscape. They say that a decline in funding and a shift away from basic research has undermined Japan\u2019s capacity to compete against both established scientific powerhouses and emerging ones such as China. Since 25 September, when Prime Minister Shinzo Abe called for a snap election, science has barely featured in the campaign. Debate has focused on the government\u2019s plan to amend the constitution and increase taxes. The latest polls suggest that Abe\u2019s conservative Liberal Democratic Party could lose some seats, but will retain enough to lead a coalition government.\u00a0 If Abe is re-elected, he says, his government will pursue an innovation agenda. At a meeting of global science leaders in Kyoto on 1 October, Abe reaffirmed his pledge to turn Japan into \u201ca cradle of innovation\u201d by cutting regulations that impede new technologies. Despite Abe\u2019s lofty ambitions, the ruling party coalition has decreased the science and technology budget by more than 5% overall since it came to power in 2012. And the budget for universities has dropped by about 1% a year for a decade. \u201cThis has been pointed out as the major cause of the deterioration of research performance and, eventually, the global rank of Japanese universities,\u201d says Takashi Onishi, president of Toyohashi University of Technology and a former president of the Science Council of Japan, which advises the government. In the past two decades, the country\u2019s share of highly cited papers has stagnated, whereas those of many other leading nations are rising, according to publisher Elsevier\u2019s Scopus database.\u00a0 In an attempt to elevate Japan\u2019s top research universities, the government has introduced reforms that categorize institutions according to their research or teaching focus, and that allocate funding on the basis of performance. The government wants leading research institutions to compete globally for the best students and faculty.\u00a0 Atsushi Sunami, a science-policy specialist at the National Graduate Institute for Policy Studies (GRIPS) in Tokyo, agrees with this aim, butsays thatto succeed, the government will need to increase its research funding. And money alone will not be enough, says Hiroshi Nagano, also a science-policy specialist at GRIPS. For universities to become world class, they need autonomy to decide their research and teaching focus, he says. \u201cThe current policy is oriented in the opposite direction.\u201d \n               Basic research left behind \n             Changes to the university system implemented by Abe\u2019s government are designed to make academia more responsive to the needs of society and industry, in the hope that it will boost low private-sector investment in research. Although scientists broadly encourage this increased collaboration, some say that it has compromised support for basic research. \u201cThe government should focus on the development of basic research to supply seeds or ideas to applied sciences,\u201d says Onishi. Science leaders point to other big concerns about the future of Japanese research. Michinari Hamaguchi, head of the Japan Science and Technology Agency in Tokyo, says that the domestic workforce will be insufficient to keep up with changes in science, technology and innovation, given the country\u2019s rapidly ageing population. He says that policies are urgently needed to encourage more women and foreigners into science and to boost the number of students in doctoral courses, which has dropped by 18% since 2003.\u00a0 Students who pursue research careers are finding it harder to get jobs. Budget cuts have depleted permanent research positions at universities, and fewer younger researchers are securing permanent posts: the number of research associates on short-term contracts more than doubled from 2007 to 2013. Biologist and 2016 Nobel prizewinner Yoshinori Ohsumi has warned that the situation for young researchers will jeopardize the country\u2019s chances of winning future Nobel prizes. Japan has the second-highest number of science laureates in the twenty-first century after the United States \u2014 but, Ohsumi says, that record is unlikely to hold. \n                     Japanese scientists call for boycott of military research 2017-Apr-06 \n                   \n                     What price will science pay for austerity? 2017-Mar-22 \n                   \n                     Japanese universities: Independence days 2002-Oct-31 \n                   \n                     5th Science & Technology Basic Plan \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22875", "url": "https://www.nature.com/articles/nature.2017.22875", "year": 2017, "authors": [{"name": "Michele Catanzaro"}], "parsed_as_year": "2006_or_before", "body": "Ahmadreza Djalali, a researcher in disaster medicine, has 20 days to appeal against his death sentence. A judge in Tehran has ordered the death penalty for Iranian researcher Ahmadreza Djalali, according to his wife and diplomatic sources in Italy. Djalali is affiliated with the Karolinska Institute in Stockholm, Sweden, and the University of Eastern Piedmont in Novara, Italy. A resident of Sweden with his family, Djalali was arrested in April 2016 on an academic visit to Tehran and accused of \u201ccollaboration with a hostile government\u201d. He works on improving hospitals\u2019 emergency responses to armed terrorism and radiological, chemical and biological threats. Djalali was convicted of espionage following a trial led by Abolqasem Salavati, a judge in Iran's revolutionary court, and sentenced to death on 21 October, according to Djalali's wife Vida Mehrannia and to Italian diplomatic sources. They say he has 20 days to appeal against the sentence. Mehrannia says that her husband was accused of obtaining money, academic positions and research projects in exchange for spying on Iran for Israel. \n             Djalali document \n           Shortly before the sentence was announced, a close contact of Djalali's (who would prefer to remain anonymous) circulated a document that claims to be a literal transcription of a handwritten text produced by Djalali inside Evin prison, where he is being held. The document states that Djalali believes he was arrested for refusing to spy for the Iranian intelligence service. According to the document, in 2014 two representatives of the Iranian military and intelligence service asked Djalali to spy on European countries for Iran \u2014 in particular, on \u201ccritical infrastructures, counter-terrorism and CBRNE [chemical, biological, radiological, nuclear and explosives] capabilities, sensitive operational plans, and also research projects, relevant to terrorism and crisis.\u201d It says he refused. The document claims that Djalali was forced to make false confessions following \u201cmultiple psychological and physical tortures\u201d. \u201cI have never acted against my country, I have never spied for Israel or any other country. My only fault is that I did not accept to use the trust of my colleagues and universities in EU to spy for Iran's intelligence services,\u201d the text states. Djalali\u2019s colleagues have reacted with dismay. \u201cNone of our shared research projects had partners in Israel and I am not aware of any money transfer from Israel to Djalali. We relied on European Commission funds,\u201d says Luca Ragazzoni, a health researcher at the University of Eastern Piedmont, who worked with Djalali from 2012 to 2015.\u00a0\u201cWe did not have access to secret data,\u201d he says. Mehrannia says that Djalali is considering a hunger strike in protest at the sentence. Since his imprisonment, Djalali has carried out multiple hunger and thirst strikes. He was also  forced to change his lawyer against his will , according to the Committee of Concerned Scientists, a lobby group. Several scholars and human-rights organizations have  repeatedly called for a fair trial or release  for Djalali. Djalali\u2019s story echoes those of other Iranian scientists. Omid Kokabee,  a physicist released from a Tehran jail in August 2016  after five years' imprisonment, says he believes he was punished for refusing to help a covert nuclear-weapons programme. Hamid Babaei, who was undertaking a PhD in finance in Belgium but is now serving a six-year prison sentence in Iran, has said he was  arrested for refusing to spy on his colleagues . \n                   Iranian scientist to go on trial for espionage 2017-Aug-02 \n                 \n                   Jailed Iranian researcher\u2019s health worsening rapidly 2017-Mar-20 \n                 \n                   Iran releases physicist after five years in jail 2016-Aug-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22867", "url": "https://www.nature.com/articles/nature.2017.22867", "year": 2017, "authors": [{"name": "Emma Young"}], "parsed_as_year": "2006_or_before", "body": "Dogs' facial expressions depend on human attention. Every dog owner is familiar with the \u2018puppy dog eyes\u2019 expression. As the inner brow lifts, the eyes get bigger and bigger \u2026 It\u2019s tempting to interpret this as a plea from a sad dog for a scrap of the family dinner. Now, a small study provides support for the idea that dogs do indeed produce facial expressions to communicate with people \u2014 although perhaps just to engage us, rather than to manipulate us. The dogs in the study produced more than twice as many facial expressions (\u2018puppy dog eyes\u2019 was one of the most common) when a researcher was facing them than when she was turned away. But it didn't seem to matter whether she also held food. Earlier studies have shown that seeing food is more exciting to a dog than is social contact with a silent person, so something other than the dogs\u2019 emotional state must have been responsible for the effect. \u201cDogs make their eyes more attractive to us while we are watching, not just when we are in the vicinity or in response to food,\u201d says Brian Hare, a cognitive neuroscientist and co-director of the Duke Canine Cognition Center at Duke University in Durham, North Carolina. \u201cThis is fantastic work.\u201d The study, published on 19 October in  Scientific Reports 1 , adds to a growing body of work that shows how sensitive dogs are to human attention. It also provides the first evidence in a non-primate species that facial expressions can be used actively to communicate, says psychologist Juliane Kaminski at the Dog Cognition Centre at the University of Portsmouth, UK, who led the research. Researchers had previously assumed that such expressions are an involuntary reflection of an animal\u2019s emotional state. \n             Brow-raising results \n           Kaminksi and her colleagues studied 24 pet dogs of various breeds (including 10 mongrels) and ages (from 1 to 12 years). Each dog was tied with a lead in a quiet room, with a video camera trained on its face. An experimenter, to whom the dog had been introduced, stood a metre away. The person adopted four different positions, in turn: facing the dog and displaying food in her hands; facing it and not displaying food; facing away from the dog and displaying food; and facing away and not displaying food. Throughout, she tried to keep her gaze focused on a spot on the wall, and did not respond to the dog\u2019s behaviours. All the dogs completed two such trials, on separate days. Their facial expressions were analysed by the Dog Cognition Centre\u2019s Bridget Waller, using a system she helped to create, called DogFACS. It is based on the Facial Action Coding System for people, which identifies observable facial changes associated with underlying muscle movements. Although the \u2018inner brow raiser\u2019 expression signifies sadness in people, there\u2019s no evidence that it indicates sadness in dogs, she notes. But humans tend to find it appealing. Kaminski cautions against concluding that dogs use the expression to communicate any specific message, however. \u201cSeeing the food plus seeing the human being attentive does not make the dogs want to look super cute.\u201d It would be interesting to determine whether dogs modulate these expressions based on the identity of the person, says Gregory Berns, a neuroscientist at Emory University in Atlanta, Georgia, who has used brain scans to explore dog behaviour. \u201cMy impression is that dogs frequently attempt to communicate with us humans, but we are not very good at recognizing the signs.\u201d \n                   Dog DNA probed for clues to human psychiatric ills 2016-Jan-26 \n                 \n                   Marmosets prove to be polite conversationalists 2013-Oct-17 \n                 \n                   Stone Age man kept a dog 2002-Nov-22 \n                 \n                   Duke Canine Cognition Center \n                 \n                   Dog Cognition Centre, University of Portsmouth \n                 \n                   Gregory Berns \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22874", "url": "https://www.nature.com/articles/nature.2017.22874", "year": 2017, "authors": [{"name": "Emma Young"}], "parsed_as_year": "2006_or_before", "body": "Getting smaller by absorbing bone tissue may help animals to save energy when food is scarce. Common shrews shrink their heads \u2014 including their skulls \u2014 in winter, researchers have found. They believe that this dramatic example of downsizing may help the animals to survive when food is scarce. Individual wild common shrews ( Sorex araneus ) captured and tagged in Germany showed large reductions in skull size and body mass over the winter. Their spines also got shorter, and major organs, including the heart, lungs and spleen, shrank. Even their brain mass dropped by 20\u201330%, according to Javier L\u00e1zaro, a biologist at the Max Planck Institute for Ornithology in Radolfzell, Germany. In spring, the animals started to regrow. \u201cWe hypothesize that these seasonal changes could have adaptive value,\u201d says L\u00e1zaro, who led the work. Shrews have an extremely fast metabolism, he points out, and reducing their body mass during winter might increase their chances of survival, because they wouldn\u2019t need so much food. In particular, he adds, \u201creducing brain size might save energy, as the brain is energetically so expensive\u201d. \n             Up and down \n           The researchers trapped live shrews, then anaesthetized, X-rayed and weighed them. They also fitted each animal with a microchip, so they could monitor changes in shrews that were recaptured over their roughly 14-month lifespan. Twelve animals were captured during each key life stage: the first summer of their lives, the next winter and the following spring and summer. The results are published in  Current Biology 1  on 23 October. The shrews\u2019 skulls shrank by about 15% from summer to winter, an effect that the X-ray images suggest was caused by resorption of tissue at the joints between skull bones. This bone then regenerated in spring, although the skulls didn\u2019t quite return to their original summer size. \u201cTracking of individual animals is crucial here \u2014 this is really great work,\u201d says zoologist Leszek Rychlik of Adam Mickiewicz University in Pozna\u0144, Poland. Rychlik has previously found 2  that common shrews in northeastern Poland show seasonal changes in body mass on a population level. But L\u00e1zaro\u2019s team is the first to show that the skulls of individual shrews shrink. \n             Cold comfort \n           L\u00e1zaro and his colleagues are now investigating which brain structures change most from season to season, and whether the animals experience any cognitive impairments in winter. If they do, it might not matter too much, says Rychlik. \u201cTheir winter life is more boring,\u201d he says. \u201cThey are less active, less involved in interactions, not busy with reproduction and searching for partners. They are just focused on foraging and saving energy.\u201d Just how many species might shrink their brains for winter is not known. Even at the population level, seasonal comparisons are often not possible, because biologists tend to collect specimens in summer rather than winter. In work being prepared for publication, Rychlik has found seasonal differences in skull size and body mass in two other members of the red-toothed-shrew sub-family: the pygmy shrew ( Sorex minutus ) and the Eurasian water shrew ( Neomys fodiens ). Some of L\u00e1zaro\u2019s co-authors have also found 3  similar differences in two species of weasel. These differences were observed in dead animals, but \u201cwe think they are caused by the same individual shrink\u2013regrow process\u201d, says L\u00e1zaro. He adds that a similar ability might exist in other small, high-metabolism animals that live in seasonal environments and don\u2019t hibernate or use other strategies to save energy. Although still exceptional, he says, \u201cthe phenomenon might be more common than we think\u201d. \n                   Wildlife energy: Survival of the fittest 2014-Sep-10 \n                 \n                   Shrew has a spine of godly strength 2013-Jul-24 \n                 \n                   Study measures mammalian growth spurt 2012-Jan-30 \n                 \n                   Javier L\u00e1zaro \n                 \n                   Leszek Rychlik \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22877", "url": "https://www.nature.com/articles/nature.2017.22877", "year": 2017, "authors": [{"name": "Barbara Casassus"}], "parsed_as_year": "2006_or_before", "body": "Biomedical-research agency accused of attempting to undermine autonomy of university\u2013hospital groups. A group of French scientists is due to meet government officials on 27 October in a bid to resolve a row that has left many of the country\u2019s leading biomedical researchers furious. Scientists were shocked earlier this month when the government unexpectedly postponed a call\u00a0for applications to create a new crop of medical-research clusters just days before the closing date, and said that it would slash the budget earmarked for the project. Government ministers said that they were delaying the project because they wanted to change the way these autonomous clusters are governed. But scientists contacted by  Nature  say they suspect that behind the decision is an effort by INSERM, France\u2019s biomedical-research agency, to exert control over the institutes. The idea of creating the clusters, known as Instituts Hospitalo-Universitaires (IHUs), was introduced in 2009 to boost translational medical research, bringing together universities, teaching hospitals, research agencies and industry. Based on public\u2013private partnerships, they enjoy much autonomy and are mostly free from government and research-agency bureaucracy. The first six IHUs \u2014 in Paris, Bordeaux, Marseilles and Strasbourg \u2014 were approved in 2010 and received total funding of \u20ac850 million (US$1 billion). The clusters have been widely hailed as a successful model, and a second call for applications \u2014 open to any group of institutions that wanted to apply \u2014 was due to close on 12 October. But in a press release on 2 October, the government announced that the deadline for the call would be postponed to an unspecified date. It also said that only two new IHUs would be funded, instead of the three initially planned, and that the total budget would be halved to \u20ac100 million. Nineteen applications had been made. In letters sent to the government last week, and to President Emmanuel Macron on 23 October, 14 applicants said they were \u201cappalled\u201d or \u201cbewildered\u201d by the sudden and drastic changes to the funding and to the terms of the selection process. The health minister and higher-education ministers have invited applicants to discuss the issue this week.  \n             Furious reaction\u00a0 \n           \u201cNone of the changes were discussed with us,\u201d says Richard Frackowiak, who was chair of the international panel that would have assessed the IHU applications, but who resigned from the post on 6 October in protest. \u201cThe IHUs are the biggest French medical-research success of the past 10 years.\u201d The delay \u201cis incomprehensible\u201d, says Jacques Marescaux, a surgeon and chairman of the IHU Institute of Image-Guided Surgery of Strasbourg. The clusters are admired worldwide for their flexibility in being able to raise funds rapidly, and to recruit well-paid, top-flight researchers, says Marescaux. \u201cThe model has already been copied in Taiwan and Brazil.\u201d Despite the clusters' autonomy, INSERM seems to have weighed in on the latest call. In a 9 September letter to the IHU applicants, seen by  Nature , the agency recommends that the candidate clusters alter their proposed structures to a \u2018contract\u2019 or \u2018consortium\u2019 model. This would give the agency a direct say in IHU affairs. The ministers\u2019 desire to change the governance models seems to directly reflect INSERM\u2019s recommendations, which were not solicited, say applicants. INSERM did not respond to a request for comment from  Nature \u2019s news team. The change of strategy suggests that INSERM wants to get its hands on all the clusters, says Didier Raoult, who heads the infectious-diseases IHU in Marseilles. The institutes largely \u2014 or, in some cases, completely \u2014 escape the control of the research agencies, he adds, as do the patents that come out of them. \u201cTo quarrel with leading French and other medical researchers is very bad news for France and its image in the scientific community.\u201d A  joint report by two French inspectorate agencies  \u2014 of social affairs, and of education and research \u2014 was completed before the latest call was opened, and said that the IHUs were \u201cpromising\u201d. The institutes had filed 183 patents and spun out 28 start-up companies. Although the report called for improved IHU governance, including closer researcher involvement, \u201cit said the autonomous foundations should be maintained and strengthened\u201d, notes Philippe Froguel, who is leading an IHU application and is an endocrinology researcher at Lille University Hospital.\u00a0 Froguel is concerned that at the upcoming meeting, applicants will simply be again told what has been already decided. But he hopes that it will provide an opportunity for negotiation and some clarity: \u201cThey will have to give us a new date for the tender and be more precise about the question of governance, which will be positive,\u201d he says. \n                   Climate scientists flock to France\u2019s call 2017-Jul-18 \n                 \n                   Macron consolidates electoral victory 2017-Jun-19 \n                 \n                   Macron presidency is a welcome experiment 2017-May-10 \n                 \n                   Scientists relieved by Emmanuel Macron\u2019s French election victory 2017-May-08 \n                 \n                   French plan to create \u20ac5-billion science \u2018super-campus\u2019 in disarray 2017-May-05 \n                 \n                   French auditors criticize \u20ac5-billion science super-campus near Paris 2017-Feb-08 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22878", "url": "https://www.nature.com/articles/nature.2017.22878", "year": 2017, "authors": [{"name": "Lauren Morello"}], "parsed_as_year": "2006_or_before", "body": "Top White House science job stays empty more than nine months after president took office. Donald Trump has now gone longer without a science adviser in place than any recent first-term US president \u2014 by any measure.On 23 October, Trump  broke the record set by former President George W. Bush . Bush\u2019s science adviser, physicist John Marburger, was confirmed by the Senate on 23 October 2001. That was 276 days after Bush took office, and 120 days after he announced that Marburger was his pick for the job. Trump has also waited longer than any president since at least 1976, when the White House Office of Science and Technology Policy was created, to name his choice for the science-adviser job (see \u2018Help wanted\u2019). Although  rumours have surfaced periodically  about scientists who may be in the president\u2019s sights, the White House has not made any official announcement.By contrast, Trump\u2019s predecessor Barack Obama took the least time of any first-term president since 1976 in naming his science adviser. Obama revealed his choice of  physicist John Holdren  on 20 December 2008 \u2014 just 47 days after he won the presidency, and exactly one month before he was sworn in. (Holdren was confirmed by the US Senate three months later, on 19 March 2009.) \n                   White House\u2019s dwindling science office leaves major research programmes in limbo 2017-Jul-11 \n                 \n                   Trump agenda threatens US legacy of science diplomacy 2017-Jan-27 \n                 \n                   Rumours swirl about Trump's science adviser pick 2017-Jan-20 \n                 \n                   Does it matter if Donald Trump has a science adviser? 2016-Dec-08 \n                 \n                   Obama\u2019s top scientist talks shrinking budgets, Donald Trump, and his biggest regret 2016-Jul-06 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22889", "url": "https://www.nature.com/articles/nature.2017.22889", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Many details of living human brain tissue have been catalogued. Fresh human brain tissue is a vanishingly rare resource for neuroscientists, not least because it is invaluable to its original owner. Yet sometimes patients will surrender a sugar-cube sized chunk of brain when undergoing surgery to remove a tumour or to treat severe epilepsy. On 25 October researchers at the Allen Institute for Brain Science in Seattle, USA, who compile large-scale databases, brain maps and other tools for neuroscience research, announced that they had put their first batch of data from live human brain cells into a publically available database. Most human brain studies use either images of functioning brains obtained by scanning volunteers or slices of dead organs obtained from cadavers. The database created by the Allen Institute uses living brain cells or neurons, which enables researchers to image and analyse the molecular content of individual cells and, ultimately, to identify the biological basis of their behaviour. However until now, the database has only contained information about mouse brains. The publication of human data represents the latest \u2013 and most extensive and systematic \u2013 step in the ongoing efforts to identify the uniqueness of the human brain since such work tentatively began in the 1970s. Neurosurgeons in the Seattle region donated, with the consent of patients, small pieces of brain that they would otherwise have discarded during surgery: bits of the outer layer called the cortex that they needed to snip out in order to access diseased tissue deeper in the brains of their patients. The cortex processes higher-level activities, including the deep introspection and abstract reasoning that is thought to be uniquely human. \u201cFinding out what the detailed differences are between the mouse and human brain will help us understand what makes us unique among species,\u201d says Christof Koch, president and chief scientific officer of the institute. The first slew of human data includes the electrical properties of 300 different types of neuron from 36 patients, along with 3-D reconstructions of the spidery shapes of some of them, and computer models that simulate their electrical behaviour. It also includes profiles of gene expression of 16,000 individual cells from the brains of another three patients. Scientists around the world may now compare these data with mouse data to generate hypotheses about where key differences lie. \u201cThis database is a major service to the scientific community,\u201d says Huib Mansvelder from the University of Amsterdam, an early pioneer of research on fresh human brain cells. He has shown, for example, that human neurons have a lower capacitance than mouse neurons, which makes them quicker to start firing and quicker transfer information. They also have more intricate shapes [1]. \u201cBut the Allen\u2019s industrial approach takes the endeavour to a whole new level,\u201d he says. A sugar-lump size of donated tissue from a patient\u2019s brain is typically the same volume as an entire mouse brain. Cut into slices 300-350 micrometres thick, its cells remain alive and active for at three days, giving scientists ample time to make their measurements. Mouse neurons, by contrast, tend to degenerate within hours. Only a few research centres worldwide work with fresh human brain tissue, partly because until recently not many brain surgeons have wanted to work with them. But rapid developments in biological research tools and have made donation more useful. The Allen Institute now plans to extend the number of human brain cells in its database and will also increase the amount of information from each of them, aiming to include full RNA profiles to indicate which genes are active. A next phase will also analyse the connections between the cells. However the work will necessarily lack the comprehensiveness of the study of mouse brains, because only small pieces of living human brains can be removed, whereas the whole brains of mice can be studied. Many scientists have worried that gaining fresh tissue from diseased brains could be problematic. The apparently healthy tissue comes from a brain with a disease, which provokes concerns that its properties may have been altered by its pathological environment. However Mansvelder has compared cortical tissue from patients with cancer or epilepsy and found them very similar. The Allen Institute has now confirmed these results. There is another advantage to using human cortical tissue. Neurosurgical teams collect vast information about the brain functions of their patients before and after surgery which can, with appropriate anonymization, be correlated with cellular properties. At a meeting of the Federation of European Neuroscience Societies in Pecs, Hungary, held on 20-23 September, Mansvelder presented data showing that IQ correlated with the threshold of firing of cells \u2013 the higher the IQ, the lower the threshold. Mansvelder, along with another pioneer, Gabor Tamas from the University of Szeged, Hungary, and groups from Israel and Sweden, will collaborate with the Allen Institute to develop the human brain database further, thanks to a US$19.4 million international grant from the Bethesda-based National Institutes of Health, announced on 23 October. Reprints and Permissions"},
{"file_id": "nature.2017.22856", "url": "https://www.nature.com/articles/nature.2017.22856", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Researchers seek approval from regulators for this quicker, easier treatment. For the first time, researchers have cured the deadly neurological disease sleeping sickness using pills instead of a combination of intravenous infusions and pills. The investigators presented the results from final clinical trials on 17 October at the European Congress on Tropical Medicine and International Health in Antwerp, Belgium, providing hope that the treatment will help to eliminate the malady within a decade. The oral therapy \u2014 called fexinidazole \u2014 cured 91% of people with severe sleeping sickness, compared with 98% who were treated with the combination therapy. It also cured 99% of people in an early stage of the disease who would typically undergo a spinal tap to determine whether they needed infusions. The relative ease of the treatment with fexinidazole means that if approved, it might save more lives than the current option, say the investigators leading the phase 3 trial, the final phase of testing before the drug goes to regulators for approval. Sleeping sickness is endemic to Africa and generally infects extremely poor people who live in remote regions. The sick often suffer from the disease for years before seeking treatment, causing them and those caring for them to miss work and spend their savings on traditional medicines. Trekking to a hospital and remaining there for intravenous infusions is costly as well. \u201cIt\u2019s not just the person with sleeping sickness, it\u2019s the family that takes care of them during years of this neurological, very serious disease,\u201d says Philippe B\u00fcscher, a sleeping-sickness specialist at the Institute of Tropical Medicine in Antwerp, Belgium, who was not involved in the study. \u201cWhatever money they have, they\u2019ll spend on this instead of anything else.\u201d B\u00fcscher commends the team for conducting a quality clinical trial under extraordinary circumstances in countries hit hardest by the disease, the Democratic Republic of the Congo and the Central African Republic. Investigators had to carry equipment to remote clinics over rugged terrain; one study site was repeatedly robbed; and early on in the trial, some participants fled armed conflict. \u201cI need to congratulate them for beautiful work,\u201d B\u00fcscher says. \n               A better way \n             Sleeping sickness \u2014 also known as human African trypanosomiasis \u2014  is spread through the bite of tsetse flies carrying parasites , most commonly  Trypanosoma brucei gambiense . The organism infects the central nervous system, and patients can experience confusion, daytime sleepiness, night-time insomnia and various psychiatric symptoms, including manic episodes and aggression. If left untreated, they enter a coma and die. For decades, the only treatment was a toxic arsenic-based drug that killed one in 20 patients. In 2009, researchers introduced a safer option: nifurtimox\u2013eflornithine combination therapy, or NECT, which consists of pills and 14 intravenous infusions. For the first time in 50 years, the incidence of sleeping sickness slipped below 10,000 new cases per year; it\u2019s currently around 2,200, according to the World Health Organization. But the need for infusions, along with the spinal tap required to qualify a patient for the treatment, still present obstacles in regions where sterile equipment, electricity and doctors are in short supply. The group that developed NECT \u2014 a non-profit research organization based in Geneva, Switzerland, called the Drugs for Neglected Diseases initiative (DNDi) \u2014 continued searching for a better therapy. In 2007, it discovered fexinidazole, a compound that had been shelved by Paris-based pharmaceutical company Sanofi. With the firm's agreement, the DNDi took the drug through clinical trials. It estimates that developing the therapy through to approval will cost a total of around US$50 million \u2014  a fraction of what pharmaceutical companies  often spend on new drugs. \n               Just the beginning \n             Sanofi will soon submit an application for drug approval through the European Medicines Agency, whose sign-off could pave the way for regulators in the Democratic Republic of the Congo. The drug might get a green light by the end of next year, says Nathalie Strub Wourgraft, the DNDi\u2019s medical director. Because it is a simple oral treatment, she suggests that patients might even be treated at home, which would save them and their families the expense of hospital stays. However, B\u00fcscher argues that home treatments could be dangerous because people who don\u2019t respond to fexinidazole could die of the disease if not seen immediately by medical staff. It\u2019s imperative that patients follow up with health workers, he says, and he suggests offering people incentives to return to the clinic, such as money or staples including salt or sorghum. \u201cThis is a success,\u201d he says, \u201cbut it is not the end.\u201d DNDi researchers and their colleagues are currently working on what they hope will be an even better oral treatment to cure the disease in a single dose, and more reliably than fexinidazole. \n                     Busting the billion-dollar myth: how to slash the cost of drug development 2016-Aug-24 \n                   \n                     Projects set to tackle neglected diseases 2014-Jan-07 \n                   \n                     Neglected diseases fund touted 2010-May-18 \n                   \n                     The Drugs for Neglected Diseases initiative \n                   \n                     Information on Sleeping Sickness \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22870", "url": "https://www.nature.com/articles/nature.2017.22870", "year": 2017, "authors": [{"name": "T. V. Padma"}], "parsed_as_year": "2006_or_before", "body": "The Chandrayaan-2 orbiter, lander and rover will track how lunar dust might scupper settlement. In a large shed near the headquarters of the Indian Space Research Organisation (ISRO) in Bangalore, a six-wheeled rover rumbles over dark grey rubble in a landscape designed to mimic the Moon\u2019s rocky surface. This test and others scheduled for the next few weeks are crucial steps in India\u2019s quest to launch a second mission to the Moon next March. The country\u2019s much anticipated Chandrayaan-2 comes almost a decade after India began its first journey to the Moon, in 2008. \u201cIt is logically an extension of the Chandrayaan-1 mission,\u201d says Mylswamy Annadurai, director of the project at ISRO. The spacecraft comprises an orbiter that will travel around the Moon, a lander that will touch down in a as-yet undecided location near the Moon\u2019s south pole and a rover. India\u2019s maiden Moon trip was a significant achievement for its space programme, but ended prematurely when ISRO lost contact with the orbiter ten months into the planned two-year mission. However, an instrument on a probe that reached the Moon\u2019s surface did gather enough data for scientists to confirm the presence of traces of water. Chandrayaan-2 will attempt more ambitious technical manoeuvres that will put Indian space technology to the test. For the first time, ISRO will attempt to give a craft a controlled, or soft, landing. The agency has had to develop advanced systems that can guide the lander to a touch down and successfully deploy the rover. \n               Lunar conditions \n             Lunar missions are also being planned by China, Japan and other countries, among others. Like these, India\u2019s explorations are partly driven by the need to improve understanding of the Moon\u2019s environment in the event that governments or private entities decide to establish a human settlement there. One poorly understood phenomenon is floating lunar dust. Without an atmosphere like Earth\u2019s, the surface of the Moon is buffeted by solar wind and ultraviolet radiation, creating a layer of charged ions called a plasma sheath in which dust particles can levitate. If humans colonize the Moon, this dust will be a significant challenge, says planetary scientist Penny King of the Australian National University (ANU) in Canberra. It gets into everything, from astronauts\u2019 suits to machinery and equipment, where it causes damage, she says. \u201cUnderstanding how it moves around is pretty critical.\u201d ISRO says the Chandrayaan-2 orbiter and lander will carry a first of its kind instrument, called the Radio Anatomy of Moon Bound Hypersensitive ionosphere and Atmosphere (RAMBHA), to measure the density of the near-surface plasma and how it changes over time. \n               Evolving environment \n             The rest of the spacecraft\u2019s suite of instruments will collect data to help scientists study other aspects of the Moon\u2019s present environment and how it has evolved. Chandrayaan-2\u2019s lander will take the first on-site thermal measurements on the lunar surface near a polar region. The mission \u201cis expected to further consolidate the findings from the first mission and add new ones with  in situ  analysis of the lunar surface and ionosphere,\u201d says Annadurai, who is also director of ISRO\u2019s Satellite Centre in Bangalore. ISRO plans to execute its mission on shoestring budget of just 6.03 billion rupees (US$93 million), including the cost of the rocket and launch. Chandrayaan-2 will be carried into space on one of the agency\u2019s three-stage rockets, a Geosynchronous Satellite Launch Vehicle Mark II, taking off from a spaceport on the island of Sriharikota in the Bay of Bengal. \u201cA nice part of the Indian space programme is that they manage to do things so cheaply,\u201d says ANU astrobiologist Charles Lineweaver. \u201cIf it succeeds, maybe everyone else will see that their mission didn\u2019t really need that extra bell or whistle.\u201d In three to four weeks, ISRO will begin one of the final and most complex testing phases for Chandrayaan-2, integrating all of its components. With one Moon mission under its belt, ISRO is settling into its role as a moon-faring organisation. \u201cMaybe we were extra anxious with the first child, as parents. But we relax a bit as more children come along,\u201d he jokes. Additional reporting by Nicky Phillips. \n                     India launches Mars-bound probe 2013-Nov-05 \n                   \n                     Old rocks drown dry Moon theory 2010-Mar-09 \n                   \n                     Water on the Moon? 2009-Sep-18 \n                   \n                     Moon mission tackles water question 2009-Jun-10 \n                   \n                     India makes history with launch of Moon mission 2008-Oct-29 \n                   \n                     ISRO \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22866", "url": "https://www.nature.com/articles/nature.2017.22866", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Juno probe discovers surprising activity in the giant planet\u2019s interior. Provo, Utah NASA\u2019s Juno spacecraft has plumbed the depths of Jupiter, revealing that the planet\u2019s famous bands of swirling winds extend thousands of kilometres down. The work is the sharpest glimpse yet into Jupiter\u2019s interior. Jupiter\u2019s colourful stripes are atmospheric patterns composed of winds that flow alternately east and west. Until now, researchers haven\u2019t been able to say whether those bands are confined to a shallow layer or reach deeper into the planet. \u201cDetermining this is one of the main goals of the Juno mission,\u201d said team member Yohai Kaspi, a geophysicist at the Weizmann Institute of Science in Rehovot, Israel, on 18 October at the American Astronomical Society\u2019s Division for Planetary Sciences meeting in Provo, Utah. Juno arrived at Jupiter in July 2016 and has been looping around it  once every 53 days . The mission has already revealed several mysterious phenomena,  such as Jupiter's patchy magnetic field  and sets of cyclones that whirl around the planet's north and south poles like dancers around a maypole. By studying Jupiter's gravitational field, researchers can probe thousands of kilometres into the planet. On each close fly-by, Juno measures the planet\u2019s complex gravitational tug. These observations have already revealed that Jupiter has a small, \u2018fuzzy\u2019, poorly defined core 1 . \n               Inner whirl \n             The latest results show that Jupiter\u2019s gravitational field is askew, with different patterns in its northern and southern hemispheres, said Tristan Guillot, a planetary scientist at the Observatory of the C\u00f4te d\u2019Azur in Nice, France. That suggests that its hydrogen-rich gas is flowing asymmetrically deep in the planet. \u201cThis is something that was not expected,\u201d Guillot said at the meeting. \u201cWe were not sure at all whether we would be able to see that.\u201d Another clue to the structure of Jupiter\u2019s interior came from how the gravity field varies with depth. Theoretical studies predict that the bigger the gravity signal, the stronger the flow of gas deep down 2 , 3 . That information is important for teasing out whether all of Jupiter\u2019s interior is rotating as a single solid body, or whether different layers spin separately from one another, like a set of nesting Russian dolls moving within each other. Juno detected a gravity signal powerful enough to indicate that material is flowing as far down as 3,000 kilometres. \u201cWe\u2019re just taking the clouds and the winds and extending them into the interior,\u201d Kaspi said. Future work could help to pinpoint how strong the flow is at various depths, which could resolve whether Jupiter\u2019s interior really resembles Russian dolls. Juno scientists are now looking to see what else the gravity data will tell them, such as how far the famous storm called the Great Red Spot extends into the atmosphere. Another instrument aboard Juno has already hinted that the Great Red Spot\u2019s roots may go hundreds of kilometres down, and it could go even deeper. \u201cIt\u2019s not yet clear that it is so deep it will show up in gravity data,\u201d said David Stevenson, a planetary scientist at the California Institute of Technology in Pasadena. \u201cBut we\u2019re trying.\u201d \n               Polar circles \n             Juno has also been peering into Jupiter\u2019s depths in other ways. One big surprise from the mission was the clusters of cyclones at each pole, seen by Juno\u2019s cameras in visible and infrared wavelengths. Scientists had not spotted the storms before because Juno is the first spacecraft to fly over Jupiter\u2019s polar regions. There are eight cyclones around the north pole and five around the south pole \u2014 all are mysterious, because computer modelling suggests that such small storms would not be stable in swirling polar winds. The answer may lie in a quirky physics concept known as a vortex crystal, said Fachreddin Tabataba-Vakili, a planetary scientist at NASA\u2019s Jet Propulsion Laboratory in Pasadena. Such crystals have been seen in a few Earth-based phenomena such as rotating superfluids; they are born when small vortices form and persist as the material in which they are embedded continues to flow. Something about the flow around Jupiter\u2019s poles may set up the same dynamics, Tabataba-Vakili said. Next up is to work out why there are eight cyclones at one pole and five at the other, he added. Between Jupiter\u2019s polar cyclones and its deep interior flows, Juno continues to tease out new surprises from the Solar System\u2019s biggest planet. \u201cIt\u2019s clear that giant planets have a lot of secrets,\u201d Guillot said. \n                     Jupiter\u2019s secrets revealed by NASA probe 2017-May-25 \n                   \n                     Juno becomes first spacecraft to visit Jupiter in 21 years 2016-Jul-05 \n                   \n                     NASA\u2019s Juno spacecraft prepares to probe Jupiter\u2019s mysteries 2016-Jun-28 \n                   \n                     NASA\u2019s Juno site \n                   Reprints and Permissions"},
{"file_id": "550439a", "url": "https://www.nature.com/articles/550439a", "year": 2017, "authors": [{"name": "Elie Dolgin"}], "parsed_as_year": "2006_or_before", "body": "Precision tools expand the number of \u2018base editors\u2019 available for manipulating DNA and RNA. The toolbox for editing genes expanded this week, as two research groups announced techniques that enable researchers to make targeted alterations to DNA and RNA. Unlike the original CRISPR gene-editing system \u2014 a relatively unpredictable and blunt form of molecular scissors that cut sizeable sections of DNA \u2014 the new systems rewrite individual letters, or genetic bases. The ability to alter single bases means that researchers can now attempt to correct more than half of all human genetic diseases 1 , 2 . The tools, developed by separate teams at the Broad Institute of MIT and Harvard in Cambridge, Massachusetts, are adaptations of the CRISPR system. Whereas most past attempts to use CRISPR-based methods to fix individual bases have been crude affairs \u2014 akin to using a machete to remove a wart \u2014 the new techniques are more like \u201cprecision chemical surgery\u201d, says David Liu, a chemical biologist at the Broad Institute who led one of the studies.\u00a0 Last year, his group reported 3  the  first \u2018base editing\u2019 method  for converting one target DNA letter into another without needing to cleave the genome\u2019s double helix. It has since been used around the world to correct genes in fungi, plants, fish and mice, and even in human embryos harbouring a defective gene that can cause a blood disorder. But that base editor could achieve only two kinds of chemical conversions: a cytosine (C) into a thymine (T) or a guanine (G) into an adenine (A).\u00a0 The new base editor \u2014 described in a paper published on 25 October in  Nature 1  \u2014 works in the other direction, converting T to C or A to G. It can therefore undo the most common types of \u2018point mutation\u2019, which involve single aberrant bases. In human embryonic kidney cells and bone-cancer cells, the technique made the desired corrections with about 50% efficiency and almost no detectable by-products. By comparison, a more conventional CRISPR-based method, in which scientists insert a strand of DNA containing the desired base change, fixed the same single-base differences with less than 5% efficiency and often caused undesired insertions or deletions of large chunks of DNA. \u201cThis is a major breakthrough in the field of genome editing,\u201d says Jin-Soo Kim, a molecular geneticist at Seoul National University. \n               Tricks of the trade \n             Another method, described in a study published on 25 October in  Science 2  and led by Broad Institute bioengineer Feng Zhang, performs a similar conversion, but for RNA instead of DNA. It turns an A into inosine (I), which is read as a G by the cell\u2019s protein-building machinery. This allows for a temporary correction of a disease-causing mutation without permanent alteration to the genome \u2014 a potentially safer option when it comes to gene-fixing therapeutics, although the treatment would need to be administered repeatedly. It would also mean that researchers could alter a treatment as they gain a better understanding of the disease. \u201cIf you use RNA therapy,\u201d Zhang says, \u201cyou can upgrade.\u201d  His team\u2019s RNA editor is based on a naturally occurring enzyme that rearranges the atoms in A to resemble I instead. The researchers fused the enzyme to a disabled version of the CRISPR system \u2014 one involving an RNA-targeted enzyme called Cas13, instead of the usual DNA-binding Cas9. With the help of a sequence-specific guide RNA molecule, they successfully corrected disease-causing mutations 23\u201335% of the time, with low incidences of off-target activity. In the base-editing method pioneered by Liu\u2019s team last year, the researchers engineered a naturally occurring enzyme and tethered it to a dud Cas9, which allowed them to convert C to T. But there is no equivalent enzyme found in nature for the opposite conversion in DNA. So the researchers started with an RNA-editing enzyme similar to the one Zhang\u2019s group used.\u00a0 The team guided the evolution of bacterial cells through seven generations, and used some protein engineering in the lab, to produce an enzyme that would recognize and manipulate DNA. The enzyme was able to rearrange atoms in adenine to change it into an inosine, which the cell reads as a guanine. The system then tricked the cell into inserting a cytosine into the unmodified DNA strand (see \u2018Changing bases\u2019). \n               Gutsy move \n             \u201cIt represents a heroic effort,\u201d says Dana Carroll, a genome-engineering researcher at the University of Utah in Salt Lake City, noting that the directed-evolution approach was something of a shot in the dark. \u201cI wouldn\u2019t have had the guts to try what they did,\u201d Carroll says. \u201cMy hat\u2019s off to David Liu.\u201d The ability to make four types of single-base conversion \u2014 A to G, G to A, C to T and T to C \u2014 \u201cwill be extremely valuable for precise therapeutic and agronomic editing\u201d, says Caixia Gao, a plant geneticist at the Chinese Academy of Sciences\u2019 Institute of Genetics and Developmental Biology in Beijing.\u00a0 It could also  prove useful in drug discovery and for DNA-based data storage , says Marcello Maresca, a gene-editing researcher at AstraZeneca in Gothenburg, Sweden. The development of any other base editors will require enzymes that do not occur in nature, even for conversions in RNA. But that kind of obstacle has not stopped Liu before. \u201cWe\u2019ll keep trying until the community has developed all possible base editors,\u201d he says. \n                     Chinese scientists fix genetic disorder in cloned human embryos 2017-Oct-02 \n                   \n                     Base editing on the rise 2017-May-09 \n                   \n                     Gene-editing hack yields pinpoint precision 2016-Apr-20 \n                   \n                     CRISPR: gene editing is just the beginning 2016-Mar-07 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22786", "url": "https://www.nature.com/articles/nature.2017.22786", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Nature  highlights just a few of the people who played a crucial part in the discovery of gravitational waves \u2014 but didn\u2019t win the Nobel Prize. Every October, the announcements of the Nobel Prizes bring with them some controversy. This year\u2019s physics prize \u2014 in recognition of the Laser Interferometer Gravitational-Wave Observatory (LIGO) in the United States \u2014 was less debated than most. The three winners \u2014 Kip Thorne and Barry Barish, both at the California Institute of Technology (Caltech) in Pasadena, and Rainer Weiss at the Massachusetts Institute of Technology (MIT) in Cambridge \u2014 had attracted near-universal praise for their roles in the project\u2019s success. But the award has still put into stark relief the difficulty of singling out just a few individuals from the large collaborations of today\u2019s 'Big Science'. The LIGO collaboration uses two giant laser interferometers to listen for deformations in space-time caused by some of the Universe\u2019s most cataclysmic events. Physicists detected their first gravitational waves \u2014 interpreted as being produced by the collision of two black holes more than a billion years ago \u2014 in September 2015. The resulting paper, published in February 2016 1 , has a mind-boggling 1,004 authors. Some of those are members of the LIGO Laboratory, the Caltech\u2013MIT consortium that manages LIGO\u2019s two interferometers in Louisiana and Washington State. But the list also includes the larger LIGO Scientific Collaboration: researchers from 18 countries, some of which \u2014 such as Germany and the United Kingdom \u2014 have made crucial contributions to the detectors. Yet more authors are from LIGO\u2019s sister Virgo Collaboration, led by France and Italy, which built the Virgo interferometer near Pisa, Italy. The two experiments pool their data and analyse them together. Countless other people not named on the paper have also been involved in LIGO\u2019s design, development, construction and operation since Weiss first detailed how to build a laser interferometer in 1972. To honour the many unsung heroes of gravitational waves,  Nature  collected testimonials about just a few of them. Like the Nobel Prize, this list is inevitably very incomplete. \n             1. The pioneer: Joseph Weber \n           Researchers using two detectors in the United States shook the world when they announced their discovery of gravitational waves. The year was 1969, and the detectors were not LIGO but tonne-sized cylinders of aluminium built by Joseph Weber, a physicist at the University of Maryland in College Park. His claim was later found to be invalid, but many physicists still credit Weber for having founded the field. \u201cJoe Weber indeed started thinking about how to detect gravitational waves in about 1957,\u201d Virginia Trimble, an astrophysicist and Weber\u2019s widow, told  Nature  in an e-mail. At that time, many researchers were not even sure that gravitational waves existed. In the 1960s, Weber was also one of the first researchers to consider the possibility of using interferometers to detect them. \n             2. The German connection: Heinz Billing \n           The founder of Germany\u2019s side of LIGO, Heinz Billing, a physicist at the Max Planck Institute for Astrophysics near Munich, first heard of Weiss\u2019s pioneering interferometer designs in 1975, when he was asked to review Weiss\u2019s request to the National Science Foundation to fund a prototype at MIT. Billing and his team liked it so much that they started building one themselves. \u201cThe Munich group quickly invented some of the most important ingredients that made the detectors possible,\u201d says Karsten Danzmann, a director at the Max Planck Institute for Gravitational Physics in Hanover, Germany. Billing, in particular, came up with an idea to stabilize the laser that was later used in the UK\u2013German GEO600 interferometer based near Hanover \u2014 and in LIGO itself. GEO600 is still a crucial testing and development centre for technologies introduced in the successive rounds of LIGO upgrades. \u201cThere is an awful lot of GEO in LIGO,\u201d says Danzmann. Billing, who died on 4 January at the age of 102, was also a pioneer in magnetic data storage. \n             3. The laser expert: Alain Brillet \n           The 1980s were years of intense research and development for gravitational-wave detectors. Alain Brillet, an optical physicist with extensive experience in interferometers, then at the University of Paris-Sud in Orsay, France, saw an opportunity to contribute. \u201cI decided to start with the optical part, the lasers and optics, because that was my specialty,\u201d he says. Brillet went on to co-found Virgo. But many of his ideas \u2014 in particular, the type of laser that would give the most stable signal \u2014 were implemented in LIGO and other interferometers as well, says MIT physicist David Shoemaker, who studied with Brillet in Orsay and is now LIGO\u2019s spokesperson. \n             4. The facilitator: Richard Isaacson \n           Gravitational theorist Richard Isaacson went to Washington DC to work at the National Science Foundation (NSF) in 1973 for what he thought would be a brief stint as one of the programme directors. During the handover, his predecessor advised him to pay attention to an \u201cinteresting guy\u201d called Rainer Weiss. Isaacson secured Weiss a small grant for his 1975 prototype, and later became LIGO\u2019s chief advocate inside government. He was instrumental in the project's winning hundreds of millions of dollars in funding, despite the uncertain prospect of success. It was the first time that the NSF had managed a large project: US facilities such as particle accelerators were traditionally the remit of the Department of Energy, which had field offices staffed with dozens of experts. Isaacson did it by himself for more than ten years, and by the early 1990s he had paid a high personal cost. \u201cEventually, my health broke and my marriage went bad,\u201d says Isaacson. By the time he retired in 2001, the construction of LIGO had been completed. \n             5. The first director: Rochus \u2018Robbie\u2019 Vogt \n           Before Barry Barish took the reins of LIGO, another director had left his mark on the collaboration: Rochus Vogt. The Caltech physicist, a veteran of the NASA Voyager mission, was put in charge in 1987. Until then, the project had been led by the \u2018troika\u2019 of visionary founders \u2014 Thorne, Weiss, and the physicist  Ronald Drever , who started UK research on gravitational waves at the University of Glasgow before moving to Caltech \u2014 but managing large organizations was not their strength. \u201cThank God that was done,\u201d Weiss recalled in a talk at NSF headquarters last year. \u201cYou don't manage it with three guys who are sort of a little bit flaky.\u201d Vogt, who was once described as a taller and leaner Henry Kissinger, had a booming voice and forceful style that did not please everyone. But he was able to put together the first major request for NSF funding and, Thorne recalled in a 5 October press conference, \u201claid the foundations for moving LIGO forward to our construction\u201d. \n             6. The theorist: Alessandra Buonanno \n           As Thorne realized early on, in the future field of gravitational-wave astronomy, it would not be enough to collect data; researchers would also need to know what signals to look for. But it is notoriously difficult to extract quantitative predictions from the equations of Einstein\u2019s general relativity. Theoretical physicist Alessandra Buonanno had devised formulae for calculating the approximate orbits of spiralling objects and the gravitational waves they would generate in work she had done, in part with Thibault Damour at the Institute of Advanced Scientific Studies near Paris. The LIGO and Virgo collaborations use a database of hundreds of thousands of these waveforms for spotting gravitational waves in their data in real time. Buonanno is now a director at the Max Planck Institute for Gravitational Physics in Potsdam and a senior member of the LIGO Scientific Collaboration. Additional reporting by Elizabeth Gibney. \n                   Gravitational wave detection wins physics Nobel 2017-Oct-03 \n                 \n                   Ronald Drever (1931\u20132017) 2017-Apr-19 \n                 \n                   The black-hole collision that reshaped physics 2016-Mar-23 \n                 \n                   Young scientists poised to ride the gravitational wave 2016-Feb-16 \n                 \n                   Nature Special: Gravitational waves \n                 \n                   Nature Video: Discovering gravitational waves \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22782", "url": "https://www.nature.com/articles/nature.2017.22782", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Human tumours grafted into mice are heavily influenced by their new environment. An analysis of more than 1,000 mouse models of cancer has challenged their ability to predict patients\u2019 response to therapy. The study, published today in  Nature Genetics 1 , catalogues the genetic changes that occur in human tumours after they have been grafted into mouse hosts. Such models, called patient-derived xenografts (PDXs), are used in basic research and as \u2018 avatars \u2019 for individual patients. Researchers use these avatar mice to test a bevy of chemotherapies against a person's tumour, in the hope of tailoring a treatment plan for the patient's specific cancer. But fresh data from geneticists at the Broad Institute of MIT and Harvard in Cambridge, Massachusetts, suggest that transplanting human cancer cells into a mouse alters the cells' evolution, reshaping the tumour's genome in ways that could affect responses to chemotherapy. \u201cThe assumption is that what grows out in the PDX is reflective of the bulk of the tumour in the patient,\u201d says cancer geneticist Todd Golub, a lead author on the study. \u201cBut there\u2019s quite dramatic resculpting of the tumour genome.\u201d No animal model is perfect, and researchers have long acknowledged that PDXs have their limitations. To avoid an immune assault on the foreign tumour, for example, PDXs are typically grafted into mice that lack a functioning immune system. This compromises scientists' ability to study how the system interacts with the tumour \u2014 an area of increasing interest given the success of  cancer therapies that unleash the immune system . PDXs can also take months to generate, making them too slow to serve as avatars for those patients who need to make immediate decisions about their therapy. \n             Reasonable reproductions \n           But previous research had suggested that the PDXs were reasonably faithful reproductions of the human tumours they are meant to model, offering researchers a chance to explore the tumour\u2019s interaction with its environment in ways that are not possible using cells grown in a Petri dish. Researchers have embraced the approach: the US National Cancer Institute has developed  a library of more than 100 PDXs for distribution to researchers , and European scientists have launched EurOPDX, a consortium that boasts more than 1,500 models for more than 30 tumour types. One company, Champions Oncology of Hackensack, New Jersey, creates and tests mouse avatars for individual patients. For the latest study, Golub and Broad Institute cancer geneticist Rameen Beroukhim, together with their colleagues, decided to examine PDXs how changed over time. The researchers implanted tumour grafts into a mouse, harvested the grafts and then re-implanted them into a fresh mouse \u2014 sometimes for multiple cycles. During this process, the researchers looked for alterations in the number of copies of a given gene in the cell. They did so for more than 1,000 PDX samples representing 24 cancer types, often extrapolating gene copy number from data on gene expression. The analysis suggests that tumours implanted in mice change in ways that are not commonly seen in the human body. For example, human brain tumours called glioblastomas tend to gain extra copies of chromosome 7 over time. But the mouse PDXs tend to lose those extra copies, says Beroukhim. Some of these genetic changes were also associated with differences in how the PDXs responded to cancer drugs. For researchers studying many PDXs and looking for relationships between genetics and drug sensitivity, the finding does not spell disaster, says Golub. \u201cThat\u2019s not to say that PDXs should be abandoned as a model \u2014 far from it,\u201d he says. \u201cBut they\u2019re not a panacea.\u201d Golub is more worried about using PDXs to predict outcomes in individual patients. \u201cIt raises some important questions around how to interpret the results of avatars,\u201d he says. But Champions Oncology co-founder David Sidransky, an oncologist at Johns Hopkins University School of Medicine in Baltimore, Maryland, points to his team's study of 92 PDXs, published in August. That showed an 85% association between the drug responses in a patient and their corresponding PDX 2 . The genetic analysis by Golub and his team did not include clinical data, but could offer important clues as to what goes wrong in the other 15% of PDXs, Sidransky says. The work is important, says David Tuveson, a cancer researcher at Cold Spring Harbor Laboratory in New York. But Tuveson also notes that PDX approaches are changing. Researchers are increasingly likely to graft a human tumour into the analogous location in the mouse avatar \u2014 for instance, by transplanting human pancreatic cancer cells into a mouse pancreas \u2014 rather than merely grafting them under the skin. This, he says, is thought to be more similar to their original environment. Researchers are also turning to mice that have been \u2018humanized\u2019 in various ways, perhaps by introducing aspects of a human immune system or human versions of proteins that interact with the tumour. As for those PDXs that have already been generated, researchers will continue to embrace them says Carlos Caldas, a researcher at the Cancer Research UK Cambridge Institute at the University of Cambridge, UK. Caldas notes that his own studies with breast cancer PDXs have not found such dramatic differences between PDXs and the tumours from which they were made. \u201cWe\u2019re going to continue to see a lot of activity with these models \u2014 they are a great development, not a hindrance,\u201d he says. \u201cThey are here to stay.\u201d \n                   Cancer therapy: an evolved approach 2016-Apr-13 \n                 \n                   US cancer institute to overhaul tumour cell lines 2016-Feb-17 \n                 \n                   Mouse 'avatars' could aid pancreatic cancer therapy 2012-Mar-21 \n                 \n                   Mice guide human drug trial 2012-Mar-19 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22731", "url": "https://www.nature.com/articles/nature.2017.22731", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "State board issues construction permit for project, but legal fight over telescope continues. Hawaii\u2019s board of land and natural resources granted a fresh construction permit to the Thirty Meter Telescope (TMT) on 28 September, reviving the fortunes of the US$1.4-billion observatory \u2014 at least temporarily. The permit moves the international project closer towards restarting construction near the summit of the Hawaiian mountain of Mauna Kea. Some Native Hawaiians oppose the TMT, saying that its construction would further violate a sacred mountain that is already home to multiple telescopes. The board\u2019s decision effectively puts the TMT project back where it was before protestors halted the telescope\u2019s construction in April 2015, just days after it had begun, by blocking the road up Mauna Kea. That December, following months of challenges, Hawaii\u2019s supreme court invalidated the telescope\u2019s first construction permit. The court ruled that the state land board had not followed appropriate procedures because it had approved the first permit, in 2011, before it held a set of public hearings on the case.\u00a0 The board\u2019s latest decision follows a July recommendation to issue the permit from retired judge Riki May Amano, who oversaw more than 40 days of additional hearings earlier this year for the board. Another set of public hearings took place this month, after which the seven-member board voted five to two to issue the permit. \u201cThis was one of the most difficult decisions the board has ever made,\u201d said chairperson Suzanne Case.\u00a0 The new permit adds requirements to construction plans for the telescope, including a zero-discharge wastewater system and cultural and natural-resources training for workers.\u00a0 \u201cWe are greatly encouraged,\u201d said TMT board chair Henry Yang in a statement. \u201cIn moving forward, we will listen respectfully to the community in order to realize the shared vision of Maunakea as a world center for Hawaiian culture, education and science.\u201d Telescope opponents have filed motions that would effectively put the permit on hold until the state supreme court can hear an appeal. \u201cConstruction should not begin before all legal processes have run their course,\u201d said KAHEA: The Hawaiian\u2013Environmental Alliance, a group in Honolulu that opposes the TMT, in a statement. Mauna Kea \u201cis being stripped and disrespected\u201d.\u00a0 But TMT supporters say the telescope would bring educational and employment opportunities to a state with a long history of astronomy. TMT organizers have been exploring the possibility of building the telescope on the island of La Palma, in Spain\u2019s Canary Islands, if they cannot begin construction on Mauna Kea by a self-imposed deadline of April 2018. Project partners include the University of California system, the California Institute of Technology in Pasadena and the governments of India, China, Japan and Canada.  \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     Embattled mega-telescope gets back-up site in Canary Islands 2016-Oct-31 \n                   \n                     Hawaiian court revokes permit for planned mega-telescope 2015-Dec-03 \n                   \n                     The mountain-top battle over the Thirty Meter Telescope 2015-Sep-29 \n                   \n                     Hawaii prunes Mauna Kea telescope hub 2015-Jun-02 \n                   \n                     28 September ruling by Hawaii Board of Land and Natural Resources (PDF) \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22793", "url": "https://www.nature.com/articles/nature.2017.22793", "year": 2017, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Take-down notices \u201cimminent\u201d as lawsuit is filed alleging widespread copyright infringement. Millions of articles might soon disappear from ResearchGate, the world\u2019s largest scholarly social network. Last week, five publishers said they had  formed a coalition  that would start ordering ResearchGate to remove research articles from its site because they breach publishers' copyright. A spokesperson for the group said that up to 7 million papers could be affected, and that a first batch of take-down notices, for around 100,000 articles, would be sent out \u201cimminently\u201d.\u00a0 Meanwhile, coalition members Elsevier and the American Chemical Society have filed a lawsuit to try to prevent copyrighted material appearing on ResearchGate in future. The complaint, which has not been made public, was filed on 6 October in a regional court in Germany. (ResearchGate is based in Berlin). It makes a \u201csymbolic request for damages\u201d but its goal is to change the site\u2019s behaviour, a spokesperson says. ResearchGate may already have begun taking articles down, according to a  10 October statement  by the coalition. The group said it had noticed that the site had removed \"a significant number of copyrighted articles\", although ResearchGate hadn't shared information about this with publishers. \"At this point, not all violations have been addressed and ResearchGate will need to take additional steps to cease unauthorized distribution of research articles,\" the statement says. The clash has been a long time coming. Researchers are increasingly posting paywalled research papers online, many of them on ResearchGate, a network often likened to Facebook for scientists. The site boasts more than 13 million members and has raised more than US$80 million in start-up funding from investors including Microsoft founder Bill Gates and the Wellcome Trust, the London-based biomedical-research funder. Not only do academics upload articles to the site, but ResearchGate also scrapes material online and invites researchers to claim and upload these papers, says James Milne, a spokesperson for the five-publisher group, which calls itself the Coalition for Responsible Sharing. In February this year, information scientist Hamid Jamali at Charles Sturt University in Wagga Wagga, Australia,  reported  that he had examined 500 articles at random from ResearchGate, and found that 40% of them breached copyright 1 . \n             Access issues \n           In September, the International Association of Scientific, Technical, and Medical Publishers, a trade group based in Oxford, UK, sent a letter to ResearchGate suggesting that the network introduce an automated filtering system, through which uploaded articles would be shared publicly or privately depending on their copyright status. Publishers generally say that paywalled articles for which they own copyright can be shared only privately; scientists are allowed to upload preprints, and peer-reviewed but unedited manuscripts, online for general access. \u201cResearchGate refused to engage with us on that,\u201d says Milne. The Coalition for Responsible Sharing, which also includes publishers Wiley, Wolters Kluwer and Brill, says it is \u201cnow left with no other choice\u201d but to issue take-down notices. Litigation has been tried before: in 2013, Elsevier sent 3,000 notices under the US Digital Millennium Copyright Act to scholarly networks including Academia.edu, demanding that they take down papers that breached Elsevier\u2019s copyright. Those notices were passed on to the networks\u2019 academic users. But the new actions would be on a larger scale. \n             Terms and conditions \n           ResearchGate declined to comment on the coalition\u2019s statement, but its terms of service ask users not to store information that infringes copyright. They also state that because the site neither previews nor automatically reviews information that users have stored on it, ResearchGate can\u2019t know about \u2014 and isn\u2019t liable for \u2014 any possible infringements. The site says it will quickly disable access to infringing material after being notified of a problem. But repeatedly sending lots of take-down notices is not a long-term solution, Milne says \u2014 hence the lawsuit, which aims to clarify what responsibility ResearchGate has to prevent copyright breaches. Milne says Elsevier and the American Chemical Society are hoping that the German court will tell the social network that it has a duty to identify copyrighted material on its website, and remove it; that the site must check whether material it scrapes from the Internet is copyrighted before users are invited to \u2018claim\u2019 it and upload it; and that ResearchGate will also be told it cannot modify copyrighted material. \u201cThe expectation is that ResearchGate will be told by the courts to cease certain behaviours. This could take months or years,\u201d says Milne. Not all publishers have stopped discussions with ResearchGate. On 9 October, the company posted a  joint statement  with  Nature \u2019s publisher Springer Nature, saying that the two firms had been in \u201cserious discussions for some time\u201d about sharing journal articles online while protecting intellectual-property rights, and that they were \u201ccautiously optimistic\u201d that a solution could be found. ( Nature \u2019s news and comment team is editorially independent from its publisher.) \n                   Science publishers try new tack to combat unauthorized paper sharing 2017-May-10 \n                 \n                   Online collaboration: Scientists and the social network 2014-Aug-13 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22738", "url": "https://www.nature.com/articles/nature.2017.22738", "year": 2017, "authors": [{"name": "Daniel Cressey"}, {"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Jacques Dubochet, Joachim Frank and Richard Henderson share the prize for developing a technique to image biomolecules. The 2017 Nobel Prize in Chemistry has been awarded for work that helps researchers see what biomolecules look like. Jacques Dubochet, Joachim Frank and Richard Henderson were awarded the prize on 4 October for their work in developing cryo-electron microscopy (cryo-EM), a technique that fires beams of electrons at proteins that have been frozen in solution, to deduce the biomolecules\u2019 structure. For decades, biologists have used X-ray crystallography \u2014 blasting X-rays at crystallized proteins \u2014 to image biomolecular structures. But  labs are now racing to adopt the cryo-EM method , because it can take pictures of proteins that can\u2019t easily be formed into large crystals. The tool has \u201cmoved biochemistry into a new era\u201d, says the Royal Swedish Academy of Sciences, which awards the prize. \n               Imaging solutions \n             In the 1970s, Henderson, a molecular biologist who works at the MRC Laboratory of Molecular Biology in Cambridge, UK, and his colleague Nigel Unwin were trying to determine the shape of a protein called bacteriorhodopsin. The molecule, which uses light energy to move protons across a cell membrane, proved unsuitable for crystallography. So the researchers turned to electron microscopy (see \u2018The rise of cryo-electron microscopy\u2019) and, in 1975, produced their first 3D model of the protein 1 . During the same decade, Frank, a biophysicist who is now based at Columbia University in New York City, and his colleagues developed image-processing software to make sense of the fuzzy pictures that are produced when an electron microscope is aimed at a protein, and to convert these two-dimensional blurs into 3D molecular structures. In the early 1980s, a team led by Dubochet, who is now an honorary professor at the University of Lausanne in Switzerland, worked out how to prevent water-soluble biomolecules from drying out in the vacuum of an electron microscope, allowing the molecules to retain their natural shape during imaging. His team found a way to flash-freeze solutions of proteins using liquid ethane, keeping the molecules relatively still when they were pummelled with electrons. This allowed researchers to use electron microscopes to determine the structures of proteins at much higher resolution than before. These and other improvements enabled Henderson to create the first atomic-resolution images of a protein using cryo-EM in 1990 2 . \n               Resolution revolution \n             Although the research recognized by the Nobel Committee was conducted in the 1970s and 1980s, it laid the groundwork for what many scientists have dubbed a revolution in recent years. Subsequent improvements in the sensitivity of electron microscopes and in software used  to transform their images into 3D structures  have caused many labs to favour the technique over X-ray crystallography. Frank told journalists gathered at the Royal Swedish Academy of Sciences in Stockholm that technological innovations can have a larger impact than discoveries. \u201cCryo-electron microscopy is about to completely transform structural biology,\u201d he said. He added that the ribosome \u2014 the machinery that makes proteins inside cells \u2014 was the \u201ccoolest\u201d molecule he had imaged. Venki Ramakrishnan, a structural biologist at the Laboratory of Molecular Biology who shared the 2009 Nobel Prize in Chemistry for his work to reveal the structure of the ribosome using X-ray crystallography, is one of many converts to cryo-EM. After learning about the award from a  Nature  journalist, he said: \u201cOh, fantastic! Those are exactly the people I thought should win the Nobel prize.\u201d Beno\u00eet Zuber, a structural biologist at the University of Bern in Switzerland, who did his PhD with Dubochet, says his mentor was always confident that cryo-EM would become a vital tool, even as others derided the field as \u201cblobology\u201d for the low-resolution molecular images it captured.\u201cHe had a vision and he was convinced about it, even when everybody was telling him that this was just a dream,\" says Zuber. \u201cIt\u2019s a great recognition for all the developments that have happened in the past. It\u2019s fantastic,\u201d says Sjors Scheres, a cryo-EM specialist who works alongside Henderson. The two were returning from a conference in Leicester, UK, yesterday, when Scheres asked Henderson whether he would keep his phone close in case the Nobel Committee called. \u201cHe said, \u2018I think they should give it to Jacques Dubochet.\u2019 He would never say that he should get one,\u201d Scheres says. \u201cIt\u2019s a well-deserved trio.\u201d\n Additional reporting by Julie Gould. \n                     World\u2019s tiniest machines win chemistry Nobel 2016-Oct-05 \n                   \n                     DNA repair sleuths win chemistry Nobel 2015-Oct-07 \n                   \n                     The revolution will not be crystallized: a new method sweeps through structural biology 2015-Sep-09 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22790", "url": "https://www.nature.com/articles/nature.2017.22790", "year": 2017, "authors": [{"name": "Mark Zastrow"}], "parsed_as_year": "2006_or_before", "body": "Coatings that force ice to grow upwards from the surface could make it easier to remove. When water droplets suspended in the air freeze, they generate snowflakes \u2014 ice crystals with six-fold symmetry. But when ice grows along a solid surface, like frost growing on windows, it can take on an almost infinite range of different shapes. These crystalline patterns are affected by whether a surface repels or absorbs water, says a team led by materials scientists Jianjun Wang of the Chinese Academy of Sciences Institute of Chemistry in Beijing and Xiao Cheng Xeng of the University of Nebraska\u2013Lincoln. The researchers showed that when a surface tends to repel water, ice crystals can be cultivated to grow away from the surface at an angle, resembling a clover with six leaves. The work was published on 9 October in the  Proceedings of the National Academies of Science 1 . \n             Clover crystals \n           Using a high-speed camera attached to a microscope, the team captured imagery of ice forming on aluminium that had been covered with a hydrophobic, or water-repellent, coating. Water drops sprayed on the surface remained taut and spherical instead of spreading out. The researchers triggered ice formation across the entire surface by spraying it with silver iodide nanoparticles, which acted as seeds for ice growth. As the ice developed, the crystals grew outwards and up from the nanoparticle, forming a symmetrical, six-leafed clover with only a single point of contact with the surface. On hydrophilic, or absorbant, surfaces, water spread out quickly, and so did ice \u2014 forming a sunflower-shaped crystal in full contact with the surface. And, when the team prepared a hybrid surface with both hydrophilic and hydrophobic parts, ice spreading on the hydrophilic side came to a halt at the boundary with the hydrophobic side. The researchers also observed that the clover-like ice crystals growing away from a hydrophobic surface could be removed by wind more easily than crystals on a hydrophilic surface.  They suggest that this could be exploited to make surfaces such as car windscreens more resistant to icing by embedding nanoparticles inside them. \u201cThe key is to have these stable ice-nucleation sites,\u201d says Wang. Reprints and Permissions"},
{"file_id": "nature.2017.22816", "url": "https://www.nature.com/articles/nature.2017.22816", "year": 2017, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Plans to cut funding to a programme that recognizes and rewards excellence in research have met with criticism. Academics in South Africa are in uproar after a government research agency announced plans to cut the budget of a prestigious grant programme that rewards the country\u2019s best researchers. The initiative aims to foster academic excellence by awarding grants to individual researchers who volunteer to be rated, with higher-rated academics attracting more money than lower-rated ones. But the National Research Foundation (NRF) said last week that, in an effort to contain costs, it would cut funds to the programme. Some rated researchers will lose up to 90% of their cash. The move is \u201ccatastrophic\u201d, according to  George Ellis , a top-rated mathematician at the University of Cape Town who receives funding from the programme. He said it would \u201cleave many of the best researchers in the country high and dry\u201d. South Africa\u2019s research and higher education system has long struggled with chronic underfunding, exacerbated in recent years by economic and  political turmoil . The budget of the government\u2019s science and technology department, the NRF\u2019s parent body, has increased slightly over the past few years but decreased in real terms owing to rising inflation. And in August 2016, academics wrote an open letter to the government,  warning that the system was on the brink of collapse  because of systemic underfunding. The rating system, introduced in 2008, aims to benchmark South Africa\u2019s researchers against those in the rest of the world and improve the country\u2019s competitiveness. The number of researchers who have been rated has since more than doubled to 3,689. South Africa\u2019s research system is \u201csubject to the availability of resources, and we are being asked to do more with less\u201d, says Gansen Pillay, deputy chief executive of the NRF. \u201cThe question was sustainability into the future. It hasn\u2019t been terminated, but the funding model has been revised.\u201d The system, known as the Incentive Funding for Rated Researchers programme, has five ratings: A (for international leaders in their field), B (for researchers who are internationally acclaimed), C (for established researchers), P (for young researchers, normally aged under 35, who have received prestigious awards and are expected to become international leaders in their subjects), and Y (for emerging young researcher). Ratings were awarded for a period of five years, and came with cash rewards that researchers were free to spend on research of their choice. The NRF\u2019s plans will cut funding across all rating categories, but top-rated researchers will be hit hardest; Y- and C-rated researchers will see comparatively moderate declines. In 2018, newly A-rated researchers will see their funding decline from up to 100,000 South African rands (\u00a35,500) a year over five years to a one-off payment of 50,000 rands in the first year of their rating. Newly Y-rated emerging researchers will receive 100,000 rands from the NRF over two years, instead of 40,000 rands a year over five years. From 2019, only P-rated researchers will get an annual sum of 50,000 rands. Those in other categories will receive a one-off payment of 30,000 rands if they retain their rating. If they are newly rated or improve their rating, they will receive a one-off payment of 50,000 rands. \"When you are an A-rated researcher, which means you\u2019re world renowned, you should be able to access funding from other sources,\u201d says Pillay. However, many of the NRF\u2019s largest grants programmes are available only to experienced researchers, he says. \u201cIt is incentive funding, not a grant. It was just to acknowledge and affirm excellence.\u201d Ellis says that, in practice, many researchers use the incentive funding to supplement their main research grants, to support students or visitors and to travel for conferences. \u201cIn practice, it is a termination of this excellent programme and a huge slap in the face for South Africa\u2019s top level scientific researchers.\u201d \u201cThe incentive grants funding was good: it encouraged researchers to get themselves rated,\u201d says Michael Davies-Coleman, dean of science at the University of the Western Cape. \u201cIt will become increasingly difficult to convince colleagues to apply for rating in the future, despite the important contribution which increasing numbers of rated researchers make to a university\u2019s national research profile.\u201d Cutting incentive cash would also have a major effect on the number of students entering research, he says. An A-rated researcher who spoke on condition of anonymity says that the NRF \u201cwere victims of their own success\u201d because of the growth in the number of rated researchers. \u201cIn an environment where the budgets are being reduced in real terms, they\u2019re desperate to save a bit of money. But from an academic point of view, it\u2019s a bit of a disaster.\u201d \n                   Theft of South African relics riles researchers 2017-Aug-21 \n                 \n                   Violence escalates at South African universities 2016-Oct-24 \n                 \n                   South African academics warn of universities on the brink 2016-Aug-26 \n                 \n                   South Africa\u2019s political turmoil endangers research 2016-Jul-13 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22817", "url": "https://www.nature.com/articles/nature.2017.22817", "year": 2017, "authors": [{"name": "Inga Vesper"}], "parsed_as_year": "2006_or_before", "body": "Post-Brexit plans to relocate the European Medicines Agency could trigger severe staff losses, its head has warned. Drug regulation in Europe could temporarily freeze if the European Medicines Agency (EMA) loses staff during its post-Brexit move from London. Up to 70 per cent of its 900 staff have said they would quit if the agency relocated to some of the cities bidding to host the organisation. According to a battle plan drawn up by agency management, failure to retain enough staff would result in a shutdown of essential operations until more people could be hired. If fewer than 30% of the staff move with the agency to its new destination \u2014 to be decided next month \u2014 it would cease operation, Guido Rasi, the agency\u2019s executive director, told  Nature . The EMA, an agency of the European Union, needs to leave London \u2014 where it has been headquartered since 1995 \u2014 as a result of Brexit. In addition to its permanent staff, the agency hires many other experts on a short-term basis. Following an internal staff survey undertaken in September, the agency urged European heads of state to pick a location to which at least 65% of staff would relocate. \n             Bids for a home \n           Some 19 cities across Europe have applied to host the prestigious organization. Last week, the EMA released its own assessment of the applications, and warned that several locations are entirely unsuitable for the agency\u2019s location. Proposals for Sofia, Malta and Warsaw met almost none of the requirements put forward by the agency and could result in huge staff losses, Rasi warned. Amsterdam was the most popular alternative to London. \u201cThe best case is, of course, a continuum of our activities, with only about 20% staff loss,\u201d he says. \u201cThe worst case scenario we have come up with is 94% staff loss. For our business-continuity plan, we found three levels of activities we can delay, put on hold or stop completely.\u201d According to Rasi, the agency\u2019s core mission \u2014 the regulation and monitoring of innovative drugs across Europe \u2014 would be the last thing to stop. But even with 50% staff loss, the agency would have to reduce advisory support to new research projects, which could stall work on innovative medicines, he says (see ' European Medicines Agency chief raises alarm at forced relocation '). The agency assesses all medicines, including veterinary products, to be sold on the European market, and passes on recommendations to the European Commission for authorization. It evaluates reports of adverse reactions and, if necessary, works with national agencies to ban medicines that are suspected of being dangerous. The EMA also has in-house scientists who provide advice to drug developers on which criteria they need to fulfil to get a product passed. In 2016, the agency recommended 81 new medicines for authorization and answered more than 450 requests for scientific advice. \n             Medication mediation \n           The European Federation of Pharmaceutical Industries and Associations, headquartered in Brussels, has called on member states to put the agency\u2019s well-being first when choosing a location. \u201cThere are many cities that could have the right criteria for the agency to settle,\u201d said a spokesman. \u201cThere is a potential for disruption, but also a potential for harmony. It all depends on what you choose.\u201d In the United Kingdom, pharmaceutical companies worry about how they will get their medicines approved after Brexit. The BioIndustry Association, a group of British life-sciences companies, has backed a UK government proposal to maintain authorizations for medicines granted before Brexit and the continuation of work with the agency during a transition period. \u201cThe alternative \u2014 organizing and delivering a wholesale change \u2014 would be a gargantuan task for companies and regulators across the UK and Europe,\u201d says Steve Bates, the association\u2019s chief executive officer. \u201cIt would be extremely challenging to successfully deliver in the short amount of time left until Brexit in March 2019.\u201d Meanwhile, the uncertainty about the agency\u2019s future is already causing problems. The agency has been unable to fill a position as head of veterinary medicine; all three potential candidates said that they would wait for the final location to be announced before deciding whether or not to take the job, according to Rasi. Europe\u2019s heads of state will meet on 18\u201320 October to begin hammering out an agreement. A decision is due to be announced on 20 November, at the next EU General Affairs Council meeting. Reprints and Permissions"},
{"file_id": "nature.2017.22757", "url": "https://www.nature.com/articles/nature.2017.22757", "year": 2017, "authors": [{"name": "Claudio Angelo"}], "parsed_as_year": "2006_or_before", "body": "If officials don't act soon, research institutions could start shutting down next year. Anxiety is growing in Brazil over the country\u2019s collapsing research budgets. President Michel Temer had  slashed funding for science by 44%  in March and has proposed additional decreases for 2018 \u2014 even as some science institutes run out of money for basic needs, such as paying electricity bills. The 2017 science budget, at 3.2 billion reais (US$1 billion), is the lowest the country has seen in at least 12 years. On 3 October, the government announced that it will release 440 million reais to science agencies to help keep them afloat until the end of this year. But the money is only about 20% of what\u2019s needed, said the Brazilian Society for the Advancement of Science in a statement. Researchers continue to voice their alarm, with a march scheduled for 8 October in S\u00e3o Paulo \u2014 the third such demonstration this year protesting the funding shortfalls. And on 10 October, a public awareness campaign called  Conhecimento Sem Cortes  (Knowledge without cuts) will deliver a petition to Congress with more than 80,000 signatures protesting both the cuts and a  2016 constitutional amendment that put a 20-year cap on federal spending . Last week, 23 Nobel laureates and nine of the country\u2019s scientific societies warned Temer that continued budget reductions will seriously jeopardize Brazil\u2019s future. They say that the ongoing uncertainty over science funding risks dismantling research groups and prompting a brain drain. They all hope to influence a revision of the 2018 budget proposal \u2014 first submitted to Congress by the executive branch in August \u2014 which included a 16% cut to the  Ministry of Science, Technology, Innovations and Communications  (MCTIC). The Temer administration has promised to release a revised budget in the coming weeks. \n               On life support \n             If the 16% cut remains, it would leave a total of about 2.7 billion reais for 22 federal laboratories and research institutes, 73 National Science and Technology Institutes and Brazil\u2019s major science funding agencies, the National Council for Scientific and Technological Development (CNPq) and the Funding Authority for Studies and Projects. \u201cThis means institutions will shut down by August next year\u201d, says physicist Luiz Davidovich, president of the Brazilian Academy of Sciences. Davidovich's estimate is based on what has happened this year. MCTIC started 2017 at 5 billion reais, its smallest budget in a decade when adjusted for inflation. In March, after the 44% cut, the ministry was left with 2.8 billion reais, not including money for special projects such as the Sirius synchrotron. The budget rises to 3.2 billion reais with those projects. As a result, institutions began running out of cash in September. \u201cWe don\u2019t have money for electricity bills or for buying radiopharmaceuticals\u201d, says Jos\u00e9 Augusto Perrotta at the federal Institute of Nuclear and Energy Research. Perrotta is the coordinator of the multi-purpose reactor, a 1.6-billion-reais project that is facing delays because of a lack of funding. This year, the reactor was supposed to receive 106 million reais but got nothing. The Brazilian Center for Physics Research isn\u2019t doing much better. \u201cWe\u2018ll be able to see it through December without layoffs, but next year I\u2019ll have to cancel all equipment maintenance contracts\u201d, says Ronald Shellard, the centre\u2019s director. The institution\u2019s proposed 2018 budget is 7.8 million reais \u2014 well below the 12.7 million reais Shellard says it needs to survive. Brazil\u2019s 1.6-billion-reais Sirius synchrotron is also in jeopardy. The 2018 budget proposal doesn\u2019t provide funding for the facility\u2019s construction, which is slated for completion in mid-2018. The build is still on schedule after science minister Gilberto Kassab unfroze 85 million reais this month, says Antonio Jos\u00e9 Roque da Silva, director of the Brazilian Synchrotron Light Laboratory and head of the project. However, the synchrotron will need an additional 331 million reais to complete construction. \u201cI pay contractors with cash, not with promises,\u201d says Roque. \n               A skeleton crew \n             Also at risk is Brazil\u2019s collaboration with CERN, Europe\u2019s particle-physics laboratory near Geneva in Switzerland. The 2017 budget cuts eliminated Brazil\u2019s financial support for CERN, and the proposed 2018 budget doesn\u2019t resume those payments. The biggest threat, however, is to CNPq, Brazil\u2019s main source of federal research grants. The agency hasn\u2019t paid out the grants it green-lit last year, didn\u2019t launch its annual call for project proposals this year and is 400 million reais short of what it needs to honour its commitments in 2017. If the situation isn\u2019t sorted, Marcelo Morales, a CNPq executive director, fears a repeat of 2016, when scholarships for undergraduates and scientists abroad were suspended. The continuing funding crisis is already driving away students and young scientists. Sergio Ferreira, a neuroscientist at the Federal University of Rio de Janeiro, runs a lab whose budget has gone downhill since 2014. It's now an average of 85,000 reais \u2014 one-tenth of what it used to be. This year, five of Ferreira\u2019s graduate students had to spend six months abroad working with his collaborators because he couldn\u2019t afford the materials the students needed for their research. \u201cIn my group I have several people who have left or are about to leave for good, with no plans to come back\u201d, Ferreira says. \u201cI can\u2019t keep a skeleton colony of students.\u201d \n                     Brazilian scientists reeling as federal funds slashed by nearly half 2017-Apr-03 \n                   \n                     Brazil\u2019s scientists battle to escape 20-year funding freeze 2016-Nov-18 \n                   \n                     Brazil's scientists start street protests against ministry merger 2016-Jun-10 \n                   \n                     Demotion of science ministry angers beleaguered Brazilian researchers 2016-May-12 \n                   \n                     Brazilian science paralysed by economic slump 2015-Sep-30 \n                   Reprints and Permissions"},
{"file_id": "550168a", "url": "https://www.nature.com/articles/550168a", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Ecologists catalogue bird and mammal populations as warming transforms Death Valley. Death Valley, California Jim Patton brushes a packrat\u2019s furry white belly with a vibrant green marker as his wife, Carol, croons over the animal. \u201cWe\u2019re making you beautiful \u2014 punk mice!\u201d\u00a0 Patton, a retired mammologist, is trapping and releasing desert wildlife as part of an ambitious project to repeat surveys conducted by renowned ecologist Joseph Grinnell from 1908 to 1939. Known as the \u2018father of field notes\u2019, Grinnell criss-crossed California in his Ford Model T to catalogue its birds and mammals. His descriptions are so complete that researchers today can compare the density and distribution of animal populations then and now.  Grinnell\u2019s records provide an unparalleled baseline for researchers to explore how urbanization, farming, mining and climate change are reshaping the state\u2019s ecosystems. The Grinnell Resurvey Project, run by the University of California, Berkeley, has sought over the past 14\u00a0years to capture current conditions, with an eye to quantifying future ecological shifts. The latest phase of the work, which began last month, is focused on cataloguing small mammals in California\u2019s rapidly changing deserts. \u201cThe only way to get a sense of what is happening under climate change, and what to expect in the future, is the kind of work going on in the Grinnell research project,\u201d says Josh Tewksbury, a sustainability scientist at Future Earth, an environmental-research group in Boulder, Colorado. \u201cIt\u2019s hard to see how the water boils when you\u2019re in the pot.\u201d\u00a0 When Grinnell began his project in the early twentieth century, he was struck by California\u2019s varied geography, from snowy mountains to blazing deserts to rocky coasts. Anticipating the state\u2019s inevitable transformation as Americans moved west, he documented the distribution of species in about 700 locations. His team deposited more than 100,000 specimens in natural-history museums, including the skull from one of California\u2019s last grizzly bears ( Ursos arctos californicus ), as well as 74,000 pages of field notes and 10,000 images.\u00a0 \u201cThe student of the future will have access to the original record of faunal conditions in California,\u201d Grinnell wrote in 1910, two years after he became the first director of Berkeley\u2019s Museum of Vertebrate Zoology. \u201cThis value will not, however, be realized until the lapse of many years, maybe a century.\u201d\u00a0 In 2003, Grinnell\u2019s academic descendants  set out to retrace his survey of Yosemite National Park . Five years later, they reported that 14 of the 28 mammal species monitored in Yosemite had migrated to higher elevations since Grinnell\u2019s time, averaging a gain of 500 metres (C.\u00a0Moritz  et al. Science   322,  261\u2013264; 2008). The animals\u2019 climb occurred during a period when winters in the park warmed by about 3\u2009\u00b0C. Because Yosemite has been a protected area since 1864, the researchers concluded that land-use changes were not a major factor in the species\u2019 shifts. Steve Beissinger, a conservation biologist at Berkeley and the project\u2019s leader, says that recent surveys have yielded less-coherent results. \u201cAs we look more broadly across sites in California, we find that responses are much more complicated,\u201d he says. \u201cSome species [are] moving to lower elevations in areas that have become rainier, and in some places we see stasis.\u201d\u00a0 But a growing number of studies suggest a dim future for desert dwellers in the coming decades, as they face warmer, drier conditions. Temperatures in Death Valley in July were the hottest for any month anywhere in the world in 2017, averaging 41.9 \u00b0C.\u00a0 Many biologists think that desert organisms are living at the limits of survival \u2014 and that cooler regions may be out of reach for slow-moving or short-lived species. Preliminary results from the Grinnell Resurvey Project corroborate this idea. Of the 135 bird species surveyed in the Mojave Desert, only the common raven ( Corvus corax ) has significantly expanded its range since the early twentieth century, Beissinger says. The ranges of 38 other species have contracted. \n               A changing landscape\u00a0 \n             Yet on a cool morning in the Lee Flat area of Death Valley, most of the 160 box traps set out by Patton contain small, furry animals. Within 24 hours, he and Carol mark 90 squirrels, mice and rats belonging to nine species \u2014 one more than Grinnell listed in the same area in 1917. Patton rejects the idea that climate change will soon drive many desert mammals to extinction. Like Grinnell, he is awed by the animals\u2019 ability to adapt to extreme conditions. Kangaroo rats ( Dipodomys  sp.) extract water from seeds, and lose little of it because their kidneys concentrate urine to a crystal-like consistency. The rodents\u2019 oily coats also prevent water loss through sweat.\u00a0 Still, Patton sees signs of change. He has not yet captured a bushy-tailed woodrat ( Neotoma cinerea ), prominent in Grinnell\u2019s Death Valley accounts. But Patton hesitates to speculate on the species\u2019 absence, because reliable data on its distribution come only from Grinnell\u2019s time and now. The rat\u2019s numbers might have dwindled before desert warming intensified in the 1970s. Others on the resurvey project are exploring how hotter, drier conditions might harm birds and mammals, by studying species\u2019 metabolisms and how much water they lose through evaporation. Ecological modellers can combine these findings with the latest population data to better project how the desert ecosystem might fare as the planet warms. Ideally, scientists would revisit these forecasts in a few decades using fresh data. But fieldwork of this sort is falling out of favour. Staring at the blue mountains on the horizon, Patton says that he doesn\u2019t know who will replace him: very few students today train as naturalists, and museums and national parks are chronically underfunded. \u201cEveryone wants to know how nature is changing and why,\u201d he says. \u201cBut there\u2019s almost nobody doing this kind of work.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @amymaxmen \n               \n                     Biology: The love of pit vipers 2013-Oct-23 \n                   \n                     Forest fires: Burn out 2012-Sep-19 \n                   \n                     Zoologists prime traps for California wildlife survey 2003-Aug-28 \n                   \n                     Grinnell Resurvey Project \n                   Reprints and Permissions"},
{"file_id": "550169a", "url": "https://www.nature.com/articles/550169a", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Project obtains tissues from recently deceased individuals to look for the origins of disease. Sharon Napper was getting ready for school one morning five years ago, when her four-year-old daughter said, \u201cDaddy fell off the bed.\u201d Her husband, Ronald, a retired US Marine who worked as a police officer on an army base, was lying on the floor. He had suffered an aneurysm that spread to the temporal artery in his head. At the hospital, the only way to relieve the swelling would have been to open Ronald\u2019s skull, leaving him unable to eat or breathe on his own. \u201cThere was a quality-of-life issue. We had discussed this, and so I let everything kind of take its course,\u201d says Napper, who had been planning Ronald\u2019s 50th birthday party the evening before.\u00a0 The couple had previously discussed Ronald\u2019s desire to be an organ donor, but another request followed: would Napper also donate his tissues for research after he died? Ronald\u2019s myriad tissues, and those of almost 1,000 other anonymous deceased donors, are now the basis of a first-of-its-kind database. Supported by the US National Institutes of Health, the US$150-million Genotype-Tissue Expression (GTEx) project is amassing data about gene sequences and activity, and other information, across 44 types of tissue, from blood vessels to 10 different brain regions.\u00a0 \u201cIt\u2019s creating a \u2018Google Maps\u2019 of the body,\u201d says Kristin Ardlie, a geneticist at the Broad Institute of MIT and Harvard in Cambridge, Massachusetts, who is part of the project\u2019s data-analysis team. It routinely releases new data, which are freely available to qualified researchers. And in this week\u2019s  Nature , GTEx is publishing its latest and biggest analysis, based on tissue from 449 donors 1 , 2 , 3 , 4 . In assembling so much information from such a large number of deceased donors, the project has raised some thorny ethical issues concerning informed consent and scientists\u2019 moral obligations to families who donate the tissues of their loved ones for nothing in return. The study aims to plug a gap in the search for the genetic origins of disease. Scientists have identified thousands of DNA variants linked to different conditions, but most lie in stretches of the genome that are devoid of protein-coding genes and are, instead, likely to alter the activity of other genes. By relating genes active in different tissues to variations in donors\u2019 genomes, researchers hope that GTEx can join the dots between non-coding variants and gene expression. When the project was proposed in 2008, many researchers were sceptical that it could succeed, says Manolis Dermitzakis, a human geneticist at the University of Geneva Medical School in Switzerland and an early proponent of GTEx. That is because RNA molecules (a readout of gene activity) start to decompose after a person dies, and no one had ever attempted to measure gene expression in so many different tissues across so many people. The challenge of amassing that much human tissue wasn\u2019t merely technical. Soon after learning of the deaths of their loved ones, the relatives of GTEx donors, such as Sharon Napper, were asked to donate dozens of tissue samples and to consent to the genome, medical history and other data of their loved ones being made widely available to researchers, albeit with most identifying details removed. \u201cThey are being asked to donate to this strange project about which they have never heard anything like it before,\u201d says Laura Siminoff, a bioethicist at Temple University in Philadelphia, Pennsylvania, who led a project on GTEx that involved re-contacting donor families to see how they felt about the entire process. Her team found that the stress of suddenly losing a family member had fogged people\u2019s memories of what they had consented to. Most recalled that they had agreed to donate their relatives\u2019 tissue for research, but often didn\u2019t recall much else. Reporter Shamini Bundell learns about the grieving families contributing to a huge genetics project. Siminoff suggests that some form of genetic counselling should be made part of the informed-consent pro\u00adcess for tissue-donation projects such as GTEx. She also thinks that the project missed an opportunity by seeking tissue donations only from organ donors, because African Americans, Latinos and other ethnic-minority groups are less likely to register. Larry Gavan donated his older brother Mark\u2019s tissues to GTEx in August 2014, he says, even though he and his family weren\u2019t entirely clear how they would be used. Mark, who died of cardiac arrest following a stroke, was born with type 1 diabetes and had lost most of his sight. Gavan says his family saw the donation of Mark\u2019s tissues as \u201can opportunity to make a contribution to future people\u2019s lives and be directly related to the diseases my brother suffered from.\u201d Napper, who along with other donor families was part of a GTEx community advisory group, emphasized that altruism motivated her decision to donate her husband\u2019s tissues. But Siminoff\u2019s research has found 5  that most donor families, including Napper\u2019s, want to know the results of tests, such as genome sequencing, conducted on the remains of their loved ones. The study was not designed to return such findings. But Nicole Lockhart, a programme director at the National Human Genome Research Institute in Bethesda, Maryland, who coordinated the ethical, legal and social aspects of GTEx, says that future tissue-donation studies might consider providing families with medically important results. \u201cA standing policy of simply \u2018we will not return results\u2019 is becoming less and less common,\u201d says Susan Wolf, a lawyer and bioethicist at the University of Minnesota in Minneapolis. Studies such as GTEx should plan to enable families to be identified if researchers discover, for instance, a mutation that dramatically increases the risk of cancer for relatives who inherit it, she says. GTEx and other tissue-donation studies are likely to offer enormous benefits to scientists and companies (which can also apply for free access to the data), says Siminoff. \u201cWe should also think about what we can do for people who are generous and make these kinds of donations that benefit everybody.\u201d Napper, who works as a nurse in cancer and chemotherapy, accepts that her late husband\u2019s tissues are now a code in the GTEx database. But, still, she checks the study\u2019s website to keep track of new research (191 studies are listed on the project website, and several more appear today in  Nature  and other journals). She sees his participation as an important legacy for their family, which includes six sons, two daughters and nine grandchildren. In June, she and other GTEx donor families attended the project\u2019s annual meeting in Rockville, Maryland. She met some of the scientists involved, who told her about the research they were doing on tissues such as those from her husband. \u201cTo know he\u2019s still there is a wonderful thing,\u201d she says.\n \n                 Tweet \n                 Follow @NatureNews \n                 Follow @ewencallaway \n               \n                     A more personal view of human-gene regulation 2017-Oct-11 \n                   \n                     Human genomics: Cracking the regulatory code 2017-Oct-11 \n                   \n                     New concerns raised over value of genome-wide disease studies 2017-Jun-15 \n                   \n                     Geneticists should offer data to participants 2016-Nov-01 \n                   \n                     Genomics is failing on diversity 2016-Oct-12 \n                   \n                     Genomics is failing on diversity 2016-Oct-12 \n                   \n                     Biospecimen policy: Family matters 2013-Aug-07 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22780", "url": "https://www.nature.com/articles/nature.2017.22780", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Tribal leaders are developing a policy for genetic research and data sharing, potentially ending a 15-year moratorium. When the Navajo Nation opens its first oncology centre next year in Tuba City, Arizona, clinicians there may be able to offer a service that has been banned on tribal lands for 15 years: analyzing the DNA of Navajo tribe members to guide treatments and study the genetic roots of disease. That's because the Navajo, the second-largest Native American group in the United States, are considering whether to lift their longstanding moratorium on genetic research. The tribal government banned DNA studies in 2002 to prevent the misuse of its members' genetic material. Although there is still some apprehension about the risk of allowing researchers access to Navajo DNA, the tribe's leaders increasingly see genetic research as a tool to improve medical care for the 174,000 residents of their sprawling reservation, which is roughly the size of Scotland.\u00a0 As it now stands, Navajo people who live on the reservation must drive hundreds of kilometres to access specialized medical care off tribal lands, in large cities such as Phoenix, Arizona. \u201cWe spend millions of dollars outsourcing [care] for cancer and diabetes,\u201d says Walter Phelps, a delegate to the Navajo Nation Council. As the tribe \u2014 a nation independent of the United States \u2014 tries to expand the health services it offers to its members, he says, \u201cthe moratorium could become a barrier when blood and tissue have to be collected\u201d. Phelps is working on the effort to create a policy by which the Navajo Nation would approve genetic-research projects and maintain control of DNA samples. The research-ethics board run by the tribal government\u2019s department of health is working with tribal officials and traditional leaders and holding a series of public hearings to solicit opinions on the matter from tribe members. The group hopes to deliver a draft proposal by the end of October. Whatever the tribe decides could influence the hundreds of other Native American groups, who have tended to be wary of genetic studies because of a history of scientists conducting research without consent or adequate privacy controls. The Navajo Nation's new oncology centre provides part of the impetus for revisiting the genetic-research ban. It will be the first such facility on Native American lands outside of Alaska. Allowing some genetic testing at the centre could help physicians to identify the most effective therapies for each patient, says Lynette Bonar, chief executive of the Tuba City Regional Health Care Corporation in Arizona, which will run the facility. That would match the standard of care that many Navajo people with cancer have received at medical facilities off the reservation. And creating a repository for such genetic material on Navajo land would enable research into the genetic and environmental factors underlying a broad range of diseases, not just cancer. So far, Phelps says, the idea of allowing some genetic research has not drawn major opposition. Many tribe members consulted about lifting the moratorium have generally supported the idea after learning how physicians could use genetic data to diagnose disease and tailor treatments. And the number of Navajo tribe members who are geneticists and medical experts has grown since 2002, bolstering the tribe\u2019s ability to evaluate proposed protocols and represent its own interests. \n               Fraught history \n             Still, some Navajo have lingering questions about whether the tribal government can protect the privacy of their genetic material and maintain control over its use. Such concerns helped to shape the current ban back in the early 2000s, when the Navajo Nation\u2019s department of health conducted an outreach campaign about genetics and medical research. \u201cIn the absence of a research code and lack of expertise at the time, they decided it was not a good time to move forward with genetic research until they were able to develop a research policy,\u201d says Nanibaa\u2019 Garrison, a member of the Navajo Nation who is a geneticist and bioethicist at Seattle Children\u2019s Hospital in Washington. The tribe had reason to be cautious. \u201cAs Native Americans, we have a problem with trust because we have been violated so much,\u201d says David Begay, a pharmaceutical scientist at the University of New Mexico in Albuquerque and a member of the Navajo Nation\u2019s human-research review board. \u201cIn the past, our data have been misused.\" Native Americans in the southwestern United States want to avoid repeating the experience of the region's Havasupai tribe. In 2004, the group sued Arizona State University in Tempe over alleged misuse of tribe members\u2019 blood samples. The Havasupai said that the samples, which had been collected for diabetes research, had later been used in studies of schizophrenia, migration and inbreeding  without their consent .  The university made a settlement with the tribe in 2010 , paying US$700,000 and returning the blood samples. Sara Hull, a bioethicist at the US National Human Genome Research Institute in Bethesda, Maryland, says the case helped to change how researchers engage with the people they study, by raising awareness of the complexities of dealing with vulnerable minority populations. For Native Americans, such thorny issues can include privacy. Science-funding agencies and journals often require researchers to put the genetic data they collect into public repositories, but the relatively small size of many Native American tribes can make it easy to identify individual members in a genetic data base. In recognition of this, the US National Institutes of Health sometimes works with researchers it funds to develop methods for sharing data on a minority group without compromising its privacy. Garrison, who is helping the Navajo Nation develop its new policy, says that the plan is likely to include rules on what types of research will be allowed, who will have access to tribe members\u2019 genetic material and information, and who will provide oversight. It is also likely to require that the tribe maintain ownership of its members\u2019 DNA samples and data. The policy that the Navajo Nation ultimately produces could serve as a template for other Native American groups considering how \u2014 or whether \u2014 to engage with genetic research, says Ellen Clayton, a bioethicist at Vanderbilt University in Nashville, Tennessee. She expects other tribes to watch the development of the Navajo Nation\u2019s new policy. \u201cIf they reach an agreement, I think it will be influential.\u201d \n                     North America\u2019s oldest mummy returned to US tribe after genome sequencing 2016-Dec-07 \n                   \n                     Lessons from the Ancient One 2016-May-04 \n                   \n                     Genomics: Bioethics on stage 2015-Aug-19 \n                   \n                     Ancient American genome rekindles legal row 2015-Jun-18 \n                   \n                     Ancient genome stirs ethics debate 2014-Feb-12 \n                   \n                     Informed consent: A broken contract 2012-Jun-20 \n                   \n                     Blogpost: Native American research lawsuit settled \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22820", "url": "https://www.nature.com/articles/nature.2017.22820", "year": 2017, "authors": [{"name": "Jo Marchant"}], "parsed_as_year": "2006_or_before", "body": "Evolutionary differences blamed for squeezing out female researchers. Male scientists are more likely to share their published work than are women \u2014 but only with other men, a study of hundreds of researchers has found.  Humans are generally considered to be a highly cooperative species, says Jorg Massen, a cognitive biologist at the University of Vienna. But most of the evidence for that assumption comes from artificial situations such as computerized cooperation tasks. \u201cI wanted to test human prosociality in an everyday situation,\u201d he says. So he chose one of the most competitive situations he could think of: his own field of research psychology. To investigate cooperation among psychologists, Massen turned his fellow researchers into guinea pigs. He and his colleagues e-mailed nearly 300 researchers and asked them to share either a PDF of one of their latest papers, or some raw data (pretending that they wanted to include it in a meta-analysis). The results were published in  Scientific Reports  on 10 October 1 . In general, the scientists contacted were highly cooperative, with almost 80% willing to share a PDF and almost 60% willing to send raw data. \u201cI was surprised,\u201d says Massen. \u201cHumans are prosocial even in this competitive field.\u201d Even more unexpected, however, was a strong gender difference in how the scientists responded to the request for help. Massen and his colleagues had wondered whether men might respond more favourably to women, or vice versa. In fact, men were more likely to share, but only with other men. A male\u2013male request was 15% more likely to be granted than any other gender combination. \n             Evolution at work?  \n           Massen and his colleagues say that one possible explanation for their results \u201cmay be that among male academics there is a network at play, in which they favor each other much like 'Old Boy' networks\u201d. They also suggest that this imbalance might have evolutionary roots and point to an idea called the male-warrior hypothesis, which states that men have evolved to form strong bonds with other males in their group because in the past this enabled them to defend territory from hostile attackers. \u201cMen are more ready to cooperate with genetic-stranger males to form these fighting coalitions,\u201d says Mark van Vugt, an evolutionary psychologist at the Free University of Amsterdam who first suggested the theory in 2007 2 . Some of the evidence for this idea comes from lab-based tasks such as public-goods games (in which volunteers choose how many tokens to keep or share), but there are some real-world hints too, he says. Boys tend to play in larger groups than girls, van Vugt says, and in sports such as tennis and boxing, men make more effort to bond with their opponent after a match or fight than women do. However cultural factors are also thought to be at work. Massen\u2019s results \u201csit very well\u201d with these previous findings, says van Vugt, who suggests that such gender differences might affect professional situations beyond psychology research. Any roles that involve teaming up with strangers \u2014 such as business, politics, law and economics \u2014 could end up favouring men, he predicts. \u201cMen are always on the lookout to find coalition partners,\u201d he says, whereas women tend to be more cautious about cooperating with strangers. \u201cThat\u2019s an obstacle to building up the same networks that men have.\u201d Many factors, including cultural ones, contribute to gender bias at work. \u201cIt is very clear that in science and many other professions, women are discriminated against,\u201d says Massen. \u201cSomething needs to change.\u201d But he suggests that an increased awareness of differences in cooperation might encourage both men and women \u2014 in science and other fields \u2014 to look at their own behaviour and consider how they might respond differently. \u201cI hope people read it and think about it,\u201d he says. \n                   To reduce gender biases, acknowledge them 2017-Aug-22 \n                 \n                   Gender bias distorts peer review across fields 2017-Mar-21 \n                 \n                   Patchy progress on fixing global gender disparities in science 2017-Mar-08 \n                 \n                   Jorg Massen \n                 \n                   Mark van Vugt \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22311", "url": "https://www.nature.com/articles/nature.2017.22311", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Barry Myers would bring private weather-forecasting experience to the National Oceanic and Atmospheric Administration. Barry Myers, the chief executive of weather-forecasting firm AccuWeather, is US President Donald Trump\u2019s pick to head the National Oceanic and Atmospheric Administration (NOAA), the White House said on 11 October. Myers, an attorney by training, has led AccuWeather \u2014 based in State College, Pennsylvania \u2014 since 2007. This experience could prove useful if the US Senate confirms Myers as NOAA\u2019s chief, given that the agency includes the US National Weather Service. But some scientists worry that Myers\u2019s ties to AccuWeather could present conflicts of interest, and note that Myers has no direct experience with the agency\u2019s broader research portfolio, which includes the climate, oceans and fisheries. \u201cI think the science community has real cause for concern,\u201d says Andrew Rosenberg, head of the Center for Science and Democracy at the Union of Concerned Scientists in Cambridge, Massachusetts. Rosenberg notes that Myers was an early proponent of carving out a larger role for the  private sector in providing weather services . And in 2005, while Myers served as executive vice-president and general counsel, AccuWeather lobbied for legislation to prevent the National Weather Service from competing with private firms in providing products including basic weather forecasting. \u201cIs he going to recuse himself from decisions which might potentially be of interest to his company down the road?\u201d asks Rosenberg. \n             A different perspective \n           Myers will probably advance efforts to bring commercial weather data into the national weather-forecasting system, says Bill Gail, chief technology officer for the Global Weather Corporation in Boulder, Colorado. Still, Gail says, Myers respects the importance of the public sector in such activities. \u201cI\u2019ve got a lot of respect for him, and I think he could do a pretty good job,\u201d adds Gail, the co-chair of a decadal survey of US Earth-science satellites being conducted by the National Academies of Sciences, Engineering, and Medicine. The chief executive's views on climate change are a little harder to parse, because Myers hasn\u2019t taken any strong public positions on global warming. But in a position statement on the Accuweather website, the company says there is \u201clittle doubt\u201d that\u00a0human activities influence the planet\u2019s climate. \u201cAt the same time, our knowledge of the extent, progress, mechanisms and results of global climate change is still incomplete,\u201d the statement says. The company says it encourages its scientists to express their own views, and it publishes a blog featuring posts about climate research. If Myers ascends to NOAA\u2019s top job, he will lead an agency facing an uncertain financial future.  Trump has proposed slashing NOAA\u2019s budget by 17% in fiscal year 2018 , compared to the 2017 level of US$5.7 billion. Although Congress has so far rebuffed Trump\u2019s attempts to cut funding for several key science agencies, funding for the 2018 budget year \u2014 which began on 1 October \u2014 is still up the air. The government is currently running on a stopgap spending bill that will expire on 8\u00a0December, prompting another round of budget negotiations. Ultimately, Myers will need to build a solid team to handle the full NOAA portfolio, says Antonio Busalacchi, president of the University Corporation for Atmospheric Research in Boulder. \u201cHe\u2019s going to face a lot of challenges, but the bottom line is that Barry does bring a lot of relevant experience to the table.\u201d Whoever ends up leading the agency will have help. On 5 October, the Senate confirmed oceanographer Timothy Gallaudet as assistant secretary of commerce for oceans and atmosphere, the number-two position at NOAA. Gallaudet, a 32-year veteran of the US Navy, has experience ranging from weather and ocean forecasting to developing policies to counter illegal fishing and assessing the national-security implications of global warming, according to the White House. \n                   US lawmakers\u2019 science spending plans ignore Trump cuts 2017-Jun-28 \n                 \n                   Trump budget would slash science programmes across government 2017-May-23 \n                 \n                   Race to provide commercial weather data heats up 2017-Feb-01 \n                 \n                   Tracking the Trump transition, agency by agency 2016-Nov-30 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22828", "url": "https://www.nature.com/articles/nature.2017.22828", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Seeing cosmic events is one thing, but what if you could hear them and taste them, too? A cottage industry of small observatories is springing up around the globe to take advantage of astronomers' new ability to capture the gravitational waves from major cosmic events. These new facilities will enable researchers to match up those gravitational waves with electromagnetic signals and perhaps one day even particles of matter from some of the cataclysms that send measurable ripples through space-time. The main goal is to look for flares of light originating from the same spot as any gravitational waves detected by the US-based Advanced Laser Interferometer Gravitational-Wave Observatory (LIGO), or the Virgo observatory near Pisa, Italy. These smaller telescopes, often built on a shoestring budget, will serve as first-line responders, filling the gap between gravitational-wave detectors and the major facilities of conventional astronomy. \u201cOnce you know where to look, you can swing the whole world\u2019s telescopes at it,\u201d says Danny Steeghs, an astronomer at the University of Warwick, UK. Moving quickly is key. It\u2019s tricky to pinpoint the source of gravitational waves \u2014 astronomers can typically narrow it down to a region of the Universe that could contain thousands of galaxies \u2014 and observatories may have only a few days before any promising flares of light dissipate. \u201cYou need to look at a lot of sky,\u201d says Steeghs, \u201cand you don\u2019t have a lot of time for it.\u201d \n             Robots of the sky \n           Steeghs leads a small UK\u2013Australian collaboration that built the Gravitational wave Optical Transient Observer (GOTO) in La Palma, Spain. It is an array of four small robotic telescopes that will eventually grow to 8 telescopes, and perhaps 16. So far, it has cost just \u00a3800,000 (around US$1 million). Alan Watson and William Lee of the National Autonomous University of Mexico (UNAM) in Mexico City and his collaborators spent even less. They built the Deca-Degree Optical Transient Imager (DDOTI), currently consisting of a pair of robotic telescopes at Sierra San Pedro Martir, Mexico, for a mere US$350,000, largely by using off-the-shelf components, he says. They plan eventually to have six telescopes, perhaps followed by more facilities in France and Australia. Some of the facilities, including GOTO, are being designed and built specifically to follow up on gravitational-wave signals. Most of these will be robotic, using machine-learning algorithms to alert each other to point at particular regions of sky and search for interesting flares without the need for human intervention. Other projects have grown out of existing collaborations that are familiar with looking for visible-light counterparts to the \u03b3-ray bursts spotted by space observatories, or tracking other transient phenomena, such as supernovae explosions or asteroids that are potentially Earth-bound. And some venerable telescopes, including one of those once used by Edwin Hubble in Palomar, California, have been retrofitted. The 1.2-metre telescope is now part of GROWTH (Global Relay of Observatories Watching Transients Happen), a network of 17 facilities around the globe that can track an object seamlessly as the Earth spins. \u201cThe idea is, basically, to beat sunrise,\u201d says Mansi Kasliwal, an astronomer at the California Institute of Technology in Pasadena, who leads GROWTH. Astrophysicist Paul Groot of Radboud University in Nijmegen, the Netherlands, whose group is part of the Virgo collaboration itself, is leading a Dutch-funded project called BlackGEM. It will initially consist of three telescopes in La Silla, Chile, costing about \u20ac6 million (US$7.1 million), that will continuously map the southern sky to build up a database of archived images. If news of a gravitational-wave detection arrives, BlackGEM will scan the relevant patch of sky within hours, and automatically compare that to its archived images to search for anything new. \n             Neutrino chasers \n           Similar efforts are already following up on detections of notable particles from space, such as unusually energetic neutrinos or cosmic rays. The Astrophysical Multimessenger Observatory Network (AMON), started in 2016, got its first interesting hint on 22 September, when it responded to a high-energy neutrino detected by IceCube, the world\u2019s largest neutrino observatory, at the South Pole. When AMON researchers looked towards the source of the neutrino, they saw that a known quasar \u2014 an entity consisting of heated matter orbiting a supermassive black hole at the centre of a distant galaxy \u2014 was flaring up. This is the type of heightened activity that theorists think could produce an excess of neutrinos, but so far, no high-energy neutrinos have been traced conclusively back to their sources. In the future, researchers hope that they might detect all three types of emission together: electromagnetic radiation, gravitational waves and particles of matter. Some compare that to seeing, hearing and tasting an astrophysical event at once. \n                   European detector spots its first gravitational wave 2017-Sep-27 \n                 \n                   Gravitational waves: 6 cosmic questions they can tackle 2016-Feb-09 \n                 \n                   Global observatory sees first light 2012-Apr-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22830", "url": "https://www.nature.com/articles/nature.2017.22830", "year": 2017, "authors": [{"name": "Allie Wilkinson"}], "parsed_as_year": "2006_or_before", "body": "Practices such as poaching and illegal logging are concentrated near inhabited areas and along rivers, study finds. Despite Brazil\u2019s efforts to safeguard the Amazon rainforest by establishing protected areas and boosting law enforcement,  illegal use of the region\u2019s natural resources  is still widespread, according to a study 1  published on 10 October in  PeerJ . The researchers looked at 4,243 law-enforcement records from between 2010 and 2015, across 118 federally protected areas of the Brazilian Amazon. Although the overall number of citations decreased over those five years, illegal activities still occurred in nearly every protected area. The analysis highlighted the need for improved monitoring and enforcement, says study co-author \u00c9rico Kauano, a conservation biologist at the Chico Mendes Institute for Biodiversity Conservation (ICMBio), the Brazilian agency responsible for the management of the federal protected areas. Kauano and his colleagues grouped illegal activities into ten categories, and found that 37% of the infractions fell into the \u201csuppression and degradation of vegetation\u201d group, which included deforestation, logging of endangered tree species and the unauthorized use of fire. Illegal fishing was the next most common citation at 27%, followed by hunting at 18%. Most of the illegal activity occured in more accessible and densely populated areas. Roads have a major role in opening up the tropics to colonization and exploitation 2 . Deforestation of the Brazilian Amazon increased after the construction of the Bel\u00e9m\u2013Bras\u00edlia Highway in the 1960s, and continued with the opening of the Trans-Amazonian Highway in 1970s. A 2014 study 2  using satellite images found that around 95% of the deforestation in Brazil\u2019s Amazon occurred within 5.5 kilometres of a road and within 1 kilometre of a navigable river. \n             Caught in the act \n           The availability and use of government data are what sets this study apart from others, says Emilio Bruna, a tropical ecologist at the University of Florida in Gainesville, who was not involved in the study. Past studies, including a paper 3  published last month in  Biotropica  (where Bruna is editor-in-chief), struggled to obtain even the most basic information, such as how many staff members were employed by the agency that manages protected areas, and how much they were paid, Bruna says. Data from efforts on the ground are important because, although  remote-sensing instruments such as satellites can detect deforestation, for example,  they fail to identify threats present beneath the forest canopy.\u00a0Law-enforcement records, when available, can complement remote-sensing data sets, the study authors say. \u201cYou can actually tell what it is they\u2019re writing infractions for, and that\u2019s valuable,\u201d says Bruna. But he points out that, without knowing where law-enforcement efforts are being allocated, it\u2019s only a partial picture. \u201cIt could be that the reason certain protected areas have the most infractions is because those are the places that are under the greatest threat,\u201d he says. \u201cOr it could be because that\u2019s where the greatest enforcement is being focused.\u201d \n             Greater enforcement \n           \u201cWe are still far from having adequate staff in the protected areas,\u201d Kauano says. In 2014,  a local news outlet  reported that the Brazilian Institute of Environment and Renewable Natural Resources had only 47 agents to monitor environmental crimes in Amazonas, the country\u2019s largest state in the Amazon region, which covers an area of about 1.6 million square kilometres. Hiring more enforcement officials looks unlikely in the short term, however, owing to Brazil\u2019s ongoing political and economic crisis, says Kauano. \u201cWhat ICMBio seeks to do to overcome this is to prioritize some regions with greater problems.\u201d Bruna cautions against jumping to conclusions from the study\u2019s results, however. \u201cNot all infractions are created equal,\u201d he says. It\u2019s important to differentiate between a resident fishing out of season and a fishing charter operator. Bruna worries that some may look at this study and think that the people living near protected areas are the problem. But they aren\u2019t the only ones breaking the law, he says. And the demand for the fruits of this illegal labour comes from all over the world. Local people can, in fact, be part of the solution. There is some evidence that people living in or near protected areas are helping with conservation, says Kauano. But he adds that the government needs to make a greater effort to work with local communities. \n                   Deforestation spikes in Brazilian Amazon 2016-Nov-30 \n                 \n                   Political upheaval threatens Brazil\u2019s environmental protections 2016-Nov-08 \n                 \n                   Brazil unveils tool to track emissions 2012-Aug-29 \n                 \n                   Nature special: The changing Amazon \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22734", "url": "https://www.nature.com/articles/nature.2017.22734", "year": 2017, "authors": [{"name": "Christie Wilcox"}], "parsed_as_year": "2006_or_before", "body": "Young amphibians are the first animals thought to use toxins against rivals of their own species. Many tadpoles ward off predators with potent poisons \u2014 but those toxins also seem to help win battles with their own kind, a new study finds. Tadpoles of common toads ( Bufo bufo ) are more poisonous when raised in crowded conditions, which may give them a competitive edge, according to the work published on 23\u00a0September in  Functional Ecology 1 . Many noxious plant species are known to modulate their defences to fend off different threats 2 , but it is less clear whether animals possess similar toxin-tuning abilities. Although predation pressure is known to induce tadpole chemical defences 3 , the new findings are the first unequivocal evidence of toxin synthesis spurred by competition in vertebrate animals. Being poisonous can make a species essentially inedible to predators, but making potent toxins comes at a metabolic cost \u2014 so it\u2019s best to make that investment count. \u201cIt would be very profitable for such animals to kill two birds with one stone by using their anti-predatory toxins as chemical weapons against their competitors, too,\u201d says the study\u2019s lead author, Veronika B\u00f3kony, an ecologist with the Hungarian Academy of Sciences in Budapest. Common toads are equipped with bufadienolides, potent toxins that cause harm by accelerating and disrupting the heart\u2019s rhythms 4 . Field studies have found that common toad toxicity varies geographically, with the intensity of competition being the most reliable predictor 5 . But it has been unclear whether such patterns occur because populations are genetically isolated from one another in different ponds, or whether they reflect defences induced by environmental factors. B\u00f3kony and her colleagues took this question to the laboratory, rearing toads in artificial ponds with varying numbers of individuals \u2014 a proxy for the strength of competition. The species composition of the ponds also varied; some contained common toads, others contained agile frogs ( Rana dalmatina ) and some contained a mix. Agile frogs hatch earlier and grow to larger sizes than common toads, so they were considered to represent tougher competition. Because the frogs are non-toxic, the researchers wanted to see whether the toads\u2019 toxins are especially aimed at these intense rivals (a phenomenon called allelopathy). \n             Toxic relationships \n           The more competitors the toads were raised with \u2014 of either species \u2014 the smaller and more toxic they were, echoing the field results. But surprisingly, toad tadpoles defended themselves against their own kind more fiercely, by producing more toxins than they did against the frogs. Meanwhile, the frogs didn\u2019t seem to be bothered by their toxic tankmates. The study is \u201cvery well designed\u201d, says Thomas Hossie, an ecologist at Trent University in Peterborough, Canada. The plasticity of other tadpole traits, including morphology and behaviour, is well documented, he notes, but most studies examine the response to predation risk. \u201cThis paper is another great example of how amazingly plastic larval amphibian traits really are.\u201d Gary Bucciarelli, an ecologist at the University of California, Los Angeles, also praises the work: \u201cI think the researchers present a very compelling study that questions the evolution and ecological role of amphibian chemical defences.\u201d His own research has shown that newts become more toxic in response to stressful conditions 6 . Such findings \u201creally begin to scrutinize the idea that predation alone drives variation in animal chemical defences\u201d, he adds. Toxicity that varies by the density of an organism\u2019s population has also been observed in insects 7 , notes Hossie: \u201cThis experiment indicates that it may be more widespread than we anticipated.\u201d B\u00f3kony and her colleagues aren\u2019t done with the toads yet, as the unexpected lack of harm to the competitor frogs \u201cbegs the question what exactly [the toads] are defending themselves from\u201d. Cannibalism is certainly a possibility, as tadpoles of many species are known to turn on their own when times are tough. But B\u00f3kony wonders whether the toxins might serve a different function altogether. She hypothesizes they may \u201cprovide a sort of immune defence against contagious diseases they could catch from [fellow tadpoles], especially when crowded\u201d. She and her colleagues hope to explore this possibility next. \n                   Population biology: Cane toads wage chemical war 2015-Sep-02 \n                 \n                   Ecology: Toxins for cane-toad control 2012-Jul-25 \n                 \n                   Predator learning favours mimicry of a less-toxic model in poison frogs 2006-Mar-09 \n                 \n                   How did the grasshopper get his stripes? 1999-Jan-28 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22657", "url": "https://www.nature.com/articles/nature.2017.22657", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Message in a bottle sums up state of research in 2017. On an Arctic island, researchers have buried a stainless-steel tube stuffed with artefacts that they say sum up science and technology in 2017. The capsule, buried on 17 September, could remain in the ground for more than half a million years before it resurfaces as a result of geological uplift, sea-level rise and erosion. Placed five metres deep in an out-of-use borehole near the Polish Polar Station in Hornsund, Svalbard, the 60-centimetre-long tube holds smaller containers with samples that include a fragment of a 4.5-billion-year-old meteorite, basaltic lava from an Icelandic volcano eruption and Namibian sand hiding particles of kimberlite and diamonds \u2014 all geared at informing a future discoverer of our present understanding of Earth\u2019s geology.\u00a0 To summarize biology, it includes dried DNA samples from humans, rats, salmon and potato, a bee in resin, seeds and around 300 tardigrades, the minuscule aquatic \u2018water bears\u2019 that can survive extreme radiation, drought and heat. And to communicate to future historians the state of today\u2019s technology, scientists packed into the tube silicon-based electronic devices, including accelerometers, a radiation detector and a mobile phone. They added a credit card, a wristwatch and a photograph, etched into porcelain for longevity, of Earth taken from space. Researchers also left their fingerprints on the inside of some of the container caps. \n             Polar anniversary \n           The message in a bottle was created to celebrate the sixtieth anniversary of Poland\u2019s polar station, which was set up during the International Geophysical Year 1957-58, a research project that included a series of global geophysical activities.  \u201cI wanted to create a memorial for the ages,\u201d says Marek Lewandowski, a permafrost specialist with the Polish Academy of Sciences Institute of Geophysics in Warsaw, who selected the objects for the time capsule. Lewandowski, who thought up the idea in May, says that he consulted dozens of experts at Polish and foreign research institutes about the capsule\u2019s inventory. The capsule is described in a manuscript published in the journal  Gondwana Research 1  on 28 September. It\u2019s a bit of a balancing act between jocular and serious science,\u201d Lewandowski says. \u201cBut I do think it\u2019s a good way to capture what we know today about the natural history of our planet and the evolution of life on it.\u201d The objects are nicely, if quirkily, chosen, says Jan Zalasiewicz, a geologist at the University of Leicester, UK. \u201cThey have put together a thoughtful and ingenious message for the far future,\u201d he says, \u201cBut the few things in the capsule will be a drop in the ocean among the huge diversity of \u2018techno-fossils\u2019 that humans will leave behind as geology.\u201d Zalasiewicz adds that he thinks the capsule might resurface well before the half-a-million year estimate, because the chosen burial place is just a few metres above sea level, and marine erosion from sea-level changes are difficult to predict. It\u2019s not the first time that humans have designed a time capsule for distant civilizations to unwrap and decode. The Voyager Golden Record \u2014 phonograph records (together with a cartridge and a needle) on board the two Voyager spacecrafts launched in 1977 \u2014 contains 115 images, musical selections, natural soundscapes and spoken greetings to any extraterrestrials that might pick up the messages. But chances are slim that Voyager\u2019s snapshot of twentieth-century human culture, selected by a NASA committee, will ever be delivered and understood, says Lewandowski. \u201cOur own time capsule is sure to be found one distant day, and its discoverers will be able to grasp the message,\u201d he says. \u201cIf they look carefully inside \u2014 like we did into the Cheops pyramid and the tombs and artefacts inside it \u2014 they will understand who we were.\u201d \n                   Anthropocene: The human age 2015-Mar-11 \n                 \n                   Voyager 1 has reached interstellar space 2013-Sep-12 \n                 \n                   International Polar Year: In from the Cold 2009-Feb-25 \n                 \n                   Geology of Svalbard \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22653", "url": "https://www.nature.com/articles/nature.2017.22653", "year": 2017, "authors": [{"name": "Allie Wilkinson"}], "parsed_as_year": "2006_or_before", "body": "Attempts to stop the spread of bird flu and protect wildlife had unintended consequences. Small, emerald-coloured birds called monk parakeets ( Myiopsitta monachus ) invaded Mexico in the span of a decade because of trade policies thousands of kilometres away in Europe, according to a study released this month. The research highlights how fears over avian flu, which prompted a ban on bird imports in Europe, had wide ranging effects in other countries. Monk parakeets, a type of parrot native to South America, popped up in countries such as the United States in the 1960s and have established themselves from Brooklyn to Brussels. There were only a handful of reported sightings of the bird in Mexico City in 2005. But by 2015, feral monk parakeets were documented in 97 cities throughout the country, say researchers in a study 1  published on 19 September in  PLoS ONE . Monk parakeets are considered agricultural pests, and their enormous communal nests can cause blackouts when built on electrical equipment 2 . But they are popular as pets, and so have been part of the international parrot trade. \u201cIt\u2019s been a really, really fast invasion,\u201d says Elizabeth Hobson, a behavioural ecologist at the Santa Fe Institute in New Mexico and lead author on the study, both in terms of the geographic scope and the shifts in the trade policies that contributed to it. Usually, it\u2019s hard to work out when a non-native species first appeared in an area, says Hobson. But the arrival of monk parakeets in Mexico has a sharply defined start and end point, thanks to shipping documentation and bird sightings recorded by citizen scientists using apps such as iNaturalist and eBird, Hobson says. \n             Unintended consequences \n           She and her colleagues contend that two pieces of legislation shifted the global demand for monk parakeets from Europe to Mexico. In 2004, concerns about the spread of avian influenza in Europe led to an import ban on birds from southeast Asia. By 2007, the European Union had banned the importation of all wild-caught birds, regardless of their origin. As EU demand for monk parakeets crashed, the international market for the birds shifted to Mexico, where regulatory changes in 2008 had made it illegal to purchase native Mexican parrots as pets, in an effort to preserve wild population numbers. The monk parakeet was one of the few options left for people who wanted to lawfully purchase a parrot. More than half a million monk parakeets were imported into Mexico as part of the pet trade between 2000 and 2015. Hobson and her colleagues used international trade data to determine that 90% of those birds entered Mexico starting in 2008 and ending in 2014, mostly from Uruguay. The increase in wild monk-parakeet sightings throughout Mexico roughly coincided with the changes in regulations and commercial imports. \u201cThis whole invasion seems like it was just a fascinating series of unforeseen consequences of regulation changes,\u201d says Hobson. It\u2019s important to think about how policy changes can both protect human populations and have unexpected negative results \u2014 such as the introduction of an invasive species, she says. \n             Setting a baseline \n           Mexico stopped its commercial imports of monk parakeets in 2014 over concerns about the possible spread of avian influenza. The country declared the monk parakeet an invasive species in late 2016, and is required by law to devise a species management plan. This doesn\u2019t necessarily mean the invasion is over, Hobson says, because there are a lot of monk parakeets in Mexico that can escape their owners and reproduce in the wild. It\u2019s also still unclear what effect the animals are having on the country\u2019s native wildlife, urban infrastructure and local economy. The study\u2019s findings punctuate the importance of banning the international trade in parrots, as well as the need for evaluating the unintended consequences of legislative and management action, says Michael Russello, an evolutionary biologist at the University of British Columbia in Kelowna, Canada. The baseline data provided by the study \u201cwill be invaluable for tracking the spread and potential establishment of self-sustaining monk-parakeet populations in Mexico moving forward, and monitoring the performance of any management action\u201d, Russello says. \n                   Behind New Zealand\u2019s wild plan to purge all pests 2017-Jan-11 \n                 \n                   Europe's bird-flu outbreaks pose little risk to humans 2014-Nov-18 \n                 \n                   Invasive species: The 18-km2 rat trap 2013-May-15 \n                 \n                   Parrots speak in tongues 2004-Sep-06 \n                 \n                   Parrots and Plunder \u2014 are monk parakeets pests? \n                 \n                   Global Invasive Species Database \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22692", "url": "https://www.nature.com/articles/nature.2017.22692", "year": 2017, "authors": [{"name": "Gabriel Popkin"}], "parsed_as_year": "2006_or_before", "body": "Combination of satellite images and on-the-ground data enables more complete tracking of forest carbon flows. Every moment, the world\u2019s roughly 3 trillion trees either suck up carbon dioxide from the air or release it into the atmosphere. Accurately quantifying these carbon flows is a long-standing challenge that has hindered scientists\u2019 understanding of how forests help to regulate Earth\u2019s climate. Now, researchers have combined ground and satellite measurements to conclude that tropical forests seem to be a net source of heat-trapping carbon emissions, rather than a carbon sink. The team\u2019s paper, published on 28 September in  Science 1 , bolsters a growing consensus: that tropical forests are drying out or being cleared, burned and logged so fast that they now spew out a lot more carbon than they squirrel away.\u00a0 Whereas earlier estimates based on measurements of atmospheric carbon flows suggested that tropical forests might be carbon neutral or even a net sink, more-recent studies \u2014 including ones based on data from NASA\u2019s Orbiting Carbon Observatory-2 satellite \u2014 agree broadly with this recent paper, says David Schimel, an ecologist at NASA\u2019s Jet Propulsion Laboratory (JPL) in Pasadena, California. He suspects that human activities such as starting fires and natural factors including droughts have dealt a severe blow to forests\u2019 ability to store carbon. \n             Tracking carbon \n           The study authors estimate that the world\u2019s tropical forests release approximately 425 million tonnes of carbon annually, equivalent to roughly 5% of the globe\u2019s annual fossil-fuel emissions, and about five times more than an estimate in a highly cited 2011 paper 2  that relied on ground-based forest inventories. Their work captures nuances in how droughts and other natural or human-caused disturbances could affect the amount of carbon that tropical forests exchange with the atmosphere. The research team first travelled to forests throughout the tropics to measure tree diameters and heights. The scientists then fed those measurements into species-specific equations to estimate how much carbon the trees stored. Next, they used those estimates to ground-truth data collected by NASA\u2019s Ice, Cloud, and Land Elevation Satellite (ICESat), a laser-equipped satellite that from 2003 to 2010 gathered data on forest height and vegetation layers around the globe. Finally, the researchers used a machine-learning algorithm to translate measurements from the Moderate-Resolution Imaging Spectrometer (MODIS) instruments \u2014 part of NASA\u2019s Terra and Aqua satellites that image Earth\u2019s entire surface every one to two days \u2014 into data they could compare to the ICESat numbers. By extrapolating this comparison to MODIS images for the entire tropics, the team tracked how much carbon tropical forests gained and lost between 2003 and 2014. The scientists quantified losses due to deforestation, degradation \u2014 including logging, firewood gathering and other human activities \u2014 and natural disturbances such as droughts. Because degradation and natural disturbances often leave forest canopies mostly intact, most previous satellite studies have failed to account for their impact on carbon emissions, says Alessandro Baccini, a remote-sensing scientist at the Woods Hole Research Center in Falmouth, Massachusetts, who led the work. Yet the researchers calculated that these processes accounted for more than two-thirds of forests\u2019 carbon emissions. \u201cWe were surprised how much of the emissions were a result of degradation,\u201d he says. \n             On the map \n           The study also tracks carbon captured by growing forests, which had been missing in previous analyses of satellite data, says Nancy Harris, a carbon scientist at the World Resources Institute in Washington DC. \u201cThis paper really helps to put carbon gains on the map.\u201d In doing so, it moves scientists closer to being able to monitor countries\u2019 progress toward forest-protection goals set under the 2015 Paris climate agreement, which requires accurate tracking of both carbon losses and carbon gains due to forest growth, she says.\u00a0 Carbon estimates from satellite imagery should be viewed with caution, however, says Matthew Hansen, a geographer at the University of Maryland in College Park who produces satellite-based maps of changes in tree cover. MODIS and other optical sensors can be compromised by atmospheric interference, he says. And Hansen is concerned that the Woods Hole team reports large carbon losses in areas where forests have not disappeared, such as northern Brazil. \u201cGeographically, there are some places that look suspect\u201d in the team\u2019s analysis, he says. Moreover, MODIS cannot easily detect how much older forests are growing, potentially causing Baccini\u2019s team to underestimate the carbon that these areas absorb, says Sassan Saatchi, a remote-sensing scientist at JPL. That could change when NASA\u2019s Global Ecosystem Dynamics Investigation instrument launches to the International Space Station in 2018, Saatchi says. The instrument will measure forest height and vegetation layers using lasers that will capture far more data than those of ICESat, and should provide a more direct way to estimate tropical-forest carbon. \n                   Forests not equal when it comes to climate 2016-Feb-04 \n                 \n                   Global count reaches 3 trillion trees 2015-Sep-02 \n                 \n                   The hunt for the world\u2019s missing carbon 2015-Jun-30 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22693", "url": "https://www.nature.com/articles/nature.2017.22693", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Geologists track hundreds of quakes caused by people and the projects that set them off. From mining projects to oil and gas operations, human activity has set off earthquakes around the world and in many geological settings. Research now highlights how big these quakes can get \u2014 and how little scientists agree on which ones are caused by people. The  Human-Induced Earthquake Database , or HiQuake, contains 728 examples of earthquakes (or sequences of earthquakes) that may have been set off by humans over the past 149 years. Most of them were small, between magnitudes 3 and 4. But the list also includes several large, destructive earthquakes, such as the magnitude-7.8 quake in Nepal in April 2015, which one paper linked to groundwater pumping 1 . Miles Wilson, a hydrogeologist at Durham University, UK, and his colleagues describe the database in a paper set to be published on October 4 in  Seismological Research Letters 2 . The scientists say that HiQuake is the biggest, most up-to-date public listing of human-caused quakes ever made. By bringing the data together in this way, they hope to highlight how diverse induced quakes can be \u2014 and help society to understand and manage the future risk. \n             Earth-shaking activity \n           HiQuake began in 2016, when the Dutch Petroleum Society (NAM), an oil and gas company based in Assen, funded a team of researchers at Durham and at Newcastle University, UK, to collect examples of induced earthquakes. NAM drills in the Groningen gas field in the Netherlands, where it has set off many small earthquakes. Wilson\u2019s team trawled through sources including scientific papers and media accounts to come up with its 728 events. When a single project, such as a wastewater-injection well, set off more than one quake, the researchers counted those as a single event. Further details appear\u00a0in  Earth-Science Reviews 3 . The result is a database in which the earliest entry dates to 1868, with a quake triggered by an Australian coal-mining operation. Of the 728 events, 271 (37%) are linked to mining \u2014 often from tunnel collapses. About 23% are linked to water piling up behind a dam and 15% to conventional oil and gas development. Just 4% are linked to hydraulic fracturing, or fracking, for oil and gas. Some of the more unusual cases involve quakes triggered by the building of heavy skyscrapers or by an underground nuclear-bomb test. \n             Mass movement \n           In HiQuake, the fastest-growing quake-inducing activity in the database is the injection of wastewater back into the ground by oil and gas operations (see 'Shaking the earth'). The process that can increase stress on buried geological faults and cause them to generate small earthquakes. The number of these projects spiked in the early 2010s,  at the height of wastewater-injection in Oklahoma  and other parts of the central United States. The largest event in the database is the magnitude-7.9 earthquake that struck in Sichuan, China, in 2008, which some have linked with the filling of a nearby reservoir 4 . Wilson says his team was initially startled to see quakes that large proposed as human-induced. But in retrospect, he says, \u201cwe probably shouldn\u2019t be surprised by any anthropogenic cause\u201d. All the projects linked to earthquakes \u2014 whether blasting a mining tunnel, injecting wastewater or pumping groundwater \u2014 involve moving mass around on Earth\u2019s surface in ways that can nudge already-stressed faults. The scientists found a relationship between the volume of material moved \u2014 such as the size of the reservoir filled before the Chinese quake \u2014 and the magnitude of the largest linked earthquake that followed. No such relationship was seen with factors such as dam height or reservoir area. The researchers suggest that limiting the amount of material moved in a construction project could help to minimize any quakes triggered. \n             Judgement calls \n           All possible instances of induced quakes were included \u201cwithout regard to plausibility\u201d, writes the team, because of the difficulty involved in deciding what constitutes absolute proof that an earthquake was caused by human activity. But that could mislead people about the real hazard from induced quakes, says Rapha\u00ebl Grandin, a geophysicist at the Institute of Earth Physics in Paris. \u201cWhen you put a dot in the database, and a scientific reference behind it, then you may lead the non-expert to think that the earthquake was caused by humans,\u201d he says. Such a listing might hide scientific uncertainty, as with the Chinese quake: despite the paper linking it to reservoir filling, many seismologists do not believe it was triggered by human activity 5 . Susan Hough, a seismologist at the US Geological Survey in Pasadena, California, says she understands why the HiQuake team included all possible instances of induced quakes. \u201cI suspect the authors were unwilling to pass judgement on published studies, which I consider a reasonable decision,\u201d she says. \u201cIf you start down the road, where do you stop?\u201d Wilson agrees. \u201cAny judgement calls we leave to users,\u201d he says. Over time, HiQuake should become more useful as researchers add examples and references to its entries, says Gail Atkinson, a seismologist at the University of Western Ontario in London, Canada, who leads  a Canadian collaboration to study induced seismicity . \n                   Race to unravel Oklahoma\u2019s artificial quakes 2015-Apr-21 \n                 \n                   Chinese data hint at trigger for fatal quake 2014-Sep-10 \n                 \n                   Man-made quakes shake the ground less than natural ones 2014-Aug-18 \n                 \n                   Energy production causes big US earthquakes 2013-Jul-11 \n                 \n                   Method predicts size of fracking earthquakes 2011-Dec-09 \n                 \n                   Human-Induced Earthquake Database \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22733", "url": "https://www.nature.com/articles/nature.2017.22733", "year": 2017, "authors": [{"name": "Barbara Casassus"}], "parsed_as_year": "2006_or_before", "body": "President Emmanuel Macron\u2019s 2018 draft budget would raise research funds by 6%. French research funding is set for a heartening increase in the country\u2019s first budget under  President Emmanuel Macron , if draft 2018 plans released on 27\u00a0September are voted into law. The research portfolio of France\u2019s ministry of higher education, research and innovation would rise by more than 6%, to \u20ac8.4 billion (US$9.9 billion) in 2018. And on top of that, a giant economic-recovery plan unveiled on 25 September by Prime Minister Edouard Philippe should divert an extra \u20ac2.4 billion to research over the next five years. The cash injection will lead to a \u201csmall revolution\u201d, said Fr\u00e9d\u00e9rique Vidal, the country\u2019s minister for higher education, research and innovation at a press conference the day after the budget release. In particular, Vidal said that France\u2019s public laboratories stand to gain money after years of cuts. \u201cWe all know we have come to the end of a movement where laboratories\u2019 allocations have been trimmed, year after year. With the 2018 budget, we are reversing the trend and are starting to give fresh oxygen to our research,\u201d she said. Scientists who have long campaigned for more funding praised the proposals. \u201cIt is a signal that President Macron and the government have understood the long-term consequences of the funding crisis that has hit universities and research agencies for years,\u201d says Patrick Lemaire, a biologist at the University of Montpellier and founder of the researcher-led campaign group Sciences en Marche. For Bernard Meunier, a chemist and a past president of the French Academy of Sciences, the most positive point of the budget was that Vidal seemed to recognize the poor state of French labs\u2019 finances. \u201cThere couldn\u2019t be any further cut in their funding, because there is practically nothing left. The minister is aware there is a problem, whereas her predecessors said there wasn\u2019t,\u201d he says. In the draft proposal, the French National Research Agency (ANR), which funds individual projects on a competitive basis, would see its budget rise by 5%, to \u20ac706\u00a0million\u00a0\u2014\u00a0although its funding levels are still slightly lower than they were in 2012, and it still has no head after former president and chief executive Michael Matlosz  resigned in July . Competition for grant funding remains fierce at the ANR, where only around 12% of grant applications are successful, and Lemaire doubts that the extra money will do much to improve that. The funding boost is welcome, but not sufficient on its own to transform the agency, says Meunier. \u201cWe need the ANR to be restructured to permit more blue-skies funding and simpler grant-application procedures,\u201d he says. There would be a smaller increase for the country\u2019s public-research bodies \u2014 including the basic-research agency CNRS and the biomedical agency INSERM \u2014 which give out grants and run their own laboratories, many of them jointly with universities. These agencies see their collective spending rise by just over 1%, to \u20ac5.94 billion. Some of the money will be used for  Macron\u2019s Make Our Planet Great Again campaign , which aims to attract foreign climate scientists to France. This year\u2019s budget is the first since Vidal, a biochemist who was president of the University of Nice Sophia Antipolis from 2012 to 2017, was appointed to the research ministry. In a sign that France\u2019s government is taking the post more seriously, Vidal's role was also made more senior: she reports directly to the prime minister, whereas her predecessor,  Thierry Mandon , reported to a minister for education. The proposed increases are all the more welcome because the European Commission is pressuring France to rein in its deficit. This July, around \u20ac184 million was trimmed from the ministry\u2019s 2017 budget for research, as part of a series of public-spending cuts. France\u2019s controversial system of tax credits for companies that conduct research will remain in place, economy and finance minister Bruno Le Maire told reporters. The system, which costs the state up to \u20ac6 billion a year in tax revenues, has come under fire for alleged abuses: critics say companies use it to reduce their tax bill, rather than to increase their research spending. But Le Maire said he would simplify the system to make it easier for smaller companies to apply for credits, although he did not give details. Macron, meanwhile, has urged the European Union to pay more attention to research. In a 26 September speech, he argued that the EU should create an agency to accelerate the commercial applications of basic science, with the idea of spurring innovation in fields such as artificial intelligence. \n                   President of troubled French funding agency resigns 2017-Jul-24 \n                 \n                   Climate scientists flock to France\u2019s call 2017-Jul-18 \n                 \n                   Scientists relieved by Emmanuel Macron\u2019s French election victory 2017-May-08 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22448", "url": "https://www.nature.com/articles/nature.2017.22448", "year": 2017, "authors": [{"name": "Mark Zastrow"}], "parsed_as_year": "2006_or_before", "body": "Despite huge clean-up effort, scientists say country\u2019s pollution problem could get worse over next five years. In a major attempt to clean its increasingly dirty air, South Korea\u2019s government last week unveiled a five-year, 7.2 trillion won ($6.3 billion) plan to close down old coal plants, get diesel vehicles off the road and curb polluting emissions from industrial plants, construction sites and ships. Although much of the spending had already been pledged, researchers say that the new strategy, announced on 26 September, is the country\u2019s most ambitious attempt yet to scrub its air. But because it omits controls on a class of chemicals called volatile organic compounds (VOCs), the initiative might make air quality worse before it improves. The plan fulfils a key campaign pledge by President Moon Jae-in, who was elected in May by a Korean public increasingly concerned about their country\u2019s worsening air quality. At times this year, Seoul ranked among the world\u2019s top three most polluted cities. And the Organisation for Economic Co-operation and Development (OECD), based in Paris, reports that in 2015 South Korea\u2019s average exposure to fine-dust particles under 2.5 micrometres in size was the highest of all OECD member nations. This particulate matter, known as PM2.5, is small enough to enter the lungs and can cause respiratory illnesses. The government hopes to cut domestic emissions of PM2.5 by 30% before 2022. Moon\u2019s administration has already focused on shutting down coal plants, temporarily closing eight of them in June and beginning the permanent shutdown of three in July. And the previous administration of Park Gyun-Hye had pledged 5 trillion won by 2020 to speed the adoption of electric cars to replace diesels. \n             NOx-ious crackdown \n           But the new strategy also aims to crack down on emissions of nitrogen oxides (NOx), which can react with other atmospheric compounds, including VOCs, sulfides and ammonia, to form ozone and fine-dust particles. Large industrial facilities such as steel plants and petroleum refineries will be fitted with monitoring equipment and held to a cap on their NOx emissions starting in 2019, the environment ministry\u2019s deputy director JaeHyun Kim says. That approach has been informed in part by  data released in July  from a joint US\u2013South Korean study called KORUS-AQ 1 , says Kim. The most comprehensive examination of air quality in the region, it involved more than 580 researchers from the United States and South Korea, as well as several research aircraft, including a NASA DC-8 jet that  flew across the Korean peninsula and the Yellow Sea . Researchers found that South Korea was emitting more NOx and VOCs than its own ministry estimated, and recommended reductions in these chemicals. This highlighted the importance of addressing South Korea\u2019s domestic pollution, says Kim, at a time when many in the country were more concerned about pollution blowing over from China. The focus on NOx means the new plan is \u201ca lot better than before\u201d, says Kyung-Eun Min, an atmospheric chemist at the Gwangju Institute of Science and Technology. But she and other scientists point out that it says little about curbing VOCs. These are typically aromatic molecules produced for activities such as painting, printing and dry cleaning. A compound called toluene, used to manufacture solvents, is particularly instrumental in producing fine dust and ozone, the KORUS-AQ study found. The VOCs often leak during production, or while being stored or used by small businesses. \n             Ozone up? \n           Paradoxically, Min says, reducing NOx without reducing VOCs is likely to increase ozone across much of South Korea. That is because, according to the KORUS-AQ results and Min\u2019s own work, relative levels of NOx are so high in Korea \u2014 especially in car-filled Seoul \u2014 that they restrict the efficiency of ozone production, much as an over-rich fuel mixture makes an engine sputter. The quickest way to cut ozone is to starve it of both NOx and VOCs, \u201cbut the VOC part is not really there,\u201d Min says. However, regions downwind of Seoul may benefit more quickly from NOx reductions, says Rokjin Park, an air chemist at Seoul National University.  Tracking VOC emissions is particularly difficult, because there is no clear way to monitor or regulate small businesses such as painters and dry cleaners. A first step would be to collect data to nail down where South Korea\u2019s VOCs are coming from, Min says. In the longer term, she suggests developing technology that can capture dirty air from such emissions sites so that it can be purified at treatment facilities \u2014 in a process analogous to sewage treatment. Yong Pyo Kim, an environmental scientist at Ewha Womans University in Seoul and an author of the KORUS-AQ report, says he thinks that both ozone and fine dust could get worse for the next five years. \u201cIn my opinion, the environment ministry did not learn from the KORUS-AQ results seriously,\u201d he says. The South Korean environment ministry has not responded to requests for comment from  Nature  about the criticisms. \n                   South Korea\u2019s scientists seek change amid political chaos 2017-Mar-22 \n                 \n                   Why South Korea is the world\u2019s biggest investor in research 2016-Jun-01 \n                 \n                   NASA jet gets a sniff of pollution over South Korea 2016-May-09 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22741", "url": "https://www.nature.com/articles/nature.2017.22741", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "September\u2019s sharpest science shots, selected by  Nature \u2019s photo team. \n             CRISPR catches \n           \n             Inside Xenon \n           \n             Coming down\u2026 \n           \n             \u2026 and going up \n           \n             A complex cloud \n           \n             Seamount squid \n           \n             Bee bounty \n           \n             Cassini comedown \n           \n             They grow up so fast \n           \n                   Volcanic views, stalking storks and the ephemeral eclipse 2017-Sep-01 \n                 \n                   An icy break up, Higgs history and a very messy eater 2017-Jul-31 \n                 \n                   Horatio\u2019s head, arty ants and an ephemeral lake 2017-May-30 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22748", "url": "https://www.nature.com/articles/nature.2017.22748", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Leading suspect \u2014 climate change \u2014 doesn\u2019t fully explain what is happening to leatherback turtles in the US Virgin Islands. The mystery behind a dramatic fall in the number of leatherback sea-turtle ( Dermochelys coriacea ) hatchlings in the US Virgin Islands remains unsolved, despite the latest efforts of researchers. Rising temperatures and changes in rainfall patterns \u2014 the top two suspects \u2014 don\u2019t seem to be connected to the decline, according to a study published on 4 October 1 . The finding contradicts previous work, leaving researchers scratching their heads over what could be happening. The latest study focused on a nesting beach in the Sandy Point National Wildlife Refuge on St Croix island in the Caribbean Sea. The researchers found that about 74% of the leatherback sea-turtle eggs laid there in 1990 hatched, but that rate had plummeted to 55% by 2010. The study analysed detailed temperature and precipitation data at these nests over the 20 years, and found no corresponding trend in either climate-change factor that could fully account for the decline. The researchers reported their results in  Royal Society Open Science . Increases in temperature and more-erratic precipitation patterns do affect the nests, but they aren\u2019t the sole reason for the hatching declines, says Anthony Rafferty, a marine biologist at Monash University in Melbourne, Australia, and a study co-author. This trend is especially confusing in light of the increase in the  adult sea-turtle population . \u201cThe number of nesting females and the population size has been trending upwards at this site,\u201d Rafferty says. \u201cBut there\u2019s been a decrease in hatching success that we are worried about.\u201d That could have negative effects on leatherback populations within one or two decades, he says, when those hatchlings come of age. \n             Conundrum continues \n           \u201cIt\u2019s hard to say how much of that is happening because of climate change,\u201d says Vincent Saba, a climate scientist at the US National Oceanic and Atmospheric Administration in Princeton, New Jersey. He co-authored a 2015 study 2  that did find a relationship between air temperature, precipitation patterns and declines in leatherback hatching success. That study examined data from 1982 to 2010 and looked at seasonal rainfall, unlike the latest paper, which analysed rainfall only during the nesting season. The study predicted that, by 2100, Sandy Point would have the most unfavourable climate conditions out of all leatherback nesting sites around the world. \u201cI like the study. They looked at the effect of climate in finer detail,\u201d says Pilar Santidri\u00e1n Tomillo, a marine biologist and science director of the Leatherback Trust, based in Playa Grande, Costa Rica. She was a co-author on the 2015 study, and appreciates the fuller picture of what could be happening at Sandy Point that the most recent study has provided. Sea-turtle eggs are exquisitely sensitive to climate because heat, carbon dioxide, oxygen and water all pass freely through their permeable shells. The surrounding temperatures determine the sex of the hatchlings: warmer conditions produce more females, whereas cooler conditions yield males. And rainfall can influence hatchling development and their ability to escape the nest, says Rafferty. Too little rain might mean that the sand is too dry for the young turtles to climb out of it; too much rain during the early stages of egg development might lead to a reduction in oxygen supplies to the growing embryo. \u201cI think changes in precipitation levels or patterns could explain the decline in hatching success partially, but there could be other reasons, too, like decline in fertility or increase in pollutants, for example,\u201d Santidri\u00e1n Tomillo says. Rafferty, who specializes in embryo research, now plans to look at how the age and health of a female sea turtle might affect her fertility, or where she lays her eggs. \n                   Mapping pinpoints turtles' danger zones 2014-Feb-12 \n                 \n                   Satellite tracking will reveal turtle wanderings 2011-Apr-27 \n                 \n                   The great turtle-egg evacuation 2010-Jul-02 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22759", "url": "https://www.nature.com/articles/nature.2017.22759", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Bird-bone structures emerge from an evolution-like algorithm. Engineers have used a supercomputing technique that mimics natural selection to design the internal structure of an aircraft wing from scratch. The resulting blueprint is not only lighter than existing wings, it also resembles natural formations, such as bird wing bones, that are not present in current aeroplanes. The organic-looking product is as stiff as a conventional aircraft wing but lighter, which could save up to 200 tonnes of fuel per year per plane. \u201cThis is a really nice illustration of how to employ computing-based optimization methods at immensely high resolution,\u201d says Matthew Santer, an aerospace engineer at Imperial College London. The method could feed into the design process, although there are a number of hurdles to using it in aerospace applications in its present form, he adds. Engineers have been using these kinds of optimization techniques for around 20 years, but only for smaller-scale problems, such as individual wing components, or much simpler structures, says Niels Aage, an engineer at the Technical University of Denmark, near Copenhagen, who led the work 1 . Aage and his colleagues used the Curie supercomputer in Bruy\u00e8res-le-Ch\u00e2tel near Paris to increase the resolution, enabling them to model the entire 27-metre-long wing of a Boeing 777. The team started with a wing outline already optimized for maximum lift and minimum drag, known as an aerofoil, and split it into 1.1 billion 3D pixels or \u2018voxels\u2019. Each is about the size of the smallest Lego brick \u2014 a resolution roughly 200 times greater than previous efforts. The algorithm began by simulating the force exerted on every block and distributing material in response to where the wing experienced a load. Without any human guidance, the program then repeated the analysis several hundred times, adding or removing material depending on the strain felt by each brick, until it reached a final optimum design. \u201cThe structure evolves through each design cycle,\" says Aage. \"The process has many similarities to nature\u2019s own evolution.\" \n             Organic flight \n           Unlike conventional wings, the resulting structure did not contain the usual straight beams running the length of the wings, interspersed by crossing supports. Instead, the design looks organic, says Aage. Curved supports fan out at the trailing edge of the wing, resembling the bones in birds\u2019 wings, and intricate support structures in the leading edge look like the internal structure of a beak. Without compromising stiffness (resistance to deformation), the design weighs 2\u20135% less than conventional wing structures. That translates into 200\u2013500 kilograms per wing, potentially saving each plane between 40 and 200 tonnes of fuel per year, say the authors. The technique could also be applied to other industries, says Aage, for example, to design high-rise buildings in earthquake-prone zones that maintain their stiffness yet can withstand the dynamics of a quake. It could be used to optimize acoustics, ventilation systems and antennas, as well, he adds. The technique\u2019s high resolution, which allows the computer to design structures that include features that range in size from millimetres up to tens of metres, could lead to more-innovative designs in these other disciplines, says Liang Xia, a computational engineer at the Huazhong University of Science and Technology in Wuhan, China. But he stresses that running the algorithm requires a heavy computing burden \u2014 the equivalent of running a single standard computer for 100 years. This computing cost could be reduced, however, if the team were to employ more-advanced simulation methods, used in artificial intelligence, which in effect model only parts of the wing in such high resolution. The design is also too intricate to be made by existing manufacturing methods, and would require a giant 3D printer to build. But for now, key aspects of it could be fed into structures produced using conventional methods, says Aage. \u201cWe\u2019re speeding up evolution rapidly, meaning we can see how designs should be, and then extract the key features \u2014 or those we can afford.\u201d \n                   Supercomputer sets protein-folding record 2010-Oct-14 \n                 \n                   A century of powered flight 2003-Dec-13 \n                 \n                   Soft cell's hard shell explained 2001-Sep-25 \n                 \n                   Hover craft 2000-Sep-11 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22735", "url": "https://www.nature.com/articles/nature.2017.22735", "year": 2017, "authors": [{"name": "Jo Marchant"}], "parsed_as_year": "2006_or_before", "body": "Archaeologists think that at least seven life-sized sculptures are hidden nearby. Marine archaeologists investigating an ancient shipwreck near the island of Antikythera, Greece, have recovered a wealth of treasures, including bronze and marble statue pieces, a sarcophagus lid and a mysterious bronze disc decorated with a bull. The artefacts were trapped under boulders in a previously unexplored part of the site, and the researchers think that the remaining parts of at least seven complete statues are still buried nearby. The discoveries are \u201cextremely exciting\u201d, says Kenneth Lapatin, curator of antiquities at the J. Paul Getty Museum in Los Angeles, California. Only a handful of bronze statues survive from the ancient world, and they have almost invariably been treated and altered by previous conservators, undergoing processes that destroyed much of the information scientists might have gleaned from them. \u201cTechnology has improved so much,\u201d says Lapatin. \u201cWe can learn from these untreated finds.\u201d The first-century- bc  cargo ship, discovered in 1900 by sponge divers, is famous for yielding a complex, bronze, geared device \u2014 heavily encrusted and corroded \u2014 that originally predicted eclipses and showed the movements of the Sun, Moon and planets in the sky. The sponge divers also retrieved many other priceless items, including luxury glassware, jewellery and a two-metre-tall bronze statue, dating from the fourth century  bc , nicknamed the \u2018Antikythera youth\u2019. \n             Statue search \n           The recovery of multiple \u2018orphan\u2019 statue pieces \u2014 limbs without matching heads or bodies, for example \u2014 suggested that several statues still lie buried here. So an international team of archaeologists and divers, co-led by Brendan Foley of the University of Lund in Sweden and Theotokis Theodoulou of the Greek Ephorate of Underwater Antiquities in Athens, is now re-excavating the 50-metre-deep wreck site to look for them. The team has made a stream of discoveries since work began in 2014, including wine jars, giant anchors, gold jewellery and a human skeleton, which is  now being analysed for DNA . But the statues have remained hidden until now. On 4 October, the team announced that during a 16-day dive season the previous month, they found several major statue pieces, including two marble feet attached to a plinth, part of a bronze robe or toga, and a bronze male arm, with two fingers missing but otherwise beautifully preserved. A slim build and \u201cturning hand\u201d gesture suggest that the arm may belong to a philosopher, says Theodoulou. In 1900\u201301, the sponge divers salvaged orphan limbs from a minimum of six bronze statues. The newly discovered arm pushes that total to at least seven, says Theodoulou. The team is particularly excited because the statue pieces were found in an area undisturbed by any previous excavations, buried beneath large boulders dislodged from Antikythera\u2019s steep cliffs over the course of 2,000 years by periodic earthquakes. \u201cWe think this means that everything is down there still,\u201d says Foley. The discovery of seven bronze statues, if they could be recovered, would significantly boost the world\u2019s total from this time period, which stands not much greater than 50, Lapatin estimates. Few of those are complete. And although these ancient figures might look beautiful, they are hard to study because the aggressive treatments by generations of conservators have altered and damaged the bronze. \n             Technological advances \n           Fresh, untreated finds such as those from Antikythera will give researchers the opportunity to use modern techniques to study a significant aspect of ancient Greek life \u2014 for example, by looking at casting methods, which precise alloys were used and whether the statues were made for export or had been previously displayed. Meanwhile, any heads found might enable researchers to identify the people depicted, and to compare their likeness with any existing portraits, for example, marble statues or images etched on coins. Foley and Theodoulou\u2019s team also recovered an intriguing bronze disc or wheel, about eight centimetres across, attached to four metal arms with holes for pins. A layer of hardened sediment hides its internal structure, but it superficially resembles the Antikythera mechanism, and researchers had initially hoped that it might be part of that ancient device: perhaps the gearing that calculated the positions of the planets, which is missing from the find. But preliminary X-ray imaging conducted in an Athens hospital on 25 September revealed a surprise: instead of gear wheels, the image of a bull appeared. The object might have been a decorative element, says Lapatin, perhaps attached to a box or a statue\u2019s shield, or even \u2014 because of its sturdy construction \u2014 to the doomed ship. More-detailed radiography is planned for the next few weeks. Other discoveries this season include a sarcophagus lid made from fine, red marble, more human remains and wooden ship planks and frames that the researchers hope will reveal information about the vessel\u2019s size and shape. The team plans to return to Antikythera in May 2018, to break up the boulders and excavate beneath. \u201cIt\u2019s going to be a major operation,\u201d says Foley. \u201cBut we think it will be spectacular.\u201d \n                   Human skeleton found on famed Antikythera shipwreck 2016-Sep-19 \n                 \n                   Famed Antikythera wreck yields more treasures 2014-Oct-10 \n                 \n                   In search of lost time 2006-Nov-29 \n                 \n                   Power and Pathos: Bronze sculpture of the Hellenistic World \n                 \n                   Return to Antikythera \n                 \n                   Brendan Foley \n                 \n                   Kenneth Lapatin \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22761", "url": "https://www.nature.com/articles/nature.2017.22761", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Hungary-New York agreement could allow Central European University to sidestep law change. The prestigious Central European University (CEU) in Budapest, Hungary, seems to have found a way around a threat to close it down. The university had been affected by a law change that is widely thought to be politically motivated. The threat arose in April, when the government rushed through an amendment to its higher-education law, requiring that all international universities operating in Hungary had also to operate as higher-education institutes in their countries of origin. The law change seriously affected only the CEU, which is legally registered in New York state. The university was founded in 1991 by Hungarian-born philanthropist George Soros, whom Hungarian Prime Minister Viktor Orb\u00e1n has described as an enemy, because of Soros\u2019s statements in support of refugees, which run counter to Orb\u00e1n's policies. The revised law, which includes other, smaller amendments, comes into effect on 11 October. \n             New York connection \n           A CEU spokesperson said on 3 October that the university has now signed a Memorandum of Understanding with Bard College in Annandale-on-Hudson, New York, to provide educational activities. She added that negotiations between the State of New York and the government of Hungary, which opened at the end of June, have now concluded, although the agreement still has to be signed off by Hungary\u2019s government and Parliament. The law change sparked immediate protest last April, when  70,000 protestors  took to the streets in Budapest, and the Hungarian Academy of Sciences expressed concern. The European Commission is pursuing an infringement procedure against what it sees as an illegal restriction of academic freedom, and an investigation by legal experts of the Council of Europe, a powerful human-rights organization with 47 member states,  published  a preliminary opinion in August indicating that the law was inappropriate. \u201cIt\u2019s no secret that it has been a hell of a way to treat a university,\u201d says CEU rector Michael Ignatieff. The university has nearly 1,500 mostly postgraduate students from more than a hundred countries, including a large number from Hungary. It operates mainly in the humanities, but recently expanded to include the cognitive and network sciences. \n                   Arctic drilling, controversial reforms and new views of Saturn 2017-May-03 \n                 \n                   Hungary's protests, coral bleaching and a neutrino anomaly 2017-Apr-12 \n                 \n                   Central European University \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22760", "url": "https://www.nature.com/articles/nature.2017.22760", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Measurement in ordinary hydrogen agrees with a surprising 2010 result on the element's exotic cousin \u2014 but gives a smaller value than virtually every other experiment. The proton might truly be smaller than was thought. Experiments on an exotic form of hydrogen first found 1  a puzzling discrepancy with the accepted size in 2010. Now, evidence from a German and Russian team points to a smaller value for the size of the proton with ordinary hydrogen, too. The results, which appeared on 5 October in  Science 2 , could be the first step towards resolving a puzzle that has made physicists doubt their most precise measurements, and even their most cherished theories. Still, \u201cbefore any resolution, this new value has to be confirmed\u201d, says Jan Bernauer, a physicist at the Massachusetts Institute of Technology in Cambridge. If other labs confirm it, he adds, \u201cthen we can find why the old experiments were wrong, hopefully\u201d. \n             Method mix-up \n           For decades, physicists have estimated the size of the proton using one of two main techniques. Atomic physicists use spectroscopy to measure the energy levels of electrons orbiting an atomic nucleus \u2014 consisting of either the single proton in a hydrogen atom, or a bigger nucleus. The size of the nucleus affects those energies because electrons spend some time moving through the nucleus as they orbit it. Meanwhile, nuclear physicists have used a similar technique to the one that enabled Ernest Rutherford to discover atomic nuclei in the first place. They hit the atoms with beams of fast-moving electrons and measure how the electrons bounce off. As their precision improved, both methods roughly came to agree on a radius of about 0.8768 femtometres (millionths of a millionth of a millimetre). But in 2010, a novel kind of experiment completed at the Paul Scherrer Institute in Villigen, Switzerland, disrupted the consensus. After a decade of unsuccessful attempts, a multinational collaboration led by Randolf Pohl, then at the Max Planck Institute of Quantum Optics (MPQ) in Garching, Germany, measured energy transitions not in ordinary hydrogen, but in lab-made \u2018muonic\u2019 hydrogen. These are atoms in which the electron has been replaced by a muon \u2014 a particle similar to an electron in most of its properties, but 200 times more massive. The heavier particle spends more time inside the nucleus, which means that the proton\u2019s size has a much larger effect on the muon\u2019s energies \u2014 which, in turn, should lead to a much more precise estimate of the proton\u2019s radius. Pohl\u2019s team found the proton to be 4% smaller than the accepted value. Some researchers speculated that perhaps some previously unknown physics could make muons act differently than electrons. This would have required a revision of the standard model of particle physics, which predicts that muons and electrons should be identical in every way except for their masses \u2014 and might have pointed to the existence of yet-to-be-discovered elementary particles. \n             Exciting technique \n           In the latest paper 2 , Pohl, now at the Johannes Gutenberg University in Mainz, Germany, and his collaborators tickled hydrogen atoms \u2014 containing ordinary electrons \u2014 with two different lasers. The first one sent the atoms\u2019 electrons into an excited state, and the second one put them into a higher-energy excitation. The team then detected the photons that the atoms released as their electrons fell back into lower-energy excitation states. The team combined its data with an earlier, high-precision measurement to calculate the Rydberg constant, which expresses the energy that it takes to rip the electron off the hydrogen atom. Standard theory then enabled the researchers to calculate the radius of the proton from this constant. The value they found was consistent with the muonic-hydrogen measurement, and 5% smaller than the 'official' proton radius. To ensure that they eliminated any spurious experimental effects, the team spent three years analysing its data, says Lothar Maisenbacher, a co-author of the paper and an atomic physicist at the MPQ. Bernauer, who works on the electron\u2013proton scattering technique, is impressed. \u201cIt\u2019s a great experiment,\u201d he says. \u201cI think they really advanced their field with this.\u201d The care that they took is \u201cvery impressive\u201d, and makes their measurement more reliable than many others, says Krzysztof Pachucki, a theoretical physicist at the University of Warsaw who is on the task group of the Committee on Data for Science and Technology (CODATA). CODATA, the international agency that publishes the best-known values of the fundamental constants, is taking notice of the Mainz experiment. \u201cWe will take this result very seriously,\u201d says Pachucki. The committee is due to revise the \u2018official\u2019 handbook of universal constants of nature next year. Because of this experiment, CODATA will \"most probably\u201d change its values for the proton radius and Rydberg constant, he says. \n             More evidence needed \n           But the German\u2013Russian group is not quite ready to claim that the puzzle has been solved, Maisenbacher says. \u201cWe have not identified any conclusive reason why the other measurements should not be correct themselves,\u201d he says. \u201cWe would like to see more experiments from other people.\u201d A number of teams around the world are doing just that. Bernauer is interested, for example, in the results of spectroscopy experiments being done at York University in Toronto, Canada. If their measurement is also small, \u201cthen I would start to believe that the old data has a problem\u201d, Bernauer says. But that would still leave open the matter of the electron\u2013proton scattering results. In those experiments, researchers have conventionally used electrons that have a range of different energies. Estimating the size of the proton required extrapolating all the way to an ideal situation, in which electrons had zero energy. Ashot Gasparian, a particle and nuclear physicist at North Carolina A&T State University in Greensboro and his team have recently conducted an experiment at the Thomas Jefferson National Accelerator Facility in Newport News, Virginia. They injected cold hydrogen gas directly into their electron accelerator, rather than bombarding liquid hydrogen kept in a plastic box, as was previously done. This technique enabled them to remove some experimental uncertainties and also to use electrons with lower energies than before. In principle, this could reveal whether and where the previous extrapolations went wrong. They are now analysing their data and hope to have results next year. \u201cThe ball is in our court,\u201d says Gasparian. \n                   The race to reveal antimatter\u2019s secrets 2017-Aug-02 \n                 \n                   Ephemeral antimatter atoms pinned down in milestone laser test 2016-Dec-19 \n                 \n                   Zombie physics: 6 baffling results that just won't die 2015-Oct-30 \n                 \n                   Shrunken proton baffles scientists 2013-Jan-24 \n                 \n                   The proton shrinks in size 2010-Jul-07 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22762", "url": "https://www.nature.com/articles/nature.2017.22762", "year": 2017, "authors": [{"name": "Rachel Cernansky"}], "parsed_as_year": "2006_or_before", "body": "Neonicotinoids are at the centre of a long-running debate about whether they harm bees. Honey bees on every continent except Antarctica face significant exposure to neonicotinoid pesticides \u2014 chemicals that  some studies suggest harm bees\u2019 health . Researchers who tested honey from nearly 200 sites worldwide found that 75% of their samples contained some level of the pesticides, according to a report published on 6 October in  Science 1 . The study is the first attempt to quantify the presence of neonicotinoids in honey on a global scale using standardized methods. Nearly half of the samples tested contained levels of neonicotinoids at least as high as those thought, on the basis of previous research, to impair bees\u2019 brain function and slow the growth of their colonies. The study also found that 45% of the samples contained two or more types of neonicotinoid. \u201cIt\u2019s not a surprise, in a sense, that we find neonicotinoids in honey. Anybody could have guessed that,\u201d says lead author Edward Mitchell, a biologist at the University of Neuch\u00e2tel in Switzerland. \u201cWhat\u2019s original is using the same protocol. We now have a worldwide map of the situation.\u201d The research provides additional context for the long-running debate over whether and how neonicotinoids affect bees\u2019 health. Some studies have suggested that exposure to neonicotinoids lowers honey bees\u2019 nutritional status 2  and impairs their immunity 3 . And in June, a paper published in  Science   reported that neonicotinoids lower honey bees' chances of survival during the winter , and threaten the queen in particular, which can affect reproduction 4 . To assess the scale of honey bees\u2019 exposure to neonicotinoids around the world, the authors of the new study collected honey from 198 sites on six continents through a citizen-science project. Then they tested those samples to determine the concentrations of five of the most commonly used neonicotinoids. Honey collected in North America had the highest proportion of samples containing at least one neonicotinoid, at 86%, with Asia (80%) and Europe (79%) close behind. The extent of the contamination, even in honey from remote places \u2014 including islands in the middle of the Pacific Ocean and off the coast of West Africa \u2014 is surprising, says Amro Zayed, an insect researcher at York University in Toronto, Canada. The findings suggest that bees the world over are exposed to neonicotinoids constantly over generations, he says, which is worrying because the insects depend so heavily on honey for food. \u201cIt\u2019s one thing to go out to a restaurant and get a bad meal, but if you have your fridge at home contaminated with insecticides, that\u2019s an entirely different method of exposure,\u201d Zayed says. Others say that the widespread presence of neonicotinoids in honey is to be expected, given how commonly the chemicals are used in staple crops such as canola and wheat, as well as in home gardens. \u201cYes, there is going to be long-term exposure, potentially, to neonics, but that doesn\u2019t say anything about the risk,\u201d says Chris Cutler, an entomologist at Dalhousie University in Halifax, Canada. \u201cJust because it\u2019s there doesn\u2019t necessarily mean there\u2019s a problem.\u201d Much of the debate about neocotinoids has focused on just this question: how problematic are the pesticides when bees are exposed to them at low levels, but over a long period of time? \u201cOne of the issues around assessing the impacts on bees has been the discussion of what a field-relevant level of exposure actually is,\u201d says Nigel Raine, a pollinator-health researcher at the University of Guelph in Canada. \u201cThis contributes toward that discussion substantially.\u201d  \n                   Largest-ever study of controversial pesticides finds harm to bees 2017-Jun-29 \n                 \n                   Controversial insecticides linked to wild bee declines 2016-Aug-16 \n                 \n                   Global biodiversity report warns pollinators are under threat 2016-Feb-26 \n                 \n                   Fears for bees as UK lifts insecticide ban 2015-Jul-23 \n                 \n                   Bee studies stir up pesticide debate 2015-Apr-22 \n                 \n                   Bumblebee study called into question 2015-Mar-26 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22736", "url": "https://www.nature.com/articles/nature.2017.22736", "year": 2017, "authors": [{"name": "Ewen Callaway"}, {"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Jeffrey Hall, Michael Rosbash and Michael Young unpicked molecular workings of cells' daily rhythms. Three scientists who studied the workings of organisms\u2019 inner circadian clocks have won the 2017 Nobel Prize in Physiology or Medicine. Jeffrey Hall and Michael Rosbash, both at Brandeis University in Waltham, Massachusetts, will split the award of 9 million Swedish kronor (US$1.1 million) with Michael Young at Rockefeller University in New York City. Beginning in the 1980s, the three researchers isolated and characterized a gene in fruit flies,  period , that encodes a protein that builds up each night, only to be broken down the following day. In subsequent work, the trio, as well as other scientists, unpicked the molecular regulation of the  period  gene (and the protein that it encodes, called PER) and identified additional components of the circadian clock. All multicellular organisms possess circadian clocks, and  human versions  of the genes that comprise their clocks have been implicated in sleeping disorders and other medical conditions. Rosbash, Hall and Young have been collecting awards together for the past five years. In 2013, for example, they shared the Shaw Prize in life science and medicine, then worth US$1\u00a0million. That has set the expectation that a Nobel might be around the corner, says Herman Wijnen, who studies circadian clocks at the University of Southampton, UK and was a postdoc in Young\u2019s lab. \u201cThis has been one that people have been looking out for,\u201d he says. \u201cIt\u2019s been settled in the scientific community that this is the trio.\u201d But Young says he was so stunned by the news that he could barely get his shoes on the morning he found out. \u201cI\u2019d go and I\u2019d pick up the shoes, and then I\u2019d realize I need the socks,\u201d he said during a press conference. \u201cAnd then I realized I needed to put my pants on first.\u201d The award took Rosbash by surprise too, says Thomas Perlmann, secretary of the Nobel Assembly, which selects the prizewinners. \u201cI first got hold of Michael Rosbash, and he was silent,\u201d says Perlmann. \u201cAnd then he said, \u2018you are kidding me\u2019.\u201d The work has its roots in genetic screens performed by physicist and molecular biologist Seymour Benzer and geneticist Ronald Konopka, who together found fruit-fly mutants with abnormal hatching rhythms. (Benzer died in 2007; Konopka in 2015.) At the time, the idea that behaviour could have a genetic basis was controversial, says Wijnen. Years later, two teams \u2014 Young leading one, Hall and Rosbash working together to lead another \u2014 would clone the genes responsible. \u201cThat really changed the situation,\u201d says Wijnen. \u201cSince then, it has become clear how conserved this system is and how conceptually it could work.\u201d The competition between the two teams \u2014 each with ambitions to be first to identify the gene \u2014 was initially intense, says Charalambos Kyriacou, a behavioural geneticist at the University of Leicester, UK, who worked with Hall in the late 1970s. \u201cAs they got older they mellowed,\u201d he says. \u201cThey\u2019re all good buddies now.\u201d Subsequent work detailed how abundance of the PER protein peaks at night and then declines during the day. Researchers gradually pieced together a model in which the accumulation of PER serves as a signal that represses expression of the gene that encodes it. This type of negative feedback loop would become a prevailing theme in the study of circadian rhythms, as researchers identified additional loops and clock proteins over the years.\u00a0 Joseph Takahashi at the University of Texas Southwestern Medical Center in Dallas and others extended the work from fruit flies to mammals, and showed that the system is remarkably conserved across species. Researchers have since tied the circadian clock to many aspects of mental and physical well-being. \u201cWe expose ourselves to inappropriate light, we travel across time zones, we do shift work,\u201d says Wijnen. \u201cAnd all of that is negatively impacting our health.\u201d The links between the circadian clock and human health are so pervasive that medical schools should increase their focus on chronobiology, says Martha Merrow, chair of medical psychology at Ludwig Maximilian University of Munich in Germany. This could be either as a speciality in its own right, or incorporated into medical training in other specialities such as endocrinology or rheumatology, she adds. A Nobel prize may give Merrow and her colleagues added force to make that case. Merrow learnt of the news before heading into an administrative meeting. \u201cI was so breathless, I could hardly go into my meeting,\u201d she says. \u201cIt\u2019s just a fantastic choice. It will be great for our field.\u201d \n                     Where Nobel winners get their start 2016-Oct-07 \n                   \n                     Medicine Nobel for research on how cells 'eat themselves' 2016-Oct-03 \n                   \n                     Anti-parasite drugs sweep Nobel prize in medicine 2015 2015-Oct-05 \n                   \n                     Circadian rhythms: Of owls, larks and alarm clocks 2009-Mar-11 \n                   \n                     Nobel Prize website \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22694", "url": "https://www.nature.com/articles/nature.2017.22694", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "A method for precisely editing genes in human embryos hints at a cure for a blood disease. A team in China has taken a new approach to fixing disease genes in human embryos. The researchers created cloned embryos with a genetic mutation for a potentially fatal blood disorder, and then precisely corrected the DNA to show how the condition might be prevented at the earliest stages of development. The report, published on 23 September in  Protein & Cell 1 , is the latest in a series of experiments to edit genes in human embryos. And it employs an impressive series of innovations, scientists say. Rather than replacing entire sections of genes, the team, led by Junjiu Huang at Sun Yat-sen University in Guangzhou, China, tweaked individual DNA letters, or bases, using a  precision gene-editing technology developed in the United States 2 . Huang\u2019s team is also the first to edit out the mutation responsible for a \u2018recessive\u2019 disease: one caused by having two faulty copies of a gene. Because it would be difficult for researchers to find dozens of embryos that all have this rare double mutation, the team worked around this roadblock by developing embryonic clones from their patient\u2019s skin cells.\u00a0 \u201cI thought, \u2018Why would they do cloning?\u2019 Then I read the paper, and thought, \u2018Wow, that\u2019s fascinating,\u2019\u201d says Shoukhrat Mitalipov, a reproductive-biology specialist at the Oregon Health and Science University in Portland who  pioneered human cloning  and also works on gene editing in embryos. \u201cI would not have thought to do this.\u201d Scientists around the world have now published eight studies reporting gene editing in human embryos, five in the past two months. None have permitted the embryos to grow beyond 14 days, and the research has had different purposes: some to test gene-editing technologies; others to  edit various disease-related genes ; and some to  unravel the mechanisms behind early embryonic development . Huang\u2019s team led the  first report,  published in April 2015, in which they used the CRISPR\u2013Cas9 enzyme complex to snip chromosomes at specific locations, excise DNA and replace it with other genetic material 3 . \n               Precision editing \n             In the latest study 1 , Huang\u2019s team used \u2018base editing\u2019, a modification of CRISPR\u2013Cas9. It guides an enzyme to specific gene sequences, but does not cut the DNA. Instead, the Cas9 enzyme is disabled and tethered to another enzyme that can swap out individual DNA base pairs. So far, this technique can convert guanine (\u2018G\u2019) to adenine (\u2018A\u2019), and cytosine (\u2018C\u2019) to thymine (\u2018T\u2019). Hundreds of genetic diseases are caused by single-base changes, or \u2018point mutations\u2019, and so editing of this sort at the embryonic stage could potentially stave off such conditions. Huang\u2019s team chose one mutation common in the Chinese population: a switch from an A to a G at a certain spot in the  HBB  gene, which can lead to \u03b2-thalassaemia, a recessive blood disorder associated with severe or fatal anaemia. Researchers generally source embryos from  in vitro  fertilization (IVF) clinics, but it\u2019s rare for these facilities to have embryos with two copies of the same rare mutation. So Huang\u2019s team found a person with the blood disorder, extracted their skin cells and used cloning techniques to develop embryos with the same genetic makeup. The researchers reported that in 8 of 20 cloned embryos, they were able to convert the errant G back into an A in one or both copies of the gene. (Repairing only one copy might be enough to cure a recessive disease.) That rate is too low for the technique to be considered for clinical use, but the efficiency was high relative to that achieved in other gene-editing studies. \u201cThe repair rate is pretty good, and certainly promising,\u201d says Gaetan Burgio, a geneticist at the Australian National University in Canberra. \u201cOur study opens new avenues for therapy of \u03b2-thalassaemia and other inherited diseases,\u201d says Huang. But scientists caution that not all cells in the eight embryos were fixed. Such embryos are \u2018mosaic\u2019, meaning that they have a patchwork of cells with different genetic make-ups, which is potentially dangerous. \u201cIt looks like solid work, but highlights that the problem of mosaicism remains a challenge for any form of gene editing in the human embryo,\u201d says Dieter Egli, a stem-cell biologist at Columbia University in New York City. \n               Unintended consequences \n             Some scientists also question whether Huang\u2019s team looked thoroughly enough for unintended genetic changes, called off-target effects, that might have been caused by the base-editing procedure, although the authors reported that none were found. Huang says future experiments will be more comprehensive, but that this first study was a successful proof of principle that the base-editing technique can be used to correct a disease mutation in a human embryo. It may be that conventional CRISPR\u2013Cas9 cannot fix embryos when both copies are faulty, although this isn\u2019t yet clear. In August, for instance, Mitalipov\u2019s team reported using CRISPR\u2013Cas9 to repair a mutation in a gene that can cause a potentially deadly heart disorder, by using the other, healthy copy of the gene as a template 4 . In the future, Huang says, he plans to ask for oocytes and sperm from donors who have one mutated copy of the gene \u2014 and so are unaffected by the condition, but are carriers of the disease \u2014 and use these to produce embryos. Some of those embryos would have two mutated copies, and some one, but Huang wants to edit both types. That raises the contentious idea that gene editing might be used not only to prevent severe disease, but also to eliminate the chance of people becoming carriers of the disorder. \u201cBase editing can repair the mutant site and block it from being passed on to the next generation,\u201d he says. \n                     CRISPR used to peer into human embryos' first days 2017-Sep-20 \n                   \n                     CRISPR fixes disease gene in viable human embryos 2017-Aug-02 \n                   \n                     Base editing on the rise 2017-May-09 \n                   \n                     Gene-editing hack yields pinpoint precision 2016-Apr-20 \n                   \n                     Chinese scientists genetically modify human embryos 2015-Apr-22 \n                   \n                     Human stem cells created by cloning 2013-May-15 \n                   \n                     Special: CRISPR \n                   \n                     Sun Yat-sen University \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22686", "url": "https://www.nature.com/articles/nature.2017.22686", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Short-term travel and meeting attendance could become harder for researchers from eight countries, including Iran. The latest version of US President Donald Trump\u2019s travel ban could make it harder for researchers from several countries to enter the United States to attend scientific meetings, perform research or visit relatives. On 24 September, Trump announced permanent travel restrictions on citizens of Chad, Iran, Libya, North Korea, Somalia, Syria, Venezuela and Yemen. That list includes five Muslim-majority countries that were targeted in the White House\u2019s first and second travel bans,  which Trump signed in January  and  March . Those policies, which were designed as temporary measures,  have been limited by a series of federal court rulings . Although the latest ban largely exempts students from any travel restrictions, its provisions appear poised to limit visits to the United States by working scientists. The rules vary by country; Iranians, for instance, can enter the United States only on student visas or temporary \u2018J\u2019 work visas, which are common among foreign postdocs in the United States. Citizens of Chad, Libya and Yemen can no longer enter the United States on business or tourist visas, and Syrians and North Koreans are barred in all circumstances. The impact is likely to be greatest for Iran, which produces more scientists and engineers than the other countries included in the policy, says Russell Harrison, a senior legislative representative for IEEE-USA in Washington DC, which advocates for US members of the Institute of Electrical and Electronics Engineers. The White House policy will tighten security for Iranian students and researchers who already hold J visas, subjecting them to \u201cenhanced screening and vetting requirements\u201d if they travel outside the United States and attempt to re-enter the country. \n               Early impacts \n             Although there is no indication that the US will stop issuing student and J visas, no new long-term work visas will be available for Iranian citizens for the foreseeable future, Harrison says. \u201cIt will be difficult for researchers to get work in the United States for more than a relatively short period of time.\u201d Iranian scientists planning brief visits to the United States are already feeling the effects of the latest ban. Arvin Haghighatfard, a graduate student at Islamic Azad University in Tehran, had hoped to present his research on the genetic basis of internet addiction at the American Society of Human Genetics conference next month in Orlando, Florida. \u201cThe president\u2019s new travel ban really disappointed me and all of my colleagues,\u201d says Haghighatfard, who says that the United States refused to consider his visa application in light of the latest restrictions. The same is true for Hossein Azizi, a geologist from the University of Kurdistan, in Sanandaj, Iran. He recently received an invitation to visit the United States and collaborate with geologist Robert Stern of the University of Texas at Dallas. \u201cIt was one of my best days in my life,\u201d Azizi says. But uncertainty over whether he can secure a US visa has jeopardized those plans. \u201cWe know there are many problems between political men,\u201d says Azizi. But geologists' work on the formation of the Earth \u201cbelongs to humanity and science\u201d, rather than to geopolitics, he adds. \n               Legal challenges expected \n             The White House says that the latest ban will remain in place until the eight listed countries improve their processes for screening travellers. But the policy is widely expected to be challenged in court in the coming days \u2014 and it is already affecting legal challenges to the previous US travel bans. On 25 September, the US Supreme Court cancelled its scheduled hearings for  a lawsuit over the first two bans , which were partly overturned on the grounds that the original policy appeared to target Muslims. The court asked both sides to clarify whether the latest ban negated the stipulations of the earlier bans. Some immigration experts worry that the unpredictability of Trump\u2019s administration will be more of a deterrent to foreign students and researchers than the standard US visa bureaucracy has been up to this point. Immigrant scientists report longer delays in visa processing since Trump took office, and confusion about the constantly changing travel bans, says Brendan Delaney, an immigration attorney at Hill, Frank & Delaney in Bethesda, Maryland. \u201cThe uncertainty for people is probably the biggest issue,\u201d he says. \u201cI think people from many countries, not just Muslim-majority countries, exhibit a higher degree of concern because they don\u2019t know where this is going. There\u2019s just no way to know what\u2019s actually going on in the background.\u201d Delaney expects that someone will sue the Trump administration over the latest travel ban within the next few days, and that the case will eventually reach the Supreme Court. The court\u2019s ruling, he says, \u201cwill hopefully bring a finality to where we stand on this issue\u201d. \n                     Scientists in limbo as US Supreme Court allows modified travel ban 2017-Jun-26 \n                   \n                     What Trump\u2019s new travel ban means for science 2017-Mar-06 \n                   \n                     How the fallout from Trump's travel ban is reshaping science 2017-Mar-02 \n                   \n                     Trump immigration ban upends international work on disease 2017-Feb-01 \n                   \n                     Meet the scientists affected by Trump\u2019s immigration ban 2017-Jan-29 \n                   \n                     http://www.nature.com/news/trumppresident-1.21186 \n                   \n                     White House Proclamation on Enhancing Vetting Capabilities and Processes for Detecting Attempted Entry Into the United States by Terrorists or Other Public-Safety Threats \n                   Reprints and Permissions"},
{"file_id": "549319a", "url": "https://www.nature.com/articles/549319a", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Modelled on big physics projects, the International Brain Lab will bring together some of the world\u2019s pre-eminent neuroscientists to probe a single behaviour. Leading neuroscientists are joining forces to study the brain \u2014 in much the same way that physicists team up in mega-projects to hunt for new particles.\u00a0 The International Brain Lab (IBL), launched on 19 September, combines 21 of the foremost neuroscience laboratories in the United States and Europe into a giant collaboration that will develop theories of how the brain works by focusing on a single behaviour shared by all animals: foraging. The Wellcome Trust in London, and the Simons Foundation in New York City have together committed more than US$13 million over five years to kick-start the IBL.\u00a0 The pilot effort is an attempt to shake up cellular neuroscience, conventionally done by individual labs studying the role of a limited number of brain circuits during simple behaviours. The \u2018virtual\u2019 IBL lab will instead ask how a mouse brain, in its entirety, generates complex behaviours in constantly changing environments that mirror natural conditions.\u00a0 The project will use chips that can record the electrical signals of thousands of neurons at once. It will also use other emerging technologies, such as optogenetics toolkits that control neurons with light. \u201cIt\u2019s a new approach that will likely yield important new insights into brain and behaviour,\u201d says Tobias Bonhoeffer, a director of the Max Planck Institute for Neurobiology in Martinsried, Germany, who is also a Wellcome Trust governing-board member.\u00a0 Large-scale neuroscience projects are hardly rare. In 2013, the European Commission announced the 10-year Human Brain Project, which will cost more than \u20ac1 billion ($1.1 billion); and in 2014, US president Barack Obama launched the US Brain Initiative to develop neuro-technologies, with $110 million of funding that year. The Allen Institute for Brain Science, in Seattle, Washington, has been creating comprehensive maps of brain anatomy and neural circuitry since 2003. Japan, China, Canada and other countries also have, or are planning, their own big neuroscience initiatives. But none operates quite like the IBL, which will be governed in a similar way to large-scale physics projects such as ATLAS and CMS, at Europe\u2019s particle-physics lab CERN, which reported evidence for the Higgs boson in 2012. The two collaborations, at CERN\u2019s Large Hadron Collider near Geneva, Switzerland, brought together experimentalists and theoreticians from hundreds of labs worldwide to test the predictions of particle physics\u2019 standard model.\u00a0 Like the massive CERN teams, the IBL has created a flat hierarchy and a collaborative decision-making process with near-daily web meetings. Instead of acting only when group consensus is reached, teams will make decisions by simple consent. \u201cNo one will be able to stop a proposed experiment being carried out without a very convincing proposal of why it would be a disaster,\u201d says Alexandre Pouget, an IBL member and a theoretician at the University of Geneva in Switzerland. So far, says Andreas Herz, a theoretical neuroscientist at the Ludwig Maximilian University of Munich, Germany, \"neuroscience has been stuck in an exploratory phase\". The IBL will aim to generate and test unifying theories about how the brain encodes and computes information \u2013 seeking to come up with the equivalent of physicists\u2019 standard model. But the IBL is hardly unique among big neuroscience projects in melding theory and practice, points out neuroanatomist Katrin Amunts at the J\u00fclich Research Centre in Germany. Amunts also chairs the scientific board of Europe\u2019s Human Brain Project, an initiative that is taking a more conventional approach to collaboration in its own attempts to understand how the brain works. \u201cThe future will show which is the best,\u201d she says. The IBL\u2019s principal investigators, who include data-analysis experts as well as experimental and theoretical neuroscientists, will dedicate around 20% of their time to the effort. During its first two years, the IBL will build informatics tools for automatic data-sharing and establish a reliable experimental protocol for a basic foraging task in mice. Members will be required to register their experiments before they start, and results will be instantly visible to the whole collaboration. \u201cIt is a big challenge \u2014 and it\u2019s not the way the field works at the moment,\u201d says Anne Churchland, an IBL member at Cold Spring Harbor Laboratory, New York. In experimental neuroscience, the slightest parameter change can alter the outcomes of the experiment. The IBL\u2019s standard protocol attempts to address all possible sources of variability, from the mice\u2019s diets to the timing and quantity of light they are exposed to each day and the type of bedding they sleep on. Every experiment will be replicated in at least one separate lab, using identical protocols, before its results and data are made public.\u00a0 \u201cThis sort of approach will help solve the reproducibility crisis,\u201d says Christof Koch, president of the Allen Institute for Brain Science. Expanding the IBL beyond its pilot phase will require much more than $13 million, Pouget acknowledges. After the foraging protocol is established, the project\u2019s second phase will test specific theories relating to how the brain integrates diverse information to make moment-by-moment decisions. He also hopes to enrol many more labs and broaden the suite of behaviours studied. For Herz, a theoretician who is part of an influential computational-neuroscience network, it\u2019s about time neuroscience adopted such rigour. \u201cA hundred years from now,\u201d he says, \u201cpeople will look back and wonder why it hadn\u2019t, until now, been possible to do a more physics-based approach of designing experiments to consolidate or disprove theories.\u201d \n                     China launches brain-imaging factory 2017-Aug-16 \n                   \n                     How to map the circuits that define us 2017-Aug-09 \n                   \n                     Big brain projects urged to aid public health 2016-Nov-08 \n                   \n                     A better way to crack the brain 2016-Nov-08 \n                   \n                     Worldwide brain-mapping project sparks excitement \u2014 and concern 2016-Sep-21 \n                   \n                     Neuroscience: Solving the brain 2013-Jul-17 \n                   \n                     The International Brain Laboratory \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22626", "url": "https://www.nature.com/articles/nature.2017.22626", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Errors in past studies could undermine conservation plans. Many sharks are living much longer than was thought, according to a major review 1  of studies on these important and often endangered top predators. This means that many estimates of how threatened particular species are \u2014 and decisions about whether they can be fished safely \u2014 could be based on faulty data. Scientists usually estimate how old sharks are by slicing through their spines and counting distinctive pairs of bands seen inside, which are often assumed to show age in the same way as the rings of a tree. But a growing number of cases are suggesting that the method can be problematic. For example, a  2014 study 2  showed that sand tiger sharks ( Carcharias taurus ), which were thought to live for around two decades, can actually survive for up to twice that. And in 2007, researchers found 3  that New Zealand porbeagle sharks ( Lamna nasus ) had been under-aged by an average of 22 years. To investigate the scale of the problem, fisheries researcher  Alastair Harry  of James Cook University in Townsville, Australia, reviewed evidence for age underestimation. He reports in  Fish and Fisheries 1  that of 53 populations of sharks and rays for which there are good data, 30% have probably had their ages underestimated (see graphic). \u201cCurrent evidence points to it being systemic, rather than restricted to a few isolated cases,\u201d says Harry. \u201cWe really can\u2019t ignore it anymore.\u201d\u00a0 \n               Sharks aren\u2019t trees \n             Growth rings are used to determine age in fish of all kinds. In teleosts (a group that contains the majority of bony fish), researchers tend to look at otoliths, lumps of calcium carbonate in the inner ear that build up layers regularly throughout the fish\u2019s life. But sharks and rays don\u2019t have otoliths, so researchers often use sections of vertebrae instead. Sometimes, when sharks stop growing, so do their vertebrae, which means that counting the rings can make an animal seem younger than it is. Harry\u2019s paper looked at two methods of checking whether the age estimated from counting rings is correct: chemical marking and bomb-carbon dating. In the former, researchers capture an animal and inject it with fluorescent dye that is taken up by its spine, making a permanent mark. When the animal is recaptured later, it is possible to count how many bands have formed since this known date. In the second method, scientists can look for carbon traces of 1950s nuclear-bomb tests in animals that were alive then, and use this to estimate age. Harry has done \u201ca very nice job\u201d, says shark scientist  Steven Campana  of the University of Iceland in Reykjavik, who has worked on more than 100 ageing studies in sharks and rays, as well as in bony fish. \u201cI fully agree with his conclusions: the shark age-underestimation problem is indeed a big one.\u201d \n               Management headache \n             The study has wide-ranging implications, says Lisa Natanson, a fisheries biologist with the  US National Oceanic and Atmospheric Administration in Narraganset t, Rhode Island, who was one of the paper\u2019s reviewers. If age information is wrong, models that guide fisheries\u2019 decisions about how many animals can safely be caught will also be wrong. Key processes such as growth, mortality and reproduction change with age, although precisely what this means for conservation will vary with each species. On the one hand, if living longer means that an animal matures and starts reproducing later in life, underestimating age will mean that it is more vulnerable than has been realized. On the other, living longer might give animals more breeding years, making a population more robust. Emerging technologies could help to solve the ageing problem. Methods include looking at aspartic acid, an amino acid that is produced in living organisms in one of two forms, then slowly converts to the other in inert tissues through a process called racemization. Near-infrared spectroscopy could be useful too, says Natanson: \u201cComplete reliance on backbones has got to disappear.\u201d Reprints and Permissions"},
{"file_id": "nature.2017.22620", "url": "https://www.nature.com/articles/nature.2017.22620", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Researchers who worked with Florian Jaeger have filed a complaint with the US government after the university cleared his name. A sexual-harassment case in the sciences is rocking the University of Rochester in New York, prompting campus protests over the university's handling of allegations against linguist Florian Jaeger. Seven current and former faculty members of the brain and cognitive sciences department, along with a former graduate student, have filed complaints against the university with the US government. They allege that Jaeger, a full professor in the department, sexually harassed graduate students and postdocs and created a hostile work environment. They also allege that the university, which last year investigated the matter and twice cleared Jaeger of wrongdoing, retaliated against the faculty members who lodged the complaint. The reports involve at least 11 women who interacted with Jaeger at various points since he arrived in Rochester in 2007. Among other things, the complaints allege sexual encounters with graduate students, parties with students involving illegal drugs, and remarks Jaeger made about the sexual attractiveness of students in front of other faculty members. Jaeger is also accused of pressuring a female student into sharing a house with him and professionally isolating students who would not sleep with him. Since the details became public in an 8 September  news article in  Mother Jones , University of Rochester administrators have faced protests from students and others on campus. In response, its president, Joel Seligman, has said the university would hire an independent investigator to review claims of retaliation and new allegations in the complaints that were not reviewed earlier by the university. The university will also ask an independent evaluator to review its procedures for dealing with claims of harassment and discrimination, and set up a commission to explore  issues of women and gender in academia . Jaeger will remain off-campus for the rest of the current semester. He declined an interview request from  Nature . \u201cThis is a very extraordinary case,\u201d says Ann Olivarius, a senior partner at the McAllister Olivarius law firm in London who is licensed to practice law in multiple US states and is co-leading the legal case against the university. (Olivarius was one of the plaintiffs in the US lawsuit that established in 1980 that sexual harassment at a university constituted illegal discrimination.) \u201cIt\u2019s the first time in all the decades that I\u2019ve worked in this area,\u201d she says, \u201cthat senior faculty combined with junior faculty to make a stand and say, \u2018This behaviour is unacceptable and we need to do something about it'.\u201d The group filed its eight identical complaints \u2014 one per complainant \u2014 with the US Equal Employment Opportunity Commission (EEOC) beginning on 30 August. The commission is responsible for enforcing federal laws that make it illegal to discriminate against an employee because of their gender, among other factors. Richard Aslin, a developmental psychologist and member of the US National Academy of Sciences, resigned from the university in December in protest over its handling of the Jaeger investigation. He had worked at the university for more than three decades, including stints as a dean and as a vice-provost. Six of the seven other co-authors of the complaint have also left, or plan to leave, the university \u2014 most for reasons directly related to the incident. \n               Controversy on campus \n             In a 10 September statement, Seligman wrote that the core allegations \u201cwere investigated, appealed and found to be unsubstantiated\u201d. And in an e-mail to department members on 9 September, department chair Greg DeAngelis wrote, \u201cI want to assure you that [department] faculty and staff care deeply about the safety, security, and well-being of our students and the importance of a welcoming and safe workplace.\u201d (DeAngelis did not respond to  Nature 's request for comment on the matter.) But the university response did not go over well with many students, some of whom set up a Facebook page to protest the administration's handling of the case. On 12 September hundreds of them met for a heated three-hour town hall with Seligman; the following day, hundreds more turned out to protest in front of the university library. The protesters had been planning to turn out at Jaeger's undergraduate linguistics class, but another instructor has taken over that class for the rest of the semester. In a 12 September e-mail to students in that class, Jaeger wrote: \u201cI am incredibly sorry for the emotional turmoil you must be experiencing....I will likely respond in more in depth to the allegations against me,\u201d but \u201cit will take time to reply in a way that does not unwittingly cause harm to witnesses.\u201d Jaeger works on developing computational frameworks for language production and understanding, including how noise affects communication. He has won a number of prestigious fellowships and this summer co-directed a summer institute in cognitive neuroscience in Santa Barbara, California, that was sponsored by the Kavli Foundation of Los Angeles, California, and the US government. On 9 September, Jaeger had been scheduled to give the closing keynote address at the Architectures and Mechanisms of Language Processing conference at Lancaster University, UK. After the  Mother Jones  story appeared on 8 September, he and the conference organisers mutually agreed to cancel the talk, according to a university spokeswoman. Jaeger\u2019s behaviour came under scrutiny in early 2016, when he allegedly said at several faculty meetings that he saw no problem with faculty members dating students. Aslin and other faculty members began discussing the subject and discovered what they say is a string of sexual predations by Jaeger over the years. \u201cWe had all these concrete examples of something that we knew was wrong,\u201d says Jessica Cantlon, an associate professor in the department. She and Aslin led the formal complaint to the university on behalf of students, arguing that Jaeger had violated its policy against discrimination and harassment. The university investigated and concluded \u2014 initially, and then again after an appeal \u2014 that Jaeger had not violated any university policies. That included its policy on intimate relationships, which forbids such relationships between faculty members and any member of the university community over whom they exercise academic authority. While the university's investigation was underway, Jaeger was granted a full professorship. \n               Two investigations \n             The complainants say that the investigation did not gather enough information to accurately assess whether Jaeger violated university policies or not. \u201cThey must have a really peculiar definition of what sexual misconduct is, and one that doesn\u2019t align with the rest of the world,\u201d Cantlon says. The 11 women from whom the group gathered witness statements describe Jaeger \u2014 among other things \u2014 allegedly sending photographs of his genitalia, describing how a student should walk in front of him while reading manuscripts to him as he sat on a couch, and having loud sex with students within earshot of other students. \u201cThe problem isn\u2019t being sexual \u2014 the problem is doing that across boundaries that involve power and authority over people,\u201d says Elissa Newport, a cognitive psychologist at Georgetown University in Washington DC. As head of the University of Rochester brain and cognitive sciences department from 1998 to 2010, she hired Jaeger there; she is now among the complainants. \u201cIt\u2019s important for faculty members to understand that these are students in your charge, and you don\u2019t take advantage of that.\u201d After the initial investigation found that Jaeger had not violated any university policies, one of the complainants filed a separate complaint alleging that Jaeger had engaged in retaliatory behaviour against her. The university commissioned an external investigator, who found no evidence of retaliation. In the EEOC filings, the wider group of eight complainants now also alleges additional instances of retaliation. In one instance the department chair allegedly disparaged them in front of the entire department faculty; in another, provost Robert Clark sent a memo to the department\u2019s faculty criticizing what he called \u201crumors\u201d and \u201cmisinformation\u201d about the investigation. \u201cThe University considers the matter closed,\u201d he wrote. \u201cI affirm that Dr. Jaeger is a valued member of our faculty.\u201d The university will now look into these new allegations of retaliation. \u201cI think it shows that the original investigation was flawed,\u201d Cantlon says. \u201cLike the students said in the town hall, the university\u2019s claims and actions don\u2019t pass the smell test.\u201d (Sara Miller, a spokeswoman for the university, says that \u201cwe do not believe the original investigation was flawed\u201d.) The complainants allege that Rochester administrators searched their university e-mails without their knowledge, a step that Cantlon says was the last straw for her. Like the other complainants who are still on the department\u2019s faculty, she is looking for a new job. \u201cI was on a particular trajectory in my career that\u2019s been disrupted,\u201d she says. \u201cNow I\u2019ll move my whole laboratory, and go and try to start somewhere else.\u201d \n               Looking ahead \n             Erika Mar\u00edn-Spiotta, a biogeochemist at the University of Wisconsin\u2013Madison, says that sexual harassment can derail or even end the careers of many scientists. She is leading a US$1.1-million initiative funded by the US National Science Foundation  to develop strategies to help scientists respond to and prevent sexual harassment  on campus and in the field. \u201cWe so often hear that people don\u2019t know how to respond in these instances,\u201d Mar\u00edn-Spiotta says. She hopes her group can roll out tools in the next few years to help faculty members better intervene in incidents of sexual harassment involving graduate students in their departments. The Rochester case, she notes, is rare in having so many faculty members unite and come forward on behalf of their younger colleagues. The EEOC will now investigate the complaint \u2014 including a response yet to be filed by university administrators \u2014 and determine whether discrimination occurred. If the commission does find evidence of discrimination, it could attempt to broker a settlement with the university or pursue a legal remedy. In the meantime, Rochester is left to deal with a department in turmoil. Newport says that she and the other complainants  see larger principles at stake . \u201cThe main reason we decided to go public is because we wanted the university\u2019s processes to be reformed,\u201d she says. \u201cIt wasn\u2019t meant to be about Florian \u2014 it\u2019s meant to be about harassment and retaliation.\u201d \n                     More universities must confront sexual harassment 2017-Jul-26 \n                   \n                     How should science funders deal with sexual harassers? 2016-Feb-08 \n                   \n                     Change the system to halt harassment 2016-Feb-08 \n                   \n                     Harassment victims deserve better 2016-Jan-20 \n                   \n                     Sexual harassment must not be kept under wraps 2016-Jan-20 \n                   \n                     Astronomy roiled again by sexual-harassment allegations 2016-Jan-12 \n                   \n                     Berkeley releases report on astronomer sexual-harassment case 2015-Dec-19 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22649", "url": "https://www.nature.com/articles/nature.2017.22649", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Ancient crustaceans in dino dung from Utah illuminates herbivores\u2019 broad diet. Plant-eating dinosaurs usually found plenty to eat, but occasionally they went looking for a nutritional boost. Fossilized dinosaur poo from Utah now reveals the snacks that some of the animals were sneaking on the side 75 million years ago: prehistoric crayfish or crabs. The work suggests that big herbivorous dinosaurs sometimes munched on crustaceans to get extra protein and calcium into their bodies before laying eggs of their own, says Karen Chin, a palaeontologist at the University of Colorado Boulder. She and her colleagues report the discovery on 21 September in  Scientific Reports 1 . \u201cIt\u2019s a very unusual case of an herbivorous dinosaur supplementing its diet with something else,\u201d says Paul Barrett, a palaeontologist at the Natural History Museum in London. Direct evidence of dinosaur diets is hard to come by. Some fossil animals have been found with their gut contents intact, but fossilized dinosaur excrement \u2014 the most convincing remains of what a dinosaur actually ate \u2014 is rare. \u201cThink of a cow pat \u2014 these things get broken down in the environment very easily,\u201d says Barrett. Most of the fossilized dung, called a coprolite, that researchers uncover comes from meat-eating dinosaurs; it is better preserved than that of plant-eating dinosaurs thanks to minerals in the bones of the creatures that carnivores consumed. Chin has long hunted for coprolites from herbivorous dinosaurs. In 2007, she reported 2  finding fossilized chunks of rotting wood inside coprolites from the Two Medicine rock formation in Montana, which dates from between about 80 million and 74 million years ago. Plant-eating dinosaurs may have chewed the wood in search of insects and other organisms scurrying inside rotting logs, she proposed. Then, in 2013, she found many similar coprolites in the Kaiparowits Formation of Grand Staircase\u2013Escalante National Monument in southern Utah. Along with rotting wood, they contained puzzling fragments of thin, convex structures. When Chin examined slices of the structures under a microscope, they looked very much like the outer covering of a crustacean\u2019s leg or claw. She consulted Rodney Feldmann, a palaeontologist at Kent State University in Ohio, who confirmed that they probably came from a crayfish or crab. \n             Dietary supplement \n           At the time the Kaiparowits rocks formed, around 75 million years ago, the landscape was a wet, subtropical environment much like today\u2019s Texas coast. Chin thinks that local dinosaurs \u2014 probably the duck-billed group called hadrosaurs \u2014 would have occasionally chomped big mouthfuls of decaying wood in search of insects and other creatures within. \u201cYou get so many invertebrates hanging out in rotting logs,\u201d she says. \u201cThere\u2019s bugs to eat, and rotting detritus \u2014 it\u2019s a really rich place.\u201d The fungi that helped to break down the logs would also have provided extra protein. Dinosaurs probably snacked on the logs when they needed a digestive boost, Chin says. Some modern birds with mostly plant-based diets add insects and other sources of protein before they lay eggs, she notes. \u201cYou can\u2019t imagine a 20-foot hadrosaur going after a butterfly,\u201d Chin says. \u201cThey would go for some place that had a predictable, concentrated source of food \u2014 some place like rotting logs.\u201d The rotting wood probably wasn\u2019t a main source of dinosaur food year-round, says Jordan Mallon, a palaeontologist at the Canadian Museum of Nature in Ottawa. \u201cHadrosaurs were some of the biggest animals in their ecosystems, so they probably couldn\u2019t have afforded to be too selective about what they were eating anyway, lest they starve to death.\u201d Mallon thinks the dinosaurs might have accidentally snaffled up a crayfish or two while feeding, as opposed to seeking the crustaceans out on purpose. Either way, he says, the latest findings \u201cprovide an excellent glimpse in the lives of these animals, 75 million years ago\u201d. \n                   The snake that swallowed dinosaurs 2010-Mar-02 \n                 \n                   Water-dwelling dinosaur breaks the mould 2010-Feb-19 \n                 \n                   Fossil evidence of early reptiles' last meal 2009-Dec-23 \n                 \n                   Dinosaurs munched on grassy snacks 2005-Nov-17 \n                 \n                   Blog post: Fossil flying dino enjoyed tasty bird snack as last meal \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22624", "url": "https://www.nature.com/articles/nature.2017.22624", "year": 2017, "authors": [{"name": "Inga Vesper"}], "parsed_as_year": "2006_or_before", "body": "But overall data don't show a big impact on UK's involvement with European science. The number of researchers applying for Europe-funded Marie Curie fellowships in the United Kingdom has dipped slightly since the country\u2019s vote to leave the European Union, data released to  Nature  show. But there is no evidence yet of a sharp collapse in interest, which  some scientists had feared  in the wake of the Brexit referendum. Every year, the European Commission funds thousands of experienced researchers \u2014 most of them European \u2014 to undertake work in other EU countries, typically for one or two years, with individual fellowships usually worth between \u20ac150,000 (US$180,000) and \u20ac200,000. More than 9,000 academics have applied for the popular programme this year, in an application round that closed on 14 September. Of those, 1,997 people \u2014 around 22% of the total \u2014 requested to work in the United Kingdom. In 2016, the United Kingdom had received 2,211 applications, some 25% of the total that year; while in 2014, the UK share of applicants reached 28%. Although the numbers hint at a decline in interest in working in Britain, they give no clear sign that the Brexit vote has immediately dented the United Kingdom\u2019s attractiveness to EU scientists. But \u201cthe slipping success rates show that British science is not impenetrable, so we must not be complacent\u201d, says Mike Galsworthy, co-founder of the advocacy group Scientists for EU. He says the results may suggest that other European countries are increasingly attractive to researchers. \u201cIt is unreasonable to expect an immediate effect from Brexit. The university and research system in the UK is massive, and it will take many years for the system to bleed out and gradually lose its competiveness,\u201d says Andre Geim, a physicist at the University of Manchester, UK, who won a Nobel prize for his work in graphene. Geim  told Bloomberg News last month  that he hasn\u2019t received any applications under the Marie Curie scheme this year, unlike in previous years. But he is sponsoring two applicants who applied to work with his colleagues, he clarifies to  Nature . A spokesperson for the University of Manchester says that for the university as a whole, \u201cMarie Curie application numbers have remained consistent over the past four years. This includes 2017, and we have several being processed in graphene at the moment.\u201d \n             Strong starting grants \n           Other statistics on the United Kingdom\u2019s involvement in Europe-funded grant schemes since the Brexit vote give a more optimistic picture \u2014 although it isn\u2019t possible to conclude from any of the data whether changes in 2017 represent significant deviations from existing trends, notes statistician Michael Lavine at the University of Massachusetts Amherst. For example, Britain has seen a  negligible decline in its involvement in multinational European research collaborations  called Innovative Training Networks (ITNs) \u2014 which, similarly to the fellowships, are paid for under the Marie Sk\u0142odowska-Curie actions, a \u20ac6.2-billion slice of the European Commission\u2019s Horizon 2020 funding programme. In 2016, 78% of ITNs had at least one British partner; the 2017 awards \u2014 all of which were applied for after the Brexit vote \u2014 show a slight dip to 74%. And Britain has achieved its usual success in winning European Research Council (ERC) \u2018starting grants\u2019, awards of up to \u20ac1.5 million over 5 years for highly promising early-career researchers to start their own laboratories anywhere they wish. The United Kingdom secured 19.5% of the 406 starting grants awarded in 2017, up from 17% in 2016; its success rates have fluctuated between 17% and 20% in the past four years. UK nationals, relative to non-British Europeans, are making up an increasing proportion of the United Kingdom\u2019s starting-grant winners, however. This year, Britain is hosting 79 grantees under the scheme \u2014 more than any other EU country \u2014 and just under half (47%) are UK nationals. In 2014, UK nationals represented just over one-quarter of those with ERC starting grants in the United Kingdom. \n             Funding guarantee \n           Two months after the Brexit vote, the UK government  announced that it would underwrite EU grants  won before the date scheduled for the United Kingdom to leave the EU. This promise has reassured some European researchers that they can have a future in Britain even without EU membership, says evolutionary biologist Simone Immler, a Swiss national who  moved her ERC starting grant  to the University of East Anglia in Norwich, UK, despite the Brexit vote. Immler says that what really matters to researchers is getting their dream post, and that they will continue to come to the United Kingdom as long as there is a chance of this happening. \u201cThe beauty of these grants is they allow people to choose a host institution that they would like to go to, and they are likely to be offered a permanent position there,\u201d she says. \u201cBut if these grants stopped, it would hurt.\u201d Michael Browne, head of European Research and Innovation at University College London, says that the most important thing is to ensure that British researchers do not drop out of European projects as a result of the Brexit vote, even temporarily. He says that EU research consortiums are highly competitive, and if one partner leaves, another will quickly step in to plug the gap, which makes it hard to re-enter. \u201cThat\u2019s why my main message to researchers would be to, despite the uncertainty, really try to stay plugged into European platforms and networks,\u201d he says. \n                   A year on, Brexit brings lessons in uncertainty 2017-Jun-20 \n                 \n                   How Brexit is changing the lives of eight researchers 2017-Mar-29 \n                 \n                   Scientists should not resign themselves to Brexit 2017-Jan-04 \n                 \n                   UK government gives Brexit science funding guarantee 2016-Aug-15 \n                 \n                   E-mails show how UK physicists were dumped over Brexit 2016-Aug-05 \n                 \n                   Lessons from Brexit 2016-Jul-25 \n                 \n                   UK scientists in limbo after Brexit shock 2016-Jun-28 \n                 \n                   How scientists reacted to the Brexit 2016-Jun-24 \n                 \n                   How scientists reacted to Brexit \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22619", "url": "https://www.nature.com/articles/nature.2017.22619", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Data from spacecraft could help determine the age of Saturn's rings and the persistence of its magnetic field. At 4:55 a.m. California time on 15 September, hundreds of scientists watched their life\u2019s work go up in flames. The Cassini spacecraft disintegrated in Saturn\u2019s atmosphere\u00a0in a mission-ending move meant to keep the probe from contaminating the planet\u2019s moons, including Titan and Enceladus, that could harbor signs of life. Cassini\u2019s final images, transmitted in the hours before its death, included an evocative sequence of Enceladus setting behind Saturn, as well as a final close-up look at some of the planet's rings. The\u00a0spacecraft\u2019s\u00a0last radio signal died away Friday morning as planned\u00a0when the probe\u00a0entered the\u00a0atmosphere at about 113,000 kilometres an hour, roughly 10 degrees north of the planet\u2019s equator. As\u00a0Cassini\u00a0plunged to its death, it transmitted a last burst of data from its Ion and Neutral Mass Spectrometer. This instrument measures the chemical composition of gases, and provided scientists with their first direct taste of Saturn\u2019s atmosphere. That data \u201cwill be the most exciting result scientifically,\u201d says Ralph Lorenz, a planetary scientist at the Johns Hopkins University Applied Phyics Laboratory in Laurel, Maryland. \n               Hidden in the dust \n             But\u00a0the research team\u2019s work\u00a0is not yet over. Many discoveries about Saturn\u2019s moons, rings\u00a0and interior\u00a0are likely to emerge in the coming months. Since April,\u00a0Cassini\u00a0has\u00a0 carried out\u00a0a series of 22 orbits, looping between the giant planet and its rings  \u2014 a perspective never before captured. During these orbits, Cassini\u2019s Cosmic Dust Analyser, which looks at the size and composition of small particles, has been directly measuring the composition of material in Saturn\u2019s main rings for the first time, says Sascha Kempf, a space physicist at the University of Colorado Boulder. \u201cThe data set is rich and surprising,\u201d he says. \u201cStay tuned.\u201d The dust data also look set to answer a long-standing question: how old the rings are. By studying how dust falls onto the rings' icy particles and dirties them, the team can estimate how long the rings have been around. Some scientists argue that they date back billions of years, whereas others think that they are much more recent, on the order of 100 million years or fewer. \u201cPlease give us a few more days to verify our conclusions, but we are pretty sure that we know the age of the rings,\u201d Kempf says. This knowledge will help researchers to narrow down how they formed. Cassini\u2019s gravity measurements are helping researchers to pinpoint other key information about Saturn. By analysing the gravitational effect of the rings on Cassini \u2014 a force best measured as the probe plunges between the planet and the rings \u2014 researchers are narrowing down their estimates of the rings\u2019 mass, as well as the mass of the planet\u2019s core, says Luciano Iess, a planetary scientist at the University of Rome La Sapienza. The rings' mass can also be used to help tease out their age, since the more massive the rings, the older they may be. Preliminary analysis of data from Cassini's grand-finale orbits have given Iess and his colleagues their best estimate yet of the rings' total mass. \u201cWe cannot release any value yet,\u201d Iess says, \u201cbut this is the first indication that we have that probably the rings didn't form together with Saturn.\u201d By comparing those results with the estimate from Cassini's dust analyser, researchers hope to be able to settle the question of ring age once and for all. \n               A puzzling match \n             Cassini\u2019s magnetometer has already made some unexpected discoveries. Saturn\u2019s axis of rotation and its magnetic axis turn out to be almost perfectly aligned, says Linda Spilker, the mission\u2019s project scientist at NASA\u2019s Jet Propulsion Laboratory (JPL) in Pasadena, California. That has puzzled researchers, because models have suggested that there needs to be at least a slight offset between the two axes for the planet to maintain a magnetic field. The finding \u201csuggests that we don\u2019t really understand Saturn\u2019s internal structure and how the planetary dynamo is generated yet\u201d, says Michele Dougherty, a space physicist at Imperial College London. She estimates that it will take another three to six months to crunch through the data and understand exactly what they mean. Other potential discoveries will require researchers to put together all of Cassini\u2019s data sets from all of its instruments over its entire 13-year study of Saturn. That includes watching the planet and its moons change over time: \u201cWe have a whole half-season of changes on Saturn and Titan to study,\u201d says Bonnie Buratti, a planetary scientist at JPL. And finishing the geological mapping of Titan will enable researchers to better understand the moon\u2019s varied terrains, from its windswept dunes to its frozen mountains, says planetary scientist Rosaly Lopes, also at JPL. Cassini scientists have another year\u2019s worth of funding to tease more secrets out of the data. But after that, there are no US missions on the books to return to Saturn \u2014 unless researchers can persuade NASA or other space agencies otherwise. Scientists have submitted proposals to NASA to study Saturn and some of its moons, projects that will be up for consideration later this year as the agency decides on its next set of missions. \n                     Cassini\u2019s 13 years of stunning Saturn science \u2014 in pictures 2017-Aug-30 \n                   \n                     Saturn spacecraft begins science swan-song 2017-Apr-12 \n                   \n                     Dust reveals ancient origin for Saturn's rings 2014-Aug-19 \n                   \n                     First hints of waves on Titan's seas 2014-Mar-17 \n                   \n                     The Cassini mission \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22621", "url": "https://www.nature.com/articles/nature.2017.22621", "year": 2017, "authors": [{"name": "Mark Zastrow"}], "parsed_as_year": "2006_or_before", "body": "Controversy over vessel's name may impede oceanographic collaboration. South Korea\u2019s flagship research ship\u00a0 Isabu \u00a0seems to have sailed into a controversy with the Japanese government over its name. The incident has hindered some oceanographic research collaborations between the two countries. The ship\u2019s name refers to a sixth-century Korean general, Kim Isabu. In South Korea, he is known for his maritime conquests, which in some historical accounts included two islets that are the subject of a decades-long territorial dispute between South Korea and Japan. Known as Dokdo in South Korea and Takeshima in Japan, the small islets are located roughly midway between the two countries, more than 200 kilometres from each mainland. The 5,900-tonne ship launched late last year and\u00a0is currently cruising the Philippine Sea. Its name was an option in a public poll held by the ship\u2019s operator, the Korea Institute of Ocean Science and Technology in Ansan. The Japanese government has issued no formal protest over the ship\u2019s name, but four scientists in South Korea and Japan have told  Nature  that researchers at Japan\u2019s national marine-research agency have been instructed not to participate in any collaborations or cruises involving  Isabu . An e-mail sent in January by an official at the Japan Agency for Marine-Earth Science and Technology (JAMSTEC) in Yokusuka, and seen by  Nature , suggests that the order came from Japan\u2019s science ministry. The e-mail states that the ministry cancelled a proposed agreement to allow JAMSTEC researchers to collaborate on the ship. A senior researcher at JAMSTEC, who asked to remain anonymous, says that he and other JAMSTEC researchers have been told not to use the ship or any data it obtains. JAMSTEC\u2019s actions regarding  Isabu  seem to be directed from more-senior officials. An e-mail sent earlier this year from a JAMSTEC staff member to an employee of a government-supported research institute in South Korea that is involved with  Isabu  suggests that JAMSTEC is acting on the wishes of its supervising authority, the Japanese Ministry of Education, Culture, Sports, Science and Technology (MEXT). The e-mail said: \u201cWe have consulted MEXT on your request to add the collaboration on the research activities using your new research vessel \u2018ISABU\u2019, and got a negative answer from MEXT due to a non-scientific reason.\u201d The e-mail goes on to state that JAMSTEC cannot \u201ccarry out the collaboration using your new research vessel\u201d. When contacted by  Nature , the JAMSTEC staff member who sent the e-mail declined to answer questions. JAMSTEC president Asahiko Tairatold  Nature  that he had no knowledge of that specific e-mail, and he had not issued an order, or personally received one from the government, prohibiting the organization\u2019s involvement with  Isabu . But he says cooperation with South Korea using the ship \u201ccould be very difficult\u201d and would require permission from MEXT. \u201cThe name of  Isabu  is a little bit unfortunate,\u201d he says, but he adds that JAMSTEC will remain involved with an ongoing 16-nation collaboration to survey the region between the Indian and Pacific oceans, to which South Korea has committed  Isabu . Pulling out of the collaboration over South Korea\u2019s use of the ship would \u201cbe a pretty stupid thing to do\u201d, he says. MEXT\u2019s director of deep-sea research, Tatsuya Watanabe, says that the ministry had discussed the South Korean ship with JAMSTEC, but would not comment on whether the ministry had instructed JAMSTEC to avoid collaborations on the ship, or whether the ministry had an issue with the ship\u2019s name. So far, the controversy has disrupted at least one planned research project between researchers from both countries. A university-based Japanese marine scientist, who also asked for anonymity, says that he had planned a cruise on\u00a0 Isabu \u00a0in collaboration with JAMSTEC before the tensions arose. But the agency\u2019s researchers have since told him that JAMSTEC instruments cannot be used on\u00a0 Isabu . His project will go ahead without the equipment, reducing the data resolution. Sang-Mook Lee, a marine geophysicist at Seoul National University, says that disruptions to the two countries\u2019 research collaborations will restrict the ship\u2019s scientific capability. \u201cHad we known that the Japanese would react in such a way, I don\u2019t think Koreans would have chosen the name,\u201d he says. But the senior JAMSTEC researcher says that the dispute is unlikely to have a major impact on Japan\u2019s marine research because the country has its own research ships and marine projects. Even so, he is upset that the ship was given such a politically-charged name: \u201cScientists should be politically neutral.\u201d \n                 Additional reporting by Ichiko Fuyuno. \n               \n                     Heavy smog, a huge ship and a smashing record 2016-Nov-09 \n                   \n                     Yellow Sea talks raise hopes for marine science 2015-Dec-15 \n                   \n                     South Korean survey ships open up to science 2015-Jan-06 \n                   \n                     R/V Isabu \n                   \n                     KIOST \n                   \n                     JAMSTEC \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22687", "url": "https://www.nature.com/articles/nature.2017.22687", "year": 2017, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Mona Nemer is a former administrator at the University of Ottawa whose research has focused on cardiovascular problems. Canadian prime minister Justin Trudeau has appointed biochemist Mona Nemer as his country's chief government science adviser,  fulfilling his campaign promise to establish the position . Nemer was most recently vice-president of research at the University of Ottawa and director of the Molecular Genetics and Cardiac Regeneration Laboratory there. Her scientific work has focused on the genetics of cardiovascular disease and birth defects. In her new role, Nemer will have a budget of Can$2 million and report to Trudeau and science minister Kirsty Duncan. The country has been without a science adviser for nearly a decade; the last time such a post existed was from 2004 to 2008. The initial reaction to her appointment has been positive. \u201cI do know her and she\u2019s fantastic,\u201d says Jim Woodgett, a biologist at the Lunenfeld-Tanenbaum Research Institute in Toronto, who has advocated reforms to Canada's funding institute for health research. \u201cShe\u2019s tough, but very very fair. She has the stature, and trust of other scientists.\u201d \u201cShe\u2019ll do a great job,\u201d  tweeted  innovation-policy expert Rob Annan. And Arvind Gupta, former president of the University of British Columbia in Vancouver,  called  Nemer \u201can inspired choice\u201d. As chief science adviser, Nemer will\u00a0advise the government on ensuring that government science is publicly available and that scientists are able to speak freely about their work, according to the official job description. The adviser is also charged with ensuring that scientific analyses are incorporated into the government's decisions. \n             Welcome decision \n           Trudeau's centre-left Liberal government created the position in part as a response to the science community\u2019s dissatisfaction with the previous Conservative government headed by Stephen Harper between 2006 and 2015.  Under Harper, the government was accused of muzzling scientists  and sidelining scientific evidence in policymaking. Nemer's appointment has been a long time coming. Trudeau was elected in October 2015, and appointed Duncan as science minister weeks later \u2014  charging her with establishing the adviser post .  The job hunt started in December 2016 , and applications were in hand by mid-February 2017. It has taken the government more than six months to settle on a candidate. \u201cI\u2019m quite happy that they have finally appointed someone,\u201d says Debi Daviau, president of the Ottawa-based Professional Institute of the Public Service of Canada, the union for government scientists. \u201cIt\u2019s been a couple of years coming.\u201d  \n                   Survey reveals basic research in Canada is falling by the wayside 2017-Jun-28 \n                 \n                   Billion-dollar boost sought for Canadian science 2017-Apr-10 \n                 \n                   Canada budget falls flat with scientists 2017-Mar-23 \n                 \n                   Help wanted: Canada begins search for chief science adviser 2016-Dec-05 \n                 \n                   Scientific challenges loom for Canada\u2019s popular prime minister 2016-Oct-25 \n                 \n                   Canadian government biography of Mona Nemer \n                 \n                   Canadian government announcement of Mona Nemer's appointment \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22656", "url": "https://www.nature.com/articles/nature.2017.22656", "year": 2017, "authors": [{"name": "Mark  Zastrow"}], "parsed_as_year": "2006_or_before", "body": "Experiment traces how online encyclopaedia influences research write-ups. Wikipedia is one of the world's most popular websites, but scientists rarely cite it in their papers. Despite this, the online encyclopedia seems to be shaping the language that researchers use in papers, according to an experiment showing that words and phrases in recently published Wikipedia articles subsequently appeared more frequently in scientific papers 1 . Neil Thompson, an innovation scholar at the Massachusetts Institute of Technology in Cambridge, says that this finding runs counter to an academic culture that downplays Wikipedia\u2019s credibility as a knowledge source. \"Academia is fighting Wikipedia,\u201d he says. Many universities, including his own, warn students against citing the website as a source in assignments. But the study, posted\u00a0on the Social Science Research Network (SSRN) preprint server on 20 September and which Thompson co-authored, shows how Wiki articles can serve as constantly updated open access review articles. \u201cIn its best form, that\u2019s what Wikipedia could be,\u201d says Thompson. Thompson and co-author Douglas Hanley, an economist at the University of Pittsburgh in Pennsylvania, commissioned PhD students to write 43 chemistry articles on topics that weren\u2019t yet on Wikipedia. In January 2015, they published a randomized set of half of the articles to the site. The other half, which served as control articles, weren\u2019t uploaded. \n             Language mirror \n           By February 2017, the chemistry articles had together received more than 2 million views. The researchers then analysed the text of 50 of the highest-impact chemistry journals published by Elsevier to see whether the language used in scientific papers had shifted by November 2016, nearly two years after the Wikipedia articles were posted. Using text-mining techniques to measure the frequency of words, they found that the language in the scientific papers drifted over the study period as new terms were introduced into the field. This natural drift equated to roughly one new term for every 250 words, Thompson told  Nature . On top of those natural changes in language over time, the authors found that, on average, another 1 in every 300 words in a scientific paper was influenced by language in the Wikipedia article.\u00a0 The influence of Wikipedia was more apparent in less-cited journals than in the most well-known publications. The authors suggest that ideas and language first published on topics entirely new to science make their way into Wikipedia before feeding back into the literature in follow-up studies, published in less-frequently cited journals. When the authors analysed papers by the author's country, they found the effect was greater in lower-income countries compared to higher-income countries. Hanley says some authors may be more reliant on Wikipedia if they have limited access to expensive journals. In this way, Wikipedia serves as an equaliser, extending science to those with less resources, he says. \n             Encourage site updates \n           Adam Dunn, a data scientist at Macquarie University in Sydney, Australia, calls the study\u2019s randomized controlled trial an \u201cingenious\u201d idea. But he questions the authors\u2019 claim that Wikipedia is shaping the ideas of science. He thinks the study shows that scientists refer to Wikipedia as a way of standardizing their language when they write papers. \"It probably is showing an effect of Wikipedia, but I\u2019m not sure the claim is what they're suggesting,\u201d he says. But Pauline Zardo, who studies research translation and impact at the Queensland University of Technology in Brisbane, Australia, says that words are symbols of thought, and, to some extent, language reflects thinking. \u201cWhat they're trying to do is really tricky. I don\u2019t think you're going to get a perfect method for this.\u201d She praises the study, which has not yet been peer-reviewed, for pointing out that academics also seek out material written for general audiences. Thompson hopes that the study will encourage scientists to embrace Wikipedia and make it better. One way to improve the site would be for journals or funding agencies to require scientists to contribute to Wikipedia once their article is published, he says. The journal  RNA Biology  has done just that for one its sections since 2008, mandating that authors put RNA information updates on a set of Wiki-style pages that are automatically mirrored on Wikipedia. Paul Gardner, the journal\u2019s assistant editor-in-chief, based at the University of Canterbury in Christchurch, New Zealand, says that students, professionals and academics seem to be accessing and using the information \u2014 \u201cwe just haven\u2019t rigorously sought to prove this, as Thompson and Hanley appear to have done\". \n                   Wikipedians reach out to academics 2015-Sep-07 \n                 \n                   Publish in Wikipedia or perish 2008-Dec-16 \n                 \n                   The more, the wikier 2007-Feb-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22685", "url": "https://www.nature.com/articles/nature.2017.22685", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Researchers report chemical evidence of organisms that lived 3.95 billion years ago, but scepticism abounds. Ancient rocks in northeastern Canada could contain chemical traces of life from more than 3.95 billion years ago, a new study suggests 1 . If confirmed, the finding would be among the earliest known signs of life on Earth. To some, the work adds to growing evidence that the young Earth was teeming with many different kinds of organism. \u201cAccept it!\u201d says Dominic Papineau, a geochemist at University College London who, in March, co-authored a report of possible fossilized microbes from Quebec that date back at least 3.77 billion years 2 . But others are sceptical that the latest work will hold up to scrutiny. Many previous claims of ancient life  have been hotly contested  \u2014 in part because rocks that formed billions of years ago have been severely heated and squished, making the geological context hard to interpret, and in part because the chemical traces of life can be difficult to distinguish from reactions that do not involve living organisms. \u201cWhen I read this I thought, \u2018here we go again,\u2019\u201d says Martin Whitehouse, a geologist at the Swedish Museum of Natural History in Stockholm who, in 2002, co-authored a study 3  that criticized a similar report of ancient life in Greenland. \n             Rock block \n           The latest work investigated a set of rocks from northern Labrador, known collectively as the Saglek block. A team led by Tsuyoshi Komiya and Yuji Sano of the University of Tokyo visited the area between 2011 and 2013, fanning out among the rocky outcrops to gather samples while armed guards kept watch for polar bears. In the 28 September issue of  Nature , the researchers report analysing carbon isotopes in powdered rock and in individual graphite grains from the Saglek area. In some of the samples, they found relatively low amounts of the isotope carbon-13 compared to carbon-12, a lighter isotope with one less neutron in its nucleus. Organisms prefer to use carbon-12 to make organic compounds, and so material in which microbes once lived \u2014 like the Saglek rocks \u2014 becomes enriched in the lighter isotope. Finding evidence of life in these ancient, highly deformed rocks \u201cis surprising and exciting\u201d, says Komiya. He says that he and his group have ruled out other possible explanations for the skewed ratio of carbon isotopes, such as decomposition of the mineral siderite. And the graphite seems to have crystallized at roughly the same temperature as that experienced by the rocks around it as they were squeezed and heated, which suggests the graphite isn\u2019t just contamination that arrived later. In previous papers 4 , 5 , Komiya\u2019s team described the geological history of the Saglek block, and used uranium\u2013lead dating on ancient zircon crystals inside a type of metamorphic rock called gneiss to conclude that the gneiss was 3.95 billion years old. They say that the graphite containing hints of life must be at least that old, because it lies within rocks that are apparently shot through with \u2014 and thus presumably older than \u2014 the 3.95-billion-year-old gneiss. Yet that scenario prompts other scientists to raise a warning flag. \u201cThe graphite is in much younger sediment than the authors claim,\u201d say geologists Monika Kusiak of the Institute of Geological Sciences at the Polish Academy of Sciences in Warsaw and Daniel Dunkley of Curtin University in Perth, Australia, who have been working to unravel the geological history of the Saglek block. They argue that the rocks that are supposedly shot through with the gneiss are not, in fact, older than it. \u201cEverything else in this paper is resting on the geochronology, and the geochronology is just not well-founded,\u201d adds Whitehouse. \u201cIt\u2019s a house of cards.\u201d Komiya says that he stands by his team\u2019s interpretation. \n             Labrador links \n           The debate over the results resembles one that began in 1996, when a US\u2013Australian\u2013British team reported finding biologically altered graphite from at least 3.86 billion years ago inside grains of a mineral called apatite, in rocks on Akilia island off southwestern Greenland 6 . That work  was criticized on many fronts 7 , although some still argue that Akilia's rocks contain traces of ancient life. Labrador\u2019s ancient rocks, including the Saglek block, lie directly across the Labrador Sea from Greenland. \u201cThere are a lot of similarities,\u201d says Minik Rosing, a geologist at the Natural History Museum of Denmark in Copenhagen who has studied possible chemical traces of life in Greenland rocks 8 . \u201cIt's extremely complex geology.\u201d He applauds Komiya's team, but says that more remains to be done. \u201cIt's a good example of very sophisticated and high-quality analytical work,\u201d he says. But the rocks are so complicated, he explains, that the graphite being studied \u201ccould be as young as 2.7 billion years old, and still pass all the tests\u201d. \n                   Claims of Earth's oldest fossils tantalize researchers 2016-Aug-31 \n                 \n                   New candidates for oldest fossils 2011-Aug-21 \n                 \n                   Complex ecosystems arrived early 2006-Jun-07 \n                 \n                   Fresh study questions oldest traces of life in Akilia rock 2004-Jun-17 \n                 \n                   Tsuyoshi Komiya's homepage \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22658", "url": "https://www.nature.com/articles/nature.2017.22658", "year": 2017, "authors": [{"name": "April Reese"}], "parsed_as_year": "2006_or_before", "body": "Panda populations are rising, but the species has less living space today than three decades ago. The number of giant pandas in the wild is reportedly on the rise, and satellite data suggest that a steady decline in the species' habitat has been halted. But the same study shows that the iconic species' living space is becoming more fragmented by roads, and that the panda still has less habitat today than three decades ago, when it was first listed as endangered. In 2016, the International Union for Conservation of Nature (IUCN) downgraded giant pandas ( Ailuropoda melanoleuca ) from endangered to vulnerable, on the basis of a 2011\u201314 population survey by the Chinese government that reported 1,864 adult pandas, up from 1,596 in the early 2000s. But in a brief communication published on 25 September in  Nature Ecology and Evolution 1 , researchers warn Chinese officials not to be complacent. \u201cChina has made a great effort for conservation,\u201d says co-author Ouyang Zhiyun, an ecologist with the Chinese Academy of Sciences in Beijing. But he adds that this doesn\u2019t mean the panda is out of danger. The government's ground-based survey already hinted that the bears\u2019  habitat was fragmenting , with pandas living in 33 isolated populations compared to the previous count of 15. In the new study, Ouyang and colleagues used satellite data collected between 1976 and 2013 to measure changes in all available panda habitat in the six mountain regions in central China that comprise its range. They found that the bamboo forests in which the pandas live shrank by 4.9% between 1976 and 2001, to about 55,500 square kilometres. From 2001 to 2013, they increased slightly, by 0.4%. But overall, there was 1.7% less habitat in 2013 than when the species was listed as endangered in 1988. The habitat that remains is indeed more fragmented, mostly because of road construction. During the study period, the number of habitat units isolated by major roads and rivers tripled (see 'Breaking Point'). \n             Mixed blessings \n           The panda is now better off than it has been in decades, says co-author Stuart Pimm, a conservation ecologist at Duke University in Durham, North Carolina. Since 1999, the government has banned logging in many natural forests, and expanded the amount of bamboo forest protected in nature reserves. But other threats are worsening: \u201cThere are a lot more roads slicing and dicing panda habitat than there were 40 years ago.\u201d Ouyang concludes that the IUCN's decision to downgrade the panda's status to vulnerable was \"too soon\". But David Garshelis, a conservation biologist at the Minnesota Department of Natural Resources in Grand Rapids and co-chair of IUCN's Bear Specialist Group, disagrees. \"Panda habitat has been increasing since 2001,\" he says. \"There is simply no way to spin this as a bleak picture.\" Panda experts agree that continued protection and expansion of habitat is crucial to prevent panda numbers from slipping again. The study authors suggest designating key habitats and the corridors of land that connect them as mandatory conservation areas, and building tunnels in corridor areas, rather than roads. \n                   Experts question China's panda survey 2015-Feb-28 \n                 \n                   Conservation: China's national treasure 2010-Nov-24 \n                 \n                   Giant pandas bounce back 2006-Jun-20 \n                 \n                   IUCN's Bear Specialist Group \n                 \n                   Ouyang Zhiyun \n                 \n                   Stuart Pimm \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22690", "url": "https://www.nature.com/articles/nature.2017.22690", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Black-hole merger pinpointed with record accuracy by the LIGO and Virgo observatories. Physicists have announced their fourth-ever detection of gravitational waves, and the first such discovery made together by observatories in Europe and the United States. The Virgo observatory near Pisa, Italy, has been hunting for ripples in the fabric of space-time since 2007. But it was being upgraded at the time of  the historic first detection of gravitational waves  by the twin laboratories of Virgo\u2019s US cousin, the Advanced Laser Interferometer Gravitational-Wave Observatory (LIGO), and was also out of action for two  subsequent sightings . Virgo  rejoined the hunt this year  on 1 August, following a 5-year, \u20ac23-million (US$27-million) upgrade. And on 14 August, both it and LIGO picked up the gravitational vibrations emanating from a pair of rotating black holes, with masses of 31 and 25 times that of the Sun, as they merged together, physicists announced on 27 September at a press conference in Turin, Italy. The collision happened around 540 million parsecs (1.8 billion light years) away. Observing the event with three detectors, rather than LIGO\u2019s two, allowed researchers to dramatically increase the accuracy with which they can pinpoint the location and distance of the merging black holes. For the Virgo team that has spent more than 20 years working on the project, the sighting is vindication that the time and effort was worth it. \u201cIt\u2019s a big event for me,\u201d says Alain Brillet, a physicist at the University of the C\u00f4te d'Azur in Nice, France who co-founded Virgo. He began lobbying to build a European gravitational wave detector in 1980, and is now about to retire. \u201cIt\u2019s very nice to become sure that you have not worked for nothing,\u201d he says.\u00a0 \u201cWe have credibility. At least we can show that we make promises and we can deliver on our promises,\u201d adds Jo van den Brand, a physicist at the VU University Amsterdam and spokesperson for the Virgo Collaboration. This year's observation run ended on 25 August, and now both observatories are working on upgrades that should double their sensitivity. \u201cThis is just the beginning of observations with the network enabled by Virgo and LIGO working together. With the next observing run planned for late 2018, we can expect such detections weekly or even more often,\u201d says David Shoemaker, a physicist at the Massachusetts Institute of Technology in Cambridge and spokesperson for the LIGO collaboration. \n             Triple power \n           Named GW170814, after the day it was detected, the wave arrived first at LIGO\u2019s station in Livingston, Louisiana, as a ripple in space-time that  subtly shifted the relative lengths of two arms  of the detector as it passed. Just eight milliseconds afterward, the same wave swept past LIGO\u2019s second detector in Hanford, Washington, before arriving at Virgo six milliseconds later. With three detectors, physicists can be more precise about the wave's origin than was possible before. On the basis of the time that Earth\u2019s detectors received the signal, the teams triangulated the likely location of the source, whittling it down to a patch of sky that, as seen from Earth, appears about 300 times the size of the full Moon. That region is more than 10 times smaller than LIGO has managed to pinpoint for its previous sightings. Having three detectors also enables researchers to make a rough measurement of the wave\u2019s polarization \u2014 a property that describes how the wave propagates through space in three dimensions. This meant physicists could test a prediction made by Albert Einstein\u2019s theory of relativity, which, besides predicting gravitational waves, also implies that such waves should stretch and contract space in planes that lie at right angles to each other. The data from GW170814 seem to support this, Fr\u00e9d\u00e9rique Marion, a physicist at the Laboratory of Particle Physics in Annecy-Le-Vieux, France and member of the Virgo Collaboration, told journalists at the press conference. \u201cThis was the first opportunity to check this fundamental property of gravitational waves,\u201d she said. The same polarization measurement also indicates how the black holes\u2019 orbital plane (the plane on which they rotate around each other) is orientated with respect to Earth. Because this angle dictates how much gravitational-wave energy is emitted in Earth\u2019s direction, combining polarization with other data allowed researchers to derive a more precise estimate of total energy released by the event and so  reduce the error in their distance estimate . A  paper describing their findings  has been accepted for publication in  Physical Review Letters . Precisely targeting the origin of a gravitational-wave signal is a significant step forward, says van den Brand. Some events \u2014 such as a collision of two neutron stars \u2014 are expected to produce such ripples and could emit a wide range of other kinds of radiation as well. If telescopes could be trained to look in precisely the right place after such a detection, they could spot this, and help astronomers to learn much more about the cataclysmic events. Some 25 telescopes raced to observe the patch of sky after the latest sighting, but none saw any kind of electromagnetic radiation coming from the event. No such signals would be expected from colliding black holes, however. Simultaneously \u2018seeing\u2019 a neutron-star collision with conventional telescopes and \u2018hearing\u2019 it through the vibrations of gravitational waves would mark a new era of astronomy. Last month,  rumours swelled that the LIGO and Virgo teams might already have seen  colliding neutron stars : telescopes are known to have been trained on a specific patch of sky after being alerted to another potential gravitational-wave detection. But the collaborations have yet to confirm what, if anything, their observatories saw.  Additional reporting by Davide Castelvecchi. \n                   Rumours swell over new kind of gravitational-wave sighting 2017-Aug-24 \n                 \n                   LIGO\u2019s underdog cousin ready to enhance gravitational-wave hunt 2017-Feb-08 \n                 \n                   The black-hole collision that reshaped physics 2016-Mar-23 \n                 \n                   Gravitational waves: 6 cosmic questions they can tackle 2016-Feb-09 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22648", "url": "https://www.nature.com/articles/nature.2017.22648", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "When forced to compete for mates, some birds develop longer penises and others almost nothing at all. Male ducks respond to sexual competition by growing either an extra-long penis or a nub of flesh, a new study finds. The unusual phenomena occurred in two species studied: the lesser scaup ( Aythya affinis ) and the ruddy duck ( Oxyura jamaicensis ). It suggests that penis size \u2014 in line with many traits and behaviours meant to impress or allow impregnation of the opposite sex \u2014 involves a trade-off between the potential to reproduce and to survive. Patricia Brennan, an evolutionary biologist at Mount Holyoke College in South Hadley, Massachusetts, compared the penises of ducks kept in male\u2013female pairs to those housed with multiple males per female. The findings are published in a study on 20 September in  The Auk: Ornithological Advances 1 . \u201cIf they were alone with a female, the males just grew a normal-sized penis, but if there were other males around, they had the ability to change dramatically,\u201d Brennan says. \u201cSo evolution must be acting on the ability to be plastic \u2014 the ability to invest only in what is needed in your current circumstance.\u201d Because evolutionary success relies on reproduction, genitals are adapted to meet the varied circumstances that every animal faces. Some male ducks, for example, have penises in the shape of corkscrews to navigate the labyrinth-like vaginas of their female counterparts. An  earlier study  by Brennan found that females\u2019 anatomy evolved to prevent access to undesirable males who force copulation 2 . To mate successfully with their chosen partners, Brennan says, female ducks assume a posture that allows males to enter them fully and deposit sperm near eggs. \n               Close competition \n             However, evolutionary changes in the size of body parts are generally thought to happen over generations, not within an individual\u2019s lifetime. Brennan wondered whether ducks might buck this trend because some species\u2019 penises emerge anew every breeding season and degenerate afterwards. Similarly, acorn barnacles ( Semibalanus balanoides ) \u2014 hermaphroditic, shelled sea creatures cemented to rocks \u2014 generate their penises only when it's time to mate. Because they use their penises to grope for other barnacles to inseminate, the organ\u2019s length depends on the proximity of a barnacle\u2019s neighbours. Brennan and her colleagues fenced off habitats so that ducks would live either in pairs or in groups with almost twice as many males as females for two breeding seasons over the course of two years. The lesser scaups grew longer penises when they were forced to compete for females than when they were coupled up. A larger reproductive organ likely improves their chances of fertilizing an egg. But the results of the social environment on ruddy ducks were more complicated. During the first year, only the largest males in the groups grew long penises (about 18 centimetres each), whereas smaller males developed half-centimetre stubs. In the second year, smaller males grew normal-sized penises, but they lasted for just five weeks, whereas the largest males kept their penises for three months. \n               Stressed-out species \n             Clues may lie in the drama of ruddy-duck life. The birds have some of the largest penis-to-body ratios found in nature \u2014 with penises sometimes longer than their bodies. \u201cI can\u2019t imagine they could grow any longer,\u201d Brennan says. The birds have also been known to fight to the death, which suggests that smaller ruddy ducks might be too stressed to develop penises normally. \u201cBullying may increase stress hormones, and those could counteract the effects of androgen hormones\u201d that control penis growth, Brennan says. This response to stress could be adaptive. The same androgen hormones that trigger penis growth every season in birds also underlie colouration. They cause the duck\u2019s feathers to turn from dull brown to chestnut when it\u2019s time to breed, and their bills to go from grey to bright blue. To females, the wardrobe change signals a male\u2019s readiness. To neighbouring males, it foreshadows a fight. \u201cI think the small ones go through it quickly so that there\u2019s less danger of getting beaten up,\u201d Brennan says. The study is \u201creally interesting\u201d, says Charlie Cornwallis, an evolutionary biologist at Lund University in Sweden. \u201cThis suggests there is a cost to having a large penis because individuals are investing according to the competition they face from other males.\u201d Cornwallis says that few studies have investigated the effect of environmental and social conditions on penis size, and that these evolutionary trade-offs could be more common than imagined. Families who picnic at the Livingston Ripley Waterfowl Conservancy in Litchfield, Connecticut, where the study was conducted, overlook the birds\u2019 bargains as well. \u201cPeople watch the ducks on the weekends, but they have no idea what\u2019s really going on,\u201d Brennan says. \u201cI now have a love\u2013hate relationship with ducks.\u201d \n                     Female insect uses spiky penis to take charge 2014-Apr-17 \n                   \n                     Ostrich penis clears up evolutionary mystery 2011-Dec-08 \n                   \n                     The sex wars of ducks 2009-Dec-23 \n                   \n                     Livingstone Ripley Waterfowl Conservancy \n                   \n                     Patricia Brennan's website \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22684", "url": "https://www.nature.com/articles/nature.2017.22684", "year": 2017, "authors": [{"name": "Emma Young"}], "parsed_as_year": "2006_or_before", "body": "But elusive coconut-cracking rodent may already be close to extinction. Mammalogist Tyrone Lavery first heard stories about \u2018vika\u2019, a giant, coconut-cracking, tree-dwelling rat from the Solomon Islands, in 2010. After years of searching for the elusive animal, he has finally confirmed its existence, making it the first new rodent species to be described from the islands in more than 80 years. Lavery made ten separate survey visits to Vangunu island in the Western Province of the Pacific Ocean archipelago. But the only rat he could spot or capture was the introduced black rat ( Rattus rattus ). For years, the only non-anecdotal evidence he had that vika was real was a \u201creally big rodent pellet, too huge to be from a black rat\u201d, that he discovered on a hike in 2012. Just as he began to worry that the animal had gone extinct, a local conservationist gave him a call: a 46-centimetre-long, orange-brown rat had been collected from a felled tree. \u201cTo finally have vika in the hand was a very special feeling,\u201d says Lavery, a postdoctoral researcher at The Field Museum in Chicago, Illinois, and lead author on the paper that describes  Uromys vika  (in honour of the local name), published on 27 September in the  Journal of Mammalogy 1 . \u201cI\u2019m really excited by this animal,\u201d says Kristofer Helgen, a zoologist at the University of Adelaide, Australia, who has identified many new species. \u201cThe Solomons have an incredible rodent fauna,\" he says, but most of the species suspected of inhabiting the islands are known only from hearsay, or from historical evidence such as partly fossilized bones found in caves, or skulls and skins in museums, often dating back to the 1880s. \u201cThis is a first-class discovery.\u201d \n             Endangered \n           The animal that Lavery studied was found leaving a tree that had been felled by a commercial logging company. It died from its injuries, but was photographed. Hikuna Judge, a ranger with the Zaira Resource Management Area on Vangunu and the paper's second author, sent the rat on to Lavery, who at the time was at the Queensland Museum in Brisbane, Australia. By the time Lavery examined the animal, almost all of its soft tissues had decomposed. But the cranium was complete, and his examination of it, along with the partial skeleton, hair and mandible, and the results of a DNA analysis, showed that this was indeed a new species. Its closest known relatives, two giant silver-coloured rats, lived on Guadalcanal island, to the southeast. The rat was not weighed before it decomposed, but Lavery thinks that an adult  U. vika  probably reaches between 500 grams and 1 kilogram. As well as perhaps coconuts, it probably eats fruits and other nuts. Given that only about 80 square kilometres of primary forest remains on Vangunu, Lavery estimates that there may be no more than 100 of the animals left. The Solomon Islands, which lie about 1,600 kilometres northeast of Australia, are biologically isolated. More than half of the islands\u2019 mammals are found nowhere else in the world. Commercial logging is a major threat to their survival. \u201cI hope that Judge and Lavery continue documenting the fauna,\u201d says Jake Esselstyn at Louisiana State University in Baton Rouge, who was part of a team that found a new rat species on the island of Sulawesi, Indonesia, in 2013. \u201cI\u2019m sure there are more unknown mammals in the Solomons, and habitat loss could drive species to extinction before they are documented. There\u2019s a good chance that has already happened.\u201d \n                   Genetics probe identifies new Galapagos tortoise species 2015-Oct-21 \n                 \n                   Dolphins, diatoms and sea dragons join census of all known marine life 2015-Mar-12 \n                 \n                   The legacy of Lonesome George 2012-Jul-18 \n                 \n                   Tyrone Lavery \n                 \n                   Jacob Esselstyn \n                 \n                   Kristofer Helgen \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22667", "url": "https://www.nature.com/articles/nature.2017.22667", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}, {"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "A new coalition could face battles over gene editing and climate regulations. As Germany reels from an unexpected surge for the far right in the 24 September elections, researchers don\u2019t expect much effect on the country\u2019s  generous support for science . But with smaller parties standing to gain political influence, battles over issues such as the regulation of gene-edited organisms and how to cut greenhouse-gas emissions could grow fiercer. Angela Merkel is set for a fourth term as Germany\u2019s chancellor and will lead negotiations with other parties to form a coalition government, after her centre-right Christian Democratic Union (CDU) won the largest share of the seats in parliament, albeit with a diminished lead. Her coalition partner in the last government, the Social Democrats (SPD), came second, but it, too, lost support, and has pledged to move into opposition. Other minor parties are instead expected to enter government, in negotiations that Merkel hopes to complete by the end of the year. Merkel has ruled out \u2014 as being too radical \u2014 partnerships with the far-right AfD (Alternative for Germany) party and the socialist Left Party. Most expect her to strike an agreement with the Green Party and the liberal Free Democrats (FDP). That would form a \u2018Jamaica coalition\u2019, named as such because the parties\u2019 colours match the green, yellow and black of the Jamaican flag. (A fourth party, the CSU, shares a platform with Merkel's CDU; it campaigns only in Bavaria). The negotiations are expected to focus on hot political issues, such as Germany\u2019s handling of the refugee crisis. All four parties strongly support science, but there are some key differences. The Greens want the same strict regulation for organisms that have been gene edited with precision technologies such as CRISPR, as has been put in place for those modified with conventional, less precise techniques. But the other three parties have hinted that they may support a more liberal form of regulation. Overall, Germany already tightly regulates research on genetically modified organisms (GMOs), and animals in general, and is unlikely to tighten that further under a new government, says Tobias Erb, a director at Germany\u2019s Max Planck Institute for Terrestrial Microbiology in Marburg. \u201cBut I do expect that it will remain complicated, and might even get more complicated, to release GMOs \u2014 and in particular GM plants \u2014 if the Greens become part of the next government coalition,\u201d he says. \n               Power struggles \n             Germany\u2019s climate and energy policies could be another area of conflict within a future coalition, says Oliver Geden, a policy expert with the German Institute for International and Security Affairs in Berlin. The Greens want to shut down the country\u2019s dirtiest coal power plants, and support a climate-protection law to help Germany meet its plans to reduce greenhouse-gas emissions by 80\u201395% from 1990 levels by 2050. But the FDP, a pro-business party in favour of free-market economics, advocates against detailed central planning to force cuts to carbon dioxide emissions \u2014 of the sort that has previously been proposed both by the Greens and by the outgoing CDU/SPD coalition. The FDP does favour eliminating \u201cinefficient\u201d subsidies in the energy sector and strengthening the European emissions-trading scheme. \u201cWe should expect a lot of ambiguity, even hypocrisy, when it comes to climate policy,\u201d says Geden. The strong presence of the AfD in parliament will make for noisy debates. Having won 13% of votes, the party is now the third largest after the SPD and CDU/CSU. The AfD did not make election statements on science, and declined to answer  Nature \u2019s questions before the election, but party leaders have previously expressed climate scepticism and distrust of genetic engineering. The AfD\u2019s rise means that for the first time, a party is represented in parliament that opposes Germany\u2019s plans to cut greenhouse-gas emissions by moving to renewable-energy sources \u2014 termed the \u2018 Energiewende \u2019, or energy transition. But its sceptical stance on climate and energy issues is unlikely to sway the next government, Geden says. \n                     Academic excellence: Golden Germany 2017-Sep-06 \n                   \n                     Germany must go back to its low-carbon future 2017-Sep-06 \n                   \n                     The secret to Germany\u2019s scientific excellence 2017-Sep-06 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22654", "url": "https://www.nature.com/articles/nature.2017.22654", "year": 2017, "authors": [{"name": "Carrie Arnold"}], "parsed_as_year": "2006_or_before", "body": "The brainless marine creatures are the simplest organisms known to seek slumber. The physiological purpose and evolutionary origins of sleep are among the biggest mysteries in neuroscience. Every complex animal, from the humblest fruit fly to the largest blue whale, sleeps \u2014 yet scientists can\u2019t explain why any organism would leave itself vulnerable to predators, and unable to eat or mate, for a large portion of the day. A study now moves science a step closer to answering this question by documenting, for the first time, sleep-like behaviour in a brainless jellyfish. Researchers observed that the rate at which  Cassiopea  jellyfish pulsed their tentacles decreased by one-third at night, and the animals were much slower to respond to external stimuli such as food or movement during that time. When deprived of their night-time rest, the jellies were less active the next day. \u201cEveryone we talk to has an opinion about whether or not jellyfish sleep. It really forces them to grapple with the question of what sleep is,\u201d says Ravi Nath, the paper\u2019s lead author and a molecular geneticist at the California Institute of Technology (Caltech) in Pasadena. The study was published on 21 September in  Current Biology 1 . \u201cThis work provides compelling evidence for how early in evolution a sleep-like state evolved,\u201d said Dion Dickman, a neuroscientist at the University of Southern California in Los Angeles. \n             Mindless sleep \n           Nath has studied sleep in the worm  Caenorhabditis elegans , but whenever he presented his work at research conferences, other scientists scoffed at the idea that such a simple animal could sleep. The question got Nath thinking: how minimal can an animal\u2019s nervous system get before the creature lacks the ability to sleep? Nath\u2019s obsession soon infected his friends and fellow Caltech PhD students Michael Abrams and Claire Bedbrook. Abrams worked on jellyfish, and he suggested that one of these creatures would be a suitable model organism, because jellies have neurons but no central nervous system. Instead, their neurons connect in a decentralized neural net. Cassiopea  jellyfish, in particular, caught the trio\u2019s attention. Nicknamed the upside-down jellyfish because of its habit of sitting on the sea floor on its bell, with its tentacles waving upwards,  Cassiopea  rarely moves on its own. This made it easier for the researchers to design an automated system that used video to track the activity of the pulsing tentacles. To provide evidence of sleep-like behaviour in  Cassiopea  (or any other organism), the researchers needed to show a rapidly reversible period of decreased activity, or quiescence, with decreased responsiveness to stimuli. The behaviour also had to be driven by a need to sleep that increased the longer the jellyfish was awake, so that a day of reduced sleep would be followed by increased rest. Other researchers had already documented a nightly drop in activity in other species of jellyfish, but no jellyfish had been known to show the other aspects of sleep. In a 35-litre tank, Nath, Abrams and Bedbrook tracked the tentacle pulses of  Cassiopea  over six days and nights and found that its pulse rate, which was an average of one pulse per second by day, dropped by almost one-third at night. They also documented night-time pulse-free periods of 10\u201315 seconds, which didn\u2019t occur during the day. \n             Restless night \n           Without an established jellyfish alarm clock, the scientists used a snack of brine shrimp and oyster roe to try to rouse the snoozing  Cassiopea . When they dropped food in the tank at night,  Cassiopea  responded to its snack by returning to a daytime pattern of pulses. The team used the jellyfish\u2019s preference for sitting on solid surfaces to test whether quiescent  Cassiopea  had a delayed response to external stimuli. They lifted the jellyfish off the bottom of the tank and released it into the water. It took longer for the creature to begin pulsing and to reorient itself when this happened at night than it did during the day. If the experiment was immediately repeated at night, the jellyfish responded as if it were daytime. Lastly, when the team forced  Cassiopea  to pull an all-nighter by keeping it awake with repeated pulses of water, they found a 17% drop in activity the following day. \u201cThis work shows that sleep is much older than we thought. The simplicity of these organisms is a door opener to understand why sleep evolved and what it does,\u201d says Thomas Bosch, an evolutionary biologist at Kiel University in Germany. \u201cSleep can be traced back to these little metazoans \u2014 how much further does it go?\u201d he asks. That\u2019s what Nath, Abrams and Bedbrook want to find out. Amid the chaos of finishing their PhD theses, they have begun searching for ancient genes that might control sleep, in the hope that this might provide hints as to why sleep originally evolved. \n                   The secret lives of jellyfish 2016-Mar-22 \n                 \n                   Why a jellyfish is the ocean's most efficient swimmer 2013-Oct-07 \n                 \n                   Neuroscience: Idle minds 2012-Sep-19 \n                 \n                   A biological clock to wind them all 2012-May-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22655", "url": "https://www.nature.com/articles/nature.2017.22655", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Giant observatory announces long-awaited result. The Pierre Auger Observatory in Argentina finally has solid evidence that the most energetic particles in nature come from sources outside the Milky Way. Scientists have suspected this for decades, but weren\u2019t able to confirm it \u2014 until now. \u201cFor the first time, we have proof that the highest-energy cosmic rays are of extragalactic origin,\u201d says Alan Watson, a UK astronomer and co-founder of the observatory. The result comes as a relief to the researchers, after previous claims regarding their origin made ten years ago by the Pierre Auger Collaboration subsequently turned out to be premature. The international team analysed 12 years\u2019 worth of data, and found that particles in the upper range of energies were more likely to come from a region of the sky outside the Milky Way\u2019s disk. That asymmetry is roughly consistent with  the distribution of neighbouring galaxies , the researchers report in the 22 September issue of  Science 1 . The study does not pinpoint individual sources of the cosmic rays, or explain how they reach their highest energies. But the researchers hope that it is a first step towards understanding their origins. \n               Invisible shower \n             Most cosmic rays are protons or other charged particles, including atomic nuclei as heavy as iron. When such a particle rains onto Earth's upper atmosphere and collides with an atomic nucleus in the air, it produces a shrapnel burst of subatomic particles. These hit other nuclei and produce more particles, generating an invisible \u2018shower\u2019 that is often spread over many square kilometres by the time it hits the ground. To detect these showers, the Pierre Auger Observatory has 1,600 car-sized water tanks placed at 1.5 kilometre intervals, to cover 3,000 square kilometres of grassy plains in Argentina\u2019s Mendoza province. Four sets of telescopes monitor the sky over the array, and \u2014 on moonless nights \u2014 can detect flashes of ultraviolet light generated by the showers. From its location relatively close to the equator, the array can pick up cosmic rays coming from the entire southern sky as well as from much of the northern sky, covering 85% of the celestial sphere. The observatory needs to be that big in order to catch enough of the most sought-after particles. Cosmic rays have been detected with energies beyond 10 20  electronvolts (eV); by comparison, the Large Hadron Collider near Geneva, Switzerland, the world's most powerful particle accelerator, pushes protons to just 7 \u00d7 10 12  eV. However, cosmic rays become increasingly rare the higher their energies. A particle in the 10 20  eV range, on average, hits a square kilometre of Earth only once per century. The researchers looked at 32,187 particles that had energies above 8 \u00d7 10 18  eV, detected by the observatory from its beginning in 2004 until 2016. The Galaxy's magnetic field bends the paths of charged particles, which can randomize their direction by the time they hit Earth. But these particles were still 6% more likely than average to come from a particular region of the sky, which is outside the Milky Way\u2019s disk. \n               Surprise skew \n             Most researchers expected a skew, but not such a strong one, says Piera Ghia, an astroparticle physicist at the CNRS Institute of Nuclear Physics in Orsay, France, who helped to coordinate the data analysis. Astrophysicist Francis Halzen of the University of Wisconsin\u2013Madison agrees. \u201cIt\u2019s really very big. To me, it was a surprise,\u201d says Halzen, who is spokesperson for IceCube, a major neutrino observatory at the South Pole. When magnetic deflection is taken into account, the asymmetry seen by the Pierre Auger Observatory is consistent with the distribution of galaxies lying within 90 megaparsecs (around 300 million light years) or so from the Milky Way, says Silvia Mollerach, an Auger astrophysicist at the Balseiro Institute in San Carlos de Bariloche, Argentina. The results strongly disfavour the supermassive black hole at the centre of the Milky Way as a major source of the higher-energy particles. \u201cThe most likely sources continue to be the usual suspects,\u201d Mollerach says: astrophysical phenomena that generate extremely intense magnetic fields, inside which charged particles can pinball around and gain energy. These include active galactic nuclei \u2014 supermassive black holes spewing jets of matter at near-light speed \u2014 and the stellar explosions called \u03b3-ray bursts. The latest claim is quite conservative compared to one that the collaboration made in 2007. Back then,  it found a correlation  between 27 extremely high-energy cosmic rays (above 57 \u00d7 10 18  eV) it had seen up until that point and a set of known active galactic nuclei 2 . The paper caused a sensation, but the statistical significance of the result was weak and soon  melted away as the array collected more data . \u201cIn retrospect, it was a mistake that we published too early,\u201d says Auger spokesperson Karl-Heinz Kampert, a physicist at the University of Wuppertal in Germany. This time, the team took no chances: it accumulated much more data and is confident that the results are solid, Kampert says. Halzen agrees. \u201cI don't think there is any doubt about the statistical significance\u201d of the latest results, he says. Now that the researchers have more data, they will again try to find correlations with potential sources. The results of that study should appear within a few months. The collaboration also plans to join forces with a smaller observatory in Utah, the Telescope Array, to try to map the origins of cosmic rays across the entire sky. The Pierre Auger Observatory is also in the initial stages of a US$12-million upgrade that should enable it to better measure the relative abundance of protons and heavier nuclei in the flux of cosmic rays. \n                     Earth's new address: 'Solar System, Milky Way, Laniakea' 2014-Sep-03 \n                   \n                     Cosmic-ray theory unravels 2010-Feb-22 \n                   \n                     Cosmic-ray source still in doubt 2007-Nov-19 \n                   \n                     High-energy cosmic rays traced to source 2007-Nov-09 \n                   Related external links Reprints and Permissions"},
{"file_id": "549443a", "url": "https://www.nature.com/articles/549443a", "year": 2017, "authors": [{"name": "Jo Marchant"}], "parsed_as_year": "2006_or_before", "body": "Biologists rush to study creatures living beneath Larsen C ice shelf before they disappear. Biologists are racing to secure a visit to a newly revealed region of the Southern Ocean as soon as it is safe to sail there. One of the largest icebergs ever recorded broke free from the Larsen C ice shelf on the Antarctic Peninsula in July. As it moves away into the Weddell Sea, it will expose 5,800 square kilometres of sea floor that have been shielded by ice for up to 120,000\u00a0years. If researchers can get to the area quickly enough, they\u2019ll have the chance to study the ecosystem beneath before the loss of the ice causes it to change. \u201cI cannot imagine a more dramatic shift in environmental conditions in any ecosystem on Earth,\u201d says Julian Gutt, a marine ecologist at the Alfred Wegener Institute for Polar and Marine Research in Bremerhaven, Germany. It is difficult for Antarctic scientists to respond quickly to sudden events, because polar-research vessels are usually booked months, if not years, in advance. A German research mission led by Boris Dorschel, head of bathymetry at the Alfred Wegener Institute, was already scheduled to visit the Larsen area and will now include a biodiversity survey of the exposed region in March 2019.\u00a0 Hopes for reaching the region this Antarctic summer lie with the British Antarctic Survey (BAS) in Cambridge. The agency has a fast-track proposal sparked by the calving event, led by BAS senior biodiversity scientist Katrin Linse, to send a research vessel in early 2018. The proposal is now being considered by a British funding council. South Korean researchers are also considering whether to divert a mission currently planned for the South Shetland Islands, says Hyoung Chul Shin, a biological oceanographer at the Korea Polar Research Institute in Incheon. If the BAS proposal is successful, it will be the first time marine biologists have been able to explore such an ecosystem so soon after the break-up of the ice. Nearby sections of ice shelf, at Larsen A and Larsen B, broke away in 1995 and 2002, respectively. But it was several years before the ocean cleared of sea ice and biologists could safely visit the area. Gutt was first in with a detailed survey, leading a team of about 50 scientists on the German research vessel  Polarstern  in 2007. The group sampled hundreds of species in areas exposed by the break-ups at Larsen A and B, and saw signs of a unique ecosystem with more deep-sea species than elsewhere on the Antarctic continental shelf (J. Gutt  et al. Deep-Sea Res. II   58,  74\u201383; 2011). But other species were already moving in, including fast-growing sea squirts, krill and minke whales. \u201cBy then, a lot had happened,\u201d says Linse. Getting to the Larsen C exposed region before it starts to change is crucial, says Gutt, to see what a sub-ice-shelf ecosystem looks like. Video footage taken by geophysicists on a US Antarctic Program cruise at the Larsen B site in March 2005 had unexpectedly showed most of the sea floor covered with a white mat, which the team interpreted as a layer of sulfur-eating microbes, as well as large clams, which were also chemotrophic\u00a0\u2014\u00a0that is, living on energy sources other than the Sun. It was the first report of a chemotrophic ecosystem in the Antarctic. But when the  Polarstern  arrived two years later, Gutt\u2019s team saw only dead clamshells and a layer of decaying plant matter and sediment. One thing the researchers won\u2019t have to worry about is disturbance from commercial fishing fleets. The Larsen C region is the first area to be protected by a 2016 agreement by the multinational Commission for the Conservation of Antarctic Marine Living Resources (CCAMLR) to automatically designate any areas of ocean exposed by the collapse or retreat of ice shelves as a Special Area for Scientific Study. This prohibits commercial fishing\u00a0\u2014\u00a0of the Antarctic toothfish, for example\u00a0\u2014\u00a0for an initial period of two years. Ice shelf break-up events could become much more common with climate change, says Andrea Kavanagh, director of the Pew Charitable Trusts\u2019 Global Penguin Conservation Campaign in Washington DC, and the CCAMLR protection will allow scientists to monitor how these changes affect wildlife. \u201cIt\u2019s really important to be able to separate the effects of fishing versus climate,\" she says. Biologists will discuss research priorities for Larsen C and future exposed regions at a swiftly organized meeting at Florida State University\u2019s Coastal and Marine Laboratory in St Teresa on 18\u201319 November. Meanwhile, Linse\u2019s team is waiting to learn whether the BAS mission proposal will be approved, and monitoring the iceberg in satellite images. \u201cWe need the wind to blow the iceberg out a bit more and to blow the sea ice out of there,\u201d says BAS spokeperson Athena Dinar.\u00a0 \n                 Tweet \n                 Follow @NatureNews \n               \n                     New Antarctic iceberg echoes old problem 2017-Jul-14 \n                   \n                     Giant crack in Antarctic ice shelf spotlights advances in glaciology 2017-Feb-20 \n                   \n                     Antarctic seas in the balance 2012-Oct-17 \n                   \n                     Letting the light in on Antarctic ecosystems 2007-Feb-28 \n                   Related external links \n                     \n                         Polarstern \n                       \n                   \n                     Project MIDAS \n                   Reprints and Permissions"},
{"file_id": "549439a", "url": "https://www.nature.com/articles/549439a", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Even before getting their own lives settled, teams collect information on storm behaviour and their effects on the ecosystem. When Hurricane Irma tore through Florida in early September, 40\u00a0scientists took shelter in the Archbold Biological Station, a fortified research facility in the south-central part of the state. They huddled there with friends, family and pets while floods and pounding winds destroyed homes across the state. It will take months for those researchers and others to assess the extent of the destruction left behind by both Irma and Hurricane Harvey, which blasted through the Caribbean and the Gulf of Mexico.\u00a0 But even as they try to get their own lives in order, scientists across the region have already started gathering data that they hope will improve understanding of how these extreme storms behave, how to improve public safety and how delicate ecosystems react. It is fairly rare to see such intense hurricanes hitting the US mainland, says Joshua Wurman, a meteorologist at the Center for Severe Weather Research in Boulder, Colorado. When they made landfall, Harvey and Irma were category\u00a04 storms \u2014 the second most extreme rating on a scale of 1 to 5 \u2014 and their swirling winds were of particular interest to Wurman and his team. So the researchers drove an instrument called a Doppler-on-wheels (DOW) to Texas and Florida to collect data from the eyes of both hurricanes.\u00a0 The DOW is a mobile Doppler radar dish bolted onto the back of a flatbed truck that scientists position in the path of hurricanes and tornados. It takes high-resolution measurements of wind speed and direction, as well as the speed and quantity of precipitation, in real time.\u00a0 Wurman and his colleagues measured a surprising mosaic of wind speeds in Harvey and Irma. Some pockets within the hurricanes had wind speeds of up to 225\u2009kilometres per hour (140\u2009miles per hour), nearly 30% higher than those of nearby pockets. \u201cIn Harvey, 140-mile-per-hour gusts were ripping apart buildings and throwing cars,\u201d says Wurman. Understanding where the most extreme winds will materialize in a hurricane can help to improve the accuracy of public warnings, he says. \n               Shelter in place \n             The DOW crew was able to leave Texas and Florida soon after gathering the data. But the scientists who took shelter in the Archbold Biological Station \u2014 which is nestled in the headwaters of the Everglades wetland region in Venus, Florida \u2014 live and work in the state.\u00a0 Evelyn Gaiser, an aquatic ecologist at Florida International University in Miami, was one of the researchers who weathered Irma at the station. After the storm, she says, \u201cwe were all outside collecting data\u201d.\u00a0 Roughly 50 researchers work from the station throughout the year, says biologist Hilary Swain, Archbold\u2019s executive director. Their projects range from monitoring the area\u2019s lakes and ecosystems to carrying on a long-term observational study of a population of Florida scrub jays ( Aphelocoma coerulescens ) listed as threatened by the federal government. Initial checks on the birds found that they had weathered Irma just fine. Gaiser studies nearby Lake Annie, and found that Irma had upended its temperature profile. Normally, layers of warm water rest on top of cooler layers \u2014 but the hurricane brought colder waters to the surface. In the next few months, Gaiser will be monitoring whether or not that inversion has affected the lake\u2019s plant communities. Another priority for Gaiser is checking on a long-term ecological research project that she oversees in Everglades National Park in south Florida. Officials closed the park on 6\u00a0September in preparation for Irma and started re\u00adopening certain areas on 21 September. Gaiser is not sure when her team will be able to access the project\u2019s sites.\u00a0 Increased amounts of salt water, carried in by storm surges, can disrupt the delicate balance of fresh- and saltwater systems that shape the region. \u201cFresh water is the lifeblood of the Everglades,\u201d Gaiser says. She is anxious to see how the mix of water from the storm surge, rain and run-off has affected the health of the wetlands, and is planning to submit a proposal for a rapid-response research grant from the US National Science Foundation to help collect those data. \n               Salting a marsh \n             Merryl Alber, a marine ecologist at the University of Georgia in Athens, will be taking similar measurements at sites for her own long-term ecological research project on Sapelo Island, a barrier island off the Georgia coast that was also affected by Irma. In an ongoing experiment in the island\u2019s freshwater marshes, her team adds diluted salt water to 6.25-square-metre plots to simulate salinity increases from rising sea levels, storm surges or droughts.\u00a0 After Irma, Alber returned to Sapelo briefly to check her experimental sites. She found that a 1.5-metre-high storm surge had raised salinity to 5 times the base levels in the artificially salted sites.\u00a0 Irma\u2019s storm surge was a naturally occurring amplification of the experiment that Alber and her team have been doing for years, and Alber plans to compare its effects with their past findings. But that will take time. The labs and some of the researchers\u2019 homes on the island flooded during the storm.\u00a0 The team will follow through on its annual data collection at the long-term research sites, says Alber. But with so much destruction in the region, her work isn\u2019t the only thing on her mind. \u201cIt\u2019s a little less the science we\u2019re worried about. It\u2019s the people.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     How labs are coping with Hurricane Harvey's devastating floods 2017-Aug-31 \n                   \n                     Hurricane Katrina\u2019s psychological scars revealed 2015-Aug-24 \n                   \n                     Stress: The roots of resilience 2012-Oct-10 \n                   \n                     Hurricanes are getting fiercer 2008-Sep-03 \n                   Related external links Reprints and Permissions"},
{"file_id": "549442a", "url": "https://www.nature.com/articles/549442a", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Despite close timing, researchers doubt that the first big tremor set off the second. When a magnitude-7.1 earthquake struck central Mexico on 19\u00a0September, seismologists immediately wondered whether the tremor had any connection to the much larger jolt that hit off the country\u2019s west coast 12\u00a0days earlier. Preliminary studies suggest that there is no direct link, but the pair of events this month has drawn renewed attention to Mexico\u2019s seismic hazards. The two quakes struck in a geologically surprising area \u2014 in the middle of the Cocos tectonic plate. This piece of Earth\u2019s outer shell dives beneath the North American plate off the country\u2019s Pacific coast, which is where most of the region\u2019s quakes tend to occur. But farther to the east, beneath Mexico itself, the Cocos plate flattens out for hundreds of kilometres under the North American plate before taking a second, steeper dive into Earth\u2019s depths. This month\u2019s quakes happened at two different spots in this flat section, owing to geological stresses from the weight of the plate as it plunges downward. \n               Shifting ground \n             The 19\u00a0September earthquake, which has killed more than 320 people, struck about 120\u00a0kilometres south of Mexico City, much of which is built on an ancient lake bed. That location makes the city vulnerable because tremors shake the sediments like a bowl of jelly ( V.\u00a0M. Cruz-Atienza  et\u00a0al. Sci. Rep .  6,  38807; 2016 ).\u00a0 At the National Autonomous University of Mexico (UNAM) in Mexico City, scientists clocked the highest ground accelerations recorded at the site since measurements began in 1964, says Victor Cruz-Atienza, head of the UNAM seismology department. The acceleration was nearly double that seen on 19 September 1985, when a magnitude-8.0 quake along the coast of Michoacan sent seismic energy rippling into the capital, killing more than 5,000\u00a0people. Because the epicentre of the 19\u00a0September 2017 quake was so much closer to Mexico City than the one in 1985, which struck 350 kilo\u00admetres away from the city, the shaking was much stronger. At least 45 buildings collapsed in the capital after last week\u2019s quake. If the 19\u00a0September tremor had lasted longer, the damage and death toll could have been even worse. UNAM calculations suggest that the magnitude-7.1 quake ruptured a section of the Cocos plate about 40\u00a0kilometres long and took only about 10\u00a0seconds, says Cruz-Atienza, so structures didn\u2019t shake for long enough to cause more of them to fall. Building regulations have also been considerably strengthened since the 1985 disaster. Some 95\u00a0people lost their lives in the magnitude-8.1 quake on 7\u00a0September. It was Mexico\u2019s largest earthquake in more than a century, tearing about 80\u00a0kilometres of the Cocos plate and lasting for more than 40\u00a0seconds. \n               Looking for links \n             The occurrence of two earthquakes in such a short time in the middle of the Cocos plate had some scientists wondering whether they could be linked. But others are sceptical: \u201cWe don\u2019t think there is a causal relationship between the events,\u201d says Cruz-Atienza.\u00a0 In the long term, big earthquakes can increase the risk of nearby seismic activity by transferring stress within Earth\u2019s crust to adjacent geological faults. But that sort of \u2018static stress\u2019 transfer would normally not happen at a distance as great as the 650\u00a0kilometres between the first and second quakes, says Gavin Hayes, a seismologist at the US Geological Survey in Golden, Colorado. Initial calculations by seismologists Ross Stein at Temblor \u2014 a California technology firm in Redwood City that runs an earthquake education app \u2014 and Shinji Toda of Tohoku University in Sendai, Japan, suggest that the static-stress increase after the first quake was negligible.\u00a0 A large earthquake can also set off another by \u2018dynamic triggering\u2019 as its seismic waves ripple outwards, affecting geological faults at much greater distances than static-stress transfer does. But dynamic triggering usually happens within hours or days of the initial quake, making the 12-day gap between the 7\u00a0September event and the 19\u00a0September tremor hard to explain, says Eric Fielding, a geophysicist at NASA\u2019s Jet Propulsion Laboratory in Pasadena, California. \u201cIf that happened, the question is why it waited so long to go,\u201d he says.\u00a0 \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     Pair of deadly Mexico quakes puzzles scientists 2017-Sep-20 \n                   \n                     Deadly Mexico earthquake had unusual cause 2017-Sep-09 \n                   \n                     The 24/7 search for killer quakes 2015-Jul-08 \n                   \n                     Earthquake tests 25 years of Mexican engineering 2012-Mar-22 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22628", "url": "https://www.nature.com/articles/nature.2017.22628", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "One gene draws the lines while a second fills in the colours. The brilliant, intricate patterns on butterfly wings \u2014 from haunting eye spots to iridescent splashes of blue \u2014 look as if they were painted on by teams of artists. Researchers thought that a complex collection of genes might be responsible, interacting to build up the final pattern. But two studies now suggest that two genes play an outsize role in determining the wing\u2019s lines and colours. Turning off these 'master' genes disrupts the canvas, dulling the colours or turning the insects monochromatic. The studies published this week in  Proceedings of the National Academy of Sciences 1 , 2 , challenge the old paradigm of wing-pattern development, says Bob Reed, an evolutionary developmental biologist at Cornell University in Ithaca, New York, and lead author of one of the papers 2  and a co-author on the other 1 . Understanding how wing patterns are controlled gives scientists greater insight into the evolution of traits that  help the insects to avoid predation  and attract mates.  \u201cThe two different genes are complementary. They are painting genes specialized, in a way, for making patterns,\u201d says Arnaud Martin, a developmental biologist at George Washington University in Washington DC, and lead author of one of the studies 1 . \u201c This is a visually compelling illustration of the power of genetic studies,\u201d says Rodolphe Barrangou, a microbiologist at North Carolina State University in Raleigh. \u201cEveryone can relate to butterflies, and this literally illustrates how altering genomes with CRISPR can provide insights into biology.\u201d \n             Fade away \n           Previous studies that used conventional genetic mapping and knock-out genes showed that  WntA  and  optix  are involved in wing-pattern development. The work showed that the two genes are \u2018adaptive hotspots\u2019, because they are linked to physical changes in the organism that appear to be adaptations to their environment. The researchers used the  CRISPR\u2013Cas9 technique  to tinker with  WntA  and  optix  in several butterfly species. Scientists switched each of the genes on and off to demonstrate how much influence they had over what appeared on the butterflies\u2019 wings. The new  WntA  study 1  involved seven species of butterfly, including the charismatic monarch butterfly ( Danaus plexippus ). In most species, when  WntA  was switched off, colours bled, patterns faded or markings disappeared. In the monarchs, for example, deep-black contouring at the wings\u2019 edges lightened to grey.  WntA  sets borders and boundaries, says Martin. \u201cIt\u2019s laying the background to be filled in later. Like colour by numbers or paint by numbers. It\u2019s making the outlines.\u201d The  optix  study 2  showed that this 'paintbrush gene\u2019, as Reed calls it, has a large role in pigmentation. Previous work had suggested that it was involved in red and orange colour patterns, but it took CRISPR to finally confirm that, says Reed. He and his colleagues knocked out  optix  in four butterfly species. Parts of the wings \u2014 as well as other areas of the butterflies\u2019 bodies \u2014 turned black or grey. \u201cOne went entirely jet black,\u201d says Reed, citing an example of an individual gulf fritillary ( Agraulis vanillae ). Most surprising, Reed says, in the common buckeye ( Junonia coenia ), its wings also developed spots of bright, iridescent blue, an indication of structural change beyond pigmentation. \n             A bigger role \n           The results indicate that  optix  affects colouring in a way that goes beyond simple pigmentation. Iridescence is created by certain microscopic structural features of the wing scales, so  optix  seems to be influencing both the pigment and  the architecture  of butterfly wings. The work provides \u201cemerging evidence to show that this gene has probably played a huge role in wing evolution\u201d, Reed says. The more researchers are able to learn about  WntA  and  optix , the more insight they will gain into butterfly evolution. These genes probably provide the framework for major adaptations, including mimicry \u2014 in which organisms copy the attributions of others in order to deceive predators as a defence mechanism, says Reed. The monarch and viceroy butterflies ( Limenitis archippus ) are textbook examples of mimicry 3 . \u201cIt\u2019s a beautiful advance and it shows you the strength of the CRISPR approach that seems to apply to any species,\u201d says developmental neurobiologist Claude Desplan of New York University. \u201cFor us who are studying butterflies, which are non-traditional organisms for a laboratory, CRISPR is opening a treasure chest of opportunities we haven\u2019t had before,\u201d says Martin. \n                   CRISPR's hopeful monsters: gene-editing storms evo-devo labs 2016-Aug-17 \n                 \n                   Welcome to the CRISPR zoo 2016-Mar-09 \n                 \n                   CRISPR: gene editing is just the beginning 2016-Mar-07 \n                 \n                   Butterfly disguise down to single gene 2014-Mar-05 \n                 \n                   Butterflies shine brighter by design 2005-Nov-17 \n                 \n                   Butterflies boast ultrablack wings 2004-Jan-28 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22585", "url": "https://www.nature.com/articles/nature.2017.22585", "year": 2017, "authors": [{"name": "Mark Zastrow"}], "parsed_as_year": "2006_or_before", "body": "Regulations are deterring research that could lead to disease treatments, say scientists. More than a decade after a  fraud scandal in stem-cell science rocked South Korea , scientists in the field are ramping up pressure on the government to relax the country\u2019s strict regulations on human-embryo research \u2014 which many researchers label a ban. On 30 August, the nation\u2019s bioethics committee held a public forum with the Ministry of Health and Welfare in Seoul, inviting 11 researchers and scholars to discuss possible changes to the country\u2019s bioethics policies on research. \u201cWe need to revise the relevant laws and institutions urgently,\u201d Jin-Soo Kim, a genome engineer at the Institute for Basic Science in Daejeon, South Korea, said at the forum. He says the regulations were made before researchers started using gene-editing tools such as CRISPR\u2013Cas9. In South Korea, such tools cannot be used in embryos, and only in extremely limited cases can they be inserted into the body, under conditions that researchers say are impossible to meet. Given the technology\u2019s  potential to treat a range of diseases , clinical and embryo testing will be needed, he says. Gene editing experiments on human embryos have been undertaken in a number of countries including China, the United States, the United Kingdom and Sweden. But some bioethicists are warning the government against making rash changes to the law without public consultation. Ahead of the forum, local media reported that a separate, government-convened panel of researchers, ethicists and religious scholars was on the verge of recommending to the government that it lift its restrictions on human-embryo research. But the health ministry\u2019s bioethics division told  Nature \u2019s news team that there is no plan to revise the current regulations. \n               Bioethics history \n             In 2004,\u00a0Woo Suk Hwang, then at Seoul National University, claimed to have produced human stem cell lines from cloned human embryos. In response to public debate,\u00a0South Korea's Bioethics and Biosafety Act came into effect\u00a0a year later in 2005, restricting\u00a0research on human embryos to scientists who are granted a licence from the national bioethics committee. Initially,\u00a0Hwang\u2019s was the\u00a0only team granted approval.\u00a0Then, in 2006, Hwang\u2019s results were  found to be fabricated  and he was later  convicted of embezzlement  and bioethics violations, such as buying human eggs in violation of the bioethics law. Although regulations for human-embryo research were in place before the scandal, approvals for new research efforts effectively ceased after it, amounting to a de facto ban, say many researchers. Since then, the only team to have received a licence for embryonic-stem-cell projects is one led by Dong Ryul Lee, a developmental biologist at CHA University in Seoul. Lee says the rules forced him to look abroad to continue his research. In South Korea, his team is limited to using surplus eggs from  in vitro  fertilization that have been cryogenically frozen. Freezing eggs can reduce the effectiveness of the cloning technique in which the egg is inserted with DNA from another person, says Lee, making it harder to obtain stem cells from the resulting embryo. Researchers prefer to use fresh eggs sourced directly from donors, he says. In 2014, Lee\u2019s group reported 1  the cloning of human embryonic stem cells. But the work was carried out at CHA\u2019s satellite facilities in Los Angeles, California, using eggs collected for research purposes from donors in the United States, where there are no federal legal restrictions on embryonic stem cell research. Lee wants South Korea\u2019s laws to be amended so that Korean researchers can work with fresh eggs from donors. Removing barriers to using eggs from Korean donors is more than a matter of convenience, says Bonghee Lee, a proteomicist at Gachon University. It would also encourage scientists to study the developmental mechanisms of genetic illnesses that are more likely to affect east Asian populations. Because Lee cannot work on Korean embryos, he collaborates with researchers in Tehran to study illnesses that are specific to the local population, using surplus eggs from the infertility clinic at the city\u2019s Royan Institute. Kim acknowledges that it could take years to make changes to the regulations, which would require new legislation to pass through South Korea\u2019s parliament. \u201cIt seems that the public hearing is a step forward for a long journey.\u201d \n                     Doubts raised about CRISPR gene-editing study in human embryos 2017-Aug-31 \n                   \n                     CRISPR fixes disease gene in viable human embryos 2017-Aug-02 \n                   \n                     CRISPR tweak may help gene-edited crops bypass biosafety regulation 2015-Oct-19 \n                   \n                     Stem cells made by cloning adult humans 2014-Apr-28 \n                   \n                     South Korea steps up stem-cell work 2012-May-01 \n                   \n                     South Korea's National Bioethics CommitteeSouth Korea's National Bioethics Committee \n                   \n                     South Korea's Bioethics and Safety Act \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22586", "url": "https://www.nature.com/articles/nature.2017.22586", "year": 2017, "authors": [{"name": "Emiliano  Rodr\u00edguez Mega"}], "parsed_as_year": "2006_or_before", "body": "US Geological Survey says tremor was within the Cocos Plate, not at the plate boundary. A deadly magnitude-8.2 earthquake struck the southern coast of Mexico on 7 September, killing dozens of people and injuring at least 200. The tremor, which Mexican President Enrique Pe\u00f1a Nieto said was the strongest registered in the past century, prompted mass evacuations along the country's Pacific coast. Scenes of demolished buildings, teetering streetlight posts and blacked-out subway stations have been circulating on social media. Mexico\u2019s Federal Commission of Electricity calculates that 1.85 million residents across the country were affected by power cuts. According to the National Seismological Service of Mexico, the quake hit the Gulf of Tehuantepec near the state of Chiapas just before midnight local time. The country\u2019s earthquake early-warning system  gave residents anywhere from a few seconds to more than a minute of warning,  depending on their proximity to the tremor\u2019s epicentre. In Mexico City, more than 725 kilometres away, that amounted to 86 seconds of advance notice. Mexico City resident and agronomist Obed Mej\u00eda Y\u00e1\u00f1ez was in a 23rd-floor apartment at the moment alarms went off in his building. \u201cI was writing my thesis when it hit. The lights went on and off, and the windows began to crack,\u201d he says. \u201cI said \u2018this is it\u2019 and even thought about jumping out the window. I got very scared. I had never felt an earthquake like this.\u201d Although buildings in the capital suffered some structural damage, the southern states of Oaxaca, Chiapas and Tabasco were the most affected, with more than 30 confirmed deaths. In Oaxaca, patients were evacuated to the streets in hospital beds and several buildings collapsed, including the city hall in Juchit\u00e1n. The region where the earthquake struck is one of the most active seismic zones in the country: this is where  the Cocos Plate  dives, or subducts, under the North American plate. \u201cEarthquakes of this size are not uncommon at subduction zone boundaries,\u201d notes Jascha Polet, a seismologist at California State Polytechnic University in Pomona. But this quake was different: it occurred within the Cocos plate as it warped or bent, not at the boundary with the North American plate, according to  the US Geological Survey. \u201cThe type of faulting that occurred here does not usually produce earthquakes of this magnitude,\u201d says Polet. \u201cThere have been others in the past 50 years of similar type and location, but none that was even close to this size.\u201d It is still too early to say why the earthquake was so massive, she adds, but \u201cit is sure to inspire much future research\u201d. Mexico\u2019s seismology agency has registered at least 337 aftershocks, with the strongest reaching a magnitude of 6.1.  \n                   In Japan, small shakes presage big quakes 2016-Jan-28 \n                 \n                   The 24/7 search for killer quakes 2015-Jul-08 \n                 \n                   Gravity map uncovers sea-floor surprises 2014-Oct-02 \n                 \n                   Earthquake tests 25 years of Mexican engineering 2012-Mar-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22587", "url": "https://www.nature.com/articles/nature.2017.22587", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Gene expression suggests that marsupials have mammary glands that function like placentas. Wallabies are kicking over scientific conventions surrounding mammalian placentas, the organ responsible for protecting and nourishing a developing fetus. A study 1  finds that contrary to what scientists thought previously, mother tammar wallabies ( Macropus eugenii ) have both a functioning internal placenta and milk that performs some of the organ\u2019s functions. Taxonomists usually separate marsupials \u2014 including kangaroos, wallabies and wombats \u2014 from placental mammals, also known as eutherians, such as mice and people. The separation is based partly on a perceived lack of a placenta in marsupials. But some researchers think that this distinction is incorrect, noting that marsupials develop simple, placenta-like structures during the end of pregnancy, just before the underdeveloped baby crawls from the uterus into the mother\u2019s pouch. These structures, just two cell layers thick, provide oxygen and nutrients to the fetus while protecting it from the mother\u2019s immune system. Marsupial pregnancy is remarkably short for a mammal. Tammar wallabies are pregnant for just 26 days \u2014 barely longer than rats. Yet the baby, or joey, spends nearly a year continuing to develop and nurse inside the mother\u2019s pouch: a long time compared to other mammals. This developmental mismatch led researchers to suspect that the majority of the baby\u2019s development was driven by specialized features of the mother\u2019s milk. The current study suggests that the milk consumed by the joey acts as a kind of late-stage placenta. \n             Mother's milk \n           To determine whether the marsupial placenta functions like a mammalian one, evolutionary biologist Julie Baker and evolutionary developmental biologist Michael Guernsey at Stanford University in California, analysed the collection of genes expressed from the tammar wallaby\u2019s placenta and compared it to those of mice and humans. They found that in the final days before the foetus is born, the tissue expressed the same genes as eutherian placentas do in the early stages of fetal development. The researchers then analysed the genes expressed in the mammary glands of tammar wallabies that were nursing joeys. They found that this tissue expressed the same genes as eutherian placentas do in late fetal development. The mammary tissue also permanently shut off one copy of a gene called  Igf2  through a process called imprinting, which has never before been seen in any tissue other than the embryo and placenta. \u201cThis is beautiful work,\u201d says Anthony Carter, a developmental biologist at the University of Southern Denmark in Odense. He says it provides a convincing argument that marsupials, contrary to common belief, have fully functioning placentas. The finding suggests that placentas across the animal kingdom could express the same suite of genes, which is surprising given that even closely related species\u2019 placentas may look very different anatomically, says Guernsey. Those differences, however, could be because the placenta evolves rapidly compared with other organs. Baker thinks the rapid evolution could be due to the fact that the placenta shields the fetus from the mother\u2019s immune system, which treats it as a foreign invader. \u201cThe placenta is evolving trying to evade the mom, and comes up with these really bizarre strategies\u201d, including taking liquid form in the mother marsupial\u2019s milk, she says. The finding also shows that placentas could be even more diverse within the animal kingdom than previously thought. Knowing more about its development could not only help researchers understand animal evolution but also the possible functions of the human placenta, which is impossible to study in real time since it would be supporting a foetus. \n                   NIH invests US$41.5 million in placenta research 2015-Feb-27 \n                 \n                   Australia's big hop into genomics 2008-Nov-21 \n                 \n                   The awesome opossum gets sequenced 2007-May-09 \n                 \n                   A wallaby school of self-defence 2001-Jul-17 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22588", "url": "https://www.nature.com/articles/nature.2017.22588", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Geological processes send more meltwater from glaciers and ice sheets to Earth's mid-latitudes. As an ice sheet melts, it leaves a unique signature behind. Complex geological processes distribute the meltwater in a distinct pattern, or 'fingerprint', that causes seas to rise unevenly around the world. Now, for the first time, researchers have observed what  these sea-level fingerprints  look like on a global scale. \u201cNo one has put it together for a complete global picture like this before,\u201d says James Davis, a geophysicist at Columbia University in Palisades, New York. The work was published in  Geophysical Research Letters  on 9 September 1 . The concept of sea-level fingerprints has been been factored into  models used to predict sea-level rise  for several years, says lead researcher Isabella Velicogna, a geophysicist at the University of California, Irvine. And researchers have used tide gauges for just as long to observe the fingerprints in coastal regions. But the global view provided by the latest study adds confidence to projections of future sea-level rise. Ice sheets and glaciers have a slight gravitational pull on the water that surrounds them, making sea level a little higher at their edges \u2014 similar to how the Moon tugs on the ocean to generate tides, but on a fraction of the scale. When a glacier or ice sheet melts, it loses mass; therefore, the gravitational pull it exerts on nearby ocean water weakens and the sea level falls. At the same time, the land rises up because the ice is no longer weighing it down, which causes a further drop in sea level. The loss of mass changes Earth's gravitational field causing the fresh meltwater and ocean water to move away towards faraway coastlines; the resulting pattern of sea-level rise is the fingerprint of melting from that particular ice sheet or glacier. For example, the latest study found that ice melt in Antarctica causes sea level to rise 52% faster in California and Florida than it does in other parts of the world, Velicogna says. Much of Earth\u2019s middle and lower latitudes bear the brunt of rising sea levels because they\u2019re sandwiched between Antarctica and Greenland, which are home to massive ice sheets that are shedding mass as meltwater or icebergs. Velicogna and co-author Chia-Wei Hsu, also at the University of California, Irvine, used gravity data from NASA's two Gravity Recovery and Climate Experiment (GRACE) satellites, which measure changes in mass on Earth\u2019s surface. The scientists looked at satellite data from April 2002 to October 2014, and matched it with measurements from pressure stations on the ocean floor. These instruments measure the total mass above them. Velicogna says that the findings should be used to create a roadmap for better placement of ocean-bottom pressure stations, which in turn can be used to improve calculations of sea-level fingerprints in the future. \u201cWe know sea-level change throughout the world won\u2019t be uniform, and it\u2019s useful for people to know how those changes might show up,\u201d says Mark Tamisiea, a geophysicist at the University of Texas at Austin. \n                   Satellite snafu masked true sea-level rise for decades 2017-Jul-17 \n                 \n                   Huge Arctic report ups estimates of sea-level rise 2017-Apr-28 \n                 \n                   Antarctica\u2019s sleeping ice giant could wake soon 2017-Apr-12 \n                 \n                   Climate science: Rising tide 2013-Sep-18 \n                 \n                   US northeast coast is hotspot for rising sea levels 2012-Jun-24 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22545", "url": "https://www.nature.com/articles/nature.2017.22545", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "An international partnership seeks African leadership to organize information about the disease. More than 11,000 people died when  Ebola tore through West Africa between 2014 and 2016 , and yet clinicians still lack data that would enable them to reliably identify the disease when a person first walks into a clinic. To fill that gap and others before the next outbreak hits, researchers are developing a platform to organize and share Ebola data that have so far been scattered beyond reach. The information system is coordinated by the  Infectious Diseases Data Observatory  (IDDO), an international research network based at the University of Oxford, UK, and is expected to launch by the end of the year. At a meeting to discuss Ebola on 7\u20139 September in Conakry, Guinea, the team heading the platform will seek input from West African scientists, health officials and advocacy groups. \u201cWe are looking for West African leadership in this initiative,\u201d says Laura Merson, associate director of the IDDO. \n               Local leaders \n             Africans must be involved in the platform\u2019s creation so that they can not only use the existing data, but also improve their capacity to conduct research during future outbreaks, says John Amuasi, an infectious-diseases researcher at the Kumasi Centre for Collaborative Research in Tropical Medicine in Ghana and a member of the platform\u2019s steering committee. A true partnership would also lessen the general public\u2019s mistrust of scientists, he adds. During the outbreak, for example, a widespread rumour claimed that the plague was an experiment conducted by the West, which led some people to resist going to clinics and helped Ebola to spread. Merson and her collaborators want to avoid the kind of data fragmentation that hindered efforts to stop the outbreak in Liberia, Guinea and Sierra Leone. As the Ebola crisis was escalating in October 2014, she visited treatment units in the three countries to advise on research. Merson found tremendous variation in practices, which complicated attempts to merge and analyse the information. For instance, some record books listed lethargy and hiccups as symptoms, whereas others recorded fatigue but not hiccups. \u201cPeople were just collecting what they could,\u201d she recalls. Non-governmental organizations \u201cwere keeping their data private; academics take a year to get it out; and West Africa had set up surveillance but they were siloed from the international systems\u201d, she says.\u00a0 \n               Questions of control \n             In July 2015, the IDDO received pilot funds from the UK charity the Wellcome Trust to pool anonymized data from the medical records of people who contracted Ebola \u2014 and those who survived it \u2014 as well as data from clinical trials and public health projects during outbreaks in West Africa, Uganda and the Democratic Republic of Congo. The hope is that a researcher could search for data to help in diagnosing, treating and understanding the disease. The platform would also provide a home for new data as they emerge. A  draft research agenda  lists questions that the information might answer, such as how long the virus can survive outside the human body, and what factors are associated with psychological issues in those who survive Ebola. One sensitive issue is deciding who will control the data. Amuasi says that he would have liked the database to be hosted and curated in Africa, rather than in Oxford, because training and paying African researchers to manage the platform would teach them how to use the information and improve their ability to respond to future outbreaks in the region. But he adds that this seems unlikely, because it would raise the cost of the project, and the infrastructure already exists at Oxford. Merson says that a copy of the database will be maintained in West Africa, although its exact location has yet to be determined. She adds that an African committee may be in charge of deciding who gets access to the data. And she says that fellowships are likely to be made available for West African students who want to work on the database. It\u2019s vital that these discussions happen now, in a period of relative calm, says Jeremy Farrar, director of the Wellcome Trust in London. When the virus emerges again, clinicians, scientists, and regulatory boards will need fast access to data so as not to repeat mistakes made last time. \u201cWe need to sit down and make sure we have a data platform in place so that we can respond to a new case of Ebola in hours and days, and not in months and years,\u201d he says. \u201cA great danger is that the world will move on and forget the horror of Ebola in West Africa.\u201d \n                     Empty rhetoric over data sharing slows science 2017-Jun-12 \n                   \n                     World Health Organization rethinks its response to disease outbreaks 2016-Dec-20 \n                   \n                     Ebola virus lingers longer than scientists thought 2016-Sep-13 \n                   \n                     Data sharing: Make outbreak research open access 2015-Feb-25 \n                   \n                     Infectious Diseases Data Observatory : Ebola \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22521", "url": "https://www.nature.com/articles/nature.2017.22521", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Rock-encased bone shard left behind by thieves allowed researchers to determine that the remains are probably more than 13,000 years old. A human skeleton that was stolen from an underwater cave in Mexico in 2012 may be one of the oldest ever found in the Americas. Scientists have now put the age of the skeleton at more than 13,000 years old after analysing a shard of hip bone \u2014 left behind by the thieves because it was embedded in a stalagmite. Cave divers discovered the remains in February 2012 in a submerged cave called Chan Hol near Tul\u00fam on Mexico's Yucat\u00e1n peninsula, and posted photos of a nearly complete skull and other whole bones to social media. The posts caught the attention of archaeologists Arturo Gonz\u00e1lez Gonz\u00e1lez at the Desert Museum in Saltillo, Mexico, and Jer\u00f3nimo Avil\u00e9s Olgu\u00edn at the Institute of American Prehistory in Canc\u00fan. By the time researchers visited the cave in late March, the remains were gone \u2014 except for about 150 bone fragments and a pelvic bone that had been subsumed by a stalagmite growing up from the cave floor. On the basis of these bones, the researchers think that the skeleton belonged to a young man who died when sea levels were much lower and the cave was above ground. \n               Dating techniques \n             To determine the age of human remains, researchers often measure levels of a radioactive isotope of carbon in collagen protein within bones. But in this case, most of the collagen had been leached out by water while the bones were submerged, making this method unreliable, says Wolfgang Stinnesbeck, a palaeontologist and geoscientist at the University of Heidelberg, Germany, who led the efforts to date the remains. Instead, Stinnesbeck\u2019s team collected a fleck of the pelvis bone and surrounding stalagmite, which contains a mineral called calcite. The team then dated the rock using the relative levels of uranium and thorium isotopes in the calcite. The deeper into the stalagmite the researchers sampled, the older the dates turned out to be; stone just 2 centimetres from the bone was 11,300 years old. Calcite closer to the bone gave conflicting results, Stinnesbeck says. The team determined that the skeleton was older than 13,000 years by analysing the rate at which calcite had formed around the bone, and by matching the shifts in stalagmite isotope levels to those in other caves. The findings were published on 30 August in  PLoS ONE 1 . Alistair Pike, an archaeological scientist at the University of Southampton, UK, notes that the stalagmite set over the bone during a time of profound climate change, which could have altered the stalagmite's rate of growth. He says he is therefore more comfortable considering the bones to be a minimum of 11,300 years old \u2014 still \u201cvery significant\u201d, he notes. \n               Ancient company \n             Few other human remains from the Americas are older than 13,000 years. The skeleton of a teenage girl recovered from a different Yucat\u00e1n cave  was carbon-dated to more than 12,000 years old , and a skeleton found in another submerged cave near Tul\u00fam was deemed to be around 13,500 years old, also using radiocarbon dating.  \u201cThey\u2019ve done a really nice job determining the age of this thing,\u201d says David Meltzer, an archaeologist at Southern Methodist University in Dallas, Texas. There is convincing archaeological proof that  humans colonized the Americas before 14,000 years ago , but very old remains are precious. \u201cThese sites are rare as hen\u2019s teeth,\u201d Meltzer says. Apart from the Yucat\u00e1n finds, the next-oldest skeleton from the Americas is that of  a 12,600-year-old boy found in Montana , whose sequenced genome places him on a lineage leading to present-day Native American groups. Researchers have sequenced only a few  other human skeletons from the Americas that are older than 10,000 years , hindering efforts to unravel the region's ancient population history. Getting DNA from what remains of the Chan Hol skeleton will be hard. A sample sent to one of the world\u2019s leading ancient-DNA labs, the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany, did not contain enough DNA, Stinnesbeck says. He hopes to find DNA in the few teeth not taken by the thieves. The theft still boggles Stinnesbeck, whose team is continuing to study the cave and its remains. The researchers recently reported the discovery of fossils in the cave that are of a new species of peccary 2  \u2014 a hoofed mammal related to pigs \u2014 as well as evidence that the cave's human inhabitants made fires. \u201cWhat would you want with a skeleton? Would you take it home?\u201d Stinnesbeck asks. \u201cIf they had known it was very old, maybe just to have a souvenir, to have something special.\u201d \u201cWe went to the police and they did some inquiries,\u201d he adds. \u201cThey never came up with anything substantial.\u201d\u00a0 \n                     Controversial study claims humans reached Americas 100,000 years earlier than thought 2017-Apr-26 \n                   \n                     Ancient bones reveal girl's tough life in early Americas 2017-Mar-31 \n                   \n                     North America\u2019s oldest mummy returned to US tribe after genome sequencing 2016-Dec-07 \n                   \n                     Plant and animal DNA suggests first Americans took the coastal route 2016-Aug-10 \n                   \n                     Fishing for the first Americans 2015-Sep-08 \n                   \n                     Mexican skeleton gives clue to American ancestry 2014-May-15 \n                   \n                     Ancient genome stirs ethics debate 2014-Feb-12 \n                   \n                     Ancient migration: Coming to America 2012-May-02 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22618", "url": "https://www.nature.com/articles/nature.2017.22618", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "A second jolt felt minutes after this month's detonation continues to confound researchers. Eight-and-a-half minutes after North Korea set off a nuclear bomb on 3 September, a second burst of energy shook the mountain where the test had just occurred. More than a week later, researchers are still puzzling over what caused that extra release of seismic energy \u2014 and what it says about North Korea\u2019s nuclear-testing site, or the risks of a larger radiation leak. Monitoring stations in South Korea have already picked up minute levels of radiation from the test. A number of theories have emerged to explain the second event, ranging from a tunnel collapse or a landslide to a splintering of the rock inside Mount Mantap, the testing site. But seismologists can\u2019t agree and say that they may not get enough evidence to pin down the cause. \u201cThis is an interesting mystery at this point,\u201d says G\u00f6ran Ekstr\u00f6m, a seismologist at Columbia University in New York City.  The nature of the first seismic signal is clearer because it matches the profile of a bomb blast. The US Geological Survey (USGS) determined the magnitude of the seismic event associated with the nuclear explosion at 6.3, whereas the Comprehensive Nuclear-Test-Ban Treaty Organization (CTBTO) in Vienna calculated it at 6.1 on the basis of a separate analysis. The explosion was many times the size of  past North Korean tests  and was the largest seismic signal from a nuclear test ever detected by the international network of seismic monitoring stations used by the CTBTO. The second event came 8.5 minutes later and registered as magnitude-4.1, reported the USGS. The agency suggested that it was associated with the test and may have been a \u201cstructural collapse\u201d. The possibility that the smaller shock was caused by a tunnel collapse inside the testing site has dominated discussion in the media. But Paul Earle, a seismologist at the USGS, told  Nature  that was just one possibility that was raised in the immediate aftermath of the explosion. The USGS, he said, was \u201cbasing that on previous nuclear tests of comparable size that had a collapse\u201d. Possible signs of a collapse are visible on satellite images taken of the testing site, according to an analysis released on 12 September by 38 North, a partnership of the US-Korea Institute and the Johns Hopkins School of Advanced International Studies in Washington, DC. But the seismic signal doesn\u2019t match what would be expected from a collapse, says Lianxing Wen, a geophysicist at the State University of New York at Stony Brook. A collapse would produce mostly vertical movement of rock, but his own unpublished work suggests that the seismic clues point to a large horizontal movement as well, something he says would be more consistent with a landslide. \n             Sliding scale \n           Although the satellite data do show a lot of landslides on Mount Mantap, other researchers argue that they could not have caused the magnitude-4.1 event.  Much larger landslides , such as at Bingham Canyon mine in Utah in 2013, haven\u2019t produced seismic signals close to that size, says Ekstr\u00f6m.\u00a0 He also argues that the seismic signals he has seen do not match the pattern expected from a landslide. Such an event would have longer-duration signals (matching the time that it takes rocks to fall down a slope) and fewer high-frequency waves (because the energy in a landslide is released more slowly than in earthquakes or explosions) than what was recorded in the North Korean event. He says that a collapse cannot yet be ruled out. The crater formed by a collapse sometimes does not become visible at the surface until much later. Another theory comes from Ekstr\u00f6m\u2019s colleague at Columbia, seismologist Won-Young Kim. Kim rules out a collapse, a landslide and the possibility that there was an earthquake triggered by the explosion. He says that the seismic event was probably a rock burst \u2014 a violent fracturing of rock around one of the many tunnels under Mount Mantap. That could explain the frequency of the seismic waves, which were lower than an earthquake rupture but higher than a landslide, as well as the other features, he says. The characterization of landslides and rock bursts could help researchers to assess how unstable Mantap is. Even if the whole mountain isn't going to collapse, as some have warned, subtler signs from landslides or rock bursts could indicate whether a major section of the mountain above the tunnels may have cracked. If so, that could lead to contamination of the mountainous area by radioactive material. \u201cIt is difficult to imagine how to contain that, given the altitude and remoteness of the place,\u201d says Kim. Stations outside of North Korea have started to detect radiation from the latest test. On 13 September, the South Korean Nuclear Safety and Security Commission in Seoul announced that several  ground- and sea-based monitoring stations  downwind of the test site had detected the radioactive isotope xenon-133, an indicator of a nuclear test. However, no other isotopes were detected, preventing a determination of what type of bomb was used. It also did not indicate whether radiation is leaking from the site at a higher rate than expected, said Cheol-Su Kim, the head of the environmental radioactivity assessment department at the Korea Institute of Nuclear Safety in Daejeon, South Korea. Based on South Korea's ground-based network of reporting stations, overall radiation levels there ranged from 50\u2013300 nanosieverts per hour \u2014 no higher than the country's background level. \n             With reporting by Mark Zastrow \n           \n                   What kind of bomb did North Korea detonate? 2016-Jan-08 \n                 \n                   Nuclear detectives sniff out North Korea 2013-Feb-12 \n                 \n                   Isotopes hint at North Korean nuclear test 2012-Feb-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22543", "url": "https://www.nature.com/articles/nature.2017.22543", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Researchers deliberately heated up a slice of the Antarctic sea bed to see how ecosystems responded. The future has come to a small patch of the Antarctic sea floor, courtesy of an experiment that placed electric heating pads on the ocean's bottom. The pioneering trial is one of the most realistic and technically challenging ocean-warming experiments yet performed, researchers say \u2014 and it opens up a new avenue to explore how warming oceans affect marine ecosystems. In the past 40 years, the surface waters of Earth\u2019s oceans have warmed by some 0.4 \u00b0C on average as a result of climate change. And if greenhouse-gas emissions continue at their current pace, models forecast that the warming could reach up to 2 \u00b0C by 2100. But researchers know little about how ocean ecosystems will respond and adapt as a result \u2014 and uncertainties are largest in polar regions where there are few field data, says study co-author Gail Ashton, a marine ecologist with the Smithsonian Environmental Research Center in Tiburon, California. That data gap spurred Ashton and her colleagues to carry out the artificial warming experiment in Antarctica. They began in 2014, when scuba divers dug trenches, laid cables and installed 12\u00a0panels 15\u00a0metres under water on flat sea bed near the Rothera Research Station of the British Antarctic Survey (BAS), which is on a small island off the west coast of the Antarctic Peninsula. Four panels were heated so that they were always 1\u00a0\u00b0C above the ambient temperature \u2014 which in the region varies from around \u20132\u00a0\u00b0C to +2\u00a0\u00b0C during the year \u2014 and four were heated to 2\u00a0\u00b0C above ambient temperature. The remaining four were left unheated, as controls. Using cameras, the divers then monitored how microorganisms \u2014 of the kind that encrust wet surfaces and biofoul underwater pipes \u2014 colonized the panels. The species, including microscopic invertebrates and sponges, represented typical sea-bed fauna in the region. The experiment was supposed to run for two years but ended after nine months, when icebergs damaged power-supply cables. Still, researchers saw significant and surprising differences between the panels, says Ashton. \u201cI had hoped we might be able to see some subtle differences after careful image analysis,\u201d she says. \u201cBut I would never have expected that the warming effects would be so easily discernible with the human eye.\u201d Metabolic theory predicts that biological growth rates increase by around 10% for every 1 \u00b0C of warming. But some species grew twice as fast on the heated panels as they did on the controls, Ashton and her colleagues report in  Current Biology 1 . Distinctly different animal communities settled on the heated surfaces. On the 1 \u00b0C set, a species called  Fenestrulina rugula  \u2014 a kind of filter-feeding invertebrate called a bryozoan \u2014 so dominated the fauna that the diversity of all the species on the panel was reduced. \u201cThe results are very exciting and provocative,\u201d says Craig Smith, a marine ecologist at the University of Hawaii at Manoa. \u201cThey suggest that climate warming in the next 50 years in Antarctica could substantially alter the unique diversity of Antarctic ecosystems.\u201d Experimenters have struggled in the past to study the effects of ocean warming in a controlled experiment, in which one area of sea is deliberately and uniformly warmed relative to another over a long period of time. Previous ocean tests have compared coastal areas with nearby regions that receive extra heat from local power plants. And one effort in 2010 used electric panels to heat a small section of water in western Australia, but the animals being studied quickly grew big enough to leave the warmed water layer. \n               Danger to diversity \n             Researchers worry that Antarctic species \u2014 adapted to cold waters \u2014 may suffer as waters warm. The results suggest that species at the bottom of the marine food web are able to cope with one or two degrees of warming, Ashton says, particularly given that it happens over decades. However, species-richness or diversity might be affected, and some species might grow to dominate others. Ashton says she would also like to know what the knock-on effects will be for other creatures. \u201cWe do need more reliable field data to validate and interpret lab experiments on how environmental change affects life in the seas,\u201d says Hans-Otto P\u00f6rtner, an ecologist at the Alfred Wegener Institute of Polar and Marine Research in Bremerhaven, Germany. \u201cAs yet, we have only a sketchy knowledge of what controls the success of species.\u201d Others agree that carefully designed controlled-warming experiments such as Ashton\u2019s are the way to go, although Smith says they should ideally be run for longer, with more replications. One caveat, he cautions, is that the panels warmed only a roughly 2-millimetre-thick layer of water. The rest of the water column \u2014 which would have contained larvae and food on which the animals in the experiment depend \u2014 remained colder. So the results aren\u2019t a perfect predictor of how sea-floor communities might change, he says. Furthermore, the results can\u2019t be generalized to suggest what will happen in other seas, says Simon Morley, a marine biologist with the BAS in Cambridge, who took part in the study. Ashton and Morley plan to do more warming experiments in other polar environments. In September, Morley will look for a suitable test site near the Canadian High Arctic Research Station in Cambridge Bay. He says he will also apply for money to do similar experiments in tropical waters, and perhaps even freshwater environments. \u201cMore of these experiments need to be done to be able to generalize, and draw wider conclusions,\u201d says Boris Worm, an oceanographer at Dalhousie University in Halifax, Canada. \u201cEach is necessary to challenge our simplistic assumptions about how climate change may alter the world we live in.\u201d \n                     Climate change is making algal blooms worse 2017-Apr-25 \n                   \n                     How much longer can Antarctica\u2019s hostile ocean delay global warming? 2016-Nov-16 \n                   \n                     Forecast ocean variability 2016-Nov-08 \n                   \n                     World\u2019s largest marine reserve hailed as diplomatic breakthrough 2016-Oct-28 \n                   \n                     Landmark experiment confirms ocean acidification\u2019s toll on Great Barrier Reef 2016-Feb-24 \n                   \n                     Smithsonian Environmental Research Center \n                   \n                     British Antarctic Survey \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22580", "url": "https://www.nature.com/articles/nature.2017.22580", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Reviewers and a co-author of a paper by genomics entrepreneur Craig Venter claim that it misrepresents the risks of public access to genome data. A storm of criticism has rained down on a paper by genome-sequencing pioneer Craig Venter that claims to predict people\u2019s physical traits from their DNA. Reviewers and even a co-author of the paper say that it overstates the ability to use a person\u2019s genes to identify the individual, which could raise unnecessary fears about genetic privacy. In the paper 1 , published on 5 September in the\u00a0 Proceedings of the National Academy of Sciences\u00a0 ( PNAS ), Venter and colleagues at his company Human Longevity, Inc. (HLI), based in San Diego, California, sequenced the whole genomes of 1,061 people of varying ages and ethnic backgrounds. Using the genetic data, along with high-quality 3D photographs of the participants\u2019 faces, the researchers used an artificial intelligence approach to find small differences in DNA sequences, called SNPs, associated with facial features such as cheekbone height. The team also searched for SNPs that correlated with factors including a person\u2019s height, weight, age, vocal characteristics and skin colour. The approach correctly identified an individual out of a group of ten people randomly selected from HLI\u2019s database 74% of the time. The findings, according to the paper, suggest that law-enforcement agencies, scientists and others who handle human genomes should protect the data carefully to prevent people from being identified by their DNA alone. \u201cA core belief from the HLI researchers is that there is now no such thing as true deidentification and full privacy in publicly accessible databases,\u201d HLI said in a statement. \n               Contentious claim \n             But other geneticists, having studied the paper, say that in their opinion, the claim is vastly overblown. \u201cI don't think this paper raises those risks, because they haven\u2019t demonstrated any ability to individuate this person from DNA,\u201d says\u00a0 Mark Shriver , an anthropologist at Pennsylvania State University in University Park. In a randomly selected group of ten people \u2014 especially one chosen from a data set as small and diverse as HLI\u2019s \u2014 knowing age, sex and race alone rules out most of the individuals, he says. To demonstrate this, computational biologist Yaniv Erlich of Columbia University in New York City looked at the age, sex and ethnicity data from HLI\u2019s paper. In a study 2  published on September on the preprint server bioRxiv, he calculated that knowing only those three traits was sufficient to identify an individual out of a group of ten people in the HLI data set 75% of the time. Erlich contends that there was no need to know anything about the people\u2019s genomes. Furthermore, he says, HLI\u2019s reconstructions of facial structure from SNPs are not highly specific \u2014 they tend to look as much like an individual as anyone of that person\u2019s sex and race. Before it was published in  PNAS , the paper had been submitted to  Science , says Shriver who reviewed the paper for that journal. He says that HLI\u2019s actual data are sound, and he is impressed with the group\u2019s novel method of determining age by sequencing the ends of chromosomes, which shorten over time. But he says that the paper doesn\u2019t demonstrate that individuals can be identified by their DNA, as it claims to. \u201cI think it totally misrepresents what they did and what they found,\u201d he says. HLI said that its paper states that using multiple parameters, of which a person's face is only one, to identify someone is possible based on work with more than a thousand genomes. \u201cIt heralds that prediction will become increasingly precise,\u201d says Heather Kowalski, an HLI spokesperson. HLI stated that it stands by its methodology and acknowledged that the sample set was small. The company published their response 3  to Erlich's paper on 11 September. Shriver says that he and Erlich pointed out their concerns to the study authors in their reviews of the paper for\u00a0 Science . Both Shriver and Erlich say that the journal ultimately rejected the paper. ( Science \u00a0does not comment on unpublished studies.) The paper was then submitted to\u00a0 PNAS \u00a0under an option that allows a member of the US National Academies of Science, Engineering, and Medicine, such as Venter, to choose the reviewers.\u00a0Two of them are information-privacy experts and the remaining reviewer is a bioethicist. PNAS \u00a0confirmed that Venter chose all three reviewers for the study. HLI declined to comment on the\u00a0 PNAS \u00a0review process for the paper. \n               Privacy issues \n             Jason Piper, a computational biologist and a paper co-author who now works at Apple in Singapore, agrees that the paper misrepresents the findings that he and the other co-authors produced. Piper adds that his contract with the company waived his right to approve the manuscript before it was submitted, allowing HLI to present his data however it saw fit. HLI responded to that by confirming that  \u201c authors were given an opportunity to review and comment on the paper\u201d. Piper has since criticized the paper heavily on Twitter and says that, in his opinion, HLI has a potential conflict of interest in encouraging restricted access to DNA databases. HLI, a for-profit company, is attempting to build the world\u2019s largest database of human genetic information. \u201cI think genetic privacy is very important, but the approach being taken is the wrong one,\u201d Piper says. \u201cIn order to get more information out of the genome, people have to share.\u201d A more useful approach, he says, would be to\u00a0 find a way to make genomic data public \u00a0without allowing individuals to be identified.\u00a0 In response to criticisms of the paper, the company responded with a statement saying that \u201cHLI stands by the protection of genome data and the promotion of modern solutions for data exchange\u201d. It added that the paper was intended to spur discussion about how to share genetic information while protecting a person's privacy. Still, Erlich is concerned that Venter\u2019s stature gives the paper extra weight in the eyes of policymakers, who may become overly concerned about DNA privacy. \u201cNew rules and regulations are based on papers like that,\u201d he says. \u201cIt\u2019s important when we deal with privacy risks to get the facts right.\u201d \n                     Spiking genomic databases with misinformation could protect patient privacy 2016-Aug-15 \n                   \n                     Mugshots built from DNA data 2014-Mar-20 \n                   \n                     Privacy protections: The genome hacker 2013-May-08 \n                   \n                     Genetic privacy needs a more nuanced approach 2013-Feb-06 \n                   \n                     Genetic privacy needs a more nuanced approach 2013-Feb-06 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22548", "url": "https://www.nature.com/articles/nature.2017.22548", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Competing spending priorities in the House of Representative and Senate could push funding negotiations into December. Scientists in the United States are nervously watching from the sidelines as the annual budget skirmish heats up in Congress this week. Legislators are back in Washington DC from their August recess with an urgent list of tasks to complete before the country's fiscal year closes at the end of September. In addition to passing a budget to fund the government, they must also raise the debt ceiling so that the country does not default on its loans, and discuss providing emergency-relief funding for victims of Hurricane Harvey. But legislators are well behind on drafting their 2018 spending plans, which creates uncertainty about how much money science agencies including the National Science Foundation (NSF) and NASA can expect. Experts say Congress will probably pass a  stopgap funding measure  to keep the lights on. Government agencies would remain on  2017 funding levels  until lawmakers eventually passed a new budget. In the meantime, they would be unable to start new programmes or end old ones without permission from Congress.  \u201c We're in for a wait,\u201d says Matthew Hourihan, director of the research and development budget and policy programme at the American Association for the Advancement of Science in Washington DC. Hashing out the differences between spending bills from the House of Representatives and the Senate for the 2018 fiscal year could take until December, says Amy Scott, a science-funding and policy specialist at the Association of American Universities (AAU) in Washington DC. \n               Bridging differences \n             At this current stage of the budget process, the House and Senate diverge on several key scientific priorities. This is reflected in the appropriations bills that have passed through the committees that oversee scientific agencies. There is a large gulf in the plans for NASA. The House bill would boost the agency\u2019s science programme by US$94 million over the 2017 level of $5.8 billion, whereas the Senate would cut it by $193 million. Lawmakers in the House have allocated $2.1 billion for NASA\u2019s planetary-science budget \u2014 up from the $1.8 billion it received in 2017. The Senate bill, by contrast, would cut $234 million from current spending levels. Support from the House and Senate is reversed for Earth-sciences research. The Senate would maintain 2017 spending levels at $1.9 billion, but the House would cut it by $217 million for 2018. Despite these differences, negotiations to reconcile NASA\u2019s budget tend to go smoothly, says Scott. A bigger sticking point is funding for the Advanced Research Projects Agency\u2014Energy (ARPA-E), a Department of Energy (DOE) programme focused on incubating innovations in clean energy. The House bill guts ARPA-E and instructs that any remaining money from the $306 million the project received in 2017 be used to \u201cconduct an orderly shutdown\u201d of the programme. The Senate, however, gives ARPA-E $330 million for 2018. Criticism for the 8-year-old programme often stems from a perceived lack of output, says Julia Smith, a DOE funding and policy specialist at the AAU. \u201cBut ARPA-E is young, so we can\u2019t say how it has changed your life because we don\u2019t know yet.\u201d Another bone of contention is  support for the multibillion-euro nuclear-fusion collaboration ITER , which is funded by an international consortium that includes the DOE. The planned facility, under construction at a site in St-Paul-lez-Durance, France, is over budget and suffering continual delays. Congress eventually allocated $50 million for the project in 2017, even though the Senate proposed eliminating its monetary support. For 2018, the Senate is again trying to cut out ITER\u2019s US funding completely, whereas the House has proposed an allocation of $63 million. \n               Polarizing programme \n             The National Oceanic and Atmospheric Administration (NOAA) may also face funding difficulties. The House slashes its 2018 budget to $5 billion, down from the $5.7 billion the agency received in 2017. The Senate has proposed $5.6 billion for 2018. The divisions come to a head on an especially contentious item: NOAA\u2019s Polar Follow-On programme, which operates satellites that collect data used to predict the weather, including hurricanes. The House has proposed only $50 million for this programme, a huge cut from the $329 million it received in 2017. The Senate, however, would give the programme $419 million. Money for designing and building  three new research vessels for the NSF  could also be problematic. Congress gave the agency $122 million for this purpose in 2017. For 2018, the House bill cut out all funding for the ships, whereas the Senate provides the $105 million requested by the NSF. Despite these differences, \u201cthis is something that does usually end up getting funded\u201d, Scott says. It is unclear whether or how items such as the funding aid package for Hurricane Harvey will affect negotiations over the budget and the debt limit, says Scott. Adding to the uncertainty is the fact that the Senate has yet to send half of its appropriations bills \u2014 including one that funds the National Institutes of Health (NIH) \u2014 through the relevant spending committees. Judging by deliberations amongst lawmakers so far, experts say that the NIH will probably get a boost from both the House and the Senate. The two chambers \u201cseem to be remarkably in agreement\u201d on NIH funding, says Jennifer Zeitzer, director of legislative relations at the Federation of American Societies for Experimental Biology in Bethesda, Maryland. But, until Congress starts working on the hurricane funding, \u201cI don\u2019t think we will know how federal science programmes will be affected\u201d, Scott says. \n                 Tweet \n                 Follow @NatureNews \n               \n                     US lawmakers\u2019 science spending plans ignore Trump cuts 2017-Jun-28 \n                   \n                     Trump budget would slash science programmes across government 2017-May-23 \n                   \n                     Science wins reprieve in US budget deal 2017-May-01 \n                   \n                     US science agencies face budget limbo 2016-Sep-06 \n                   \n                     US advised to stick with troubled fusion reactor ITER 2016-May-26 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22583", "url": "https://www.nature.com/articles/nature.2017.22583", "year": 2017, "authors": [{"name": "Bruno Martin"}], "parsed_as_year": "2006_or_before", "body": "Smooth, vertical structures such as steel and glass buildings appear invisible to bats' echolocation system. \u201cI heard a thud behind me,\u201d says zoologist Stefan Greif, recalling the first time he noticed a bat crash into a metal plate propped up against a wall in his lab\u2019s flight chamber. Now, in a study published on 7 September in  Science 1 , a team led by Greif \u2014 of the Max Planck Institute for Ornithology in Seewiesen, Germany \u2014 explains why bats often slam into vertical panes, such as glass windows.These smooth surfaces interfere with bats\u2019 echolocation by reflecting sound away from the creatures. Bats rely on echolocation to navigate in the dark. They locate and identify objects by sending out shrill calls and listening to the echoes that bounce back. Greif and his colleagues tested the echolocation of 21 wild-caught greater mouse-eared bats ( Myotis myotis ) in the lab. The researchers placed a featureless metal plate on a side wall at the end of a flight tunnel. The bats interpreted the smooth surface \u2014 but not the adjacent, felt-covered walls \u2014 as a clear flight path. Over an an average of around 20 trials for each bat, 19 of them crashed into the panel at least once. The researchers also put up smooth, vertical plates near wild bat colonies, and saw similar results. The animals became confused owing to a property of smooth surfaces called \u2018acoustic mirroring\u2019. Whereas rough objects bounce some echoes back towards the bat, says Greif, a smooth surface reflects all echolocation calls away from the source. This makes a smooth wall appear as empty space to the bats, until they are directly in front of it. Only once a bat is facing the surface are their perpendicular echoes reflected back, which alerts the bat to its mistake. This explains why some bats attempted to swerve out of harm\u2019s way at the last second \u2014 but often too late. \n             Sound over sight \n           Gareth Jones, a behavioural ecologist at the University of Bristol, UK, says researchers can rule out the possibility that the bats were visually confused, because the experiments were done under infrared light, which bats can\u2019t see, and so they would have been relying entirely on echolocation. The results highlight how unaware humans are of the sensory problems faced by other species, says Christian Voigt, who studies bats at the Leibniz Institute for Zoo and Wildlife Research in Berlin. In a 2010 study 2 , Greif investigated the animals\u2019 response to smooth horizontal surfaces. When his team placed smooth plates on the ground, bats descended and attempted to drink from them. In nature, bats encounter this type of acoustic mirroring from the surfaces of lakes and ponds. They seem adapted to interpret the perpendicular echoes that they hear when they fly over smooth planes as a cue for the presence of still water. Echolocation-fooling vertical structures have appeared only in recent decades, notes Jones. Although the bats tested experimentally were not injured, because the size of the test room constrained their flying speed, bats flying much faster in the wild may be under threat from human structures, according to Grief. It\u2019s not uncommon to find dead or injured bats near buildings, but their toll on bat populations isn\u2019t known. If human-made structures are found to be a serious threat, the authors suggest mitigating damage near important bat colonies and migratory highways by, for example, avoiding the use of smooth materials in construction. A more feasible solution may be the use of acoustic deterrents \u2014 small bundles of speakers that emit ultrasound near buildings in these ecologically important sites, says Greif. \u201cWe have to be realistic.\u201d \n                   Geneticists hope to unlock secrets of bats\u2019 complex sounds 2016-Nov-18 \n                 \n                   The woman who sees like a bat 2015-Jan-13 \n                 \n                   Hawkmoths zap bats with sonic blasts from their genitals 2013-Jul-03 \n                 \n                   Bats adjust squeaks to focus sonar 2012-Nov-21 \n                 \n                   Ancient bat flew without echolocation (Updated) 2007-Oct-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22627", "url": "https://www.nature.com/articles/nature.2017.22627", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Analysis suggests that researchers have underestimated how much carbon humanity can emit before reaching this level of warming. A team of climate scientists has delivered a rare bit of good news: it could be easier than previously thought to limit global warming to 1.5 \u00b0C above pre-industrial levels, as called for in  the 2015 Paris climate agreemen t. But even if the team is right \u2014 and some researchers are already questioning the conclusions \u2014 heroic efforts to curb greenhouse-gas emissions  will still be necessary to limit warming . Published on 18 September in  Nature Geoscience 1 , the analysis focuses in part on the fact that global climate models used in the 2013 report from the Intergovernmental Panel on Climate Change (IPCC) tend to overestimate the extent of warming that has already occurred. After adjusting for that discrepancy and running further models, the authors of the latest study found that the amount of carbon that humanity can emit from 2015 onward while holding temperatures below 1.5 \u00b0C is nearly three times greater than estimated by the IPCC \u2014 or even larger if there is aggressive action on greenhouse gases beyond carbon dioxide. The implications for global policymakers are significant. Humanity is poised to blow through the IPCC\u2019s carbon budget for a 1.5 \u00b0C rise within a few years, leading many scientists to declare the goal impossible. But the new analysis suggests that it could be met with a modest strengthening of the current Paris pledges up to 2030, followed by sharp cuts in carbon emissions thereafter. \u201cThe Paris goal of 1.5 \u00b0C is not impossible \u2014  it\u2019s just very, very difficult ,\u201d says lead author Richard Millar, a climate researcher at the University of Oxford, UK. \n             Debate rages on \n           The work is receiving mixed reviews. Some argue that the analysis is fundamentally flawed, because it centres on a period of slower warming that began around the turn of the millennium. This period,  often referred to as the climate hiatus , continued until 2014. Scientists think that natural variability in the climate system temporarily suppressed temperatures during this period. The team\u2019s estimate for the amount of warming that humans have caused so far \u2014 0.93 \u00b0C \u2014 could thus be artificially low, because it calculates the human contribution to warming during this cooler time, says Ben Sanderson, a climate modeller at the National Center for Atmospheric Research in Boulder, Colorado. At the same time, he says, the oceans and the land were probably absorbing more carbon than normal during this period. Natural processes will eventually dump some of that back into the atmosphere, thus reducing the amount of carbon that humanity can emit before reaching 1.5\u00b0C. \u201cThese two effects, to my mind, explain away their result and reinforce the original IPCC conclusion,\u201d Sanderson says. But Millar and his colleagues argue that the effects of the hiatus would be minimal. The team used multiple methodologies to estimate the actual warming due to greenhouse gases, independent of short-term climate variability. The scientists calculated how much carbon would be needed to push the temperature up by another 0.6 \u00b0C, to 1.5 \u00b0C. But they also calculated how much carbon it would take to reach that threshold if the amount of human-caused warming so far was lower or higher than their estimate of 0.93 \u00b0C. In all cases, Millar says, the amount of carbon that humans could emit before Earth warms to that 1.5 \u00b0C threshold is larger than previously estimated. \n             Counting carbon \n           Nathan Gillett, a climatologist at the Canadian Centre for Climate Modelling and Analysis in Victoria, says that other teams have previously documented the slight discrepancy between the warming projected by climate models and that shown by actual observations. But Gillett credits Millar\u2019s team with teasing out the implications of this gap, and of reducing the uncertainty surrounding the amount of emissions that would produce warming of 1.5 \u00b0C. \u201cI think their central conclusion is robust,\u201d Gillett says. The debate over how close the world is to the 1.5 \u00b0C warming threshold is unlikely to be resolved any time soon, but one thing is clear: modelling scenarios that enable Earth to remain below that target poses a new kind of challenge. Uncertainty about the details of humanity\u2019s carbon budget don\u2019t matter so much when scientists are modelling the cumulative effect of greenhouse gases over the course of centuries. But fine details matter a great deal when researchers are looking at what level of greenhouse-gas emissions would bump warming to 1.5 \u00b0C, because, in that case, scientists\u2019 goal is to tease out the precise effects of heat-trapping gases over a few decades. \u201cWhen we start thinking about really ambitious mitigation goals in the really near term, everything starts to matter,\u201d Millar says. That is true for science as well as for climate policy. \u201cFor a lot of people, it would probably be easier if the Paris goal was actually impossible,\u201d Millar says. \u201cWe\u2019re showing that it\u2019s still possible. But the real question is whether we can create the policy action that would actually be required to realize these scenarios.\u201d \n                   California scientists push to create massive climate-research programme 2017-Aug-16 \n                 \n                   Fears rise for US climate report as Trump officials take reins 2017-Aug-01 \n                 \n                   How scientists reacted to the US leaving the Paris climate agreement 2017-Jun-02 \n                 \n                   Global warming \u2018hiatus\u2019 debate flares up again 2016-Feb-24 \n                 \n                   Is the 2\u2009\u00b0C world a fantasy? 2015-Nov-24 \n                 \n                   Climate change: The case of the missing heat 2014-Jan-15 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22566", "url": "https://www.nature.com/articles/nature.2017.22566", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "UK government document fails to extinguish concerns over funding and migration. More than one year after UK citizens voted to leave the European Union, and close to three months into \u2018Brexit\u2019 negotiations, the British government has finally laid out how it would like to handle scientific relationships with the EU after it leaves the bloc in 2019. Many scientists are less than impressed. In a policy document published on 6 September, the UK government pledges to \u201cseek an ambitious science and innovation agreement\u201d in Brexit negotiations with the EU. But it simply sets out areas in which agreement will be sought, rather than making any specific proposals. John Womersley, director-general of the European Spallation Source, a research facility in Lund, Sweden, says that although the aspirations in the document were welcome, the lack of detail means it will probably disappoint the scientific community more than reassure it. \u201cI downloaded the document and I thought, hoped, expected, it would be too big for me to digest in ten minutes. It was trivially easy to digest in ten minutes,\u201d he says. Mike Galsworthy, of the Scientists for EU pressure group, says that the document makes \u201cgenerally warm and happy noises\u201d but contains nothing really new. \u201cMy anxiety is specifically we could have told you all of this two years ago,\u201d he says of its contents. \u201cWe have now wasted a quarter of the negotiation time and the government hasn\u2019t really put forward anything that really addresses the hard challenges.\u201d \n               Money matters \n             In January, the government listed science as one of its 12 priorities for Brexit negotiations, but it has said little about what this would mean in practice. UK institutions currently receive around \u20ac1 billion in funding every year from EU programmes, mainly from the huge Horizon 2020 funding programme, the latest of the EU\u2019s research-funding \u2018Framework Programmes\u2019. Freedom-of-movement rules have allowed academic staff from EU countries other than the United Kingdom \u2014 currently more than 30,000 \u2014 to move to UK universities and live and work without visas. Today\u2019s document \u2014 one of a series outlining the government\u2019s position in continuing negotiations with the EU \u2014 confirms that the United Kingdom would like to remain a member of Horizon 2020, and of any successor schemes. It would \u201cwelcome discussions\u201d about continued UK participation in these, as well as in space, nuclear and defence research-and-development programmes. But it warns that any payments that the United Kingdom would have to make to remain part of such projects would be weighed \u201cagainst other spending priorities\u201d. It also says that, although EU citizens will lose the automatic right to come and work in the United Kingdom, the country \u201cwill continue to welcome the brightest and best\u201d. In a statement, David Davis, the minister in charge of the Department for Exiting the European Union, said: \u201cThis paper sends a clear message to the research and innovation community that we value their work and we feel it is crucial that we maintain collaboration with our European partners after we exit.\u201d \n               Over the horizon \n             Ministers have previously declined to say whether they would seek to keep the United Kingdom in EU schemes such as Horizon 2020. Reports circulating in the media this week indicated that Britain would be willing to pay \u20ac1.3 billion a year to stay in. However, this figure doesn\u2019t appear in the document, and no other specific financial contribution is mooted. How much Britain might have to pay if it were to join a successor to Horizon 2020 would have to be negotiated. Several non-EU countries have joined the Framework Programme as \u2018associated countries\u2019. That allows their researchers to apply for grants, but it also involves the nations paying a proportion of the programme\u2019s budget. How much countries pay is based on a ratio of their gross domestic product to the EU\u2019s. On the basis of those rules, the UK might expect to pay between \u00a31.8 billion and \u00a32 billion to rejoin the scheme. Kurt Deketelaere, secretary-general of the League of European Research Universities in Leuven, Belgium, says it is \u201can absolute necessity\u201d that the United Kingdom joins the planned successor to Horizon 2020, which begins in 2021. However, this could require some changes to current rules, which allow membership to categories of countries that the United Kingdom is unlikely to fall into, he says. Changes to the Framework Programme to make it more open internationally could be one solution to this, he notes. A key concern for some is the gap between the UK leaving the EU in 2019, and potentially joining the Horizon 2020 successor scheme in 2021. Britain has already promised to fund grants that are awarded under the current scheme before it leaves the EU. But whether it will continue to pay into Horizon 2020 after it leaves the EU is part of the negotiations \u2014 the EU argues that Britain has a legal commitment to do so. Deketelaere agrees that Horizon 2020 should not present a problem. But Edward Whiting, director of policy at the Wellcome Trust, says \u201cwe are concerned about the continuing uncertainty for UK researchers\u201d about the gap regarding participation between 2019 and 2021. \n               \u2018Brightest and best\u2019 \n             Whiting praises the plans for addressing the ability of researchers to move to the United Kingdom, but he says it will be important for the government to think beyond researchers with established careers when they look for the \u201cbrightest and best\u201d. Younger researchers and support staff are also crucial to science, he points out, and these scientists may fall foul of immigration controls, such as the need to earn above a certain salary. The government\u2019s science plan was not the only document attracting attention from policy watchers today. The  Guardian  newspaper released a leaked draft of what might be the United Kingdom\u2019s post-Brexit immigration policy, which included a rapid end to freedom of movement for EU citizens, and visas of three to five years for highly skilled workers. It also included suggestions for salary caps and restrictions on the ability to bring family members to Britain. Deketelaere thinks the document will make researchers think twice about moving to the country. To attract the \u201cbrightest and best\u201d, Britain is touting a new \u00a3100-million \u2018Rutherford Fund\u2019, which will provide fellowships for researchers to move to the country. But James Wilsdon, who studies research policy at the University of Sheffield, notes that the current EU system allows, for example, an Italian scientist with a grant from the prestigious European Research Council to move to the Britain with her grant, her partner and her children. Allowing a researcher to come to the United Kingdom is not enough, he says, if that person\u2019s family would have to be left behind. \u201cThe upside of the European system in mobility terms is clearly that it\u2019s very flexible in terms of movement of you and your partner and your kids,\u201d says Wilsdon. \u201cScientists are not these people who only sit there doing science. This is real life.\u201d \n                     A year on, Brexit brings lessons in uncertainty 2017-Jun-20 \n                   \n                     UK election: science spending pledges overshadowed by Brexit 2017-May-31 \n                   \n                     How Brexit is changing the lives of eight researchers 2017-Mar-29 \n                   \n                     Government position paper \n                   Reprints and Permissions"},
{"file_id": "549143a", "url": "https://www.nature.com/articles/549143a", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "The United States is set to trial a version that will also cover race and disability, while other countries have already embraced the voluntary rating system. A programme that grades UK universities on gender equality in science is going global. Versions of the rating scheme have started up in the past two years in Australia and Ireland, and a small-scale pilot begins next month in the United States. The British programme, Athena SWAN (Scientific Women\u2019s Academic Network), launched at ten universities in 2005 and has since spread to more than 140 UK institutions. The voluntary scheme relies on universities supplying self-assessments to the Equality Challenge Unit, a non-profit organization that judges the institutions on their inclusiveness and equality in hiring, promoting and retaining female staff.\u00a0 In addition to gender equality, the US project \u2014 called STEM Equity Achievement Change (SEA Change) \u2014 will assess inclusiveness with regards to race, ethnicity, sexual orientation, disability, socioeconomic status and other marginalized groups, says Shirley Malcom, who directs the education and human-resources programmes at the American Association for the Advancement of Science (AAAS) in Washington DC, which will oversee the project. The US effort will assess the experiences of both students and university staff. \u201cWe\u2019ve had a lot of intervention programmes and it\u2019s not moving the needle,\u201d says Malcom. \u201cWe are exploring this strategy in order to try something that\u2019s better.\u201d Around eight or nine currently unnamed US institutions will participate in the pilot scheme, which uses Athena SWAN as a model. Over a period of 12 to 18 months, individual departments or institutions as a whole will gather data on equality and identify problem areas. They are then expected to set plans and targets, such as boosting student diversity, closing pay gaps or making the campus climate more supportive. An AAAS panel will assess the submitted reviews and issue a bronze, silver or gold award accordingly.\u00a0 Most higher-education institutions in the United Kingdom now have at least one Athena SWAN rating. The scheme has been expanded in Britain to include the arts, humanities and social sciences, and has spread to Ireland and Australia, where the first 40 participating institutions will learn of their ratings in early 2018. There are also calls to launch similar schemes in India and Japan.\u00a0 \n               Funding incentive \n             A major reason for the scheme\u2019s rapid rise in the United Kingdom was its link to funding. In 2011 the UK government\u2019s chief medical officer, Sally Davies, made holding a silver award a requirement for receiving grants from a \u00a3816-million (US$1.1-billion) pot of government biomedical funding. But the scheme spread well beyond the institutions competing for that funding. This was motivated in part by \u201cmoral pressure\u201d but also because some staff thought that future funding decisions could become linked to such ratings, says Athene Donald, a physicist at the University of Cambridge, UK. Major funders such as the UK Research Councils recommend that institutions seek accreditation, but have not made it a requirement. Success in the United States may depend on a major funder such as the US National Science Foundation requiring certification as a pre\u00adrequisite for funding, says Curt Rice, who is head of the Norway government\u2019s Committee on Gender Balance and Diversity in Research.\u00a0 Evaluations of the British programme have been positive. In a 2016 survey of UK academics, almost 90% of respondents who were aware of Athena SWAN felt that the scheme\u2019s initiatives had a positive impact on the work environment. Some institutions saw particular success. Between the University of Liverpool receiving a bronze award in 2013 and a silver in 2016, the proportion of women promoted to professor posts increased from 28% to 50%. Other participating universities have made similar gains. With thousands of public and private institutions in the United States, the pilot will have to adapt to the US higher-education system, says Malcom. Holding institutions accountable for every aspect of diversity will be impossible, she says, but examining data that they already collect will be a place to start. \u201cMy sense is that we really can\u2019t address the gender issues without looking at these other aspects\u201d of diversity, she says. The AAAS hopes to expand the $200,000 pilot scheme to universities across the United States, but will need more funding. SEA Change has the potential to succeed, says Renee Horton, president of the National Society of Black Physicists. But she cautions that deep-rooted, prevailing and often unconscious prejudices that underlie inequality in the United States could make it difficult for universities to assess themselves, which means oversight by the AAAS would be essential. \u201cInstitutions struggling with diversity and inclusion likely have causative elements which they are unable to identify,\u201d she says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Science and gender: Scientists must work harder on equality 2015-Dec-21 \n                   \n                     Gender balance: Women are funded more fairly in social science 2015-Sep-09 \n                   \n                     Sexism has no place in science 2015-Jun-15 \n                   \n                     How to tackle racism in UK universities 2015-Apr-02 \n                   \n                     Athena SWAN awards: Bridging the gender gap in UK science 2011-Oct-05 \n                   \n                     Equality Challenge Unit \n                   Reprints and Permissions"},
{"file_id": "549142a", "url": "https://www.nature.com/articles/549142a", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "As strains on the desert nation\u2019s supply increase, scientists collaborate on projects to keep water flowing. Umm El-Jimal, Jordan For centuries, the land now called Jordan has been one of the world\u2019s driest places. Today, the nation\u2019s water supply is more constrained than ever: wells are running dry, groundwater is increasingly polluted and precious water leaks from old pipes. Waves of refugees are stretching resources even thinner: Jordan\u2019s population has swelled from 5.9\u00a0million in 2006 to 9.5\u00a0million in 2016. The average amount of water available annually per person is less than 150 cubic metres \u2014 one-sixtieth the amount that is available to a person in the United States. Researchers, who expect the situation to worsen as temperatures rise and precipitation levels drop with climate change, are coming to Jordan to collaborate on water-technology research and development.\u00a0 Samer Talozi, a water expert at the Jordan University of Science and Technology in Irbid, says that the country has become an inter\u00adnational test bed because of the environmental, structural and social challenges to its water supply. \u201cIf we can build systems that work in Jordan,\u201d he says, \u201cthey will work everywhere.\u201d\u00a0 But not all technologies evolving in Jordan are new. In August, Hassan Fahad al-Rhaibeh, the mayor of the Jordanian town of Umm el-Jimal, was re-elected after pledging to restore reservoirs built by Arabs as early as  ad \u00a090. Winter rains and run-off from mountains in Syria \u2014 10\u00a0kilometres to the north \u2014 once streamed through canals and into basalt-block reservoirs, which stored the water throughout parched summers. People maintained the system for 800\u00a0years, through the Roman, Byzantine and Islamic eras, until the town was abandoned around  ad \u00a0900. Today, those living around the ruins rely almost entirely on deep wells drilled after 1990. They complain that the well water smells and tastes salty. Mayor al-Rhaibeh recalls an evening in November 2015, after archaeologists and engineers had restored the first of the original reservoirs\u00a0\u2014 a rectangular basin the size of four Olympic swimming pools. \u201cAbout one hour before midnight,\u201d he says, \u201cwater began streaming into the reservoir, and I stayed up late into the night to watch it.\u201d\u00a0 The project continued this summer under the watch of Bert de\u00a0Vries, an archaeologist at Calvin College in Grand Rapids, Michigan. Engineers from the college\u2019s Clean Water Institute mapped which canals channel the most run-off. Al-Rhaibeh expects that, once completed, the system will provide 10% of the supply needed to support about 4,000 people in the community surrounding the ruins. \u201cIt\u2019s becoming apparent that if people don\u2019t return to some reliance on surface water, they will run out and farms will dry up,\u201d de Vries says. In 2012, a report from US intelligence agencies predicted that water scarcity, coupled with poverty, social tensions and weak political institutions, could lead to conflict in the Middle East. It was not the first such warning. The US Agency for International Development has invested more than US$700\u00a0million since 2000 to develop water technology in Jordan, as a way of preventing that outcome. Researchers are choosing to work in Jordan, as opposed to other arid nations, because of its geopolitical stability and support from the Jordanian government. Talozi spent this summer teaching officials and private-sector staff how to use modelling software from the Jordan Water Project, an international consortium of researchers based at Stanford University in California. The software takes into account an array of factors, including urban growth and water prices, to guide decisions about repairing or replacing water infrastructure and siting developments that might pollute groundwater, such as a refugee camp or a landfill. \u201cPreviously, there was software for the management of water according to physical parameters like precipitation, surface run-off and the efficiencies of the system,\u201d Talozi says, \u201cbut we wanted software that not only recognizes physical elements, but institutional behaviours that govern those systems, and considers economics.\u201d\u00a0 He is also collaborating with scientists at the Massachusetts Institute of Technology in Cambridge on a low-pressure \u2018drip\u2019 irrigation technology that\u2019s thrifty with water and requires about half the energy of standard drip irrigation. The team has tested its technology in olive, citrus and pomegranate farms this summer, and plans a version in the next two years that will be powered by solar energy. And the Helmholtz Centre for Environmental Research in Leipzig, Germany, is collaborating with the Jordanian government to test small, soil-filtered waste-treatment facilities that could lessen the leakage and inefficiencies seen in large plants, which can pollute nearby groundwater. Securing Jordan\u2019s water supply would also benefit Germany, says Roland M\u00fcller, a biotechnologist at Helmholtz. \u201cThe flow of Syrian refugees to Germany more or less started when camps in Jordan could not support them.\u201d Talozi says the country might take its cue from ancient systems in Petra and Umm el-Jimal and store more rain \u2014 although these conduits alone cannot support today\u2019s population. Migrants are not the only cause of shortages, he says. \u201cJordanians want to go to the grocery store and buy apples and tomatoes and lettuce year round, not just eat wheat and barley.\u201d\u00a0 But to de Vries, the resurrection of ruins in Umm el-Jimal serves as a hopeful reminder that people have survived harsh conditions by ingenuity. \u201cAs civilizations rotated through this land, one constant over time is the reuse and reliance of the water system,\u201d he says. \u201cPeople in antiquity were not backwards; they were clever and thought of a technology we can revive.\u201d Travel for this story was supported by the Pulitzer Center on Crisis Reporting. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @amymaxmen \n               \n                     Jordan stakes its future on science 2017-Aug-02 \n                   \n                     US foreign aid saves money as well as lives 2017-Apr-13 \n                   \n                     'Water scarcity' affects four billion people each year 2016-Feb-12 \n                   \n                     The rising pressure of global water shortages 2014-Dec-29 \n                   \n                     Jordan Ministry of Water and Irrigation \n                   \n                     Jordan Water Project, Stanford \n                   \n                     Jordan water resources, USAID \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22625", "url": "https://www.nature.com/articles/nature.2017.22625", "year": 2017, "authors": [{"name": "Dalmeet Singh Chawla "}], "parsed_as_year": "2006_or_before", "body": "Scientists hit back at a proposal to make it tougher to call findings statistically significant. Researchers are at odds over when to dub a discovery 'significant'. In July, 72 researchers  took aim at the  P  value , calling for a lower threshold for the popular but much-maligned statistic. In a response published on 18 September 1 , a group of 88 researchers have responded, saying that a better solution would be to make academics justify their use of specific  P  values, rather than adopt another arbitrary threshold. P  values have been used as measures of significance for decades, but  academics have become increasingly aware of their shortcomings  and the potential for abuse. In 2015, one psychology  journal banned  \n                 P \n                values  entirely. The statistic is used to test a \u2018null hypothesis\u2019, a default state positing that there is no relationship between the phenomena being measured. The smaller the  P  value, the less likely it is that the results are due to chance \u2014 presuming that the null hypothesis is true. Results have typically been deemed \u2018statistically significant\u2019 \u2014 and the null hypothesis dismissed \u2014 when  P  values are below 0.05. In a July preprint, since published in  Nature Human Behaviour 2 , researchers, including leaders in the push for greater reproducibility, said that this threshold should be reduced to 0.005 to keep false positives from creeping into social sciences and biomedical literature. But \u201csetting this one threshold for all sciences is too extreme,\u201d says Daniel Lakens, an experimental psychologist at Eindhoven University of Technology in the Netherlands and lead author of the new commentary, which was posted to the PsyArXiv preprint server. \u201cThe moment you ask people to justify what they are doing, science will improve,\u201d he adds. \n             Unintended consequences \n           Some researchers worry that lowering  P  value cut-offs may exacerbate the \u2018file-drawer problem\u2019, when studies containing negative results are left unpublished. A more stringent  P  value threshold could also lead to more false negatives \u2014 claiming that an effect doesn\u2019t exist when in fact it does. \u201cBefore you implement any policy, you want to be more certain that there are no unintended negative consequences,\u201d says Lakens. Instead, Lakens and colleagues say, researchers should select and justify  P  value thresholds for their experiments, before collecting any data. These levels would be based on factors such as the potential impact of a discovery, or how surprising it would be. Such thresholds could then be evaluated via their registered reports, a type of scientific article in which methods and proposed analyses are peer-reviewed before any experiments are conducted. \u201cI don\u2019t think researchers will ever have an incentive to say they need to use a more stringent threshold of evidence,\u201d counters Valen Johnson, a statistician at Texas A&M University in College Station who is a co-author of the July manuscript. And many scientists are likely to go easy on their own work, says another co-author, Daniel Benjamin, a behavioural economist at the University of Southern California, Los Angeles. But Lakens thinks that any attempts to manipulate  P  values will be obvious from the justifications that researchers pick. \u201cAt least everyone agrees that it\u2019s good to change the mindless use of 0.05,\u201d he says. Setting specific thresholds for standards of evidence is \u201cbad for science\u201d, says Ronald Wasserstein, executive director of the American Statistical Association, which last year took the unusual step of  releasing explicit recommendations on the use of  P http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503 values  for the first time in its 177-year history. Next month, the society will hold a  symposium on statistical inference , which follows on from its recommendations. Wasserstein says he hasn\u2019t yet taken a position on the current debate over  P  value thresholds, but adds that \u201cwe shouldn\u2019t be surprised that there isn\u2019t a single magic number\u201d. \n                   Big names in statistics want to shake up much-maligned P value 2017-Jul-26 \n                 \n                   Statisticians issue warning over misuse of P values 2016-Mar-07 \n                 \n                   Reproducibility: A tragedy of errors 2016-Feb-03 \n                 \n                   How scientists fool themselves \u2013 and how they can stop 2015-Oct-07 \n                 \n                   Statistics: P values are just the tip of the iceberg 2015-Apr-28 \n                 \n                   Psychology journal bans P values 2015-Feb-26 \n                 \n                   Scientific method: Statistical errors 2014-Feb-12 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22646", "url": "https://www.nature.com/articles/nature.2017.22646", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Gene-edited embryos enable researchers to unpick role of a crucial gene, with more studies likely to follow. Gene-edited human embryos have offered a glimpse into the earliest stages of development, while hinting at the role of a pivotal protein that guides embryo growth. The first-of-its-kind study stands in contrast to  previous research that attempted to fix disease-causing mutations  in human embryos, in the hope of eventually preventing genetic disorders. Whereas those studies  raised concerns  over  potential \u2018designer babies\u2019 , the latest paper describes basic research that aims to understand human embryo development and causes of miscarriage. Published online today in  Nature 1 , the study relied on  CRISPR\u2013Cas9 , a gene-editing system that can make precise changes to DNA in the genome. In this case, researchers harnessed CRISPR\u2013Cas9 to disrupt the production of a protein called OCT4 that is important for embryo development. Researchers have traditionally done such studies in mouse embryos, which are more plentiful and carry fewer ethical considerations than human embryos. But the latest study highlights key differences between the role of OCT4 in human and in mouse embryos, underscoring the limitations of relying on animal models, says stem-cell scientist Dieter Egli of Columbia University in New York City. \u201cIf we are to truly understand human embryonic development and improve human health, we need to work directly on human embryos,\u201d he says. \u201cWe cannot rely only on inference from model organisms.\u201d \n             Regulated research \n           To perform the study, a team led by developmental biologist Kathy Niakan of the Francis Crick Institute in London used a total of 58 embryos that had been generated in fertility clinics as a result of  in vitro  fertilization (IVF) treatments. The embryos were no longer needed for IVF and had been donated for research. The UK Human Fertilisation and Embryology Authority  granted permission to do the study  \u2014 the first time a national regulator has approved research involving gene editing in human embryos (previous studies in other countries were endorsed by local review boards). The team injected the molecular machinery needed for CRISPR\u2013Cas9 gene editing when the fertilized eggs, or zygotes, consisted of just one cell and then followed their development in the lab for a week. It soon became clear that normal development had derailed in embryos that lacked normal levels of OCT4. About half of the controls (which had unaltered, normal OCT4 levels) developed to form multicellular embryos called blastocysts. Of the edited embryos with disrupted OCT4 levels, only 19% made it that far. The results will reassure scientists that CRISPR\u2013Cas9 is efficient enough for studies in human embryos, says Fredrik Lanner, a developmental biologist at the Karolinska Institute in Stockholm. \u201cIf you do this in mice, you can test hundreds of embryos,\u201d he says. \u201cBut you have a limited access to human embryos.\u201d Lanner,  whose lab is conducting studies with CRISPR  of other genes that are crucial for embryo development, points to the importance of painstakingly optimizing the experimental conditions in mouse embryos before moving the studies to human embryos, as Niakan\u2019s team had done. \n             Striking differences \n           But additional studies in human embryos will still be needed to pinpoint what OCT4 is doing. The differences between mouse and human embryos were striking, says Amy Ralston, a developmental biologist at Michigan State University in East Lansing who has studied the protein in mice. Niakan's team found that human embryos stopped growing earlier than mouse embryos lacking the protein and showed different patterns of gene expression. There were also unexpected abnormalities in the cells that give rise to the placenta. The latter finding is particularly important, Niakan says, because researchers have poor models for studying placenta development \u2014 and for understanding how the process can go awry. The research could also eventually yield ways to boost the success rate of IVF and help explain why some pregnancies fail, she says. \u201cIt\u2019s an exciting first step,\u201d says Ralston. \u201cThis paper opens up a new era of human functional genetics.\u201d \n                   South Korean researchers lobby government to lift human-embryo restrictions 2017-Sep-08 \n                 \n                   Doubts raised about CRISPR gene-editing study in human embryos 2017-Aug-31 \n                 \n                   Biotechnology: At the heart of gene edits in human embryos 2017-Aug-02 \n                 \n                   CRISPR fixes disease gene in viable human embryos 2017-Aug-02 \n                 \n                   Gene-editing research in human embryos gains momentum 2016-Apr-19 \n                 \n                   UK scientists gain licence to edit genes in human embryos 2016-Feb-01 \n                 \n                   CRISPR special \n                 \n                   Kathy Niakan \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22650", "url": "https://www.nature.com/articles/nature.2017.22650", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Latest big tremor could be linked to major earthquake earlier this month. A magnitude-7.1 earthquake struck central Mexico on 19 September, killing more than 200 people and reducing buildings to rubble in the states of Puebla, Morelos and Guerrero, as well as in Mexico City. The event came 12 days after  a magnitude-8.1 tremor hit off the state of Chiapas  \u2014 Mexico's largest quake in more than a century \u2014 and 32 years to the day after the country's most damaging tremor, an 8.0, killed thousands. Like the recent Chiapas quake, the 19 September tremor struck in the middle of the Cocos geological plate \u2014 rather than along its edge, where it begins its plunge beneath the North American plate. Mexico\u2019s national seismological service  placed the epicentre of the quake at a depth of 57 kilometres , near the border of the states of Puebla and Morelos and about 120 kilometres from Mexico City. The earthquake occurred on a 'normal' fault, in which one part of Earth's crust moves higher than land on the other side. Whether the 7 September and 19 September quakes are linked \u2014 and if so, how \u2014 remains to be seen. They are too far apart (about 650 kilometres) for the second one to be considered an aftershock of the first. \n             Searching for clues \n           Big earthquakes can increase the long-term risk of seismic activity nearby by transferring stress within Earth\u2019s crust to adjacent geological faults. But that sort of \u2018static stress\u2019 transfer usually happens only within a radius equal to about three to four times the length of the original fault's rupture, says Gavin Hayes, a seismologist at the US Geological Survey in Golden, Colorado. The 7 September earthquake ruptured about 100 kilometres of the crust, which would imply its stress transfer reached no more than about 300 to 400 kilometres away, Hayes says. That puts the 19 September quake, whose epicentre was 650 kilometres away, outside the zone of influence. \u201cBut the time coincidence makes it pretty suspicious,\u201d Hayes says. \u201cA lot of people will think that they are related, and there\u2019s going to be a lot of work on that.\u201d Another possibility is that the 19 September quake is an example of \u2018dynamic triggering', in which seismic waves rippling outward from one quake affect faults much more quickly \u2014 and at much larger distances \u2014 than in static stress transfer. But dynamic triggering usually happens within hours or days of the initial quake, making the 12-day gap between the 7 September event and the latest big tremor hard to explain, says Eric Fielding, a geophysicist at NASA's Jet Propulsion Laboratory in Pasadena, California, who studies dynamic triggering. \n             Shifting ground \n           His team has been analysing  satellite radar images of the landscape around the 7 September quake , looking for changes in ground level that indicate which parts of the landscape have uplifted and which have dropped down as a result of that event. The data come from Europe\u2019s Sentinel radar satellites and Japan\u2019s ALOS-2 satellite. Fielding's team will be looking for similar information in the coming days from the 19 September quake. Radar images can help to reveal where geological stress is transferred within the ground after an earthquake. The Cocos plate begins its dive downward off the western coast of Mexico, and then flattens out for hundreds of kilometres before taking a second, steeper dive and plunging below the North American plate. The 19 September quake happened where this second bend occurs, thanks to the geological stresses that have built up where the weight of the steeply descending plate tugs on the flat section. Much of the worry about Mexico's seismic danger has focused off the western coast, where the slab begins its dive. There, on the plate boundary itself, is where the deadly earthquake struck in 1985, flattening buildings \u2014 particularly in Mexico City, which is built atop a shaky foundation of dried-up lake sediments. That disaster prompted Mexico to build an earthquake early-warning system, which on 19 September provided crucial seconds of warning for people to prepare for the shaking. Many \u2018seismic gaps\u2019 remain off Mexico's west coast, where geological stress built up by the diving plate has yet to be released by an earthquake. They include the Guerrero gap, near Acapulco, considered by many scientists to be a major threat. The death toll from the 19 September quake is expected to rise. \n                   Deadly Mexico earthquake had unusual cause 2017-Sep-09 \n                 \n                   The 24/7 search for killer quakes 2015-Jul-08 \n                 \n                   Earthquake tests 25 years of Mexican engineering 2012-Mar-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22691", "url": "https://www.nature.com/articles/nature.2017.22691", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Hundreds of species can subsist for years on tsunami debris. Two years after a tsunami devastated parts of Japan, a small black-and-white-striped fish washed ashore in Long Beach Peninsula, Washington. The barred knifejaw ( Oplegnathus fasciatus ), which is native to Asian waters, had made the 7,000-kilometre trip in the stern well of a deserted fishing vessel set adrift by the giant wave. The knifejaw found in 2013 is just one of hundreds of species carried across the Pacific Ocean to North America by debris \u2014 estimated to weigh a total of nearly 1.5\u00a0million tonnes \u2014 that was swept out to sea after the Tohoku earthquake in March 2011. As extreme coastal weather events such as hurricanes, typhoons and tsunamis become more intense and frequent as a result of climate change, researchers warn that such mass-migration events could also become more common. James Carlton, a marine ecologist at the Maritime Studies Program of Williams College and Mystic Seaport in Mystic, Connecticut, and his colleagues worked with more than 100 volunteers to look for tsunami debris along North American shores, including the west coast of the United States and Canada, as well as Hawaii. Over almost 5 years starting in 2012, they intercepted 634 objects that could be traced back to the tsunami, ranging in size from small fragments of plastic to fishing vessels and mooring docks (see ). Between them, they carried from Japan 289 species of living invertebrates and fish, the researchers report in  Science 1 . Some of the creatures had survived adrift for several years. That\u2019s just a fraction of the \u201cthousands or tens of thousands\u201d of objects estimated to have landed in North America, says Carlton. And he suspects there are more to come. \u201cMany of these can subsist in the ocean for longer than we could imagine,\u201d he says. \u201cWe had no idea this would last into 2017.\u201d The team began its search when a 165-tonne dock \u2014 made of concrete, steel and polystyrene foam \u2014 washed up on the coast of Oregon, 15 months after the disaster. This \u2018megaraft\u2019 was coated with almost 100 different species. It was a harbinger, Carlton says, of the need to monitor what else might be coming. More-recent debris has not been so species-rich; only one object hosting more than 20\u00a0species has been found since summer 2015. The team\u2019s finds included gooseneck barnacles ( Lepas  sp.) that blanketed the bottom of a wrecked fishing boat and a Japanese limpet ( Siphonuria sirius ) that had hitched a ride on a buoy. Most of the creatures arriving were invertebrates: molluscs, annelid worms, cnidarians (jellyfish and their relations), crustaceans and moss-like marine invertebrates called bryozoans. It is unusual for vertebrates such as the knifejaw fish to be carried so far, says Gail Ashton, a marine ecologist at the Smithsonian Environmental Research Center in Tiburon, California. The mass migration raises the concern that some of these trans-Pacific passengers might establish invasive populations on the North American coast. None of the species has been spotted doing so yet. But \u201cthe fact that they\u2019ve lasted in the ocean for four or five years shows they\u2019re pretty hardy\u201d, says Ashton. And by the time any species do settle, says Carlton, it could be too late to do anything about it. Once a population is common enough to see, he says, \u201cit becomes harder to manage eradication\u201d. Such a huge rafting event is unprecedented, say the researchers. Japan has seen only two other earthquakes with magnitudes comparable to Tohoku in the last few centuries; they occurred in 1896 and in 1933. \u201cIf you look at photos of the same coasts in those years, there are small villages with wood houses,\u201d says Carlton. \u201cBack then, a tsunami could not generate this sea of plastic we saw in 2011.\u201d Biodegradable objects such as wood would rarely survive such a long trip. The study underscores the far-reaching consequences of plastic in the environment, says Jenna Jambeck, an environmental engineer at the University of Georgia in Athens. \u201cOnce something enters the ocean, it becomes a global problem.\u201d \n                   Killer qualities of Japanese fault revealed 2013-Dec-05 \n                 \n                   Tsunami triggers invasion concerns 2013-Mar-06 \n                 \n                   The Japanese tsunami: After shock 2012-Mar-07 \n                 \n                   Rebuilding Japan: After the deluge 2012-Mar-07 \n                 Reprints and Permissions"},
{"file_id": "550016a", "url": "https://www.nature.com/articles/550016a", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Concern over the use of public data spurs guideline update. British graffiti artist Banksy is renowned for his anonymity. But that status was dented last year when researchers published a paper that cross-referenced the locations of Banksy\u2019s street art with public information about people\u2019s addresses and likely movements ( M. V. Hauge  et al. J. Spatial Sci.   61,  185\u2013190; 2016 ). The team, led by academics at Queen Mary University of London, concluded that someone previously suspected to be Banksy probably was the secretive artist. Because the study used public data, a university ethics committee said that the work was exempt from formal review\u00a0\u2014\u00a0and informally advised academics that it would do no harm because a UK national newspaper had already identified the person in question as Banksy. But for some ethicists, the paper highlights growing concerns about the potential hazards of research that uses public data. \u201cI think this study should never have been done,\u201d says Jake Metcalf, a technology ethicist at the think tank Data & Society in New York City. Metcalf is one of several academics calling for new guidelines to steer scientists through ethical quandaries in Internet research. The unprecedented availability of online data\u00a0\u2014\u00a0together with tools to draw patterns from it, such as machine learning\u00a0\u2014\u00a0is opening up research possibilities that outpace existing ethics frameworks around privacy, consent and harm, says Charles Ess, a research ethicist at the University of Oslo and a member of the Association of Internet Researchers. The association will discuss how to update its guidelines at its annual meeting on 19\u00a0October in Tartu, Estonia.\u00a0 A flurry of similar initiatives is under way. Earlier this year, the SATORI project, funded by the European Commission, published recommendations on Internet research as part of an effort to standardize and update research-ethics guidelines. In September, the US National Science Foundation funded a US$3-million, 4-year study called PERVADE\u00a0\u2014\u00a0of which Metcalf is a part\u00a0\u2014\u00a0that aims to chart attitudes to data-research ethics, produce best-practice guidelines and create tools to assess the potential harms of such work. And some British universities are preparing their first guidelines on the ethics of Internet research, after the UK Research Integrity Office, a national advisory body, published non-binding recommendations about it last December.\u00a0 Common themes among these efforts include rethinking what counts as \u2018public\u2019 data, the ethical use of social media and the need to consider a study\u2019s potential harm to wider society, as well as to individuals. Many countries have long-standing ethical checks for research that intervenes in human lives. But those principles, set up for medical and psychological studies, apply to research on human subjects, the definition of which often excludes Internet research, says Metcalf.\u00a0 In the United States, for instance, studies using public data (which includes that purchased from a third party) generally do not count as human-subjects research because they don\u2019t access private, identifiable information about people. They don\u2019t need to be checked by an institutional review board (IRB) or require informed consent. Guidelines issued in 2013 add that researchers should sometimes consider seeking review\u00a0\u2014\u00a0if a person incorrectly assumed that access to his or her public information was restricted, for example. But IRBs have no obligation to adopt these proposals, and different committees may come to different verdicts, says Metcalf.\u00a0 Peter Hedges, head of the research-operations office at the University of Cambridge, UK, argues that even researchers who use information that is undeniably public, such as Twitter data, should review the ethics of their work. The SATORI guidelines advise that regulators and researchers should carefully consider whether publicly available information is actually private, and not fall back on simple classifications. If someone\u2019s data are considered private and identifiable, that would usually mean obtaining their informed consent. But, in practice, such consent is often impossible to acquire for large-scale data studies, says Ess. And anonymizing data is difficult, because search engines can easily identify individuals from even small snippets of anonymized text or by cross-referencing them in multiple data sources. The SATORI guidelines recommend that researchers take precautions to ensure the anonymity of study participants, and Ess suggests that scientists can still, without too much effort, seek consent from anyone they explicitly quote in research papers. When ethics committees do assess data studies, their viewpoint might be too narrow, says Ansgar Koene, an engineer and ethicist at the University of Nottingham, UK. They tend to consider the direct damage to an individual involved in research, rather than a project\u2019s potential to do widespread harm to society. That debate flared up in September when artificial-intelligence researchers at Stanford University in California posted a preprint of research that predicted whether someone is gay from their photo; it used pictures sourced from an online dating site (see  https://osf.io/zn79k ). The study was approved by Stanford\u2019s IRB, but provoked condemnation from some advocacy groups for lesbian, gay, bisexual, transgender and queer (LGBTQ) people, which branded it dangerous. The study\u2019s lead author, Michal Kosinski, said the work aimed to protect people by exposing an existing threat from widely used technology. Kosinski and his colleague, Yilun Wang, discussed their results afterwards with representatives of the LGBTQ community, but Koene says that the discussion should have happened beforehand and the paper should have addressed their comments. Computer science is a flashpoint for Internet-research ethics. Researchers in this field are not used to working with human study participants and often don\u2019t consider the ethical impact of their work, says Koene, who has surveyed approaches to ethics in different disciplines. A major concern, academics agree, is how companies use online data for research \u2014 much of which they have proprietary access to. In 2014, for example, Facebook altered users\u2019 newsfeeds without telling them, to study how this affected their emotions. A public backlash prompted Facebook to publish some details of its internal review process ( M.\u00a0Jackman and L.\u00a0Kanerva  Wash. Lee Law Rev. Online   72,  442; 2016 ) \u2014 but there is little transparency overall about how this works, says Koene.\u00a0 Researchers may not want to see their science slowed by formal ethical review, which can be time-consuming and opaque. Better ethics training is one solution, says Koene. But a failure to align data science with public perceptions of what is acceptable could generate a severe reaction, he warns. \u201cThe public will see us as no different from corporate or other special-interest groups pursuing a hidden agenda,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Controversial patient-consent proposal left out of research-ethics reforms 2017-Jan-18 \n                   \n                     Research integrity: Don't let transparency damage science 2016-Jan-25 \n                   \n                     Researchers wrestle with a privacy problem 2015-Sep-22 \n                   \n                     US agencies plan research-ethics overhaul 2015-Sep-03 \n                   \n                     Guidance issued for US Internet research 2013-Apr-24 \n                   \n                     Social science: Open up online research 2011-Dec-07 \n                   \n                     SATORI project \n                   \n                     Association of Internet Researchers Annual Conference \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22858", "url": "https://www.nature.com/articles/nature.2017.22858", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Artificial-intelligence program AlphaGo Zero trained in just days, without any human input. An artificial intelligence (AI) program from Google-owned company DeepMind has reached superhuman level at the strategy game Go without learning from any human moves. This ability to self-train without human input is a crucial step towards a general AI that can tackle practical challenges such as protein folding or materials research, said DeepMind chief executive Demis Hassabis at a press briefing. \u201cWe\u2019re quite excited because we think this is now good enough to make some real progress on some real problems,\u201d he said. Previous Go-playing computers developed by DeepMind, which is based in London, began by training on more than 100,000 expert human games. The latest program, known as AlphaGo Zero, instead starts from scratch using random moves, and learns by playing against itself. After 40 days of training and 30 million games, the AI was able to beat the previous world champion \u2014 another  DeepMind AI known as AlphaGo Master . The results are published today in  Nature 1 , with an accompanying commentary 2 . Getting this technique, known as reinforcement learning, to work well is difficult and resource-intensive, says Oren Etzioni, chief executive of the Allen Institute for Artificial Intelligence in Seattle, Washington. That the team could build such an algorithm that surpassed previous versions using less training time and computer power \u201cis nothing short of amazing\u201d, he adds. \n             Strategy supremo \n           The ancient Chinese game of Go involves placing black and white stones on a board to control territory. Like its predecessors, AlphaGo Zero uses a deep neural network \u2014 a type of AI inspired by the structure of the brain \u2014 to learn abstract concepts from the boards. Told only the rules of the game, it learns by trial and error, feeding back information on the eventual winning strategy to improve itself after each game.\u00a0 At first, AlphaGo Zero\u2019s learning mirrored that of human players. It started off trying greedily to capture stones, as beginners often do, but after three days it had mastered complex tactics used by human experts. \u201cYou see it rediscovering 1,000 years of human knowledge,\u201d said Hassabis. After 40 days, the program had found plays unknown to humans. Approaches using purely reinforcement learning have struggled in AI because ability does not always progress consistently, said David Silver, a scientist at DeepMind who has been leading the development of AlphaGo, at the briefing. Bots often beat their predecessor, but forget how to beat earlier versions of themselves. \u201cWhat we have now is the first, if you like, really stable, solid version of reinforcement learning, that\u2019s able to learn completely from scratch,\u201d he said. AlphaGo Zero\u2019s predecessors used two separate neural networks: one to predict the probable best moves, and one to evaluate, out of those moves, which was most likely to win. To do the latter, they used \u2018roll outs\u2019 \u2014 playing multiple fast and randomized games to test possible outcomes. AlphaGo Zero, however, uses a single neural network. Instead of exploring possible outcomes from each position, it simply asks the network to predict a winner. This is like asking an expert to make a prediction, rather than relying on the games of 100 weak players, said Silver. \u201cWe\u2019d much rather trust the predictions of that one strong expert.\u201d Merging these functions into a single neural network made the algorithm both stronger and much more efficient, said Silver. It still required a huge amount of computing power \u2014 four of the specialized chips called tensor processing units, which Hassabis estimated to be US$25 million of hardware. But this was less than one-tenth what its predecessors used. It also trained itself in days, rather than months. The implication is that \u201calgorithms matter much more than either computing or data available\u201d, said Silver. \n             Think outside the board \n           Several DeepMind researchers have already moved from working on AlphaGo to practical applications, said Hassabis. One promising area, he suggested, is understanding how proteins fold, an essential tool for drug discovery. Generating examples of protein folding can involve years of painstaking crystallography, so there are few data to learn from, and there are too many possible solutions to predict structures from amino-acid sequences using a brute-force search. The puzzle shares some key features with Go, however. Both involve well-known rules and have a well-described goal. In the longer term, such algorithms might be applied to similar tasks in quantum chemistry, materials design and robotics. Silver acknowledged that to apply its approach to real-world tasks more generally, the AI will need the ability to learn from smaller amounts of data and experience. Another essential step will be learning the rules of a game for itself, as  another DeepMind bot did in 2015  for arcade games. Hassabis reckons this is something AlphaGo Zero could eventually do: \u201cWe\u2019re pretty sure it would work, it would just extend the learning time a lot,\u201d he said. \n                   Google reveals secret test of AI bot to beat top Go players 2017-Jan-04 \n                 \n                   Google's AI reasons its way around the London Underground 2016-Oct-13 \n                 \n                   What Google\u2019s winning Go algorithm will do next 2016-Mar-15 \n                 \n                   Google AI algorithm masters ancient game of Go 2016-Jan-27 \n                 \n                   Game-playing software holds lessons for neuroscience 2015-Feb-25 \n                 \n                   Computer science: The learning machines 2014-Jan-08 \n                 \n                   Nature  special: The Go files \n                 Reprints and Permissions"},
{"file_id": "nj7674-147a", "url": "https://www.nature.com/articles/nj7674-147a", "year": 2017, "authors": [{"name": "Chris Woolston"}], "parsed_as_year": "2006_or_before", "body": "Organizers are starting to drop meetings, thanks to falling attendance and budget squeezes. Citing flagging attendance and falling revenue, two scientific organizations are scaling back their conference rosters. The American Society for Microbiology (ASM) in Washington DC has cut out most of its small specialized conferences, and the European Molecular Biology Organization (EMBO) in Heidelberg, Germany, has dropped its large annual meeting in favour of speciality events. Every year since 2014, the ASM has sponsored seven to ten specialized conferences that each drew several hundred attendees. But attendance has dropped by 5\u201310% since then, says David Hooper, head of the Infection Control Unit at Massachusetts General Hospital in Boston and chair of the ASM's meetings board, probably because of tightened purse strings and a growing need for cross-discipline collaborations, which are more easily fostered at larger meetings. The society will now host just one or two small conferences each year, including one on next-generation sequencing and one on cell communication in bacteria. It has also committed to keeping a meeting on biofilms that it has scheduled for next October in Washington DC. Hooper says that the society will not trim its medium-sized or larger conferences, which continue to draw thousands of attendees. Those include the popular Biothreats conference, slated for February in Baltimore, Maryland. ASM Microbe, the society's largest conference, which draws more than 10,000 attendees for posters and presentations, is scheduled for next June in Atlanta, Georgia. \n               Different tack \n             EMBO, by contrast, decided to drop the annual EMBO Meeting after a sharp decline in attendance in 2015 and 2016, says programme manager Gerlind Wallon. In 2009 and 2010, the first years of its existence, the meeting drew close to 1,500 participants. But by 2016, attendance had halved. \u201cScientists, particularly the younger ones, are economizing to go to more specialist conferences,\u201d she says. Small meetings seem to be more successful for EMBO, which has not seen a comparable decline in the number of attendees or presenters at those speciality events, including more than 60 meetings this year. Although some had lower attendance than expected, others had higher, Wallon says. Since 2009, she adds, EMBO has seen a 50% increase in the number of scientists applying for grants to organize meetings. Attendance at the some of the world's largest science conferences has stayed relatively steady in recent years. The Society for Neuroscience in Washington DC reported that more than 24,300 scientists attended its annual meeting last year in San Diego, California, just slightly below the average for the previous five years. And the European Society of Cardiology Congress brought more than 32,800 delegates to Rome in 2016, matching its 10-year high. Hooper notes that the ASM may change its line-up and the content of smaller conferences according to input from its advisory panel. He also says that it is unclear why attendance has fallen at smaller ASM conferences, but notes that researchers have had to make hard choices. \u201cOne can't go to multiple conferences every year,\u201d he says. \n                     Sustainability: A greener culture \n                   \n                     A clean, green science machine \n                   \n                     Biotech audience shrinks \n                   \n                     American Society for Microbiology \n                   \n                     European Molecular Biology Organization \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22737", "url": "https://www.nature.com/articles/nature.2017.22737", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Rainer Weiss, Barry Barish and Kip Thorne share the 2017 prize for their work at LIGO to detect ripples in space-time. Three physicists who had leading roles in the first direct detection of gravitational waves have won the 2017 Nobel Prize in Physics. Rainer Weiss, at the Massachusetts Institute of Technology (MIT) in Cambridge and Barry Barish and Kip Thorne, both at the California Institute of Technology in Pasadena, share the 9 million Swedish krona (US$1.1-million) award for their work at the US-based Laser Interferometer Gravitational-Wave Observatory (LIGO). In September 2015, LIGO picked up the deformations in space-time caused by the collision of two distant black holes. That discovery, which was  announced in February 2016 , opened up a new field of astronomy, in which scientists listen to the space-time vibrations emitted by some of the Universe\u2019s most cataclysmic events. And it confirmed the existence of gravitational waves, which Albert Einstein had predicted a century before. Weiss and Thorne are two of three physicists known as the Troika \u2014 the founders of LIGO\u2019s giant twin detectors in Livingston, Louisiana, and in Hanford, Washington. The third troika member,  Ronald Drever, died on 7 March this year . And Barish, who was LIGO director from 1997 to 2005, is widely credited with having transformed the collaboration from a chaotic endeavour to a well-oiled machine. \"I view this more as a thing that recognizes the work of about 1,000 people, a really dedicated effort that\u2019s been going on for \u2014 I hate to tell you \u2014 as long as 40 years,\" said Weiss in an interview with the Nobel Committee just after winning the prize. \"We were all very happy for them to be recognized. They worked on this for decades,\" says Gabriela Gonzalez, a physicist at Louisiana State University in Baton Rouge, and a LIGO team member and former spokesperson for the collaboration. The Nobel prize can be awarded only to a maximum of three people, but the Nobel Committee noted the huge numbers of people who worked on LIGO in its press release. Researchers had been widely expecting the committee to reward the team since last year's detection announcement. \"I'm very happy that they got the right people,\" says Charles Misner, a general relativity theorist at the University of Maryland in College Park. Half of the Nobel prize has been awarded to Weiss, with the other half split between Barish and Thorne. \n               Unimpeded motion \n             Few physicists doubted the existence of gravitational waves before the LIGO discovery. The distortions in space-time are an inevitable consequence of Einstein\u2019s general theory of relativity, and propagate across the Universe almost unimpeded. In 1974, they were confirmed indirectly when researchers examined the radio flashes emitted by a pair of merging neutron stars; the shifts in the flashes' timing matched predictions of how gravitational waves would carry energy away from the event. That discovery was rewarded with the 1993 Nobel Prize in Physics. But sensing the waves themselves was a monumental task. Even the most powerful deformations\u00a0\u2014\u00a0those produced by collapsing stars or colliding black holes\u00a0\u2014\u00a0would typically be tiny by the time they reached Earth. The waves detected in 2015 stretched and squeezed LIGO\u2019s perpendicular 4-kilometre vacuum pipes by a fraction of a proton\u2019s width, but that was enough to noticeably shift out of sync the laser beams bouncing inside the pipes. Physicists in the United States and the then-Soviet Union first proposed using laser interferometers to detect gravitational waves in the 1960s. Weiss made the first detailed calculations for how an interferometer would work in 1972. The idea seemed so far-fetched that even he was not sure it would work. \u201cIt might come to a junction in a year or so when we will decide it ain\u2019t worth it,\u201d he told science sociologist Harry Collins at the time 1 . Weiss, who was born in Germany in 1932, emigrated with his family to the United States in 1938 to escape from Nazism. He built his first prototype interferometer in the mid-1970s, soon followed by researchers in Europe \u2014 among them, Drever and his collaborators at the University of Glasgow, UK, and another group in Munich, Germany. Thorne, born in Utah in 1940 to Mormon parents, specialized in general relativity and had also been developing ideas on the waves. At a conference in Washington DC in 1975, Thorne and Weiss shared a room in an over-booked hotel. During their conversations, Weiss convinced Thorne that interferometers were the right approach. Thorne, Weiss and Drever joined forces in the early 1980s, when it became clear that the US National Science Foundation would not fund two separate efforts, and the LIGO collaboration was born. \n               Dramatic turn-around \n             The troika did not always work smoothly and, at their own admission, did not possess the right skills for managing what was quickly becoming a vast operation. Things improved dramatically after Barish, who had been LIGO\u2019s principal investigator since 1994, became director in 1997. Collins, who has closely studied the collaboration for decades, says that Barish turned LIGO into a \u2018big science\u2019 organization. \u201cWithout Barish turning things around, it would have collapsed,\u201d he says. LIGO initially struggled to get funded, but ended up being the largest and most expensive experiment in the history of the US National Science Foundation. Its two nearly identical detectors first opened in 2002, with an admittedly scant chance of detecting anything during their first phase of data collection. The observatory shut down in 2010 for a major overhaul, and restarted in September 2015, three times more sensitive than before. Researchers were cautiously optimistic of a discovery within a few years. But the Universe was kind to LIGO, providing a dramatic event for it to record on 14 September, while the interferometers were still being calibrated, days before their official science run was due to start. Since then, LIGO has detected at least three other gravitational-wave events\u00a0\u2014\u00a0the most recent  also spotted by Virgo, a similar interferometer near Pisa, Italy . The LIGO team benefited from significant research efforts in other countries. Germany and the United Kingdom have contributed funding and research, and GEO600, a smaller interferometer near Hannover, Germany, is the main test-bed for technologies that are implemented on its larger cousins in the United States. The three winners have other strings to their bows: as well as working on LIGO, Weiss was a leading scientist in the Cosmic Background Explorer (COBE), a NASA probe that in the 1990s produced the first map of the cosmic microwave background, the \u2018afterglow\u2019 of the Big Bang. (Two other COBE researchers shared the physics Nobel in 2006.) Thorne, who has spearheaded theoretical studies of gravitational waves, also helped to conceive  the original idea for the plot of the 2014 film  Interstellar , on which he was an executive producer. And before joining LIGO, Barish worked on neutrino experiments at the Fermi National Laboratory in Batavia, Illinois and elsewhere. He has also led the design of a proposed International Linear Collider. Thorne and Weiss were generally considered shoo-ins for the Nobel. Before Drever\u2019s passing last March, the troika raked up almost every prize there was for them to win, including the  $3-million Special Breakthrough Prize in Fundamental Physics ; the $500,000 Gruber Foundation Cosmology Prize; the $1.2-million Shaw Prize in Astronomy; and the $1-million Kavli Prize in Astrophysics. Additional reporting by Elizabeth Gibney. \n                     Medicine Nobel awarded for work on circadian clocks 2017-Oct-02 \n                   \n                     Physics of 2D exotic matter wins Nobel 2016-Oct-04 \n                   \n                     Einstein's gravitational waves found at last 2016-Feb-11 \n                   \n                     Morphing neutrinos win physics Nobel 2015-Oct-06 \n                   \n                     Nature Video: Discovering gravitational waves \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22822", "url": "https://www.nature.com/articles/nature.2017.22822", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Controversial policy means mainstream media are starting to rival rigorous academic publications in some universities in China. One of China\u2019s most prestigious universities plans to give some articles in newspapers and posts on major social-media outlets the same weight as peer-reviewed publications when it evaluates researchers. The policy has sparked a vigorous debate among Chinese academics. Proponents say it will encourage researchers to engage with the public, but many are concerned that it will promote those who toe the party line established by China\u2019s strictly censored media and social media, at the expense of more highly qualified researchers. Critics also say the system could be manipulated to inflate a researcher\u2019s impact, for example by artificially boosting page views. Zhejiang University in Hangzhou announced the policy on its WeChat page on 15 September, saying that it would mainly apply to the humanities and social sciences. But Chinese researchers say the move could influence science as well, by giving a hiring and promotion advantage to politically minded scientists. \u201cYou do not need to be good scientist, you do not need to publish good science papers,\u201d says one biologist at a prominent Beijing-based university who requested anonymity. He is concerned that the policy could alter evaluations at China\u2019s main grant agency, the National Natural Science Foundation of China (NSFC). \u201cIf they open the Pandora\u2019s box, the NSFC might change its policy as well,\u201d he says. The agency's head, Yang Wei, says it will do no such thing. NSFC grants are given solely \u201caccording to the judgement of peer reviewers\u201d, he says. \n             Viewing figures \n           The Zhejiang policy sets specific criteria: articles have to be original, written by the researcher and at least 1,000 words long; they need to be picked up by major news outlets and widely disseminated through social media; and they need to have been seen by a large number of people. The policy requires an article to be viewed more than 100,000 times on WeChat, China\u2019s most popular instant-messaging service, or 400,000 times on news aggregators such as Toutiao. Articles that meet the criteria will be considered publications, alongside papers in peer-reviewed journals.\u00a0 The university has also established a publication hierarchy, with official media outlets such as the  People\u2019s Daily  considered most important, regional newspapers and magazines occupying a second tier, and online news sites such as Sina, NetEase or Sohu ranking third. Ping Fu, who researches library science at Central Washington University in Ellensburg, is concerned that the policy will blur the distinction between peer-reviewed academic publications and popular writing. This could affect the top levels of scholarship in China, he says.\u00a0Liu Jin-ping, a biologist at Hainan University in Haikou, also worries that the policy will give prominence to stories that \u201cflatter the government\u201d. Some academics will aim to \u201cbecome Internet stars\u201d so they can be promoted, he wrote on his blog. \n             Full credit \n           Lin Boqiang, an energy-policy and climate-change researcher at Xiamen University who has published some 800 media commentaries, thinks researchers should get credit for this work. He \u201ccriticizes government policy all the time\u201d and would never write something incorrect to please political powers, he says: \u201cOur reputation is on the line.\u201d But both Liu and Lin are concerned the system could be gamed, either for self-interest or with political motivation. Lin says these articles should not be considered equal to academic publications. \u201cOther universities will do this,\u201d he says. \u201cI hope they do it in a more sophisticated way.\u201d Zhejiang University refused to answer  Nature \u2019squestions about the policy, but it posted a statement on its homepage in response to the controversy, saying that the commentaries in the mainstream media will supplement and not replace peer-reviewed journals: \u201cThis policy is to explore more forms of exposure of research, especially for humanities and social sciences, and the assessment will be made by a strict panel review, which will not lower the academic standard.\u201d Grant committees in other countries encourage researchers to do public outreach, but the Zhejiang policy is rare in how it ranks such efforts for researcher evaluation. Jilin University in Changchun announced a similar policy in August. \n             Balancing act \n           Glen Peters, a climate-policy researcher at the Center for International Climate Research in Oslo, agrees that researchers should be acknowledged for important contributions to public understanding, but he says the challenge in giving scientists credit for public outreach is how to measure its quality and impact against those of conventional journal publications. \u201cIf you don\u2019t get the weighting right, then incentives could be perverted and lead to bad outcomes, such as poor quality and political bias,\u201d he says. \u201cThe potential is high, but so are the risks.\u201d One journalist at China\u2019s  Legal Daily  has  questioned whether such a policy is legal . It was drafted by the university\u2019s propaganda department, part of the Communist Party of China. According to the laws that govern universities,\u00a0evaluation decisions are supposed to be made by university administrative departments or faculty committees, writes the journalist. Some scientists contacted by  Nature  are confident that this initiative will not affect science. But others see it as part of the government\u2019s attempts to control information. There is already concern about Chinese President Xi Jinping\u2019s efforts to align education with communist values and to control what is written by journalists or on social media. Scientists say that bans on Google, Google Scholar and other Internet-based technologies hamper their ability to stay in touch with international peers.\u00a0\u201cThere are certainly many layers of concern,\u201d says one environmental scientist who did not want to be named for fear of damaging relationships with Chinese colleagues. \n                   Don\u2019t pay prizes for published science 2017-Jul-07 \n                 \n                   Policy: Boost basic research in China 2016-Jun-22 \n                 \n                   China rushes through major funding system 2008-Sep-10 \n                 \n                   Nature  special: Science in China \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22482", "url": "https://www.nature.com/articles/nature.2017.22482", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Gossip over potential detection of colliding neutron stars has astronomers in a tizzy. Astrophysicists may have detected gravitational waves last week from the collision of two neutron stars in a distant galaxy \u2014 and telescopes trained on the same region might also have spotted the event. Rumours to that effect are spreading fast online, much to researchers\u2019 excitement. Such a detection could mark a new era of astronomy: one in which phenomena are both seen by conventional telescopes and \u2018heard\u2019 as vibrations in the fabric of space-time. \u201cIt would be an incredible advance in our understanding,\u201d says Stuart Shapiro, an astrophysicist at the University of Illinois at Urbana\u2013Champaign. Scientists who work with gravitational-wave detectors won\u2019t comment on the gossip because the data is still under analysis. Public records show that telescopes around the world have been looking at the same galaxy since last week, but astronomers caution that they could have been picking up signals from an unrelated source. As researchers hunt for signals in their data,  Nature  explains what is known so far, and the possible implications of any discovery. \n             What is the gossip? \n           The Laser Interferometer Gravitational-Wave Observatory (LIGO) in Louisiana and Washington state has  three times detected gravitational waves  \u2014 ripples in the fabric of space-time \u2014 emerging from colliding black holes. But scientists have been hoping to detect ripples from another cosmic cataclysm, such as the merger of neutron stars, remnants of large stars that exploded but were not massive enough to collapse into a black hole. Such an event should also emit radiation across the electromagnetic spectrum \u2014 from radio waves to \u03b3-rays \u2014 which telescopes might be able to pick up. On 18 August, astronomer J. Craig Wheeler of the University of Texas at Austin began the public rumour mill when he tweeted, \u201cNew LIGO. Source with optical counterpart. Blow your sox off!\u201d An hour later, astronomer Peter Yoachim of the University of Washington in Seattle tweeted that LIGO had seen a signal with an optical counterpart (that is, something that telescopes could see) from a galaxy called NGC 4993, which is around 40 million parsecs (130 million light years) away in the southern constellation Hydra. \u201cMerging neutron-neutron star is the initial call\u201d, he followed up. Some astronomers who do not want to be identified say that rumours had been privately circulating before Wheeler\u2019s and Yoachim\u2019s tweets. If gravitational-wave researchers saw a signal, it is plausible that they could know very quickly whether it emerged from colliding black holes or neutron stars, because each type of event has its own signature, even though data must be studied carefully to be more precise about an event\u2019s origin. It\u2019s also possible that  LIGO\u2019s sister observatory Virgo  in Pisa, Italy, which has been helping LIGO to hunt for gravitational waves since August, after taking a break for an upgrade, might have spotted the event. That would give researchers more confidence about its source. (Virgo has an average sensitivity for neutron-star mergers of only 25 million to 27 million parsecs, but in some regions of the sky, it can see farther, up to 60 million parsecs away, says physicist Giovanni Losurdo, who led the detector's upgrade work.) Both Wheeler and Yoachim declined to comment, and Wheeler later apologized on Twitter. \u201cRight or wrong, I should not have sent that tweet. LIGO deserves to announce when they deem appropriate. Mea culpa,\u201d he wrote. \n             What about the telescope observations? \n           Public records  show that NASA\u2019s Fermi Gamma-ray Space Telescope has spotted \u03b3-rays emerging from the same region of sky as the potential gravitational-wave source. A senior Fermi member declined to comment on the observation, but it would be consistent with expectations that neutron-star collisions may be behind the enigmatic phenomena known as short \u03b3-ray bursts (GRBs), which typically last a couple of seconds and are usually followed by an afterglow of visible light and sometimes, radio waves and x-rays, lasting up to a few days. But although the Fermi telescope has seen a GRB, it may not be able to pinpoint its origin with high precision, astronomers caution. Other telescopes were also turned to look at NGC 4993 after an alert about a potential gravitational wave sighting. On 22 August, a Twitter feed called Space Telescope Live, which provides live updates of what the Hubble Space Telescope is looking at, suggested that a team of astronomers was looking at a binary neutron-star merger using the probe\u2019s on-board spectrograph, which is what astronomers would normally use to look at the afterglow of a short GRB. The Hubble tweet has since been deleted.  Public records also confirm  that multiple teams have used the Hubble Space Telescope over the last week to examine NGC 4993, and state as their reason that they are trying to follow up on a candidate observation of gravitational waves. On 23 August, a commenter on the  blog of astrophysicist Peter Coles , of Cardiff University in the UK, noted that NASA\u2019s Chandra X-ray observatory had jumped into the action, too. The Chandra website contains a public record of an observation made on 19 August. The telescope pointed at celestial coordinates in the galaxy NGC 4993 and observed an event called SGRB170817A \u2014 indicating \u2018short GRB of 2017-August-17\u2019. The most revealing part of the report is the \u201ctrigger criteria\u201d section, which explains the reason for over-riding any previously scheduled observation to turn the telescope in that direction. It says: \u201cGravitational wave source detected by aLIGO, VIRGO, or both.\u201d\u00a0 Publicly available records from other major astronomy facilities \u2014 including the European Southern Observatory\u2019s Very Large Telescope and the world\u2019s premiere radio observatory, the Atacama Large Millimeter/submillimeter Array (ALMA), both in Chile \u2014 show that those also targeted NGC 4993 on 18 and 19 August. \n             What could we learn from a neutron-star merger? \n           Gravitational-wave signals from black-hole mergers are brief, typically lasting a second or less. But a neutron-star merger could yield a signal that lasts up to a minute: neutron stars are less massive than black holes and emit less-powerful gravitational waves, so it takes longer for their orbits to decay and for the stars to spiral into each other. Longer events enable much more precise tests of Albert Einstein\u2019s general theory of relativity, which predicts gravitational waves \u2014 perhaps giving more clues to the origins of neutron stars. The short GRB that telescopes might have observed would be significant, too \u2014 not least because if it is associated with gravitational waves, it would validate decades of astrophysical theorizing that GRBs are associated with neutron-star collisions. \u201cOnly gravitational waves could give us the smoking gun,\u201d says Eleonora Troja, an astrophysicist at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland. Still, a short GRB would be an important discovery on its own. Most such events are seen in the distant Universe, billions of parsecs away. NGC 4993, at 40 million parsecs away, would probably be the closest short GRB ever detected, says astrophysicist Derek Fox of Pennsylvania State University in University Park. Details of the gravitational waves at the time of the collision and in the following instances could also reveal information about the structure of neutron stars \u2014 which is  largely unknown  \u2014 and whether their merger resulted again in a neutron star or in the formation of a new black hole. \n             When will we know? \n           On 25 August, LIGO and Virgo will end their current data-collecting run. After that, researchers will post only a \u201ctop-level update\u201d, meaning a brief note indicating whether the observatories have picked up potential \u2018candidate events\u2019 that need further analysis, says David Shoemaker, a physicist at the Massachusetts Institute of Technology who is LIGO\u2019s spokesperson. \"It will take time to do justice to the data, and ensure that we publish things in which we have very high confidence,\u201d he says. \n             Update 25 August: The LIGO\u2013Virgo collaboration posted its  \n             top-level update \n             , saying: \u201cSome promising gravitational-wave candidates have been identified in data from both LIGO and Virgo during our preliminary analysis, and we have shared what we currently know with astronomical observing partners. We are working hard to assure that the candidates are valid gravitational-wave events, and it will require time to establish the level of confidence needed to bring any results to the scientific community and the greater public. We will let you know as soon we have information ready to share.\u201d \n           \n                   LIGO\u2019s underdog cousin ready to enhance gravitational-wave hunt 2017-Feb-08 \n                 \n                   Gravitational waves: 6 cosmic questions they can tackle 2016-Feb-09 \n                 \n                   Has giant LIGO experiment seen gravitational waves? 2015-Sep-30 \n                 \n                   Nature Special: Gravitational waves \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22474", "url": "https://www.nature.com/articles/nature.2017.22474", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Simulations follow how swirls in a fluid transfer and dissipate energy. \u201cWhen I meet God, I\u2019m going to ask him two questions: why relativity? And why turbulence? I really believe he\u2019ll have an answer for the first.\u201d This probably apocryphal quote, attributed to physicist Werner Heisenberg, captures the way many scientists feel about turbulence: a phenomenon in which the orderly flow of a fluid (a liquid or a gas) disintegrates into seemingly unpredictable swirls, such as when a river flows round a rock, or when milk mixes with coffee. But researchers are making progress on understanding the physics of turbulence. In a paper published on 17 August in  Science 1 , simulations by a Spanish team of aeronautical engineers help to solve a long-standing puzzle over how energy moves around in turbulent fluids. And in the past 12 months, mathematicians have made progress in explaining how turbulence helps to dissipate the energy of fluids, causing them to stop moving. An improved understanding of turbulence and its implications for energy transfer could have big pay-offs for scientists \u2014 from astrophysicists who want to model how gas flows in galaxy clusters to climatologists simulating how ocean currents carry heat.  \n               An issue of scale \n             In theory, the Navier\u2013Stokes equations, developed almost 200 years ago, describe the physics of fluids well. But these equations are devilishly hard to solve. So engineers and scientists usually come up with simplified theoretical models or resort to numerical simulations when they want to predict fluid flow. This approach has its limits: modelling turbulence bogs down even supercomputers. Now, aeronautical engineer Jos\u00e9 Cardesa of the Polytechnic University of Madrid and his collaborators say that they have been able to fully simulate for the first time how turbulence spreads kinetic energy across swirls of smaller and smaller scales. For water held in a large tank, for instance, their computer simulations could track how energy is transferred over about a minute from a 1-metre-diameter swirl into smaller eddies down to the 12-centimetre scale. Their results validate a theory formulated by Russian mathematical physicist Andrei Kolmogorov in the early 1940s. Among its consequences is that turbulence occurs in a cascade: large eddies break down into smaller ones, which in turn split into even smaller ones, in a fractal fashion. In this model, the transfer of kinetic energy occurs rather like a baton being passed around runners in a relay race, Cardesa says, but one in which the runners get progressively smaller and more numerous. Kolmogorov\u2019s picture implies that energy spreads from large swirls to smaller eddies nearby, rather than spreading to farther distances. That has some support from mathematical theorems, but Cardesa\u2019s team has confirmed it, says Gregory Eyink, a theoretical physicist at Johns Hopkins University in Baltimore, Maryland. Cardesa says that understanding these dynamics could help to improve predictions of energy flow in phenomena such as aerodynamic drag. \n               Turbulence cascade \n             Researchers think that this \u2018turbulence cascade\u2019 explains how even fluids with low viscosity \u2014 such as gases in the atmosphere, where there is little resistance between moving layers \u2014 still quickly convert their kinetic energy into heat and slow down when turbulence kicks in. Turbulence spreads energy into increasingly tiny eddies, which, at their smaller scale, increase local viscosity. Like friction between solid objects, this viscosity acts to increase resistance to movement between layers of fluid, and thereby dissipates kinetic energy as heat. Mathematicians are pushing exploration of low-viscosity fluids to their ultimate limit. The physicist, chemist and mathematician Lars Onsager suggested in 1949 that, in theory, a fluid could still dissipate energy even if its viscosity were to become vanishingly small, or zero (a situation that is never seen in the real world). In this hypothetical scenario, the fluid\u2019s motion will just keep dispersing into infinitesimally small eddies, where it still will die out eventually. \u201cThat was kind of a shocking idea,\u201d says Philip Isett, a mathematician at the University of Texas at Austin.  \n               boxed-text \n             Onsager conjectured that turbulence could slow non-viscous fluids only under particular conditions; in other cases, the fluids would keep flowing for ever, as might be expected. In the 1990s, Eyink proved mathematically that this idea was correct. And in a paper that he posted online last year 2 , Isett published solutions to the Navier\u2013Stokes equations showing that some zero-viscosity flows can indeed slow and stop because of turbulence alone. His work is due to appear in the  Annals of Mathematics . The motions of the fluids described by these solutions are not very realistic: they start at rest, magically begin to move, and then grind to a stop. But this year, other mathematicians, including Camillo De Lellis of the University of Zurich in Switzerland and L\u00e1szl\u00f3 Sz\u00e9kelyhidi of the University of Leipzig in Germany (on whose work Isett had based his own), found slightly more realistic solutions to the same equations, in which initially-moving fluids slow down 3 . Physicists might pay attention to the latest mathematical work only when it becomes more relevant to the real world, Sz\u00e9kelyhidi says. A start would be to find solutions describing a fluid that starts with viscosity and gradually becomes infinitesimally thin. But Charles Doering, a mathematical physicist at the University of Michigan in Ann Arbor, says he hopes that the approach might ultimately point the way to a model of turbulence that is simpler to use than the Navier\u2013Stokes equations, and works in all situations. That is the \u201cgrand dream\u201d, he says. Related external links Reprints and Permissions"},
{"file_id": "548379a", "url": "https://www.nature.com/articles/548379a", "year": 2017, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Mixing artificial intelligence with climate science helps researchers to identify previously unknown atmospheric processes and rank climate models. As Earth-observing satellites become more plentiful and  climate models more powerful , researchers who study global warming are facing a deluge of data. Some are now turning to the latest trend in artificial intelligence (AI) to help trawl through all the information, in the hope of discovering new climate patterns and improving forecasts.\u00a0 \u201cClimate is now a data problem,\u201d says Claire Monteleoni, a computer scientist at George Washington University in Washington DC who has helped to pioneer the marriage of machine-learning techniques with climate science. In machine learning, AI systems improve in performance as the amount of data that they analyse grows. This approach is a natural fit for climate science: a single run of a high-resolution climate model can produce a petabyte of data, and the archive of climate data maintained by the UK Met Office, the national weather service, now holds about 45 petabytes of information \u2014 and adds 0.085 petabytes a day.\u00a0 Researchers hoping to wrangle all these data will meet next month in Boulder, Colorado, to assess the state of science in the field known as climate informatics. Work in this area has grown rapidly. In the past several years, researchers have used AI systems to help them to rank climate models, spot cyclones and other extreme weather events \u2014 in both real and modelled climate data \u2014 and identify new climate patterns. \u201cThe pace seems to be picking up,\u201d says Monteleoni. Conventional computer algorithms rely on programmers entering reams of rules and facts to guide the system\u2019s output. Machine-learning systems \u2014 and a subset, deep-learning systems, which simulate complex neural networks in the human brain \u2014  derive their own rules after combing through large amounts of data . This is often useful for subtle tasks that people take for granted but conventional computers find hard to perform: understanding language,  reading handwritten notes  or identifying a category of objects in a messy data set, such as spotting cats in YouTube videos.\u00a0 Weather, another complex topic, is well suited to analysis by deep-learning approaches. In 2016, researchers reported the first use of a deep-learning system to identify tropical cyclones, atmospheric rivers and weather fronts: loosely defined features whose identification depends on expert judgement 1 . That feat showed that the algorithm could replicate human expertise. Now the team, which is based at Lawrence Berkeley National Laboratory (LBNL) in California, hopes to use similar techniques to study all kinds of extreme events \u2014 including ones not yet identified. The researchers\u2019 ultimate goal is to better assess and predict how these events are shifting in the face of climate change. \u201cIt\u2019s not simple,\u201d says Prabhat, lead author of the 2016 paper, who directs big-data efforts for the National Energy Research Scientific Computing Center at the LBNL. \u201cBut it\u2019s not as hard as the commercial applications for deep learning\u201d, such as language translation and image identification. Vipin Kumar, a computer scientist at the University of Minnesota in Minneapolis, has used machine learning to create algorithms for monitoring forest fires and assessing deforestation. When his team tasked a computer with learning to identify air-pressure patterns called teleconnections,  such as the El Ni\u00f1o weather pattern , the algorithm found a previously unrecognized example over the Tasman Sea 2 . And Monteleoni has developed machine-learning algorithms to create weighted averages of the roughly 30 climate models used by the Intergovernmental Panel on Climate Change. By learning the models\u2019 strengths and weaknesses, such algorithms generate better results than conventional approaches that treat all models equally, Monteleoni says. The climate community is starting to adopt AI algorithms that weight climate models as a way to help improve forecasts. \n               Machine mysteries \n             Because deep-learning systems develop their own rules, researchers often can\u2019t say how or why these algorithms arrive at a given result. That makes some people uneasy about relying on these \u2018black boxes\u2019 to forecast imminent weather emergencies such as floods. \u201cI\u2019m reluctant to use [AI] as an answer machine,\u201d says William Drew Collins, a climate modeller at the LBNL. \u201cIf I can\u2019t explain what the machine is doing, then there\u2019s a problem.\u201d\u00a0 Instead, Collins says that AI algorithms are best suited to help test the next generation of climate models. These models aim to incorporate complex climate phenomena such as the fine structures of clouds, atmospheric rivers and ocean eddies. \u201cWe need a benchmark of the level of detail that these models should be aiming for,\u201d Collins says. \u201cWe need a guide star. Machine learning is well suited for that.\u201d\u00a0 Nevertheless, some AI algorithms are proving useful for weather forecasting. In a 2016 test, nine meteorologists from the US National Weather Service chose to use an AI algorithm in about 75% of their forecasts of storm duration when given a choice between AI and conventional methods 3 . The study\u2019s lead author, computer scientist Amy McGovern of the University of Oklahoma in Norman, now plans to incorporate an AI algorithm into the weather service\u2019s hail forecasts.\u00a0 Most climatologists are still using conventional methods to analyse their data \u2014 but that is changing. \u201cIf you go to the major modelling centres and ask them how they work, the answer won\u2019t be machine learning,\u201d says Collins. \u201cBut it will get there.\u201d \n                     The \u2018time machine\u2019 reconstructing ancient Venice\u2019s social networks 2017-Jun-14 \n                   \n                     Machine learning predicts the look of stem cells 2017-Apr-05 \n                   \n                     Machine-learning algorithm quantifies gender bias in astronomy 2016-Nov-04 \n                   \n                     Can we open the black box of AI? 2016-Oct-05 \n                   \n                     Can artificial intelligence create the next wonder material? 2016-May-04 \n                   \n                     Computer science: The learning machines 2014-Jan-08 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22531", "url": "https://www.nature.com/articles/nature.2017.22531", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Monkeys implanted with neurons derived from stem cells showed sustained improvement after two years. Japanese researchers report promising results from an experimental therapy for Parkinson\u2019s disease that involves implanting neurons made from \u2018reprogrammed\u2019 stem cells into the brain. A trial conducted in monkeys with a version of the disease showed that the treatment improved their symptoms and seemed to be safe, according to a report published on 30 August in  Nature 1 . The study\u2019s key finding \u2014 that the implanted cells survived in the brain for at least two years without causing any dangerous effects in the body \u2014 provides a major boost to researchers\u2019 hopes of testing stem-cell treatments for Parkinson\u2019s in humans, say scientists.\u00a0 Jun Takahashi, a stem-cell scientist at Kyoto University in Japan who led the study, says that his team plans to begin transplanting neurons made from  induced pluripotent stem (iPS) cells  into people with Parkinson\u2019s in clinical trials soon. The research is also likely to inform several other groups worldwide that are testing different approaches to treating Parkinson\u2019s using stem cells, with trials also slated to begin soon. Nature  breaks down the latest research \u2014 and what it means for the future of stem-cell treatments. \n             Why are stem cells a promising treatment for Parkinson\u2019s disease? \n           Parkinson\u2019s is a neurodegenerative condition caused by the death of cells called dopaminergic neurons, which make a neurotransmitter called dopamine in certain areas of the brain. Because dopamine-producing brain cells are involved in movement, people with the condition experience characteristic tremors and stiff muscles. Current treatments address symptoms of the disease but not the underlying cause.  Researchers have pursued the idea that pluripotent stem cells, which can form any cell type in the body, could replace dead dopamine-making neurons in people with Parkinson\u2019s, and thus potentially halt or even reverse disease progression. Embryonic stem cells, derived from human embryos, have this capacity, but they have been the subject of ethical debates. Induced pluripotent stem (iPS) cells, which are made by coaxing adult cells into an embryonic-like state, have the same versatility without the associated ethical concerns.  \n             What did the latest study find? \n           Takahashi\u2019s team transformed iPS cells derived from both healthy people and those with Parkinson\u2019s into dopamine-producing neurons. They then transplanted these cells into macaque monkeys with a form of the disease induced by a neuron-killing toxin. The transplanted brain cells survived for at least two years and formed connections with the monkey\u2019s brain cells, potentially explaining why the monkeys treated with cells began moving around their cages more frequently. \n             Why is the research important? \n           Crucially, Takahashi\u2019s team found no sign that the transplanted cells had developed into tumours \u2014 a key concern with treatments that involve pluripotent cells \u2014 or that they evoked an immune response that couldn\u2019t be controlled with immune-suppressing drugs. \u201cIt\u2019s addressing a set of critical issues that need to be investigated before one can, with confidence, move to using the cells in humans,\u201d says Anders Bjorklund, a neuroscientist at Lund University in Sweden. \n             When will clinical trials begin and how will they work? \n           \u201cI hope we can begin a clinical trial by the end of next year,\u201d says Takahashi. Such a trial would be the first iPS cell trial for Parkinson's. In 2014, a Japanese woman in her 70s became the  first person to receive cells derived from iPS cells , to treat her macular degeneration. In theory, iPS cells could be tailor-made for individual patients, which would eliminate the need to use drugs that suppress a possible immune response to foreign tissues. But customized iPS cells are expensive to make and can take a couple months to derive and grow, Takahashi notes. So his team instead plans to establish iPS cell lines from healthy people and then use immune cell biomarkers to match them to people with Parkinson\u2019s in the hope of minimizing the immune response (and therefore the need for drugs to blunt the attack). In a study described in an accompanying paper in  Nature Communications 2 , Takahashi\u2019s team implanted into monkeys iPS-cell-derived neurons from different macaques. They found that transplants between monkeys carrying similar white blood cell markers triggered a muted immune reaction. \n             What other stem-cell approaches are being tested for Parkinson\u2019s? \n           Earlier this year, Chinese researchers began a Parkinson\u2019s trial that used a different approach:  giving patients neural-precursor cells made from embryonic stem cells , which are intended to develop into mature dopamine-producing neurons. A year earlier, in a separate trial, patients in Australia received similar cells. But some researchers have expressed concerns that the immature transplanted cells could develop tumour-causing mutations. Meanwhile, researchers who are part of a Parkinson\u2019s stem-cell therapy consortium called GForce-PD, of which Takahashi\u2019s team is a member, are set to bring still other approaches to the clinic. Teams in the United States, Sweden and the United Kingdom are all planning trials to transplant dopamine-producing neurons made from embryonic stem cells into humans. Previously established lines of embryonic stem cells have the benefit that they are well studied and can be grown in large quantities, and so all trial participants can receive a standardized treatment, notes Bjorklund, also a consortium member. Jeanne Loring, a stem-cell scientist at the Scripps Research Institute in La Jolla, California, favours transplanting iPS-derived neurons made from a patient\u2019s own cells. Although expensive, this approach avoids dangerous immunosuppressive drugs, she says. And because iPS cells are established anew for each patient, the lines go through relatively few cell divisions, minimizing the risk that they will develop tumour-causing mutations. Loring hopes to begin her team\u2019s trial in 2019. \u201cThis shouldn\u2019t be a race and we\u2019re cheering for success by all,\u201d she says. Lorenz Studer, a stem-cell scientist at the Memorial Sloan Kettering Cancer Center in New York City who is working on a trial that will use neurons made from embryonic stem cells, says that there are still issues to work out, such as the number of cells needed in each transplant procedure. But he says that the latest study is \u201ca sign that we are ready to move forward\u201d. \n                   Trials of embryonic stem cells to launch in China 2017-May-31 \n                 \n                   Japanese man is first to receive 'reprogrammed' stem cells from another person 2017-Mar-28 \n                 \n                   How iPS cells changed the world 2016-Jun-15 \n                 \n                   Fetal-cell revival for Parkinson\u2019s 2014-Jun-11 \n                 \n                   Stem-cell treatment for Parkinson's brings mixed results 2006-Oct-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22513", "url": "https://www.nature.com/articles/nature.2017.22513", "year": 2017, "authors": [{"name": "Jeff Tollefson"}, {"name": "Amy  Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Researchers were told to censor descriptions of projects funded by a Department of Energy laboratory. Multiple researchers who received grants from the US Department of Energy (DOE) say that they have been asked to remove references to \u201cclimate change\u201d and \u201cglobal warming\u201d from the descriptions of their projects, they say. In one case, a lab official at the DOE\u2019s Pacific Northwest National Laboratory (PNNL) in Richland, Washington, asked an ecologist to elide references to climate change from her grant proposal to satisfy US President Donald Trump's budget language restrictions. The scientist, Jennifer Bowen of Northeastern University in Boston, Massachusetts, posted an e-mail from the lab official to Facebook on 24 August. \u201c I have been asked to contact you to update the wording in your proposal abstract to remove words such as \u2018global warming\u2019 or \u2018climate change\u2019,\u201d wrote the official, project coordinator Ashley Gilbert of the PNNL\u2019s Environmental Molecular Sciences Laboratory (EMSL). Bowen\u2019s project will examine how environmental stressors, such as climate change, affect the ecology of saltwater marshes. Gilbert\u2019s office told  Nature  that she was unavailable for comment, and a PNNL spokesperson referred questions to DOE headquarters in Washington DC. Department spokeswoman Shaylyn Hynes declined to answer questions about the situation, but said that \u201cthere is no departmental-wide policy banning the term \u2018climate change\u2019 from being used in DOE materials\u201d. Bowen could not be reached for comment on the matter. But Jonathan Sanderman, a biogeochemist at the Woods Hole Research Center in Falmouth, Massachusetts, and co-principal investigator on the marsh project, confirmed that the e-mail came from Gilbert. Sanderman speculates that PNNL officials \u201care worried the grant will get zeroed out if someone sees that it lists climate change\u201d. \n             Not the only one \n           Bowen and Sanderman\u2019s project is among 14 that were announced on 23 August as winners of research grants from the EMSL and the Joint Genome Institute, which is managed by the DOE\u2019s Lawrence Berkeley National Laboratory in California. Another grant winner from that group, ecologist Scott Saleska of the University of Arizona in Tucson, confirmed that he, too, had received a request from a DOE official on 24 August to remove references to climate change from his project\u2019s description. Saleska\u2019s study focuses on the effects of decomposing plant material on permafrost, and his team\u2019s abstract highlighted the implications of this process for climate change. The  White House\u2019s 2018 budget proposal for the DOE Office of Science  proposes scaling back or eliminating support for many climate-research programmes and research areas, such as climate feedbacks. But the document also emphasizes the need to study how carbon cycles through ecosystems \u2014 a category that encompasses Bowen\u2019s, Sanderman\u2019s and Saleska\u2019s projects. Saleska says it appears that DOE programme managers are being careful to make it clear that they are, in fact, following the president\u2019s budget directive. \u201cWhat else can they do?\u201d he asks. Saleska says that he is more concerned that research priorities are being set by political ideology that is at odds with scientific knowledge. Sanderman also lamented the fact that scientists are being forced to change the way they talk about their work. \u201cBut if that's what it takes to keep science going for a couple of years, we will I guess play along,\u201d he adds. \n                   US science envoy resigns in protest at Trump policies 2017-Aug-23 \n                 \n                   US government disbands climate-science advisory committee 2017-Aug-20 \n                 \n                   Fears rise for US climate report as Trump officials take reins 2017-Aug-01 \n                 \n                   How scientists reacted to the US leaving the Paris climate agreement 2017-Jun-02 \n                 \n                   Trump pulls United States out of Paris climate agreement 2017-Jun-01 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22479", "url": "https://www.nature.com/articles/nature.2017.22479", "year": 2017, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Efforts to relocate artefacts to sites of origin could stall after gold robbery at national park. When thieves stole some centuries-old golden artefacts from a South African park in December, they did more than just spirit away archaeological treasures. The robbery has triggered an outcry among academics, who have only just heard of the theft, and raised questions about growing efforts to return culturally important materials to the region where they were found. Archaeologists and curators from major museums worry that smaller, local facilities sometimes fall short on security and cannot preserve artefacts properly, leaving them at risk. \u201cThere is always a trade-off of security versus local relevance and tourism benefits at remote regional museums,\u201d says Kevin MacDonald, an archaeologist at University College London. \u201cIf I were custodian of such materials, I would think twice before putting them into vulnerable situations.\" The stolen artefacts include a necklace, bracelets and beads excavated from two graves at the Thulamela archaeological site, which was inhabited between the thirteenth and seventeenth centuries. This site is located within Kruger National Park, and the artefacts were on loan to the park when they were stolen from a small museum there. The theft was first publicly reported this June in an Afrikaans-language newspaper,  Die Beeld . In South Africa, heritage legislation encourages that artefacts be stored in their province of origin. However, only universities and museums have the accreditation to store them permanently. The Thulamela relics are usually housed at the Ditsong National Museum of Cultural History in Pretoria. The robbery leaves a gap in the history of the gold trade in southern Africa, says Sian Tiley-Nel, who manages the museums at the University of Pretoria. Tiley-Nel oversees a group of artefacts discovered at what was once the kingdom of Mapungubwe in the north of South Africa. Mapungubwe, a 13th and 14th century trading centre, was excavated from the 1930s; Thulamela in the 1990s. The two sites were the most significant archaeological gold discoveries in southern Africa, Tiley-Nel says. \u201cGold artefacts are an extreme rarity and that is why the Thulamela theft is a travesty.\u201d Researchers say that it is a blow to lose the Thulamela materials because new techniques are providing more information than ever about the composition and provenance of ancient metals. Samples such as those from Thulamela could help researchers to\u00a0trace the origins of Africa\u2019s pre-colonial gold trade, says MacDonald. \n               Roadblock to return \n             The theft is also hampering discussions about moving other artefacts to locations under the authority of South African National Parks, or SANParks, a government-supported conservation body. Researchers at other institutions say that SANParks has been seeking to become an official repository for about a decade, and it has a number of artefacts on loan from both the Thulamela and Mapungubwe collections. But Tiley-Nel says that the University of Pretoria has serious concerns about the state of the Mapungubwe collection on loan to SANParks. \u201cSite inspections have revealed deteriorating conditions, poor curation and improper collections management practices at the Mapungubwe Interpretation Centre, which was not originally designed to house original museum material,\u201d she says. A SANParks spokesperson disputed Tiley-Nel's criticisms of the conditions in its facilities. \u201cSANParks has a duty to tell the full story about its parks and where it necessitates exhibiting artefacts, steps are taken to put such on display,\" the spokesperson added, saying that the criticisms were meant to undermine the work done by the authority to upgrade its museums and keep artefacts where they historically belong. Tiley-Nel says the University of Pretoria has raised its concerns several times with SANParks, but has received no response. And the University of Pretoria and other curators say that they are considering withdrawing their artefacts from SANParks and halting talks about future loans. Researchers are also concerned that SANParks has yet to officially inform the Ditsong museum about the theft of the Thulamela pieces. The museum found out only through the archaeological grapevine this April, says Frank Teichert, an archaeologist there, and has received an email confirmation but no comprehensive list of what has been stolen. A SANParks spokesperson says that the museum had informed police and was not aware it had to let anyone else know about the theft. The loss of the Thulamela materials could have a broader impact, says Chris Wingfield, an archaeologist at the Museum of Archaeology and Anthropology in Cambridge, UK. \u201cThe international significance may partly relate to repatriation debates, since these sometimes hinge around the security of repatriated artefacts,\u201d he says. \n                     Dreams of the Stone Age dated for first time in southern Africa 2017-May-03 \n                   \n                     North America\u2019s oldest mummy returned to US tribe after genome sequencing 2016-Dec-07 \n                   \n                     South African academics warn of universities on the brink 2016-Aug-26 \n                   \n                     Museums: The endangered dead 2015-Feb-18 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22511", "url": "https://www.nature.com/articles/nature.2017.22511", "year": 2017, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "Soft-tissue patterns on a well-preserved fossil suggest that elaborate spines helped dinosaurs to attract mates and communicate. The thick body armour on some dinosaurs seems perfectly engineered to foil hungry predators. But the remains of a newly discovered armoured dinosaur hint that its spiky suit had another role: showing off to potential mates and rivals. The spikes on a well-preserved fossil of a 1,300-kilogram armoured dinosaur called  Borealopelta markmitchelli  exhibit the same growth pattern as antelope horns and other structures used for both defence and display, says vertebrate palaentologist Caleb Brown of the Royal Tyrrell Museum of Palaeontology in Drumheller, Canada. \u201cThey might have been billboards, basically, to advertise for the animal,\u201d Brown says. He is scheduled to present his findings on 26 August at the Society of Vertebrate Paleontology annual meeting in Calgary, Canada 1 . Fossils generally don\u2019t reveal much about the size of a dinosaur\u2019s spines when it was alive. Armoured dinosaurs were sheathed in bone plates, but that bone was also crowned by more flexible tissue made partly of keratin. Such soft tissue is seldom preserved in the fossil record, leaving researchers uncertain of the size and variety of these keratin caps. But researchers got a rare glimpse of this soft tissue with the 2011 discovery in Canada of the first specimen of  B. markmitchelli , which lived 110 million years ago. The exquisitely preserved fossil allowed Brown to measure both the keratin caps and bone plates from the animal\u2019s snout to its hips. He found that the flatter bone plates closer to its tail were covered with a thin crust of keratin. But the keratin on the tusk-like spines protruding from the animal\u2019s shoulders was much thicker, making up one-third of the spines\u2019 length. Chunky keratin ornaments also capped the bone spikes on the animal\u2019s neck. Up and down the animal\u2019s body, the taller the bone plate, the thicker its cap of keratin. Brown says that pattern is common in horns and antlers, which today\u2019s animals use to send signals to each other as well as to fend off\u00a0attackers. \n             Armour attraction \n           It\u2019s also telling that  B. markmitchelli \u2019s most elaborate decorations are near the front of its body, as are modern-day horns and antlers. Two Borealopeltas facing off would each have gotten an eyeful of bristling armour. The details add up to suggest that the evolution of  B. markmitchelli \u2019s flashy spikes was driven by the demands of social communication. The adornments might have provided a warning to potential foes, a lure to potential sexual partners \u2014or both. The argument that dinosaur armour had a role beyond protection makes sense, says vertebrate palaeontologist Thomas Holtz of the University of Maryland in College Park. \u201cThis is a nice indication that there is more to armour than absorbing damage,\u201d he says. B. markmitchelli  tells scientists \u201can incredible amount\u201d, agrees vertebrate palaeontologist Michael Burns of Jacksonville State University in Alabama. The animal helps to reveal how armour was patterned and how it evolved over time, he says, but saying that the spikes served a role in mating displays is speculation, given that there\u2019s data from only one specimen. Brown agrees that his idea isn\u2019t definitive. Other exceptionally preserved fossils would help to confirm his thinking, he says, although it may be a long time before researchers are lucky enough to find anything to match Borealopelta. \n                   Feathers were the exception rather than the rule for dinosaurs 2013-Dec-27 \n                 \n                   Fossil scans reveal origins of teeth 2013-Oct-16 \n                 \n                   Fossil scars capture dinosaur headbutts 2012-Oct-19 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22447", "url": "https://www.nature.com/articles/nature.2017.22447", "year": 2017, "authors": [{"name": "Ben Upton"}], "parsed_as_year": "2006_or_before", "body": "Blast from  Hunley \u2019s own torpedo probably killed its crew instantly. Researchers say they\u2019ve solved one of the most enduring mysteries of the American Civil War: what caused the puzzling demise of the  H.L. Hunley , the first combat submarine in history to sink an enemy warship. The Confederate craft famously disappeared with all its crew on 17 February 1864, just after destroying the USS  Housatonic  in Charleston Harbour. The  Hunley \u2019s wreck was not found until 1995. When it was raised from the seabed in 2000, the skeletons of its eight-man crew were still at their stations, with no evidence of escape attempts. Since then, archaeologists and conservationists have pored over the submarine, which is kept at Clemson University Restoration Institute in South Carolina, for clues to its destruction. Popular theories have suggested that the crew of the  Housatonic  managed to shoot holes in the craft; that the  Hunley  accidentally collided with another ship; or that its crew were incapacitated, and perhaps instantly killed, by the blast from the submarine\u2019s own torpedo. The latter theory now seems correct, says Rachel Lance, a graduate student in injury biomechanics at Duke University, North Carolina. \u201cThe pressure wave from the explosion was transmitted into the submarine. It was sufficiently large that the crew were killed,\u201d she says. Lance and other researchers simulated the explosive forces the crew experienced by blowing up a scale model dubbed the USS  Tiny , one-sixth the size of the  Hunley , while it was submerged in a farmer\u2019s pond. They published their findings on 23 August in  PLOS One 1 . \n               Early submarine \n             The  Hunley  was one of many early submersibles developed by the Union and Confederate sides in the Civil War while each side battled for naval supremacy, says James Delgado, a former director of maritime heritage at the US National Oceanic and Atmospheric Administration. (Delgado is now vice-president at a marine archaeology firm called SEARCH, based in Florida).\u00a0 The 12-metre-long vessel was built from sheets of high-tensile boiler iron, held together by rivets hammered flush with her exterior to minimize drag. The crew used geared hand cranks to power the craft, and sat hunched on a bench over the central crankshaft. The  Hunley \u2019sonly weapon was a black gunpowder-filled copper cylinder \u2014 \u201cabout the size of a beer keg\u201d, says Lance \u2013 attached to a 6.7-metre pole mounted on the bow. In 2013, the theory that the explosion from this cylinder had affected the  Hunley \u2019s own crew gained credence when researchers established that the submarine was still attached to the explosive charge when it went off. They found copper ribbons from the charge embedded in the pole; suggesting that the torpedo was never designed to be detached from the submarine, but was intended instead to be rammed directly into an enemy ship. To gauge the effect of the explosion, Lance and other researchers blasted the  Tiny  with increasingly large black-powder charges, and used sensors to measure the peak pressure experienced inside the midget submarine. Lance then used equations to scale up the blast to match that which struck the crew of the  Hunley , which had a much thinner hull than modern submarines do. \n               Instant death? \n             Robert Salzar, who studies blast injury biomechanics at the University of Virginia in Charlottesville says that the blast might have killed the crew indirectly, by knocking them unconscious and causing the craft to sink, but he doubts that the effect was instantaneous. The bleeding and trauma caused by excessive pressure on the lungs \u2014 a condition called blast lung \u2014 is \u201cnot instantly lethal by itself\u201d, Salzar says. Lance says that to be sure about the blast strength, a full-scale re-creation would be needed. She says her findings suggest that the crew had a 16% chance of survival, based only on the lung trauma they would probably have experienced. But she adds that the absence of an autopsy \u2014 which would have had to be performed right after the  Hunley \u2019s sinking \u2014 makes it impossible to determine a precise cause of death. By the night of the  Hunley \u2019s final mission, the submarine had already sunk twice during training, killing 13 men \u2014 including Horace Lawson Hunley, a wealthy lawyer who gave his name and financial support to the vessel. Still, says Delgado, perceptions of the craft as a failed experiment are wrong. The submarine was at the cutting edge of nautical engineering for its time, and its pyrrhic victory bolstered the spirits of the Confederate side after a string of battlefield defeats. \u201cThere\u2019s nothing primitive about the  Hunley, \u201d Delgado says. \n                     Show of shipwrecked treasures raises scientists\u2019 ire 2017-Feb-07 \n                   \n                     Human skeleton found on famed Antikythera shipwreck 2016-Sep-19 \n                   \n                     Underwater archaeologists unearth ancient butchering site 2016-May-13 \n                   \n                     Shipwreck points to 18th-century race to colonize New Zealand 2014-Jan-06 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22547", "url": "https://www.nature.com/articles/nature.2017.22547", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Alternative explanations challenge whether technique actually fixed a genetic mutation as claimed. Doubts have surfaced about a landmark paper claiming that human embryos were cleared of a deadly mutation using genome editing. In an article 1  posted to the bioRxiv preprint server on 28 August, a team of prominent stem-cell scientists and geneticists question whether the mutation was actually fixed. The 2 August  Nature  paper 2 , led by reproductive biologist Shoukhrat Mitalipov at the Oregon Health and Science University in Portland, described  experiments in dozens of embryos to correct a mutation  that causes a heart condition called hypertrophic cardiomyopathy. In contrast to previous human-embryo editing studies, Mitalipov\u2019s team reported a high success rate at correcting a disease-causing mutation in a gene. The team claimed that the CRISPR\u2013Cas9 genome editing tool was able to replace a mutant version of the  MYBPC3  gene carried by sperm with a normal copy from the egg cell, yielding an embryo with two normal copies. Mitalipov\u2019s team also introduced a healthy version of the gene along with the CRISPR machinery, but they found that the corrected embryos had shunned it for the maternal version. But there is reason to doubt whether this really occurred, reports a team led by Dieter Egli, a stem-cell scientist at Columbia University in New York City, and Maria Jasin, a developmental biologist at Memorial Sloan Kettering Cancer Center in New York City. George Church, a geneticist at Harvard Medical School in Boston, Massachusetts, is another co-author. In their bioRxiv paper, Egli and Jasin and their co-authors say that there is no plausible biological mechanism to explain how a genetic mutation in sperm could be corrected based on the egg\u2019s version of the gene. More likely, they say, Mitalipov\u2019s team failed to actually fix the mutation and were misled into thinking they had by using an inadequate genetics assay. Egli and Jasin declined to comment because they say they have submitted their article to  Nature . \u201cThe critique levelled by Egli  et al . offers no new results but instead relies on alternative explanations of our results based on pure speculation,\u201d Mitalipov said in a statement. \n             Shared concerns \n           But other scientists contacted by  Nature 's news team shared the Egli team's concerns. ( Nature \u2019s news team is editorially independent of its journal team.) Reproductive biologist Anthony Perry at the University of Bath, UK, says that after fertilization, the genomes of the egg and sperm reside at opposite ends of the egg cell, and each is enshrouded in a membrane for several hours. This fact, Perry says, would make it difficult for CRISPR-Cas9 to fix the sperm\u2019s mutation based on the egg\u2019s version of the gene, using a process called homologous recombination. \u201cIt\u2019s very difficult to conceive how recombination can occur between parental genomes across these huge cellular distances,\u201d he says. Egli and Jasin raise that issue in their paper. They suggest that Mitalipov\u2019s team was misled into believing that they had corrected the mutation by relying on a genetic assay that was unable to detect a far likelier outcome of the genome-editing experiment: that CRISPR had instead introduced a large deletion in the paternal gene that was not picked up by their genetic assay. The Cas9 enzyme breaks DNA strands, and cells can attempt to repair the damage by haphazardly stitching the genome together, often resulting in missing or extra DNA letters. That explanation makes sense, says Ga\u00e9tan Burgio, a geneticist at the Australian National University in Canberra. \u201cIn my view Egli  et al . convincingly provided a series of compelling arguments explaining that the correction of the deleterious mutation by self repair is unlikely to have occurred.\u201d Another possibility Egli\u2019s team raise is that the embryos were produced without a genetic contribution from sperm, a process known as parthenogenesis. Mitalipov\u2019s team showed that the paternal genome was present in only 2 out of the 6 embryonic stem cell lines they made from gene-edited embryos. Robin Lovell-Badge, a developmental biologist at the Francis Crick Institute in London, says that it is possible that there is a \u201cnovel or unsuspected\u201d biological mechanism at work in the very early human embryo that could explain how Mitalipov\u2019s team corrected the embryos\u2019 genomes in the manner claimed. He would first like to hear from Mitalipov before passing judgement. \u201cIt simply says that we need to know more, not that the work is unimportant,\u201d Lovell-Badge says of Egli and Jasin\u2019s paper. In the statement, Mitalipov\u2019s said his team stands by their results. \u201cWe will respond to their critiques point by point in the form of a formal peer-reviewed response in a matter of weeks.\u201d \n                   CRISPR fixes disease gene in viable human embryos 2017-Aug-02 \n                 \n                   UK bioethicists eye designer babies and CRISPR cows 2016-Sep-30 \n                 \n                   Gene-editing research in human embryos gains momentum 2016-Apr-19 \n                 \n                   Should you edit your children\u2019s genes? 2016-Feb-23 \n                 \n                   UK scientists gain licence to edit genes in human embryos 2016-Feb-01 \n                 \n                   Nature special: CRISPR \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22508", "url": "https://www.nature.com/articles/nature.2017.22508", "year": 2017, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "The animals seem to have died while huddling together 70 million years ago. The fossilized remains of three young dinosaurs who seem to have been snuggled together in sleep have been found in a stone block that poachers hacked out of the Mongolian desert. Researchers say the 70-million-year-old specimens are the first known example of dinosaurs sleeping in a group, a behaviour called communal roosting. Many modern species, including crows and bats, engage in the practice, which helps animals to regulate their body temperature and avoid predators. The three dozy dinosaurs were probably relatives and possibly siblings, says vertebrate palaeontologist Greg Funston of the University of Alberta in Canada, who led the team that analysed the fossils. The trio \u201cclearly had a quite close bond\u201d, Funston says. \u201cThey were living together at the time of death.\u201d He is scheduled to describe the fossils on 25 August at the annual meeting of the Society of Vertebrate Paleontology in Calgary, Canada. Mongolian customs agents seized the stone specimen at an airport in 2006, before it could be smuggled out of the country. A geochemical analysis by Federico Fanti, a vertebrate palaeontologist at the University of Bologna in Italy, and his colleagues suggests that the dinosaurs probably come from the Bugiin Tsav fossil site in the Gobi desert. Fanti presented the geochemical data on 24 August, at the same palaeontology meeting. Funston\u2019s team identified the fossils as a new species of oviraptorid \u2014 a group of dinosaurs with short faces, long necks and toothless beaks that lived during  the Cretaceous period, 145 million to 65 million years ago . The species, which has not yet been formally named, has a domed crest on its head, like that of a modern-day cassowary, and walked on two legs. \n               Teenage gang \n             Unlike most dinosaur fossils, two of the animals in the block are crouched belly down. These two, which are more complete than the third, have their necks curled back towards their bodies, while their arms cradle their heads. The pose \u201cis quite similar to what ostriches and emus do when they get into deep sleep,\u201d Funston says. A handful of previously discovered fossils  capture napping dinosaurs, but all show a lone animal . The new fossil suggests that communal roosting developed in animals with rich social lives, Funston says. Oviraptorids fit the bill: they browsed for food in groups and probably flashed their crests at rivals or potential mates. By contrast, another group of bird-like dinosaurs called troodontids lacked such sophisticated behaviours and did not roost communally. From the width of the thighbones of the two more extensive skeletons in the block, the researchers estimate that each weighed roughly 45 kilograms, a little more than a German shepherd dog. The third skeleton is too fragmented for the researchers to estimate its weight. But it is roughly the same size as its companions, suggesting the three were close in age. A female oviraptorid could lay dozens of eggs, always in multiples of two. So the animals might well have been siblings, Funston says, or perhaps cousins. Two additional Mongolian fossils of the same species help to bracket the age of the sleeping trio. A previously discovered adult from a different bone bed weighed 75 kilograms. Another specimen recovered from poachers in 2006 was 33 kilograms and, judging by its bone development, was probably less than one year old. That led the team to estimate the block animals\u2019 age at 2 to 5 years \u2014 making them the equivalent of \u201cteenagers hanging out in the parking lot\u201d, jokes David Varricchio, a vertebrate palaeontologist at Montana State University in Bozeman. Having specimens of varied ages will bring insights on how this class of animals grew and evolved, says Michael Pittman, a palaeontologist at the University of Hong Kong. \n               Sleep study \n             The configuration of the three animals implies they were touching each other, and the researchers think the youngsters were probably huddling for warmth. That suggests that the animals had tried to maintain a constant body temperature, Funston says, even though most animals that huddle for warmth are small. Funston speculates that frigid weather or a sand storm drove the three dinosaurs to nestle together. Other researchers have reservations about that idea. The animals may have huddled together to hide or merely because the spot was \u201ca great place to sleep\u201d, says John Grady, a biologist at Bryn Mawr College in Pennsylvania who has studied the metabolic rates of dinosaurs. And Varricchio wonders whether the young reptiles were resting or taking shelter from harsh conditions rather than sleeping. But Funston argues that modern animals that roost together don\u2019t usually make direct contact except for warmth. Animals that died in events such as floods are preserved in very different stances from that of the oviraptorid trio, he says, making it unlikely that the young dinosaurs were awake. Whatever the three fossilized dinosaurs were doing, researchers say that their remains suggest that young oviraptorids were social animals. There is fossil evidence of adult oviraptorids sitting on nests, and it makes sense that the young \u201cshould be palling around\u201d rather than getting in the adults\u2019 way, Varricchio says. The life-like pose of the fossils in the block, he adds, shows \u201cthey were alive together and they perished together\u201d. \n                     Geology: A trip to dinosaur time 2010-Sep-08 \n                   \n                     Fossil dinosaur slept like a bird 2004-Oct-13 \n                   \n                     Dinosaur like chicken-rabbit cross 2002-Sep-19 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22510", "url": "https://www.nature.com/articles/nature.2017.22510", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Energy researcher Daniel Kammen faults US president\u2019s positions on climate change and energy and his failure to condemn white supremacists. An energy researcher at the University of California, Berkeley, resigned his post as a science envoy for the US Department of State on 21 August, citing US President Donald Trump\u2019s \u201cattacks on the core values of the United States\u201d. In a  resignation letter  addressed to Trump, Daniel Kammen joined political leaders from both major parties who have criticized the president\u2019s equivocal response to violent demonstrations by white supremacists in Charlottesville, Virginia, on 12 August. Kammen also condemned the Trump administration\u2019s \u201cdestructive\u201d policies on energy and the environment, which he said have affected his work as a science envoy. Such policies include the president\u2019s decision  to pull the United States out of the 2015 Paris climate pact . \u201cYour presence in the White House harms the United States domestically and abroad and threatens life on this planet,\u201d wrote Kammen, whose term as an envoy was set to end next month. The first letter of each paragraph in his message forms an acrostic that spells out the word \u201cimpeach\u201d. Former president Barack Obama created the science envoy programme in 2010  to boost outreach and partnerships with predominantly Muslim countries . The effort, which is run by the state department, has since expanded to cover more countries. Kammen is one of 18 scientists who have taken part in the envoy programme; his work in Africa and the Middle East has focused on national security, jobs and sustainable energy. The White House did not immediately respond to requests for comment. A state department official confirmed that Kammen was one of three active science envoys and said the department is in the process of appointing more. The official declined to comment on Kammen\u2019s resignation letter. Andrew Rosenberg, who heads the Center for Science and Democracy at the Union of Concerned Scientists in Cambridge, Massachusetts, says that Kammen\u2019s letter illustrates the moral and ethical quandaries that Trump\u2019s policies have created for  scientists who serve the US government . \u201cFor the science envoys like Dan, where you are going and representing the United States, it\u2019s particularly difficult,\u201d Rosenberg says. \u201cIt\u2019s a personal struggle that everyone has to go through.\u201d Another science envoy, ecologist Thomas Lovejoy of George Mason University in Fairfax, Virginia, says that he understands and respects Kammen\u2019s decision to resign. Nonetheless, Lovejoy has elected to continue in his work on biodiversity and sustainability with Amazon rainforest nations, including Peru, Columbia and Brazil. That includes working to advance an agreement between the United States and Peru to address a spike in illegal gold mining in the western Amazon. \u201cI\u2019ve seen how catalytic this kind of thing can be,\u201d Lovejoy says of his envoy efforts. \u201cI\u2019m just personally going ahead and doing what I think needs to be done.\u201d \n                     US government disbands climate-science advisory committee 2017-Aug-20 \n                   \n                     Fears rise for US climate report as Trump officials take reins 2017-Aug-01 \n                   \n                     Seek climate advice through established routes 2017-Aug-01 \n                   \n                     Trump pulls United States out of Paris climate agreement 2017-Jun-01 \n                   \n                     Trump agenda threatens US legacy of science diplomacy 2017-Jan-27 \n                   Related external links Reprints and Permissions"},
{"file_id": "548508a", "url": "https://www.nature.com/articles/548508a", "year": 2017, "authors": [{"name": "Nicky Phillips"}], "parsed_as_year": "2006_or_before", "body": "Australian lawsuit highlights how difficult it is to turn global warming data into useful advice. In a world-first case, an Australian court will next month begin hearing from shareholders who have sued a bank for failing to disclose its vulnerability to climate change. The case highlights the fact that financial institutions around the world have been slow to acknowledge the risk that climate change poses to investments in infrastructure, agriculture and property. But researchers say the lawsuit also shows that Australia and many other countries are currently unable to forecast the financial risks of climate change. Shareholders Guy and Kim Abrahams filed the lawsuit on 8 August against the Commonwealth Bank of Australia, saying that the institution\u2019s 2016 directors\u2019 report did not adequately inform investors of climate-change risks. Their suit also seeks an injunction to stop the bank from making the same omissions in future annual reports. Climate scientist Andy Pitman at the Centre of Excellence for Climate System Science in Sydney, Australia, says that researchers have been warning companies and governments for years about the need to invest in climate modelling and the related field of climate services, which provides forecasts and other information to public and private users. He says that it would take substantial investment and five to ten years of work for his team to provide banks with the climate information they need. To be useful, he says, the forecasts would need to be on a time scale that is specific to a business or government\u2019s climate vulnerabilities, such as a period of months to years, or on small spatial scales, such as the size of a farmer\u2019s field. \u201cThat\u2019s hugely challenging,\u201d he says. \u201cIt\u2019s the difference between building a car that travels around Sydney and building one that wins a Formula One Grand Prix.\u201d In theory, it should be possible to make such forecasts, but \u201cit\u2019s a huge undertaking to actually do it\u201d, says Pitman; and it would require high-performance supercomputers generating massive amounts of data. \n               A question of scale \n             No country can yet produce climate forecasts on the scales and with the accuracy needed for detailed planning, says Simon Mason, a climate scientist at Columbia University\u2019s International Research Institute for Climate and Society in Palisades, New York. Even the best forecasts are highly uncertain, which makes it difficult to use them for planning, he says. For instance, if a farmer\u2019s bank wants to know the probability that the farm might experience drought, a 10-year projection might suggest a 60% chance of more frequent droughts, says Mason. But that doesn\u2019t indicate how severe the droughts might be or whether they will lead to crop failures, he says. \u201cThese are exactly the types of questions that need a lot of research.\u201d But Jacqueline Peel, who specializes in climate-change law at the University of Melbourne, Australia, says that companies are likely to face more lawsuits like the Australian one, meaning that they won\u2019t have time to wait for fine-scale, tailored models. She says that there is already sufficient information on future warming scenarios for a business to disclose its vulnerabilities. In Australia, researchers say that budget cuts haven\u2019t helped. A report released earlier this month by the Australian Academy of Science identified major gaps in climate research and climate services. The report found that Australia needs an additional 77 climate scientists, including 33 in modelling and 12 in climate services. The academy commissioned the report after the Australian national science agency, the Commonwealth Scientific and Industrial Research Organisation (CSIRO), axed about 30 climate-science positions in 2016. CSIRO says it later added back 31 posts. \u201cThere is a pressing need to improve projections of extreme-weather events to meet the demand for adaptation planning and disaster risk management,\u201d the report said. The situation is better in Germany, the Netherlands and the United Kingdom, which have well-established, government-funded systems that provide climate information. But in the United States, researchers say that climate services are fragmented and struggle to meet the needs of governments or private-sector decision-makers. The Obama administration tried to launch a climate services division, but the US Congress blocked that effort. \u201cWe haven\u2019t invested as much in climate services in time scales from several weeks to decades in the US,\u201d says John Furlow, who works on climate change and development at Columbia. \n                 Tweet \n                 Follow @NatureNews \n               See Editorial  p.499 \n                     Extreme weather events are the new normal 2017-Aug-29 \n                   \n                     How machine learning could help to improve climate forecasts 2017-Aug-23 \n                   \n                     Global warming: Shareholders must vote for climate-change mitigation 2016-Feb-10 \n                   \n                     Climate change: Embed the social sciences in climate policy 2015-Apr-01 \n                   \n                     Climate change: The forecast for 2018 is cloudy with record heat 2013-Jul-10 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22540", "url": "https://www.nature.com/articles/nature.2017.22540", "year": 2017, "authors": [{"name": "Gabriel Popkin"}], "parsed_as_year": "2006_or_before", "body": "Controversial experiment ignites debate over whether scientific work could be used to justify harsh prison tactics. A little bit of nature can calm even the most stressed populations of people, according to a study conducted on prisoners in solitary confinement. In the experiment, researchers found that prisoners who watched videos with nature scenes felt less stressed and weren\u2019t as violent as those who didn\u2019t. The team, led by ecologist Nalini\u00a0Nadkarni at the University of Utah in Salt Lake City, published their findings on 1 September in  Frontiers in Ecology and the Environment 1 . Nadkarni first proposed the study in 2010 while visiting a prison that housed criminals who were considered to be the highest security risks. \u201cSix\u00a0guards in Kevlar vests and full riot gear had to go in and subdue an inmate in a restraining chair,\u201d she says. \u201cI thought, wow, if we could just calm them with nature rather than with Kevlar vests and riot gear, that would be really great.\u201d But it took Nadkarni years to find a prison that was willing to let her test her hypothesis. The experiment's results have now convinced some prison officials to offer inmates access to nature videos. However, critics of the study argue that it could be used to justify the continued use of solitary confinement \u2014 a practice that some consider too harsh. \n             Calming influence \n           Past research has shown that regularly seeing plants \u2014 even from a window \u2014 can improve hospital patients\u2019 and prison inmates\u2019 physical and mental health 2 . Nadkarni went further by studying people in solitary confinement, where inmates typically spend 23 hours a day alone in bare-walled cells. Her team divided inmates at the Snake River Correctional Institution in Ontario, Oregon, into 2 groups of 24. Those in one group could choose to exercise or, up to five times per week, go to a 'blue room' to watch 45-minute-long videos showing natural scenes such as mountains, forests and oceans. Those in the other group were offered exercise, but no videos. The researchers and prison staff measured inmates\u2019 moods and stress levels, and tracked violent incidents over a year. They found that inmates who had access to videos reported feeling calmer and were involved in 26% fewer violent incidents. The results suggest that nature imagery can help even society\u2019s most nature-deprived populations, which includes prison inmates, but also residents of nursing homes and inner city areas, says Nadkarni. The blue room has also helped Snake River to save thousands of dollars in medical costs resulting from altercations and self-harm, says Renee Smith, the institution\u2019s behavioral health systems manager. \u201cWe were pretty excited,\u201d she says. The programme is already being\u00a0replicated in three other states. \n             A controversial idea \n           \u201cIt\u2019s certainly a pretty creative naturalistic experiment,\u201d says Lisa Nisbet, a psychologist at Trent University in Peterborough, Canada. \u201cYou couldn\u2019t get a much more deprived group of people.\u201d But she and others caution that it is impossible to know whether exposure to nature had the beneficial effect because no group was shown videos with other content. Without this additional control group, \u201cyou can\u2019t really draw any definitive conclusions,\u201d says Marc Berman, a psychologist at the University of Chicago in Illinois. The study authors acknowledge this limitation, which they say is due to there being an insufficient number of prison staff to implement the additional control condition. But they say that inmates specifically mentioned the videos\u2019 nature content during interviews. One wrote: \u201cThe nature project help\u2019s [ sic ] me think clearer to know there is so much more beauty in this world then [ sic ] this prison\u201d. Not everyone is embracing the study.\u00a0Opponents of solitary confinement worry that the paper could provide cover for perpetuating a practice that many consider to be cruel and counterproductive. \u201cI would hate to think that this study will be used to justify keeping solitary confinement prisoners in conditions where they are deprived of opportunities to actually experience nature,\u201d says Craig Haney, a psychologist at the University of California, Santa Cruz. Nadkarni says her collaboration has helped inmates even if it hasn\u2019t dramatically reformed the prison system. \u201cAs an ecologist, it is not in my power to change the system of mass incarceration,\u201d she says. \u201cOne thing I can do is think about ways that bring the therapeutic value of nature to people who are incarcerated.\u201d \n                   Brain scans predict which criminals are more likely to reoffend 2013-Mar-25 \n                 \n                   Stress and the city: Urban decay 2012-Oct-10 \n                 \n                   City living marks the brain 2011-Jun-22 \n                 \n                   Lighter sentence for murderer with 'bad genes' 2009-Oct-30 \n                 \n                   Prisoners pitch in to save endangered butterfly \n                 Reprints and Permissions"},
{"file_id": "548507a", "url": "https://www.nature.com/articles/548507a", "year": 2017, "authors": [{"name": "Philip Ball"}], "parsed_as_year": "2006_or_before", "body": "High-speed shooter will help scientists to make molecular movies. Scientists who make movies of molecules in motion have a new high-speed camera to shoot with. The \u20ac1.2-billion (US$1.4-billion) European X-ray Free Electron Laser (XFEL) will start running its first experiments in September near Hamburg, Germany. The European XFEL fires powerful X-rays in bursts of a few hundred femtoseconds: so short that, like strobe lights, they can capture snapshots of jittery molecules frozen in time, and with a wavelength small enough to provide pictures at atomic resolution. The Hamburg machine is one of a few such X-ray lasers worldwide, but boasts a unique rapid-fire feature: it can rattle off 27,000 pulses every second, a firing rate more than 200 times greater than the next-fastest facility, the $420-million Linac Coherent Light Source (LCLS) at the SLAC National Accelerator Laboratory in Menlo Park, California. \u201cIt\u2019s such a different beast to anything else on the planet that it really feels like going into uncharted territory,\u201d says Arwen Pearson, a biochemist at the Centre for Free-Electron Laser Science in Hamburg. In a single second, scientists should be able to collect more than 3,000\u00a0good-quality X-ray pictures, compared with 100 or so at other facilities, says Adrian Mancuso, a project scientist at the European XFEL\u2019s experimental stations in Schenefeld, near Hamburg. \u201cHaving lots of data matters, and the European XFEL will deliver it in truckloads,\u201d says Abbas Ourmazd, a physicist at the University of Wisconsin\u2013Milwaukee. The European machine\u00a0\u2014\u00a0paid for by 12\u00a0countries\u00a0\u2014\u00a0should relieve some of the pressure on older XFELs in the United States and Japan (see \u2018X-ray laser guns\u2019), which are heavily oversubscribed by scientists keen to capture atomic-scale images of their samples. Another XFEL opened to users in Pohang, South Korea, in June, and a machine in Villigen, Switzerland, is due to start experiments in 2018.  At the Hamburg XFEL, bunches of electrons are first accelerated down a 1.7-kilometre-long tunnel. Magnets then bend the electrons\u2019 path into wiggling slalom tracks, causing them to emit bunches of high-energy X-rays as they curve. The bright X-ray pulses are so intense that they destroy the samples they hit \u2014\u00a0but not before enough photons have been scattered to reveal the sample\u2019s atomic structure. \n               X-ray movies \n             In structure-determination experiments using conventional X-ray sources, molecules must be packed into crystals to scatter enough photons to deduce their structure. But the X-rays from XFELs are so bright that researchers can gather diffraction patterns from crystals just a few nanometres in size, or even from non-crystalline clusters of molecules. This means that XFELs can study proteins that are hard to crystallize. And researchers can create movies of enzymes, viruses or catalysts in action by building up thousands of different snapshots of the same system taken at different timepoints\u00a0\u2014\u00a0often by passing a jet of molecules in solution past an X-ray beam. In 2015, for example, scientists using the LCLS reported eight snapshots of myoglobin, a muscle protein that binds oxygen, at a resolution of 0.18\u00a0nanometres. The images were taken a\u00a0few picoseconds after a flash of light dislodged a molecule of carbon monoxide from its binding position on the protein ( T.\u2009R.\u2009M. Barends  et\u00a0al. Science    350,  445\u2013450; 2015 ). On 14\u00a0August, Ourmazd and his colleagues reported using X-ray scattering from single viruses at the LCLS to create a 3D movie at 9-nm resolution. It shows the motions of a virus as it reorganizes its genome so that the genetic material can squeeze through a tubular molecular structure \u2014 a process that occurs when the virus infects a cell (A.\u00a0Hosseinizadeh  et al. Nature Methods  http://dx.doi.org/10.1038/nmeth.4395 ; 2017). Work such as this depends on gathering many snapshots of identical particles in different conformational states to build up a composite picture of a particle\u2019s range of motion, explains physicist John Spence at Arizona State University in Tempe. He says that the European XFEL\u2019s high pulse rate will make this process much quicker\u00a0\u2014\u00a0so structural data could be accumulated for much smaller individual particles. One of the European facility\u2019s most important milestones will be proving that diffraction patterns can indeed be collected from single particles at very high rates, says Mancuso. Because an intense X-ray burst obliterates each particle it hits in a passing spray or jet, it can be a challenge to ensure that the destroyed sample does not impede capture of the next shot. \u201cWe won\u2019t know that until we try,\u201d he says. Hamburg\u2019s facility also has a larger capacity than its competitors: unlike other XFELs, it has three separate undulators to create simultaneous X-ray beams, with the 27,000 pulses per second distributed among them. But the European XFEL will reign for only a limited time: SLAC this year began construction of a $1-billion project to create an even brighter laser beam that, by the early 2020s, will fire up to 1\u00a0million pulses each second. \n                 Tweet \n                 Follow @NatureNews \n               Additional reporting by Mark Zastrow. \n                     The next big hit in molecule Hollywood 2017-Apr-26 \n                   \n                     X-ray science: The big guns 2014-Jan-29 \n                   \n                     X-ray free-electron lasers fire up 2009-Oct-07 \n                   \n                     The European XFEL \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22550", "url": "https://www.nature.com/articles/nature.2017.22550", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "An open letter to the US National Institutes of Health says that classifying human-behaviour studies as clinical trials creates unnecessary red tape. Scientists studying human behaviour and cognitive brain function are up in arms over a plan by the US National Institutes of Health (NIH) to classify most studies involving human participants as clinical trials. An open letter posted to an online petition site on 31 August and addressed to NIH director Francis Collins on says that the policy could \u201cunnecessarily increase the administrative burden on investigators\u201d, slowing the pace of discovery in basic research. It asked the NIH to delay implementation of the policy until it has consulted with the behavioural-science and neuroscience communities. The letter has so far garnered more than 2,700 signatures. \u201cEvery scientist I have talked to who is doing basic research on the human mind and brain has been shocked by this policy, which makes no sense,\u201d says Nancy Kanwisher, a cognitive neuroscientist at the Massachusetts Institute of Technology in Cambridge, who co-wrote the letter with four other researchers. The policy is part of an NIH reform effort started in 2014, which aims to ensure that all clinical results are publicly reported. The policy is scheduled to go into effect in January 2018; it defines a clinical trial as anything involving behavioural \u2018interventions\u2019, such as asking participants to perform a memory task or monitor their food intake. Under the policy, such studies would need special evaluation by NIH committees and institutional ethics-review boards. The experiments would also need to be registered in the  ClinicalTrials.gov  database. \n             Waiting for clarification \n           But many researchers think that studies of normal human behaviour \u2014 intended to discover phenomena rather than alter them \u2014 should not be classified in this way. Among other concerns, small institutions that do not normally perform clinical trials may not have the resources or knowledge to comply fully with the policy. These concerns are overblown, said Michael Lauer, NIH deputy director for extramural research, at a meeting of the agency\u2019s advisory council on 1 September in Bethesda, Maryland. \u201cThe only regulation we\u2019re talking about is reporting that the trial exists and telling the world about the results. It is as simple as this and as profound as this.\u201d He said that his office would work with behavioural scientists to ensure that their studies were getting the proper review and that their research could be registered properly. But council member Terry Jernigan, a cognitive scientist at the University of California, San Diego, told Lauer that it was \u201cnot as simple as that\u201d. She said the policy has already caused problems for a study she is leading that tracks normal brain development in adolescents. When her group asked participants\u2019 parents to sign the required clinical-trial consent form, some expressed concerns that the form\u2019s language indicated that something was being done to their children, rather than that researchers were simply observing them. In response to some of those concerns, the NIH will update a list of examples of studies that qualify as clinical trials under the policy this week. \u201cThe NIH definition of a clinical trial may be broader than other clinical-trial definitions because it reflects NIH\u2019s mission, encompassing biomedical and behavioural outcomes as they pertain to human health,\u201d said the agency in a statement to  Nature \u2019s news team. \u201cThis definition does not encompass all psychological and cognitive research that is funded by NIH.\u201d Jeremy Wolfe, a vision researcher at Brigham and Women\u2019s Hospital in Boston, Massachusetts, says it is encouraging that the NIH plans to work with researchers in his field, but he adds that the details of the policy will be key. \u201cWe\u2019re worried about whether those details can be worked out by the January deadline,\u201d he says. \n                   NIH scraps plans for cap on research grants 2017-Jun-08 \n                 \n                   The best-kept secrets to winning grants 2017-May-24 \n                 \n                   The quiet rise of the NIH\u2019s hot new metric 2016-Nov-09 \n                 \n                   US toughens rules for clinical-trial transparency 2016-Sep-16 \n                 \n                   US government cracks down on clinical-trials reporting 2014-Nov-19 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22544", "url": "https://www.nature.com/articles/nature.2017.22544", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "August\u2019s sharpest science shots, selected by  Nature \u2019s photo team. \n             Souvenirs of travel \n           \n             Eclipse excitement \n           \n             Go northwest! \n           \n             Harvey's toll \n           \n             Stork, stalking \n           \n             Catching dinner \n           Do svidaniya ! \n             Cassini\u2019s legacy \n           \n                   An icy break up, Higgs history and a very messy eater 2017-Jul-31 \n                 \n                   Party slugs, pseudo-Saturn and a dancing Moon rover 2017-Jun-30 \n                 \n                   Horatio\u2019s head, arty ants and an ephemeral lake 2017-May-30 \n                 Reprints and Permissions"},
{"file_id": "548146a", "url": "https://www.nature.com/articles/548146a", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "From ground, sky and space, researchers are ready to test latest technologies on the Great American Eclipse. When the Moon\u2019s shadow races across the continental United States on 21\u00a0August, researchers will be waiting \u2014 in planes, on mountaintops and at other carefully chosen vantage points along the roughly 110-kilometre-wide path of totality. Thanks to  the sheer number of observers , solar physicists hope to learn more from this latest total solar eclipse than from  any previous such event , and to use that knowledge to develop tools for next time. \u201cThe beauty of eclipses is, each time you find something and then the next time you try to look for something else to enhance your science,\u201d says Shadia Habbal, a solar physicist and long-time eclipse chaser at the University of Hawaii at Manoa in Honolulu. Total solar eclipses, which occur about once every 18 months, provide the best chance to study the Sun\u2019s corona \u2014  the ethereal wisps of superheated plasma  that are usually obscured by glare from the solar surface (see \u2018Citizen science\u2019). Solar researchers typically use instruments called corona-graphs that physically block the Sun\u2019s disk and reveal the surrounding corona. But corona-graphs, which are installed on satellites and ground-based telescopes, are not ideal; to protect other instruments from potential damage caused by stray sunlight, they obscure an area slightly larger than the solar disk, blotting out a bit of the corona.\u00a0 The Moon blocks the Sun perfectly during a total solar eclipse, enabling better views of the corona than when using a coronagraph. Over the centuries,  astronomers have used eclipses to make fundamental advances , such as discovering helium and confirming Albert Einstein\u2019s general theory of relativity ( J. M.\u00a0Pasachoff  Nature Astron.   1,  0190; 2017 ).\u00a0 During the coming eclipse, one major effort will use a US National Science Foundation Gulfstream V plane to probe magnetic flows in the solar corona at infrared wavelengths, which can be difficult to measure from the ground (see \u2018Day of darkness\u2019). In the past, researchers have focused on studying the corona at ultraviolet wavelengths from space, and at visible wavelengths from the ground. But now, infrared detectors have become sensitive enough to begin opening a new window on the corona, says Jenna Samra, a graduate student at the Harvard-Smithsonian Center for Astrophysics (CfA) in Cambridge, Massachusetts, who helps to lead the project. Infrared studies reveal more about the corona\u2019s magnetic fields, where energy is unleashed in powerful currents from the Sun\u2019s surface up into the atmosphere. \u201cWe\u2019ve been missing this piece of the puzzle,\u201d says Chad Madsen, a postdoctoral fellow with the project at the CfA. The infrared instrument aboard the plane will gather detailed spectral information at several locations around the solar corona. The distance between certain lines in the spectrum reveals the strength of the magnetic field in that location \u2014 information that can\u2019t be measured directly otherwise. Pilots will fly the plane to a height of about 15\u00a0kilometres, to escape any clouds, and will catch about 4\u00a0minutes of totality on its path through Missouri, Kentucky and Tennessee. Testing equipment such as the infrared spectrometer on the plane will allow scientists to develop next-generation technologies that could be flown into space to gather data cheaply and quickly for a range of scientific applications, says Scott McIntosh, director of the National Center for Atmospheric Research\u2019s High Altitude Observatory in Boulder, Colorado. Similarly, NASA is sending two jets, once used to monitor space-shuttle launches, to chase totality. They will carry high-speed video cameras to capture the movement of the corona\u2019s wispy filaments. \u201cIdeally, we\u2019re going to discover some mechanism that carries enough energy into the corona to heat the corona,\u201d says Amir Caspi, an astronomer at the Southwest Research Institute in Boulder who is leading the effort. \u201cUntil now, that\u2019s been very elusive.\u201d The jets will fly one after the other, and together will collect data from more than seven minutes of totality. Along with taking infrared measurements, they will create the first-ever thermal map of the planet Mercury and hunt for vulcanoids \u2014 small asteroids that might lie between Mercury and the Sun. Meanwhile, researchers will fan out across the ground for additional studies \u2014 such as Habbal\u2019s long-running work to make temperature maps of the solar corona. This year, she will have 30\u00a0people at 5\u00a0sites across the western United States using enhanced detectors to look for spectral lines from superheated elements such as iron and argon. \u201cThis tells us about the chemistry of the corona,\u201d she says, data that are otherwise hard to gather. In a valley in Idaho, a French team will analyse spectral lines in the corona, in part to support the infrared work of the CfA team, says Serge Koutchmy, an astronomer at the Institute of Astrophysics in Paris. The group will also use new light-detecting instruments to continue a project to measure the Sun\u2019s radius \u2014 which is not known precisely \u2014 by studying how the star\u2019s light dips as the Moon slips on and off its face ( P.\u00a0Lamy  et al. Solar Phys.   290,  2617\u20132648; 2015 ). Depending on how things go, the 21\u00a0August eclipse may spawn a new generation of eclipse scientists. \u201cI have not been an eclipse chaser until now, but this is certainly sparking the bug,\u201d says Caspi. \u201cI\u2019m very much looking forward to trying to do this thing again.\u201d \n                     Citizen scientists chase total solar eclipse 2017-Aug-09 \n                   \n                     Hubble sees light bending around nearby star 2017-Jun-07 \n                   \n                     Eighty-eight days till the next total eclipse of the Sun 2017-May-24 \n                   \n                     Astronomy: An all-American eclipse 2017-May-24 \n                   \n                     American Astronomical Society eclipse site \n                   \n                     NASA eclipse site \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22441", "url": "https://www.nature.com/articles/nature.2017.22441", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Melanin pigment in darkened skin binds to pollutants and helps animals rid themselves of chemicals. Sea snakes that live in polluted waters have evolved to \u2018fill in\u2019 their light stripes, darkening their skins to cope with pollution. The finding 1  adds turtle-headed sea snakes ( Emydocephalus annulatus ) to the diverse list of creatures that exhibit \u2018industrial melanism\u2019, when darker animal varieties become dominant in polluted environments. The phenomenon is a classic example of natural selection, and one of the best-known cases \u2014 the  spread of the dark version of the peppered moth  in sooty nineteenth-century Britain \u2014 is often quoted in biology textbooks. For decades, evolutionary ecologist Rick Shine has snorkelled in the bays of Noum\u00e9a in the South Pacific island of New Caledonia to study the sea snake species and collect their shed skins. Over the years, while studying the snakes in the Indo\u2013Pacific, he noticed something curious: in some populations, most snakes were jet black, whereas in others, most sported pale banding or blotchy white markings. In 2014, Claire Goiran, a marine biologist at the University of New Caledonia in Noum\u00e9a who sometimes helped Shine to collect sea snakes, came across a study about Parisian pigeons 2 . The research had found that the birds' darker feathers store more zinc and other elements indicative of pollution than do lighter feathers, because the elements bind with the pigment melanin. It suggested that 'melanic', or dark-coloured, plumage or coats could be a selective advantage for animals living in polluted areas because the animals can rid themselves of harmful chemicals faster. So Goiran and Shine, who is based at the University of Sydney in Australia, collaborated to see whether the same went for sea snakes. Some parts of the Noum\u00e9a lagoon are polluted by run-off from nearby mining activities, they note. Their work is published on 10 August in  Current Biology 1 . \n             Black and white \n           The researchers compared the colours of 1,400 turtle-headed sea snake specimens that Shine had collected over 13 years from both industrial and non-industrial sites in New Caledonia and Australia. The black variety was most common in industrial populations, they found, whereas only a few lived in non-industrial areas. They then tested sloughed skins for concentrations of elements such as arsenic and zinc, and found that, as in the pigeons, black skins hosted higher concentrations of pollutants. What\u2019s more, in banded snakes, the black rings stored more pollutants than did white rings, showing that melanin is likely to be responsible for retaining the contaminants. The researchers found the same to be true for a similar banded sea snake species called sea kraits ( Laticauda saintgironsi  and  Laticauda aggregate ), which live in more pristine bays in Noum\u00e9a. The snakes might ingest pollutants in sediments when they feed on fish eggs on the sea floor, says Goiran. Black snakes also sloughed their skins more often, the researchers found. \u201cIf shedding is a mechanism for getting rid of pollutants then it may actually be an advantage,\u201d Shine says. \n             Unfortunate adaption \n           \u201cI have no problems in accepting that the dark areas in the skin have a higher concentration of pollution,\u201d says Arne Rasmussen, a herpetologist at the Schools of Architecture, Design and Conservation at the Royal Danish Academy of Fine Arts in Copenhagen. But the conclusion that more snakes with dark skin live in polluted areas because of the pollution might go too far, he says. Other factors, including temperature, could explain the distribution of black versus banded snakes, Rasmussen says. Previous research has found darker coloured snakes tend to live in cooler areas. Shine says he knows those studies and has conducted one himself. The connection makes sense for land snakes, he says, which would benefit from having a heat-absorbing dark skin \u2014 but the colour advantage doesn\u2019t apply to their aquatic cousins 3 . For them, water acts as an insulator to keep both banded and black snakes warm. Anecdotally, Rasmussen says he has seen both black and banded sea snakes living in areas that are more polluted than Noum\u00e9a. But \u201cif you could use a sea snake to indicate how much pollution there is in an area, that would be great\u201d. That doesn\u2019t address the fact that the snakes had to adapt to pollution in the first place, says Shine. Although shedding might be advantageous, there are limits to how much it can protect a population, he adds. Still, \u201cit\u2019s an encouraging story in terms of rapid evolution\u201d, he says. \u201cHere is yet another avenue in which organisms are able to deal with some of the problems that we\u2019ve raised.\u201d \n                   Dark satanic wings 2016-Jun-01 \n                 \n                   Evolution sparks silence of the crickets 2014-May-29 \n                 \n                   The peppered moth's dark genetic past revealed 2011-Apr-14 \n                 \n                   Darwin's finches tracked to reveal evolution in action 2009-Nov-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22419", "url": "https://www.nature.com/articles/nature.2017.22419", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Women with sleep disorders were about twice as likely to deliver babies more than six weeks early. Despite strides in maternal medicine,  premature birth remain s a vexing problem  for obstetricians worldwide. But an analysis of medical records from almost 3 million pregnant women in California 1  suggests that a surprisingly simple intervention \u2014 better sleep \u2014 might help to address the issue. Researchers found that women who had been diagnosed with  insomnia  or sleep apnoea were about twice as likely as women without sleep disorders to deliver their babies more than six weeks early. \u201cIt seems obvious, but strangely this study has not been done before,\u201d says Laura Jelliffe-Pawlowski, an epidemiologist at the University of California, San Francisco (UCSF), and an author of the research, which was published on 8 August in the journal  Obstetrics and Gynecology 1 . \u201cSeeing this relationship is important because we are just starved for interventions that can make a difference.\u201d Public-health experts say that better treatment for pregnant women with serious sleep disorders could save babies' lives, and do so with approaches that avoid the use of medication. Every year, 15 million babies worldwide are born prematurely \u2014 more than three weeks before the typical full-term pregnancy of 40 weeks. These children have less time to develop in the womb, and 1.1 million will die from birth-related complications. Many others are left with hearing impairment, learning disabilities, cerebral palsy and other health issues. The new study is part of the UCSF Preterm Birth Initiative, an ambitious US$100-million effort to study prematurity, focusing on California and East Africa. The researchers working on the effort plan to mine large quantities of historical data, ensuring that any findings are statistically significant. They hope to use these findings to identify medical and social interventions that could reduce preterm births, and test them in trials of pregnant women.The programme is funded by the Bill and Melinda Gates Foundation and philanthropists Lynne and Marc Benioff. \n               Forty winks for forty weeks \n             Jennifer Felder, a postdoctoral researcher in clinical psychology at UCSF who led the study, says that she had been troubled by the lack of research on sleep and pregnancy. Because pregnant women often have some difficulty sleeping, she suspects that doctors and researchers had not thought to examine the consequences of sleep disorders more closely. Felder and her colleagues acquired the records of almost three million births that took place in California between 2007 and 2012, which were scrubbed of identifying information but linked to hospital-discharge papers from the women who had given birth. Each record contained a medical history of the mother and notes taken throughout her pregnancy and baby's delivery. Doctors had diagnosed about 2,300 of the women with a sleep disorder during their pregnancy. Insomnia and sleep apnoea were the main problems, although narcolepsy, excessive sleepiness and restless leg syndrome were also seen. Insomnia, the researchers found, increased a woman's risk of preterm birth by 30%, while sleep apnoea increased the risk by 40%. Sleep disorders also increased the risk of very premature births: 5.3% of women with sleep issues delivered their babies at less than 34 weeks' pregnancy, compared to 2.9% for women without such a diagnosis. Felder says that a lack of sleep is unlikely to be a direct cause of early births. But it could trigger other processes, such as inflammation, that eventually result in prematurity. A 2010 review of studies linked premature birth to the presence of the inflammatory proteins C-reactive protein and interleukin-6, in amniotic fluid 2 . To explore the idea, the UCSF initiative will soon begin to examine immune-system proteins in pregnant women using blood stored in a repository associated with California\u2019s department of public health. The scientists will compare samples with an attention to premature birth and insomnia. And in the meantime, sleep troubles in expectant mothers can alert doctors to potential danger. \u201cI counsel women on how to have the best pregnancy outcome,\u201d says Louis Muglia, the director of the Center for Prevention of Preterm Birth at Cincinnati Children\u2019s Hospital Medical Center in Ohio. \u201cNow I might start asking, 'do you get a good night\u2019s sleep?'.\u201d \n                     Bacteria found in healthy placentas 2014-May-21 \n                   \n                     MicroRNAs mediate an early birth 2010-Nov-16 \n                   \n                     Neuroscience: The most vulnerable brains 2010-Jan-13 \n                   \n                     Preterm Birth Initiative at UCSF \n                   Reprints and Permissions"},
{"file_id": "548144a", "url": "https://www.nature.com/articles/548144a", "year": 2017, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Scientific network aims to train a generation of African leaders in primate research. Inza Kon\u00e9, a primate conservationist at the Swiss Centre for Scientific Research in Abidjan, C\u00f4te d\u2019Ivoire, is used to overcoming adversity. During the country\u2019s bloody civil war in the 2000s, he and his colleagues managed to keep research going in conflict zones, even after most international scientists had fled, because of long-standing ties with communities in these areas. In the country\u2019s Ta\u00ef National Park \u2014 one of the last vestiges of primary rainforest in West Africa \u2014 such relationships allowed long-running studies of chimpanzees and monkeys to continue safely, and largely spared the park from poaching. As the first president of the African Primatological Society (APS), launched at a congress near Abidjan on 24\u201326 July, Kon\u00e9 will lead another hard task: training a generation of home-grown primate researchers. The aim is for them to start and lead efforts such as the Ta\u00ef Chimpanzee Project \u2014 established in 1979 by researchers from Germany\u2019s Max Planck Institute for Evolutionary Anthropology in Leipzig \u2014 and to gain the institutional buy-in needed to protect Africa\u2019s 200 or so species of apes, monkeys and lemurs.\u00a0 Few primate-research and conservation efforts are currently led by Africans, and those run by scientists from elsewhere don\u2019t usually last long enough to make a difference, notes Inaoyom Imong, director of the Cross River Gorilla Landscape Project in Nigeria. \u201cGreater involvement in and leadership of primate-conservation projects by Africans has the potential to ensure the necessary long-term commitment to sites, stronger local ownership and sustainability of such projects.\u201d Continental Africa has an estimated 111\u00a0species of primate, with the greatest diversity in the Democratic Republic of the Congo, Tanzania, Cameroon, Nigeria and Equatorial Guinea. Another 103\u00a0species are found in Madagascar, an island nation and biodiversity hotspot. But many African primate species are at risk of extinction: 37% of species on the mainland and 87% of species in Madagascar are listed as threatened. This is largely a result of habitat loss caused by human activities, such as large-scale farming and logging, as well as overhunting of bushmeat. The APS\u2019s scientific congress will be an annual event. The first meeting brought together around 100\u00a0African primatologists and conservation biologists from across the continent, and some 30\u00a0non-Africans. \u201cFor African primatology to get its own society is tremendously important,\u201d says Roman Wittig, a primatologist at the Max Planck Institute for Evolutionary Anthropology. \u201cIt\u2019s a milestone.\u201d Most primate research and conservation in Africa over the past half-century has been done by overseas researchers, says Russell Mittermeier, vice-president of the non-profit environmental organization Conservation International in Arlington, Virginia, who attended the launch. \u201cBut the job is too big to continue in this way,\u201d he adds. \u201cWe need a large community of African primatologists working in their own countries and helping to train new generations of specialists.\u201d That\u2019s already starting to happen, says Wittig, who is co-director of the Ta\u00ef Chimpanzee Project. \u201cThere is now a crop of well-trained African researchers who are taking the lead,\u201d he says. Kon\u00e9, who is involved in the Ta\u00ef chimp study and a project with Western scientists focused on the national park\u2019s monkeys, says that having local researchers as partners benefits international conservation efforts. \u201cLocal communities and decision-makers will be more sensitive to messages from nationals working in synergy with expats.\u201d Although the prospects look bleak for primates in many parts of Africa, no species are yet believed to have gone extinct, says Wittig. But it will not be possible to rapidly solve major challenges such as habitat loss, so long-term planning is needed. Sustaining research and conservation in national parks is one of the best ways to protect vulnerable primate populations, he adds. The biggest challenges facing African primatology are the lack of training and expertise for the continent\u2019s researchers, says Rachel Ikemeh, principal investigator of the SW/Niger Delta Forest Project in Abuja, Nigeria, and a driving force behind the APS\u2019s establishment. The society will therefore focus on training African scientists to start conservation efforts and to lead research projects. \u201cIncreasing the roles and responsibilities of Africans is paramount, if we consider that Africans are essentially the main custodians of primates occurring within their natural habitat across the continent,\u201d says Ikemeh, who saw plenty of future leaders in primate conservation and research at the congress. For funding agencies, it can be more cost-effective to support nationals in countries with primate populations than to employ international researchers, says Mittermeier. \u201cWe can bring many more people to work on primate conservation in their own backyards.\u201d\u00a0 Mittermeier points to Brazil, a world leader in primatology, as an example of what can be achieved. Since its creation in 1979, the Brazilian Society of Primatology has spurred research and conservation efforts, supported hundreds of Brazilian primatology PhD students and helped to build extensive networks among non-governmental organizations, universities and government, he says. \u201cNow is the time for Africa.\u201d \n                     Ecology: Chimps at risk from anthrax 2017-Aug-02 \n                   \n                     In praise of parks 2016-Jan-26 \n                   \n                     Averting biodiversity collapse in tropical forest protected areas 2012-Jul-25 \n                   \n                     Apes in Africa: The cultured chimpanzees 2011-Aug-17 \n                   \n                     Research in a war zone 2011-Jun-29 \n                   \n                     Inaugural Congress of the African Primatological Society \n                   \n                     Impending extinction crisis of the world\u2019s primates: Why primates matter \n                   \n                     Primates Specialist Group of the International Union for Conservation of Nature (IUCN) \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22413", "url": "https://www.nature.com/articles/nature.2017.22413", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Odd results could still be consistent with the \u2018standard model\u2019 of cosmology. Cosmologists have produced the biggest map yet of the Universe\u2019s structure, and found that matter might be spread more evenly than previously thought. The results, part of the ongoing Dark Energy Survey (DES), chart the distribution of matter in part by measuring how mass bends light, an effect known as weak gravitational lensing. It was the first time the technique had been fed enough data to measure some of the crucial features of cosmic evolution with a precision approaching that for the maps generated from cosmic microwave background (CMB) data, which measure the afterglow of the Big Bang and are the gold standard of cosmology. \u201cWe believe that, with these results, we\u2019re no longer the poor cousin\u201d to other efforts, says DES leader Joshua Frieman, a cosmologist at the Fermi National Accelerator Laboratory (Fermilab) in Batavia, Illinois. \u201cWe now have results that have comparable power to constrain cosmology.\u201d There are still some discrepancies with earlier surveys on measurements such as the lumpiness of mass, but they are within the experiments\u2019 margins of error. As the DES maps larger volumes of space, it should become clear whether the disagreements are real, says cosmologist Anthony Tyson, a pioneer of weak gravitational lensing at the University of California, Davis. So far, he says, \u201cI believe they have been very careful and conservative in their interpretations\u201d.\u00a0 The DES, a collaboration of more than 400 researchers, gathers its data using the 4-metre Victor M. Blanco telescope, part of the Cerro Tololo Inter-American Observatory in Chile. Data collection began in 2013; the current map is based on the first year of measurements, which logged 26 million galaxies in the southern sky and their apparent shapes.\u00a0 According to Albert Einstein\u2019s general theory of relativity, mass warps space, so a large amount of matter in the foreground of a galaxy can bend its light in a way that makes the galaxy look slightly squashed. This is true whether the foreground mass is made of ordinary matter or of invisible dark matter. Galaxies can appear squashed for other reasons, including their actual shapes and orientations. But if many galaxies in a certain region of the sky seem on average to be skewed along the same direction, gravitational lensing is the probable culprit. The DES cosmologists were able to tease out the composition of the Universe in a similar way to how the CMB surveys have done in the past \u2014 most recently using the European Space Agency\u2019s Planck satellite. Their results confirm that ordinary matter constitutes only 4% the Universe\u2019s contents. But they show a slightly smaller amount of dark matter \u2014 about 26% \u2014 than the 29% estimated by Planck, with the rest being taken up by \u2018dark energy\u2019, the stuff thought to be pushing the cosmos apart at an accelerating speed. More intriguingly, the DES seems to have found a deviation from Planck\u2019s prediction of the current lumpiness of matter. Whereas ordinary and dark matter were evenly distributed in the Universe\u2019s infancy 14 billion years ago, that is not the case in present galaxies. Gravity has been pulling the matters together into a web-like structure of clusters and filaments, with enormous voids in-between. The concentration measured by the DES is 7% lower than that predicted by the standard model of cosmology. \n               Intriguing gap \n             The gap is not statistically large, at about one standard deviation. But another weak lensing project, the Kilo Degree Survey (KiDS), found the same kind of deviation last year 1 . If confirmed, the discrepancy could mean that, over cosmic history, mass has been clumping more slowly than expected. And that could potentially reveal new physics, such as unexpected interactions between dark matter and dark energy or new types of neutrino. The DES presented its results on 3 August at a meeting of the American Physical Society at Fermilab, and the authors posted a battery of ten papers online (see  go.nature.com/2ubhr8l ). Although cosmological observations have been converging towards a consistent, detailed picture in recent decades, the weak-lensing observations are not the only ones still troubling researchers. Astronomers have, for instance, found that the cosmos is expanding faster than predicted on the basis of Planck data. George Efstathiou, director of the Kavli Institute for Cosmology in Cambridge, UK, and a member of both the Planck and DES collaborations, says that the clumping discrepancy is potentially more worrisome than the one relating to cosmic expansion. Overall, researchers are excited to have another tool with which to probe the cosmos in ever-greater detail. \u201cMy own view of all of these measurements is that they are stunning tests of the cosmological model, and the precision and accuracy only keep getting better and better,\u201d says astronomer Wendy Freedman of the University of Chicago in Illinois. The final survey, due to conclude in 2018, will cover one-eighth of the sky; the results might be available some time in 2020, Frieman says. Ultimately, the DES aims to map a large-enough region to see how the influence of dark energy has evolved over the Universe\u2019s recent history. \u201cThis is exciting,\u201d Tyson says. \u201cThe future looks bright for weak gravitational lensing.\u201d \n                     Measurement of Universe's expansion rate creates cosmological puzzle 2016-Apr-11 \n                   \n                     Dark matter mapped at cosmic scale 2015-Apr-13 \n                   \n                     Cameras to focus on dark energy 2012-Sep-12 \n                   \n                     Survey tunes in to dark energy 2012-Jan-04 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22415", "url": "https://www.nature.com/articles/nature.2017.22415", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Non-scientists are being recruited to collect data on everything from the Sun\u2019s outer atmosphere to animal behaviour. Fred Isberner is a retired healthcare professor in Carbondale, Illinois. But on 21 August, the 69-year-old will be collecting data about the Sun\u2019s superheated outer atmosphere during a total solar eclipse. Isberner is one of thousands of people across the United States who plan to gather data during the event. Their combined efforts will be one of the largest, one-off citizen-science efforts yet. \u201cIt absolutely has the potential to be the biggest,\u201d says Scott McIntosh, director of the National Center for Atmospheric Research\u2019s High Altitude Observatory in Boulder, Colorado.  Total solar eclipses occur about once every 18 months, but they often pass over remote areas such as the ocean. The  21 August eclipse  is rare because it will be visible over a heavily populated landmass \u2014 the continental United States. About 12 million people live in the path of totality, which stretches from Oregon to South Carolina. Scientists and volunteers plan to take advantage of the situation  to gather data  and encourage the public to participate in research. \n               Star gazers \n             One of the larger efforts is the Eclipse Megamovie Project. The team behind it is inviting anyone with a camera, telescope or smartphone to submit images of the eclipse to an app. Data collected by the project, co-led by McIntosh, will allow researchers to study the \u2018diamond ring effect\u2019: a period when sunlight leaks through a valley on the Moon prior to and just after totality, resembling the diamond on a ring. Analysing how this effect changes during the eclipse could help scientists to measure the size of the Sun more precisely. The project that Isberner is part of \u2014 Citizen Continental-America Telescopic Eclipse (Citizen CATE) \u2014 involves 68 teams of volunteer stargazers along the path of totality. They will capture images of the eclipse using identical telescopes to get a close, continuous look at the corona, the Sun\u2019s outermost atmosphere. It is a region people normally do not see owing to the Sun's brightness. Researchers hope to spot features including plumes, streamers and loops. If they are successful, the data could provide insights about this poorly studied region of the Sun, says Matt Penn, a solar astronomer at the National Solar Observatory in Tucson, Arizona, and leader of the Citizen CATE project. Penn\u2019s team will analyse the information and compile the images into a 90-minute timelapse. \u201cNo one has taken a 90-minute sequence of this part of the solar atmosphere before\u201d, he says. \n               Coming home to roost \n             Not every citizen-science effort will focus on the heavens, however. A project called Life Responds will ask people to record what animals do during the eclipse. Volunteers can submit their observations on the iNaturalist app. Life Responds is the brainchild of Elise Ricard, a public programmes supervisor at the California Academy of Sciences in San Francisco, who noticed that birds stopped singing during a 2012 eclipse in Australia. \u201cIt wasn\u2019t just us on the beach enjoying the eclipse,\u201d Ricard says. \u201cAnimal life was responding.\u201d There is a lot of anecdotal evidence of odd animal behaviour during an eclipse, but research on it is sparse, says Andrew Fraknoi, a Life Responds adviser and retired astronomy professor at Foothill College in Los Altos Hills, California. Stories of unusual behaviour during a solar eclipse include chickens returning to their roosts, llamas surrounding a group of people during the event and whales and dolphins surfacing around a boat minutes before totality. The data collected by Life Responds is not currently destined for a scientific study. But Ricard hopes that the observations will inspire future research on animal behaviour during eclipses. \n               The sounds of an eclipse \n             Other projects will keep an ear out on 21 August. The Eclipse Soundscapes project wants people to collect audio of wildlife in urban and rural settings during the eclipse. The information could have potential applications for anthropological or biological studies, says project leader Henry Winter, an astrophysicist at the Harvard-Smithsonian Center for Astrophysics in Cambridge, Massachusetts. His primary goal, however, is to create an app that pairs sound and vibrations to deliver an eclipse experience to blind people. The idea came to Winter when he noticed that some solar eclipse museum displays only included one label written in braille for the visually impaired. Like Winter, the scientists leading these projects emphasize the importance of including non-researchers in scientific endeavours. \u201cIt gives people the sense that they can contribute to science,\u201d says Fraknoi, who is also helping with Citizen CATE. This is especially true for students. \u201cIt will get kids outside of the classroom and give them the hands-on ability to explore science instead of reading about it in a textbook,\u201d says Janet Jorgensen, a former prinicpal at Harlem Junior High School in Harlem, Montana. She will be in Jay Em, Wyoming, along with two teachers and a student from her former school collecting data for Citizen CATE. The excitement of doing science is a sentiment Isberner, the first Citizen CATE volunteer, can get behind. \u201cProves that an old guy like me can be trained without any experience in astroimaging and succeed,\u201d he says. \n                     Mysteries of Sun\u2019s corona on view during upcoming eclipse 2017-Aug-09 \n                   \n                     Hubble sees light bending around nearby star 2017-Jun-07 \n                   \n                     Eighty-eight days till the next total eclipse of the Sun 2017-May-24 \n                   \n                     Citizen scientists to rescue 150 years of cosmic images 2017-Mar-24 \n                   \n                     Citizen scientists aid Ecuador earthquake relief 2016-May-03 \n                   \n                     Citizen scientists take on latest gravitational-wave data 2016-Mar-09 \n                   \n                     Citizen Science projects \n                   \n                     Eclipse MegaMovie \n                   \n                     Life Responds \n                   \n                     Eclipse Soundscapes \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22445", "url": "https://www.nature.com/articles/nature.2017.22445", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Scientists call for wider access to rare samples rich in DNA. The quest to chronicle the past using DNA from ancient humans and animals has become a cut-throat \u2018game of bones\u2019, in which a handful of genetics laboratories are hoarding precious samples, three archaeologists charge in a 9 August  letter to  Nature . The scientists call for more careful stewardship of DNA-rich bone specimens to ensure that they remain available to multiple research teams to study. They point to the example of a newly established centre in Israel that will act as a national clearing house to curate animal bones from archaeological sites, so that many researchers can access samples for genetic analysis. \u201cThere\u2019s a lot of pressure on these resources right now, on this skeletal material,\u201d says Cheryl Makarewicz, an archaeologist at Christian-Albrechts University in Kiel, Germany, and a co-author of the letter. \u201cThe problem is there\u2019s not enough to go around.\u201d \n             Lending an ear \n           Makarewicz and her colleagues are particularly concerned about a portion of bone in the inner ear, the petrous,  that is especially rich in ancient DNA . \u201cCompetition for these rare specimens promotes hoarding, which, along with the destruction of samples for DNA analysis, makes it hard to replicate findings,\u201d she and her colleagues write in the letter. \u201cIt also hinders research by scientists who are not connected to the few groups who dominate access to such samples.\u201d It\u2019s important, too, to preserve samples for scientists in future generations, who may invent better methods to extract any DNA that remains in a sample after a first battery of tests, Makarewicz adds \u2014 as well as improvements in other techniques, such as isotope analysis. In the past few years, geneticists have accrued hundreds of archaeological samples \u2014 many of them petrous bones \u2014 from sites around the world and used them for blockbuster ancient-genomics papers that have charted the spread of  agriculture ,  languages  and  little-understood cultures . \u201cIt\u2019s been like the Wild West, with several ancient-DNA labs approaching museums across the world on a daily basis,\u201d says Eske Willerslev, an evolutionary geneticist at the Natural History Museum of Denmark in Copenhagen. In 2015, his team published  the first ancient-genome study to sequence the DNA of more than 100 individuals 1 ; it charted a massive Bronze Age migration originating in the steppes of Russia and Ukraine. David Reich, a population geneticist at Harvard Medical School in Boston, Massachusetts, and  another leading ancient-DNA researcher , says preserving archaeological samples is crucial. But Reich says that his lab samples bones to minimize their destruction and aims to return remains to archaeology collections within a year. He also notes that his lab is willing to share excess bone powder from petrous samples, and that the data they generate are freely available. \n             Centralized science \n           In Israel, a centre in Haifa that was opened in early 2017 will act as a clearing house for animal bones used in ancient-DNA studies, says Guy Bar-Oz, an archaeozoologist at the University of Haifa, Israel, and a co-author of the letter. Researchers excavating sites in Israel won\u2019t be required to deposit samples to the facility. But Bar-Oz says the fact that the centre is co-managed by the Israel Antiquities Authority means that most of the animal petrous bones recovered in Israel are already there. Scientists must apply for permission to sample material, and data sharing will be strictly enforced, Bar-Oz says. Not all archaeologists are on board with the idea. \u201cI do not support a central facility of some kind. I think that restricting the science at this point is not in the interest of anyone,\u201d says David Anthony, an archaeologist at Hartwick College in Oneonta, New York, who has provided Bronze Age samples to Reich\u2019s lab (and received them back after DNA extraction with no strings attached, he says). Marc Vander Linden, an archaeologist at University College London who collaborates with ancient-DNA researchers, likes the idea of ancient-DNA clearing houses. But he is not sure that centralized repositories will work in all countries; many of them, he points out, do not have central organizations with authority over archaeological digs akin to Israel\u2019s Antiquities Authority. Vander Linden says that the onus is on archaeologists who dig up and curate samples to come up with ideas to tackle the issue. \u201cSamples are a finite resource, and thus any way to improve their curation is more than needed,\u201d he says. \u201cAncient DNA is a fast-moving field, which is exciting \u2014 but more care and less politics would be great.\u201d \n                   Ancient-genome study finds Bronze Age \u2018Beaker culture\u2019 invaded Britain 2017-May-17 \n                 \n                   Farming invented twice in Middle East, genomes study reveals 2016-Jun-20 \n                 \n                   Bronze Age skeletons were earliest plague victims 2015-Oct-22 \n                 \n                   DNA data explosion lights up the Bronze Age 2015-Jun-10 \n                 \n                   Steppe migration rekindles debate on language origin 2015-Feb-18 \n                 \n                   Israel Facility for the Curation of Archaeological Animal DNA \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22116", "url": "https://www.nature.com/articles/nature.2017.22116", "year": 2017, "authors": [{"name": "Emily Waltz"}], "parsed_as_year": "2006_or_before", "body": "US firm AquaBounty Technologies says that its transgenic fish has hit the market after a 25-year wait. Genetically engineered salmon has reached the dinner table. AquaBounty Technologies, the company in Maynard, Massachusetts, that developed the fish, announced on 4 August that it has sold some 4.5 tonnes of its hotly debated product to customers in Canada. The sale marks the first time that a genetically engineered animal has been sold for food on the open market.  It took AquaBounty more than 25 years  to get to this point. The fish, a variety of Atlantic salmon ( Salmo salar ), is engineered to grow faster than its non-genetically modified counterpart, reaching market size in roughly half the time \u2014 about 18\u00a0months. AquaBounty sold its first commercial batch at market price: US$5.30\u00a0per pound ($11.70\u00a0per kilogram), says Ron Stotish, the company\u2019s chief executive. He would not disclose who bought it. AquaBounty raised the fish in tanks in a small facility in Panama. It plans to ramp up production by expanding a site on Canada\u2019s Prince Edward Island, where local authorities gave the green light for construction in June. In the same month, the company also acquired a fish farm in Albany, Indiana; it awaits the nod from US regulators to begin production there. The sale of the fish follows a long, hard-fought battle to navigate regulatory systems and win consumer acceptance. \u201cSomebody\u2019s got to be first and I\u2019m glad it was them and not me,\u201d says James West, a geneticist at Vanderbilt University in Nashville, Tennessee, who co-founded AgGenetics, a start-up company in Nashville that is engineering cattle for the dairy and beef industries. \u201cIf they had failed, it might have killed the engineered livestock industry for a generation,\u201d he says. \n               Swimming upstream \n             AquaBounty\u2019s gruelling path from scientific discovery to market terrified others working in animal biotechnology, and almost put the company out of business on several occasions. Scientists first demonstrated the fast-growing fish in 1989. They gave it a growth-hormone gene from Chinook salmon ( Oncorhynchus tshawytscha ), along with genetic regulatory elements from a third species, the ocean pout ( Zoarces americanus ). The genetic modifications enable the salmon to produce a continuous low level of growth hormone. AquaBounty formed around the technology in the early 1990s and approached regulators in the United States soon after. It then spent almost 25 years in regulatory limbo. The US Food and Drug Administration (FDA)  approved the salmon for consumption in November 2015 , and Canadian authorities came to the same decision six months later. Neither country requires the salmon to be labelled as genetically engineered. But unlike in Canada, political battles in the United States have stalled the salmon\u2019s entry into the marketplace. The law setting out the US government\u2019s budget for fiscal year 2017 includes a provision that instructs the FDA to forbid the sale of transgenic salmon until it has developed a programme to inform consumers that they are buying a genetically engineered product. Senator Lisa Murkowski (Republican, Alaska), who inserted the provision, has called AquaBounty\u2019s salmon \u201cfake fish\u201d. Activists in both the United States and Canada have demanded that regulators reconsider their decisions, and some have filed lawsuits. The Center for Food Safety, an environmental-advocacy group in Washington DC, sued the FDA last year in an attempt to overturn its salmon decision. The group says the agency lacks the legal authority to oversee genetically engineered animals, and that it made its decision without fully considering the environmental risks. The announcement that AquaBounty\u2019s fish are landing on Canadian tables is sure to dredge up opposition, says Stotish. He argues that the genetically engineered fish are good for the economy \u2014 attractive because they can be grown near metropolitan areas rather than being flown in from overseas, bringing salmon-farming jobs back to the United States and Canada. And because the AquaBounty salmon are grown in tanks, he adds, they don\u2019t encounter many of the pathogens and parasites that often afflict salmon raised in sea cages. \u201cI think the larger market is viewing it as a more predictable, sustainable source of salmon,\" Stotish says. \u201cAs a first sale this was very positive and encouraging for us.\u201d \n                     Gene-edited animals face US regulatory crackdown 2017-Jan-19 \n                   \n                     Salmon approval heralds rethink of transgenic animals 2015-Nov-23 \n                   \n                     Salmon is first transgenic animal to win US approval for food 2015-Nov-19 \n                   \n                     Fishy business 2014-Jul-30 \n                   \n                     Transgenic salmon nears approval 2013-May-01 \n                   \n                     Transgenic fish wins US regulatory backing 2012-Dec-22 \n                   \n                     Politics holds back animal engineers 2012-Oct-17 \n                   \n                     Transgenic fish go large 2010-Sep-14 \n                   \n                     AquaBounty Technologies \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22442", "url": "https://www.nature.com/articles/nature.2017.22442", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Deep-learning methods successfully classify thousands of herbarium samples. Computer algorithms trained on the images of thousands of preserved plants have learned to automatically identify species that have been pressed, dried and mounted on herbarium sheets, researchers report. The work, published in  BMC Evolutionary Biology  on 11 August 1 , is the first attempt to use  deep learning  \u2014 an artificial-intelligence technique that teaches neural networks using large, complex data sets \u2014 to tackle the difficult taxonomic task of identifying species in natural-history collections. It's unlikely to be the last attempt, says palaeobotanist Peter Wilf of Pennsylvania State University in University Park. \u201cThis kind of work is the future; this is where we\u2019re going in natural history.\u201d Natural-history museums around the world are racing to digitize their collections, depositing images of their specimens into open databases that researchers anywhere can rifle through. One data aggregator, the US National Science Foundation\u2019s iDigBio project, boasts more than 150 million images of plants and animals from collections around the country. \n             Complementary computing \n           There are roughly 3,000 herbaria in the world, hosting an estimated 350 million specimens \u2014 only a fraction of which has been digitized. But the swelling data sets, along with advances in computing techniques, enticed computer scientist Erick Mata-Montero of the Costa Rica Institute of Technology in Cartago and botanist Pierre Bonnet of the French Agricultural Research Centre for International Development in Montpellier, to see what they could make of the data. Bonnet's team had already made progress automating plant identification through the Pl@ntNet project. It has accumulated millions of images of fresh plants \u2014 typically taken in the field by people using its smartphone app to identify specimens. Researchers trained similar algorithms on more than 260,000 scans of herbarium sheets, encompassing more than 1,000 species. The computer program eventually identified species with nearly 80% accuracy: the correct answer was within the algorithms\u2019 top 5 picks 90% of the time. That, says Wilf, probably out-performs a human taxonomist by quite a bit. Such results often worry botanists, Bonnet says, many of whom already feel that  their field is undervalued.  \u201cPeople feel this kind of technology could be something that will decrease the value of botanical expertise,\u201d he says. \u201cBut this approach is only possible because it is based on the human expertise. It will never remove the human expertise.\u201d People would also still need to verify the results, he adds. \n             Helping hand \n           This approach can help herbaria process new samples, simplifying an arduous taks that sometimes requires hours of work. And similar efforts could help with other projects, such as a current crowdsourcing project that asks people to manually tick off which herbarium specimens feature a flower or a fruit. Researchers would certainly welcome an automated way of doing that, says botanist Gil Nelson of Florida State University in Tallahassee and a digitization specialist at iDigBio. The algorithm could also aid smaller herbaria with their species identifications, Bonnet says. His team found that algorithms trained on large data sets from big herbaria improved the identification of plants from relatively data-poor regions of the world \u2014 a finding that could be particularly useful for areas that are rich in biodiversity but have smaller plant collections. And this deep-learning approach will allow researchers to perform additional analyses. Herbaria samples contain a wealth of data: when and where the sample was collected, for example, and characteristics such as whether the plant was flowering or fruiting at collection time and how densely clustered the flowers were. Because some samples are centuries old, that data can paint a portrait of how plants have adapted to shifting climates \u2014 an area of growing interest in the face of concerns about climate change. \n             Moving ahead \n           Such efforts, including the identification study, are the next phase of digitization, Nelson says. \u201cWe\u2019ve been trying to transition to methods that we can use to mine those images and to pull out useful data,\u201d he says. \u201cThat\u2019s our focus right now.\u201d The projects aren't limited to herbaria. Nelson points to ongoing efforts to automate the identification of fly larvae, and Wilf is working with collaborators to carry out a similar analysis on plant fossils. Such fossils pose other problems, in part because they come in a variety of forms \u2014 fossilized fruits and flowers, petrified tree trunks or impressions of leaves in rock. Herbarium sheets, by contrast, are mercifully uniform: flat, dry and typically mounted on a standardized size of paper. Still, Wilf has no doubt that the field will eventually work out these details. \u201cIt\u2019s just going to get better,\u201d he says. \u201cSomeday we\u2019ll have students who won\u2019t be able to remember when we didn\u2019t have these sorts of tools.\u201d \n                   Natural-history collections face fight for survival 2017-Apr-07 \n                 \n                   Deep learning boosts Google Translate tool 2016-Sep-27 \n                 \n                   Plant collections left in the cold by cuts 2015-Jul-01 \n                 \n                   Computer science: The learning machines 2014-Jan-08 \n                 \n                   Superstars of botany: Rare specimens 2012-Apr-25 \n                 \n                   Integrated Digitized Biocollections (iDigBio) \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22440", "url": "https://www.nature.com/articles/nature.2017.22440", "year": 2017, "authors": [{"name": "Gabriel Popkin"}], "parsed_as_year": "2006_or_before", "body": "Disruptive weather pattern in 2014\u20132016 spurred tropical forests to pump out 3 billion tonnes of carbon. Portland, Oregon The  monster El Ni\u00f1o weather pattern of 2014\u201316  caused tropical forests to burp up 3 billion tonnes of carbon, according to a new analysis. That's equivalent to nearly 20% of the emissions produced during the same period by burning fossil fuels and making cement. Measurements taken by NASA\u2019s Orbiting Carbon Observatory-2 (OCO-2) satellite,  which measures the level of carbon dioxide in the atmosphere , suggest that El Ni\u00f1o boosted emissions in three ways. A combination of high temperatures and drought increased the number and severity of wildfires in southeast Asia, while drought stunted plant growth in the Amazon rainforest, reducing the amount of carbon it absorbed. And in Africa, a combination of warming temperatures and near-normal rainfall increased the rate at which forests exhaled CO 2 . The overall jump in emissions from tropical forests was roughly three times the annual average carbon output from deforestation and land-use change globally between 2006 and 2015 1 . The analysis, presented on 7 August at a meeting of the Ecological Society of America in Portland, Oregon, is a coup for OCO-2. Since 2014, the satellite has given scientists their best view yet of how human activities and natural systems affect the ebb and flow of CO 2  emissions. The El Ni\u00f1o work \u201cis a very profound discovery\u201d, says Berrien Moore, an atmospheric scientist at the University of Oklahoma in Norman and co-author of a forthcoming paper on the results. Scientists have used satellites to study living plants for decades. But until recently, these probes could provide only indirect measurements of how vegetation influences the level of carbon in the atmosphere, by monitoring factors such as plant biomass and greenness. OCO-2, one of a new class of satellites to track CO 2  from space, has changed this \u2014 and  the 2014\u201316 El Ni\u00f1o  was one of its first big tests. \u201cIn the past we had to model how those vegetation changes affected carbon dioxide,\u201d says David Schimel, an ecologist at NASA\u2019s Jet Propulsion Laboratory in Pasadena, California, who presented the results. \u201cNow we\u2019re getting a chance to see what we got right and what we got wrong.\u201d Combining data from OCO-2 and satellites that measure methane and carbon monoxide is giving Schimel and his colleagues a detailed view of how forests around the world respond to El\u00a0Ni\u00f1o\u2019s climate shocks. \n               Looking ahead \n             All three of the emissions-increasing mechanisms that the team points to had been previously identified as ways in which extreme weather events could affect plants, says Abigail Swann, an atmospheric scientist and biologist at the University of Washington in Seattle. \u201cWhat\u2019s interesting is that they all happened,\u201d she says. \u201cIt suggests that [El Ni\u00f1o response] is going to be a more complicated combination of factors in the future.\u201d The 2014\u201316 event is also  the first large El Ni\u00f1o  for which the effects are visible in annual maps of tree cover based on imagery from the US government\u2019s Landsat probes and the European Space Agency\u2019s Sentinel satellites. Preliminary calculations by the maps' maker, geographer Matthew Hansen of the University of Maryland in College Park, show that the number of trees lost worldwide increased by about 50% from 2015 to 2016. Tropical forests in South America, Asia and Africa were the hardest hit. But some uncertainties remain about the El Ni\u00f1o\u2019s effect on forests. Hansen sees evidence that the area of burned forest increased substantially in Central Africa and in Brazil, where annual tree loss roughly doubled, but OCO-2 does not. Hansen notes that the CO 2 -monitoring satellite\u2019s view is much less sharp than those of Landsat and Sentinel, which could cause it to miss some fires. OCO-2 leaders agree that the satellite does not provide the last word on emissions; it samples 10-kilometre-wide swathes of ground that add up to only around 6% of the planet\u2019s surface, from which researchers must extrapolate global numbers. But despite its limitations, OCO-2 provides today\u2019s best carbon measurements. Help may be on the way, however. A fleet of instruments that will be sent to the International Space Station in 2018 could give scientists sharper views of plants\u2019 responses to future extreme climate events. NASA\u2019s Global Ecosystem Dynamics Investigation (GEDI) will measure forest biomass, and the agency\u2019s Ecosystem Spaceborne Thermal Radiometer Experiment on Space Station (ECOSTRESS) will measure plants\u2019 water use. The Japanese Hyperspectral Imager Suite (HISUI)\u00a0will help to monitor plants' molecular composition and species diversity.\u00a0 These may be joined by a fourth instrument:  the Orbiting Carbon Observatory-3 (OCO-3) , built with spare parts from OCO-2. US President Donald Trump and his administration have proposed to cancel OCO-3, but it is not clear whether Congress will agree. If all these missions go forward, says Annmarie Eldering, deputy project scientist for OCO-2 and project scientist for OCO-3 at the Jet Propulsion Laboratory, \u201cyou\u2019ll really have a pretty complete picture of plant behaviour\u201d. \n                     Surprise El Ni\u00f1o causes devastation but offers lessons for ecologists 2017-Apr-25 \n                   \n                     Epic El Ni\u00f1o yields massive data trove 2016-Mar-02 \n                   \n                     Monster El Ni\u00f1o probed by meteorologists 2016-Jan-20 \n                   \n                     Hunting the Godzilla El Ni\u00f1o 2015-Oct-20 \n                   Reprints and Permissions"},
{"file_id": "548271a", "url": "https://www.nature.com/articles/548271a", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Multi-lab efforts point the way to shoring up the reliability of field studies. In an unusual reproducibility effort, 14\u00a0ecology labs across Europe have teamed up to watch grass grow, using identical soil and seeds shipped round the continent. Their study, posted on the bioRxiv preprint server on 8\u00a0August (A.\u00a0Milcu  et al.  Preprint at bioRxiv  http://dx.doi.org/10.1101/080119 ; 2017), is part of a budding movement to bolster trust in ecological research. Following the reproducibility crisis that has gripped psychology and biomedical science, ecologists are starting to recognize that their own field might not be immune to doubts over the reliability of its findings. But few replication studies have been done. Ecologists Clint Kelly at the University of Quebec in Montreal, Canada, and Rob Lanfear of the Australian National University in Canberra, found only a handful of replication efforts out of the thousands of studies they analysed, Kelly told the annual meeting of the Ecological Society of America last week in Portland, Oregon. Some ecologists have proposed replication efforts. In May, Emilio Bruna, a plant ecologist at the University of Florida in Gainesville, circulated a  proposal to replicate ten seminal experiments in tropical biology  that have never been repeated. They include, for instance, a 1967 study showing how ants and acacia trees benefit one another (D. H. Janzen  Univ. Kansas Sci. Bull.   47,  315\u2013558; 1967), which has influenced theories about other mutualistic relationships. But many ecologists are sceptical about repeating field experiments, Bruna says \u2014 arguing that the results of ecological field studies can never come out the same. A study conducted in a Panamanian forest, for example, may not translate to Costa Rica; even if the trees are the same species, herbivores may vary. \u201cThere are people who say, \u2018Every study is a snowflake. If you replicate my study and you don\u2019t find the same results, it\u2019s because conditions are changed and it\u2019s meaningless,\u2019\u201d says Tim Parker, an ecologist at Whitman College in Walla Walla, Washington, who is working on a teaching module that would enlist undergraduates to help with replication efforts. The objection holds even for replicating simplified model-ecosystem experiments conducted in the lab, says Alexandru Milcu, an ecologist who led the grass-growing study at the Ecotron in Montferrier-sur-Lez, France, run by the country\u2019s basic-research agency, the CNRS. \u201cWe can try to standardize everything but we will never take into account all the variables that affect an experiment\u00a0\u2014\u00a0some of which we don\u2019t even know,\u201d he says. So Milcu\u2019s suggestion, at least for lab work, is to make a virtue of including variation in experiments, which may make conclusions more robust. That idea is inspired by a 2010 mouse study, which found that behavioural tests yielded fewer spurious results when factors such as the age of the mice or the size of their cages were deliberately varied ( S.\u00a0H.\u00a0Richter  et\u00a0al. Nature Meth.    7,  167\u2013168; 2010 ). Milcu and his colleagues examined the tenet that grass grows better when it is paired with legumes (which snatch nitrogen from the atmosphere and enhance soils)\u00a0\u2014\u00a0a widely supported theory that is the basis for crop rotation using leguminous plants such as clover. In one set of experiments, the 14 labs controlled every variable as best they could; in the second set, they deliberately planted mixed strains of grass in varying soil conditions. The study, which has not yet been peer reviewed, finds that labs were more likely to come to similar conclusions about the benefits of growing grasses and legumes together in the less-controlled experiments. By making each lab\u2019s data noisier, a robust effect generalizable across many conditions is more likely to stand out, Milcu says. The strategy could lead to ecologists missing small but significant local effects in particular systems, he acknowledges\u00a0\u2014\u00a0but he says that this could be remedied by doing larger experiments. How the idea could be translated to field work isn\u2019t clear, although Milcu thinks it is worth exploring. Bruna\u2019s ecology replication initiative\u00a0\u2014\u00a0proposed in association with the Center for Open Science in Charlottesville, which has coordinated high-profile replication initiatives in psychology and cancer biology\u00a0\u2014\u00a0still lacks funding. He estimates that it could be pulled off for US$600,000. Such funding would be better spent rigorously testing fundamental theories using updated approaches, rather than repeating old studies, argues Stefan Schnitzer, an ecologist at Marquette University in Milwaukee, Wisconsin. \u201cI think we need to replicate ideas and fundamental theory rather than replicate a single study. I\u2019m not sure how that will advance the field,\" he says. But Bruna thinks that some ecologists' resistance to replication studies comes from a mis\u00adunderstanding over their goals, as well as their consequences for ecological theory. Replication studies needn\u2019t be perfect facsimiles to be useful, he says: just because an effect observed in one tropical ecosystem doesn\u2019t seem to hold true in another does not mean the original study was wrong. \u201cIn ecology we want to explore why there is so much variance,\u201d Bruna says. \u201cNo pun intended here, but people don\u2019t seem to be able to see the forest for the trees.\u201d \n                     Cancer reproducibility project releases first results 2017-Jan-18 \n                   \n                     1,500 scientists lift the lid on reproducibility 2016-May-25 \n                   \n                     Ecology\u2019s $434,000,000 test 2016-Jan-19 \n                   \n                     Over half of psychology studies fail reproducibility test 2015-Aug-27 \n                   \n                     Transparency in Ecology and Evolution \n                   Reprints and Permissions"},
{"file_id": "548268a", "url": "https://www.nature.com/articles/548268a", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Hub aims to make industrial-scale high-resolution brain mapping a standard tool for neuroscience Neuroscientists who painstakingly map the twists and turns of neural circuitry through the brain are about to see their field expand to an industrial scale. A huge facility set to open in Suzhou, China, next month should transform high-resolution brain mapping, its developers say. Where typical laboratories might use one or two brain-imaging systems, the new facility boasts 50 automated machines that can rapidly slice up a mouse brain, snap high-definition pictures of each slice and reconstruct those into a 3D picture. This factory-like scale will \u201cdramatically accelerate progress\u201d, says Hongkui Zeng, a molecular biologist at the Allen Institute for Brain Science in Seattle, Washington, which is partnering with the centre. \u201cLarge-scale, standardized data generation in an industrial manner will change the way neuroscience is done,\u201d she says. The institute, which will also image human brains, aims to be an international hub that will help researchers to map neural connectivity for everything from studies of Alzheimer\u2019s disease to brain-inspired artificial-intelligence projects, says Qingming Luo, a researcher in biomedical imaging at the Huazhong University of Science and Technology (HUST) in Wuhan, China. Luo leads the new facility, called the HUST-Suzhou Institute for Brainsmatics, which has a 5-year budget of 450 million yuan (US$67\u00a0million) and will employ some 120 scientists and technicians. Luo, who calls himself a \u201cbrainsmatician\u201d, also built the institute\u2019s high-speed brain-imaging systems. \n               Hot topic \n             \u201cThere will be large demand, for sure,\u201d says Josh Huang, a neuroscientist at Cold Spring Harbor Laboratory in New York, which is also partnering with the Chinese institute. Access to high-throughput, rapid brain mapping could transform neuro-scientists\u2019 understanding of how neurons are connected in the brain, he says\u00a0\u2014\u00a0just as high-throughput sequencing helped geneticists to untangle the human genome in the 2000s. \u201cThis will have a major impact on building cell-resolution brain atlases in multiple species,\u201d he says. Mammalian brains have millions of cells, and human brains even have billions. And the cells come in some 10,000 different types, marked by differences in shape, size and the genes they express. Neuroscientists hope that mapping out the structures and how they interact will help to reveal their functions (see  Nature 548, 150\u2013152; 2017 ). By comparing particular neuron types across multiple brains, scientists might be able to pick out the effects of a disease or a learned behaviour on cell structure, says J\u00fcrgen Goldschmidt, a brain-imaging researcher at the Leibniz Institute for Neuro-biology in Magdeburg, Germany. But such maps often require months\u00a0or years\u00a0of effort. The process involves shaving centimetre-long mouse brains into 15,000 ultrathin slices with a diamond blade, staining each layer with chemicals or fluorescent tags to pick out particular features, imaging each layer with a microscope and then reconstructing the images into a 3D map.\u00a0 \n               High-speed mapping \n             That\u2019s where Luo\u2019s institute can help. Its vast number of machines have impressive speed and resolution, collaborators say. According to Zeng, the devices can gather the same amount of detail on a mouse brain in two weeks as would require months using other technologies,\u00a0such as super-resolution confocal imaging.\u00a0 Participants at a February meeting of the US BRAIN initiative (Brain Research through Advancing Innovative Neurotechnologies) in Bethesda, Maryland, were treated to a display of the technology\u2019s capabilities when they were shown an image of a neuron that wrapped all of the way around a mouse brain (see  Nature 543, 14\u201315; 2017 ). Allen Institute neuroscientist Christof Koch, whose team did the work in collaboration with Luo\u2019s group, suggests the extensive reach of the neuron shows that the cell has a role in coordinating inputs and outputs across the brain to create consciousness. The Suzhou institute will generate a huge amount of data: each mouse brain map alone will be 8 terabytes, Luo says. But the volume of a human brain is nearly 1,500\u00a0times that of a mouse brain; it would take a single machine around 20 years to digitally reconstruct one at the institute\u2019s current rate. Luo aims to increase the speed of his machines and to use multiple devices in parallel.\u00a0 Luo is keen for worldwide collaboration; along with the Allen Institute and Cold Spring Harbor Laboratory, Stanford University in California is forming a partnership with the centre. But Luo says that interest is so high that he won\u2019t be able to accommodate everyone. \u201cWe are already turning people down.\u201d \n                     How to map the circuits that define us 2017-Aug-09 \n                   \n                     A giant neuron found wrapped around entire mouse brain 2017-Feb-24 \n                   \n                     Worldwide brain-mapping project sparks excitement \u2014 and concern 2016-Sep-21 \n                   \n                     Neuroscience: Idle minds 2012-Sep-19 \n                   \n                     Brain imaging: fMRI 2.0 2012-Apr-04 \n                   Reprints and Permissions"},
{"file_id": "548267a", "url": "https://www.nature.com/articles/548267a", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Effort backed by the state\u2019s flagship universities comes as US President Donald Trump shrugs off global warming. California has a history of going it alone to protect the environment. Now, as US President Donald Trump pulls back on climate science and policy, scientists in the Golden State are sketching plans for a home-grown climate-research institute \u2014 to the tune of hundreds of millions of dollars per year.\u00a0 The initiative, which is backed by California\u2019s flagship universities, is in the early stages of development. If it succeeds, it will represent one of the largest US investments in climate research in years. The nascent \u2018California Climate Science and Solutions Institute\u2019 would fund basic- and applied-research projects designed to help the state to grapple with the hard realities of global warming.\u00a0 The project could be funded by revenue from the state\u2019s cap-and-trade programme to reduce greenhouse-gas emissions, but its political prospects are unclear. Advocates say they have received a warm reception from California Governor Jerry Brown, but a spokesperson for Brown would say only that \u201cdiscussions are ongoing\u201d. The proposal must also clear the state legislature.\u00a0 \u201cThe goal is to develop the research we need, and then put climate solutions into practice,\u201d says Daniel Kammen, an energy researcher at the University of California, Berkeley. Although the institute would focus on science to serve California, Kammen says Brown and other state leaders recognize that their work will have global impact \u2014 particularly now that Trump has promised to  pull the United States out of the 2015 Paris climate accord . \u201cThe term we often use is \u2018rule from below,\u2019\u201d Kammen says. And California might ultimately have some company. At Columbia University in New York City, science dean Peter de Menocal \u2014 a palaeoclimatologist \u2014 hopes to build an alliance of major universities and philanthropists to support research into pressing questions about the impacts of climate change. Potential topics include local variations in sea-level rise and the changing availability of freshwater resources and food.\u00a0 De Menocal  has already tested the idea on a smaller scale . Last year, he launched the Center for Climate and Life at Columbia, enlisting corporate philanthropists to fund the university\u2019s Earth scientists. The project has raised about US$8 million. \u201cThis problem is bigger than any one institution,\u201d says de Menocal. \u201cWhat private philanthropy can do that the federal government doesn\u2019t do is target assets to solve specific problems.\u201d Writ large, that is what academics in California hope to do. The proposed climate institute there has drawn support from nearly all the state\u2019s major academic institutions, including all ten University of California campuses and private powerhouses such as Stanford University and the California Institute of Technology in Pasadena. Scientists from any institution would be eligible for grants to study topics ranging from ocean acidification to tax policy, Kammen says; priority would go to projects and experiments that engage communities, businesses and policymakers. It would not be the first time that California has stepped up to support an area of science that has fallen out of favour in Washington\u00a0DC. In 2004, the state\u2019s voters approved $3 billion to create the California Institute for Regenerative Medicine in Oakland, after then-President George W. Bush restricted federal support for research on human embryonic stem cells; that centre  has since funded more than 750 projects . The proposal for a new climate institute began similarly, as a reaction to White House policies, but its organizers say that the concept has evolved into a reflective exercise about academics\u2019 responsibility to help create a better future.\u00a0 \u201cIt almost became an inventory or indictment of ourselves,\u201d says Benjamin Houlton, director of the John Muir Institute of the Environment at the University of California, Davis, and chair of the committee that is developing the institute proposal. \u201cWe realized we weren\u2019t doing enough.\u201d Panel members aim to bring a complete plan to the California legislature this year, in the hope of persuading lawmakers to fund the effort. Kammen says that the institute\u2019s backers would like to have the institute up and running by September 2018, when Brown is set to host a global climate summit in San Francisco, California. But the California initiative still faces significant challenges. Severin Borenstein, an economist at the University of California, Berkeley, warns that academics will face plenty of competition for a limited pool of cap-and-trade revenue. He also notes that efforts to create such interdisciplinary climate institutes have struggled in the past, largely because it\u2019s hard to rally academics from disparate fields around a common goal. Nonetheless, Borenstein favours the climate initiative, because he sees global warming as an issue on which California can have a truly global impact.\u00a0 \u201cThe main way California can contribute to dealing with climate change is through innovation,\u201d he says. \u201cWe can invent and test the technologies and processes that will allow the rest of the world to reduce their greenhouse-gas emissions.\u201d \n                     Fears rise for US climate report as Trump officials take reins 2017-Aug-01 \n                   \n                     White House\u2019s dwindling science office leaves major research programmes in limbo 2017-Jul-11 \n                   \n                     Trump pulls United States out of Paris climate agreement 2017-Jun-01 \n                   \n                     US Earth scientists plan for uncertain future under Trump 2016-Dec-20 \n                   \n                     University seeks private donations to offset climate funding crunch 2016-Feb-01 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22439", "url": "https://www.nature.com/articles/nature.2017.22439", "year": 2017, "authors": [{"name": "T. V.  Padma"}], "parsed_as_year": "2006_or_before", "body": "Protesters demand respect for research \u2014 but some scientists were told to stay away. Delhi, India Thousands of scientists, university students and science enthusiasts gathered in dozens of Indian cities to march in support of science on 9 August \u2014 lamenting their country\u2019s low levels of funding for research, and complaining about government promotion of \u2018unscientific ideas\u2019. But several scientists  Nature  spoke to said they stayed away from the event, either because they had been directly asked not to attend, or because they feared repercussions from higher authorities if they did. They included some researchers at the Institute of Genomics and Integrative Biology (IGIB) in Delhi, who said they had been sent an email on 8 August directing them not to take part in the march, without specifying a reason. Other researchers, who did not want to be identified, said they had been asked not to engage in anti-government activity. The Indian demonstrations come 4 months after the  global March for Science on 22 April , which saw people gather in at least 600 cities around the world in support of scientific research and evidence-based policymaking. On that day, only two Indian cities, Hyderabad and Coimbatore, took part. \u201cWe felt that the global march was more to do with the [US President Donald] Trump administration\u2019s anti-science perspective, and not related to Indian science problems,\u201d says Satyajit Rath, an immunologist at the Agharkar Research Institute in Pune who attended a march in his city. \u201cIn retrospect, we should have participated more keenly in the global march,\u201d he says. At 11 a.m., protestors in Bangalore, a southern city that is one of India\u2019s key science hubs, were among the first to set off; more than 1,000 people were there, according to the Breakthrough Science Society, the advocacy group that coordinated Wednesday's events across India. The society, which is headquartered in Kolkata, says that in total, some 40 cities saw marches. In Delhi, India's capital, the march was a tamer affair. Some 200people took to the streets, carrying placards with messages such as \u201cDefend science, not defund science\u201d and \u201cStop killing science for your personal and political agenda\u201d. Asked why IGIB scientists had been told not to attend the Delhi event, the institute's director, Sanjay Kumar, said that it was a safety measure. \"Scientists' safety is our responsibility. How can one predict what can happen if the large gathering turns into a mob,\" he said. The March for Science events focused attention on India's  stagnant investment in research and development . Despite promises from successive governments to increase investment to 2% of gross domestic product (GDP), the proportion invested hasn\u2019t changed significantly from around  0.9% for the past decade . March organizers say the government should invest 3% of GDP in research. Scientists who did not march also share concerns over the allocation of resources to research. \u201cIt\u2019s a very difficult time for research in India,\u201d says Satyajit Mayor, director of the National Centre for Biological Sciences in Bangalore. \u201cThere is no real focus on expanding the research base in the country.\u201d But Ashutosh Sharma, secretary of India\u2019s Department of Science and Technology (DST), disagrees in part with the protesters\u2019 complaints. Funding for India's ministry of science and technology (which allocates cash to the DST among other science agencies) has  risen by double-digit percentages annually since 2014\u201315 , he points out \u2014 outstripping the country's economic growth \u2014 while the DST's funds for basic and applied science have almost doubled in the past five years. The marchers also protested against the government\u2019s support for what they call unscientific ideas. Rath cites a government push for research institutions to investigate the health benefits of cow products such as milk and urine, apparently motivated in part by religious groups' veneration of the cow as a sacred animal. \u201cIt is incumbent upon the representatives of the government to acknowledge that scientific knowledge is based on free and open enquiry,\u201d Rath says. \u201cResearch should not be used for validation of prejudices and ideology.\u201d \n                     What happened at March for Science events around the world 2017-Apr-21 \n                   \n                     India\u2019s budget keeps dream of genomics hub alive 2016-Feb-29 \n                   \n                     India: The fight to become a science superpower 2015-May-13 \n                   \n                     Research management: Priorities for science in India 2015-May-13 \n                   \n                     India's 'yoga ministry' stirs doubts among scientists 2014-Nov-19 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22475", "url": "https://www.nature.com/articles/nature.2017.22475", "year": 2017, "authors": [{"name": "Ben Upton"}], "parsed_as_year": "2006_or_before", "body": "Researchers fear sport fishing is a serious threat to endangered species \u2014 but study of Internet forum also finds awareness of environmental issues. Marine researchers have turned to an innovative data source to track the impact of \u2018game fishing\u2019 on endangered shark species: Internet message boards where anglers boast about their catches. An analysis of more than a thousand posts revealed both illegal behaviour \u2014 and surprisingly warm attitudes towards conservation 1 . Commercial overfishing  is responsible for population declines in many marine species. But researchers suspect that recreational, or sport, fishing \u2014\u00a0done for the thrill of catching big fish \u2014\u00a0could be a serious threat to some endangered species,\u00a0particularly sharks. One in four shark species worldwide  is threatened with extinction , according to the International Union for Conservation of Nature Red List. A 2004 study 2  found that although recreational anglers landed only 4% of all fish caught in US waters they landed 64% of endangered fish \u2014 including sharks \u2014 caught from the Gulf of Mexico. But precise data on the scale of activities \u2014 and how recreational anglers feel about conservation \u2014 are hard to come by. \u201cThere\u2019s a lack of data because it isn\u2019t considered a priority,\u201d says David Shiffman, a shark ecologist at Simon Fraser University in Vancouver who led the latest work. Information on fish-handling techniques, which can mean the difference between life and death for the animals, are particularly sparse. \u201cI think there is a need to better characterize the behaviour of anglers in the field,\u201d says Steven Cooke, a fish ecologist at Carleton University in Ottawa. \n             Illegal catches \n           Shiffman was based at the University of Miami in Florida at the time of the study. Florida is an angling hotspot and especially popular for shark fishing. So Shiffman's team sought to gather data on the practices of land-based anglers in the state \u2014 those who fish from beaches or piers rather than from boats. The team downloaded entries posted between 2009 and 2015 on the South Florida Shark Club, a large Internet discussion board where anglers share advice and photos of their catches. \u201cIt\u2019s a low-cost, logistically simple way to get observational data,\u201d says Shiffman. The study is published in  Fisheries Research 1 . The researchers counted posts that mentioned certain species, conservation issues, fishing techniques and opinions of other anglers. They also used messages with images featuring identifiable sharks to estimate the number of endangered species being caught. \u201cRecreational fishermen are, in general, infamous for exaggerating,\u201d says Shiffman. In all, the researchers found 1,527 reported shark catches. Of those, 620 were from protected species,\u00a0such as lemon sharks ( Negaprion brevirostris ).\u00a0 Florida state law says that accidentally caught endangered fish must be released immediately and not removed from the water. If sharks are pulled over beaches, for instance, it can kill them or damage their delicate eyes and gills.\u00a0 The researchers collected 389 images of anglers illegally bringing protected species ashore.\u00a0\u201cI was very surprised to see blatantly illegal behaviour out there publicly,\u201d says Shiffman. The team also noted that even after tiger sharks ( Galeocerdo cuvier ) and hammerhead sharks ( Sphyrna \u00a0sp.) were added to Florida\u2019s protected-species list in 2012, there was no significant drop in users admitting to catching them. \u201cFor a scientist it\u2019s easy for that to seem callous or bull-headed,\u201d says Catherine MacDonald a PhD student at the University of Miami and a co-author of the study. But some forum users expressed concern for shark populations and knowledge that certain handling techniques are safer than others. \u201cWe encourage everyone to safely release tiger sharks and hammerhead sharks back into the wild,\u201d wrote one poster. (Identities were anonymized as part of the data collection.) Many saw declines in local populations as the fault of commercial fisheries. \u201cUndoubtedly the root of shark declines is commercial fishing,\u201d says MacDonald. \u201cBut in the present moment that probably isn\u2019t the central challenge for sharks in Florida.\u201d \n             Fishing for answers  \n           The work is a good starting point, says Andy Danylchuk, who studies fish conservation at the University of Massachusetts Amherst. But he thinks the approach needs to be repeated with other forums before broad conclusions about attitudes and practices can be drawn. \u201cNot all recreational anglers are the same.\u201d \u201cThere\u2019s no way to extrapolate to the wider population of anglers because it\u2019s voluntary, self-reporting,\u201d agrees Shiffman. \u201cIt tells you, \u2018This is here, this is happening.\u2019\u201d Cooke says there is room for a variety of methods to track the activity. \u201cIt could be done with video cameras and binoculars, or looking at message boards or video-sharing sites.\u201d Ultimately, the study is \u201ctrying to shine a light on a large-scale, community-wide problem\u201d, says Shiffman. \u201cIf I were to monitor this population through more traditional methods,\u201d he adds, \u201cI would need to be doing it for years.\u201d \n                   Harvesting sharks could be key to saving them 2017-Feb-09 \n                 \n                   It\u2019s time to get real about conservation 2016-Oct-11 \n                 \n                   Biodiversity: The ravages of guns, nets and bulldozers 2016-Aug-10 \n                 \n                   Detective work uncovers under-reported overfishing 2013-Apr-02 \n                 \n                   Shark species more diverse than thought 2012-Jun-22 \n                 \n                   Conservation meets capitalism in Florida 2012-Feb-23 \n                 \n                   Overfishing hits all creatures great and small 2011-May-03 \n                 \n                   Overfishing hits all creatures great and small 2011-May-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22446", "url": "https://www.nature.com/articles/nature.2017.22446", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Science panel says institutions need to do more to prevent and mitigate damage to research equipment and animals. When Hurricane Sandy hit New York City in 2012, the storm  destroyed   scientific equipment worth  more than US$20 million  at the New York University (NYU) Langone Medical Center. Tropical Storm Allison hit the University of Texas Health Science Center (UT Health) in Houston in 2001, and caused so much damage that some researchers had to restart their careers elsewhere. Despite such catastrophes, a report published on 10 August finds that many research institutions in the United States are still unprepared for disasters. The report, released by the US National Academies of Sciences, Engineering, and Medicine, looked at what happened to research facilities during past disasters, interviewed people about how they had changed their current policies and procedures and consulted with experts on disaster and risk management. It recommends that universities and scientists take steps to protect biomedical research from emergencies on all scales, including natural disasters, fire, cyber-attacks and terrorism. Biomedical research is especially vulnerable to disasters, says the report\u2019s lead author Georges Benjamin, executive director of the American Public Health Association, a non-profit organization in Washington DC. Although insurance companies may cover expensive machinery, resources such as strains of genetically engineered mice and cells are irreplaceable, and it is difficult for insurance companies to quantify their value. Researchers at NYU lost 35,000 mice, including 751 different lines of genetically modified animals that existed nowhere else. The report suggests ten steps that researchers, institutions and funding organizations can take to  prepare for disasters and minimize the damage . It says that although every institution has different needs, all should appoint a \u201cchief resilience officer\u201d who can handle contingency plans for various scenarios. They should also institute mandatory training for staff to prepare them for emergencies. \n               Taking responsibility \n             One of the biggest problems is that many institutions house their animals in basements, often in an attempt to isolate the smell and to protect them from animal-rights activists, says report co-author Bradford Goodwin, former animal-facilities director at UT Health. But basements are susceptible to flooding, and can be difficult to evacuate in the event of an emergency. Individual researchers should also take responsibility for protecting their own work, the report says. \u201cYou go into the lab every day and you worry about your lab work, but you\u2019re making the assumption that everyone around you is protecting you,\u201d Benjamin says. Instead, scientists should make sure their data are backed up off-site, and work with their institutions to ensure that the most crucial samples and resources are duplicated, with the duplicates stored at other locations. It\u2019s also important that institutions assess their individual risks and prepare for all types of potential disaster, say the report\u2019s authors. For instance, California\u2019s building codes already require lab buildings to withstand earthquakes. But research facilities on the US East Coast, which was unexpectedly hit by an earthquake in 2011, may not be as resilient. And because climate change means that major storms and floods are becoming more common, Benjamin says, institutions should reassess whether their risk assessments are accurate. The report adds that funders such as the National Institutes of Health should do more to help pay for redesigns and preparedness efforts. Institutions are becoming better about disaster preparedness, Goodwin says. But most people still think it\u2019ll never happen to them, he adds. \u201cWe\u2019ve got to change that attitude.\u201d \n                     Emergency planning: Be prepared 2014-Oct-22 \n                   \n                     Hurricane Sandy: After the deluge 2013-Apr-24 \n                   \n                     Researchers battle storm\u2019s wrath 2012-Nov-06 \n                   \n                     Quake shakes Japan's science 2011-Mar-21 \n                   \n                     Texan labs batten hatches against Hurricane Rita 2005-Sep-23 \n                   \n                     Strengthening the disaster resilience of the academic biomedical research community \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22371", "url": "https://www.nature.com/articles/nature.2017.22371", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Rising rates of chronic disease can be curbed only if conflict is brought to an end, say researchers. Ramtha, Jordan Ibrahim Midyab is propped up on pillows on a cement floor when a physician comes to check on him. Midyab fled to Jordan from southern Syria after conflict erupted there in 2011. The 65-year-old can no longer walk as a result of multiple strokes, which his doctor blames on high blood pressure \u2014 but Midyab blames on fear. One stroke hit just as Midyab made it to Syria\u2019s border with Jordan, after 18 hours of dodging bullets, bombs and hostile soldiers. Midyab\u2019s encounter with tragedy is terrifyingly common here. Across the Middle East, death resulting from violence grew by 850% between 1990 and 2015, according to a series of reports published on 3 August in the  International Journal of Public Health 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 . This increase accelerated after 2010, corresponding with the beginning of the Arab Spring movement and wars in Syria and Iraq. At the same time, the authors found, the incidence of many chronic diseases has also increased dramatically; the death rate from diabetes, for instance, grew 216% over the study period. Taken together, the analyses describe a disturbing deterioration in health across a broadly defined Middle Eastern region, which includes 22 countries \u2014 including Afghanistan, Iraq, Syria, Somalia and the United Arab Emirates \u2014 that are home to more than 580 million people. \u201cGenerations of people are being exposed to a lot of shocks that will impact health throughout their lives,\u201d says Ali Mokdad, an epidemiologist at the University of Washington\u2019s Institute for Health Metrics and Evaluation (IHME) in Seattle, and a co-author of many of the new analyses 1 . \u201cThere is a strong link between mental health and diabetes and cardiovascular disease,\u201d he adds. \u201cIf someone faces a shock in their life, it puts pressure on their mental health, and they\u2019ll be less likely to stop smoking if they smoke. They\u2019ll be less likely to seek medical care if it\u2019s dangerous to do so. They\u2019ll be less likely to eat a balanced diet.\u201d \n             A fight for health \n           Sitting cross-legged across from her husband, Midyab\u2019s wife, Zahra, recalls how she watched the Syrian regime burn her son in front of her in 2012. The regime arrested another son, who returned home days later beaten nearly to death. That was when the family decided to flee to Jordan. After Ibrahim had his stroke at the Syria\u2013Jordan border, it took Zahra two weeks to find the Jordanian hospital where he was being treated. Since then, daily pills keep Ibrahim\u2019s blood pressure in check, but Zahra \u2014 who also has high blood pressure \u2014 says that their days remain dark. Both still struggle with physical and mental health problems. \u201cAfter they killed my son and took my child, I used to walk down the streets and say, I don\u2019t care anymore,\u201d Zahra says in tears. \u201cI\u2019m really sick now. My body is sick.\u201d The latest studies add country-specific details to  the Global Burden of Disease study  released by the IHME last year, which so far is the most comprehensive investigation worldwide of the causes of death and disease. To carry out analyses focused on the Middle East, the authors gathered information from the media, government officials and university researchers, among other sources. They used mathematical models to extrapolate in cases in which data were limited. For countries that do not track rates of smoking, for instance, the team estimated smoking prevalence using a model that included data on lung-cancer rates, income and education 3 . \n             Disease burden grows \n           Cardiovascular disease is the biggest killer in the region, just as it as worldwide, according to one of the papers 4 . In 2015, cardiovascular-related diseases, such as strokes, were responsible for the deaths of 34%  of men who died in the Middle East; that is roughly even with the 1990 figure of 30%. Among the starkest changes was a 1,027% increase in deaths from events such as war, terrorism and state-sanctioned punishment for crimes 5 . In 2015 alone, around 144,000 people in the Middle Eastern study region died from this collective violence. Yet during the same period in other parts of the world, deaths from the same cause decreased by 67%. Homicide and death from physical and sexual assault also increased in the Middle East between 1990 and 2015, but the current overall rate \u2014 5.7 people per 100,000 in 2015 \u2014 remains lower than in the Americas or Africa. Richard Garfield, an epidemiologist at Columbia University in New York City, says that the overall trends highlighted by the latest reports are probably true, but that figures related to the incidence of specific diseases or death rates in some areas might be off because of the paucity of public-health data in the Middle Eastern region studied. \n             Data dearth \n           Mokdad\u2019s team relied on modelling to compensate for a lack of hard numbers, and as a result, the margins of error for some estimates are wide. Although the team suggests that diabetes caused the loss of about 510 collective 'healthy years' for every 100,000 men in Syria 2 , that\u2019s the midpoint of a range that spans from 381 years to 672. In Somalia, the range is even wider: between 328 and 1,303 healthy years lost. The authors of the studies \u201chave done the most with the data they have, and nothing they\u2019ve done is wrong, but it\u2019s a bit opaque to give precise numbers at the country level\u201d, Garfield says. To address the rise in chronic disease, Mokdad and his colleagues say, people in the Middle East require healthier diets, more exercise and better access to health care. But Mokdad says that these improvements are unlikely in areas where conflict continues. \u201cPeople are resilient, and I am optimistic that the medical sectors can rebuild themselves, but I am pessimistic because there is no end in sight to the war,\u201d he says. \u201cThe best intervention is to stop the violence.\u201d Travel for this story was supported by the Pulitzer Center on Crisis Reporting. \n                   Global Burden of Disease Study 2015 \n                 \n                   Institute for Health Metrics and Evaluation \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22340", "url": "https://www.nature.com/articles/nature.2017.22340", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Scientists will look into the heart of Surtsey, an island created 50 years ago by a volcanic eruption. Geologists and biologists are about to pierce one of the world\u2019s youngest islands: tiny Surtsey, which was formed by a series of volcanic eruptions off Iceland's southwestern coast between 1963 and 1967. Next month, the team plans to drill two holes into Surtsey\u2019s heart, to explore how warm volcanic rock, cold seawater and subterranean microbes interact 1 . It will be the most detailed look ever at the guts of a newly born oceanic island. \u201cSurtsey is our best bet at getting a detailed picture of this type of volcanic activity \u2014 how ocean islands start to form,\u201d says Magn\u00fas Gu\u00f0mundsson, a volcanologist at the University of Iceland in Reykjavik. The results could help to explain how hydrothermal minerals strengthened the island\u2019s rock, enabling it to withstand the pounding of the North Atlantic Ocean. Engineers might be able  to use those secrets to produce stronger concrete . And deep within Surtsey, scientists plan to learn more about how buried microbes munch on rock, extracting energy from minerals and hot fluids. \u201cIf we can address this, we will get a lot closer to answering what role  the deep crustal biosphere  plays in maintaining and shaping our present-day environment,\u201d says Steffen J\u00f8rgensen, a geomicrobiologist at the University of Bergen in Norway. One of the two holes will parallel a 181-metre-deep hole drilled in 1979, allowing scientists to compare how microbial populations change over time. The second hole will go in at an angle, to explore the hot water percolating through a network of cracks within the volcanic craters that make up Surtsey. If all goes well, both holes will penetrate into the original sea floor, as it stood before the 1960s eruptions, about 190 metres down. \n               What lies beneath \n             At just 1.3 square kilometres, Surtsey is a natural laboratory for researchers to study  the biogeographic evolution of newborn islands  as they are seeded by plants and colonized by seabirds. It is a United Nations Educational, Scientific and Cultural Organization (UNESCO) World Heritage site, set aside strictly for science. \u201cThis is one of the most pristine environments on Earth,\u201d says Marie Jackson, a geologist at the University of Utah in Salt Lake City and principal investigator for the US$1.4-million project, which is supported in part by the International Continental Scientific Drilling Program. On 28 July, Iceland\u2019s coast guard plans to begin moving 60 tonnes of drilling equipment and other supplies to Surtsey, over the course of some 100 helicopter flights. \u201cThis is the most complicated logistics operation I\u2019ve taken part in,\u201d says Gu\u00f0mundsson. Strict environmental regulations require all waste to be removed from the island, including the sterilized seawater that functions as drilling fluid. Only 12 people will be allowed on Surtsey at any given time, even as drilling proceeds 24 hours a day. Others will stay on the neighbouring island of Heim\u00e6y, where a warehouse will temporarily be repurposed into a core-analysis lab. Microbiologists have continued to monitor the 1979 hole, where the maximum temperature has slowly cooled from 140 \u00b0C to about 130 \u00b0C (see \u2018Going deep\u2019). It is now rife with a host of microorganisms that are probably indigenous to Surtsey, says Vigg\u00f3 Marteinsson, a microbiologist at the Mat\u00eds food- and biotechnology-research institute in Reykjavik 2 . These organisms are thought to have colonized the rock from the seawater below, protected from contamination from above by scorching rock. Marteinsson expects to find similar types of microbe, including bacteria, archaea and viruses, in the new hole.\u00a0 After the new hole is drilled, engineers will lower five incubation chambers to different depths. These will remain in place for a year before they are retrieved so that researchers can determine what organisms colonize them. Monitoring what microbes move in, and how quickly, will offer scientists an unprecedented chance to study how the deep biosphere evolves in space and time, Marteinsson says. \n               Rock bottom \n             Meanwhile, geologists and volcanologists on the team will be investigating the second, angled hole. \u201cThat will allow us to reconstruct the way subsurface layers are connected \u2014 what we call the structure of the volcano,\u201d says Jocelyn McPhie, a geologist at the University of Tasmania in Hobart, Australia. The drilling should reveal the earliest stages of the Surtsey eruption \u2014 before it broke the surface of the ocean in November 1963, catching the attention of the cook aboard a passing fishing vessel. In the mix of seawater and heat, hydrothermal minerals formed within the volcanic rock. This made the rock less porous and helped to buttress it against erosion from waves. The drill core should reveal how these minerals were created over time, Jackson says, and modern scientists might be able to take hints from this process to build stronger concrete for structures such as nuclear-waste containers. Thus strengthened, Surtsey\u2019s core is likely to remain an island for thousands of years, says Gu\u00f0mundsson. That\u2019s in stark contrast to many volcanic islands, such as one that appeared near Tonga in 2014 but has already eroded by 40% 3 . \u201cBecause the vast majority of these islands disappear, we most likely substantially underestimate the number and volume of eruptions occurring at or just below sea level in the ocean, and hence the associated volcanic risk,\u201d says Nico Fournier, a volcanologist with the GNS Science research institute in Taupo, New Zealand. Whatever comes out of the Surtsey drilling, it should dramatically advance the snapshot gleaned from the 1979 project, says James Moore, an emeritus geologist with the US Geological Survey in Menlo Park, California, who was a leader of the earlier effort. \u201cWe made a lot of estimates that are going to be tested now,\u201d he says. \u201cIt feels wonderful.\u201d \n                     Seawater is the secret to long-lasting Roman concrete 2017-Jul-03 \n                   \n                     Earth science: Under the volcano 2013-Dec-09 \n                   \n                     Volcanology: Fire and life 2008-Aug-20 \n                   \n                     Submarine eruption bares volcanic island in Tonga 2006-Nov-22 \n                   \n                     Surtsey drilling project \n                   \n                     Surtsey Research Society \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22377", "url": "https://www.nature.com/articles/nature.2017.22377", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "After hints leaked out on Twitter, researchers made last-minute decision to reveal what might be the first discovery of a satellite outside our Solar System. The high-profile  quest to spot moons orbiting distant planets  has been a series of let-downs, with each hint of an \u2018exomoon\u2019 fading under closer inspection. So astronomer David Kipping, at Columbia University in New York City, didn't want to reveal his team\u2019s detection of another possible exomoon, until they could confirm it using the Hubble Space Telescope. That plan was abandoned a few days ago, after news of the team\u2019s request for Hubble time rocketed around social media. It culminated in the announcement that \u201cexomoon candidate Kepler-1625 b I\u201d had been observed orbiting a planet 4,000 light years (1,230 parsecs) from Earth, in an  arXiv preprint 1  posted on 27 July. That paper, reporting the results of a 5-year search for exomoons, was hastily amended to include the exomoon claim. Kepler-1625 b is a candidate planet that Kepler, NASA\u2019s flagship exoplanet mission, had previously observed. Periodic dips in the host star\u2019s brightness indicated that a massive object was crossing the line of sight from the star to Earth; but the dips were lopsided, suggesting that perhaps instead of one object there were two: a Jupiter-sized planet with a Neptune-sized moon in tow. If this were indeed an \u2018exomoon\u2019, it would have been a long-awaited discovery. But it was still a big if. \u201cIt wasn\u2019t something we were planning on announcing, because at this point it\u2019s only a candidate,\u201d says Kipping, who would have preferred to be more cautious with the news. \u201cIt really only takes the slightest misstep in our language to miscommunicate the reality of what we have.\u201d But his hand was forced this week, when another astronomer noticed that Kipping\u2019s team had requested time on the Hubble Space Telescope in October and shared the news on Twitter. Kipping is one of the most prominent astronomers in the hunt for exomoons. So if he wanted to use the Hubble, there was only one possible reason. Kipping says he does not blame the colleague for tweeting about something that was in the public record. But then, on 25 July, his phone started to ring: journalists were wondering whether Kipping had made the big discovery he had focused his whole career on. So, to pre-empt speculation, the team decided to be transparent about what it had found \u2014 and about what it hadn\u2019t. \u201cWe figured the only option we had was to get ahead of the story,\u201d says Kipping. As news reports appeared, one of the authors of the arXiv preprint, Alex Teachey, wrote  a guest-blog post for Scientific American  to explain his team\u2019s decision. \u201cLet\u2019s be clear: we\u2019re not just trying to save ourselves from embarrassment,\u201d Teachey wrote. \u201cThe announcement and subsequent retraction of potentially ground-breaking results has the effect of eroding public trust in science over time, and we are chiefly concerned with not contributing to that problem.\u201d Jean Schneider, an exomoon hunter at the Paris Observatory, says that the authors were right to make this candidate public. Now, he says, \u201cother people can re-analyse the Kepler data for Kepler-1625 b and make their own opinion\u201d. Astronomer David Bennett at the University of Notre Dame in Indiana agrees. \u201cI don\u2019t consider it to be terribly controversial to put a paper on the arXiv before it is peer reviewed,\u201d he says. \u201cIt is often the case that the journal doesn\u2019t really find the best person to review the paper,\u201d he adds. \u201cIf it is posted on arXiv.org, then you might get much more useful comments from a real expert who wasn\u2019t picked by the journal to review the paper.\u201d Astronomers  have spotted potential exomoons  before, only to find after gathering more data that the orbs weren't really there. \u201cI\u2019ve seen moons evaporate,\u201d Kipping says. In the past, confounding factors such as instrumental glitches have been found to mimic the signature of an exomoon. He considers the latest prospect exciting because, so far, it has survived all the tests that have shot down previous contenders. After they look at the star again in October with Hubble, Kipping says that he and his team will take around six months before they announce the result of their observation. Unless, perhaps, the news gets ahead of them again. \n                   The hunt for rogue planets just got tougher 2017-Feb-08 \n                 \n                   First possible exomoon spotted 2013-Dec-23 \n                 \n                   How to spot moons far, far away 2009-Jan-12 \n                 \n                   Are Astronomers on the Verge of Finding an Exomoon? \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22376", "url": "https://www.nature.com/articles/nature.2017.22376", "year": 2017, "authors": [{"name": "Shannon Hall"}], "parsed_as_year": "2006_or_before", "body": "Some of the Universe's most luminous objects have disappeared much faster than expected. Some of the brightest objects in the Universe \u2014 quasars \u2014 are vanishing rapidly. Astronomers now think that they understand this mysterious behaviour 1 , 2 , and the answer could help them to explain  how galaxies such as the Milky Way evolve . Quasars are supermassive black holes at the centres of galaxies fed by huge quantities of gas that shine across the visible Universe. Astronomers have long thought that quasars persist for millions of years before dimming slowly over tens of thousands of years. But in 2014, Stephanie LaMassa, an astronomer now at the Space Telescope Science Institute in Baltimore, Maryland, discovered a quasar that seemed to disappear in less than ten years 3 . That\u2019s a blink of an eye, astronomically speaking. Researchers struggled to explain the oddity. Perhaps a massive dust cloud passed in front of the quasar\u2019s bright beacon and momentarily blocked its light. Or maybe a star passed too close to the black hole and was rapidly torn apart, causing a bright flare that scientists mistook for a quasar. It seemed physically impossible that such a bright object could fade in such a short time. The discovery set in motion the hunt for more of these \u2018changing-look\u2019 quasars. The search has identified dozens of these mysterious beasts, some of which have dimmed more dramatically than the first. The two studies published this month on the preprint server arXiv suggest that these quasars blaze out of existence because the amount of gas and dust flowing through their accretion disks \u2014 the swirl of hot matter that encircles a black hole \u2014 drops dramatically. In effect, the black hole starves. \n             Flickering light \n           In one study, Zhenfeng Sheng, an astronomer at the University of Sciences and Technology of China in Hefei, and his colleagues peered closely at ten changing-look quasars that had been previously imaged by the Sloan Digital Sky Survey and NASA\u2019s Wide-Field Infrared Survey Explorer 1 . By looking at these quasars in both optical and infrared wavelengths, the team could probe both the quasar\u2019s accretion disk and its torus \u2014 the doughnut-shaped ring of dust clouds that wraps around it. This approach worked because the glowing accretion disk sends optical light towards the dark torus, where it is absorbed and re-emitted as infrared light. Any change to the torus\u2019s light mirrors a change to the accretion disk\u2019s light. So when Sheng and his colleagues found that the optical light emitted by each quasar dimmed before the infrared light did, they knew it was caused by a drop in the amount of material flowing through the accretion disk. The other study, led by astronomer Damien Hutsem\u00e9kers of the University of Li\u00e8ge in Belgium, reinforces this idea. Hutsem\u00e9kers\u2019 team examined the light emanating from a single changing-look quasar. Some of this light is polarized as it passes through regions around the quasar that are thought to be rich in electrons, just as molecules in Earth's atmosphere scatter and polarize light from the Sun. The researchers were trying to determine whether a dust cloud was blocking the quasar\u2019s accretion disk; if it was, more of the light from the quasar would appear to come from the polarizing regions. But the team did not detect an increase in polarized light from the quasar once it started dimming. This rules out the presence of a dust cloud, but not changes in the accretion disk. Nicholas Ross, an astronomer at the University of Edinburgh, UK, says that the two studies\u2019 results are intriguing, if preliminary. \n             A peek at primordial galaxies \n           If astronomers can pin down the mechanism behind changing-look quasars, and the timescales on which these objects wink out of existence, it could help them to better understand  how galaxies evolve . Every massive galaxy is thought to have hosted a quasar in its early years . The supermassive black holes in quasars can release winds strong enough to halt star formation in a young galaxy. Over time, a galaxy that hosted a stable quasar for long periods may look very different to one with a quasar that behaved unpredictably. One way to think about it is to picture two identical bathtubs full of water, says Meg Urry, an astronomer at Yale University in New Haven, Connecticut. Pouring a cup of boiling water into one and a couple of litres of lukewarm water into the other would give bathers very different experiences, she notes. Uncovering the inner workings of changing-look quasars could also help astronomers to trace how gas and dust flows into a black hole. Although the latest results suggest that changing-look quasars dim dramatically because they run out of fuel, researchers still can\u2019t explain how that would happen in such a short time. But LaMassa, who was one of the chairs of the first conference on changing-look quasars in July along with Ross, thinks that the field is on the right track. \u201cThere are a lot of questions still to be answered,\u201d she says. \u201cBut I think we\u2019re asking the right questions and going in the right direction.\u201d \n                   3D simulations of colliding black holes hailed as most realistic yet 2015-Apr-20 \n                 \n                   Young black hole had monstrous growth spurt 2015-Feb-25 \n                 \n                   European probe shoots down dark-matter claims 2014-Dec-02 \n                 \n                   Light from ancient quasar reveals intergalactic web 2014-Jan-19 \n                 \n                   Astrophysics: The heart of darkness 2014-Jan-15 \n                 \n                   Small galaxy harbours super-hefty black hole 2012-Nov-28 \n                 \n                   Galaxy formation: The new Milky Way 2012-Oct-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22394", "url": "https://www.nature.com/articles/nature.2017.22394", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "University of Tokyo investigated anonymous allegations of manipulated images in papers by Yoshinori Watanabe. An investigation at the University of Tokyo has found that one of its most prominent scientists, cell biologist Yoshinori Watanabe, committed scientific misconduct in five papers 1 , 2 , 3 , 4 , 5 . Another former member of the same laboratory was also found guilty in the same investigation. The university has yet to punish Watanabe, but the year-long investigation has already taken its toll. Colleagues report that his lab members have already cleared out and that he lost his\u00a0only major grant, leaving his career in tatters even before the university issued its judgment. The case has shaken the community of scientists who study how cells divide, in which Watanabe was a pillar. \u201cWatanabe is a giant of science with incredibly impressive discoveries,\u201d says Iain Cheeseman, a cell biologist at the Whitehead Institute for Biomedical Research in Cambridge, Massachusetts. \u201cThese are discoveries that have been validated, repeated, built on, and continue to be central to our understanding of cell division.\u201d The investigation into Watanabe started in 2016. In August that year, the University of Tokyo received anonymous allegations that 22 papers from 6 labs contained fabricated data. The university cleared the five other labs of misconduct, representatives of the University of Tokyo said at a 1 August press conference announcing the results of the investigation, according to Japanese news reports. In May, a university investigative committee, having completed an eight-month inquiry, concluded that five of Watanabe\u2019s papers, published between 2008 and 2015, contained manipulated images. Watanabe was given a chance to respond to the charges by the University of Tokyo committee. But after news of the report was leaked to the Japanese press, Watanabe also posted  his defence  online in June. In that post, Watanabe admitted that the five papers included problems. Most of his research details the interactions between proteins that guide the separation of chromosomes as cells divide. In the five papers, several illustrations intended to show which proteins were involved in a particular experiment \u201cwere captured under different imaging conditions\u201d or \u201cimproperly processed\u201d, Watanabe said. Different data sets were also \u201cimproperly combined into a single graph\u201d, he added. But Watanabe maintained that these manipulations were not intended to deceive and that none undermined the main conclusions of the papers. \n             Reaction from peers \n           Some of Watanabe\u2019s peers who were contacted by  Nature  accepted that explanation. \u201cI\u00a0find it impossible to think that these mistakes were dictated by the intention to deceive the scientific community or falsify the data,\u201d says Daniela Cimini, a cell biologist at Virginia Polytechnic Institute and State University in Blacksburg. Other experts were more dubious. \u201cIf the data were manipulated, what does it matter whether the conclusions\u00a0are right or wrong?\u201d says Angelika Amon, a cell biologist at the Massachusetts Institute of Technology in Cambridge. Amon thinks that action needs to be taken in such cases. \u201cThere is no grey area here. Data manipulation is scientific misconduct.\u201d The University of Tokyo investigation found that intentional enhancement of images was common in Watanabe\u2019s lab. According to the report, Watanabe even taught members how to perform these alterations to make them more convincing \u2014 a practice confirmed by a former lab member who asked not to be named. Yuji Tanno, a former assistant professor in Watanabe\u2019s lab, was also found guilty of misconduct in one of the papers. However, the report noted that Tanno was also the victim of poor mentoring on Watanabe\u2019s part. Another university committee will now recommend to Watanabe whether to retract or correct each of the five papers. Watanabe has already issued a correction for one of the papers, which was published in  EMBO Reports 1 . In his online defence, Watanabe said he was considering whether to retract a 2015  Science  paper 2  that contained 11 images and figures that he said need to be corrected. Watanabe did not immediately respond to an e-mail from  Nature 'snews team asking him for comment on the allegations in the University of Tokyo report. In a statement posted to his lab homepage on 1 August, he apologized for the errors and reiterated that he had never tried to change the fundamental results of experiments. \u201cHearing that these types of behaviors constitute fabrication and falsification fills me with regret,\u201d Watanabe wrote. Representatives for  Science  said that the journal is in contact with the authors and hopes to resolve the issue soon. Those at  Nature  have not yet responded to questions about the status of Watanabe\u2019s two  Nature  papers flagged in the report 4 , 5 . ( Nature \u2019s news team is editorially independent from the journal  Nature .) The University of Tokyo said that it would decide what penalties to apply only after looking into additional papers from Watanabe\u2019s lab. However, the investigation has already derailed Watanabe\u2019s career. As of March, all 15 membersof Watanabe\u2019s lab have left, according to a former member who asked not to be named because of the sensitivity of the situation. Watanabe\u2019s major grant \u2014 a 5-year, 416-million-yen (US$3.7-million) award from Japan\u2019s science ministry that was due to run until March 2018 \u2014 was suspended last March. \u201cHe is virtually and heavily punished already, even without any decision from the university,\u201d says the former lab member. \n                   Image doctoring must be halted 2017-Jun-28 \n                 \n                   Problematic images found in 4% of biomedical papers 2016-Apr-22 \n                 \n                   The image detective who roots out manuscript flaws 2015-Jun-12 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22385", "url": "https://www.nature.com/articles/nature.2017.22385", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "July\u2019s sharpest science shots, selected by  Nature \u2019s photo team. \n             Jupiter ascending \n           \n             An icy separation \n           \n             A crime in animal print \n           \n             Higgs-hunter history \n           \n             Flat out for lithium \n           \n             Messy eater \n           \n             Robot gold \n           \n             Mammal out-competes dinosaur \u2014 again \n           \n                   Horatio\u2019s head, arty ants and an ephemeral lake 2017-May-30 \n                 \n                   Jupiter\u2019s secrets revealed by NASA probe 2017-May-25 \n                 \n                   Golden neurons, river piracy and bright nights 2017-Apr-28 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22370", "url": "https://www.nature.com/articles/nature.2017.22370", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Analysis of chimp brains reveals protein plaques and tangles that signal brain disease in humans, but whether the animals can develop dementia is unclear. Aged chimpanzees develop brain characteristics that are similar \u2014 but not identical \u2014 to those seen in early Alzheimer's disease in humans, researchers report on 1 August in  Neurobiology of Aging 1 . The findings from humanity's closest relatives could help researchers to understand why people develop dementia, as well as suggest that caretakers of aging, captive chimpanzees watch them closely for behavioural changes. Although most animals\u2019 cognitive abilities decline late in life, only people seem to develop Alzheimer\u2019s disease, which can result in severe dementia symptoms. The brains of people with Alzheimer\u2019s  show several signs of the disease : plaques made of a protein called amyloid-\u03b2, tangles of a protein called tau and the loss of neurons. Humans were thought to be the only primates with brains that can contain plaques and tangles simultaneously \u2014 although one study did find both markers in a single chimp brain 2 . Using  a collection of chimpanzee brains that has been compiled over several decades , a team led by Mary Ann Raghanti, a biological anthropologist at Kent State University in Ohio, analysed the brains of 20 aged chimps that had died between 37 and 62 years of age. The team examined the brain regions that are damaged in people with Alzheimer's \u2014 such as the memory-forming hippocampus \u2014 and found that four of the preserved chimp brains contained both plaques and tangles. All 20 of the specimens contained \u2018pre-tangles\u2019, and blood vessels in several of the chimp brains contained amyloid-\u03b2. Because the protein is normally found outside of blood vessels in the human brain, this suggests that plaques may form in a different way in chimps. \u201cThis is a really cool paper\u201d, says Elizabeth Head, a neuroscientist at the University of Kentucky in Lexington. Even if chimps never develop the symptoms of Alzheimer's, knowing that they spontaneously develop biological signs of the disease could yield useful information about its early stages and potentially how to prevent it, she says. Lary Walker, an experimental neuropathologist at Emory University in Atlanta, Georgia, is also impressed with the study. The strength of the paper, he says, is that the large number of animals involved provide a good sample of the different ways in which chimp brains age. The researchers were not able to link the biological changes in the chimps\u2019 brains to shifts in their behaviour later in life. The animals had lived in zoos, research labs and sanctuaries, and had, therefore, been exposed to different stimuli and undergone different cognitive tests. Although severe dementia has never been observed in chimps, the presence of both plaques and tangles suggests that it could, says study co-author William Hopkins, a psychologist at Georgia State University in Atlanta. Given these findings, he says, those who look after chimps should actively monitor the cognitive health of ageing animals. In 2015, the United States  effectively ended   biomedical research on chimps , including magnetic resonance imaging scans, but Hopkins says that such scans could be useful for the aging population of animals retired from research facilities. The sequences of amyloid-\u03b2 and tau proteins are identical in humans and chimps. But it is possible that there is a factor protecting chimp brains from severe dementia. \u201cThey're missing something,\u201d Walker says of the chimps. One possibility, he adds, is that the amyloid-\u03b2 and tau proteins may fold differently in chimps than in people. Another difference could be the behaviour of a protein called APOE, which controls how amyloid-\u03b2 aggregates into plaques. Humans have evolved several versions of the  APOE  gene, one of which \u2014  APOE4  \u2014 makes a person more likely to develop Alzheimer\u2019s. It is possible that evolution selected for the \u2018bad\u2019 version of APOE in people because it protects them from something else, such as a parasite 3 , says Caleb Finch, who studies ageing at the University of Southern California in Los Angeles. Raghanti says that the researchers are now counting the neurons in the chimp brains they studied to determine whether the cells are lost with age, and studying inflammation in the brains. Both neuron loss and inflammation seem to contribute to Alzheimer\u2019s in humans. \u201cIf we could identify the things that are similar and different in chimpanzees and humans, we can start to unlock why humans are so uniquely susceptible to this pathology,\u201d she says. \n                   'Digital chimp' trove preserves brains of retired apes 2015-Nov-25 \n                 \n                   NIH to retire all research chimpanzees 2015-Nov-18 \n                 \n                   Chimpanzee IQ starts in the genes 2014-Jul-10 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22395", "url": "https://www.nature.com/articles/nature.2017.22395", "year": 2017, "authors": [{"name": "Jason Bittel"}], "parsed_as_year": "2006_or_before", "body": "Plants illuminated by artificial lights see a drop in the number of insects that move pollen at night. When the sun goes down, moths, beetles and other nocturnal insects that spread pollen between plants go to work. But the latest research reveals that these creatures might be at risk from artificial lighting. S cientists working in Switzerland report large drop-offs in pollinator visits as well as reduced fruit production in patches of cabbage thistle ( Cirsium oleraceum ) under artificial lighting at night, in a study published on 2 August in  Nature 1 . Researchers were largely in the dark about how problems such as light pollution affected pollinators. But the study authors say their work highlights how the  human footprint can reverberate throughout an ecosystem  \u2014 even after people have gone to bed. The researchers placed mobile street lamps over plots of cabbage thistle that had never before been exposed to artificial light at night. Using night-vision goggles to observe and capture pollinators, the team found that those plots had 62% fewer visitations from insects than plots situated in darkness. The artificially lit plants also saw 29% fewer pollinator species. Illuminated thistles produced significantly fewer developed fruits than those in darkness. Plants covered in pollinator-proof bags, meanwhile, yielded the same relative number of fruits under artificial light and in the dark. Even though daytime pollinators are usually more numerous than night-time pollinators, they were unable to make up the difference in lost pollination of plants kept under artificial lighting. This could be because some studies have shown that night-time pollinators seem to be more effective at transferring pollen between plants than their diurnal counterparts, says Eva Knop, an ecologist at the University of Bern in Switzerland and first author of the study. \u201cThus, it is not just the quantity but also the quality that counts.\u201d \n             Ripple effect \n           The study by Knop and her team only looked at 14 plots, but their work hints at the interconnectedness of both daytime and night-time pollinators such as moths, flies and even earwigs, as well as the plants they frequent. For instance, if lights drive away night-time pollinators, that could lead to less fruit and fewer plants. It\u2019s a change that could ripple through  daytime pollinator populations , which rely on plants such as cabbage thistles for food, according to the study authors. This study is \u201cthe first to show that light pollution not only affects moth communities, but the ecological process of pollination\u201d, says Darren Evans, an ecologist at Newcastle University, UK, who has studied how artificial light affects moths. This doesn\u2019t bode well for moths in particular, says Evans, because they\u2019re undergoing significant long-term declines across Europe. Light pollution is also on the rise globally. \u201cStudies such as this demonstrate that moths are part of an intricate web of interactions and, in this case, perform important roles as pollinators,\u201d says Evans. \n             A mixed bag \n           It\u2019s not all bad news, however. Jon Sadler, an ecologist and biogeographer at the University of Birmingham, UK, has found that although city lighting can negatively affect the movement of bats 2 , those same lights can also attract pollinators such as moths, which bats love to devour. Sadler also points out that not all artificial light is the same. It varies in direction, intensity and duration \u2014 each of which could affect the overall impact lights have on surrounding plants and animals. He adds that it\u2019s entirely possible that light pushes night-time pollinators into darker areas, and that this might actually enhance pollination in those places. It\u2019s not clear why artificial light has a negative impact on the pollinators, says Knop. It could mess with the plants\u2019 circadian rhythms and alter scent emissions or nectar production, she says. What\u2019s interesting, however, is that the fate of night pollinators seems to be intertwined with that of the day pollinators, Knop adds. And in some instances, artificial light may be unravelling that tapestry. \n                   The insect crisis we can\u2019t ignore 2016-Nov-08 \n                 \n                   Global biodiversity report warns pollinators are under threat 2016-Feb-26 \n                 \n                   Bee studies stir up pesticide debate 2015-Apr-22 \n                 \n                   Losing a single pollinator species harms plants 2013-Jul-22 \n                 \n                   The pollinator crisis: What's best for bees 2011-Nov-09 \n                 \n                   The pollinator crisis: What's best for bees 2011-Nov-09 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22397", "url": "https://www.nature.com/articles/nature.2017.22397", "year": 2017, "authors": [{"name": "Nicky Phillips"}], "parsed_as_year": "2006_or_before", "body": "One in five say they have been harassed in university settings. Students at Australian universities are experiencing \u201cunacceptable rates\u201d of sexual harassment and assaults, according to the Australian Human Rights Commission, which on 1 August released the  first national report  charting the extent of the problem. Of more than 30,000 undergraduate and postgraduate students who answered an online survey, 21% said that they had experienced sexual harassment, such as unwelcome touching or offensive comments, on a campus or a location related to a university. The survey also revealed that 7% of students were sexually assaulted in 2015 or 2016; about one-quarter of them said it happened on campus, at a university-organized event or while travelling to or from a university. But the vast majority of those harassed or assaulted did not report the incidents to their university. \u201cThe impact of these events can be devastating, affecting [people\u2019s] health, studies and future careers,\u201d said Kate Jenkins, sex-discrimination commissioner with the Australian Human Rights Commission, at a press briefing. \u201cUniversities owe [students] swift action to address these issues. It cannot wait.\u201d The results of the Australian study echo  data on sexual assault  collected at universities in the United States. A country-wide survey of sexual misconduct by university staff towards students at UK universities will be released next year by the National Union of Students. The Australian report follows years of pressure from student representatives and those who have experienced sexual assault calling on universities to acknowledge and address the issue on campuses. Universities Australia, which oversees universities in the country, asked the commission in 2016 to conduct a national survey. Results from the survey show that women were almost twice as likely to be sexually harassed, and three times more likely to be sexually assaulted, as men. Students who identified as gay, lesbian or homosexual, as well as trans or gender-diverse students, were the most likely to be harassed. Perpetrators of sexual harassment or violence against undergraduates were most commonly men who were students at the same university; postgraduate students were twice as likely as undergraduates to be harassed by a lecturer or tutor. \n             Individual reports \n           Each of the country\u2019s 39 universities also released figures on 1 August of sexual assault and harassment at their institution, the first time that such information has been made public. Sophie Johnston, president of the National Union of Students in Melbourne, urged universities with lower rates not to use the results as a way to promote themselves. \u201cThere is nothing to revel in having a few less sexual assaults or rapes than the university next door,\u201d she said at the press conference. Michael Flood, a researcher on gender, sexuality and violence at the Queensland University of Technology in Brisbane, says that the findings reflect research on some of the risk factors of sexual violence in the broader population. The survey found that four major factors increased the chances of sexual violence or unwelcome behaviour at universities: negative attitudes towards women and sex; alcohol use; abuse of positions of power; and perpetrators having easy access to bedrooms in university settings. The report recommends that universities help to prevent sexual violence through education programmes that address the drivers of sexual assault, as well as initiatives that support victims and give them access to counselling and clear procedures to report events. It also recommends that an independent body repeat the national survey every three years. Flood says that pressure on universities to act may lead them to introduce ineffective measures. \u201cIf universities are serious about responding to victims, and lessening rates of sexual assault and harassment on campus, then they need to adopt comprehensive and robust measures,\u201d he says. Reviews of several programmes in US secondary schools have found that education programmes that address attitudes and social norms and develop healthy relationship skills over multiple sessions can reduce violent sexual behaviour. Responding to the report, Universities Australia announced evidence-based education programmes for students, training for staff, leaders and first responders, and a temporary support phone line for victims of sexual assault or harassment. It also committed to developing guidelines for interactions between supervisors and postgraduate students. \n                   More universities must confront sexual harassment 2017-Jul-26 \n                 \n                   Harassment victims deserve better 2016-Jan-20 \n                 \n                   Sexual harassment must not be kept under wraps 2016-Jan-20 \n                 \n                   Astronomy roiled again by sexual-harassment allegations 2016-Jan-12 \n                 \n                   Scientific groups revisit sexual-harassment policies 2015-Nov-16 \n                 \n                   Change the course: National report on sexual assault and sexual harassment at Australian universities \n                 Reprints and Permissions"},
{"file_id": "548017a", "url": "https://www.nature.com/articles/548017a", "year": 2017, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "Islands in the region could be rid of the biting insects within a decade. Papeete, Tahiti The South Pacific islands have long drawn sailors and tourists seeking paradise on Earth, but biologists are now trying to make the region even more alluring. A biomedical lab in Tahiti has succeeded in nearly eradicating mosquitoes from a tiny nearby island, and researchers are gearing up to eliminate the pests from a larger island that is permanently inhabited by people.\u00a0 The eventual goal is to cut off transmission routes for mosquito-borne diseases such as dengue, chikungunya and Zika, which plague the Pacific. Researchers also hope that reducing the mosquito burden will help populations of local birds. On other islands, such as Hawaii, avian malaria spread by mosquitoes can devastate bird populations.\u00a0 The mosquito problem could be solved in the Society Islands \u2014 a part of French Polynesia that includes Tahiti, Moorea, Bora Bora, Huahine and Raiatea \u2014 within ten years, says Herv\u00e9 Bossin, an entomologist at the mosquito lab of the Louis Malard\u00e9 Institute in Paea, Tahiti, and the project\u2019s lead scientist. He and his team plan to do this using a technique that infects mosquitoes with a specific strain of a bacterium called  Wolbachia . About 65% of insects around the world carry  Wolbachia , but the strains vary. If mosquitoes with different strains mate, the resulting eggs develop incorrectly and don\u2019t hatch. If there are enough of these doomed pairings, an area\u2019s mosquito population usually dies out.\u00a0 But first, scientists must sort the males from the females. In a small, tidy lab on Tahiti\u2019s east coast, nestled among coconut palms and fragrant white tiare blossoms, senior technician Michel Cheong Sang pours water between two glass plates set at an angle, washing several dozen larvae of  Aedes polynesiensis  mosquitoes down between them. The larger females get stuck about halfway down. The smaller males descend a bit farther, forming a dark, wriggling band behind the glass. The low-tech method sorts more than 99% of the larvae correctly, says Bossin.\u00a0 All the larvae are infected with a particular strain of  Wolbachia  \u2014 taken from a related mosquito species,  Aedes reversi  \u2014 that is not naturally present in French Polynesia. Only the males will be released in target areas to mate with wild female mosquitoes. Researchers are working at a total of five sites, most located at luxury hotel properties around the Society Islands (see \u2018The  Wolbachia  approach\u2019).\u00a0 Right now, the  Wolbachia  method is the gold standard for ridding islands of mosquitoes, says Zhiyong Xi, a medical entomologist at Michigan State University in East Lansing. His group has used the technique to nearly eliminate  Aedes albopictus  mosquitoes from two small, inhabited islands in Guangzhou, China. \u201cI predict that the technology will be used in large scale in five years and we will see large tropical countries free of mosquitoes in less than ten years,\u201d Xi says. Researchers have run similar trials in Brazil and in the United States, where three states saw populations of wild  A.\u00a0albopictus  reduce by 70% over three years. The  Wolbachia  approach is based on a naturally occurring bacterium, and has drawn less opposition than experimental methods that use genetically modified mosquitoes. Still, Bossin and other researchers are following the progress of genome-based techniques, because they could eventually become faster and cheaper to use than the bacterial method.\u00a0 Bossin and his team started their first large-scale study in 2015, on a tiny island in the atoll of Tetiaroa. The atoll, once owned by film star Marlon Brando, is a 20-minute flight from Tahiti. The researchers\u2019 monitoring efforts currently find about one female per trap per week. Last year, earlier in the project, they found one per trap per day. The Tetiaroa pilot study had funding from the governments of French Polynesia and France, and logistical support from the small resort on the atoll. The hotels where Bossin is running trials this year are also funding his work.\u00a0 \n               No limits \n             The researchers are ramping up preparations to eradicate mosquitoes from an entire permanently inhabited island. They plan to announce the exact location soon, and hope to release  Wolbachia -infected male mosquitoes in two years. They already have the funds to expand their lab to handle the necessary increase in larvae production. If the team is successful, the island could become the first in the South Pacific to be cleared of mosquitoes.\u00a0 Bossin thinks the incompatibility technique could be scaled up to eradicate the biting insects from islands across the Pacific \u2014 perhaps even from continents. \u201cThe only limit is the size of your production facility,\u201d he says.\u00a0 Giovanni Benelli, an entomologist at the University of Pisa in Italy, is less sanguine about the prospect of continental eradication. And he wouldn\u2019t want to see all mosquitoes disappear in any case. \u201cThe mosquito\u2019s ecological role is still important,\u201d he says. Some aquatic animals eat mosquito larvae, and adult mosquitoes help to regulate mammal and bird populations by transmitting diseases among them, Benelli says.\u00a0 Bossin says he\u2019s happy to see mosquitoes thrive \u2014 just not where people live. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Rio fights Zika with biggest release yet of bacteria-infected mosquitoes 2016-Oct-26 \n                   \n                     US reviews plan to infect mosquitoes with bacteria to stop disease 2016-May-24 \n                   \n                     Why transgenic insects are still not ready for prime time 2016-Apr-22 \n                   \n                     'Gene drive' mosquitoes engineered to fight malaria 2015-Nov-23 \n                   \n                     Brazil tests GM mosquitoes to fight Dengue 2012-Apr-11 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22382", "url": "https://www.nature.com/articles/nature.2017.22382", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Gene-editing experiment pushes scientific and ethical boundaries. An international team of researchers has used CRISPR\u2013Cas9 gene editing \u2014 a technique that allows scientists to make  precise changes to genomes with relative ease  \u2014 to correct a disease-causing mutation in dozens of viable human embryos. The study represents a significant improvement in efficiency and accuracy over previous efforts. The researchers targeted a mutation in a gene called  MYBPC3 . Such mutations cause the heart muscle to thicken \u2014 a condition known as hypertrophic cardiomyopathy that is the leading cause of sudden death in young athletes. The mutation is dominant, meaning that a child need inherit only one copy of the mutated gene to experience its effects. In the gene-editing experiment, published online today in  Nature 1 , the embryos were not destined for implantation. The team also tackled two safety hurdles that had clouded discussions about applying CRISPR\u2013Cas9 to gene therapy in humans: the risk of making additional,  unwanted genetic changes  (called off-target mutations) and the risk of generating mosaics \u2014 in which different cells in the embryo contain different genetic sequences. The researchers say that they have found no evidence of off-target genetic changes, and generated only a single mosaic in an experiment involving 58 embryos. \n               Edits with potential \n             Several  teams in China  have already reported using CRISPR\u2013Cas9 to alter disease-related genes in human embryos. Work is also under way  in Sweden and the United Kingdom  to use the technique to study the early stages of human embryo development. That research is aimed at understanding basic reproductive and developmental biology, as well as unpicking some of the causes of early miscarriages. For the latest  Nature  paper, embryo experiments were conducted in the United States and led by Shoukhrat Mitalipov, a reproductive-biology specialist at the Oregon Health and Science University in Portland. The United States does not allow federal money to be used for research involving human embryos, but the work is not illegal if it is funded by private donors. In February, an influential report by the US National Academics of Science, Engineering, and Medicine concluded that scientists  should be allowed to use gene editing  in human embryos for research. The report also said that, ultimately, it may be acceptable to use the technique to alter embryos destined for implantation, if the goal was to treat a devastating disease and if there were no other reasonable alternatives. \n               Safety measures \n             Mitalipov\u2019s team took several steps to improve the safety of the technique. The CRISPR system requires an enzyme called Cas9, which cuts the genome at a site targeted by an RNA guide molecule. Typically, researchers wishing to edit a genome will insert DNA encoding CRISPR components into cells, and then rely on the cells' machinery to generate the necessary proteins and RNA. But Mitalipov\u2019s team instead  injected the Cas9 protein itself, bound to its guide RNA , directly into the cells. Reporter Shamini Bundell investigates a new development in the gene editing of human embryos. Because the Cas9 protein degrades faster than the DNA that encodes it, the enzyme is left with less time to cut DNA, says genome engineer Jin-Soo Kim of the Institute for Basic Science in Daejeon, South Korea, and a co-author on the study. \u201cCas9 is rapidly degraded,\u201d he says. \u201cThere is little time for off-target mutations to accumulate.\u201d Even so, Kim notes that the CRISPR\u2013Cas9 error rate can vary depending on which DNA sequence is being targeted. The  MYBPC3  mutation, in particular, was predicted to produce relatively few opportunities for off-target cutting. Just because the team did not find off-target changes does not mean that the changes aren't there, cautions Keith Joung, who studies gene editing at the Massachusetts General Hospital in Boston. \"Although this is likely the widest examination of off-target effects in genome-edited human embryos performed to date,\" he says, \"these investigators would need to do much more work if they wanted to define with certainty whether off-target effects do or do not occur in this context.\" \n               Mosaics minimized \n             The researchers also attempted to reduce the risk of mosaics by injecting the CRISPR\u2013Cas9 components into the egg at the same time as they injected the sperm to fertilize it. This is earlier in development than previous human embryo editing experiments had tried 2 , and studies in mouse embryos have shown that the technique can eliminate mosaics when the father\u2019s genome is targeted 3 . In an experiment Mitalipov's group performed in 58 human embryos fertilized with sperm carrying the  MYBPC3  mutation, 42 contained two normal copies of the  MYBPC3  gene. Because the sperm donor contained one normal copy and one mutated copy of  MYBPC3 , some of those embryos would have simply inherited the normal copy. The others were successfully edited to generate a normal gene. Only one was a mosaic. By comparison, the team found that 13 of 54 treated embryos were mosaics when the CRISPR\u2013Cas9 machinery was injected 18 hours after fertilization. The low rate of mosaics and the unusually high efficiency of gene editing make the study stand out, says stem-cell biologist Fredrik Lanner of the Karolinska Institute in Stockholm, who co-authored  a commentary accompanying the article . Additional testing is needed to show that the low rate of mosaics holds true for other gene-editing targets, but for now, he says, \"it's a huge step in that direction\". Lanner is also editing genes in human embryos, as a way of learning more about developmental biology. But he notes that in Sweden, it would be illegal for him to create embryos solely for the sake of research. Instead, he must use surplus embryos from fertility clinics (created using eggs that have already been fertilized), putting the kind of study that Mitalipov's team did \u2014 in which CRISPR\u2013Cas9 machinery is introduced at the same time as sperm \u2014 out of reach. \n               No 'designer babies' \n             The efficiency of gene editing in the  Nature  paper is exciting, says stem-cell biologist George Daley of Boston Children\u2019s Hospital in Massachusetts. \u201cIt puts a stake in the ground that this technology is likely to be operative,\u201d he says. \u201cBut it\u2019s still very premature.\u201d Daley worries that the success reported in the paper could motivate a clinician to try the technique before it has been fully tested. He points to an experimental technique called mitochondrial replacement therapy, which aims to treat embryos for a disorder that disables energy-generating cell structures called mitochondria. Last September,  news broke that a doctor had performed the technique  in a fertility clinic in Mexico, even though many experts believed it was not yet ready for clinical practice. Since then, reports have rolled in of  other clinicians performing the technique . Developmental biologist Robin Lovell-Badge of the Francis Crick Institute in London shares those concerns. But he notes that worries about \u201cdesigner babies\u201d \u2014 children who have been genetically enhanced, rather than merely correcting disease-causing mutations \u2014 may be eased somewhat by the new paper. In their experiments, Mitalipov\u2019s team provided a strand of DNA to serve as a template for rewriting the disease-causing mutation. But, surprisingly, the embryos did not use the template the researchers provided. Instead, the embryos used the mother\u2019s DNA as a guide to repair the  MYBPC3  mutation carried by the father\u2019s sperm. \u201cThis isn\u2019t a clear step towards a designer baby,\u201d says Lovell-Badge. \u201cThis suggests that you couldn\u2019t add anything that wasn\u2019t already there.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @heidiledford \n               \n                     UK bioethicists eye designer babies and CRISPR cows 2016-Sep-30 \n                   \n                     Second Chinese team reports gene editing in human embryos 2016-Apr-08 \n                   \n                     Should you edit your children\u2019s genes? 2016-Feb-23 \n                   \n                     UK scientists gain licence to edit genes in human embryos 2016-Feb-01 \n                   \n                     Enzyme tweak boosts precision of CRISPR genome edits 2016-Jan-06 \n                   \n                     Global summit reveals divergent views on human gene editing 2015-Dec-08 \n                   \n                     Nature  special: CRISPR \n                   \n                     National Academies of Science, Engineering, and Medicine: Human Gene-Editing Initiative \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22393", "url": "https://www.nature.com/articles/nature.2017.22393", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Researchers target suppressive cells to keep the body from attacking itself. Researchers in both academia and industry are turning to  immune-suppressing cells  to clamp down on autoimmune disorders, and the effort is building to a fever pitch. On 24 July, pharmaceutical firm Eli Lilly of Indianapolis, Indiana, announced that it would pay up to US$400 million to support the development of a drug \u2014 which entered clinical trials in March \u2014 that stimulates these cells, called  regulatory T cells . And in January, Celgene of Summit, New Jersey, announced plans to buy a company working on a similar therapy for $300 million. Other companies, from tiny biotechs to pharmaceutical heavyweights, are also investing in an approach that could yield treatments for a variety of disorders caused by an immune attack on the body\u2019s own cells. Such conditions include type 1 diabetes, lupus and rheumatoid arthritis. \u201cIt\u2019s a field that\u2019s just, like, crazy,\u201d says David Klatzmann, an immunologist at Pierre and Marie Curie University in Paris, who has been studying regulatory T cells and advises a Paris company called ILTOO Pharma. \u201cThe competition is coming very hard. It\u2019s going to be exciting to see where it goes.\u201d \n             Booster molecule \n           T cells are often thought of as key foot soldiers in the immune system\u2019s battle against foreign invaders. But there are many kinds of T cell, each armed with a different set of skills. Regulatory T cells serve to dampen immune responses \u2014 rather than attack invaders \u2014 and are important for preventing autoimmunity. People with disorders caused by an autoimmune attack often also have reduced levels of regulatory T-cell activity, leading scientists to suspect that bolstering such cells could reduce the immune system\u2019s attack on the body. To boost these cells, many researchers \u2014 now including those at Lilly and Celgene \u2014 are turning to a molecule called interleukin-2 (IL-2). High doses of IL-2 stimulate the \u2018effector\u2019 T cells that attack invaders, and in 1992, US regulators approved the treatment for some people with cancer, to prompt immune responses against the tumours. But low doses of IL-2 \u2014 roughly ten times lower than those used to treat cancer \u2014 instead  stimulate regulatory T cells , and have relatively little effect on effector T cells. This observation was made in the 1990s, but some researchers resisted the idea of using IL-2 to treat people with autoimmune disorders, even at low doses. The high doses used in cancer treatment are notoriously toxic, and can be fatal. \u201cInitially, lots of people were so afraid to use it,\u201d says Di Yu, an immunologist at the Australian National University in Canberra. \u201cThey have some bitter memories of IL-2.\u201d \n             Molecular tweaks \n           Gradually, a handful of promising small clinical trials have begun to overcome those concerns. And in 2011, a pair of studies provided the first clinical evidence that the approach could work. One of these was in graft-versus-host disease 1 , a condition that can occur when transplanted bone marrow produces immune cells that attack its new host, and the other was in an autoimmune disorder caused by hepatitis C virus infection 2 . Researchers have also launched other studies in type 1 diabetes and lupus. The lower doses seem, so far, to be much safer than the doses used for cancer treatment. Even so, there are still concerns about how specific the IL-2 treatment can be \u2014 any potential stimulation of effector T-cell responses in a patient who is already undergoing an autoimmune attack could be dangerous. \u201cIt\u2019s a robust field, but a challenging field,\u201d says Jeffrey Bluestone, an immunologist at the University of California, San Francisco, who has advised several companies on regulatory T-cell projects. \u201cIt's still unclear that you can get a regulatory T-specific response without any other effects.\u201d Instead, many companies are interested in tweaking IL-2 to make it more specific. Lilly\u2019s $400-million investment went to Nektar Therapeutics, a biotech company in San Francisco, California, that has produced chemically modified IL-2 that is less likely to bind to effector T cells. Delinia, the company that Celgene bought, which is based in Cambridge, Massachusetts, was developing a mutated form of IL-2 that has a similar effect. Other researchers are investigating possible cell therapies, for example extracting regulatory T cells from a patient's blood, expanding and activating the cells in the laboratory, and then reintroducing them into the patient. Another approach, still in the early stages of development, is to engineer regulatory T cells taken from the body to help the cells better recognize the molecules that are provoking an autoimmune response and to shut that response down. And basic researchers are still discovering more about the biology of regulatory T cells that could aid the development of future therapies. Hongbo Chi, an immunologist at St. Jude Children\u2019s Research Hospital in Memphis, Tennessee, has been studying how the metabolism of regulatory T cells differs from that of other T cells. And Alexander Rudensky, an immunologist at the Memorial Sloan Kettering Cancer Center in New York City, and his colleagues, this year reported a new subset of regulatory T cell that may have a more specific function[3]. Although Chi is not directly seeking out new drugs, he has noted industry\u2019s enthusiasm with interest. \u201cIt\u2019s really encouraging to see those therapeutics go into clinical trials,\u201d he says. \u201cThat motivates us basic researchers to understand the mechanism.\u201d \n                   Eye-opening picture of fetal immune system emerges 2017-Jun-14 \n                 \n                   Old cancer drug gets fresh look 2014-May-27 \n                 \n                   Cancer treatment: The killer within 2014-Apr-02 \n                 \n                   How microbes train our immune system 2011-Sep-21 \n                 \n                   Nature supplement: Cancer immunotherapy \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22412", "url": "https://www.nature.com/articles/nature.2017.22412", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Researchers pull study after several failed attempts by others to replicate findings describing a proposed alternative to CRISPR. The Chinese authors of a high-profile gene-editing paper retracted their study yesterday, citing scientists\u2019 inability to replicate the main finding. The paper, published in  Nature Biotechnology  in May 2016, detailed how an enzyme named NgAgo could be used to knock out or replace genes in human cells\u00a0by making incisions at precise points on the DNA 1 . The study promised a more versatile alternative to the now ubiquitous CRISPR\u2013Cas9 gene-editing system, which has revolutionized molecular biology and has even been  used to fix genes for a heritable heart condition  in human embryos. Han Chunyu, a molecular biologist at Hebei University of Science and Technology in Shijiazhuang, became a celebrity in China after publishing the NgAgo paper. But within months, doubts emerged on social media, with scientists saying that  they could not replicate the paper\u2019s result . These doubts were solidified in a series of a papers  asserting that NgAgo could not edit genomes  as stated in the paper 2 , 3 , 4 , 5 . On 2 August,  Nature Biotechnology  posted the  statement  from Han\u2019s team: \u201cWe are retracting our study because of the continued inability of the research community to replicate the key results.\u201d The retraction throws into question the future of a gene-editing centre that Han\u2019s university planned to build with 224 million yuan (US$32 million) and that Han was going to lead.  Nature 's news team could not immediately reach the university or Han for comment. Novozymes, a Danish enzyme manufacturer, previously paid the university an undisclosed sum as part of a collaboration agreement. Novozymes\u2019 Beijing-based press manager, Dongyi Chen,  told  Nature 's news team in January : \u201cWe have tested the technology and seen indications that it might be useful, but it is very early in its development and still needs a lot of work before we can determine if it is relevant for us.\u201d ( Nature \u2019s news team is editorially independent of  Nature Biotechnology .) Responding to news of the retraction, Chen says that the company has \u201cfurther explored the efficiency of the gene-editing technology called NgAgo. However, no obvious improvement has been tracked so far\u201d. The company has not, however, given up hope on NgAgo. \u201cScientific research takes time and we\u2019ll continue to look for any technological advances, NgAgo included, that can have a positive impact on our work,\u201d adds Chen.\u2028 Han has  told  Nature \u2019s news team on several occasions that he had identified a contaminant that explains why he and others have been unable to reproduce the NgAgo results. In June, he said that this work would be finished in two months and published soon after. In the retraction statement, Han\u2019s team writes: \u201cWe continue to investigate the reasons for this lack of reproducibility with the aim of providing an optimized protocol.\u201d But Gaetan Burgio, a biologist at the Australian National University in Canberra and one of the scientists who first raised about NgAgo and later  published an account  describing its failure to edit genes, is ready to move on. \u201cI think the story is over for now,\u201d he says. \n                   Biotech firm backs controversial CRISPR challenger 2017-Jan-20 \n                 \n                   Updated: NgAgo gene-editing controversy escalates in peer-reviewed papers 2016-Nov-23 \n                 \n                   Replications, ridicule and a recluse: the controversy over NgAgo gene-editing intensifies 2016-Aug-08 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22384", "url": "https://www.nature.com/articles/nature.2017.22384", "year": 2017, "authors": [{"name": "Michele Catanzaro"}], "parsed_as_year": "2006_or_before", "body": "Academics call for release of Ahmadreza Djalali, a disaster-medicine researcher who has been held in a Tehran prison for more than a year. An Iranian disaster-medicine researcher who was sent to prison in April 2016 is due to go to trial on 2 August, on charges of \u201ccollaboration with a hostile government\u201d. Ahmadreza Djalali has been warned by the Iranian court that he may be facing a death sentence, according to his wife, Vida Mehrannia. Djalali, who is 45, is affiliated with Sweden\u2019s Karolinska Institute in Stockholm and Italy\u2019s University of Eastern Piedmont in Novara, where he carried out research on improving hospitals\u2019 emergency responses to armed terrorism and radiological, chemical and biological threats. On 25 April 2016, Djalali was arrested during a visit to Iran and accused of spying. Djalali denies the charge, according to Mehrannia. She says that he was kept in solitary confinement for three months in Tehran\u2019s Evin prison and forced to sign a confession under threats to his wife and two children, who live in Sweden. On 31 January during a pre-trial meeting, Abolqasem Salavati, a judge with Iran\u2019s revolutionary court,  told Djalali that he could face a death sentence . The judge later vetoed Djalali's first choice of lawyer and forced him to select another. \n             Outside support \n           Djalali went on hunger and thirst strikes in early 2017,  which left him in dire health . And in early July, He was placed into solitary confinement for several hours during a prison visit by representatives from 45 foreign diplomatic missions, according to Mehrannia. Several scientific organizations have expressed support for Djalali. On 21 July, the academic-freedom network Scholars at Risk  urged supporters  to petition Iranian officials, including Supreme Leader Ayatollah Ali Khamenei, for Djalali\u2019s release, describing his continued imprisonment as \u201cretaliation for peacefully exercising his right to academic freedom\u201d. \n             Update (2 August): Djalali\u2019s trial has been postponed owing to the judge\u2019s illness, according to Mehrannia, who says that a new trial date has not been set. \n           \n                   Jailed Iranian researcher\u2019s health worsening rapidly 2017-Mar-20 \n                 \n                   Iran releases physicist after five years in jail 2016-Aug-29 \n                 \n                   Iran needs to present a united front on science 2014-Apr-23 \n                 \n                   Iranian says he was jailed for refusing to engage in military research 2013-Apr-26 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22403", "url": "https://www.nature.com/articles/nature.2017.22403", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Changes to flowering times helped the staple crop spread into new areas thousands of years ago. Genome sequences from nearly 2,000-year-old cobs of maize (corn) found in a Utah cave paint a portrait of the crop at the dawn of its adaptation to the highlands of the US southwest. That maize, researchers found, was small, bushy and \u2014 crucially \u2014 had developed the genetic traits it needed to survive the short growing seasons of high altitudes. The team\u2019s study 1 , published on 3 August in  Science , is remarkable in how it tackles complex genetic traits governed by the interactions of many different genes, say researchers. It uses that information to create a detailed snapshot of a crop in the middle of domestication. Such insights could help modern plant breeders to buffer crops against global climate change. Geneticists of both modern and ancient crops have poured tremendous effort into understanding maize, which was one of the most important subsistence crops in the New World thousands of years ago, and is a cornerstone of global agriculture today. Maize originated in Mexico and rapidly spread into the lowlands of the southwest United States about 4,000 years ago. But communities at higher altitudes did not fully embrace the crop until 2,000 years later \u2014 a delay that has long puzzled archaeologists studying the region, says Kelly Swarts, a quantitative geneticist at the Max Planck Institute for Developmental Biology in T\u00fcbingen, Germany. \u201cThere was always the question: why wasn\u2019t this catching on? Why weren\u2019t people doing agriculture in the uplands?\u201d she says. Swarts and her colleagues turned to a site in a Utah cave called Turkey Pen Shelter, where a farming community lived about 2,000 years ago. Inhabitants of the cave raised turkeys, wove intricate baskets and shoes, and had the resources needed to store and process corn. Maize, which they probably served in soups and stews, comprised about 80% of their diet. \n             Complex crops \n           Swarts\u2019s team sequenced the genomes of fifteen 1,900-year-old maize cobs found in the shelter and compared their sequences to those in a database of genomes and physical traits from some 2,600 modern maize lines. The researchers then used that information to extrapolate the physical characteristics of the Turkey Pen maize plants, including complex traits such as flowering time. The analysis revealed a crop that was shorter and more branched than modern varieties. \u201cMore like little bushes,\u201d says Swarts, though the role of these traits is unclear. The crop also flowered more quickly than lowland varieties \u2014 an important adaptation to life in the highlands, which have a shorter growing season than lower elevations. The analysis could open the way for similar studies of complex traits in other plants and animals, including humans, says Matthew Hufford, who studies evolutionary genomics in maize at Iowa State University in Ames. \u201cWe just now have the genetic tools and the analytic tools to make really good use of them.\u201d Plant evolutionary biologist Robin Allaby of the University of Warwick, UK looks forward to seeing the same approach applied to earlier stages of maize domestication. \"That stuff was 1,900 years old, and a lot of the whistles and bangs had already happened,\" he says. \"It's going to be really cool to see what a full 5,000-year-old maize phenotype looks like.\" A key finding from the study, says Hufford, was the realization that the genetic variants needed to adapt to highland life were already circulating in maize populations thousands of years ago \u201cThe diversity needed for high altitudes was there, but getting it in the right combination took 2,000 years,\u201d he says. And that diversity could be crucial for breeders as they try to adapt modern maize to a rapidly changing climate, says Swarts. \u201cIt\u2019s really promising for maize\u2019s future that it has so much standing variation \u2014 assuming we can conserve that diversity,\u201d says Swarts. \u201cIf we needed to do this, it wouldn\u2019t take 2,000 years. We could do it a lot faster now.\u201d \n                   Ancient genomes heat up dog domestication debate 2017-Jul-18 \n                 \n                   Neanderthal tooth plaque hints at meals \u2014 and kisses 2017-Mar-08 \n                 \n                   How cats conquered the world (and a few Viking ships) 2016-Sep-20 \n                 \n                   Ale genomics: how humans tamed beer yeast 2016-Sep-08 \n                 \n                   Nature  Insight: Plants \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22228", "url": "https://www.nature.com/articles/nature.2017.22228", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Artificial soils that mimic the surfaces of the Moon, Mars and asteroids are hard to make \u2014 and often miss the mark. James Carpenter just needed some fake Moon dirt. Carpenter, a lunar-exploration expert at the European Space Agency (ESA) in Noordwijk, the Netherlands, works on a drill designed to hunt for buried ice on the Moon. His team recently ordered half a tonne of powdery material  to replicate the lunar surface  from a commercial supplier in the United States. But what showed up was not what the team was expecting. \u201cThe physical properties were visibly different,\u201d says Carpenter. His experience underscores a longstanding problem with artificial space soils, known as simulants: how to make them consistently and reliably. But now there is a fresh effort to bring the field into line. Last month, NASA established a team of scientists from eight of its research centres to analyse the physical properties and availability of existing simulants. And, for the first time, an asteroid-mining company in Florida is making scientifically accurate powders meant to represent the surfaces of four classes of asteroid. It delivered its second batch to NASA on 28 June. \u201cNASA is trying to conquer the Wild West of simulants,\u201d says Philip Metzger, a planetary scientist at the University of Central Florida in Orlando. Such materials are meant to mimic the mix of dust and broken rock that covers the surfaces of planets and asteroids. Engineers use the artificial soils to test  space-exploration technologies such as drills and rovers , and to determine whether astronauts could make structures by feeding space dirt  into 3D printers  or by compressing it 1 . Scientists use simulants to explore geological processes such as how rocks weather in space. \n               The dirt on dirt \n             Over the years, space agencies and research groups have tended to make their own artificial soils as needed from mixtures of ash and grit, sand and crushed bricks, and even glass beads. This has led to a wild proliferation of soils; there are more than 30 lunar simulants alone 2 . \u201cThere are a lot of people out there creating their own simulant with no geology or materials-processing background,\u201d says Jennifer Edmunson, a geologist at NASA\u2019s Marshall Space Flight Center in Huntsville, Alabama. But no artificial soil can re-create all the physical and chemical properties of a planet's surface. A mixture that was developed for engineers to drive rovers in would probably be terrible for studying the geochemical properties of the Moon. Researchers do not always pay attention to those limitations, says Clive Neal, a lunar scientist at the University of Notre Dame in Indiana. \u201cWe have no accreditation in terms of what this can be used for and what it can\u2019t be used for,\u201d he says. \u201cIf you use it for the wrong thing you end up with misleading results.\u201d In 2010, a panel of lunar scientists recommended that NASA develop a database that researchers could use to compare the characteristics of different simulants and pick the best one for each use. But the agency had no money to support such a project. The new working group aims to outline how much it would cost to produce a database covering simulants for all types of planetary bodies. \u201cHopefully, we\u2019ll be able to develop this repository,\u201d says Brad Bailey, associate director of NASA\u2019s Solar System Exploration Research Virtual Institute, who is based in Washington DC. The database would include the four new asteroid simulants being made by the Orlando office of Deep Space Industries, an asteroid-mining company. NASA has ordered five tonnes over the next two years. Each simulant is based on a different class of meteorites called carbonaceous chondrites, which are thought to be chunks of asteroids. \n               Secret recipe \n             To make fake asteroid dirt, technicians mix various minerals \u2014 including bronzite, which is sourced from jewellery suppliers as polished stones \u2014 compress them into bricks and then pulverize them. \u201cWe have to do something that is basically equivalent to hitting a solid rock with thousands of meteorites over a long period of time,\u201d says Stephen Covey, the company\u2019s director of research and development. Deep Space Industries delivered 512 kilograms of the first simulant to NASA in March, and 532 kilograms of the second type in June. The agency plans to use it in work on missions such as  OSIRIS-REx, a spacecraft that is making its way to an asteroid  to collect a sample and bring it back to Earth. In Europe, Carpenter and his colleagues are still hunting for their perfect lunar soil \u2014 but they have given up on ordering it commercially. The researchers, who need 700 tonnes for a planned lunar habitat at ESA\u2019s astronaut-training centre in Cologne, Germany, are looking much closer to home. They have decided to grind up rocks from the nearby basalt mines of the Eifel region. \n                     The $2.4-billion plan to steal a rock from Mars 2017-Jan-18 \n                   \n                     OSIRIS-REx spacecraft blazes trail for asteroid miners 2016-Sep-02 \n                   \n                     Astronomers comb through Moon smash haul 2010-Oct-21 \n                   \n                     NASA's lunar simulant page \n                   \n                     Deep Space Industries \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22320", "url": "https://www.nature.com/articles/nature.2017.22320", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Results point to a single origin for modern canines and push back the timing by thousands of years. Researchers chasing the origin of modern dogs find that canines were domesticated once, between 20,000 and 40,000 years ago. The results, published on 18 July in  Nature Communications 1 , push back against a controversial 2016 study 2  that suggested dogs were domesticated twice. The latest analysis also add weight to previous research that moves the timing of domestication back as far as 40,000 years ago.  Everyone has their own idea about where and when dogs originated, says Krishna Veeramah, a palaeogeneticist at Stony Brook University in New York and an author on the latest study. \u201cArchaeologists suggest one and geneticists suggest another \u2014 people are always getting very different answers.\u201d Zeroing in on a precise time and location for dog domestication has long been challenging because of seemingly contradictory or incomplete evidence. A 14,700-year-old jawbone is the oldest undisputed fossil from a domesticated dog ( Canis lupus familiaris ), but dog-like remains date back as far as 35,000 years ago. Genetic data show that the ancestors of all modern dogs split into two populations: one that gave rise to East Asian breeds and another that would become modern European, South Asian, Central Asian and African dogs. Yet researchers still can\u2019t pin down when this split occurred. And they can\u2019t agree on whether dogs were domesticated once or twice. \n             Origin story \n           The latest research offers a little clarity on the timing of domestication and on the dual or single origin question. Veeramah and his colleagues studied genomes from Neolithic dog fossils found in different parts of Germany \u2014 one from the start of the period, 7,000 years ago, and one from 4,700 years ago. They also looked at data from a 5,000-year-old dog specimen found in Ireland. The team then compared these ancient genome sequences with genetic data from 5,649 canids, including modern dogs and wolves. The researchers estimate that dogs and wolves diverged genetically between 36,900 and 41,500 years ago, and that eastern and western dogs split 17,500\u201323,900 years ago. Because domestication had to have happened between those events, the team puts it somewhere from 20,000 to 40,000 years ago. These dates challenge the need for a dual-origin domestication explanation suggested in a 2016 study published in  Science 2 . That work compared genetic sequences from 59 ancient dogs, as well as a Neolithic canine from Ireland, and pegged the split between eastern and western dogs between 6,400 and 14,000 years ago. The team suggested that because the split occurred thousands of years after the first known appearance of dogs in Europe and East Asia, there must have been two instances of domestication that happened around the same time. \u201cWe really don\u2019t know where dogs were domesticated and as far as we can tell it happened once,\u201d says Pontus Skoglund, a geneticist at Harvard Medical School in Boston, Massachusetts, who has worked to pin down when dogs were first domesticated but was not involved in either study.\u00a0 The authors of the latest work acknowledge that their study won\u2019t settle the debate over when and where man\u2019s best friend originated. \u201cMore ancient dog DNA from genomes will ultimately solve the problem,\u201d Veeramah says.  \u201c If we can add in other ancient samples from all around the world, it'll give us a more comprehensive picture of population history and likely dog origins,\u201d says Adam Boyko, a geneticist at Cornell University in Ithaca, New York. But we need diverse samples not just geographically, but also through time, says Boyko, who is compiling a modern dog genetic database from canines all over the world. Veeramah, whose research focuses mainly on ancient humans, says that learning more about the origins of modern dogs can inform his work on people. \u201cDogs and humans have an important history together,\u201d he says. \n                   Ancient genomes suggest dual origin for modern dogs 2016-Jun-02 \n                 \n                   Ancient wolf genome pushes back dawn of the dog 2015-May-21 \n                 \n                   Prehistoric genomes reveal European origins of dogs 2013-Nov-14 \n                 \n                   Dog genetics spur scientific spat 2013-Jun-18 \n                 \n                   Dog's dinner was key to domestication 2013-Jan-23 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22309", "url": "https://www.nature.com/articles/nature.2017.22309", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Europe\u2019s highest court will rule on Poland's policy that encourages tree-felling in biodiversity hotspot. A campaign by scientists and environmental activists to prevent a surge in logging in Europe\u2019s ancient Bia\u0142owie\u017ca Forest is headed to the courts. The European Commission announced on 13 July that it is referring Poland to Europe's highest court after the Polish government declined to roll back controversial new rules that permit more tree-felling in Bia\u0142owie\u017ca \u2014 a biodiversity hotspot and the largest remaining patch of a primeval forest that once covered the European Plain. The court case could take years, but the commission has also asked for an immediate ban on logging in the forest to prevent further environmental damage. That\u2019s a rare request, says Agata Szafraniuk, a Warsaw-based legal expert with environmental-lawyer group ClientEarth, which is campaigning to protect the forest. The Court of Justice of the European Union (ECJ) has been asked only four times before to impose interim bans on activities that might result in environmental harm \u2014 and in all cases, it ordered a halt within days or weeks. (Those instances concerned the illegal hunting of wild birds in Malta in 2008, and in Italy in 2006 and 2009; and, in 2007, the  construction of a highway through protected wetlands in northeast Poland ). The battle over management of Bia\u0142owie\u017ca \u2014 a woodland area that covers roughly 1,500 square kilometres straddling Poland\u2019s border with Belarus, and a United Nations World Heritage Site \u2014 has been raging for over a year. The forest\u2019s ancient trees provide habitats for a rich diversity of fungi, insects, birds and mammals, including the largest population of European bison ( Bison bonasus ), and are also a valuable research resource, ecologists say. Scientists have conducted numerous studies there, most recently into the activity patterns of two bat species ( Nyctalus noctula  and  Nyctalus leisleri ) 1  and the Eurasian lynx ( Lynx lynx ) 2 . \n               A beetle burden \n             In March 2016, Poland\u2019s environment minister, Jan Szyszko, who is also a forester and entomologist, amended forest management rules to permit a three-fold increase in timber harvesting from Bia\u0142owie\u017ca (save for a central region designated a national park, where logging is forbidden). His ministry argues that dead wood needs to be removed to combat an infestation of the European spruce bark beetle ( Ips typographus ) in the forest\u2019s Norway spruce ( Picea abies ). But  scientists argued against those plans . \u201cBeetle pests are natural processes from which a\u00a0forest can regenerate without intervention,\u201d says Rafa\u0142 Kowalczyk, director of the Polish Academy of Sciences\u2019 Mammal Research Institute in the village of Bia\u0142owie\u017ca. \u201cThe current outbreak is severe, but absolutely not dangerous.\u201d On 29 April, the 150 participants of an international forest conference in Neusch\u00f6nau, Germany, wrote a letter to Szyszko, arguing that natural disturbances such as wildfires and insect outbreaks are an inherent part of forest ecosystems. \u201cBia\u0142owie\u017ca is a unique ecosystem in Europe that can well do without any so-called salvage logging,\u201d says Wolfgang Weisser, an ecologist at the Technical University of Munich in Germany who organized the letter. Meanwhile, environmental protesters have taken more extreme action \u2014 including chaining themselves to logging machines in protest. Weisser and Kowalczyk say \u2014 as do other opponents of the logging policy \u2014 that they suspect that the amended forest-management plan is a concession to commercial interests, although the environment ministry says there are no commercial incentives at play. Extracted timber is a valuable resource, used to make charcoal and other wood products \u2014 and char dubbed 'Bia\u0142owie\u017ca' turns up for sale in Polish supermarkets, Weisser says. \n               Court warnings \n             In June 2016, the European Commission sent a formal notification to Poland\u2019s government that the logging amendments risked infringing EU laws protecting birds and habitats, and urging it to comply. In April this year, it sent a final warning. Poland replied, in a letter that has not been made public. But Kowalczyk thinks it is likely that the country re-stated its oft-repeated stance that active forest management is necessary to combat the beetle pest, and that the long-term impact of increased logging on forest health and biodiversity would be closely monitored. Whatever it said, the reply did not satisfy the commission. It\u2019s now up to the ECJ to rule on the matter. The court is the final arbiter on EU legal matters, and its decisions cannot be contested. No country has ever failed to comply in cases when the ECJ has ordered interim bans to prevent immediate harm, Szafraniuk says: if a ban were ordered and Poland did not obey, the commission could impose severe daily fines \u2014 perhaps as large as hundreds of thousands of euros \u2014 or withdraw EU funds. \u201cWe hope that the Court of Justice will impose the ban on logging, as a matter of urgency, before its summer break on 21 July,\u201d says Szafraniuk. If it does not, any decision on an interim ban will have to wait until September, when the ECJ resumes its work. \n                     Polish scientists protest over plan to log in Bia\u0142owie\u017ca Forest 2016-Feb-24 \n                   \n                     Ecology: The heart of the wood 2008-Sep-17 \n                   \n                     European Commission fights for rare Polish wetland 2007-Mar-09 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22318", "url": "https://www.nature.com/articles/nature.2017.22318", "year": 2017, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "President said \u2018Make Our Planet Great Again\u2019 \u2014 and researchers signed up. Hundreds of climate scientists, including many from the United States, have applied to work in France under a \u20ac60-million (US$69-million) scheme set up by the country's president, Emmanuel Macron, after his US counterpart Donald Trump rejected the Paris accord on global warming. And Germany has announced that it will set up a similar programme to lure researchers. Macron launched his \u2018 Make Our Planet Great Again \u2019 initiative on 8 June, seeking to entice researchers in other countries to France with offers of 4-year grants worth up to \u20ac1.5 million. Six weeks on, the programme has been flooded with applicants, says Anne Peyroche, a biologist and the chief research officer of the CNRS, France\u2019s national basic-research agency. \"Applications continue to come in every hour,\" she says. Most applied for relatively short sabbaticals in France, but the 154 scientists attracted by longer-term stays of four years or more are of most interest to the initiative's organizers, Peyroche says. France is also headhunting some top climate scientists individually, she adds. The scheme will shortlist as many as 80 scientists by mid-September, with 50 or so winners to be announced around the end of November. \n               Visionaries wanted \n             One applicant is Ashley Ballantyne, a bioclimatologist at the University of Montana in Missoula. His proposal involves laying the foundation for a global integrated carbon-observing network, combining satellite and atmospheric data to seek insights into how ecosystems respond to climate change. \"There are very few funding opportunities in the United States that promote research on carbon\u2013climate interactions at the global scale, so the fact this programme was looking for visionary thinking was appealing,\" he says. Ballantyne has long had informal collaborations with French and other European scientists, including at the renowned Laboratory of Climate and Environmental Sciences (LSCE) at Gif-sur-Yvette near Paris. His principal motivation for applying was the opportunity to strengthen and formalize these ties, he says. The French offer is a \"very attractive proposition for many scientists in the US\", says Kim Cobb, a palaeoclimatologist at the Georgia Institute of Technology in Atlanta. US climate science is under pressure, she adds: scientists are waiting to hear whether Congress will approve Trump's proposed drastic cuts to the field. Cobb says that, were she not a tenured scientist working in an exceptional research environment, she would be \"jumping at the opportunity\" to work in France. \n               German backing \n             Officials in Germany announced on 13 July that they will establish a scheme to operate alongside the French programme. The German fund will comprise  \u20ac15 million of government money , matched by a sum from the country's participating research organizations. The details of the programme have not yet been finalized, but Germany's research ministry has  created a website  for interested scientists to sign up to receive details. Peyroche says that the German fund will target younger or more-junior scientists than its French counterpart. Climate scientists in France support Macron's strong political and diplomatic stance on the Paris agreement. But a vocal minority of researchers argue that the scheme is largely a public-relations exercise to boost France's image abroad, even while research funds at home are scarce. The French government last week proposed trimming the 2017 budget for research and higher education by \u20ac331 million, as part of more than \u20ac3 billion of cuts in public spending to pay for new initiatives without increasing the national deficit. (The cuts for research activities are distributed across several ministries, from agriculture to defence; the research and higher education ministry itself will see only a \u20ac180-million reduction in its \u20ac23.85-billion budget, says its minister Fr\u00e9d\u00e9rique Vidal.) On 13 July, France's Conference of University Presidents said in a  statement  that it \"deplored\" what it described as \"incomprehensible\" cuts. \"These numbers should make any foreign scientist wonder about the generous invitation of President Macron to relocate to France,\" says Patrick Lemaire, a biologist at the University of Montpellier and founder of the researcher-led campaign group Sciences en Marche. \"The cuts are a warning that the scientific environment they would find in France may be very far from the one they are promised.\" But Sacha Wunsch-Vincent, an economist at the World Intellectual Property Organization in Geneva, Switzerland, says that Macron's prominent overtures to foreign scientists and entrepreneurs are helping to promote France as a good place to do research and innovation, which is important for attracting top talent. \"There is a seismic shift in the branding of France,\" he says. \n                     Macron consolidates electoral victory 2017-Jun-19 \n                   \n                     Trump pulls United States out of Paris climate agreement 2017-Jun-01 \n                   \n                     Macron presidency is a welcome experiment 2017-May-10 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22304", "url": "https://www.nature.com/articles/nature.2017.22304", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Treatment shows promise in young people with leukaemia, but safety risks abound. External advisers to the US Food and Drug Administration (FDA) have thrown their support behind a therapy that genetically engineers a patient\u2019s own immune cells to target and destroy cancers. In a unanimous vote on 12 July, the panel determined that the benefits of CAR-T therapy outweigh its risks. The vote comes as the agency considers whether to issue its first approval of a CAR-T therapy, for a drug called tisagenlecleucel, manufactured by Novartis of Basel, Switzerland. The FDA is not obligated to follow the recommendations of its advisers, but it often does. Novartis is seeking approval to use tisagenlecleucel to treat children and young adults who have a form of leukaemia called acute B-cell lymphoblastic leukaemia, and who have not responded sufficiently to previous treatment or have relapsed since that treatment. In the United States, about 15% of children and young adults with acute lymphoblastic leukaemia relapse. Studies have shown that CAR-T therapies can produce lasting remissions in such cases. In one key trial of tisagenlecleucel, which started in 2015,  52 out of 63 participants \u2014 82.5% \u2014 experienced overall remissions . The unpublished trial had no control group, so investigators cannot yet say with certainty how much effect the treatment had. But many participants of such trials have remained cancer-free for months or years. Many of the FDA\u2019s advisers were effusive in their praise. \u201cThis is a major advance, and is ushering in a new era,\u201d said panel member Malcolm Smith, a paediatric oncologist at the US National Institutes of Health in Bethesda, Maryland. Timothy Cripe, an oncologist at Nationwide Children\u2019s Hospital in Columbus, Ohio, called it one of the most exciting things he has seen in his lifetime. But the therapy  poses serious risks . During the 2015 tisagenlecleucel trial, 47% of participants experienced an extreme inflammatory reaction known as cytokine release syndrome, severe cases of which are called cytokine storms. The syndrome \u2014 characterized by symptoms such as high fevers and organ failure \u2014 can be life-threatening. But Novartis says trial clinicians were able to manage the reaction successfully in all cases. Neurological problems such as seizures and hallucinations were also relatively common but temporary, the Novartis team reported. This is in stark contrast to some other CAR-T trials that have, over the past year, reported the deaths of several participants from severe brain swelling. Novartis\u2019s therapy is not identical to the CAR-T cells used in those trials, which were administered in adults, but the deaths cast a pall over the entire field. \n               Thorny issues \n             CAR-T therapies also present a gnarly regulatory challenge for the FDA: how do you assure the potency and purity of a complex, living drug that must be made fresh for each patient? FDA advisers spent half of the 12 July meeting learning about how Novartis has attempted to standardize, as much as possible, a treatment based on cells taken from individual people. To generate a batch of tisagenlecleucel, white blood cells are purified from a sample of a patient\u2019s blood and shipped to a central processing centre. There, staff use a virus to insert into the T\u00a0cells genes that encode a cellular receptor \u2014 called a chimaeric antigen receptor \u2014 that will recognize leukaemia cells. The cells are grown in culture before they are reintroduced into the patient. It takes Novartis about 22 days to manufacture each person\u2019s treatment. Several committee members expressed concern about the uncertainties that still swirl around the therapy. These include the risk that the virus used to engineer the cells could acquire the ability to replicate, or that improper insertion of the foreign gene could turn the T cells cancerous. The panel also noted the uncertain effects of engineering and reintroducing a mix of different kinds of T cells and other immune cells. CAR-T therapy is high-risk, and little is known about any long-term toxicity effects. But the young patients who would receive it have few alternatives, and those alternatives carry risks of their own, said Bruce Roth, an oncologist at Washington University School of Medicine in St. Louis, Missouri, and chair of the FDA advisory panel. \u201cAlthough I have some concerns about late toxicity, you have to be a long-term survivor to be concerned about late toxicity\u201d, he said. \u201cAnd I think that\u2019s what this drug gets us.\u201d \n                     Safety concerns blight promising cancer therapy 2016-Oct-12 \n                   \n                     Cancer treatment: The killer within 2014-Apr-02 \n                   \n                     Engineered immune cells battle acute leukaemia 2013-Mar-20 \n                   \n                     FDA report on tisangenlecleucel \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22291", "url": "https://www.nature.com/articles/nature.2017.22291", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Two-fifths report feeling unsafe at work, and 18% have concerns about attending conferences. Women of colour working in astronomy and planetary science experience high rates of harassment at work, a study finds. In a survey, a striking 40% of these scientists reported feeling unsafe in their workplaces owing to their gender, and 28% reported feeling unsafe on account of their race. The findings, published on 10 July in the  Journal of Geophysical Research: Planets 1 , illustrate a well-researched phenomenon: a woman\u2019s risk of being subjected to gendered or race-based harassment is higher if she belongs to multiple minority groups. Women of colour were more likely than white women or men of colour to recall a negative workplace experience during a five-year period from 2011-2015. Such incidents included having their mental or physical ability questioned. \u201cThis is something that I\u2019ve known about, that I\u2019ve seen and experienced, as someone of colour, for as long as I\u2019ve been in the field. So I\u2019m not surprised,\u201d says Cristina Thomas, an astronomer at the Planetary Science Institute who is based at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland. \u201cI was very happy to see someone quantify what was happening so other people would see it.\u201d \n               In plain sight \n             The study, whose participants ranged from undergraduate students to senior researchers, suggests that the negative environment experienced by many female scientists of colour is often apparent to colleagues of other genders or ethnicities. Eighty-eight per cent of the 474 participants \u2014 a group that was 84% white and included both men and women \u2014 had heard remarks that were racist,  sexist  or directed at a person\u2019s gender or intelligence in their current workplace. Survey respondents included 45 women of colour, who collectively accounted for 11% of participants. That proportion is double the percentage of minority women in the United States who hold bachelor's degrees in physical science. The analysis is the first of its kind in the astronomy and planetary-science fields, and one of few in a science, technology, engineering or medicine discipline that specifically examines the experiences of women of colour, says study co-author Christina Richey, former chair of the American Astronomical Society\u2019s Committee on the Status of Women in Astronomy in Washington DC. The research team was made up of two planetary scientists and two social scientists, including anthropologist Kathryn Clancy of the University of Illinois at Urbana-Champaign, who led a high-profile survey of harassment in scientific fieldwork that was published in 2014 in  PLoS ONE 2 . The latest study found that harassment and discrimination can have a heavy impact on an individual\u2019s career decisions. Eighteen per cent of women of colour and 12% of white women reported avoiding a class, conference or professional event because they did not feel safe attending. Such events can help to foster professional networks, mentorship and opportunities for collaboration \u2014 connections that can advance a scientist\u2019s career, says Zuleyka Zevallos, a sociologist at Swinburne University of Technology in Melbourne, Australia. \n               Systemic solutions \n             \u201cIf a culture of hostility remains in place, it doesn\u2019t matter what we do at the individual level because the system is broken. The pipeline is broken,\u201d says Zevallos, who helped to implement gender-education programmes at universities in her former position at the Australian Academy of Science in Canberra. The analysis has sparked intense discussion online among astronomers and planetary scientists. Several female scientists of colour have  shared their stories on Twitter , describing the significant, but sometimes subtle, consequences of harassment and discrimination in their own lives. Chanda Prescod-Weinstein, a theoretical physicist at the University of Washington in Seattle,  tweeted  that when faced with events that she thought might expose her to harassment, discrimination or other negative experiences, she sometimes brought her husband along. But that created an extra financial burden for the couple. In recent years, professional societies such as the American Astronomical Society and American Geophysical Union  have taken steps to prevent harassment at their meetings . The latest study suggests several actions that research institutions, funding agencies and scientific societies can take to reduce harassment. These include updating their codes of conduct to bar harassment; instituting mandatory cultural-awareness training; encouraging leading researchers to model appropriate behaviour; and putting in place swift sanctions for perpetrators. \u201cIt\u2019s time to pivot away from the conversation of, \u2018Is gender equity and racism a problem in science?\u2019, and shift to taking action,\u201d Zevallos says. \u201cWe can\u2019t afford to lose more women of colour, white women and under-represented minorities.\u201d \n                     Women in physics face big hurdles \u2014 still 2016-Aug-01 \n                   \n                     Speak up about subtle sexism in science 2016-Apr-26 \n                   \n                     Excluded, intimidated and harassed: LGBT physicists face discrimination 2016-Mar-22 \n                   \n                     Harassment victims deserve better 2016-Jan-20 \n                   \n                     Sexual harassment must not be kept under wraps 2016-Jan-20 \n                   \n                     Astronomy roiled again by sexual-harassment allegations 2016-Jan-12 \n                   \n                     Berkeley releases report on astronomer sexual-harassment case 2015-Dec-19 \n                   \n                     Scientific groups revisit sexual-harassment policies 2015-Nov-16 \n                   \n                     Science and sexism: In the eye of the Twitterstorm 2015-Nov-11 \n                   \n                     US astronomers rally to end sexual harassment 2015-Oct-21 \n                   \n                     Sexism has no place in science 2015-Jun-15 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22230", "url": "https://www.nature.com/articles/nature.2017.22230", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "The technique could be used on everything from flowers to cells to examine the factors that influence the shapes of plant parts. The story of a plant is etched in its leaves. A tree growing in a cold environment with plenty of water is more likely to have large leaves with many serrated teeth around the edges. But if the same species lives in a warm, dry region,  its leaves are likely to be smaller and smoother . Now, an atlas that traces the shapes of 182,000 leaves from 141 plant families and 75 locations around the world shows promise for refining scientists\u2019 ability to read that story. Using that atlas, researchers found that leaf shape alone accurately predicted where a leaf was collected 14.5% of the time 1 , and plant family correctly 27.3% of the time. That is far better than predictions made using conventional methods to describe a leaf's shape. Researchers hope that the approach will help them to learn more about the forces that shape plant leaves, and even to get a glimpse of ancient climates by analysing the shapes of fossilized plants. \u201cIt\u2019s an amazing data set,\u201d says Dan Peppe, a palaeobotanist at Baylor University in Waco, Texas. \u201cWe\u2019re getting closer and closer to automating measures of leaf shape, and using that to figure out the taxonomy of a plant and reconstruct climate.\u201d The results  were posted  on 20 June to bioRxiv, a server that hosts biology preprints. Plant morphologist and lead author Dan Chitwood also presented the study at the Botany 2017 meeting in Fort Worth, Texas, on 27 June. \n               Shaping up the data \n             Chitwood, formerly of the Donald Danforth Plant Science Center in St Louis, Missouri, and his colleagues pulled together data from their own work on specific plant groups, such as grape and  tomato plants , as well as several large data sets from projects that aimed to catalogue a wider swath of plant species and locations. They then used a topological method called persistent homology to analyse the shape of each leaf. The method assigns each pixel in an image a value according to the density of the pixels around it. The team broke each leaf into 16 parts, and analysed the pattern of values in each one. The researchers used the resulting catalogue of leaf shapes to look for taxonomic and geographic relationships between species. Chitwood\u2019s ultimate goal is to reconstruct the leaf \u2018morphospace\u2019: the full catalogue of possible leaf shapes. \u201cIf you could measure all the leaves that currently existed and all the leaves that ever existed, would it be completely random?\u201d he asks. \u201cOr would there be some leaves that never showed up? Was it because the plants can\u2019t make them?\u201d Persistent homology has been used to map everything from networks of neurons to the structure of musical phrases, and Chitwood hopes that it can provide a unified method for analysing all parts of a plant. Others are eager to apply the same method to their own research needs. Plant morphologist Yannick St\u00e4dler of the University of Vienna wants to use the technique to analyse his growing library of X-ray images of flowers. He hopes that it will help him to overcome a stumbling block with conventional morphological methods, many of which involve placing landmarks \u2014 points on structures that recur across species \u2014 on images. Those techniques  work well for animals , he says, which tend to have obvious landmarks: the point at which two bones meet, the corner of an eye, the tip of a nose. But flowers often have smooth, curved surfaces, which makes it difficult for researchers to pinpoint specific landmarks. \u201cThis has been a horrible problem in leaves and in flowers,\u201d St\u00e4dler says. \u201cIt has held us back.\u201d \n               Leaf by leaf \n             Palaeobotanists such as Peppe are hoping for ways to automate the analysis of fossilized leaves \u2014 a process that currently requires painstaking work to manually place landmarks on fossils for analysis. Other projects are analysing plant features, including leaves, fruits and flowers, to enable researchers and hobbyists to rapidly identify them in the field. A project called Pl@ntNet, for example, has collected millions of images submitted by users around the world through a mobile-phone app, says botanist Pierre Bonnet of the French Agricultural Research Centre for International Development in Montpellier, France. So far, the project has analysed 580,000 images from 13,000 plant species using machine-learning techniques. Pl@ntNet is better at identifying plants than Chitwood\u2019s atlas, says one of Bonnet's collaborators, computer scientist Alexis Joly of the French Institute for Research in Computer Science and Automation in Montpellier. The team hasn\u2019t yet used Pl@ntNet to study the diversity of leaf shape, he adds. Chitwood hopes to feed the results of his topological methods into machine-learning algorithms as well, to see whether those can improve his taxonomic and geographical predictions. But he is more interested in understanding leaf shape than in classifying plants, he says. There was a time when it seemed as if such efforts to understand plant morphology were dying out, says St\u00e4dler. But the field is experiencing a renaissance thanks in part  to widespread efforts to characterize the traits of plants  \u2014 particularly crops \u2014 and to understand how genetics and the environment influence them. \u201cMorphology is being reborn,\u201d St\u00e4dler says. \u201cThat\u2019s where the field is headed. And I think, especially together with genetic data, we have a very bright future.\u201d \n                     Overlooked water loss in plants could throw off climate models 2017-Jun-28 \n                   \n                     Ancient oak's youthful genome surprises biologists 2017-Jun-19 \n                   \n                     Plant biologists welcome their robot overlords 2017-Jan-25 \n                   \n                     Plant-genome hackers seek better ways to produce customized crops 2016-Nov-02 \n                   \n                     Dan Chitwood's laboratory \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22324", "url": "https://www.nature.com/articles/nature.2017.22324", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Immunization can stop resistant infections before they get started, say scientists from industry and academia. The battle against drug-resistant superbugs has neglected a key weapon, scientists say: using vaccines to quell the spread of resistance. As drug-resistant infections sweep across the globe, public-health organizations have focused mainly on developing new antimicrobial treatments and cutting the overuse of existing ones, to prevent resistant strains emerging. But not enough attention has been paid to vaccines as a defence strategy, say microbiologists and vaccine-developers from academic institutes and drug companies around the world. They attended a meeting at the Wavre, Belgium-based campus of drug firm GSK on 6\u20137 July, to discuss the issue with representatives from funding agencies and regulatory authorities. \u201cVaccines should be part of the general strategy to combat antimicrobial resistance (AMR),\u201d says Rino Rappuoli, chief scientist in GSK\u2019s vaccines division, who organized the gathering.  Some global health funders already seem convinced by the argument: Anita Zaidi, a programme director at the Bill & Melinda Gates Foundation in Seattle, Washington, told the meeting that the charity has just decided to make vaccines its main AMR strategy. It is looking for guidance on priorities, she said. \n             The vaccine advantage \n           Drug firms have invested huge amounts in the hunt for new antibiotics, so far with dismal results, notes Helen Steel, a vice-president for infectious-diseases research at GSK. Steel told the meeting that she had looked at 200 separate programmes from several firms, which all aimed to find new drugs by scouring chemical libraries; not one produced a new antibiotic. While the search for new antibiotics continues, several studies have highlighted that vaccines also have benefits against AMR. By reducing cases of disease, they slow the rise of drug-resistant pathogens, because the microbes have fewer opportunities to multiply and evolve.\u00a0 Researchers cite, for example, the introduction of vaccines against the most prevalent strains of pneumococcus bacteria ( Streptococcus pneumoniae ) in the 2000s \u2014 which studies in the United States have shown cut instances of pneumonia while simultaneously slashing the number of infections resistant to front-line antibiotics such as penicillin 1 . The same benefit was seen in South Africa  when the country introduced a pneumococcal vaccine in 2009 , says James Wassil, vice-president for vaccines at New York City-based drug company Pfizer. Even vaccines against viral diseases, such as influenza, can help to prevent overuse of antibiotics. Many antibiotics are prescribed to treat opportunistic bacterial infections that occur in people weakened by flu \u2014 and a flu vaccine can lessen the chances of these infections occurring. Nicolas Van de Velde, the director of global health economics at GSK, told the meeting about an unpublished 2011\u201314 trial of one of his firm\u2019s influenza vaccines in Europe, in which children who were vaccinated but caught flu anyway had such mild cases that use of antibiotics against other infections was halved. As well as advocating the wider roll-out of existing vaccines against flu and pneumonia, scientists are keen to develop new vaccines against other infections. Vaccines have an advantage over antimicrobials in that they rarely generate resistance, says David Livermore, a microbiologist at the University of East Anglia in Norwich, UK. That\u2019s because antibiotics are administered after an infection has started, when there is already a dense population of microbes from which new resistant strains can evolve. Vaccines, by contrast, prevent infections from arising in the first place.\u00a0 \n             Data drive \n           Still, researchers say, more evidence of vaccines\u2019 action against AMR is needed if authorities are to be persuaded to roll them out more widely for that purpose. At the GSK meeting, drug firms pledged to draw together and publish all their data on the subject, and to generate new data monitoring the circulation of resistant bacterial strains. One way to start may be to check whether existing vaccines have unexpected benefits against resistant infections. A study published in  The Lancet  on 10 July 2  reported that a mass-vaccination campaign in New Zealand in the mid-2000s after a meningitis B outbreak seemed also to protect against gonorrhoea, a  sexually transmitted infection that is increasingly becoming resistant to antibiotics . This may be because the bacteria that cause meningitis and gonorrhoea are related. Vaccines are expensive to develop. But by demonstrating how effective they are at fighting antimicrobial resistance \u2014 as well as protecting against infections \u2014 drug firms hope to encourage governments and health organizations to provide better incentives for new products, for example by guaranteeing a market for them, says David Salisbury, a former chair of the World Health Organization\u2019s strategic advisory group of experts on vaccines. \u201cWe need to make a stronger, more evidence-based case for more vaccines,\u201d he says. \n                   Modified viruses deliver death to antibiotic-resistant bacteria 2017-Jun-21 \n                 \n                   The drug-resistant bacteria that pose the greatest health threats 2017-Feb-28 \n                 \n                   Antibiotic alternatives rev up bacterial arms race 2015-May-27 \n                 \n                   A place in the sun 2007-Mar-07 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22312", "url": "https://www.nature.com/articles/nature.2017.22312", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Revised tallies confirm that the rate of sea-level rise is accelerating as the Earth warms and ice sheets thaw. The numbers didn\u2019t add up. Even as  Earth grew warmer and glaciers and ice sheets thawed , decades of satellite data seemed to show that the rate of sea-level rise was holding steady \u2014 or even declining. Now, after puzzling over this discrepancy for years, scientists have identified its source: a problem with the calibration of a sensor on the first of several satellites launched to measure the height of the sea surface using radar. Adjusting the data to remove that error suggests that sea levels are indeed rising at faster rates each year. \u201cThe rate of sea-level rise is increasing, and that increase is basically what we expected,\u201d says Steven Nerem, a remote-sensing expert at the University of Colorado Boulder who is leading the reanalysis. He presented the as-yet-unpublished analysis on 13 July in New York City at a conference sponsored by the World Climate Research Programme and the International Oceanographic Commission, among others. Nerem's team calculated that the rate of sea-level rise increased from around 1.8 millimetres per year in 1993 to roughly 3.9 millimetres per year today as a result of global warming. In addition to the satellite calibration error, his analysis also takes into account other factors that have influenced sea-level rise in the last several decades, such as the eruption of Mount Pinatubo in the Philippines in 1991 and  the recent El Ni\u00f1o weather pattern . \n               The view from above \n             The results align with three recent studies that have raised questions about the earliest observations of sea-surface height, or altimetry, captured by the TOPEX/Poseidon spacecraft, a joint US\u2013French mission that began collecting data in late 1992. Those measurements continued with the launch of three subsequent satellites. \u201cWhatever the methodology, we all come up with the same conclusions,\u201d says Anny Cazenave, a geophysicist at the Laboratory for Studies in Space Geophysics and Oceanography (LEGOS) in Toulouse, France. In an analysis published in  Geophysical Research Letters 1  in April, Cazenave\u2019s team tallied up the various contributions to sea-level rise, including expansion resulting from warming ocean waters and from ice melt  in places such as Greenland . Their results suggest that the satellite altimetry measurements were too high during the first six years that they were collected; after this point, scientists began using TOPEX/Poseidon's back-up sensor. The error in those early measurements distorted the long-term trend, masking a long-term increase in the rate of sea-level rise. The problem was first identified in 2015 by a group that included John Church, an oceanographer at the University of New South Wales in Sydney, Australia. Church and his colleagues identified a discrepancy between sea-level data collected by satellites and those from tide gauges scattered around the globe 2 . In a second paper published in June in  Nature Climate Change 3 , the researchers adjusted the altimetry records for the apparent bias and then calculated sea-level rise rates using a similar approach to Cazenave\u2019s team. The trends lined up, Church says. \n               Rising tide \n             Still, Nerem wanted to know what had gone wrong with the satellite measurements. His team first compared the satellite data to observations from tide gauges that showed an accelerating rate of sea-level rise. Then the researchers began looking for factors that could explain the difference between the two data sets. The team eventually identified a minor calibration that had been built into TOPEX/Poseidon's altimeter to correct any flaws in its data that might be caused by problems with the instrument, such as ageing electronic components. Nerem and his colleagues were not sure that the calibration was necessary \u2014 and when they removed it, measurements of sea-level rise in the satellite's early years aligned more closely with the tide-gauge data. The adjusted satellite data showed an increasing rate of sea-level rise over time. \u201cAs records get longer, questions come up,\u201d says Gavin Schmidt, a climate scientist who heads NASA\u2019s Goddard Institute for Space Studies in New York City. But the recent spate of studies suggests that scientists have homed in on an answer, he says. \u201cIt\u2019s all coming together.\u201d If sea-level rise continues to accelerate at the current rate, Nerem says, the world\u2019s oceans could rise by about 75 centimetres over the next century. That is in line with projections made by the Intergovernmental Panel on Climate Change in 2013. \u201cAll of this gives us much more confidence that we understand what is happening,\u201d Church says, and the message to policymakers is clear enough. Humanity needs to reduce its output of greenhouse-gas emissions, he says \u2014 and quickly. \u201dThe decisions we make now will have impacts for hundreds, and perhaps thousands, of years.\u201d\u00a0 \n                     How scientists reacted to the US leaving the Paris climate agreement 2017-Jun-02 \n                   \n                     Huge Arctic report ups estimates of sea-level rise 2017-Apr-28 \n                   \n                     Antarctica\u2019s sleeping ice giant could wake soon 2017-Apr-12 \n                   \n                     Giant crack in Antarctic ice shelf spotlights advances in glaciology 2017-Feb-20 \n                   \n                     Climate science: Rising tide 2013-Sep-18 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22346", "url": "https://www.nature.com/articles/nature.2017.22346", "year": 2017, "authors": [{"name": "Ben Upton"}], "parsed_as_year": "2006_or_before", "body": "Randomized controlled trial finds economic benefits of avoided carbon emissions are double the costs. A two-year project that paid a total of US$20,000 to 180 people in 60 Ugandan villages not to cut down trees on their land was worth the money, researchers say. By delaying carbon dioxide emissions, the project\u2019s benefits to society were more than double its costs. The study, published in  Science 1  on 20 July, is an \u201cincredibly rare\u201d example of a rigorous evaluation of efforts to pay people to preserve forests, says Shahid Naeem, an ecologist at Columbia University in New York City. The findings can\u2019t necessarily be extrapolated to conclude that handing out cash payments to prevent trees being cut down is always an economically worthwhile activity, Naeem says: the particular conditions in Uganda might not be relevant in other places. But it\u2019s proof that, at least in one case, the strategy does work. \n             Billions on trees \n           Over the past two decades, individual countries have authorized billions of dollars in cash payments to preserve trees. In 2008, the United Nations launched the REDD+ (Reducing Emissions from Deforestation and Forest Degradation) programme, which permits countries to offset their emissions by paying people in other nations to halt deforestation. But it\u2019s hard to tell whether the payments are worthwhile, usually because projects aren\u2019t well evaluated: Naeem co-authored one review 2  of 118 projects that made payments to protect ecosystems, and found that it was impossible to judge the effectiveness of 60% of them. Projects can fall into traps such as not checking whether ecosystems have actually been protected, or not paying a sufficient sum of money to incentivize people to preserve trees. \u201cThere\u2019s been a lot of projects that expect people to do a lot for the price of a Coca Cola,\u201d says Ina Porras, a market-based-conservation researcher at the International Institute for Environment and Development, based in London. \n             Why Uganda worked \n           By contrast, says Porras, the Uganda study gave meaningful payments to villagers: around $28 per year per hectare of forest they conserved \u2014 equivalent, on average, to the amount they would have earned by cutting down the trees for timber. The study ran from 2011 to 2013; villagers were paid cash at the end of each year if they complied with their contract. In the study \u2014 which was paid for by the Ugandan government from UN funds \u2014 a team led by Seema Jayachandran at Northwestern University in Evanston, Illinois, chose villages at random in Uganda's Hoima and Kibaale districts to be offered payment, and used satellite imaging to track whether trees were cut down. \u201cYou could see every tree with your eye,\u201d she says. \u201cIt\u2019s really useful when the pattern of tree cutting is a few here and a few there.\u201d Tree cover fell by 4.2% in the 60 villages that were paid to preserve their trees \u2014 but by 9.1% in the 61 villages that were not. On that basis, Jayachandran\u2019s team estimate that the project's economic costs ran to around $0.46 per avoided tonne of carbon dioxide. That makes it more than worthwhile, they say: using estimates by the US Environmental Protection Agency (EPA) to determine the damage caused by carbon dioxide emissions \u2014 a figure also known as the  \u2018social cost\u2019 of carbon  \u2014 they say that the benefit of delaying the emissions of a tonne of carbon dioxide by two years runs to $1.11, more than double the project's costs. Even if the villagers were to immediately cut down the trees that they\u2019d been paid to preserve once the project was over, the payments would still have been worthwhile, Jayachandran says \u2014 a promising sign for other projects. \u201cI hope our study makes people more optimistic that it will work and that they can measure it,\u201d she says. \n                   Tree cheers 2015-Apr-01 \n                 \n                   Stopping deforestation: Battle for the Amazon 2015-Apr-01 \n                 \n                   Carbon sequestration: Managing forests in uncertain times 2014-Feb-12 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22338", "url": "https://www.nature.com/articles/nature.2017.22338", "year": 2017, "authors": [{"name": "Philip Ball"}], "parsed_as_year": "2006_or_before", "body": "Phenomenon thought to occur only in exotic, high-energy physics environments seen in quantum material. An exotic effect in particle physics that\u2019s theorized to occur in immense gravitational fields \u2014 near a black hole, or in conditions just after the Big Bang \u2014 has been seen in a lump of material in a laboratory, physicists report. A team led by physicist Johannes Gooth at IBM Research near Zurich, Switzerland, say they have seen evidence for a long-predicted effect called the axial\u2013gravitational anomaly 1 . It states that huge gravitational fields \u2014 which  general relativity  describes as the result of enormous masses curving space-time \u2014 should destroy the symmetry of particular kinds of particles that usually come in mirror-image pairs, creating more of one particle and less of another. The kinds of conditions needed to prove this unusual breakdown of a fundamental \u2018conservation law\u2019 can\u2019t be created in a laboratory. But the researchers exploited a peculiar parallel between gravity and temperature to create a lab analogue of the anomaly in niobium phosphide crystals. \u201cThis anomaly is so hard to measure that even indirect evidence is a major breakthrough,\u201d says team member Adolfo Grushin of the University of California, Berkeley. Inside the crystal, the effect is as if a drawerful of pairs of gloves were suddenly to acquire an excess of right-handed gloves because some of the left-handed ones had switched handedness. The result, published in\u00a0 Nature 2 ,\u00a0bolsters an emerging view that quantum materials \u2014 crystals whose properties are dominated by quantum-mechanical effects \u2013 can act as experimental test-beds for physics effects that could only otherwise be seen under exotic circumstances. \n             Quasiparticles and quantum materials \n           The particles affected by the anomaly are known as  Weyl fermions, which were proposed in the 1920s by mathematician Hermann Weyl . These particles differ from other kinds of fermions (such as the electron) because they seem to have no mass, and because they also have a kind of handedness, or chirality. Weyl fermions have never been seen as individual physical entities \u2014 although it\u2019s thought they might be fleetingly involved in the decays of other kinds of particles. But they have been spotted as \u2018quasiparticles\u2019 inside some crystals. In these materials, quantum-mechanical effects cause a material\u2019s electrons to move together in such a way that their collective behaviour resembles that of Weyl fermions. The chiral Weyl fermions are generally produced in equal numbers, like mirror-image pairs. In 2015, researchers showed that strong magnetic and electric fields could break this symmetry inside a quantum material known as a Dirac semimetal 3  \u2014 vindicating a long-predicted effect in high-energy physics called the axial (or chiral) anomaly. Now, Gooth\u2019s team has confirmed that gravity \u2014 or space-time curvature \u2014 can also destroy the symmetry. To do so, they relied on a connection between gravitational and temperature effects, which states that the effect of space-time curvature on Weyl fermions is mathematically equivalent to the effect of a gradient in temperature 4 , 5 . In other words, the anomaly should also appear if one part of a material in which Weyl fermions appear is hotter than another. The reason \u201cis rooted in Einstein\u2019s famous equation  E  =  mc 2 \u201d, explains Gooth. \u201cIn relativistic quantum field theory, energy and mass flows become the same,\u201d he says. \u201cMass flow is driven by gravitational-field gradients, and energy flow by temperature gradients. The temperature gradient for the relativistic Weyl fermions thus mimics a gravitational-field gradient.\u201d The researchers measured the conductivity of their crystalline niobium phosphide \u2014 which is known as a Weyl semimetal \u2014 in a microelectronic circuit. When they applied a thermal gradient and a magnetic field, they saw an induced electric current created by an imbalance in the two types of Weyl fermion: the number of left-handed quasiparticles moving in one direction through the sample was not the same as the number of right-handed ones moving in the opposite direction. Furthermore, \u201cthe behaviour of the current as we change the magnetic field is exactly what the theory of the axial\u2013gravitational anomaly predicts\u201d, says Grushin. \n             Compelling evidence \n           Not everyone is persuaded that the researchers have observed what they claim. Boris Spivak, a physicist at the University of Washington in Seattle, insists that the axial\u2013gravitational anomaly simply doesn't exist in Weyl semimetals. A temperature gradient, he says, can\u2019t induce electrons to convert between the two quasiparticles of different handedness. \u201cThere are many other mechanisms which can explain their data,\u201d Spivak says. He thinks the researchers are just measuring the impact of a magnetic field on the well-known thermoelectric effect, in which electrical currents are produced by temperature gradients. But Gooth and his colleagues disagree. They say that the existence of the temperature-induced chiral anomaly is strongly supported by theory. And Subir Sachdev, a specialist on quantum effects in solid-state materials at Harvard University in Cambridge, Massachusetts, says the researchers have \u201ccompelling evidence for the physical consequences of the axial\u2013gravitational anomaly\u201d. The existence of the anomaly was not really in doubt, Sachdev adds, but \u201cit is nice to see it appear in real materials\u201d. He says it confirms that gravity interacts with quantum fields in the manner indicated by Einstein\u2019s theories of relativity. Grushin suspects that understanding how this anomaly manifests in these materials should lead to new physics. And IBM also hopes that the finding might be exploited in electronics, because it generates an electrical current inside the niobium phosphide crystal. Devices that expoit the anomaly might improve the efficiency of materials that can generate electrical energy from temperature gradients, Gooth says. \n                   The strange topology that is reshaping physics 2017-Jul-19 \n                 \n                   Inside Microsoft\u2019s quest for a topological quantum computer 2016-Oct-21 \n                 \n                   The rise of quantum materials 2016-Feb-02 \n                 \n                   A solid case for Majorana fermions 2012-Mar-06 \n                 \n                   Topological insulators: Star material 2010-Jul-14 \n                 \n                   Nature Materials : Weyl semimetals and other topological materials \n                 \n                   Johannes Gooth \n                 \n                   Adolfo Grushin \n                 \n                   Subir Sachdev \n                 \n                   Boris Spivak \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22365", "url": "https://www.nature.com/articles/nature.2017.22365", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Scientists added two genes to the plant's genome to get the new hue. Roses are red, but science could someday turn them blue. That\u2019s one of the possible future applications of a technique researchers have used to genetically engineer blue chrysanthemums for the first time. Chyrsanthemums come in an array of colours, including pink, yellow and red. But all it took to engineer the truly blue hue \u2014 and not a violet or bluish colour \u2014 was tinkering with two genes, scientists report in a study published on 26 July in  Science Advances 1 . The team says that the approach could be applied to other commercially important flowers, including carnations and lilies. \u201cConsumers love novelty,\u201d says Nick Albert, a plant biologist at the New Zealand Institute for Plant & Food Research in Palmerston North, New Zealand. And \u201cpeople actively seek out plants with blue flowers to fill their gardens\u201d. Plenty of flowers are bluish, but it\u2019s rare to find true blue in nature, says Naonobu Noda, a plant researcher at the National Agriculture and Food Research Organization near Tsukuba, Japan, and lead study author. Scientists, including Noda, have tried to artificially produce blue blooms for years:  efforts that have often produced violet or bluish hues  in flowers such as roses and carnations. Part of the problem is that naturally blue blossoming plants aren\u2019t closely related enough to commercially important flowers for traditional methods \u2014 including selective breeding \u2014 to work. Most truly blue blossoms overexpress genes that trigger the production of pigments called delphinidin-based anthocyanins. The trick to getting blue flowers in species that aren\u2019t naturally that colour is inserting the right combination of genes into their genomes. Noda came close in a 2013 study 2  when he and his colleagues found that adding a gene from a naturally blue Canterbury bells flower ( Campanula medium ) into the DNA of chrysanthemums (Chrysanthemum morifolium) produced a violet-hued bloom. \n             Getting the blues \n           Noda says he and his team expected that they would need to manipulate many more genes to get the blue chrysanthemum they produced in their latest study. But to their surprise, adding only one more borrowed gene from the naturally blue butterfly pea plant ( Clitoria ternatea ) was enough. Anthocyanins can turn petals red, violet or blue, depending on the pigment\u2019s structure. Noda and his colleagues found that genes from the Canterbury bells and butterfly pea altered the molecular structure of the anthocyanin in the chrysanthemum. When the modified pigments interacted with compounds called flavone glucosides, the resulting chrysanthemum flowers were blue. The team tested the wavelengths given off by their blossoms in several ways to ensure that the flowers were truly blue. The quest for blue blooms wouldn't only be applicable to the commercial flower market. Studying how these pigments work could also lead to the sustainable manufacture of artificial pigments, says Silvia Vignolini, a physicist at the University of Cambridge, UK, who has studied the  molecular structure of the intensely blue marble berry . Regardless, producing truly blue flowers \u201cis a great achievement and demonstrates that the underlying chemistry required to achieve 'blue' is complex and remains to be fully understood\u201d, says Albert. \n                   Biohackers gear up for genome editing 2015-Aug-26 \n                 \n                   Alien plants may come in all colours but blue 2007-Apr-11 \n                 \n                   Blue as a rose 2000-Oct-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22369", "url": "https://www.nature.com/articles/nature.2017.22369", "year": 2017, "authors": [{"name": "Nicky Phillips"}], "parsed_as_year": "2006_or_before", "body": "Conservationists accuse government of ignoring science-based recommendations. When Australia established a vast network of marine reserves in 2012, it was hailed as a major win for conservation. But management plans for the sea havens were suspended a year later. Now, scientists are angry at the Australian government's release last week of a draft proposal to significantly erode the size of protected areas in the reserves, opening up large stretches to commercial and recreational fishing.\u00a0 \u201cAustralia has been one of the leaders in marine conservation,\u201d says Callum Roberts, a biologist who studies marine reserves at the University of York, UK. \u201cThe government is dressing it up as progress, but this is a giant leap backwards for conservation.\u201d Roberts says that dismantling protected areas will make species less able to cope with increasing threats such as climate change and plastic pollution. \u201cAustralia will find its seas considerably less resilient than they would have been if they hadn\u2019t rolled back this protection,\u201d he says. Almost 2.4 million square kilometres, about 36% of Australia\u2019s oceans, were designated marine parks in 2012. Close to one-third of the area in the reserves was given the highest level of protection, which bans activities such as fishing, mining and drilling for oil or gas. Although  scientists found some shortcomings in the reserve network  \u2014 many of the highly protected areas were in deep water, for instance, whereas the most vulnerable ecosystems are usually closer to shore \u2014 it was largely considered an ambitious plan for protecting biodiversity. Little more than a year after the system was established, the country\u2019s newly elected conservative prime minister, Tony Abbott, suspended the park\u2019s management plans and ordered an independent review. Scientists accused the government of bowing to pressure from the fishing and mining industries. The independent review, released in September 2016, recommended that protected sections in some parks should be increased, but it reduced protected areas in others. \u201cThe independent review already eroded the overall protections from 2012, but the new draft plans have seriously gutted it,\u201d says Jessica Meeuwig, a marine scientist at the University of Western Australia in Perth. \n             Contradictions \n           The latest proposals, released on 21 July, leave park boundaries unchanged, but will reduce the total area protected from fishing to 20% down from 33% in the review\u2019s recommendations. In the largest marine park in the Coral Sea off Australia\u2019s northeast coast, the proposal reduces the fully protected areas from 41% to 24% of the park. This would allow various types of commercial fishing in most of the park, including the use of long lines to catch tuna. A 2010 independent assessment of fishing in marine parks along the east coast had concluded that this practice posed an \u201cunacceptable risk\u201d to seabirds, whales, sharks and turtles. In a 21 July statement, the government\u2019s environment minister, Josh Frydenberg, said that the proposals represent a \u201cmuch more balanced, scientific approach than those previously undertaken for marine parks. These plans protect what needs to be protected, without negatively impacting communities and our country\u2019s economy.\u201d But Meeuwig says that the government is ignoring recommendations from its own review, and that research contradicts the government\u2019s claim that the plans are based on science. \u201cIt\u2019s saying partially protected areas can achieve conservation outcomes. We know that\u2019s not true.\u201d One study, for example, published in 2014 1 , showed that fully protected areas, often called no-take zones, were essential for adequate conservation of marine ecosystems. The expert scientific panel convened by the government\u2019s review also acknowledged \u201cthe significant body of scientific literature that demonstrates the effectiveness of \u2026 no take zones \u2026 in achieving conservation outcomes\u201d. But Sally Barnes, director of the National Parks agency, which wrote the draft plans, told  Nature  that they achieve the right balance between conservation and use. The plans are open for public comment until September. \n                   World\u2019s largest marine reserve hailed as diplomatic breakthrough 2016-Oct-28 \n                 \n                   Marine reserves planned around commercial interests 2014-Feb-28 \n                 \n                   Australia\u2019s plans for sea havens \u2018flawed\u2019 2013-Mar-12 \n                 Reprints and Permissions"},
{"file_id": "547390a", "url": "https://www.nature.com/articles/547390a", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Business-focused funding agency Innovate UK is driving British efforts to commercialize research. UK scientists fearful for their research funds ahead of Brexit were cheered last November when the government announced it would plough an extra \u00a34.7\u00a0billion (US$6.1\u00a0billion) into research and development (R&D) by 2020\u201321. But the biggest winner from the largely industry-focused cash may be a government innovation agency that is rapidly gaining clout. Innovate UK began operating ten years ago this month as an independent body called the Technology Strategy Board \u2014 a prosaic title that reflected its origins as a small government advisory panel of industrialists and civil servants. Since then, the organization has rebranded and has seen its budget quadruple to around \u00a3800\u00a0million a year (see \u2018Innovation boom\u2019), mainly doled out as grants to consortia of research organizations and businesses, which must match the money with private funds. That budget is soon expected to grow further, says Ruth McKernan, the agency\u2019s chief executive. The government\u2019s R&D windfall includes an Industrial Strategy Challenge Fund (ISCF) to help researchers working on key technologies that might benefit the UK economy. That fund has already been promised \u00a31\u00a0billion, including \u00a3246\u00a0million to help develop batteries; on 24\u00a0July, the government announced that this would include a \u00a345-million competition to establish a new centre for battery research.  It was a team at Innovate UK that first suggested the challenge concept after studying the workings of the US Defense Advanced Research Projects Agency (DARPA), McKernan says. And her agency has been allotted joint responsibility for running the ISCF alongside the research councils, the main funders of UK university science. Ties between the two groups are growing because of a shift in the United Kingdom\u2019s funding landscape: from April 2018, both Innovate UK and the research councils will become part of a central organization called UK Research and Innovation (UKRI). The ISCF\u2019s set-up marks a departure from normal operations for Innovate UK and the research councils, says McKernan. \u201cThis is setting a challenge that together we can try to solve.\u201d The government is relying on the R&D boost, and on the ISCF in particular, to reassure researchers who are wary of Brexit\u2019s detrimental impacts on science, says Kieron Flanagan, a science-policy researcher at the Alliance Manchester Business School. \u201cI think the fund is going to be too big for academics to ignore.\u201d \n               Technology catapults \n             Innovate UK is more focused on businesses than on universities. The largest beneficiary of its funding is car-maker Rolls-Royce, which has received almost \u00a3300\u00a0million since 2007; the agency\u2019s most-quoted success story is its early funding of SwiftKey, a firm making predictive text apps that was bought by Microsoft for a reported $250\u00a0million in 2016. The organization says that it is increasingly focusing on funding small- and medium-sized enterprises. Only 20% of its cash ends up at universities, although some are adept at winning funds: the University of Sheffield, which has strengths in engineering and manufacturing research, has received \u00a3150\u00a0million, for instance. Outside Britain, the name Innovate UK is familiar to scientists and business people, but few know what it does, says Dan Breznitz, a researcher in innovation policy at the University of Toronto, Canada. One of the agency\u2019s major outputs is more widely appreciated, Breznitz says \u2014 its Catapult centres. This network of physical centres, which are loosely based on the Fraunhofer Institute\u2019s centres in Germany, provides equipment and resources to bridge the gap between university research and commercial technologies. The largest, with \u00a3150\u00a0million in Innovate UK funding, is the Cell and Gene Therapy Catapult in London. It has \u201cgalvanized\u201d UK researchers in the field, says Stuart Forbes, who works on regenerative medicine at the University of Edinburgh. He relied on its advice to help get a potential cell therapy for liver cirrhosis into phase II trials. A first formal evaluation of the success of the Catapult centres \u2014 most of which are now five years old \u2014 will be published in September. A major focus in the future, says McKernan, will be helping businesses from one sector benefit from research expertise in another; for example, by bringing the benefit from large data sets, satellite technology, machine learning and artificial intelligence into sectors such as health and agriculture. As Innovate UK\u2019s influence grows, it is in danger of losing focus on its core mission, says Breznitz. The agency has so far struggled to find its identity, restructuring several times in its short existence, he says. If it now tries to act both like DARPA, with calls to solve key challenges, and like the US Small Business Innovation Research programme, which hands out grants to small research firms, it will struggle, he says. The agency may also sharpen UK science\u2019s focus on economic returns. It uses economy-based metrics, such as jobs generated and return on investment, to analyse its success, McKernan says. She thinks that under UKRI, research councils might learn from this approach. \u201cI would anticipate a much stronger analytics group across UKRI that understands how to get the return on investment from early, translational and applied research \u2014 and how we change some levers to get a stronger output,\u201d she says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     UK political parties promise science funding boost 2017-May-19 \n                   \n                     The most powerful man in UK science on his new role 2017-Feb-08 \n                   \n                     UK scientists excited by surprise \u00a32-billion government windfall 2016-Nov-23 \n                   \n                     Innovate UK \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22307", "url": "https://www.nature.com/articles/nature.2017.22307", "year": 2017, "authors": [{"name": "Lauren Morello"}], "parsed_as_year": "2006_or_before", "body": "Legislation introduced in the House of Representatives also rejects a White House plan to cut 'indirect cost' payments to research institutions. The US National Institutes of Health (NIH) would see its budget rise by US$1.1 billion in 2018, to $35.2 billion, under a spending proposal released on 12 July by lawmakers in the House of Representatives. The legislation explicitly rejects  a plan by the administration of President Donald Trump to cut the NIH\u2019s budget by 18% in 2018 . The president\u2019s proposal would achieve that largely by reducing how much the agency pays to reimburse its grant recipients\u2019 institutions for \u201cindirect costs\u201d \u2014 expenses such as administration and facilities maintenance. Instead, the House bill includes a provision that directs the NIH to compensate institutions for those expenses, although the materials released today do not include full details of the requirements. The House spending subcommittee that oversees the NIH is scheduled to vote on the legislation on 13 July. The NIH spent $6.3 billion of its $30.4-billion budget for 2015 on indirect-cost payments. It has long negotiated with individual research institutions to set the rate at which they are reimbursed for overhead costs. These payments are not deducted from the amount awarded to specific researchers, but are paid separately as a percentage of the grant amount. A  Nature  investigation in 2014  found that indirect-cost rates vary from 20% to 85% at universities, with an even wider range for hospitals and non-profit institutions. The White House plan had sought to set a uniform rate for these payments, arguing that the change would help to reduce \u201cthe risk for fraud and abuse\u201d. The House bill\u2019s overall funding for the NIH and its treatment of indirect costs is encouraging, especially in contrast to the Trump proposal, says Benjamin Corb, director of public affairs at the American Society for Biochemistry and Molecular Biology in Rockville, Maryland. \u201cWe are appreciative that the committee recognizes the important role universities play in the research enterprise,\u201d he says. The House legislation also includes increased funding for several high-profile projects in which the NIH is involved. The agency\u2019s All of Us research programme, an ambitious study of health records and genomic information from one million people in the United States, would receive $400 million, an $80-million boost from the 2017 level. The BRAIN Initiative (Brain Research through Advancing Innovative Neurotechnologies) would receive $336 million, an increase of $76 million. The agency\u2019s research programmes on Alzheimer\u2019s disease would get an extra $400 million above the 2017 level, raising their total funding to $1.8 billion. Funding for the Cancer Moonshot, which seeks to accelerate progress towards cures, would hold steady at $300 million. \n                     Trump says Francis Collins will stay on at the NIH 2017-Jun-06 \n                   \n                     Trump budget would slash science programmes across government 2017-May-23 \n                   \n                     Indirect costs: Keeping the lights on 2014-Nov-19 \n                   \n                     2018 House spending bill for the NIH and related agencies \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22360", "url": "https://www.nature.com/articles/nature.2017.22360", "year": 2017, "authors": [{"name": "Barbara Casassus"}], "parsed_as_year": "2006_or_before", "body": "Chief's departure after management complaints might not solve National Research Agency's woes. French researchers say they\u2019re pleased that the president and chief executive of the country\u2019s National Research Agency (ANR) has stepped down, but worry that the organisation's woes might not be resolved by his exit. Michael Matlosz resigned on 21 July, after more than a year of widely reported discontent with how the funding body was being managed. Despite an uptick in its budget this year, the ANR's funding is still less than it was in 2012, and success rates for grant applications are worryingly low. Matlosz, a former chemical engineer who was promoted to his post in 2014, left because the agency needed \u201ca new impetus\u201d following recent organizational changes, according to an 18 July statement by Fr\u00e9d\u00e9rique Vidal, who became France\u2019s minister for higher education, research and innovation in May. Matlosz and the ANR declined to comment further. Arnaud Torres, an ANR director, is serving as an interim chief until a new head is found. \n             Year of discontent \n           Many scientists say that Matlosz\u2019s management created serious tensions within the ANR, including administrative choices that upset senior scientists and those who served on grant-evaluation panels. The agency has had a number of public upsets. In March 2016, sociologist Fran\u00e7ois H\u00e9ran was fired as head of its social-sciences department. In June the same year, all 20 members of an evaluation panel in mathematics and computer science resigned together, complaining that bureaucracy had reduced their freedom to select proposals. Last month, molecular biologist Catherine Dargemont, director of the agency\u2019s biology and health division, was fired after she sent a letter to the ANR's governing board, co-signed by ten colleagues, complaining about \u201crecurrent dysfunctions\u201d at the ANR, including the gradual sidelining of senior scientists in important decisions. And on 26 June, Bernard Hoflack, a proteomics researcher at the Technical University of Dresden, Germany, who is president of the ANR\u2019s evaluation panel in cellular and developmental biology, wrote to the agency\u2019s management on behalf of 9 out of 13 panel heads, criticizing poor internal communication, among other things. Bernard Meunier, a chemist and past president of the French Academy of Sciences, says that ANR bureaucracy is still too burdensome. \u201cPrincipal investigators spend a huge amount of time on applications, filling in endless forms, finding partners and trying to justify the nine new \u2018societal challenges\u2019, which politicians believe will help create jobs and wealth,\u201d he says. He thinks that 70\u00a0measures introduced by previous research minister Thierry Mandon to simplify researchers\u2019 lives have had almost no impact because administrative bodies resisted them. The ANR also has broader problems. In France\u2019s latest budget, for 2017, the agency\u2019s spending was boosted 8% to \u20ac643 million (US$748 million) \u2014 still lower than the \u20ac710 million it was allotted five years ago. This means that competition to win project funds is fierce, with average success rates running at a paltry 12\u201313%. On 11 July, Vidal told a French senate committee that the ANR budget would have to be increased. But last week, the government proposed a cut of \u20ac180 million to the research ministry\u2019s budget, out of a total \u20ac331-million reduction in funding for higher education and research amidst wider cuts of more than \u20ac3 billion in public spending. That does not augur well for increases at individual agencies; the ministry said it had not yet decided how much the ANR might lose in funds. \n                   Climate scientists flock to France\u2019s call 2017-Jul-18 \n                 \n                   Scientists relieved by Emmanuel Macron\u2019s French election victory 2017-May-08 \n                 \n                   Science spending boosted in French budget 2016-Sep-28 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22361", "url": "https://www.nature.com/articles/nature.2017.22361", "year": 2017, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Crowding antennas closer together may affect the Square Kilometre Array's ability to observe the early Universe. Designs for the world\u2019s largest radio telescope have been scaled back to save money \u2014 a decision that astronomers say could affect its ability to peer deep into the Universe\u2019s past.\u00a0 The Square Kilometre Array (SKA), a telescope 50 times more sensitive than current instruments, is expected to cost billions of dollars. Its final design calls for around 2,000 radio dishes in Africa, together with up to one million antennas in Australia, that will have a total light-collecting area of roughly 1 square kilometre \u2014 hence the project's name. But the first phase of construction, called SKA1, is a more modest affair. Already slimmed down from a larger design proposed in 2013, it now comprises 194 dishes in South Africa and around 130,000 antennas in Australia. In March, the SKA's board said that the project would have to find further cuts of around 20% so that it could be built within a \u20ac674 million (US$785 million) cap imposed by the project\u2019s ten funders \u2014 Australia, Canada, China, India, Italy, New Zealand, South Africa, Sweden, the Netherlands and the United Kingdom. And at a meeting in the Netherlands on 18\u201319 July the board decided to make the savings by, among other measures, scaling back SKA1\u2019s computing power and crowding its antennas and radio dishes closer together. It\u2019s the latter idea that concerns astronomers the most. Packing the telescope\u2019s individual components into a smaller space will mean a loss of resolution, making SKA1 less able to pick up on fine details. In most cases this change won\u2019t seriously affect the array\u2019s scientific projects, says Tony Beasley, an astronomer and head of the US National Radio Astronomy Observatory in Charlottesville, Virginia. But Heino Falcke, an astronomer at Radboud University in Nijmegen, the Netherlands, says that it may have an impact on the project's ability to detect faint signals emanating from a few hundred million years after the Big Bang, when the Universe\u2019s first stars and galaxies formed and began to emit light.  These low-frequency radio waves are to be picked up by the Australian antennas. And under the new cuts, clusters of these antennas \u2014 known as low-frequency stations \u2014 will now be placed a maximum of 40 kilometres apart, rather than 65. With inferior resolution, the telescope could struggle to pick up low-frequency radio waves over the noise of the Milky Way, says Falcke. \n               The cost of change \n             Astronomers were consulted about the changes at a meeting in Manchester, UK, in June. But since then, they have grown more concerned about the idea of crowding the Australian stations closer together. So the board's decision may not be final: SKA working groups are still running simulations to work out the impact of the change, says Philip Diamond, the director-general of the SKA Organisation at the Jodrell Bank Observatory near Manchester. Once construction starts on the antennas, it would be difficult and expensive to change the distances between them, says Roy Maartens, an astronomer at the University of the Western Cape in Bellville, South Africa. But if the SKA board can find some additional funding in the next two years, the design change could be rolled back. Moving the antenna clusters a more comfortable 50 kilometres apart, for instance, would only add another \u20ac14 million to the budget, Diamond says. \u201cThis is at the top of our list of things to restore once more funding becomes available.\u201d  Astronomers are less worried about the decrease in computing power, from 260 petaflops to 50 petaflops, says Falcke. Although this means it will take longer to process data, the limiting factor for translating SKA1\u2019s observations into images will be ironing out initial problems with software and algorithms. By the time they\u2019re sorted, the project will be looking to upgrade to a new generation of computers anyway, he says. The cuts are a \"sensible compromise\", given the funds available, says Huib Jan van Langevelde, an astronomer who heads Europe's Joint Institute for Very Long Baseline Interferometry in Dwingeloo, the Netherlands. \u201cThe bottom line is the SKA1 will still be doing transformational science,\u201d says Maartens. Diamond says he hopes that more countries can be persuaded to join the SKA project and inject extra funding, or that existing members will bring more money to the table. But some astronomers are not convinced that will happen. \"In this environment, where they are continuously back-pedalling, are major partners going to come forward?\u201d says one astronomer who asked not to be named. After delays caused by choosing what to cut in SKA1\u2019s design, construction is set to begin in mid-2019. But the SKA still lacks an intergovernmental organization to run it. Diamond says that a treaty to create such an organization should be ready this year, and all member countries will need to ratify it before construction starts. No funding has yet been agreed for development of SKA beyond its first phase, but a construction push has been tentatively earmarked for the mid-2020s. \n                     Ghana telescope heralds first pan-African array 2017-May-09 \n                   \n                     Giant SKA telescope rattles South African community 2016-Jun-22 \n                   \n                     An array of problems 2015-Mar-10 \n                   \n                     Germany pulls back from international mega-telesope project \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22249", "url": "https://www.nature.com/articles/nature.2017.22249", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Treatments tailored to a person's individual cancer mutations train immune system to attack tumours. Vaccines tailored to match a person\u2019s particular constellation of cancer mutations seem to have fended off tumours in a handful of patients, two small clinical trials show. The vaccines are described in papers published in  Nature  on 5 July 1 , 2 . The studies are the first to report that the approach \u2014 which is gaining support in academia and industry \u2014 could combat cancer in humans. They also provide hints about ways to boost the vaccines' power by combining them with treatments that target the immune system, called immunotherapies. \u201cIt\u2019s potentially a game changer,\u201d says Cornelis Melief, a cancer immunologist at Leiden University Medical Centre in the Netherlands, and author of a  commentary accompanying the papers . \u201cThe two papers really strongly indicate that the patients experienced clinical benefit.\u201d In principle, the vaccines are similar to those used against infectious diseases: unique components of a foreign invader \u2014 cancer cells, in this case \u2014 are mixed with agents that stimulate an immune response. The mixture is injected into the patient, in the hope of triggering an immune attack strong enough to vanquish the invader. But for personalized cancer vaccines, the components are  tailored to each patient  and are administered after the cancer has already appeared \u2014 rather than aiming to prevent occurrence. \n             Looking for a response \n           In the studies, researchers began by sequencing the genes that encode proteins in each patient\u2019s tumour. They selected mutant proteins that were  most likely to generate an immune response  and used these as the basis for their vaccines. One group, led by Catherine Wu at the Dana-Farber Cancer Institute in Boston, Massachusetts, treated six people with melanoma, a type of skin cancer. For each person, they formulated a vaccine that contained up to 20 protein fragments corresponding to the mutations in their tumours 1 . The participants, who received surgery to remove their tumours, had been deemed at high risk for cancer recurrence. But they were not due to receive further treatment unless their cancer came back. Recurrence typically occurs in about half of all such melanoma patients, says Wu.  Two years later, four of those patients had not seen their tumours return. And although tumours did grow in the remaining two participants, both experienced a complete remission when subsequently treated with a drug that rouses the immune system  by blocking a protein called PD-1 .\u00a0 The second group, led by Ugur Sahin, a physician who studies tumour immunology and cancer genomics at the University of Mainz in Germany, treated 13 melanoma patients with vaccines that contained RNA encoding up to 10 mutated proteins in each patient 2 . The eight patients who had no visible tumours at the time of vaccination remained tumour-free more than a year later. The remaining five participants' tumours had spread by the time they received the vaccine. Tumours shrank in two of them, but later resurged in one patient. A third experienced a complete remission after subsequent treatment with a PD-1 inhibitor. \n             Challenges ahead \n           Personalized cancer vaccines had already been shown to provoke immune responses in humans 3 . But the new trials are the first to evaluate whether these immune responses can successfully battle tumours. The numbers are small and the trials lacked a control group, but the results are encouraging, says Robert Schreiber, a cancer immunologist at Washington University in St Louis, Missouri. Larger trials in academia and industry are ongoing, he notes, and researchers are particularly interested in  combining the vaccines with PD-1 inhibitors . \u201cI\u2019m convinced that personalized vaccines are a way to go,\u201d he says. The field  still faces challenges . It took both teams about three months to formulate and manufacture their vaccines \u2014 too long to delay treatment for many cancers. But both groups say they could accelerate the process as they scale it up. Wu estimates that she could get the lag down to six weeks. It is also unclear how many types of cancer will respond to the approach. Cancer vaccines may work best if they target several different cancer mutations, to lessen the chance of a tumour becoming resistant to the vaccine by shedding any one particular mutation. The genomes of melanoma cells tend to carry many mutations, giving researchers a host of options when designing the vaccines. But some cancers will present fewer avenues for attack. \u201cWe have to think about how we can launch a multipronged attack,\u201d says Wu. \u201cHow many prongs do you need? We don\u2019t know.\u201d With a wave of clinical trials in the pipeline, researchers will gradually work out which cancers are suited to the approach, and how best to combine the vaccines with other treatments, says Sahin. \u201cWe are entering the next phase of rational cancer immunotherapy,\u201d he says. Read the accompanying News & Views article:  'Precision T-cell therapy targets tumours' \n                   Algorithms compete to predict recipe for cancer vaccine 2016-Dec-13 \n                 \n                   Researchers push for personalized tumour vaccines 2016-Apr-22 \n                 \n                   Cocktails for cancer with a measure of immunotherapy 2016-Apr-13 \n                 \n                   Immune system offers clues to cancer treatment 2014-Nov-26 \n                 \n                   Nature Outlook: Cancer Immunotherapy \n                 \n                   US National Cancer Institute: Cancer vaccines \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22250", "url": "https://www.nature.com/articles/nature.2017.22250", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}, {"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Bilateral partnership may provide new blueprint for EU east-west collaboration. Germany and Poland are to jointly fund top scientists to start research groups at Polish institutes, in a scheme that could provide a new blueprint for east\u2013west research collaboration in the European Union. On 4 July, the two nations announced the Dioscuri programme\u00a0\u2014\u00a0named after the ancient Greek word for the mythological twin brothers Castor and Pollux \u2014\u00a0which will provide ten scientists with up to \u20ac3 million (US$3.4 million) each over the next decade, to establish their own centres of excellence in Poland. The programme aims to boost research excellence in the EU\u2019s less-developed science regions, and is overseen by Germany\u2019s prestigious Max Planck Society (MPS). If successful, it will be extended to nearby EU countries, says society president Martin Stratmann. The society already has connections with the EU\u2019s largest Eastern European country: it operates two research groups with sites in Poland, but they are entirely Polish-funded. By contrast, the new centres will get half of their funding from Germany. Poland\u2019s National Science Centre, a government research-funding agency in Krakow, will manage the centres, and the MPS will oversee an international committee to select the winning scientists. Calls for applications will go out in November. The programme is modelled on the MPS\u2019s \u2018Minerva\u2019 scheme, which has supported research in Israel along similar lines for more than 50 years, albeit with different historical roots. Minerva was designed to build bridges between the two countries after the Second World War. \n             A new way to team up? \n           The EU has already spent hundreds of millions of euros on  \u2018twinning\u2019 and \u2018teaming\u2019 initiatives that fund centres of excellence at labs in poorer regions , formed in partnership with elite institutions in richer countries. But critics say these programmes are heavily bureaucratic, are influenced by political and geographical factors as well as research excellence, and focus on centres of technological innovation rather than on individual scientists. \u201cWhy should a research programme focus on business and innovation when what we really need is a culture of excellence?\u201d says molecular biologist Maciej \u017bylicz, president of the Foundation for Polish Science, a large research-funding agency in Warsaw. Poland does participate in the EU programmes, but has not done particularly well. This year, for example, institutions in the country won just 3 out of 30 EU \u2018teaming\u2019 grants \u2014\u00a0whereas those in the Czech Republic received 6, and those in tiny Cyprus scored 9. (The European Parliament raised queries about Cyprus\u2019s surprising performance, but research commissioner Carlos Moedas responded in June that the competition was impartial and fair, and put the discrepancy down to a relatively low number of applications overall.) Stratmann says that the EU teaming initiatives encourage \u201cwise spending\u201d of the bloc\u2019s funds on science, although they are not based on excellence alone. \u201cBut the EU money has to fall on fertile ground,\u201d he says\u00a0\u2014\u00a0and the Dioscuri initiative could help on that score. Such lean and less-bureaucratic efforts that focus on individual researchers have the best chance of closing the EU\u2019s east\u2013west gap in science, says Tomasz Dietl, a semiconductor physicist at the Polish Academy of Sciences\u2019 Institute of Physics in Warsaw. \u201cThis is the right way to go to improve the quality of research here,\u201d he says. \u201cPoland is a land of opportunity now, with an excellent national granting system,\u201d says Marcin Nowotny, a group leader at the Inter\u00adnational Institute of Molecular and Cell Biology in Warsaw and one of a few scientists in Poland who have received grants from the European Research Council. \u201cBut it needs more entry points \u2014 and a Max Planck-stamped programme will help exactly this.\u201d Additional reporting by Inga Vesper. \n                   Poland: Into the light 2017-Feb-22 \n                 \n                   After the Berlin Wall: Central Europe up close 2014-Nov-05 \n                 \n                   Europe waters down transnational 'research buddy' plan 2013-Dec-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22269", "url": "https://www.nature.com/articles/nature.2017.22269", "year": 2017, "authors": [{"name": "Barbara Casassus"}], "parsed_as_year": "2006_or_before", "body": "Pulmonologist Michel Aubier has been found guilty of misleading France\u2019s Senate during an inquiry on air pollution. In an unprecedented court case in Paris, an eminent French lung specialist has been fined \u20ac50,000 (US$57,000) and given a six-month suspended prison sentence because he did not disclose his ties to the oil industry during a Senate air-pollution inquiry. The case is the first time that the French Senate has pressed criminal charges over false testimony. \u201cIt is an extremely important decision,\u201d the Senate\u2019s lawyer, Emmanuel Marsigny, told reporters. \u201cIt underlines the importance of the Senate\u2019s commissions of inquiry and the risk of false declarations.\u201d French researchers say that it also serves as a sharp reminder of the importance of disclosing all possible conflicts of interest when presenting evidence. Michel Aubier had testified to a Senate commission about the financial and economic costs of air pollution in April 2015. At the time, he was head of pneumonology and allergology at the Bichat-Claude Bernard Hospital in Paris \u2014 although he has since retired from that position \u2014 and was speaking on behalf of the public authority that runs Paris public hospitals (AP-HP). \n             Financial ties \n           Aubier\u00a0told the Senate commission that he had no ties with economic actors. But French newspapers later  revealed  that for 20 years, Aubier had been paid by the French oil company Total as an occupational physician looking after executive staff, and for managing a team of physicians at the company. (According to the court ruling, he earned around \u20ac100,000 a year for that work from 2012\u201315.) He is also an unpaid board member of Total\u2019s philanthropic foundation. During the judicial inquiry, it emerged that Aubier had erred in other ways as well, by failing to seek clearance from his employers for five  ad hoc  work contracts that he had signed with pharmaceutical companies and declared in a health-ministry database. Aubier told a court hearing in June that he never intended to mislead the Senate commission. \u201cI made a mistake,\u201d he said. \u201cIf I were to do it again, I would declare, but [the omission] was absolutely not intentional.\u201d But on 5 July, a Parisian judge found him guilty of false testimony. The \u20ac50,000 fine represents two and a half months of Aubier\u2019s total annual earnings and pension income, the judgement says. Aubier\u2019s lawyer, Fran\u00e7ois Saint-Pierre,says that no decision has been reached on whether to appeal the verdict. \n             Air-pollution debate  \n           The case illustrates that researchers and physicians who are encouraged to work closely with industry need to understand what constitutes a conflict of interest, and to be aware of the need for transparency regarding outside links, says Herv\u00e9 Chneiweiss, a neuroscientist who is chairman of the ethics committee of the French biomedical-research agency INSERM. Aubier has long been accused of downplaying the impact of small particles in urban pollution on disease. During the 2015 inquiry, Aubier told the Senate that respiratory, bronchial and cardiovascular diseases, on which the AP-HP spends millions of euros each year, were most frequently linked to air pollution. But he said that the impact of pollution on lung cancer \u201cis extremely low and a subject of much debate\u201d. In fact, the World Health Organization\u2019s cancer-research agency, the IARC, has said since 2012 that diesel particles are carcinogenic; in 2013, it declared that outdoor air pollution in general was also carcinogenic. In March 2016, six physicians pointed to the IARC decision in protest against comments Aubier made to a television interviewer that month. \u201cI do not think, and most experts agree, that being exposed to ambient pollution in cities such as Paris predisposes to lung cancer, unless there is another factor such as smoking,\u201d he said. Still, Aubier stuck to his line during the court case, telling the judicial inquiry that scientific studies showed that air pollution\u2019s effects on cancer were \u201cmodest and low\u201d. \u201cI have never minimized the impact of air pollution,\u201d he added. Alongside the criminal conviction, Aubier lost a civil lawsuit pressed by the Senate on the same charge. His employers AP-HP also launched a civil lawsuit against Aubier for tarnishing their image: they won, but Aubier was given only a symbolic \u20ac1 fine. Two French non-governmental ecology organizations, G\u00e9n\u00e9rations Futures and Ecologie sans Fronti\u00e8re, also launched civil lawsuits: Fran\u00e7ois Lafforgue, a lawyer for the NGOs, argued that\u00a0Aubier\u2019s \u201cfalse statement shows a clear conflict of interest and could have a negative impact on the evolution of French regulations on air pollution\u201d. But in her 5 July ruling, judge Evelyne Sire-Marin noted that Aubier's comments did not directly infringe on laws on environmental protection, and so ruled the NGOs\u2019 suit inadmissible. \n                   Set up a public registry of competing interests 2016-May-03 \n                 \n                   Atmospheric chemistry: China\u2019s choking cocktail 2015-Oct-21 \n                 \n                   Earth science wrestles with conflict-of-interest policies 2015-Jun-24 \n                 \n                   Air pollution: Clean up our skies 2014-Nov-19 \n                 Reprints and Permissions"},
{"file_id": "547017a", "url": "https://www.nature.com/articles/547017a", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Influential report suggests simpler, more citizen-friendly system for post-2020 EU research funding. Midway through the European Union\u2019s sprawling 7-year, \u20ac75-billion (US$85-billion) research-funding programme known as Horizon 2020 (H2020), scientists are already angling for more money and less red tape in its successor.  So researchers are delighted with an  influential 3 July report  that urges the EU to double the budget of its next funding scheme, called Framework Programme Nine (FP9), which is due to launch in 2021. The report says that FP9\u2019s structure should be largely similar to that of H2020, but with less bureaucracy, and suggests that it includes a few major \u2018moonshot\u2019 missions in areas such as energy and information technology.  \u201cScientists are generally happy with the report because it mostly confirms our thinking,\u201d says Stephan Kuster, the acting director of Science Europe, a Brussels-based organization that represents member-state research agencies. But it lacks details on some of its aims, he says: in particular, how to persuade politicians to approve such a large budget hike.  The report comes from a group of academic and industry experts invited by the European Commission to formulate a vision for future research plans, headed by a former director-general of the World Trade Organization, Pascal Lamy. Commission insiders say its ideas will strongly influence the shape of FP9 \u2014 set to be the first major EU funding programme to take place after the United Kingdom leaves the union in 2019. Uncertainty over Brexit negotiations means that the commission isn\u2019t close to determining its total post-2020 budget, and it will not propose what FP9 might look like until the end of this year. That has not stopped advocates asking for more cash: in June, a research committee for the European Parliament proposed a \u20ac120-billion budget for FP9, assuming that, like H2020, it will run for 7 years.  In an  interview with the European Commission  alongside his report, Lamy calls that \u201ca bare minimum\u201d. His team\u2019s report says that whatever the result of Brexit negotiations, \u201cfull and continued engagement\u201d with the United Kingdom in FP9 would be \u201can obvious win-win for the UK and the EU\u201d. The programme should also be opened up more widely to non-EU countries, the report says. \n               Falling success rates \n             European scientists have a love\u2013hate relationship with the EU\u2019s massive research programmes. Researchers appreciate the funding and the support of collaborative projects, but deplore the bureaucracy and the way each new programme changes the rules. An  interim evaluation  of H2020, published in May, suggests it has been more popular than its predecessors, in part because of cuts to red tape.  Still, the evaluation noted that H2020 is heavily oversubscribed, with barely 1 in 9 applications funded\u00a0\u2014\u00a0well down on its predecessor programme, which funded nearly 1 in 5. FP9 should return to earlier levels, the Lamy report says.  Success rates are even lower, below 1 in 10, at the prestigious European Research Council (ERC), which as part of H2020 was given a \u20ac13.1-billion budget to fund basic research for 2014\u201320. The ERC is supposed to reward excellence, but in some of its grant programmes, half of the projects deemed \u201cexcellent\u201d by reviewers have gone unfunded. \u201cWe would need to double our budget to make sense of our mission,\u201d says ERC president Jean-Pierre Bourguignon. The Lamy report recommends keeping H2020\u2019s broad divisions into grants for excellent science, for industrial-innovation projects, and for multinational collaborations that meet societal grand challenges. It suggests that rules of participation be made simpler \u2014 with documentation and reporting obligations kept to a minimum, and audits restricted to cases where fraud is suspected. And it proposes that FP9 adopt broader measures of the \u2018impact\u2019 of work \u2014 going beyond scientific impact to capture effects on policymaking and industrial competitiveness, for instance.  The EU has an \u2018innovation gap\u2019 compared with its trading partners, the report says, noting that the region trails South Korea on business-research spending, and has one-fifth of the number of fast-growing start-up firms that the United States does. The report also argues that FP9 should do more to involve Europe\u2019s citizens, including involving them in choosing \u2018moonshot\u2019 missions in areas of societal importance, such as climate change, that set targets to be achieved within precise time frames. (As an example, it suggests producing carbon-free steel by 2030.)  In general, scientists should get better at communicating their work using stories that citizens can understand, the report says: \u201cCommunicating on science should become part of researchers\u2019 career and their reward system.\u201d  \n                 Tweet \n                 Follow @NatureNews \n               \n                     Europe can build on scientific intuition 2017-Mar-21 \n                   \n                     Europe should hold fast to its scientific ambitions 2016-Dec-21 \n                   \n                     Boon or burden: what has the EU ever done for science? 2016-Jun-15 \n                   \n                     Nature  Special: Brexit and science \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22242", "url": "https://www.nature.com/articles/nature.2017.22242", "year": 2017, "authors": [{"name": "Nicola Nosengo"}], "parsed_as_year": "2006_or_before", "body": "Statistical study of how names are geographically distributed suggests fewer professors are hiring relatives after 2010 clampdown. A 2010 law aimed at cracking down on nepotism in Italy\u2019s academic system seems to be working, according to an analysis of academic scientists' surnames. In 2011, ecologist and statistician Stefano Allesina at the University of Chicago in Illinois looked at the diversity of last names in Italian academia and said that his analysis 1  supported widespread  anecdotal evidence that nepotism was a problem  in the country\u2019s science system. But some Italian researchers criticized the work and questioned the methods. They thought that it overestimated nepotism, and suggested that the study underestimated how much regional naming trends might account for any unusual clustering of last names. It also ignored other possible explanations, critics suggested: for example, some children of professors might legitimately deserve an academic position. Now, Allesina, along with his University of Chicago colleague Jacopo Grilli, has redone his analysis with more sophisticated statistical methods. Their results suggest that there has been a decline in nepotism in Italy since the introduction of the 2010 law, which banned even indirect relatives \u2014 such as cousins \u2014 of professors from being hired in the same department. The work is published 2  in  Proceedings of the National Academy of Sciences USA . Allesina and Grilli assembled a list of the names, ranks, genders and scientific fields of all permanent professors at Italian public universities in 2000, 2005, 2010 and 2015 \u2014 around 60,000 researchers in each year. To find out what Italy\u2019s scientific system would look like if professors were chosen at random, they shuffled the names around in three different ways: at the national level, within cities, and within each field. By comparing these pictures with the real situations, the pair could detect statistical anomalies in the genuine distribution: for example, where particular surnames might occur too often to be explained by chance or geography alone. \n             Friends in high places \n           According to Allesina and Grilli, the likely cause for such anomalies is nepotism: professors hiring their relatives. This seems to happen in particular in medicine and chemistry, and in the southern regions of Puglia, Sicilia and Campania, they found. But when the researchers compared the data from 2015 with the earlier years, they found that things were worse in the past. In 2010 and before, statistical evidence of nepotism was stronger, and showed up in more fields, including engineering, law and economics. That was not a surprise, says Grilli, because of the 2010 law. \u201cThe fact that the effects of the law show up in the data proves that our method works,\u201d says Grilli. \u201cIt means that we are indeed measuring nepotism, and that it is declining but still there.\u201d Giuseppe De Nicolao, who studies data analysis at the University of Pavia in Italy, says that the pair\u2019s revised methods suggest that they have taken into account that the problem is more complex than it seemed. But he remains sceptical. \u201cStatistical significance is one thing; practical significance is another one,\u201d he says. The absolute figures show that only a small proportion of appointments are suspect, he says, so nepotism has a small effect. De Nicolao adds that the kind of \u201cbiological nepotism\u201d that Allesina and Grilli measured is less important than \u201cacademic nepotism\u201d, where professors favour their own students and friends. \u201cBut that is not a uniquely Italian problem, and can\u2019t be as easily detected,\u201d he says. Allesina and De Nicolao agree that the 2010 law isn\u2019t a complete solution. Professors could still have a friend hire their relatives in another department or university, says Allesina. The law might even have negative side effects: it can make it impossible for researchers who marry each other to keep working in the same department. \u201cWe are already losing many brilliant researchers because of this,\u201d De Nicolao says. \u201cIt is the opposite of what happens in other countries, where universities lure brilliant researchers by also offering a position to their partner.\u201d Allesina, Grilli and De Nicolao all agree that the most striking finding in the paper has nothing to do with nepotism: it\u2019s the fact that the number of publicly funded research professors in Italy has shrunk by 10% since 2005, from 60,000 to 54,000 today. Some universities have lost one-third of their staff, mainly as a result of budget cuts. If there are too many cuts, there will be no more nepotism, but no professors either, says Allesina. That \u201cwould not be a great solution\u201d. \n                   Italy rebuked for failure to prevent olive-tree tragedy 2017-Jun-07 \n                 \n                   Researchers frustrated by Italian misconduct probe 2017-May-02 \n                 \n                   Italian scientists won\u2019t miss departing Prime Minister Matteo Renzi 2016-Dec-09 \n                 \n                   Italian scientists shocked by earthquake devastation 2016-Aug-30 \n                 \n                   Italy chooses new brooms to clean up science institutes 2011-Aug-23 \n                 Reprints and Permissions"},
{"file_id": "547016a", "url": "https://www.nature.com/articles/547016a", "year": 2017, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Researchers braced for shortages as Gulf state forced to close its refineries. Scientists fear they may be forced to halt experiments or shut down laboratory instruments because the ongoing blockade of Qatar is threatening their helium supplies. The Gulf state supplies hospitals and laboratories around the world, but had to close its two helium plants after Saudi Arabia and several neighbouring countries blocked most of its exports and imports in June, in a political dispute over Qatar\u2019s alleged support for terrorism. \u201cThis is a situation that is changing day-by-day, so you can imagine we are watching it carefully,\u201d says Sophia Hayes, a chemist who specializes in nuclear magnetic resonance (NMR) spectroscopy at Washington University in St. Louis, Missouri. \u201cI\u2019m extremely concerned.\u201d Her research depends on a continuous supply of liquid helium, which has a uniquely low boiling point of 4\u00a0kelvin, to cool the superconducting magnets in her lab\u2019s spectrometers. It\u2019s also used in the lab\u2019s low-temperature research. Another scientist, who requested anonymity, says that their lab is reserving available helium stocks for NMR instruments. A junior colleague who uses large quantities of helium has agreed to cut back his work to help out with supplies, if needed. \u201cThis can negatively impact his career; all of us who are senior colleagues would do anything we can to avoid that situation,\u201d says the scientist. Qatar is the world\u2019s largest exporter of helium and its second-largest producer, accounting for 25% of global demand (see \u2018Helium supplies\u2019). So the blockade will inevitably cause shortfalls over the next few months, says Phil Kornbluth, a consultant based in Bridgewater, New Jersey, who specializes in the helium industry. Countries likely to be most affected are those closest to Qatar. But Asian countries such as India, China, Japan, Taiwan and Singapore are also at risk. \u201cBut none of us are immune,\u201d adds William Halperin, a researcher in low-temperature physics at Northwestern University in Evanston, Illinois. \n               Low priority \n             Labs account for only around 6% of the helium market; most helium is used in the electronics industry, hospital magnetic resonance imaging scanners, and airships and balloons. This means that suppliers tend to prioritize deliveries to larger customers \u2014 not scientists \u2014 when supplies are limited. Many researchers had hoped that supply disruptions were a thing of the past, because the installation of substantial new plant in Qatar had expanded and helped to secure the global helium supply. But Hayes says that she warned the community against complacency, given the political volatility in the Middle East. Scientists have already been banding together to protect themselves against disruption in helium supplies and the rising price of the gas. The American Physical Society (APS) and the American Chemical Society jointly launched a programme in 2016 to help researchers negotiate lower prices and secure more timely helium deliveries through joint bulk purchases. The programme gives preference to researchers who are paying the highest prices or have unreliable deliveries. Mark Elsesser, an analyst at the APS who oversees the programme, says that research groups at 12 universities have already seen an average price reduction of 15% and improved deliveries. The programme will be expanded later this year to include more research groups. Some labs have invested in equipment to capture, reliquefy and store helium gas that evaporates from equipment and would otherwise be lost to the atmosphere. The ISIS pulsed neutron and muon source at the Rutherford Appleton Laboratory near Harwell, UK, installed such a system after a shortage in 2012 forced it to shut down its neutron beams for several days. \u201cCurrently, we have in storage enough helium to run operations for half a year,\u201d says Oleg Kirichek, head of support at ISIS. \u201cWe are relatively safe for a while.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Helium should be recycled 2017-Jul-04 \n                   \n                     Helium high 2014-Feb-19 \n                   \n                     Resources: Stop squandering helium 2012-May-30 \n                   \n                     APS-ACS Liquid Helium Purchasing Program \n                   \n                     Liquid-helium report \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22259", "url": "https://www.nature.com/articles/nature.2017.22259", "year": 2017, "authors": [{"name": "Laura  Castells"}], "parsed_as_year": "2006_or_before", "body": "Organisms use red fluorescent protein to optimize light for photosynthesis. Researchers have pinpointed the reason that deep-water corals emit an eerie glow: to help their algae do photosynthesis. Scientists know that in shallow waters, the organisms light up green, using fluorescent proteins as a kind of sun block. The proteins soak up harmful ultraviolet rays, re-emit green light and shield their symbiotic algae, which supply most of the corals\u2019 energy needs through photosynthesis. In 2015, a team led by J\u00f6rg Wiedenmann at the University of Southampton, UK, found that  deep-dwelling corals also fluoresce  \u2014 this time in an array of vivid yellows, oranges and reds. Some of these organisms live in water as deep as 165 metres, where little sunlight reaches them, and most of what does is in the blue part of the spectrum. So the researchers suspected a different reason for the glow. Now, Wiedenmann thinks his team has the answer: the corals use a fluorescent protein to make the most of the small amount of light available in their habitats for photosynthesis. In other words, the deep-water corals and their shallow relatives fluoresce for opposite reasons. Blue light is more useful for photosynthesis, but red light penetrates farther into coral tissues. So corals use a red fluorescent protein to convert the blue light into orange\u2013red wavelengths. That means it reaches more of the organisms\u2019 symbiotic algae, helping the corals to survive by making as much food as possible through photosynthesis. The researchers\u2019 work is published in  Proceedings of the Royal Society B 1 . \u201cCorals need special features to adjust to life in these low-light depths for the benefit of their vital photosynthetic partners,\u201d says Wiedenmann. The finding \u201cshows how sophisticated the symbiosis between corals and their algal partners can be\u201d. As researchers worry about the fate of the world\u2019s corals after a  spate of bleaching events  caused by rising water temperatures, some marine scientists have suggested that stressed shallow-water corals could adapt and find refuge in deeper waters. However, says Wiedenmann, the study shows that the protein pigments expressed by shallow corals are \u201cbiochemically and optically distinct\u201d from those of their deep-dwelling counterparts. \u201cNot many of them may have the capacity to escape to deeper waters,\u201d he says. \u201cWe need to make sure that reefs in shallow water stay habitable for corals.\u201d \n                   First fluorescent frog found 2017-Mar-13 \n                 \n                   Mass coral death drives efforts to identify resilient reefs 2016-Jun-15 \n                 \n                   Corals worldwide hit by bleaching 2015-Oct-08 \n                 \n                   Radiant reefs found deep in the Red Sea 2015-Jun-24 \n                 \n                   Corals use multiple tricks to adapt to hotter seas 2014-Apr-24 \n                 \n                   Marine biology: Lights in the deep 2007-Nov-21 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22227", "url": "https://www.nature.com/articles/nature.2017.22227", "year": 2017, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Experts say effective response to the outbreak in the Democratic Republic of the Congo helped prevent the virus from spreading. Epidemiologist Anne Rimoin boarded a flight to Kinshasa on 19 May with a precious cargo in her luggage: the components of a diagnostic test for Ebola. Rimoin hoped that the test, the GeneXpert Ebola Assay, would help officials to track cases in the latest Ebola outbreak, which was declared in the Democratic Republic of the Congo (DRC) on 11 May. The test was developed during  the disastrous 2014 Ebola epidemic in West Africa . The existence of the Ebola assay is a sign that the world\u2019s ability to respond to outbreaks of the virus has improved. But the test was not available where it was needed when Ebola erupted in the DRC, says Rimoin, of the University of California, Los Angeles, who has worked with the Congolese Ministry of Health for 15 years. \u201cThe fact that I had to go out there with diagnostics in my briefcase is an example of the fact that we\u2019re not fully prepared on that score,\u201d she says. On 2 July, the Congolese government and the World Health Organization (WHO) declared an end to the DRC outbreak \u2014 but public-health officials caution that its low death toll doesn\u2019t prove that the world has learnt all the lessons of the West African crisis. They credit the fact that only four people died to the expertise of Congolese officials, who had dealt with seven previous Ebola outbreaks, and to the remoteness of the northern Bas Uele province where the outbreak occurred. \u201cThe response was good, but it would not be valid to say that this shows that we\u2019re ready for a larger response in a bigger context \u2014 that remains to be seen,\u201d says Daniel Bausch, director of the UK Public Health Rapid Support Team, an agency created to fill some of the gaps exposed by the 2014 crisis. International agencies sent personnel and equipment in response to the most recent outbreak much faster than they did in 2014,  when months of delays allowed the West African epidemic to spiral out of control  and eventually claim more than 11,000 lives. That failure led to calls for drastic improvements in the world\u2019s public-health safety net, some of which have been heeded. The WHO, which was widely criticized for responding too slowly to the 2014 outbreak, has created a Health Emergencies Programme in response. The WHO deployed 50 people to the DRC starting three days after the most recent outbreak was declared. But other parts of the response came too slowly. Although  an experimental Ebola vaccine was shown to be effective  against the disease in the 2014 outbreak,  its use in the DRC wasn\u2019t approved until 29 May . The vaccine was ultimately never shipped to the country because no new cases emerged after that date. \n               Slow progress \n             The latest outbreak apparently began in April, when a 39-year-old man began vomiting and bleeding after handling the carcass of a dead wild boar in a forest in Likati. The man died while en route to a hospital; within days, two people who had helped to transport him fell ill themselves, as did their contacts. Health workers shipped blood samples from contacts of these three people to a lab at the National Institute for Biomedical Research in Kinshasa, which found two cases positive for Ebola; a total of five people ultimately tested positive. Samples were also shipped to the International Centre for Medical Research in Franceville, Gabon, which analysed the viral genetic sequences of one of the samples. The lab found that the Ebola strain that caused the Congolese outbreak is similar to one first seen in 1995 in Kikwit, DRC, a few thousand kilometres southwest of Likati, says Jean-Jacques\u00a0Muyembe-Tamfum, director of the National Institute for Biomedical Research. By contrast, when the 2014 Ebola outbreak began with a suspected case in Guinea, there were no labs in the country that could test for the virus. So public-health officials had to ship viral samples out of Africa for sequencing. But the most crucial difference between the two outbreaks may have been the level of community engagement with efforts to halt Ebola\u2019s spread. Muyembe-Tamfum was on the team that investigated the 1995 Kikwit outbreak, as well as on the team that worked on the very first Ebola outbreak in Yambuku, DRC, in 1976. The people of his country are no strangers to Ebola \u2014 whereas in West Africa, communities hid from and even killed officials seeking to track the disease in Sierra Leone, Guinea and Liberia. \u201cWe are lucky because our population will collaborate with medical teams,\u201d Muyembe-Tamfum says. \u201cIn the West African epidemic, community engagement came too late.\u201d \n                     Ebola vaccine approved for use in ongoing outbreak 2017-May-30 \n                   \n                     Ebola vaccine could get first real-world test in emerging outbreak 2017-May-12 \n                   \n                     World Health Organization rethinks its response to disease outbreaks 2016-Dec-20 \n                   \n                     Unusual deal ensures Ebola vaccine supply 2016-Jan-20 \n                   \n                     Nature  special: Ebola epidemic \n                   \n                     World Health Organization, AFRO region: Ebola virus disease situation reports \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22270", "url": "https://www.nature.com/articles/nature.2017.22270", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Non-profit group helps marshal trial of a new antibiotic in an attempt to beat back resistant infections. Gonorrhoea is becoming as incurable as it was in the 1920s, before the first drugs to treat it were discovered. More than 60% of countries surveyed around the world have reported cases that resist last-resort antibiotics, according to an  announcement by the World Health Organization  (WHO) on 6 July. The announcement included information about a new gonorrhoea drug in development. Since the 1930s, several classes of antibiotics have been used to kill the bacterium that causes gonorrhoea,  Neisseria gonorrhoeae . Widespread use \u2014 and misuse \u2014 of these drugs, however, has  led to a rise of antibiotic-resistant strains of the bacteria . \u201cThe best time to have had gonorrhoea was the eighties, since there were many drugs to treat it with,\u201d says Ramanan Laxminarayan, director of the Center for Disease Dynamics, Economics and Policy in Washington DC. Increasingly, that's no longer the case, he says. Health agencies in the United States, Europe and Canada have in recent years flagged drug-resistant gonorrhoea as an emerging threat. If left untreated, gonorrhoea can increase a woman\u2019s risk of developing HIV infection, infertility or ectopic pregnancy \u2014 among other effects. When the WHO partnered with the Drugs for Neglected Diseases initiative (DNDi), a non-governmental organization in Geneva, Switzerland, in May 2016 to  confront antimicrobial resistance , gonorrhoea was at the top of the list. According to a paper to be published in  PLoS Medicine 1 on 7 July, there is robust resistance to three common types of antibiotics prescribed for gonorrhoea. Of the countries surveyed around the world, 97% reported cases that were resistant to ciprofloxacin, the cheapest and most widely available treatment; 81% reported gonorrhoea cases resistant to azithromycin; and 66% to cephalosporins. \n             Treading carefully \n           In a  quest for new treatments , DNDi \u201clooked for drugs that had stalled in the pipeline because of a lack of commercial viability\u201d, says Manica Balasegaram, head of the antimicrobial partnership. Policymakers are realizing that antibiotics ought to be used sparingly, and that\u2019s not great for a drugmaker\u2019s bottom line, he says. The group had previously noted how slowly zoliflodacin \u2014 the first drug in a new class of antibiotics \u2014 was progressing through the approval pipeline. Entasis Therapeutics, a biotech company in Waltham, Massachusetts, that owns the drug, depended on public funding from the US National Institutes of Health to conduct a phase II trial of zoliflodacin in 2015. Although trial results showed that most patients treated with the drug were cured of gonorrhoea, Balasegaram says that a lack of investment stopped the drug from progressing further. Now, the DNDi and Entasis have announced that they will launch a phase III trial of zoliflodacin involving about 650 individuals in South Africa, the United States and Thailand, among other countries. The team expects to start in November 2018. If the drug is approved by regulators, Entasis will permit generic manufacturers to sell the drug in most low- and middle-income nations. Entasis will retain exclusivity to the treatment in high-income countries. And the DNDi says that it will fund public-health studies to find the best means of ensuring that the drugs are not overused. However, studies alone do not satisfy Laxminarayan. He would like the groups to roll out the new antibiotic alongside a test to make sure that people get the treatment only if they have gonorrhoea that\u2019s resistant to existing alternatives. DNDi says they've been looking for a simple diagnostic tool like this, but haven't yet found one. \u201cYes, we need a new drug,\u201d Laxminarayan says, \u201cbut without a rapid diagnostic test, this drug will meet the same fate as the others.\u201d \n                   Modified viruses deliver death to antibiotic-resistant bacteria 2017-Jun-21 \n                 \n                   Resistance to last-ditch antibiotic has spread farther than anticipated 2017-Jun-12 \n                 \n                   The drug-resistant bacteria that pose the greatest health threats 2017-Feb-28 \n                 \n                   Busting the billion-dollar myth: how to slash the cost of drug development 2016-Aug-24 \n                 \n                   Antibiotic alternatives rev up bacterial arms race 2015-May-27 \n                 \n                   WHO warns against 'post-antibiotic' era 2014-Apr-30 \n                 \n                   WHO: Steering plans for neglected diseases 2014-Mar-26 \n                 \n                   Common STD grows resistant to treatment in North America 2013-Jan-09 \n                 \n                   Global Antibiotic Research and Development Partnership \n                 \n                   Information on gonorrhea \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22165", "url": "https://www.nature.com/articles/nature.2017.22165", "year": 2017, "authors": [{"name": "Edwin Cartlidge"}], "parsed_as_year": "2006_or_before", "body": "Italian scientists eager to go it alone on experiment to tackle \u2018waste heat\u2019 problem. Fusion energy holds the tantalising promise of limitless, clean electricity for humanity \u2014 but colossal engineering problems must be solved first. Among them: how to deal with the scorchingly hot exhaust from a fusion power plant\u2019s plasma fuel. But scientists don\u2019t agree on the best way to study the issue. Italian researchers want to test novel exhaust systems in a new \u20ac500-million (US$570-million) nuclear fusion reactor that they hope to start operating around 2025. Yet last monthEUROfusion, a European consortium of fusion-research organizations, opted to postpone for half a decade a decision on whether to contribute funds for the experiment. That leaves Italy, for now, having to go it alone. \u201cAll the risks are on the Italian side,\u201d says Tony Donn\u00e9, EUROfusion\u2019s programme manager.\u00a0 \n             Fusion's waste-heat problem \n           Inside a doughnut-shaped tokamak \u2014 the leading model for a practical fusion reactor \u2014 a plasma of hydrogen isotopes is compressed and heated to hundreds of millions of degrees so that the nuclei fuse, generating energy. Magnetic fields hold the plasma in place, but some hot particles inevitably leak and drift towards the tokamak\u2019s wall, dumping huge amounts of energy and eroding its surface. So the fields are shaped to channel leaks to a metal divertor, which dissipates heat by transferring it to a coolant. ITER, the giant \u20ac20-billion fusion reactor under construction in southern France to demonstrate fusion technology, will have a divertor made of stainless steel coated with tungsten. But ITER would generate energy only in bursts of a few minutes. By contrast, the planned DEMO reactor, which would be built after ITER to show that fusion can supply electricity to the grid, would need to operate more or less continuously. It\u2019s not clear whether conventional divertors could deal with the greater heat load. Enter the  Divertor Tokamak Test facility (DTT) : a fusion reactor that would have a plasma volume only 4% that of ITER's but that would have space to test different ways to divert waste heat 1 . For example, it could test differently-shaped magnetic fields and divertors to spread the particle load over a larger surface, or could try out materials that might be less susceptible to damage, such as liquid lithium. Physicist Flavio Crisanti of ENEA, Italy\u2019s energy and technology agency, which is leading the DTT\u2019s design, says the project is an important stepping stone to DEMO. EUROfusion agrees, but thinks that funding the expensive new facility would be premature. At its general assembly meeting in April, the organization approved funding for five other projects on plasma exhaust, most involving upgrades of existing facilities to study specific divertor designs. That decision followed an expert review that recommended delaying EUROfusion support for the DTT until some of the smaller facilities yield results, which should make clear which design is most promising. It might even be possible to use a conventional divertor in DEMO if it is protected by a layer of gas, such as neon, that could help to dissipate energy by colliding with the hot plasma waste. \n             A machine that tries to do it all \n           Other researchers also have reservations about the DTT. Brian LaBombard, a physicist at the Massachusetts Institute of Technology in Cambridge, says that the DTT\u2019s scale \u201cspeaks to the severity\u201d of the plasma-exhaust problem, but is scientifically unnecessary. \u201cIt is a machine that tries to do it all,\u201d he says. He and his colleagues have proposed an as-yet-unfunded Advanced Divertor Experiment. At an estimated US$70 million, it would be far cheaper than the DTT because, unlike the Italian design, it would not use superconducting cables to create its magnetic fields and would have a smaller plasma core, but it would still have space to test alternative divertors. At a workshop in June in Frascati, Italy \u2014 the home of ENEA\u2019s fusion laboratory \u2014 EUROfusion agreed \u201cin principle\u201d to commit \u20ac60\u00a0million to the DTT in five or six years\u2019 time, irrespective of the other experiments\u2019 results. However, it will provide the money only if ENEA shows that the DTT can be flexible enough to accommodate a range of possible divertors; the agency must also make good progress on construction over the next few years. EUROfusion will still need to approve that commitment at its general assembly in October. Crisanti says ENEA hopes to secure a \u20ac250-million loan for the facility, possibly from the European Investment Bank, as well as some \u20ac120\u00a0million from Italy\u2019s central government and further money from regional governments and China. He aims to get Italian government approval by the end of 2017. Italy has a political reason to urgently support the project, Crisanti adds: it is keen to maintain the status of Italian manufacturers of superconducting cables, control systems and robotics. \u201cIf we wait for a few years, companies in other countries might overtake them,\u201d he says. \n                   US advised to stick with troubled fusion reactor ITER 2016-May-26 \n                 \n                   ITER's new chief will shake up troubled fusion reactor 2014-Nov-21 \n                 \n                   South Korea makes billion-dollar bet on fusion power 2013-Jan-21 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22198", "url": "https://www.nature.com/articles/nature.2017.22198", "year": 2017, "authors": [{"name": "Inga Vesper"}], "parsed_as_year": "2006_or_before", "body": "Conservationists fear trend of selling wild-caught birds will hurt populations. The number of owls traded illegally on Indonesian markets has risen sharply in the past two decades \u2014 and researchers think the popularity of the Harry Potter books and films may be fuelling the trend. Anecdotal evidence from countries including India have previously suggested that demand for pet owls spiked with the popularity of Harry Potter, but a study of Indonesia\u2019s bird markets \u2014 which are known for selling a variety of wild-caught birds as pets \u2014 puts numbers on the trend. Wildlife researchers surveyed 20 bird markets on the islands of Bali and Java and say that the number of owls being sold has risen dramatically: from perhaps a few hundred a year before 2001 to 13,000 by 2016. Owls also now make up a greater proportion of the birds on offer in the markets, researchers say. Before 2001 they accounted for less than 0.1% of birds being sold; last year, the share had risen to around 1.5% on some markets. The work is  published in  Global Ecology and Conservation 1 . \n               Accio owl \n             Study co-author Vincent Nijman, a wildlife-trade researcher at Oxford Brookes University, UK, says he is pretty sure there is a link between the rising owl sales and the popularity of the Harry Potter books and films, in which the titular character keeps a pet owl named Hedwig. The first novel was translated into Indonesian in 2000, and the first film adaptation was released in 2001. Although it\u2019s difficult to prove a direct causation between the fictional phenomenon and rising owl sales, says Nijman, \u201cHarry Potter normalized keeping owls as pets.\u201d Owls are called  Burung Hantu  in Malay, one of Indonesia's main languages, but are now colloquially known as  Burung Harry Potter , meaning 'Harry Potter' birds, he says. Nijman adds that there are online forums where fans clamouring for pet owls share tips on where to obtain the birds. The increase in Internet access in Indonesia \u2014 one-fifth of the population is now online compared with just 2% in 2001 \u2014 made it easier for people to source the birds and is also likely to have contributed to the rise in sales, he says. Richard Thomas from the UK-based network Traffic, which monitors wildlife trade, says that the issue is complex and it\u2019s \u201cnot possible to say unequivocally\u201d that the cause is Harry Potter. However, a  2015 report  from Traffic on Indonesia\u2019s bird markets also noted the jump in owl sales, and suggested that the rise in demand could be down to the popularity of the fictional character. In 2010, the network also found that the  illegal owl trade was growing in India , where the animals are sought mainly for their purportedly magical properties. \n               Conservation issue \n             Nijman says that owls can usually be bought for US$6\u201330 in Indonesia's bird markets \u2014 easily affordable for most people with a job. The most popular variety are scops owls, and endangered species in same genus ( Otus )  are still being discovered  on the country\u2019s many islands 2 . That makes the owl trading a conservation issue, the researchers warn, because nearly all the birds for sale are caught in the wild. Indonesian law forbids the trade of wildlife for which there is no official catch quota \u2014 and there isn\u2019t one for owls. But according to the researchers, state authorities have not taken any action. The Indonesian government did not respond to repeated requests for comment by  Nature . The country doesn\u2019t monitor its owl population, so researchers must rely on guesswork to estimate the impact of sales on wild numbers. \u201cOwls are nocturnal, so it may be less apparent over a short period if there is a massive decline,\u201d says Thomas. The researchers propose that owls should be added to Indonesia\u2019s protected species list to raise awareness among buyers that they are not suitable pets. Nijman compares the owls to cut flowers: beautiful to buy but doomed to die quickly. \u201cThey are alive and cute when you see them on the market,\u201d he says, \u201cbut realistically they are already dead.\u201d Reprints and Permissions"},
{"file_id": "nature.2017.22235", "url": "https://www.nature.com/articles/nature.2017.22235", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Brenda Fitzgerald will be the next director of the Centers for Disease Control and Prevention. Obstetrician and gynaecologist Brenda Fitzgerald will direct the US Centers for Disease Control and Prevention (CDC), Secretary of Health and Human Services Tom Price announced on 7 July. \u201c She has a deep appreciation and understanding of medicine, public health, policy and leadership \u2014 all qualities that will prove vital as she leads the CDC in its work to protect America\u2019s health 24/7,\u201d Price said in a statement. Fitzgerald has led the Georgia Department of Public Health since 2011, and has championed early-intervention programmes to improve maternal health and counter childhood obesity. Before that, she practised medicine, advised former Speaker of the US House of Representatives Newt Gingrich on health-care policy, and served in the US Air Force. \u201cDr Brenda Fitzgerald is a solid choice as the new director of the CDC,\u201d said Donna Petersen, chair of the Association of Schools and Programs of Public Health in Washington DC and dean of the College of Public Health at the University of South Florida in Tampa, in a statement. \u201cHer leadership of the Georgia Department of Public Health has given her first-hand experience in dealing with the many challenges facing state and local health departments.\u201d Fitzgerald's appointment does not require confirmation by the US Senate, unlike many other top government jobs. At the CDC, she will lead efforts to combat and prevent infectious and chronic diseases. If President Donald Trump has his way, she would have to do so with  US$1.2 billion less in 2018 than the agency received in 2017 . It is not clear whether Congress will go along with the president's plan, however. \n             Ten million patients \n           Fitzgerald entered the public-health realm in 2011 when the newly elected Governor of Georgia, Nathan Deal, asked her to advise him on medical issues. Fitzgerald pointed out concerns over the organization of the state\u2019s public-health efforts, and the governor decided to hand her the department's reins. \u201cI really saw my life as going from seeing one patient at a time to going to see ten million at a time,\u201d Fitzgerald said  in an interview in 2015 . While making that transition, Fitzgerald led a reorganization of the state's public-health programmes, and worked tirelessly to earn extra support \u2014 and funding \u2014 for her department from a conservative state legislature during a financial downturn, says Phillip Williams, dean of the College of Public Health at the University of Georgia in Athens. There have been some bumps along the road. In 2014, Governor Deal was reported to have said that the Ebola virus could be killed by water. The gaffe was widely criticized and Deal blamed Fitzgerald, saying that she had misinformed him. But he also emphasized that he still believed her to be competent for her position. \n             Data driven \n           Through it all, Fitzgerald has maintained a strong focus on mothers and children, which Williams attributes to both her medical background and her emphasis on hard data. \"She's very data-driven,\" he says. \"She has established systems to use the data to prioritize her policy- and decision-making.\" She also has close ties to the schools of public health in the state, says Colin Smith, a social epidemiologist at Georgia State University in Atlanta and the incoming president of the Georgia Public Health Association. \u201cShe\u2019s everywhere, every time I turn around,\u201d he says. \u201cWill that translate to the national level? I don\u2019t know. But I sure know that she\u2019s been a resource for Georgia.\u201d Fitzgerald has donated money to several Republican politicians over the years, according to a database maintained by the Center for Responsive Politics, a non-partisan group in Washington DC that analyses political donations. Other information collected by the US Open Payments programme, which holds data on the fees physicians receive from drug firms, shows that she received only $14 from pharmaceutical companies in 2015. \n                   Trump budget would slash science programmes across government 2017-May-23 \n                 \n                   Physician with drug-industry ties is Trump's FDA pick 2017-Mar-10 \n                 \n                   Gene-edited cows, rogue clinics, speedier drug approvals: the challenges facing Trump's FDA chief 2017-Jan-06 \n                 \n                   Trump's pick for US health secretary has pushed to cut science spending 2016-Nov-29 \n                 \n                   US Centers for Disease Control and Prevention \n                 Reprints and Permissions"},
{"file_id": "547013a", "url": "https://www.nature.com/articles/547013a", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Large projects explore how to integrate data from smart devices with other health metrics. On the morning of Tuesday 27 June, a young man walked into an office in northern California, signed a consent form and picked up two devices that will monitor his heartbeat, sleep patterns and a range of other bodily functions. He is one of the first participants in a planned 4-year, 10,000-person study being run by Google\u2019s spin-off company Verily Life Sciences, which aims to find out how readings from smart devices can be combined with genetic tests and other data to improve overall health and to predict when someone might suffer a medical emergency such as a stroke or seizure. Verily\u2019s study, Project Baseline, joins a handful of similar experiments, including one led by the US National Institutes of Health (NIH), which enrolled its first person earlier in June and will collect data from wearable devices on some of its one million participants. Together, these studies are part of a broad effort by companies and researchers to take advantage of the data generated by smart electronics. Today\u2019s devices appeal mainly to a select group that wants to quantify the minutiae of their lives, down to how many steps they take while mowing the lawn. But tech proponents foresee a day when sensors linked to smartphones will be an integral part of personalized medicine. A first step towards that goal will be developing software platforms to integrate the output from sensors with genomic data and conventional medical information. Researchers hope the combination will yield data signatures that can predict diseases and point the way to treatments tailored to each patient. \u201cTechnology is not really the barrier,\u201d says Adrian Hernandez, a cardiologist at Duke University in Durham, North Carolina, and a principal investigator on Project Baseline. \u201cWhat we really need to understand is individual health.\u201d To find indicators of diseases, researchers are taking an approach reminiscent of the Framingham Heart Study, which started monitoring about 5,000 adults in Massachusetts in 1948. Over the next few decades, it revealed links between heart disease and high cholesterol, elevated blood pressure and smoking. In Project Baseline, participants will wear Verily\u2019s proprietary Study Watch, which will transmit their heart rate, movements and other information to the company\u2019s database. Another sensor below people\u2019s mattresses will monitor their sleep patterns. Verily will also collect genomic data, information on participants\u2019 feelings (gathered through self-reported surveys), health records, family histories and the results of periodic lab tests on urine, saliva and blood. In-person appointments will mainly take place at clinics at Duke University and at Stanford University in California, which are collaborating on the project. Jessica Mega, chief medical officer at Verily in South San Francisco, California, says that a key goal is to help the company test and refine its platform for integrating multidimensional health data. \u201cWe are building infrastructure that others can use to test hypotheses, tools and technologies,\u201d she says. Verily will make its participants\u2019 anonymized data available to researchers from universities and companies on a case-by-case basis. This may involve companies sponsoring studies that test new technology, says Mega. The NIH study, called All of Us, received $230 million in the current fiscal year and is part of the agency\u2019s Precision Medicine Initiative. Some participants will have an option to send researchers data collected through smart wristbands, sleep sensors, environmental monitors, genetic and microbiome sequencing and other technologies. The two massive studies follow smaller ones such as a project led by Stanford genomicist Mike Snyder, who has been collecting more than 250,000 daily measurements from about 100 people in an ongoing project called iPOP (integrated personal omics profiling). In January, Snyder published a paper reporting how sensors he wears clued him in to abnormalities, such as elevated skin temperature and decreased oxygen in his blood, that prompted him to visit a doctor ( X.\u00a0Li  et\u00a0al. PLoS Biol.   15,  e2001402; 2017 ). The clinician diagnosed him with Lyme disease. Leroy Hood, co-founder of the Institute for Systems Biology in Seattle, Washington, has also completed a deep-data study, this one with 108\u00a0people. He used lessons from the project to co-found biotechnology company Arivale, which charges $3,500 per year to evaluate people\u2019s data over time from a range of sources, including wearables, genome sequencing and blood biomarkers. Users also repeatedly talk to a coach who looks at the data, and makes recommendations on how to improve their lives. Some people who sign up for the programme are at risk of diseases such as Parkinson\u2019s and Alzheimer\u2019s, and Hood says that pharmaceutical companies may be willing to pay for information on these individuals to learn how their chemistry changes if they start to become ill. \u201cThis information can indicate biomarkers,\u201d he says, \u201cand the idea is that you could then make drugs that would prevent the disease.\u201d One challenge in all these efforts is keeping people engaged over many months. Verily is considering using games to sustain participation. But Hood doubts the long-term efficacy of that approach. He says Arivale\u2019s clients stick with their programme because of the monthly visits to a coach. \u201cIt\u2019s a lot like therapy,\u201d he says, \u201cthey become your mother or father.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @amymaxmen \n               \n                     Sanofi and Google in type 2 diabetes smartphone tie-up 2016-Nov-08 \n                   \n                     Q&A: Kathy Hudson 2016-Sep-07 \n                   \n                     Precision medicine 2016-Sep-07 \n                   \n                     Digital medicine's march on chronic disease 2016-Mar-10 \n                   \n                     The body electric 1999-Jul-15 \n                   \n                     Verily\u2019s\u00a0Project Baseline \n                   \n                     NIH\u2019s\u00a0All of Us \n                   \n                     Snyder\u2019s iPOP \n                   \n                     Institute for\u00a0Systems Biology\u2019s 100K Wellness Project \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22281", "url": "https://www.nature.com/articles/nature.2017.22281", "year": 2017, "authors": [{"name": "Laura Castells"}], "parsed_as_year": "2006_or_before", "body": "Chemical produced by tomato plants in response to pest attack can change insect behaviour. It is not unusual for insect pests to feast on each other as well as on their staple veg, but it's now been shown that tomato plants can team up to directly push caterpillars into cannibalism. \u201cThis is a new ecological mechanism of induced resistance that effectively changes the behaviour of the insects,\u201d says Richard Karban, who studies interactions between herbivores and their host plants at the University of California at Davis and was not involved in the study. Herbivorous pests often turn on each other when their food is of poor quality or it runs out. And some plants are known to affect the behaviour of their pests by making them more predatory towards other species. But until now it was unclear whether plants could directly cause caterpillar cannibalism. Integrative biologist John Orrock and his colleagues at the University of Wisconsin in Madison triggered a defensive reaction in tomato plants ( Solanum lycopersicum ) by exposing them to various amounts of methyl jasmonate (MeJA). This is an airborne chemical that plants release to alert each other to danger from pests. When cued with MeJA, tomato plants respond by producing toxins that make them less nutritious to insects. The researchers then allowed caterpillars of a common pest, the small mottled willow moth ( Spodoptera exigua ), to attack the crop. Eight days later, they observed that plants more strongly cued with MeJA had lost less biomass compared with control plants or with ones that had received a weaker induction. This showed that the reaction was somehow effective at protecting the plants. \n             Cannibalism trigger \n           Next, the team wanted to test whether the plants\u2019 response was triggering cannibalistic behaviour in the caterpillars. So they cued tomato plants with MeJA and then fed leaves from cued plants and non-cued control plants to single caterpillars in containers that also contained a set number of dead caterpillars. Two days later, the team observed that caterpillars fed with leaves from the treated plants had turned onto the dead larvae earlier, and had eaten more of them, than those fed with leaves from control plants. The results are published in  Nature Ecology & Evolution 1 . The caterpillars will always eat each other eventually, but the difference in timing is critical, says Orrock, \u201cif plants can induce pests to eat each other earlier, there will be more of the plant left untouched\u201d. However, he also cautions that the cost to the plant of activating its defences is very high. \u201cIt is very possible that the plants will strike a balance and decide if the attack is serious enough to activate the defences.\u201d Anurag Agrawal, who studies plant\u2013animal interactions at Cornell University in Ithaca, New York, says that the study suggests that farmers could foster cannibalism as a pest-management strategy. \u201cNonetheless, under some field conditions, cannibals may be more fit than non-cannibals. So this is something to watch out for,\u201d he added, \u201cWe don\u2019t want to be encouraging super-pests\u201d. \n                   Plant biology: Growth industry 2010-Dec-15 \n                 \n                   Stressed-out plants warn their offspring 2006-Aug-06 \n                 \n                   Pests bug plant defence message 2002-Oct-17 \n                 \n                   Chemical plant 2000-Aug-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22287", "url": "https://www.nature.com/articles/nature.2017.22287", "year": 2017, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Scientists hope pooled records could answer major archaeological questions and map human migration patterns. Radiocarbon dating has long been used to reveal the age of organic materials \u2014 from ancient bones to wooden artefacts. Scientists are now using the amassed dates for wider applications, such as spotting patterns in human migration. And a Canadian database is poised to help researchers around the world to organize this trove of archaeological and palaeontological data, and to address problems that have plagued carbon dating for years. Set up in the 1980s, the Canadian Archaeological Radiocarbon Database (CARD) is undergoing an expansion that began in 2014. The database currently holds 70,000 radiocarbon records from 70 countries. The latest effort aims to make the software behind the site open source, making it easier for other research groups to set up their own version of CARD while still contributing core information to the main database. The first such site should come online within the year. There are other radiocarbon databases out there, but CARD is by far the largest, says Robert Kelly at the University of Wyoming in Laramie, who is collecting data to contribute to CARD. It\u2019s also the only one so far with global ambitions, he says. \u201cThis is big data. That\u2019s where the action is,\u201d says Kelly. \u201cWe\u2019ve spent 60 years running radiocarbon dates, and you can do a lot with them if they\u2019re all in one place.\u201d \n             Preparing for the future \n           Radiocarbon dating uses the ratio of stable carbon atoms to a radioactive isotope called carbon-14 in the material to determine the age of a once-living specimen.  Researchers need to consider a host of factors during their analyses , including the type of material tested and variations in the rate at which the organic matter incorporated different carbon isotopes, in order to produce an accurate age. In the past, this information wasn\u2019t often published alongside carbon dates, says Thomas Stafford, a radiocarbon-dating consultant in Lafayette, Colorado. A global database would ensure that this kind of information accompanies every data point, so that  if dates have to be recalculated  in the future, they can be, he says. A centralized database would also make it easier to find previously published radiocarbon data. \u201cI\u2019ve been working in my area for 20 years, and just last month I found a data set I didn\u2019t know existed,\u201d says Andrew Martindale, an anthropological archaeologist at the University of British Columbia in Vancouver and director of CARD. But the most compelling reason for a single large data set, says Kelly, is that it enables data mining. Given enough properly dated archaeological finds, some experts argue that they can start to make careful population estimates and trace how human populations moved over space and time. It\u2019s a new and controversial idea, however. Others argue that such data sets can be biased by archaeologists\u2019 interests in particular areas or time periods: an abundance of radiocarbon dates in a given spot or time might reflect a researcher\u2019s focus rather than real demographic change. But the CARD database is getting large enough to iron out such factors, says Kelly. In 2015, Martindale and his colleagues used CARD to make the first continent-wide map of human occupation of the Americas over the past 13,000 years 1 . Martindale plans to mine the data to confirm and quantify North American population changes due to wars or settlement relocations that are currently known only through indigenous traditional storytelling. \n             Database clones \n           Expanding CARD has its difficulties, however, says Martindale. Some information, such as precise site locations, must be kept secret in some countries to avoid looting. And metadata, including the context of an archaeological find or the exact testing methodology, are hard to standardize. \u201cThere is a lot in a date. It\u2019s not just a number,\u201d says Tom Higham, deputy director of the Oxford Radiocarbon Accelerator Unit in the United Kingdom. He worries that squeezing all this information into a single database, and wrangling permissions from the people who own the data, may make the mission \u201cworthy but fruitless\u201d. Funding is also an issue. \u201cEveryone agrees we should have a global archive, but granting agencies are always looking for specific research questions,\u201d Martindale says. To sidestep the problem, he will make the CARD software open source, so that other groups can create clones of the site tailored to their needs. The core data can then be sucked into the CARD database. \u201cThat decentralizes the funding,\u201d says Martindale. The University of Ottawa\u2019s high-precision isotope lab, the A. E. Lalonde Accelerator Mass Spectrometry Laboratory (AMS), is now working with Martindale to organize their own data using the first such clone. They hope to have something up and running within the next year, says Carley Crann, a lab technician at AMS who is heading the effort. \u201cThe data belong to the people who paid for it,\u201d says Martindale. \u201cBut if we make it easy for them, just a button they can push that says \u2018yes, upload my data to CARD\u2019, then we think they will.\u201d \n                   Democratic databases: science on GitHub 2016-Oct-03 \n                 \n                   The unsung heroes of scientific software 2016-Jan-04 \n                 \n                   Computers read the fossil record 2015-Jun-30 \n                 \n                   Core sample sends carbon clock farther back in time 2012-Oct-18 \n                 \n                   Archaeology: Date with history 2012-May-02 \n                 \n                   Canadian Archaeological Radiocarbon Database \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22288", "url": "https://www.nature.com/articles/nature.2017.22288", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Microbial immune system can encode movies in bacterial genomes. Internet users have a variety of formats in which to store their movies, and biologists have now joined the party. Researchers have used the microbial immune system called CRISPR\u2013Cas to encode a movie in the genome of the bacterium  Escherichia coli . The technical achievement, reported on 12 July in  Nature [1], is a step towards creating cellular recording systems capable of encoding a series of events, says Seth Shipman, a synthetic biologist at Harvard Medical School in Boston, Massachusetts. While studying brain development, Shipman became frustrated because no available technique could capture what caused one cell to take on a different identity than another. This inspired him to try out cellular encoding. \u201cCells have this privileged access to all sorts of information,\u201d he says. \u201cI would like to have these molecular recordings functioning in the developing nervous system and recording information.\u201d To develop such a system, however, would require his team to establish a method for recording hundreds of events in the cell. Shipman and his colleagues, including geneticist George Church, harnessed the CRISPR\u2013Cas immune system best known for enabling researchers to  alter genomes with relative ease and accuracy . This system employs an enzyme called Cas9, which can be directed to make cuts at specific sites in the genome. Shipman\u2019s team, however, exploited a different feature of the system: its ability to  capture snippets of DNA from invading viruses  and store them in an organized array in the genome. In nature, those snippets then target Cas9 to slice up the invader\u2019s DNA. In Shipman\u2019s system, the snippets instead corresponded to pixels in an image. The researchers encoded the shading of each pixel, along with a barcode to indicate its position in the image, into 33 DNA letters. Each frame of the movie consisted of 104 of these DNA fragments. \n             Moving pictures \n           The movie that the researchers selected consisted of five frames adapted from British photographer Eadweard Muybridge\u2019s  Human and Animal Locomotion  series. The photos capture a mare named Annie G. galloping in 1887. The team introduced the DNA into the bacteria at a rate of one frame per day for five days. They then sequenced the CRISPR regions in a population of bacteria to recover the image. Because the CRISPR system adds DNA snippets sequentially, the position of each snippet in the array could be used to determine the original frame to which the snippet belonged. The system is a long way from becoming the recorder that Shipman dreamt of while studying the brain. But Victor Zhirnov, chief scientist at the Semiconductor Research Corporation in Durham, North Carolina, calls the work \u201crevolutionary,\u201d and thinks that the ability to store information in living cells could ultimately overcome  some of the storage problems associated with DNA , such as the relative slowness and difficulty of reading and writing the information. Other CRISPR-Cas systems can convert RNA into DNA that is then inserted into the CRISPR array, notes bioengineer Randall Platt at the Swiss Federal Institute of Technology in Basel. This could open up the door to using the arrays to track gene expression. Getting to that point will take substantial technological advances, he adds. The information is stored in populations of cells, rather than individual cells. And no one has yet transferred the CRISPR arrays into mammalian cells. \u201cIt\u2019s full of limitations, but this is pioneering work that they\u2019re doing,\u201d he says. \u201cIt\u2019s elegant.\u201d Zhirnov hopes to start tinkering with the technique at his research foundation. \u201cIt\u2019s like this is the first airplane flown in 1930: it was just a curiosity,\u201d says Zhirnov. \u201cBut ten years from that, we had airplanes almost like what we have today.\u201d \n                   The trickiest family tree in biology 2017-Jul-05 \n                 \n                   Five big mysteries about CRISPR\u2019s origins 2017-Jan-12 \n                 \n                   How DNA could store all the world\u2019s data 2016-Aug-31 \n                 \n                   CRISPR, the disruptor 2015-Jun-03 \n                 \n                   Cellular 'computers' gain a hard drive 2014-Nov-14 \n                 \n                   US Library of Congress: Eadweard Muybridge \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22196", "url": "https://www.nature.com/articles/nature.2017.22196", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Some doubt that the publishing giant will see any money from the pirate site. One of the world\u2019s largest science publishers, Elsevier, won a default legal judgement on 21 June against websites that provide illicit access to tens of millions of research papers and books. A New York district court awarded Elsevier US$15 million in damages for copyright infringement by Sci-Hub, the Library of Genesis (LibGen) project and related sites. Judge Robert Sweet had  ruled in October 2015 that the sites violate US copyright . The court issued a preliminary injunction against the sites\u2019 operators, who nevertheless continued to provide unauthorized free access to paywalled content. Alexandra Elbakyan,  a former neuroscientist who started Sci-Hub in 2011 , operates the site out of Russia, using varying domain names and IP addresses. In May, Elsevier gave the court a list of 100 articles illicitly made available by Sci-Hub and LibGen, and asked for a permanent injunction and damages totalling $15 million. The Dutch publishing giant holds the copyrights for the largest share of the roughly 28 million papers downloaded from Sci-Hub over 6 months in 2016, followed by Springer Nature and Wiley-Blackwell. ( Nature  is published by Springer Nature, and  Nature \u2019s news and comment team is editorially independent of the publisher.) According to a recent analysis, almost 50% of articles requested from Sci-Hub are published by these three companies 1 . The defendants\u2019 \u201cunlawful activities have caused and will continue to cause irreparable injury to Elsevier, its customers and the public,\u201d Elsevier\u2019s New York-based attorneys, DeVore & DeMarco, told the court. After the 21 June hearing, Judge Sweet of the US district court in southern New York ruled in favour of Elsevier, in the absence of Elbakyan or legal representatives of any of the defendants. \u201cThe Court has not mistaken illegal activity for a public good,\u201d said Maria A. Pallante, president and CEO of the Association of American Publishers \u2014 a trade group that Elsevier belongs to \u2014 in a statement released on 22 June. \u201cOn the contrary, it has recognized the defendants\u2019 operation for the flagrant and sweeping infringement that it really is and affirmed the critical role of copyright law in furthering scientific research and the public interest.\u201d But observers in academic publishing who are following the case  have questioned  whether Elsevier will ever see any damages from Elbakyan, who lives outside the court\u2019s jurisdiction and has no assets in the United States. The ruling is also unlikely to prompt Sci-Hub or other pirate sites to close up shop. Elbakyan could not be reached for comment. \u201cSci-Hub is obviously illegal,\u201d says structural biologist Stephen Curry at Imperial College London in the United Kingdom. \u201cBut the fact that it is so immensely popular, inside and outside academia, is a symptom of many people\u2019s frustration with the status quo in academic publishing.\u201d Academic institutions and libraries in several countries, including the Netherlands, Germany, Finland and Taiwan are at loggerheads with Elsevier over affordable licensing agreements, he notes. In Finland, for example, several thousand scientists have signed a petition saying they will abstain from all editorial and reviewing requests from Elsevier journals until a \u201cfair deal\u201d is reached between the publisher and the Finnish library consortium over subscription costs and open access models. \u201cThis ruling should stand as a warning to those who knowingly violate others\u2019 rights,\u201d says Matt McKay, a spokesperson for the International Association of Scientific, Technical and Medical Publishers in Oxford, UK. \u201cSci-Hub does not add any value to the scholarly community. It neither fosters scientific advancement nor does it value researchers\u2019 achievements. It is simply a place for someone to go to download stolen content and then leave.\u201d \n                   Science publishers try new tack to combat unauthorized paper sharing 2017-May-10 \n                 \n                   Unpaywall finds free versions of paywalled papers 2017-Apr-04 \n                 \n                   Paper piracy sparks online debate 2016-May-02 \n                 \n                   Pirate research-paper sites play hide-and-seek with publishers 2015-Dec-04 \n                 Reprints and Permissions"},
{"file_id": "546460a", "url": "https://www.nature.com/articles/546460a", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "DNA of 234-year-old tree has few mutations, giving weight to idea that plants protect their stem cells. The towering 234-year-old 'Napoleon' oak on the campus of the University of Lausanne in Switzerland has weathered storms both meteorological and political. The tree was young when Napoleon\u2019s troops passed through town in 1800, and has grown into a majestic city landmark. But through it all, its genome has remained largely \u2014 and surprisingly \u2014 unchanged. Researchers at the university discovered this unexpected stability after sequencing the genome in different branches of the tree. Their work \u2014 posted on 13 June as a bioRxiv preprint, which has not been peer reviewed \u2014 meshes with a growing body of evidence that plants are able to shield their stem cells from mutations 1 . The practice may be valuable for sustaining their health over a lifespan that can reach hundreds of years. \u201cIf you just accumulate more and more mutations, you would eventually die of mutational meltdown,\u201d says Cris Kuhlemeier, a developmental biologist at the University of Bern in Switzerland. Each time a cell divides, mutations can arise because of errors made while copying the genome. Animals shield their reproductive cells from these mutations by isolating them early in development. These cells, called the germline, then follow a different developmental path, and typically have a low rate of cell division. But plants do not have a dedicated germline: the cluster of stem cells that gives rise to the reproductive parts of flowers also generates plant stems and leaves. Because of this, scientists thought that the stem cells would accumulate many mutations,  and that newer branches at the top of a long-lived tree would be remarkably different from the lower branches . \n               Branching out \n             Plant biologist Philippe Reymond and his team at the University of Lausanne decided to test this hypothesis using the university\u2019s prized oak tree. They sequenced the genome from leaves on lower, older branches and upper, younger ones, and tallied the number of single-letter changes they found in the tree's DNA. (Reymond declined to be interviewed by  Nature  because the paper is currently under review at a scientific journal.) The team found that the number of mutations was much lower than would be expected based on calculations of the number of cell divisions that occurred between the lower branch and the higher one. \u201cIt\u2019s a tantalizing study,\u201d says Daniel Schoen, a plant evolutionary biologist at McGill University in Montreal, Canada. \u201cIt touches on something that was simmering always, in the back of the minds of plant biologists.\u201d It is too soon to say how general this phenomenon will be in plants, cautions Karel \u0158\u00edha, a plant geneticist at the Central European Institute of Technology in Brno, Czech Republic. The researchers also looked only at one kind of genetic change \u2014 single-letter changes to the sequence \u2014 and did not evaluate other kinds of mutations, such as deleted DNA. Mao-Lun Weng, a plant evolutionary biologist at South Dakota State University in Brookings, notes that the team used a stringent filter to weed out background noise in the sequencing data, and may have inadvertently missed some mutations as a result. \n               Planting the seed \n             This could mean that some mutations were left out of the analysis. But \u0158\u00edha and Weng are quick to note that the results are in line with two studies published last year. In the first 2 , led by Kuhlemeier, researchers tracked individual stem-cell divisions in the growth region of plants called the meristem. They found that in tomato and thale cress ( Arabidopsis ), the meristem contains a set of three or four cells that are set aside and divide much less often than the other cells in the region. The other study 3 , led by \u0158\u00edha, also found few mutations between old and new leaves in thale cress. For Kuhlemeier, the results provide an answer to a question that has troubled him ever since a trip to Oregon 20 years ago. As he looked up at a soaring, 400-year-old Douglas fir, Kuhlemeier wondered how the branches towards the top of the tree would differ from those at the bottom. \u201cI had always thought of a tree not as an organism, but as a collection of organisms with different genomes \u2014 more like a colony,\u201d he says. Many ecologists shared his view, but now he has begun to question his earlier idea. A clearer picture of plant development could help breeders as they increasingly focus on long-lived, perennial plants, says Schoen. \u201cIf, as plants age, there is this mutation accumulation that could impact vigour, we would want to know about it,\u201d he says. \u201cWe need more information of this type.\u201d  \n                     Italy rebuked for failure to prevent olive-tree tragedy 2017-Jun-07 \n                   \n                     Genomics: Sunflowers sequenced 2017-May-31 \n                   \n                     Trees in eastern US head west as climate changes 2017-May-17 \n                   \n                     Geneticists enlist engineered virus and CRISPR to battle citrus disease 2017-May-16 \n                   \n                     Technology: The Future of Agriculture 2017-Apr-26 \n                   \n                     Tree's leaves genetically different from its roots \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22168", "url": "https://www.nature.com/articles/nature.2017.22168", "year": 2017, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "Fossils from ancient hippo ancestor suggest that grass helped the animals to conquer a continent. Quick, huge and deadly,  the common hippo is the king of Africa\u2019s rivers . Now fossils suggest that hippos assumed power swiftly and that changes in vegetation helped to propel their rise. An analysis of hippo teeth excavated at an Ethiopian fossil site suggests that the hippo went from bit player to boss of the waterways in less than 1.5 million years 1 . Earlier research had established that hippos exploded in abundance and diversity at some point in their history, but how long this \u2018hippopotamine event' took and when it happened was unknown 2 , 3 . The latest study concludes that the event began around 8 million years ago, as new grass types spread through Africa. This timing supports the theory that the hippo\u2019s ascent is linked in part to the spread of these grasses. Today\u2019s common hippo ( Hippopotamus amphibius ) lolls in the water during the day, emerging at night onto land to tuck into nearby greenery, especially grasses. \u201cThanks to this site, we can document how this sudden burst of hippos occurred in the fossil record,\u201d says co-author Jean-Renaud Boisserie, a palaeontologist at France\u2019s National Center of Scientific Research in Poitiers and at the French Centre for Ethiopian Studies in Addis Ababa. \u201cIt\u2019s clear to me this expansion of hippos is really related to this change in vegetation.\u201d The shift, which was probably tied to changes in the climate, boosted plants that thrive in hot, dry areas. The fossils were excavated over the past decade by a Japanese\u2013Ethiopian team working at Ethiopia\u2019s Chorora site, also the name of a local village. The fossils are mostly teeth, but those are distinctive enough to recognize new species, Boisserie says. The star of the show is  Chororatherium roobii , a new species named in part after a local word for hippopotamus. The animal lived roughly 8 million years ago and probably spent much of its time in the water. It weighed perhaps half as much as the 1,400-kilogram common hippo. \n               Hungry hungry hippos \n             Chororatherium    roobii \u2019s teeth have similarities to those of  Kenyapotamus , an older, more primitive hippo. But they also bear modern features, such as the pattern of cusps on the lower molars. The thicker enamel on the  C.\u00a0roobii  teeth would have been suitable for eating grasses, although the researchers cannot say for sure what the animal ate. These traits mark  C. roobii  as the first modern hippo, Boisserie says, and a transitional species between the archaic beasts that came before it and the larger hippos that started appearing half a million years later. Chorora\u2019s fossil wealth helped Boisserie and his team to chart the hippo\u2019s climb to prominence. Hippo remains account for only 6% of fossil specimens in a stratum from 8.5 million years ago. But the animals account for more than 30% of identified specimens 7.6 million years old or younger, which is comparable to fossil sites of similar age in Kenya and Chad. The analysis helps researchers to close in on when hippos began to dominate Africa\u2019s riversides, says biological anthropologist Colin Groves of the Australian National University in Canberra. The idea that grasses had a role \u201clooks a good hypothesis\u201d, he adds. \u201cSomething had to have caused the hippos to sprout so rapidly.\u201d But the findings from the teeth might be overturned if researchers discover other remains, says Eleanor Weston, an independent mammalian palaeontologist in the United Kingdom. A jawbone or skull \u201cmight completely change the story\u201d, she says. Boisserie agrees that\u2019s possible but says the teeth of  C. roobii  look exactly as would be expected in an animal leading to today\u2019s hippo species. Chororatherium    roobii  might have differed from its modern kin in one important way. Today\u2019s common hippo is known to kill humans and even crocodiles.  Chororatherium    roobii  might have been less of a danger, Boisserie says, because it was smaller \u2014 but there\u2019s no way of knowing whether it was sweeter-tempered.  \n                     Mystery of Darwin's 'strange animals' solved 2015-Mar-18 \n                   \n                     Mini mammoth once roamed Crete 2012-May-09 \n                   \n                     The land-based ancestor of whales 2007-Dec-19 \n                   \n                     Hippos beat the burn 2004-May-27 \n                   Related external links Reprints and Permissions"},
{"file_id": "549459a", "url": "https://www.nature.com/articles/549459a", "year": 2017, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "The party of France\u2019s recently elected president won an absolute majority in its first general elections, with an agenda that included strong support for research. A wave of fresh faces \u2014 including the flamboyant mathematician C\u00e9dric Villani \u2014 rose to victory in the French parliamentary elections on 18\u00a0June. Together with the science- and innovation-friendly policies announced by President Emmanuel Macron, the results have stoked optimism among many researchers in France and abroad. They \u201care a real hope of dynamism for our country\u201d, says French climatologist Jean Jouzel, a former senior figure in the Intergovernmental Panel on Climate Change. He echoes many researchers who have responded positively to the latest election outcome and, more generally, to the president\u2019s stances since he was  elected on 7 May . \u201cMacron is going exactly in the right direction,\u201d says Sacha Wunsch-Vincent, an economist at the World Intellectual Property Organization in Geneva, Switzerland. He says he can\u2019t remember any French president placing such a firm focus on innovation. With 43% of the popular vote, Macron\u2019s newcomer party, La R\u00e9publique en Marche!\u00a0(LREM), completed a political takeover as it won a comfortable majority of 308 seats in the National Assembly, the lower house of the French parliament. That was well over the bar needed to control the 577-seat body \u2014 even without counting the 42 seats won by Mouvement D\u00e9mocrate (MoDem), a centrist party allied with LREM. The outcome gives Macron the means to push his pro-business, pro-innovation and pro-European Union agenda. The large victory of LREM, whose policies span the moderate left, right and centre, is all the more astonishing in that the party was born barely a year ago and announced its list of candidates on 11 May, just a month before the first round of the general election. Half of its candidates were women, and a majority had no previous political experience. LREM\u2019s new deputies include Villani, who won more than 69% of votes in his constituency, Saclay, in Sunday\u2019s run-off. Saclay is home to a cluster of research institutions that is among the largest in the country. \n               Warm welcome \n             Earlier this month, in one of his first actions on science, Macron launched a programme to attract leading climate scientists to work in France, offering 4-year grants of up to \u20ac1.5\u00a0million (US$1.7\u00a0million) for senior scientists and up to \u20ac1\u00a0million for younger researchers. The move came in response to US President Donald Trump\u2019s announcement that he would  withdraw his country from the Paris climate accord . \u201cBeyond his call for attracting scientists, Macron has shown a deep interest for climate issues,\u201d says Jouzel. A particularly hopeful sign for Jouzel was last month\u2019s appointment of Nicolas Hulot, an environmental activist and former nature-documentary presenter, as head of a powerful ministry overseeing energy and the environment. More generally, Macron wants to foster an entrepreneurial environment by reducing the costs of doing business, simplifying bureaucracy and making labour laws more flexible \u2014 things that some of his predecessors have attempted, but with limited success. He has also said he wants to encourage the country\u2019s entrepreneurs to focus on sectors such as robotics, artificial intelligence and green technology, which he sees as the industries of the future. He has announced a \u20ac10-billion state fund to invest in start-ups, and a \u20ac50-billion stimulus package to train young people and modernize agriculture, health care, transport and infrastructure. Wunsch-Vincent cautions, however, that it will be several months before it becomes clearer how the various pledges will pan out, and how well they will be implemented. The outcomes of the initiative to lure in climate researchers largely depend on whether the US Congress enacts drastic cuts to climate science proposed by Trump, says Robert Socolow, who works on carbon management and sequestration at Princeton University in New Jersey. If that were to happen, the Macron initiative would have \u201cmyriad positive effects\u201d, he says, including positions for promising young scientists who are usually the first victim of budget cuts. \u201cFrance will have the benefit of youthful energy,\u201d he says. \u201cI\u2019ve several colleagues who have already left the US for the EU in search of, and finding, an environment where science is respected and funding opportunities are more plentiful,\u201d says Katharine Hayhoe, an atmospheric scientist at Texas Tech University in Lubbock. \u201cI wouldn\u2019t be surprised if Macron\u2019s offer provided those who were already considering a move with the impetus to do so.\u201d Macron has admitted that the country hasn\u2019t always had the best reputation as a place for nimble innovation, but he argued that this was changing. \u201cI want France to be a \u2018start-up nation\u2019,\u201d he said last week. \u201cI hope he will not disappoint the hopes he has raised,\u201d says Jouzel, \u201cin particular in the area of jobs.\u201d \n                     Trump pulls United States out of Paris climate agreement 2017-Jun-01 \n                   \n                     Macron presidency is a welcome experiment 2017-May-10 \n                   \n                     Scientists relieved by Emmanuel Macron\u2019s French election victory 2017-May-08 \n                   \n                     French plan to create \u20ac5-billion science \u2018super-campus\u2019 in disarray 2017-May-05 \n                   \n                     Mathematics: Groping in the dark for glimpses of beauty 2015-Mar-04 \n                   \n                     Make Our Planet Great Again \n                   \n                     French Tech Visa \n                   Reprints and Permissions"},
{"file_id": "546464a", "url": "https://www.nature.com/articles/546464a", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Funding agencies announce harsh penalties and stronger policing efforts. The Chinese government is going on the offensive against scientists who dupe journals by creating fraudulent reviews of submitted papers. A coalition of agencies led by the science ministry announced on 14\u00a0June that the government would suspend the grants of researchers involved in such fraud, which surfaced earlier this year when a cancer journal retracted 107\u00a0research papers from Chinese authors. And funding agencies in China promised to increase policing of the scientific community to prevent similar deceptions. The harsh penalties and stricter enforcement were decided earlier this month at a meeting of representatives of the science ministry, the health ministry, the National Natural Science Foundation of China (NSFC) and other agencies.\u00a0 \u201cTo have so many agencies and so much personnel work together on the problem of manuscript fabrication is, to my knowledge, unprecedented,\u201d says Jiang Wenlai, a water-resources researcher at the Institute of Agricultural Resources and Regional Planning in Beijing, part of the Chinese Academy of Agricultural Sciences.\u00a0 The meeting was a response to retractions made in April by the journal  Tumor Biology , after its publisher, Springer Nature, found that reviews submitted in support of 107\u00a0papers had been fabricated. (Springer Nature no longer publishes  Tumor Biology .  Nature  is published by Springer Nature, and  Nature \u2019s News and Comment team is editorially independent of the publisher.) Fraud in peer review is a global problem. It occurs when researchers\u00a0\u2014 or companies acting on their behalf\u00a0\u2014 suggest scientists as potential peer reviewers, but the e-mails supplied for the reviewers route back to the authors or the companies, who then write spurious reviews supporting publication.\u00a0 Online companies that orchestrate fake peer review are among the main targets of the crackdown. The coalition hopes to enlist the government\u2019s Cyberspace Administration of China, the agency that censors the Internet in China. It could identify the culprits behind the companies, says Yang Wei, head of the NSFC. \u201cIf you shut one [website] down, they will just open three others,\u201d he says. \u201cOur goal is to find the person behind them.\u201d\u00a0 The problem extends well beyond cancer research. \u201cYou can go online and see lots of them. Different fields are served by different companies,\u201d says Yang. Surprisingly, only 17 of the 107 retracted papers were funded by the NSFC, even though the agency supports more than 60% of Chinese scientific research. Yang says that many of the scientists involved are at the start of their careers, trying to get a foot in the door. They are desperate to have a first publication so that they can then apply for better grants. The NSFC found that more than 30 of its pending grant applications were based on the retracted papers. Those applications have been cancelled. Some observers on social media are sympathetic towards clinical researchers caught up in the scandal. Physicians in China are often pressured to publish, but are given little time or resources to do so. Jiang, too, is sympathetic, but says that such publications are aimed at personal advancement, rather than making a contribution to science. He says that although the authors cannot be excused, other factors are to blame, including an unreasonable evaluation system and academic journals that show insufficient diligence over peer review. \u201cIt is not just the problem of the author, it is a societal problem,\u201d says Jiang. \u201cJust punishing the author will not eradicate the problem.\u201d\u00a0 The success of the government\u2019s crackdown will depend on whether it can link strict implementation to a fairer system of evaluation for doctors and researchers, says Jiang. \n                     Web of Science owner buys up booming peer-review platform 2017-Jun-01 \n                   \n                     Peer-review 'heroes' do lion's share of the work 2016-Nov-22 \n                   \n                     Publisher pulls 58 articles by Iranian scientists over authorship manipulation 2016-Nov-01 \n                   \n                     Faked peer reviews prompt 64 retractions 2015-Aug-18 \n                   \n                     Publishing: The peer-review scam 2014-Nov-26 \n                   \n                     Publishers withdraw more than 120 gibberish papers 2014-Feb-24 \n                   \n                     Investigating journals: The dark side of publishing 2013-Mar-27 \n                   \n                     Nature  Special: The future of publishing \n                   \n                     Nature \u2019s peer-review policy \n                   \n                     National Science Foundation of China \n                   \n                     Cyber Administration of China \n                   \n                     Ministry of Science and Technology China \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22177", "url": "https://www.nature.com/articles/nature.2017.22177", "year": 2017, "authors": [{"name": "Gabriel Popkin"}], "parsed_as_year": "2006_or_before", "body": "Orbits of four newfound objects show no signs of gravitational pull from proposed giant planet. An analysis of four icy bodies discovered in the outer Solar System reveals no sign that they are being influenced by a large, unseen planet lurking beyond Neptune. The finding chips away at a line of evidence for a \u2018 Planet Nine \u2019 proposed in 2014 on the basis of the clustering of objects in a region called the Kuiper belt, argues a team of astronomers in a paper 1  first posted on the arXiv preprint server on 16 June. The objects were found by researchers leading the Outer Solar System Origins Survey (OSSOS), which is studying the region of space beyond Neptune. The bodies that piqued the astronomers\u2019 interest dwell in the outer reaches of the Kuiper belt. Using the 3.6-metre Canada-France-Hawaii telescope on Mauna Kea, Hawaii, the team found four bodies that orbit the Sun in enormous ellipses at least 250 astronomical units ( au ) wide. An  au  is equivalent to the distance between Earth and the Sun; Neptune orbits at around 30  au . About 12 large-orbit bodies have been spotted so far, including the four found by OSSOS. Arguments for Planet Nine are based on the clustering of six of those previously known large-orbit objects. Studies 2 , 3  by two other research teams, which drew on multiple astronomical surveys, found that the six bodies were arranged in two groups. Both teams suggested that the gravity of an unseen planet, perhaps ten times Earth\u2019s mass, had shepherded the objects into those curious arrangements (see \u2018Far afield\u2019). \n             Disappearing clusters \n           Scientists agree that the astronomical surveys that spotted those six bodies weren\u2019t perfect, says Cory Shankman, an astronomer at the University of Victoria in Canada and the lead author of the latest study. Each had to contend with reduced visibility due to bad weather in some seasons, and the fact that it\u2019s easier to see Kuiper belt objects away from the plane of the Milky Way. Such factors can lead astronomers to spot more bodies in certain parts of the sky than in others, even when the objects are actually distributed evenly, says Shankman. It\u2019s possible to account for such biases using statistical methods, but most of the previous surveys didn\u2019t report doing so. The OSSOS team argues that the biases could have led to false indications of clustering. \u201cThey were building this entire argument around six objects with unknown biases in how they were detected,\u201d says astronomer Samantha Lawler at the National Research Council Canada in Victoria, \u201cwhich is a very dangerous game to play.\u201d Three of the objects found by OSSOS appeared to be in the two previously identified clusters. But when the study authors accounted for the fact that their survey preferentially spotted bodies in certain parts of the sky at certain times of year, the evidence for clustering disappeared, says Shankman. \n             The case for Planet Nine \n           The unknown biases in previous surveys do weaken the case for a Planet Nine at the size and distance proposed, says Renu Malhotra, an astronomer at the University of Arizona in Tucson. However, she adds, the OSSOS team has not proved that these biases actually enhance the appearance of clustering among distant Kuiper belt objects, so its paper does little to change the debate. Scott Sheppard, an astronomer at the Carnegie Institution for Science in Washington DC and part of the  team that first suggested the presence of an unseen planet , agrees. Even with the new data, the best explanation for the odd grouping of Kuiper belt objects is a planet, he says. And even if previous surveys had issues, they could still have spotted evidence for the existence of a massive planet, says Konstantin Batygin, an astronomer at the California Institute of Technology in Pasadena and a member of the other team that proposed the existence of Planet Nine. Besides, clustering is only one line of evidence for Planet Nine, he says. Discoveries of Kuiper belt objects that aren\u2019t tethered to Neptune, and others with orbits nearly perpendicular to those of most Solar System objects, are most easily explained by the presence of a large planet in the outer Solar System, Batygin adds. What will ultimately resolve the Planet Nine question, says Malhotra, is more data from current and future telescopes. \u201cWe are really working at the margins of what\u2019s technically feasible with the outer Solar System observations,\u201d she says. \u201cWe\u2019re really pushing the boundaries of what\u2019s possible to detect.\u201d \n                   Astronomers spot distant world in Solar System\u2019s far reaches 2016-Oct-18 \n                 \n                   On the hunt for a mystery planet 2016-Mar-15 \n                 \n                   Evidence grows for giant planet on fringes of Solar System 2016-Jan-20 \n                 \n                   Astronomers spy most distant Solar System object ever 2015-Nov-10 \n                 \n                   Dwarf planet stretches Solar System's edge 2014-Mar-26 \n                 \n                   The Outer Solar System Origins Survey (OSSOS) \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22152", "url": "https://www.nature.com/articles/nature.2017.22152", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Large analyses dredge up 'peripheral' genetic associations that offer little biological insight, researchers say. Compare the genomes of enough people with and without a disease, and genetic variants linked to the malady should pop out. So runs the philosophy behind genome-wide association studies (GWAS), which researchers have used for more than a decade to find genetic ties to diseases such as schizophrenia and rheumatoid arthritis. But a provocative analysis now calls the future of that strategy into question \u2014 and raises doubts about whether funders should pour more money into these experiments. GWAS are fast expanding to encompass hundreds of thousands, even millions, of patients (see 'The genome-wide tide'). But biologists are likely to find that larger studies turn up more and more genetic variants \u2014 or 'hits' \u2014 that have minuscule influences on disease, says Jonathan Pritchard, a geneticist at Stanford University in California. It seems likely, he argues, that common illnesses could be linked by GWAS to hundreds of thousands of DNA variants: potentially, to every single DNA region that happens to be active in a tissue involved in a disease. In a paper published in  Cell  on 15 June 1 , Pritchard and two other geneticists suggest that many GWAS hits have no specific biological relevance to disease and wouldn\u2019t serve as good drug targets. Rather, these 'peripheral' variants probably act through complex biochemical regulatory networks to influence the activity of a few \u2018core\u2019 genes that are more directly connected to an illness. \u201cThe implicit assumption of GWAS has been that when you find hits, they should be directly involved in the disease you\u2019re studying,\u201d he says. \u201cWhen you start to think that all of the expressed genes in a tissue can matter, it becomes untenable that there\u2019s a simple biological story for each one.\u201d Many geneticists think Pritchard's view could be correct \u2014 and say that he articulates widely-held concerns about the difficulty of interpreting GWAS findings because of gaps in understanding about biochemical networks. \u201cI think it\u2019s pretty plausible,\u201d says Joe Pickrell, a human geneticist at the New York Genome Center in New York City. \u201cWe might not actually be learning anything hugely interesting until we understand how these networks are connected.\u201d Rather than more and bigger GWAS, researchers and funders should devote their efforts to mapping regulatory networks in cells, Pritchard argues. Biologists who aim to link genes with diseases, he says, should focus on identifying the mutations that directly cause disorders; some of these  variants are so rare  that they aren't picked up in GWAS. \n               GWAS puzzles \n             GWAS  have identified some genes  that contribute to the risk of developing conditions such as obesity, but they have also thrown up plenty of vexing problems. Most of the hits found in GWAS don\u2019t seem to encode genes that make proteins, so it is hard to interpret their connection to a disease or trait. And even for traits that are known to be highly heritable \u2014 suggesting that they have a large genetic influence \u2014 the cumulative influence of all the DNA variants spotted by GWAS  doesn\u2019t fully explain the variation  seen between people. A 2014 study of 250,000 people, for example, identified nearly 700 DNA variants linked to height, but together, they explain only about 16% of differences in height across a population 2 . In the  Cell  paper, Pritchard\u2019s team re-analysed the data from the 2014 study. The researchers estimate that as many as 100,000 single-letter DNA variants can influence a person\u2019s height, but each one has a minuscule impact; on average just about one-tenth of a millimetre. These variants tend to lie in regions that do not themselves encode genes but which influence the activity of regions that do. The researchers also re-analysed data from GWAS of schizophrenia, rheumatoid arthritis and Crohn\u2019s disease. They found GWAS hits in DNA regions that are expressed in the particular cells relevant to the disease: neurons for schizophrenia, and immune cells for the two autoimmune diseases. But regions of DNA active in many types of body tissue were just as likely to be hits as those that were active only in neurons or immune cells, the team found. That lends credence to the idea that large GWAS are simply picking up most of the DNA variants that have an influence on gene regulation, and that happen to be active in broad functions of disease-relevant cells, rather than in particular activities linked to illness. This doesn\u2019t mean that researchers should stop carrying out GWAS, some geneticists say. Although GWAS hits might be peripheral to a disease, identifying more of them enables scientists to knit together the biological networks implicated in a disease and understand how they interact, says Mark McCarthy, a human geneticist at the University of Oxford, UK, who is working on a GWAS of type 2 diabetes involving around 1 million participants. \u201cThose of us who do ever bigger GWAS, we don\u2019t just simply crank the handle,\u201d he says. \u201cWe\u2019re motivated by lots of biological insights coming out of GWAS.\u201d And Joel Hirschhorn, a human geneticist at Children's Hospital Boston in Massachusetts, says that not all hits uncovered by very large GWAS are peripheral. The 2014 height study, which Hirschhorn co-led, uncovered an association to an important growth factor that wasn't picked up in a smaller GWAS of height, he points out. But Aravinda Chakravarti, a human geneticist at Johns Hopkins University in Baltimore, Maryland, hopes that the paper will challenge what he terms a \u201ccowboy attitude\u201d in genomics research that emphasizes collecting ever more genetic associations over understanding the deeper biology behind them. \u201cThis is a nice paper simply because it\u2019s going to kick people in the shin, which, as scientists, we need from time to time.\u201d \n                     Genomics is failing on diversity 2016-Oct-12 \n                   \n                     First robust genetic links to depression emerge 2015-Jul-15 \n                   \n                     Genomics shifts focus to rare diseases 2009-Sep-22 \n                   \n                     Personal genomes: The case of the missing heritability 2008-Nov-05 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22224", "url": "https://www.nature.com/articles/nature.2017.22224", "year": 2017, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "The number of researchers who work on basic-science questions has dropped precipitously. The number of scientists who report conducting purely fundamental research in Canada dropped from 24% to 1.6% between 2006 and 2015, according to a survey released on 28 June. The analysis reveals researchers\u2019 frustration with the country\u2019s long-term shift towards the support of applied research over basic science. The survey was conducted by the Global Young Academy \u2014 an international organization made up of 200 early-career scientists that was founded in Berlin in 2010 as a counterpart to national senior-scientist academies. Academy member Julia Baum, a biologist at the University of Victoria in Canada, spearheaded the investigation, which compiled the views of more than 1,300 Canadian researchers who completed an online survey. \u201cEvery academic can unequivocally tell you that the landscape of funding for basic research in Canada has been changed and damaged beyond recognition over the past decade,\u201d said an anonymous survey participant, according to the report. The results hammer home the message of the  Fundamental Science Review , a report commissioned by the federal government that was released in April: Canada is investing too little in basic science, and is falling behind internationally (see 'Downward trend'). Canada is the only G8 country where research investments as a proportion of gross domestic product have shown a clear downwards trend, the report notes, from nearly 2% in 2005 to 1.6% in 2014. \u201cThat\u2019s pathetic,\u201d says Baum. Basic researchers in the country have also faced a 35% drop in available funds per person since 2013, she says: the number of researchers has increased but funding and the number of available grants hasn\u2019t kept pace. These long-term declines in funding have left researchers dispirited, says Baum. \u201cThese scientists felt Canada used to be a wonderful place to do research,\u201d she says, but that it\u2019s no longer the case for their students. \u201cScience is no longer seen as a viable career option.\u201d \n             Holding onto hope \n           The report recommends a baseline rise of Can$459 million (US$352 million) to the country\u2019s three main granting bodies, which fund the natural, health and social sciences. That would give researchers the same level of support they enjoyed, per person, in 2005. This is in line with the Fundamental Science Review\u2019s recommendations. Canadian researchers hold out hope that the left-centre Liberal government, which was elected in 2015 with a pro-science platform, will bring change. More than two-thirds of survey respondents said that they think that fundamental research is important to the federal government. But scientists haven\u2019t seen much money mobilized in this direction yet. The Liberals gave Canada\u2019s three main granting bodies a much-needed Can$76 million boost in their 2016 budget \u2014 but in an unusual and controversial move,  didn't increase their budgets in 2017 . Science minister Kirsty Duncan told  Nature  that she is working to improve things for researchers in Canada. She will be moving ahead with some of the Fundamental Science Review\u2019s recommendations, including formalizing coordination between the granting councils and forming a review panel for big international science projects. She will also be introducing legislation to fix the leadership of the health-research granting agency. But \u201cI can\u2019t undo ten years of cuts in one budget cycle\u201d, Duncan says. \u201cThat\u2019s going to take time.\u201d \n                   Billion-dollar boost sought for Canadian science 2017-Apr-10 \n                 \n                   Canada budget falls flat with scientists 2017-Mar-23 \n                 \n                   Scientific challenges loom for Canada\u2019s popular prime minister 2016-Oct-25 \n                 \n                   Nine years of censorship 2016-May-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22226", "url": "https://www.nature.com/articles/nature.2017.22226", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "NASA sees a slight increase under the proposed budget whereas funding for the National Oceanic and Atmospheric Administration is cut by 13%. The US National Science Foundation\u2019s (NSF) budget would fall slightly and NASA\u2019s funding would see a small bump in 2018 under legislation unveiled by a US House of Representatives spending subcommittee on 28 June. The panel, which also oversees the budget of the National Oceanic and Atmospheric Administration (NOAA), largely rejected many of the deep cuts sought by President Donald Trump. Under the plan, the NSF would receive US$7.3 billion, a 1.8% drop from the 2017 spending level, but significantly smaller than the 11% cut that Trump wants. The agency\u2019s research budget would remain flat, at $6 billion. The House bill would increase NASA\u2019s budget to $19.9 billion, compared with $19.7 billion in 2017; Trump has proposed a $600-million cut. The legislation sets aside $495 million for two missions to Jupiter\u2019s moon Europa: an orbiter that would launch by 2022 and a lander that would launch by 2024. The funding includes $5.9 billion for NASA\u2019s science directorate, an increase of $94 million above the 2017 level. The spending panel has not yet released a detailed breakdown of how the money would be spent, but says that it will give more support to planetary science and astrophysics and reduce \u201cfunding for lower-priority research\u201d \u2014 which probably includes Earth science and heliophysics research. NOAA\u2019s budget would see the largest drop, to $4.97 billion \u2014 13% below the 2017 level. The House panel has not said how that money would be distributed, but says that its priorities include weather prediction and research, fisheries management and ocean exploration. It\u2019s not surprising that the House\u2019s budget proposal is similar to 2017 funding levels, says Michael Lubell, a physicist at City College of New York in New York City. That\u2019s because the House and the Senate haven\u2019t decided on an overall spending level for the entire government for 2018, which normally happens before spending bills are introduced. As a result, lawmakers are loathe to make major changes, such as those proposed by the White House, he says. \n             Fiscal fight \n           The House spending subcommittee is scheduled to vote on the proposal on 29 June. It is one of several bills released by the House Committee on Appropriations this week that ignore the cost-cutting requested by Trump for 2018. Trump has proposed slashing most government funding for the US Food and Drug Administration (FDA), and increasing the agency\u2019s reliance on user fees, but the House\u2019s FDA spending bill includes $2.8 billion for the agency \u2014 roughly even with the 2017 level. Another House spending bill would set aside $1.1 billion for research at the US Department of Agriculture, an 8% drop from the 2017 level, compared with the $894-million cut the White House has sought. The House would also give the Department of Energy\u2019s Office of Science $5.4 billion in 2018, which is what it received in 2017. But the House agrees with Trump on one significant point: both have proposed doing away with all support for the department\u2019s Advanced Research Projects Agency\u2013Energy, which funds \u2018high-risk, high-reward\u2019 energy research. \n                   Trump budget would slash science programmes across government 2017-May-23 \n                 \n                   Science wins reprieve in US budget deal 2017-May-01 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22191", "url": "https://www.nature.com/articles/nature.2017.22191", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Proteins involved in gene regulation once fought viruses. Viruses and their hosts have been at war for more than a billion years. This escalating arms race has driven a dramatic diversification of viruses and of host immune responses. Although the earliest antiviral systems have long since vanished, researchers may now have recovered remnants of it embedded like a fossil in human cells. A protein named Drosha, which helps to control gene regulation in vertebrates, also tackles viruses, researchers report today in  Nature 1 . They suggest that Drosha and the family of enzymes from which it descends, called RNAse III, were the original virus-fighters in a single-celled ancestor of animals and plants. \u201cYou can see the footprint of RNAse III in the defence systems through all kingdoms of life,\u201d says Benjamin tenOever, a virologist at Mount Sinai School of Medicine in New York and lead author of the paper. Plants and invertebrates deploy RNAse III proteins in an immune response called RNA interference, or RNAi. When a virus infects a host, the proteins slice the invader\u2019s RNA into chunks that keep it from spreading. Instead of RNAi, vertebrates ward off viruses using powerful interferon proteins. In these animals, Drosha and a related protein regulate genes within the nucleus. But in 2010, tenOever witnessed an odd phenomenon: Drosha left the nucleus of human cells whenever a virus invaded 2 . \u201cThat was weird and made us curious,\u201d tenOever says. His team found that Drosha demonstrates the same behaviour in cells from flies, fish, humans, and plants. To test the hypothesis that Drosha can combat viruses in vertebrates, they infected cells that had been genetically engineered to lack Drosha, and found that the viruses replicated faster. Finally, the team inserted Drosha from bacteria into fish, human and plant cells. The protein appeared to stunt the replication of viruses as well, suggesting this function dates back to an ancient ancestor of all the groups. \u201cDrosha is like the beta version of all antiviral defense systems,\u201d tenOever says. tenOever speculates that RNAse III proteins originally helped bacteria maintain their own RNA, and they later deployed it against the genetic material of viruses. He points out the appearance of the family in immune responses throughout the tree of life. For instance, some CRISPR systems, a virus-fighting response in archaea and bacteria, include RNAse III proteins. Plants and invertebrates deploy the proteins in RNAi. And although vertebrates rely on interferons for viral control, this study shows how Drosha still comes scuttling after viruses, like a Golden Retriever dutifully returning a stick to its owner as if it were a fallen duck. Donald Court, a geneticist at the National Cancer Institute in Frederick, Maryland, calls that finding cool, but he doesn\u2019t buy the evolutionary scenario. \u201cRNAse III is involved in many things, in almost all domains of life,\u201d he explains. But he sees no reason to believe that one anti-viral system evolved into the next. For instance, he says the fact that a CRISPR system includes RNAse III and other CRISPR systems don\u2019t suggests that the proteins were likely acquired for use independently and not inherited. \u201cIt\u2019s a really intriguing story, and the data are good, but you\u2019re talking about processes that happened over millennia so it\u2019s hard to know whether it\u2019s true,\u201d says Bryan Cullen, a virologist at Duke University in Durham, North Carolina. Cullen predicts the paper will prompt researchers who study RNA and infectious diseases to test teneOver\u2019s hypothesis. \u201cThe immune system has been under tremendous pressure to evolve as viruses overcome defenses, and this paper suggests that RNAse III has played an important role in that evolution,\u201d he says. \u201cIt\u2019s like what the Red Queen said to Alice in  Through the Looking Glass , \u2018you have to keep running to stay in one place'.\u201d \n                   The tenOever Lab \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22229", "url": "https://www.nature.com/articles/nature.2017.22229", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Scientists say the industry-funded work confirms that neonicotinoids are harmful, but manufacturers question its conclusions. The largest study so far on the fraught question of whether neonicotinoid pesticides harm bees is providing new ammunition for those who argue against the use of the controversial chemicals. The large-scale field study found that overall, exposure to neonicotinoids harms bee populations. In particular, the pesticides reduce honeybees\u2019 ability to survive their winter hibernation, say researchers. \u201cWe\u2019re showing significant negative effects at critical life-cycle stages, which is a cause for concern,\u201d says Richard Pywell, who studies sustainable land management at the Centre for Ecology and Hydrology near Wallingford, UK, and is co-author of a paper resulting from the experiment, published on 29 June in  Science 1 . However, the work was mainly funded by two major neonicotinoid makers, Bayer CropScience and Syngenta. They question the scientists\u2019 conclusions and defend the pesticides, which are already banned or restricted in several countries. The researchers who did the work say they were totally independent. \n             Mounting concern \n           In recent years, concern has grown among scientists and policymakers that neonicotinoids harm bees; the pesticides are often applied to seeds before they are sown, and can later be found in pollen. But laboratory studies investigating the effects on bee health and behaviour have sometimes been criticized for giving the bees bigger doses of the chemicals than they would experience outdoors. And previous field trials have produced inconsistent results, for example finding harm to wild bees but not to honeybees 2 . To try to settle some of the outstanding questions, a team led by the Centre for Ecology and Hydrology undertook the biggest ever study of its kind, funded with US$3 million from Bayer CropScience and Syngenta, and another \u00a3400,000 (US$520,000) from the institution itself. They distributed three bee species \u2014 honeybees ( Apis mellifera ) and two wild varieties, bumblebees ( Bombus terrestris ) and solitary bees ( Osmia bicornis ) \u2014 across 33 field sites in the United Kingdom, Germany and Hungary growing oilseed rape. Some were placed near crops protected with neonicotinoids, and others in fields where no neonicotinoids were used.\u00a0 Although the study found that neonicotinoids have an overall negative effect on bees, the results aren\u2019t completely clear-cut: the pesticides seemed to harm bees at the UK and Hungarian sites, but apparently had a positive effect on honeybees in Germany. Pywell notes that the German effects were \u201cshort lived\u201d, and the reason for them is unclear. They might be linked in part to the generally healthier state of hives in the German arm of the trial, he speculates. \n             Industry rejoinder \n           The study\u2019s funders have responded by questioning the authors\u2019 data analysis and conclusions. Peter Campbell, a senior environmental specialist at Syngenta, says the data show that there are circumstances in which\u00a0neonicotinoids can be used safely. The study\u2019s \u201cvery negative\u201d conclusion is unfair, he adds. Christian Maus, Bayer\u2019s global lead scientist for bee care, also disputes the authors' conclusions and questions some of their statistical analysis. In a statement, Syngenta, based in Basel, Switzerland, also called the data \u201cvariable\u201d, and Bayer CropScience, headquartered in Monheim am Rhein, Germany, said the study delivered \u201cinconsistent results\u201d. The finding comes at a crucial time for the industry, because the European Union is reviewing a 2013 ban it imposed on the use of neonicotinoid products to coat seeds. The EU is expected to reach a conclusion later this year, and the restrictions could either be removed or extended. Pywell says that he stands by the paper, which was peer reviewed. He also notes that the entire experiment was conducted under the scrutiny of a independent advisory board that included a statistician. The differences between countries are intriguing, he adds, and should be investigated further. But as the industry complains, those who advocate for more control of neonicotinoids have welcomed the results. \u201cYou\u2019ve got to give them 10 out of 10 for effort,\u201d says Dave Goulson, a bee researcher at the University of Sussex in Brighton, UK. The study is \u201cwell designed, well replicated, well funded \u2014 ironically by industry who won\u2019t be best pleased. But the results tally with what has gone before.\u201d \u201cIt\u2019s reached a point where it\u2019s just not plausible to keep denying these things harm bees in realistic studies,\u201d he adds. \u201cI\u2019d say it\u2019s the final nail in the coffin.\u201d Nigel Raine, who studies pollinators at the University of Guelph in Canada, says the study answers a number of debated questions, for example, the finding that neonicotinoids negatively affect honeybees in fields. \u201cThat\u2019s been a question mark in a lot of debates.\u201d \n             Long exposure \n           A separate study published at the same time in  Science 3  looks at the situation in North America.\u00a0Insect researcher Amro Zayed and his team studied how routine use of neonicotinoid pesticides on farms affected bees in Canadian regions where maize (corn) is grown. Their work was funded by the Ontario Ministry of Agriculture, Food and Rural Affairs. \u201cThe knowledge of how much neonicotinoids are found in nature and for how long is very patchy,\u201d says Zayed, who works at York University in Toronto. \u201cOne of the biggest surprises we found was we were detecting neonicotinoids all through the growing season. The duration of exposure was frankly a lot bigger than anybody expected.\u201d Zayed\u2019s team found that honeybees were exposed to \u201ctoxicologically significant\u201d levels of neonicotinoids throughout their active season. In follow-up lab work, the researchers fed bees levels of the chemicals that were equivalent to those observed in the field. They found that the insects had shorter lifespans than undosed bees, and their colonies were less able to maintain healthy queens. A lot of the findings are results that \u201cother researchers have found but their work was criticized as unrealistic\u201d, notes Zayed. Zayed\u2019s study also shows that bees fare worse when exposed to neonicotinoids in combination with a fungicide crop treatment. Raine says that this is an area for future study, along with the country-to-country differences seen by Pywell\u2019s group. \u201cWhat comes out of all these studies is the complexity in the system,\u201d says Raine. \n                   Controversial insecticides linked to wild bee declines 2016-Aug-16 \n                 \n                   Fears for bees as UK lifts insecticide ban 2015-Jul-23 \n                 \n                   Bee studies stir up pesticide debate 2015-Apr-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22190", "url": "https://www.nature.com/articles/nature.2017.22190", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Justices overturn lower-court rulings on policy targeting people from six majority-Muslim countries. The US Supreme Court has reinstated a limited version of President Donald Trump\u2019s temporary order banning travellers from six majority-Muslim countries from entering the United States. The court will hear a legal challenge to the ban in October. The court\u2019s decision, announced on 26 June,  casts doubt on the fate of students and scientists  from these countries who hope to study or work in the United States. It bars citizens of Iran, Libya, Somalia, Sudan, Syria and Yemen from travelling to the United States unless they have a \u201cbona fide\u201d connection with a person or entity in the country. Such a relationship should be formal and documented, the court said. Examples include a person with an offer of admission from a US university or someone who has accepted a job offer from a US company or organization. But that wording leaves room for interpretation, says Brendan Delaney, an immigration lawyer at Leavy, Frank & Delaney in Bethesda, Maryland. \u201cUntil there is some degree of certainty in how they\u2019re going to apply this language, if I were a research scientist affected by this, I would be reticent right now\u201d about making job or travel decisions, he says. \n               boxed-text \n             All US visas are granted at the discretion of immigration officials, who will now have to determine whether applicants from the six travel-ban countries have a \u201cbona fide\u201d relationship to the United States. Delaney notes that even after the government awards a visa, there is no guarantee that the person who receives it can cross the border into the United States. He hopes that US immigration officials will soon clarify how they are interpreting the Supreme Court decision. \u201cRight now, we\u2019re back into a wait-and-see pattern,\u201d Delaney says. \n               Knock-on effects \n             But regardless of the eventual outcome of the case before the Supreme Court, many researchers worry that uncertainty surrounding immigration to the United States \u2014 and perceptions that the country is unwelcoming \u2014 may have already driven away some international students and scientists. \u201cThis is a big worry and concern, not just for the individual nations that have been specified [in the ban], but a broader concern that I certainly have heard from people all over the world,\u201d says Katharine Donato, a sociologist at Georgetown University in Washington DC. She is beginning a research project that she hopes will quantify the policy\u2019s impact on international students\u2019 enrolment in US universities. New York University, which has about 120 students and 12 faculty members and postdocs from the 6 affected countries, said today that it does not expect that any of those people will be directly affected by the Supreme Court decision. But Josh Taylor, the university\u2019s associate vice chancellor for global programmes, still worries about the broader impacts. \u201cIf we start to send this message that US higher education is no longer welcoming of all international students, that could impact a lot of us,\u201d he says. According to  a 31 March white paper from the Institute of International Education  in New York City, more than 15,000 university students \u2014 mostly in graduate programmes \u2014 and 2,100 scholars currently in the United States are from the 6 countries named in Trump\u2019s executive order. \n               Countdown clock \n             Trump said on 14 June that the travel ban would take effect within 72 hours if the Supreme Court lifted injunctions on its enforcement that had been put in place by lower courts. In a statement today, he called the court\u2019s decision \u201ca clear victory for our national security\u201d. The president signed  his first attempt at a travel ban  into law on 27 January. That order blocked citizens of 7 countries \u2014 the 6 affected by today\u2019s ruling, plus Iraq \u2014 from entering the United States for 90 days. It also barred all refugees for 120 days, and Syrian refugees indefinitely. Scientists and students were among those caught up in the ban\u2019s messy aftermath. Several who had accepted jobs in the United States or had plans to study at US universities were unable to enter the country as planned, and some US visa holders who had left the country to travel were temporarily barred from returning. After several federal courts blocked Trump\u2019s order,  the president issued a revised ban on 6 March . That policy is the subject of the legal case now before the Supreme Court. It prevented people from the 6 countries from entering the United States for 90 days, with exemptions for permanent residents and current visa holders. The order also imposed a 120-day ban on refugees from Syria. The policy was immediately challenged in federal court in several states, producing two rulings that blocked the ban from taking effect. The White House asked the Supreme Court to intervene, submitting an emergency request to allow the ban to proceed while the legal proceedings played out. Universities have had a key role in fighting both versions of the travel ban. Washington state, which sued the administration over the original policy,  cited the cases of several students and \u201cmedicine and science interns\u201d  who had planned to spend time at two state universities but were blocked from entering the country. And Hawaii, which challenged the revised ban,  argued that the policy would harm the state by barring students  who had been admitted to the University of Hawaii.  \n                     What Trump\u2019s new travel ban means for science 2017-Mar-06 \n                   \n                     How the fallout from Trump's travel ban is reshaping science 2017-Mar-02 \n                   \n                     Academics must protest against Trump\u2019s travel ban \u2014 but they should do so productively 2017-Feb-07 \n                   \n                     Trump immigration ban upends international work on disease 2017-Feb-01 \n                   \n                     Obama science adviser: Trump immigration ban \u2018an abomination\u2019 2017-Jan-30 \n                   \n                     Meet the scientists affected by Trump\u2019s immigration ban 2017-Jan-29 \n                   \n                     The Supreme Court's 26 June order \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22167", "url": "https://www.nature.com/articles/nature.2017.22167", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Lethal effects from pulses of sound used to probe the sea floor can travel over a kilometre. Powerful sound waves created during offshore surveys for oil and gas can kill microscopic animals at the base of the ocean food chain, according to a new study. And these lethal effects travel much farther than ecologists had previously assumed. Researchers fear that damage to these animals, collectively known as zooplankton, could harm top predators and commercially important species of fish that depend on such species for food. Seismic surveys blast compressed air to produce pulses of sound that can probe the sea floor thousands of metres down for natural resources. At 220\u2013250 decibels, the pulses produced by these air guns are louder than a Saturn V rocket during launch. Scientists have known for decades that whales and other marine mammals that use sound to communicate  change their behaviour in response to such noise 1 . There is increasing evidence that seismic surveys also affect fish 2  and marine invertebrates 3 . And now, researchers have found that the noise from air-gun blasts can kill zooplankton at distances of up to 1.2 kilometres away \u2014 more than two orders of magnitude farther than previously thought. They reported their results 4  on 22 June in  Nature Ecology and Evolution . \u201cWe were quite gobsmacked,\u201d says lead author Jayson Semmens, a marine biologist at the University of Tasmania in Hobart, Australia. Semmens and his team conducted their study off the southeastern coast of Tasmania in 2015. They used sonar and nets to assess populations of zooplankton, including krill larvae and tiny crustaceans called copepods, before and after firing a series of air-gun shots. The team found that zooplankton abundance dropped by 64% within one hour of the blasts. And the proportion of dead zooplankton increased by 200\u2013300% as far away as 1.2 kilometres \u2014 the maximum distance the researchers sampled. This suggests that the impact of the blasts could extend well beyond such distances, Semmens says. \u201cDead bodies in net tows don't lie,\u201d says Doug Nowacek, a marine ecologist at Duke University Marine Laboratory in Beaufort, North Carolina, who was not involved in the study. He suggests the next question for researchers is figuring out what this means for the ocean ecosystem. \u201cIf you start impacting the zooplankton population, that can cause a serious cascade through the food web.\u201d \n               The forgotten ones \n             The results come as US President Donald Trump proposes opening up large swathes of the Atlantic coast of the United States to seismic surveys. The US Bureau of Ocean Energy Management is considering permit requests from six companies to conduct seismic surveys that were denied under former President Barack Obama (see \u2018Under consideration\u2019). As part of that process, the National Oceanic and Atmospheric Administration (NOAA) must also evaluate permit requests from those companies since their proposed activities could affect marine mammals. The NOAA permit requests are open for public comment until 6 July. Although it's unclear if the companies will be able to start seismic surveys, initiating the permit process is part of a larger effort \u2014 laid out in an executive order that Trump issued in April \u2014 to expand US offshore energy development. The study didn't pin down precisely how air-gun blasts kill zooplankton, Semmens says, but the noise they produce probably damages the highly sensitive hair-like receptors that the animals use to navigate. The blast might not kill them all directly, but it could disorient them and make it harder for them to survive. Semmens is planning a follow-on study with a full seismic air gun set-up similar to that used in industrial activities to determine how far the effects of the noise extend. He and his team also want to look at what these blasts do to zooplankton physically. Although most research has focused on the impact of air-gun blasts on marine mammals, Semmens notes, perhaps it\u2019s the invertebrates that are most at risk. \u201cIt could be that our focus has kind of been blinkered because it\u2019s been on whales,\u201d he says. \u201cInvertebrates are the forgotten ones.\u201d \n                     Marine life needs protection from noise pollution 2015-Sep-11 \n                   \n                     Noisy oil exploration disrupts marine life 2011-May-18 \n                   \n                     Environmental concerns delay seismic testing 2009-Aug-18 \n                   \n                     Whale deaths caused by US Navy's sonar 2002-Jan-10 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22173", "url": "https://www.nature.com/articles/nature.2017.22173", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Engineered microbes turn a bacterium's immune response against itself using CRISPR. Genetically modified viruses that cause bacteria to kill themselves could be the next step in  combating antibiotic-resistant infections . Several companies have engineered such viruses, called bacteriophages, to use the CRISPR gene-editing system to kill specific bacteria, according to a presentation at the CRISPR 2017 conference in Big Sky, Montana, last week. These companies could begin clinical trials of therapies as soon as next year. Initial tests have saved mice from antibiotic-resistant infections that would otherwise have killed them, said Rodolphe Barrangou, chief scientific officer of Locus Biosciences in Research Triangle Park, North Carolina, at the conference. Bacteriophages isolated and purified from the wild  have long been used to treat infections in people , particularly in Eastern Europe. These viruses infect only specific species or strains of bacteria, so they have less of an impact on the human body\u2019s natural microbial community, or microbiome, than antibiotics do. They are also generally thought to be very safe for use in people. But the development of phage therapy has been slow, in part because these viruses are naturally occurring and so cannot be patented. Bacteria can also quickly evolve resistance to natural phages, meaning researchers would have to constantly isolate new ones capable of defeating the same bacterial strain or species. And it would be difficult for regulatory agencies to continually approve each new treatment. \n               CRISPR-fuelled death \n             To avoid these issues, Locus and several other companies are developing phages that turn the bacterial immune system known as CRISPR against itself. In Locus' phages, which target bacteria resistant to antibiotics, the CRISPR system includes DNA with instructions for modified guide RNAs that home in on part of an antibiotic-resistance gene. Once the phage infects a bacterium, the guide RNA latches on to the resistance gene. That prompts an enzyme called Cas3, which the bacterium normally produces to kill phages, to destroy that genetic sequence instead. Cas3 eventually destroys all the DNA, killing the bacterium. \u201cI see some irony now in using phages to kill bacteria,\u201d says Barrangou. Another company, Eligo Bioscience in Paris, uses a similar approach. It has removed all the genetic instructions that allow phages to replicate, and inserted DNA that encodes guide RNAs and the bacterial enzyme Cas9. Cas9 cuts the bacterium\u2019s DNA at a designated spot, and the break triggers the bacterium to self-destruct. The system will target human gut pathogens, says Eligo chief executive Xavier Duportet, although he declined to specify which ones. The two companies hope to start clinical trials in 18\u201324 months. Their first goal is to treat bacterial infections that cause severe disease. But eventually, they want to develop phages that let them precisely engineer the human microbiome by removing naturally occurring bacteria associated with conditions such as obesity, autism and some cancers. Both Barrangou and Duportet acknowledge that for now, causal links between the human microbiome and these conditions are tenuous at best. But they hope that by the time their therapies have been proved safe and effective in humans, the links will be better understood. Phages could also allow researchers to manipulate the microbiomes of experimental animals, which could help them to untangle how certain bacteria influence conditions such as autism, says Timothy Lu, a synthetic biologist at the Massachusetts Institute of Technology in Cambridge and a co-founder of Eligo. \n               An engineered solution \n             Other companies are working to get phages to perform different tasks. \u2018Supercharged\u2019 phages, created by a group at Synthetic Genomics in La Jolla, California, could contain dozens of special features, including enzymes that break down biofilms or proteins that help to hide the phages from the human immune system. But engineered phages still have to overcome some hurdles. Treating an infection might require a large volume of phages, says Elizabeth Kutter, a microbiologist at Evergreen State College in Olympia, Washington, and it\u2019s unclear whether this would trigger immune reactions, some of which could interfere with the treatment. Phages could also potentially transfer antibiotic-resistance genes to non-resistant bacteria, she notes. Lu adds that bacteria may still develop resistance even to the engineered phages. So researchers might have to frequently modify their phages to keep up with bacterial mutations. But as  antibiotic resistance spreads , Kutter says, there will be plenty of space for both engineered phages and natural phage therapies, which are also growing in popularity. \u201cI think they\u2019ll complement the things that can be done by natural phages that have been engineered for hundreds of thousands of years,\u201d she says. \n                     Antibiotic alternatives rev up bacterial arms race 2015-May-27 \n                   \n                     Phage therapy gets revitalized 2014-Jun-03 \n                   \n                     Phage on the rampage 2011-Jun-09 \n                   \n                     Engineered viruses fight bacteria 2009-Mar-02 \n                   Reprints and Permissions"},
{"file_id": "546583a", "url": "https://www.nature.com/articles/546583a", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Technology far exceeded expectations in LISA Pathfinder test. Europe\u2019s gravitational-wave hunters are celebrating. On 1 July, a satellite will wrap up its mission to test technology for the pioneering quest to measure gravitational ripples in the stillness of space. Over the past year, the craft has performed much better than many had hoped. That success has convinced the European Space Agency (ESA) to give the go-ahead to a full-scale version able to sense cataclysmic events that can\u2019t be felt on Earth.\u00a0 The LISA Pathfinder mission,  launched in late 2015 , beat its precision target by a factor of 1,000 and quieted critics who have doubted its potential, says project scientist Paul McNamara, an astrophysicist at ESA in Noordwijk, the Netherlands. \u201cThis is not the impossible task that some people believed it was.\u201d\u00a0 Currently set to fly in 2034, the full-scale Laser Interferometer Space Antenna (LISA) will be the space analogue of the Laser Interfero-meter Gravitational-Wave Observatory (LIGO), two machines in the United States \u2014 each with a pair of 4-kilometre-long arms \u2014 that first detected the ripples by  \u2018hearing\u2019 the merger of two black holes . LISA\u2019s three probes will fly in a triangle, millions of kilometres apart, making the mission sensitive to much longer gravitational waves, such as the ripples produced by the collisions of even larger black holes. The mission will bounce laser beams between the three LISA craft \u2014 or, more precisely, between test masses suspended in a vacuum inside each satellite. Taking advantage of the vibration-free conditions of space, it will measure tiny variations in the distances between the test masses that reveal the passage of space-warping gravitational waves. LISA Pathfinder\u2019s goal was to show that such variations could be measured in zero gravity and with a precision of one pico-metre, or one-billionth of a millimetre. High-precision thrusters adjusted Pathfinder\u2019s route so that it would closely follow the gravitational free fall of two test masses inside the craft and not interfere with their orbit. At the same time, the probe bounced a laser beam between the two masses\u00a0\u2014\u00a0a pair of 2-kilogram cubes made of a gold and platinum alloy\u00a0\u2014\u00a0and measured fluctuations in their separation (see \u2018Gravity Laboratory\u2019). The \u20ac400-million (US$447-million) probe was  declared a success  in February 2016, two weeks after LIGO announced its first detection. Pathfinder did not detect gravitational waves\u00a0\u2014\u00a0which would not have appreciable effects over the short distance inside the probe\u00a0\u2014\u00a0but it showed that it could detect motions 100 times smaller than the pico-metre requirement. Since then, the experiment\u2019s performance has improved by another order of magnitude ( M. Armano  et al. Phys. Rev. Lett.    118,  171101; 2017 ). By early June this year, LISA Pathfinder had almost run out of thruster fuel, and mission control used what was left to nudge the spacecraft out of its operating orbit and into its final orbit around the Sun. On 1 July, Pathfinder will stop collecting data, and the spacecraft will be put to sleep for good on 18 July. Pathfinder was \u201ca triumph\u201d, says William Klipstein, a physicist at NASA\u2019s Jet Propulsion Laboratory in Pasadena, California, who works on LISA development but was not involved in ESA\u2019s Pathfinder mission. Its performance \u201cremoves the last major technical barrier for proceeding with a long-planned ESA-led gravitational-wave mission\u201d, he says. In a unanimous decision on 20 June, ESA\u2019s Science Programme Committee officially selected LISA as the third of the agency\u2019s large, or \u20ac1-billion-class, mission in its current science programme. The approval was long-awaited but had been in little doubt after Pathfinder\u2019s success and LIGO\u2019s gravitational-wave discoveries, says Karsten Danzmann, a director of the Max Planck Institute for Gravitational Physics in Hanover, Germany, and Pathfinder\u2019s co-principal investigator. The decision is not final, but it means that industrial partners will now be involved in detailed design and cost projections. Once those are finished, ESA will decide whether to \u2018adopt\u2019 the mission and commit the funding to build it. The United States \u2014 which was an equal partner in the mission until 2011, when it reduced its participation to save costs \u2014 is expected to provide important components.\u00a0 ESA has chosen two other large missions to go ahead before LISA\u00a0\u2014\u00a0one to the moons of Jupiter, slated to launch in 2022, and an X-ray observatory for 2028. This puts LISA on schedule to be launched in 2034. But Pathfinder principal investigator Stefano Vitale, a physicist at the University of Trento in Italy, and others hope that its schedule can be accelerated. ESA\u2019s call for proposals to lead the gravitational-wave observatory \u2014 won by Vitale\u2019s team \u2014 was put out in late 2016, instead of late 2019 as the agency had planned. Vitale and other gravitational-wave researchers hope the agency will push the launch date forward so that LISA can start sending back data before too many of the current key researchers have retired.  \n                 Tweet \n                 Follow @NatureNews \n               \n                     Successful test drive for space-based gravitational-wave detector 2016-Feb-25 \n                   \n                     Gravitational waves: How LIGO forged the path to victory 2016-Feb-16 \n                   \n                     Gravitational waves: 6 cosmic questions they can tackle 2016-Feb-09 \n                   \n                     Freefall space cubes are test for gravitational wave spotter 2015-Nov-17 \n                   \n                     Budget restrictions bite for Europe's space mission hopefuls 2015-Mar-30 \n                   \n                     LISA mission concept \n                   Reprints and Permissions"},
{"file_id": "546585a", "url": "https://www.nature.com/articles/546585a", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Errors could cause researchers to overestimate the rate of photosynthesis when water is scarce. Errors in how scientists account for water loss from leaves may be skewing estimates of how much energy plants make through photosynthesis, according to the latest research. This in turn could jeopardize models of how individual leaves function and even of the global climate. The errors are particularly pronounced when a plant\u2019s water supply is limited \u2014 a condition of increasing interest as plant breeders and climate scientists grapple with the effects of global warming. \u201cIf you\u2019re trying to understand why a crop you\u2019re growing or a particular plant is able to survive and do better under drier conditions, you may misinterpret that,\u201d says plant physiologist David Hanson of the University of New Mexico in Albuquerque. Hanson presented his findings at the annual meeting of the American Society of Plant Biologists in Honolulu, Hawaii, on 25 June. Researchers have long assumed that the main way that plants lose water is through leaf pores called stomata. When water is abundant, the stomata open wide to let carbon dioxide flow in \u2014 maximizing photosynthesis, but allowing water to exit. Plants also lose moisture through a leaf\u2019s waxy outer surface, or cuticle, but this effect has been considered negligible. This understanding, in turn, has shaped how scientists extrapolate the flow of CO 2  into a leaf. Measuring CO 2  inside a leaf requires cumbersome, custom-made equipment, so researchers in the field often use measures of water loss and other factors to calculate the concentration of CO 2  inside. Once they have estimated the internal CO 2  concentration, researchers can calculate how efficiently the plant is converting the gas into food \u2014 a component of primary productivity, a measure that is an important factor in some climate models. But such calculations are based on water loss through stomata, and disregard the water vapour that passes directly through the cuticle. Hanson\u2019s experiments suggest that this is a workable approximation when water is plentiful \u2014 but when it is scarce, and the stomata close, a greater proportion of moisture is lost through the cuticle. Failing to adjust for this could throw off calculations of how well plants convert CO 2  to sugars during photosynthesis, Hanson says. \u201cWhile stomata are closed, this small error is now a massive error,\u201d he adds. Hanson first became aware of this in 2015, when plant physiologist John Boyer of the University of Missouri in Columbia approached him after a seminar. Hanson had just presented data showing his attempts to explain how properties of leaf cells can limit CO 2  capture. Boyer offered Hanson an alternative explanation \u2014 water loss through the cuticle \u2014 and described data that his lab had collected in the 1980s, but that had garnered little attention. Boyer\u2019s team had found that water loss through the cuticle skewed calculations of CO 2  concentrations inside sunflower leaves to be 15% too high when water was abundant and stomata were open ( J. S. Boyer  J. Exp. Bot.   66,  2625\u20132633; 2015 , and  D. T. Hanson  et al. J. Exp. Bot.    67,  3027\u20133039; 2016 ). And when stomata were closed, predicted CO 2  concentrations were six times higher than direct measurements taken inside the leaf. \u201cWithin six months or so of that talk, I started doing my first measures and said, \u2018OK, yes, this is a problem\u2019,\u201d says Hanson. He is now working to simplify those measurements so that more labs can follow suit. Until that happens, measurement errors could be affecting more than just individual lab experiments, says Boyer. \u201cThe carbon dioxide inside the leaf is a central feature of climate models and our understanding of how photosynthesis works,\u201d he says. It is an intriguing issue, says Donald Ort, a plant physiologist at the University of Illinois at Urbana-Champaign. Ort suspects that water loss through the cuticle will be important only under conditions of extreme drought. \u201cI don\u2019t see that it would be something that would impact how we\u2019re estimating global primary productivity, or have any consequence on breeding plants for greater yield,\u201d he says. But Hanson says that in his unpublished studies of rapeseed ( Brassica napus ), a crop harvested for its oil, he found that measurements that did not account for the water lost through the cuticle overestimated water loss through the stomata by an average of 12.6%, even when the plants were well watered. Even mild drought could be enough to affect water-use measurements, agrees Susanne von Caemmerer, a plant physiologist at the Australian National University in Canberra. \u201cWe have models that try to capture global carbon dioxide uptake and water loss,\u201d she says. \u201cThat\u2019s where this is really going to matter.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Ancient oak's youthful genome surprises biologists 2017-Jun-19 \n                   \n                     Italy rebuked for failure to prevent olive-tree tragedy 2017-Jun-07 \n                   \n                     Trees in eastern US head west as climate changes 2017-May-17 \n                   \n                     Video: Sunflowers move to internal rhythm 2014-Jul-15 \n                   \n                     Climate change linked to shrinking leaves 2012-Jul-04 \n                   \n                     American Society of Plant Biologists annual meeting \n                   Reprints and Permissions"},
{"file_id": "nj7660-693b", "url": "https://www.nature.com/articles/nj7660-693b", "year": 2017, "authors": [{"name": "Virginia Gewin"}], "parsed_as_year": "2006_or_before", "body": "Female first authors' work is cited less often. Astronomy publications with first authors who are female receive roughly 10% fewer citations than do those with male first authors, finds a study in  Nature Astronomy  ( N. Caplar  et al .  Nature Astron.   1 , 0141; 2017 ). In 2014, the study's lead author, Neven Caplar, a PhD student in astronomy at the Swiss Federal Institute of Technology in Z\u00fcrich, attended a talk at the institute on women in science by Meg Urry, an astronomer at Yale University in New Haven, Connecticut. Inspired by Urry's presentation, Caplar and two fellow PhD students sought to confirm anecdotal evidence of gender bias in astronomy. They used data collated from the Astrophysics Data System, a comprehensive database of astronomy and physics publications maintained by the Smithsonian Astrophysical Observatory in Cambridge, Massachusetts, augmented with information from the preprint server arXiv. The trio analysed almost 150,000 articles that were published in 5 major astronomy journals between 1950 and 2015. They found that the percentage of papers with a female first author rose from less than 5% in the 1960s to about 25% in 2015. But since 1985, astronomy publications with a male first author have received about 6% more citations than those led by a woman \u2014 a figure that Caplar and his co-authors suspected could reflect a hidden gender bias. To determine the expected number of citations for publications led by women, the team trained an algorithm using non-gender-specific data \u2014 including the seniority of the paper's first author and other criteria \u2014 that were derived from publications with male first authors. They then used the algorithm to predict the number of citations for papers with female first authors and compared this to the actual number the papers had collected. Caplar notes that the trio's study cannot determine the drivers of gender bias. But if women leave the field in greater numbers or earlier in their career than do men, for example, they would not be in a position to present their findings at conferences or otherwise promote their papers in ways that could boost citations. \n                     Machine-learning algorithm quantifies gender bias in astronomy \n                   \n                     Nature  Focus on gender bias in astronomy \n                   \n                     Nature  Special on women in science \n                   \n                     ETH Zurich \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22115", "url": "https://www.nature.com/articles/nature.2017.22115", "year": 2017, "authors": [{"name": "Katherine Bourzac"}], "parsed_as_year": "2006_or_before", "body": "Just one atom thick, the magnet will allow researchers to perform previously impossible experiments. The  number of 2D materials has exploded  since the discovery of graphene in 2004. However, this menagerie of single-atom-thick semiconductors, insulators and superconductors has been missing a member \u2014 magnets. In fact, physicists weren\u2019t even sure that 2D magnets were possible, until now. Researchers report the first truly 2D magnet, made of a compound called chromium triiodide, in a paper published on 7 June in  Nature 1 . The discovery could eventually lead to new data-storage devices and designs for quantum computers. For now, the 2D magnets will enable physicists to perform previously impossible experiments and test fundamental theories of magnetism. Pablo Jarillo-Herrero, a condensed-matter physicist at the Massachusetts Institute of Technology in Cambridge, and Xiaodong Xu, an optoelectronics researcher at the University of Washington in Seattle, were searching for a 2D magnet separately before meeting in 2016. They decided to combine forces to investigate. \u201cIt\u2019s a matter of principle \u2014 there is a big thing missing,\u201d says Jarillo-Herrero. \n             Magnetic personality \n           Xu and Jarillo-Herrero worked with chromium triiodide because it\u2019s a crystal comprising stacked sheets that can be separated using the 'Scotch tape method': a way of making 2D materials by using adhesive tape to peel off ever thinner layers. The scientists were also attracted to the compound because of its magnetic properties. Like refrigerator magnets, chromium triiodide is a ferromagnet, a material that generates a permanent magnetic field owing to the aligned spins of its electrons. Chromium triiodide is also anisotropic, meaning that its electrons have a preferred spin direction \u2014 in this case, perpendicular to the plane of the crystal. These fundamental properties made Xu and Jarillo-Herrero suspect that chromium triiodide would retain its magnetic characteristics when stripped down to a single layer of atoms. That\u2019s something other 2D materials can\u2019t do. Jarillo-Herrero\u2019s group grew chromium triiodide crystals and flaked off single- and multi-layer sheets, while Xu\u2019s lab studied the samples using a sensitive magnetometer. The team found that not only was a single atomic layer of chromium triiodide magnetic, but also that this property emerged at what is considered a relatively warm temperature: about \u2013228 \u00b0C. They also discovered that a two-layered sheet of this material isn\u2019t magnetic, but when a third is added the substance becomes a ferromagnet again. The material remains magnetic if a fourth layer is added, but gains other properties the researchers say they\u2019re still investigating. \n             Method in the magnets \n           Jarillo-Herrero and Xu aren\u2019t the only ones studying 2D magnets. In late April, another group of researchers published their observations of magnetism in an ultrathin crystal made of chromium, germanium and tellurium 2 . A true 2D magnet would retain its magnetism at the single-atom layer, but this ultrathin crystal was only magnetic at multiple layers. Both results are significant, however, says Nitin Samarth, a condensed-matter physicist at Pennsylvania State University in University Park, who was not involved with the work. Samarth wrote a  commentary accompanying the recent studies . Before these discoveries, \u201cwe never had a generic method for creating truly 2D magnetic materials,\u201d he says. Researchers have been trying to make and study ultrathin magnets since the 1970s, but all the resulting materials contained holes and bumps, and weren\u2019t truly 2D. Physicists would like to find a 2D magnet that works at room temperature and that doesn\u2019t have to be protected from oxygen, so that it might eventually be  used in consumer electronics . For now, Jarillo-Herrero and Xu are looking for other 2D magnets in chromium triiodide\u2019s chemical family, and further exploring the one they\u2019ve created. Jarillo-Herrero wants to layer the 2D magnet with a 2D superconductor and see what happens. In a magnet, the electron spins are all aligned; in a superconductor, they\u2019re arranged in opposite pairs. \u201cDoes the superconductor destroy the ferromagnet, or does the ferromagnet destroy the superconductor?\u201d he wonders. \u201cIt was just not possible to do this experiment before.\u201d It\u2019s too early to tell whether there\u2019s something fundamentally new here in terms of the physics, says Samarth. But now that physicists can experiment with 2D magnets, they\u2019re excited to try to find out. \n               See the related News & Views article, 'Magnetism in flatland'. \n             \n                   Physics of 2D exotic matter wins Nobel 2016-Oct-04 \n                 \n                   Atom-thin 'borophene' joins 2D materials club 2015-Dec-17 \n                 \n                   Physicists announce graphene\u2019s latest cousin: stanene 2015-Aug-03 \n                 \n                   The super materials that could trump graphene 2015-Jun-17 \n                 \n                   Batches of ultra-thin transistors made from 2D materials 2015-Apr-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22131", "url": "https://www.nature.com/articles/nature.2017.22131", "year": 2017, "authors": [{"name": "Tim Hornyak"}], "parsed_as_year": "2006_or_before", "body": "Population crash feared amid a fad for badger meat. On Japan\u2019s Kyushu Island, farmers regularly trap and spear local badgers, which are regarded as pests. But ecologists say the practice is getting out of hand. In Kyushu\u2019s Kagoshima Prefecture, they note, killings spiked from a few hundred to more than 4,000 last year \u2014 and that might lead to a population crash. \u201cIf the cull continues at this pace, there\u2019s a possibility the Japanese badger could become extinct,\u201d says Yayoi Kaneko, an ecologist at Tokyo University of Agriculture and Technology. A culinary fad for badger meat in Japan's restaurants is also taking off, although it's unclear if that is driving the culls, or is a response to the ready supply. Japan\u2019s government should intervene in the cull and take scientific advice on whether it is sustainable, the scientists say. \n             Ecological crisis \n           Kaneko and two other ecologists, Christina Buesching and Chris Newman at the University of Oxford, UK, first raised their concerns in a  correspondence  published in  Nature  on 13 April 1 . They warned that the rise in killings could lead to an \u201cecological crisis\u201d unfolding, and say that the cull is being carried out \u201cwithout scientific advice or strategic planning\u201d. The Japanese badger ( Meles anakuma ) is endemic to Japan. It is smaller than its European counterpart and has less-distinct facial stripes. Confusingly, Kaneko notes, the Japanese word used to describe the badger \u2014  anaguma,  or \u2018hole bear\u2019 \u2014 can also be used for two other species that are regularly trapped by farmers: raccoon dogs (celebrated as trickster animals in Japanese folk tales) and raccoons, an invasive species in Japan. Local governments are increasingly promoting the hunting of pests in efforts to mitigate crop damage, and it seems that badgers are being heavily affected by the culls, Kaneko says. Kagoshima government officials say the prefecture does not track badger populations, but confirmed that 4,354 badgers were culled in the 12 months to March 2016, up 70% on the preceding year, and an order of magnitude more than in previous years. \u201cThis unique population should be monitored and regulated under scientific control,\u201d says Alexei Abramov, a researcher at the Russian Academy of Sciences in St Petersburg, who \u2014 together with Kaneko \u2014 is an assessor of the Japanese badger\u2019s status on the Red List maintained by the International Union for Conservation of Nature (IUCN). The badger is not currently listed as endangered by the IUCN, but Kaneko says that may soon change on the basis of her estimates of the species\u2019 population density, which show that up to 70% of badgers in Kagoshima have been culled in the past few years. \n             Licence to kill \n           Whether the cull is illegal \u2014 as Kaneko also asserts \u2014 is unclear. The government of Kagoshima Prefecture says the cull is being carried out in accordance with a national environment ministry law that allows pests, including Japanese badgers, to be hunted under licence. It adds that it is compiling badger data from reports by hunters and others who have permission to trap the animals. But Kaneko argues that because the culling is excessive, it does not comply with details prescribed by the environment ministry. A spokesman for Japan\u2019s environment ministry who did not want to be named confirmed that culls of the Japanese badger are permitted \u2014 but said that the ministry wasn\u2019t aware of detailed information concerning recent operations on Kyushu Island. Guillem Molina-Vacas, a biologist associated with the University of Barcelona in Spain, also thinks the badger\u2019s IUCN classification will soon change if the culling campaigns aren\u2019t regulated. An instance from Japan\u2019s history doesn\u2019t inspire confidence, he notes: in the nineteenth century, Japanese farmers were permitted to use the poison strychnine to kill a subspecies of grey wolf, known as the Hokkaido or Ezo wolf; it is now extinct. \u201cThat example should not be repeated,\u201d Molina-Vacas says. \n                   Japan: Unjustified killing of badgers in Kyushu 2017-Apr-12 \n                 \n                   Scientists track badger\u2013cow encounters to understand cattle TB 2016-Aug-05 \n                 \n                   UK official defends badger cull 2013-Jun-06 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22108", "url": "https://www.nature.com/articles/nature.2017.22108", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Rare astronomical observation shows effects of relativity. The Hubble Space Telescope has spotted light bending because of the gravity of a nearby white dwarf star \u2014 the first time astronomers have seen this type of distortion around a star other than the Sun. The finding  once again confirms Einstein\u2019s general theory of relativity . A team led by Kailash Sahu, an astronomer at the Space Telescope Science Institute in Baltimore, Maryland, watched the position of a distant star jiggle slightly, as its light bent around a white dwarf in the line of sight of observers on Earth. The amount of distortion allowed the researchers to directly calculate the white dwarf\u2019s mass \u2014 67% that of the Sun. \u201cIt\u2019s a very difficult observation with a really nice result,\u201d says Pier-Emmanuel Tremblay, an astrophysicist at the University of Warwick in Coventry, UK, who was not involved in the discovery. The findings were published in  Science 1  and presented at a meeting of the American Astronomical Society in Austin, Texas, on 7 June. White dwarfs are the remains of stars  that have finished burning their nuclear fuel. The Sun will eventually become one. Sahu\u2019s team studied a white dwarf known as Stein 2051 B, in the constellation Camelopardalis. At 5 parsecs (17 light years) from Earth, it is the sixth-nearest white dwarf. Because it is so close, it appears to move quickly across the sky compared with more-distant stars. Sahu and his colleagues realized that during 2014 it would pass directly in front of a background star that lies around 1,500 parsecs, or 5,000 light-years, away. They signed up for time on Hubble to watch the event. In eight observations between October 2013 and October 2015, the background star seemed to shift back and forth slightly. The shift was so small it was equivalent to a person in London watching an ant crawl across a coin in Moscow, but it was enough to confirm that the gravity of Stein 2051 B was bending the light of the background star. In 1919, British astronomer Arthur Eddington and his team watched light bending around the Sun during a total solar eclipse, confirming Einstein\u2019s theory. Researchers have since seen light from distant galaxies bending around the gravity of intervening galaxies, but the new work is the first time anyone has observed a single object \u2014 the white dwarf \u2014 seemingly cause a background star to shift. The phenomenon is known as astrometric microlensing, and there may be many more examples to come, says Martin Dominik, an astronomer at the University of St Andrews, UK. The European Space Agency\u2019s Gaia space telescope is mapping the precise positions of a billion stars and may spot as many as 1,000 instances of such microlensing, Dominik says. Sahu\u2019s team has already started another project to look for this phenomenon using Proxima Centauri, which at 1.3 parsecs (4 light-years) away is the nearest star to Earth. It is passing a background star now, and the team has obtained a couple of observations with Hubble, Sahu says. \n                   Dead star spotted eating planetary leftovers 2015-Oct-21 \n                 \n                   White dwarf acts as cosmic magnifying glass 2014-Apr-17 \n                 \n                   Massive double star is latest test for Einstein\u2019s gravity theory 2013-Apr-25 \n                 \n                   Space Telescope Science Institute \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22200", "url": "https://www.nature.com/articles/nature.2017.22200", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Researchers from ethnic minorities are more likely to be discouraged from taking parental leave. A survey of 741 US postdoctoral researchers has found that their ability to take time off after the birth or adoption of a baby varies widely depending on the person's funding source and principal investigator. Postdocs from ethnic minorities were more likely to report that their principal investigator discouraged them from taking time off. Twenty per cent of Asian respondents and 17% of participants from other under-represented minority groups, such as African Americans, said that their boss discouraged leave. Only 9% of white respondents reported the same. \u201cWe think about mothers being driven out of science, but there are also subgroups that are especially vulnerable,\u201d says Jessica Lee, lead author of  the report  and a lawyer at the Center for WorkLife Law at the University of California Hastings College of the Law in San Francisco. \u201cThat\u2019s something that isn\u2019t really being raised in a lot of the conversation about this.\u201d Postdocs who are paid by an external funder, such as through a fellowship, were particularly vulnerable. The report also includes a survey of 66 institutions, which found that 44% did not give externally funded postdoc mothers time off of any kind after they had given birth (see 'Postdocs and parental leave'). This included paid and unpaid leave during which their jobs would be protected. Paternity-leave policies were even less common. Just 15% of externally funded postdocs and 39% of directly empoyed postocs had the option of paid paternity leave at their institutions. Fathers also reported having to fight the stereotype that men do not need time away from work to provide care. The analysis, published on 21 June, was conducted by the Center for WorkLife Law and the National Postdoctoral Association in Rockville, Maryland. Study participants included men and women, because they were not randomly selected so might not reflect the general US postdoc population. Women, biologists and US citizens or permanent residents were over-represented in the pool of respondents. Nevertheless, the results highlight the difficulty faced by postdocs. This group has a complicated mix of employment statuses and funding sources, and often lacks the structured policies that are in place for graduate students and faculty members, says Lee. \u201cThe postdoc situation is very unique because they often feel they have no one to turn to,\u201d she says. \u201cOne of the first steps to combating that is for there to be formal written institutional policies.\u201d\u00a0 \n                   Battle over US overtime pay rules leaves many postdocs in limbo 2016-Dec-01 \n                 \n                   Young scientists ditch postdocs for biotech start-ups 2016-Nov-01 \n                 \n                   Young, talented and fed-up: scientists tell their stories 2016-Oct-26 \n                 \n                   The plight of young scientists 2016-Oct-26 \n                 \n                   US law could increase postdoc pay \u2014 and shake up research system 2016-May-19 \n                 Reprints and Permissions"},
{"file_id": "546193a", "url": "https://www.nature.com/articles/546193a", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "European Commission reveals widespread delays by the country\u2019s authorities to halt spread of deadly plant disease. A vicious pathogen that is destroying historic olive groves in Puglia, southern Italy, is marching north and threatens to reach the rest of Europe. Yet Italian authorities last year failed to track the infection\u2019s spread, and didn\u2019t follow containment plans agreed with the European Commission, according to an audit released last week by the commission. Scientists in the region aren\u2019t surprised by the criticism: their efforts to stop the infection have been repeatedly hampered over the past four years, since they first suspected that the disease was caused by the bacterium  Xylella\u00a0fastidiosa . \u201cThe situation is ridiculous,\u201d says plant pathologist Giovanni Martelli at the University of Bari in northern Puglia. \u201cThe authorities have always moved too slowly, when quick action was needed,\u201d he says. The pathogen \u2014 for which there is no cure \u2014 had never been seen in Europe before it was spotted in Puglia in 2013. It probably arrived from the Americas, where it is endemic. Researchers established that it was causing olive quick decline syndrome (OQDS) in Puglia, but protesters challenged their findings. In 2015, a local public prosecutor, prompted by angry environmentalists protesting about the felling of ancient olive trees, even  opened a criminal investigation  into whether researchers had actually caused the infection themselves. The commission\u2019s audit, published on 31\u00a0May, includes a litany of failures by Italian authorities. It says that systematic monitoring of the infection began too late, and that there were \u2018excessive delays\u2019 in uprooting some infected trees. And the report charges that national and regional authorities have disbursed little more than half of the \u20ac10\u00a0million (US$11.2\u00a0million) budgeted for containment measures. Data obtained by  Nature  add further evidence of a slow response. In most of 2016, Italian laboratories processed almost no  Xylella  samples \u2014 indicating that monitoring had almost ceased (see \u2018Lab drought\u2019). Authorities did not respond to requests for comment. The commission is worried that  X.\u00a0fastidiosa pauca  \u2014 the subspecies now known to cause OQDS \u2014 could threaten the whole of Europe\u2019s olive industry if it is not contained. But the commission also has broader concerns. New monitoring programmes that it coordinates have now identified several other subspecies of  Xylella  in other European Union countries. In May, Spanish authorities even reported that the much-feared  X. fastidiosa fastidiosa \u2014 the cause of Pierce\u2019s disease, which periodically wipes out vineyards in California \u2014 had been spotted on a grapevine on the Spanish island of Mallorca. That infection was easily contained, but scientists are worried that as-yet-undiscovered subspecies may launch epidemics in other fruit crops. \n               Italian tragedy \n             The small town of Oria exemplifies the struggle to control the devastation hitting southern Italy\u2019s olive groves. Two years ago, environmentalists chained themselves to ancient trees there to prevent them being uprooted. They won a pyrrhic victory: trees all around the area are now dying and  Xylella  has been declared endemic there. The strife in Oria started after Italy declared a state of emergency for the disease in early 2015 and appointed a military-police general, Giuseppe Silletti, to begin radical containment measures, including felling healthy trees around infected ones. Following EU regulations, Silletti drew up a map of the infected areas, outlining a 20-kilometre buffer zone that was mostly free of infection, where authorities were to monitor trees with particular care. Oria, which became a hotspot of protest, was near its northern border. Puglia\u2019s public prosecutor suspended the destruction of trees in the region as his investigation continued. Silletti resigned in December 2015, saying that his ability to implement his containment plan had been blocked at every turn. The public prosecutor did not lift his ban until July 2016, after the commission threatened to report Italy to the European Court of Justice. Efforts to halt the infection have hit other roadblocks. Early in 2016, Puglia\u2019s regional governor, Michele Emiliano, announced that a task force would replace Silletti\u2019s emergency forces, but its exact composition and mandate have never been made public. In April, the commission defined a new, more northerly, containment zone that was initially infection-free (see \u2018Quick decline\u2019), writing off the southernmost tip of Puglia \u2014 including Oria \u2014 as a region of endemic  Xylella  infection. But, as the commission\u2019s auditors noted after their visit to Puglia in November 2016, systematic monitoring of olive trees had not started until the end of August 2016 \u2014 inactivity that increased the risk of the infection\u2019s spread, their report says. Results of intense monitoring at the end of 2016 now show almost 900  Xylella -positive plant samples from the new containment zone, according to a subset of data that has been made public. The commission has invested about \u20ac10\u00a0million in international research programmes to study  Xylella , but the region of Puglia has not yet honoured its pledges to support local research. It announced projects worth \u20ac2.5\u00a0million last September, after a competitive call for grants the previous year, but the scientists involved have not yet received the money. Some protestors still don\u2019t believe that  Xylella  is causing OQDS. The prosecutor\u2019s investigation into Puglian scientists will close if a prosecution is not made by next month. In mid-May, some environmentalists sent a new complaint to the prosecutor\u2019s office, saying that research programmes were unjustly ignoring other possible causes of the infection, such as a fungus (although the commission has already ruled out that possibility). Meanwhile, widened surveillance has spotted subtypes of  Xylella  in France, Germany, Switzerland and Spain\u2019s Balearic Islands, including Mallorca, where the brisk tourism trade increases the risk of the infection spreading. \u201cWe are very concerned,\u201d says Cinta Calvet, who heads a plant protection programme at IRTA, Catalonia\u2019s institute for agricultural research and technology in Barcelona. The city is a hub for visitors to the Balearics. Such an array of subspecies suggests that  Xylella  has been introduced into Europe many times, EU researchers say \u2014 and more introductions may yet be found. What\u2019s more, it is now clear that genes flow \u201crelatively easily\u201d between the different subspecies, says Rodrigo Almeida, who studies  Xylella  at the University of California, Berkeley. He and his team published their findings in March ( H.\u00a0D.\u00a0Coletta-Filho  et\u00a0al. Phytopathology    107,  305\u2013312; 2017 ). Such gene flow increases the risk that different subspecies could recombine to create more-pathogenic versions of  Xylella , he says \u2014 another reason to contain Italy\u2019s outbreak urgently. There is some good news. Scientists in Puglia have identified two varieties of olive tree that are relatively resistant to the disease. Last month, the commission proposed that these could be planted in infected areas, to replace dead trees. But work to develop fully resistant trees could take a decade or more, says Martelli. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alison_c_abbott \n               \n                     Gridlock over Italy\u2019s olive tree deaths starts to ease 2016-May-18 \n                   \n                     Italian scientists under investigation after olive-tree deaths 2015-Dec-21 \n                   \n                     Italian scientists vilified in wake of olive-tree deaths 2015-Jun-01 \n                   \n                     Orange bugs unpeeled 2000-Jul-13 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22096", "url": "https://www.nature.com/articles/nature.2017.22096", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Withdrawal from global pact may take almost four years \u2014 which could give the winner of the 2020 presidential race the final word. US President Donald Trump has decided to withdraw the United States from the 2015 Paris climate accord, after months of heated debate among members of his administration.  More than 190 nations agreed to the pact  in December 2015, pledging to hold average global temperatures to 1.5\u2013 2\u2009\u00b0C above pre-industrial levels . \u201cThe United States will withdraw from the Paris climate accord but begin negotiations to re-enter either the Paris accord or an entirely new transaction on terms that are fair to the United States and its businesses, workers and taxpayers,\u201d Trump said during a press conference in the White House rose garden on 1 June. \u201cThis agreement is less about the climate and more about other countries gaining a financial advantage over the United States.\u201d The president added that \u201cas of today,\u201d the United States would stop implementing its Paris pledges, including contributions to  the Green Climate Fund to help developing countries  deal with the effects of climate change. But Trump also pledged to \u201censure that the United States remains the world leader on environmental issues\u201d. The mechanics of the US exit are complicated. The terms of the Paris agreement prevent the United States from withdrawing from the pact for four years, which means that the final word on US participation would not come before November 2020 \u2014 around the time of the next presidential election. Meanwhile, the United States remains a party to the United Nations Framework Convention on Climate Change (UNFCCC), the foundational agreement under which the Paris accord was negotiated. This means that the country is likely to participate to some degree in international climate talks, just as it did when former President George W. Bush pulled out of another global climate pact \u2015 the 1997 Kyoto Protocol. In a statement, the UNFCCC said that the Paris agreement \u201ccannot be renegotiated based on the request of a single Party\u201d. \n               Changing of the guard \n             Trump's announcement fulfils one of his campaign promises and plays well to his core Republican supporters. But it goes against the wishes of many US business leaders \u2014 including some representing fossil-fuel interests \u2014 who had lobbied fiercely to remain in the agreement. Twenty-five companies, including technology giants Apple, Facebook and Google, took out an advertisement in major newspapers on 1 June arguing that exiting the Paris accord would harm US economic competitiveness. The White House has also faced fierce pressure to participate in the Paris agreement from the leaders of other nations, who have vowed to push forward with or without the United States. China, which has overtaken the United States to become the world\u2019s largest greenhouse-gas emitter, has said that it will continue to uphold its Paris pledge. China is expected to announce a new climate partnership with the European Union on 2 June. But it is not clear whether China and the EU can fill the leadership void left by the United States, which  under President Barack Obama played a major part in negotiating the Paris agreement . \u201cI think it\u2019s very hard to fill the American shoes here,\u201d says David Victor, a climate-policy expert at the University of California, San Diego. \u201cThis is more about the diminishing of American leadership and credibility than about the rise of others \u2014 yet.\u201d He notes that even before Trump intervened, the United States was probably not going to meet its Paris commitment, and many other industrialized countries are likely to come up short. \n               Climate impact of US exit \n             Trump's move could still give some countries the political cover to scale back their efforts to reduce greenhouse-gas emissions, says Niklas H\u00f6hne, a founding partner at the NewClimate Institute in Cologne, Germany. But the US decision does not yet spell doom for the climate itself. That\u2019s because big companies and US states have said that they will go on with their own plans to reduce greenhouse-gas emissions, and energy markets continue to shift away from coal and toward renewable energies. \u201cEven with the Trump administration in place, the global trend toward renewable energies is continuing \u2014 including in the United States,\u201d H\u00f6hne says. An analysis by the Climate Action Tracker, a consortium of researchers, suggests that climate-change policies instituted by Obama would have cut US greenhouse-gas emissions by 10% below 2005 levels in 2025. That is well short of the country's Paris pledge to reduce emissions by 26% over the same period.\u00a0 The consortium also estimates that US emissions would remain relatively flat if Trump succeeds at rolling back those Obama policies, increasing the country's total greenhouse-gas emissions by 400 million tonnes of carbon dioxide by 2030, compared with previous projections. By contrast, the analysis finds, China and India's efforts to shift from coal to renewable energy are gaining momentum, and could reduce projected emissions by 2-3 gigatonnes of CO 2  by 2030. \n                 Tweet \n                 Follow @NatureNews \n               \n                     How Trump plans to wipe out Obama-era climate rules 2017-Mar-28 \n                   \n                     Trump nominee backs Paris climate agreement and questions Iran nuclear deal 2017-Jan-11 \n                   \n                     Paris climate deal to take effect as EU ratifies accord 2016-Oct-04 \n                   \n                     Obama\u2019s science legacy: climate (policy) hots up 2016-Aug-23 \n                   \n                     Paris climate deal: what comes next 2016-Apr-22 \n                   \n                     Nations approve historic global climate accord 2015-Dec-12 \n                   \n                     Is the 2\u2009\u00b0C world a fantasy? 2015-Nov-24 \n                   \n                     Nature  special: 2015 Paris climate talks \n                   Related external links Reprints and Permissions"},
{"file_id": "546197a", "url": "https://www.nature.com/articles/546197a", "year": 2017, "authors": [{"name": "Inga Vesper"}], "parsed_as_year": "2006_or_before", "body": "Researchers refuse to sit on evaluation panels after government bans international participation. Researchers in Romania are stepping up protests against controversial government science reforms. Hundreds of scientists at leading research institutions say they will refuse to sit on national panels that assess and award grants, after the Romanian researchers\u2019 association Ad\u00a0Astra called for the boycott on 30\u00a0May. But not all scientists in the country support the move. Since Romania\u2019s current government took power in January, it has replaced formerly independent research councils with state-controlled bodies and has thrown international scientists off review panels. Panels can now only use international scientists to help select grants if no Romanian expert can be found\u00a0\u2014\u00a0and even then, only if government officials approve it. The government has told Romanian media that the changes are to help \u201ccapitalize on Romania\u2019s national potential\u201d. But researchers say that they are the latest in a series of policy backslides, whereby Romania\u00a0\u2014\u00a0which this year celebrates a decade in the European Union\u00a0\u2014\u00a0is retreating from international scrutiny of its research funding, and reintroducing political interference into the grant process. \u201cIt is inconceivable for an EU country to intentionally forbid European expert evaluators to participate in national competitions for funding research,\u201d says Daniel David, vice-rector for competitiveness at Romania\u2019s Babe\u0219-Bolyai University in Cluj-Napoca. \u201cJust by this decision, researcher competition gets under political influence,\u201d he says. \n               Papers please \n             Last month, Romania\u2019s government said that scientists had to provide certificates showing that they have their university\u2019s permission to participate in the evaluation process. Officially, this is to provide confirmation of a researcher\u2019s work status at their organization \u2014 but Ad Astra sees the paperwork as a government ploy to approve only researchers who won\u2019t be too critical of grant applications. Its boycott asks researchers not to provide the certificates. \u201cThe degradation of research management in Romania has reached a worrisome level,\u201d says Ad Astra member Lucian Ancu, who adds that he has received many messages of support for the boycott. The Romanian research ministry did not respond to requests for comment. After Romania joined the EU in 2007, its government hoped to encourage local scientists to apply for excellence-based European research funds. In 2010, the government introduced laws to increase domestic merit-based research assessments and reduce political interference in grants. Those policies were popular with the most capable scientists at top universities, says Daniel Funeriu, Romania\u2019s research and education minister from 2009 to 2012. But others resented them, he says. In 2012,  some of the reforms were rolled back , and the latest moves to exclude overseas experts effectively complete the reversal of these policies, says Funeriu. The government can now decide who gets grants according to its own set of priorities, he says, adding that the risk is that money is distributed to a political clientele and not to excellent science. The European University Association (EUA) in Brussels says that it deplores the research changes. On 30\u00a0May, it issued a statement calling them a \u201cworrying development\u201d. The number of nationally funded projects has dropped, and researchers say that calls for excellence-based grants have been shelved, adds Lesley Wilson, the EUA\u2019s secretary-general. She notes that the reforms are part of a long chain of policy changes, which together \u201cdo not allow universities to develop long-term strategies\u201d. But not all scientists in Romania support the boycott. \u201cA lot of people were really hurt by the meritocratic system, so they like the status quo,\u201d says Costin Raiciu, a computer scientist at the University Politehnica of Bucharest. The boycotting scientists pledge that they will rejoin the approval process only when international experts are re-admitted. But the reforms might not be reversed, owing to the split between academics inside Romania, Ancu and Raiciu say. If they are not rolled back, Raiciu worries that many of the country\u2019s experienced researchers, tempted back to Romania by the merit-based grant system, will leave again. \u201cWithout [merit-based] funding, people would either give up research altogether or move out of the country,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Corruption: Good governance powers innovation 2015-Feb-18 \n                   \n                     On the mend 2014-Nov-05 \n                   \n                     Romanian science in free fall 2013-Aug-21 \n                   \n                     Romania's high hopes for science 2011-Jan-12 \n                   \n                     Ad Astra statement \n                   \n                     European University Association statement \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22136", "url": "https://www.nature.com/articles/nature.2017.22136", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Agency plans to set up a separate fund for early- to mid-career investigators to help lower average age of NIH grantees. Following backlash from the scientific community, the US National Institutes of Health (NIH) has decided to drop a controversial proposal to cap the number of grants from the agency that an investigator can hold at any one time. The NIH announced on 8 June that it will instead create a special fund \u2014 drawn from its existing budget \u2014 for  early- and mid-career scientists  in an attempt to lower the average age of the researchers it supports. The Next Generation Researchers Initiative will initially set aside US$210 million for this fund, but the amount would grow to $1.1 billion per year in five years. It will be for researchers with less than 10 years\u2019 experience as an NIH-funded principal investigator whose grant proposals would have been rejected \u2014 despite having received high scores from peer-review committees \u2014 owing to a lack of money. The agency\u2019s  previous attempt to free up funds for younger researchers , announced in May, would have limited investigators to the equivalent of three R01 grants \u2013 the most common type awarded to individuals. The agency justified the decision by pointing to studies suggesting that a lab\u2019s productivity decreases once it holds a certain amount of grants, probably because the lead investigator\u2019s time is spread too thinly. \n             Pushing pause \n           Many praised the NIH\u2019s effort to increase funding for younger scientists, who often have  more difficulty receiving grants than do their older colleagues . But others complained that the agency\u2019s proposed point-based scoring system would make collaborations difficult and penalize labs that were productive. Some challenged NIH\u2019s interpretation of its productivity data, saying that the trend didn\u2019t apply to all labs, and that groups with three or four R01s were more productive than labs with only one. \u201cThe original plan was still a work in progress when we decided we didn\u2019t have sufficient confidence in it,\u201d said NIH director Francis Collins in a press call after the presentation. He added that the agency is \u201cpushing pause\u201d on the points-based system. \u201cWe realised it needs a lot more study.\u201d Larry Tabak, the agency's principal deputy director, presented its new plan at the NIH director\u2019s advisory council meeting in Bethesda, Maryland. The agency will award funding to early-career researchers whose grant proposals received scores in the top 25th percentile and to mid-career researchers who would lose all funding if their high-scoring grants were not renewed. \n             Taking stock \n           Collins expects that $210 million will be sufficient to cover all the researchers who fall into these categories. The NIH will immediately begin creating an inventory of investigators who meet these criteria, he says, meaning that researchers who have already been denied a grant in 2017 might now be funded.  Tabak thinks that this approach will ultimately allow more than 2,000 additional R01 grants to be funded. The previous, cap-based plan would have freed up 1,600 new awards, and would have affected 6% of NIH-funded investigators. The plan is still likely to generate controversy, however. Although it no longer directly pulls funding from 'mega-labs', researchers in later stages of their careers will probably be affected as the NIH diverts funding. \u201cWe don\u2019t have a printing press for money here,\u201d Collins says. He says that the initiative to fund younger researchers will remain a priority for the agency, but proposed budget cuts could affect everything at the NIH in the coming years. \n                   The best-kept secrets to winning grants 2017-May-24 \n                 \n                   NIH grant limits rile biomedical research community 2017-May-05 \n                 \n                   NIH to limit the amount of grant money a scientist can receive 2017-May-03 \n                 \n                   Young, talented and fed-up: scientists tell their stories 2016-Oct-26 \n                 \n                   Extra scrutiny for \u2018grandee grantees\u2019 2012-Feb-20 \n                 \n                   Nature  special: Young scientists \n                 \n                   Presentation to NIH Director's Advisory Council \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22132", "url": "https://www.nature.com/articles/nature.2017.22132", "year": 2017, "authors": [{"name": "Dalmeet Singh Chawla"}], "parsed_as_year": "2006_or_before", "body": "Wide-Open checks that the data sets underlying published studies are made freely available. Forgotten to free your data? A tool called  Wide-Open  can search out instances of locked online research data sets that are supposed to be public \u2014 and it has already flagged hundreds of such instances in genetics research, according to a study 1  published in  PLoS Biology  on 8 June. Scientists often post \u2018hidden\u2019 data online in repositories while their related studies are going through peer review, intending to make data sets public later. Two popular repositories that offer researchers the option to keep genetics data hidden, for example, are the Gene Expression Omnibus (GEO) and the Sequence Read Archive (SRA), both run by the US National Center for Biotechnology Information. Both sites require data sets to be made open when papers are published. But in practice, scientists often forget to do this, says Maxim Grechkin, a computer scientist at the University of Washington in Seattle. So Grechkin and his collaborators developed Wide-Open to find non-open data, focusing on GEO and SRA. The tool scans papers for mentions of unique data-set identifier codes (called accession codes) that use the GEO\u2019s or SRA\u2019s  code format . The tool could be tweaked to query other repositories as well, notes Grechkin.Once it identifies a valid code, Wide-Open trawls the relevant repository to find out whether the data set is public. It notes as \u201coverdue\u201d any data set that isn\u2019t available, but should be. \n             Small minority \n           Grechkin\u2019s team ran Wide-Open on roughly 1.5 million papers in PubMed Central, an open-access database of biomedical studies. The tool identified 473 data sets missing in GEO, and 84 in SRA. The team alerted the repositories of its finds. By the time the GEO staff checked, they found that 27 of the flagged data sets were already live \u2014 representing a short lag in posting for some publications \u2014 and they released 429 data sets that were overdue, says Tanya Barrett, GEO\u2019s group leader of curation. The remaining cases either cited incorrect codes or mentioned data sets that couldn\u2019t be made open because of privacy concerns or incomplete data submission. \u201cWe are happy to add Wide-Open to the tools that we use,\u201d says Barrett. Most researchers using GEO do release their data on publication, she says. GEO staff also routinely use alerts from PubMed Central and Google Scholar to keep track of published papers, she adds, but because it\u2019s a manual process some are missed. The researchers say in their paper that they plan to work with SRA staff to ensure the release of their hidden data sets as well. Wide-Open now trawls GEO and SRA roughly every month, and automatically updates its site with papers whose data are missing. \n             Bigger problem \n           \u201cIn my experience, people putting their data onto GEO or SRA intend it to be made public at some point,\u201d says Timothy Vines, a former managing editor of  Molecular Ecology , who has  written  about the importance of  data sharing .The bigger problem is that many researchers still aren\u2019t making their data public. \u201cMost researchers I know don\u2019t even bother to deposit data anywhere, let alone deposit and then not share,\u201d says Chris Hartgerink, a statistician at Tilburg University in the Netherlands. Hartgerink adds that Wide-Open could be tweaked to monitor clinical-trial data sets that have clear identifiers. But it would be more difficult to apply to fields such as the social sciences, which doesn\u2019t widely use  accession codes , making data sets difficult to track.A key limitation of Wide-Open is that it can currently scan only open-access papers because the team has not yet secured legal permissions to scan subscription content. Grechkin says that they are liaising with subscription publishers to ask for permission.Ultimately, Grechkin thinks journals should share some of the responsibility for making sure that data sets are openly available. In future, Wide-Open might also start ranking journals on the basis of their data-sharing practices, he says. \n                   Our path to better science in less time using open data science tools 2017-May-23 \n                 \n                   Open data: towards full transparency 2016-Oct-26 \n                 \n                   Open data: curation is under-resourced 2016-Oct-05 \n                 \n                   Digital badges motivate scientists to share data 2016-May-12 \n                 \n                   Data sharing: An open mind on open data 2016-Jan-06 \n                 \n                   Text-mining block prompts online response 2015-Nov-20 \n                 \n                   Scientific community: Journals must boost data sharing 2014-Apr-02 \n                 \n                   Elsevier opens its papers to text-mining 2014-Feb-03 \n                 \n                   Researchers opt to limit uses of open-access publications 2013-Feb-06 \n                 \n                   Trouble at the text mine 2012-Mar-07 \n                 Reprints and Permissions"},
{"file_id": "546195a", "url": "https://www.nature.com/articles/546195a", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Space agency takes a hard look at plans for its next big space observatory. NASA\u2019s next major space observatory is meant to tackle some of the biggest questions in astronomy when it launches in 2025 \u2014 including what exoplanets look like and how dark energy is driving the Universe\u2019s expansion. But the project\u2019s cost is rising quickly, and NASA managers are struggling to keep its budget in check. The Wide-Field Infrared Survey Telescope (WFIRST) has grown in scope and complexity since it was proposed nearly a decade ago, and its price has swollen from US$1.6\u00a0billion in 2010 to the current estimate of $3.2\u00a0billion ($2.4\u00a0billion in 2010 dollars). That has raised concern at NASA, which in April commissioned a review by independent aero-space experts. Their report is due in the next few months. Above all, the agency wants to keep WFIRST from following  the path of the James Webb Space Telescope  (JWST), a successor to the Hubble telescope that is scheduled to launch in 2018. That project\u2019s cost spiralled from $1\u00a0billion in the early 2000s to $8.8\u00a0billion \u2014 and nearly exhausted NASA\u2019s astrophysics budget. The WFIRST review is meant to stave off that kind of meltdown. \u201cThis is a good time to take a look at the scale and scope of the mission,\u201d says Jon Morse, a former head of NASA\u2019s astrophysics division who is now chief executive of the BoldlyGo Institute, a non-profit space-exploration organization in New York City. \u201cNobody wants this thing to double in cost.\u201d \n               Bonus features \n             WFIRST was the top-ranked big space mission  in the 2010 decadal survey in astronomy and astrophysics, a list created by researchers to prioritize projects for the next ten years. Then the  National Reconnaissance Office gave NASA a 2.4-metre mirror  \u2014 replacing WFIRST\u2019s planned 1.5-metre mirror \u2014 and the space agency started dreaming big. The larger mirror allowed NASA to add a corona-graph, an instrument that studies exoplanets by blocking light from the stars they orbit. And NASA made other design changes to go along with the big mirror. It also began to consider adding a \u2018starshade\u2019, a free-floating umbrella-like spacecraft that would fly alongside WFIRST and block enough light for the telescope to spy Earth-sized planets. WFIRST\u2019s heart is a gigantic camera with 18\u00a0detectors, each capable of capturing a 16-mega-pixel shot \u2014 giving it a field of view 200\u00a0times Hubble\u2019s. \u201cWhen you have this enormous field of view you can address scientific problems that really are not practical with missions like Hubble or Webb,\u201d says Jeffrey Kruk, the WFIRST project scientist at the Goddard Space Flight Center in Greenbelt, Maryland. Those include a survey to measure how the structure of the Universe evolved over time, which will shed light on the nature of dark energy. WFIRST\u2019s data should complement the observations of several other dark-energy explorers set to come online in the early 2020s, such as the European Space Agency\u2019s Euclid probe, says Rachel Mandelbaum, an astrophysicist at Carnegie Mellon University in Pittsburgh, Pennsylvania. WFIRST\u2019s exoplanet studies will include hunting indirectly for planets in the bulge of stars at the centre of the Milky Way, and imaging others directly using the coronagraph. The coronagraph is meant to demonstrate technologies for future missions, but should also be able to photograph Neptune-sized planets. \u201cWe really hope and expect to do revolutionary exoplanet science,\u201d says Jeremy Kasdin, a technologist and engineer at Princeton University in New Jersey who leads the coronagraph team. But there is only so much money to put towards all these goals. Last August, a review of NASA\u2019s progress towards its 2010 decadal priorities singled out WFIRST as at risk of ballooning costs. The review cited the cost of the coronagraph \u2014 which a different panel estimated at around $350 million \u2014 and design changes that added another $550\u00a0million. The new study will help NASA evaluate how to preserve as much of WFIRST\u2019s scientific capability as possible while remaining within budget, says John Gagosian, the mission\u2019s programme executive at NASA headquarters in Washington DC. But he sees no reasonable scenario \u201cin which the current mission scope and requirements (including the coronagraph) can be implemented for $3.2\u00a0billion or less\u201d. One potential cut would be to eliminate the coronagraph or to pare back its capabilities. Another would be to trim the number of detectors on the wide-field camera, or the amount of time dedicated to the dark-energy survey. Whether such belt-tightening is enough to keep WFIRST under $3.2 billion is unclear. A way to save money year-to-year would be to stretch the project\u2019s lifespan, says Kruk \u2014 but that increases the total cost. And launching it later than 2025 would cut back on the mission\u2019s chance to overlap with the JWST and find rare celestial objects that that telescope could then study in detail. The next major milestone for WFIRST will come after the review panel submits its recommendations. Late this year or early next, programme managers will decide what they may need to strip off the spacecraft to keep the project alive. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     The telescopes that came in from the cold 2012-Oct-03 \n                   \n                     Scope sails into budget void 2010-Nov-16 \n                   \n                     Space science: The telescope that ate astronomy 2010-Oct-27 \n                   \n                     WFIRST \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22138", "url": "https://www.nature.com/articles/nature.2017.22138", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Conservative party loses majority but aims to form government. The United Kingdom\u2019s general election on 8 June produced no clear outcome \u2014 but scientists trying to divine meaning from the chaos hope that the result will ultimately benefit their nation\u2019s research ties with the European Union. The Conservative government had called the election in an effort to stretch its slim majority, which would have given it a firmer mandate to negotiate Brexit, the United Kingdom\u2019s split from the EU. The party, under the leadership of Theresa May, was aiming for a \u2018hard\u2019 Brexit \u2014 placing priorities on ending the free movement of EU citizens to the United Kingdom, cutting immigration and taking the country out of the EU\u2019s single market. That stance  alarmed scientists : it\u00a0seemed likely also to cut the United Kingdom out of EU research programmes and dent the easy movement of scientists to and from the EU. But the party actually lost seats \u2014 ending up eight short of an overall majority, although still the largest single bloc in the British parliament. After the result, which is termed a \u2018hung\u2019 parliament because no party has an outright majority, May said that she would form a government anyway, relying on the support of Northern Ireland\u2019s Democratic Unionist Party, a relatively minor player in UK politics. Although the situation remains uncertain, the result suggests that the government has lost its mandate for the strict Brexit deal for which May had been aiming, says Paul Nightingale, deputy director of the Science Policy Research Unit at the University of Sussex in Brighton, UK. The result \u201cmakes it more likely that the UK will have a softer Brexit and will stay within  EU science programmes \u201d, says Nightingale, who was speaking in a personal capacity. Any softening of the United Kingdom\u2019s position on Brexit is \u201cobviously good for our chances of staying in EU funding programmes\u201d, agrees Kieron Flanagan, a science-policy researcher at Alliance Manchester Business School, UK. \u201cPlanning to ameliorate the effects of Brexit on science and research should be the number one goal,\u201d he adds. \u201cScience has a lot to lose from a hard Brexit. So the prospect of a minority government yielding a softer Brexit is likely to appeal to science leaders who have been pushing to retain a range of EU benefits,\u201d says Sarah Main, executive director of the Campaign for Science and Engineering (CaSE) in London. \u201cThe result may provide hope that a hard Brexit can\u2019t be pursued with such vigour as before,\u201d says Anne Glover, a biologist at the University of Aberdeen, UK, who was formerly the European Commission\u2019s chief scientific adviser. \u201cThe optimist in me hopes that the hung parliament we seem to have at this stage might end in a rethink on Brexit, perhaps a delay,\u201d she says. \u201cIf Brexit is pursued, research needs the closest possible deal we have to the one we have now.\u201d \n             \u2018Still in a mess\u2019 \n           Senior Conservatives say that the result could weaken the United Kingdom\u2019s hand in negotiations with the EU, which were set to begin on 19 June. \u201cWe had an evidence-free EU referendum, and now we have a negotiating party who, by their own admission, think their negotiating position has been weakened,\u201d says Glover. \u201cNot much cause for celebration \u2014 the future of research in the UK is still in a mess.\u201d Although May will, for now, remain Britain\u2019s prime minister, her long-term position as leader could be in doubt. \u201cMay will limp along, but politically, she is toast,\u201d says Nightingale. If she does ultimately go, then the Conservative government\u2019s direction might shift under new leadership. \u201cI don\u2019t think there will be any change in alignment in the science budget and industry strategy,\u201d he adds. Still, May\u2019s  trademark stance on restricting the number of foreign students coming to the country as part of large cuts to UK immigration  could also be softened, Nightingale notes. Universities and some politicians in May\u2019s own party have opposed the idea that overseas students should count in immigration quotas. Ahead of the election,  all three of the nation\u2019s main national parties had pledged to raise funding for science , an unusual consensus that reflects the difficulties that UK research could face as a consequence of Brexit. Reaching an agreement on science spending becomes more important when governing is reliant on collaboration and cross-party consensus, says Graeme Reid, a science-policy researcher at University College London. The role of science minister becomes even more crucial in such an environment, he says, because the minister needs to provide a sense of direction, and work across political lines. Jo Johnson was science minister before the election; it's not yet clear if he will be chosen to retain his post. Although opposition party Labour failed to win a majority of votes or seats, it did much better than expected. Commentators speculate that a high turnout among young people and a wider drift away from the UK Independence Party were behind the rise. Labour, like the Conservatives, has pledged to follow through plans to leave the EU, but has said that it will seek to stay part of EU research programmes. The third national party, the Liberal Democrats, opposes leaving the EU: it increased its number of seats but did not see a large surge. Among individual results, biochemist Julian Huppert failed to win back his seat as a Liberal Democrat MP, which he lost in 2015. And Conservative Nicola Blackwood lost her seat in Oxford West and Abingdon. Blackwood chaired the House of Commons Science and Technology Committee in 2015\u20142016, and had been \u201cwonderful at reaching out to the science community to engage a broader range of people and coming up with innovative new ways of drawing science advice into parliamentary debate\u201d, says Reid. \n                   Keep shouting to save science 2017-May-31 \n                 \n                   UK election: science spending pledges overshadowed by Brexit 2017-May-31 \n                 \n                   How Brexit is changing the lives of eight researchers 2017-Mar-29 \n                 \n                   UK scientists excited by surprise \u00a32-billion government windfall 2016-Nov-23 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22140", "url": "https://www.nature.com/articles/nature.2017.22140", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Emergence of colistin resistance in farm animals around the world takes researchers by surprise. Eighteen months ago, a gene that confers resistance to  colistin \u2014 known as an \u2018antibiotic of last resort\u2019  \u2014 emerged in bacteria from pigs in China. Since then, the resistance gene, called  mcr-1 , has been found around the world at an alarming rate, according to several presentations at the American Society for Microbiology (ASM) meeting in New Orleans, Louisiana, last week. In some places, nearly 100% of farm animals carry  mcr-1 , and an increasing number of people do as well. The gene\u2019s spread is one of the clearest examples of how antibiotic use on farms can lead to resistance in human infections, says Lance Price, an antibiotic researcher at George Washington University in Washington DC. Colistin has been around since the 1950s, but was rarely used in people because it causes kidney problems. Instead, many countries use it to promote growth in livestock \u2014 a practice that seems to have selected for colistin-resistant bacteria. That\u2019s a problem, because physicians have increasingly turned to colistin over the past decade to treat patients who  don\u2019t respond to other antibiotics . \u201cIt\u2019s a crappy drug and I think this is a sign of our desperation that we are so concerned about the loss of a toxic antibiotic,\u201d says Price. \n             Spreading resistance \n           Colistin-resistance genes evolve naturally in bacteria, but public-health experts started to worry when researchers in China reported 1  last year that  mcr-1  had moved from the bacterial genome on to a plasmid: a circular piece of DNA that can hop between species of bacteria. Some evidence suggests that plasmids carrying  mcr-1  have existed on farms for decades, and that researchers are seeing the plasmid and the gene now only because they\u2019re looking for them 2 . But their occurence does seem to be increasing. An analysis of gut bacteria in 8,000 human faecal samples collected over five years from Guangzhou, China, discovered  mcr-1  in 497 samples. It also found an increasing prevalence of the gene during that time, according to Guo-Bao Tian, a microbiologist at Sun Yat-sen University in Guangzhou, at the ASM meeting. Tian and his colleagues discovered that 10% of the  mcr-1  genes showed up in strains of the gut bacterium  Escherichia coli  that were also resistant to other antibiotics. In another study presented at the meeting, Tian\u2019s group found  mcr-1  in 25% of patients at a Guangzhou hospital in 2016. A strain of  E. coli  found in the samples also contained a gene called  bla NDM-5  that  confers resistance to carbapenems  \u2014 another class of antibiotics of last resort. Although the two genes were found on separate plasmids, it\u2019s common for one plasmid to carry resistance genes for multiple drugs, says Catherine Logue, a veterinary microbiologist at Iowa State University in Ames. Treatment with one drug can select for bacteria with such plasmids, thus potentially increasing the amount of resistance to several drugs. \n             A wake-up call \n           During one ASM presentation, Logue and her team reported finding resistance genes to carbapenems and to antibiotics from the class that includes penicillin. These were discovered in swab samples from 107 farmed chickens in Brazil \u2014 the world\u2019s largest poultry exporter. About 60% of the samples had  E. coli  strains that carried  mcr-1 . The prevalence of  mcr-1  was even higher at two randomly chosen farms in Portugal: 98% of 100 healthy pigs researchers sampled harboured theresistance gene, said Laurent Poirel, an antibiotic-resistance researcher at the University of Fribourg in Switzerland, who also presented at ASM. He and his colleagues also found  mcr-1  on three different types of plasmid and in multiple strains of bacteria, suggesting the pigs weren\u2019t necessarily spreading the gene to one another but getting it from various sources. \u201cWe have no idea how it got there,\u201d he says. Logue and Tian also found  mcr-1  in numerous different plasmids and strains of bacteria. The gene seems to be particularly good at jumping into different organisms, Logue says, which could make it very successful \u2014 and difficult to treat. If someone ate undercooked meat or worked with animals harbouring bacteria containing  mcr-1 , a person's gut microbes could theoretically acquire the resistance gene. Price is astounded by the prevalence of  mcr-1  found in these countries. Brazil banned colistin for agricultural use in 2016 while China followed suit in 2017, but Price isn\u2019t sure how much that will curb the spread of these genes. He hopes that the  mcr-1  case can serve as a wake-up call about the  overuse of all antibiotics in farm animals . \n                   Spread of antibiotic-resistance gene does not spell bacterial apocalypse \u2014 yet 2015-Dec-21 \n                 \n                   Dramatic rise seen in antibiotic use 2015-Sep-17 \n                 \n                   WHO warns against 'post-antibiotic' era 2014-Apr-30 \n                 \n                   MRSA: Farming up trouble 2013-Jul-24 \n                 \n                   Antibiotic resistance: The last resort 2013-Jul-24 \n                 Reprints and Permissions"},
{"file_id": "546196a", "url": "https://www.nature.com/articles/546196a", "year": 2017, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "United Nations meeting hopes to focus artificial intelligence on sustainable development goals. In the world\u2019s wealthiest neighbourhoods, artificial intelligence (AI) systems are starting to steer self-driving cars down the streets, and homeowners are giving orders to their smart voice-controlled speakers. But the AI revolution has yet to offer much help to the 3 billion people globally who live in poverty. That discrepancy lies at the heart of a meeting in Geneva, Switzerland, on 7\u20139 June, grandly titled the  AI for Good Global Summit . The meeting of United Nations agencies, AI experts, policymakers and industrialists will discuss how AI and robotics might be guided to address humanity\u2019s most enduring problems, such as poverty, malnutrition and inequality. Development agencies are buzzing with ideas, although only a few have reached the stage of pilot experiments. But scientists caution that the rise of AI will also bring societal disruption that will be hard to foresee or manage, and that could  harm\u00a0the world\u2019s most disadvantaged . \u201cDeveloping countries may have the most to gain from AI, but also the most to lose if we are not vigilant,\u201d says Chaesub Lee, director of the Telecommunication Standardization Bureau of the UN\u2019s International Telecommunications Union, which is organizing the meeting. Many researchers expect that AI systems will help to assess and track measures to alleviate poverty. At present, there are few accurate data on where the poorest people live because household surveys are infrequently carried out in poor or remote areas, says Marshall Burke, an economist at Stanford University in California. Burke and his colleagues are training algorithms using night-time satellite images (in which well-lit areas are a rough proxy for affluence) to learn which features in daytime satellite images\u00a0\u2014\u00a0such as roads, or roof types\u00a0\u2014\u00a0correlate with relative wealth or poverty. In a  pilot study in five African nations , the team found that its AI system predicts village-level wealth better than do earlier methods that use night lights alone. Other scientists at Stanford, led by Jiaxuan You, are using AI and satellite remote-sensing data to predict crop yields months ahead of harvest, hoping to anticipate food shortages. And the UN children\u2019s charity UNICEF is investing in work to test whether deep learning can diagnose malnutrition from photographs and videos of children. \u201cThis is currently done using mid-upper-arm circumference and is slow and not always super-accurate,\u201d says Christopher Fabian, the head of UNICEF\u2019s innovation and venture funding unit. \u201cWe believe we can do better.\u201d AI has been used for years in responses to natural disasters: helping to track where casualties and relief needs are greatest by  parsing social-media messages  and  analysing satellite and drone imagery . In 2016, the XPRIZE Foundation, based in Culver City, California\u00a0\u2014\u00a0which is co-organizing the Geneva summit \u2014\u00a0announced a  US$5-million prize fund  to reward ideas for using AI to solve challenges facing society. But just as the Internet has brought risks and rewards that few could have anticipated, so AI will have \u201cgood, bad, transformative and plain weird effects\u201d on societies, says Anders Sandberg, who studies the societal and ethical issues of new technologies at the University of Oxford, UK. The Geneva summit, for instance, focuses on how AI could help to achieve  the UN\u2019s Sustainable Development Goals  \u2014 targets to improve the lives of the world\u2019s poorest people by 2030. One is to ensure decent jobs for all. Yet a  2016 report from financial institution Citi  suggests that AI and robotics might hit jobs in developing countries hardest. Concerns over some of these risks have prompted industry to fund initiatives focused on societal benefit. They include  OpenAI \u00a0\u2014\u00a0a non-profit research company launched in December 2015 with $1\u2009billion of funding from philanthropists and entrepreneurs, in part to develop \u2018safe\u2019 AI systems\u00a0\u2014\u00a0and the  Partnership on Artificial Intelligence to Benefit People and Society , founded last October. The partnership includes Google, Microsoft and Facebook,\u00a0but also UNICEF, Human Rights Watch and a host of non-profit organizations; in May, it announced that it would launch a grand-challenge series to boost initiatives that use AI to address long-term societal issues. Ultimately, it is the firms developing AI that will have the greatest say in the technology\u2019s future direction, warns Milton Mueller, an expert on Internet governance at the Georgia Institute of Technology in Atlanta. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @DeclanButlerNat \n               \n                     Track how technology is transforming work 2017-Apr-13 \n                   \n                     Smart manufacturing must embrace big data 2017-Apr-05 \n                   \n                     There is a blind spot in AI research 2016-Oct-13 \n                   \n                     Can we open the black box of AI? 2016-Oct-05 \n                   \n                     More accountability for big-data algorithms 2016-Sep-21 \n                   \n                     Anticipating artificial intelligence 2016-Apr-26 \n                   \n                     A world where everyone has a robot: why 2040 could blow your mind 2016-Feb-24 \n                   \n                     Nature  Insight: Machine intelligence \n                   \n                     AI for Good Global Summit \n                   \n                     IBM Watson AI XPRIZE \n                   \n                     Partnership on Artificial Intelligence to Benefit People and Society \n                   \n                     OpenAI \n                   \n                     Sustainable Development Goals \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22142", "url": "https://www.nature.com/articles/nature.2017.22142", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Probe sends entangled photons \u2014 which could underpin quantum-based data encryption \u2014 over unprecedented distance. Just months into its mission,  the world\u2019s first quantum-communications satellite  has achieved one of its most ambitious goals.Researchers report in  Science 1  that, by beaming photons between the satellite and two distant ground stations, they have shown that particles can remain in a linked quantum state at a record-breaking distance of more than 1,200\u00a0kilometres. That phenomenon, known as  quantum entanglement , could be used as the basis of a future secure quantum-communications network. The feat is the first result reported from China\u2019s Quantum Experiments at Space Scale (QUESS) mission, also known as Micius after an ancient Chinese philosopher. Launched last August, the craft is designed to demonstrate principles underlying quantum communication. The team is likely to launch more quantum-enabled satellites to start building a network.Quantum communication is secure because any interference is detectable. Two parties can exchange secret messages by sharing an encryption key encoded in the properties of entangled particles; any eavesdropper would affect the entanglement and so be detected. The Micius team has already done experiments exploring whether it is possible to create such encryption keys using entangled photons, and even  'teleport' information securely between Earth and space , says  Pan Jian-Wei , a physicist at the University of Science and Technology of China in Hefei and the main architect of the probe. But he says that his team is not yet ready to announce the results.  \n             Bell test \n           In theory, entangled particles should remain linked at any separation. That can be checked using a  classic experiment called a Bell test .Central to QUESS's experiments is a laser beam mounted on the satellite. For the  Bell test , the beam was split to generate pairs of photons that share a common quantum state, in this case related to polarization. The entangled photons were funnelled into two onboard telescopes that fired them at separate stations on the ground: one in Delingha, on the northern Tibetan Plateau, and the other 1,203\u00a0kilometres south, at Gaomeigu Observatory in Lijiang. Once the particles arrived, the team used the Bell test to confirm that they were still entangled.The researchers had a window of less than 5 minutes each night when the satellite, which orbits at an altitude of about 500 kilometres, was in view of both observatories. Within weeks of launch, they were able to transmit a pair of entangled photons per second \u2014 a rate ten times faster than they had hoped. The crucial experiment was completed before the end of the year, says Pan: \u201cWe are very happy that the whole system worked properly.\u201d\u00a0The previous record for such an experiment was 144 kilometres 2 . \u201cThis proves that one can perform quantum communications at continental distances,\u201d says Fr\u00e9d\u00e9ric Grosshans, a quantum-communications physicist at the University of Paris South in Orsay. Entangled particles are the \u201cworkhorse\u201d of quantum communications, he adds. \n             Next-generation satellite \n           \u201cI am really impressed by the result of the Chinese group,\u201d says Wolfgang Tittel, a physicist at the University of Calgary in Canada. \u201cTo me, it was not clear after the satellite launch if they would succeed,\u201d he says, or whether they would use it to learn for the next improved mission. Pan says that in addition to the quantum-key and teleportation experiments, the team also plans to use Micius to test how gravity affects the quantum state of photons. And they want to launch a second, improved, quantum satellite in two years. A major challenge, he says, will be to upgrade the technology so that it can send and receive signals during the day, when there are many more photons around and it is harder to pick out the ones coming from the satellite.For now, Pan feels vindicated about the first spacecraft\u2019s design. Colleagues thought that it was too ambitious, he says, because it produced the entangled photons in space and required two photon-firing systems.Similar missions in the planning stages \u2014 such as Canada\u2019s Quantum Encryption and Science Satellite (QEYSSat) \u2014 use a simpler approach, creating the entangled photons on Earth and beaming them to a satellite. In a study 3  published last week, the QEYSSat team reported a successful test of its technology, transmitting photons from the ground to an aircraft as much as 10\u00a0kilometres in the air. Thomas Jennewein, who is at the University of Waterloo in Canada and part of the Canadian mission, says that his group and others around the world are now racing to catch up with the Chinese effort. \u201cThey are now clearly the world leader in quantum satellites,\u201d he says. \n                   Chinese satellite is one giant step for the quantum internet 2016-Jul-27 \n                 \n                   China\u2019s quantum space pioneer: We need to explore the unknown 2016-Jan-13 \n                 \n                   Data teleportation: The quantum space race 2012-Dec-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22137", "url": "https://www.nature.com/articles/nature.2017.22137", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Finding could help researchers to better predict where these viruses are likely to make the jump from animals to people. Bats are the major animal reservoir for coronaviruses worldwide, according to a survey of thousands of animals across Africa, Asia and the Americas. The animals had previously been linked to the coronaviruses that caused outbreaks of severe acute respiratory syndrome (SARS) and Middle East respiratory virus (MERS), but until now researchers were not sure whether that was a coincidence or a sign of a broader trend. The findings suggest that researchers who study infectious diseases can improve their predictions of where coronaviruses are likely to leap from animals to people by looking at the geographical distribution of different bat species and the behaviour of the viruses that they carry. \u201cIt\u2019s time to stop being reactive,\u201d says Simon Anthony, a virologist at Columbia University in New York City and lead author of the study published today in  Virus Evolution 1 . \u201cThe point is to take a different approach and be more proactive by understanding the diversity of viruses out there before they actually emerge.\u201d The research was funded by the US Agency for International Development through a programme that aims to preempt pandemics of viruses that pass from animals to humans. Coronaviruses made headlines  in 2002, when SARS appeared in China  and spread to 27 countries, killing 774 people. In 2012,  the coronavirus that causes MERS surfaced in Saudi Arabia ; 640 people died. Previous research has  suggested that bats spread the virus to camels , which then passed it to people 2 , 3 . \n               Bat signal \n             To map the distribution of coronaviruses, Anthony and his colleagues trapped and released about 12,300 bats, 3,400 rodents and shrews, and 3,500 monkeys. Their work took them to 20 countries in Africa, Asia, South America and Central America that had previously been identified as  'hotspots' where diseases may jump from wildlife to humans . From dusk until dark, teams of biologists \u2014 including local researchers \u2014 bagged bats that flew into long, thin nets strung between trees. They collected samples of the animals' saliva, urine and faeces, and shipped these to labs for genetic testing. Nearly 10% of the bats carried coronaviruses, compared with 0.2% of the other animals sampled. And the team found that the diversity of viruses was highest in places where multiple bat species lived, such as the Amazon rainforest. Yet bat diversity alone is not an indicator of risk, because only a fraction of coronaviruses infect people. One hint that a pathogen may spill over into people is a history of jumping between distantly related species. Anthony and his colleagues observed that coronaviruses in Africa had spread among unrelated bat species four times more often than viruses in Mexico, Brazil, Bolivia and Peru did. This could be due to genetic differences in the coronaviruses present in each region, or to the way that disparate bat species interact in different forests. \u201cIt\u2019s very interesting that the viruses in Latin America don\u2019t jump around as much,\u201d says Vincent Munster, a virologist at the US National Institutes of Health\u2019s Rocky Mountain Laboratories in Hamilton, Montana. \u201cIt\u2019s worth more study.\u201d Anthony says a next step is to learn more about viruses that jump between host species, and those that don't. For instance, in a study published on 4 April in  mBio , his team showed that a virus closely related to MERS \u2014 and found in a bat in Uganda \u2014 cannot bind to receptors on human cells in the lab 4 . Because of this, the virus does not present an immediate threat to human health. \n               Crystal ball \n             But some scientists who study infectious disease argue for a more pragmatic approach. Michael Osterholm, director of the Center for Infectious Disease Research and Policy at the University of Minnesota in Minneapolis, says that researchers and politicians should direct their limited resources towards halting new outbreaks of pathogens that are known to be deadly in people, rather than trying to predict which virus will be the next to cross over to humans. For example, Osterholm says that an outbreak of MERS is likely to emerge in eastern Africa at some point because the camel trade connects that region to Saudia Arabia. Because of this risk, he sees the development of a MERS vaccine as a top research priority. And although there is a vaccine for the Ebola virus that is close to the clinic, it is effective only against the Zaire strain of the virus. \u201cWe aren\u2019t much better prepared for Ebola today than we were during the crisis in West Africa, so you have to wonder,\u201d Osterholm says. \u201cIf we aren\u2019t preparing for the outbreaks we know will happen in the near future, what good does it do to know about spillover events?\u201d Anthony argues that both strategies are vital. \u201cIf we ever want to get ahead of the curve,\u201d he says, \u201cwe need to learn about the process of emergence in the first place.\u201d \n                     Vaccine initiative marks bold resolution 2017-Jan-25 \n                   \n                     The power of prediction markets 2016-Oct-18 \n                   \n                     Hunt for Ebola\u2019s wild hideout takes off as epidemic wanes 2016-Jan-12 \n                   \n                     Disease specialists identify post-Ebola threats 2015-Dec-07 \n                   \n                     South Korean MERS outbreak spotlights lack of research 2015-Jun-09 \n                   \n                     USAID\u2019s PREDICT project \n                   \n                     USAID\u2019s Emerging Pandemic Threats program \n                   Reprints and Permissions"},
{"file_id": "546338a", "url": "https://www.nature.com/articles/546338a", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Analysis reveals that the number of clinical trials funded by the National Institute of Mental Health has fallen by 45% since the agency began to focus on the biological roots of disease. Roy Perlis is done with clinical research. The psychiatrist at the Broad Institute in Cambridge, Massachusetts, has led about 20 clinical trials on depression and other mood disorders over the past two decades. But he has given up seeking grants from the US National Institute of Mental Health (NIMH)\u00a0\u2014\u00a0the world\u2019s biggest funder of mental-health research \u2014 since it began promoting a new way to investigate mental illness. The agency urges researchers to study the biological roots of disease, rather than specific disorders. This shift has been having profound impacts on mental-health research in the United States, but the magnitude of the transformation is only now coming to light. An analysis by  Nature  suggests that the number of clinical trials funded by the NIMH dropped by 45% between 2009 and 2015 (see \u2018Rethinking mental-health studies\u2019). This coincides with the agency\u2019s launch, in 2011, of the Research Domain Criteria (RDoC) \u2014 a framework for research on the mechanisms of mental illness. The NIMH\u2019s roll-out of RDoC included asking researchers to focus more on the biological bases of behaviour \u2014 such as brain circuitry and genetics \u2014 than on the broader symptoms that clinicians typically use to define and classify mental illness. The NIMH\u2019s embrace of fundamental research has infuriated many clinical researchers, who see it as an attempt to invalidate their methods \u2014 and say that there is scant evidence to support the idea that using RDoC will lead to greater insight or better treatments for mental illness. Many of these researchers also note that NIMH funding for clinical trials has declined steadily over the past decade, adding to the perception that the agency now favours research that uses the RDoC framework. \u201cIt is fair to say we needed a better understanding of the neuroscience [of mental illness] to stop flailing around in the darkness,\u201d says Perlis. \u201cBut I think we understand enough about the neurobiology and genetics that now we should be making a strong push into clinical research.\u201d NIMH director Joshua Gordon, who took office in July 2016, has tried to assuage these concerns by clarifying that the use of RDoC is not required to win a grant. But in a 5 June blogpost, he emphasized that the agency is not backing away from the framework. \u201cWe are going to continue with the RDoC experiment,\u201d Gordon wrote. The NIMH will also take steps to validate the science behind RDoC\u2019s design, he said, responding to persistent concerns that the framework has not been properly tested. The NIMH began developing RDoC amid concerns that research into mental health was not producing more-effective treatments. Since the 1950s, psychiatrists have diagnosed patients using the  Diagnostic and Statistical Manual of Mental Disorders , a handbook\u00a0\u2014\u00a0now in its fifth edition,  DSM-5 \u00a0\u2014\u00a0that defines various illnesses by symptoms. These definitions have in turn guided clinical research on mental disorders. But progress in developing effective therapies for many common illnesses, including depression, has been slow. The RDoC framework takes a different approach, ignoring clinical diagnoses in favour of classifying people using five categories, such as cognitive characteristics and social interactions, that each include behavioural and biological elements. The goal is to avoid lumping people with the same broad diagnosis into a single group, which can mask the differences between them \u2014 as can happen with the  DSM . Not all people diagnosed with depression are suicidal, for instance, and those who are may have more in common with people with schizophrenia and suicidal feelings than with other people with depression. \n               Ups and downs \n             Neuroscientists and mental-health researchers agree that the general idea is scientifically sound. Even the psychiatrist who led the writing of the  DSM-5 , David Kupfer of the University of Pittsburgh in Pennsylvania, thinks that an approach like that of RDoC \u2014 based on categories that cut across diagnoses \u2014 is necessary to improve psychiatric treatment. But clinical researchers bristled in 2013 when former NIMH director Thomas Insel announced that the agency would shift away from funding research that classified people using  DSM-5 , and again in 2014 when Insel said that the NIMH would not fund clinical trials that didn\u2019t seek to understand the biological mechanism underlying a particular treatment or illness. Although the initial furore has died down, many researchers still think that the NIMH will only fund studies that use the RDoC framework. Daniel Weinberger, who directs the Lieber Institute for Brain Development in Baltimore, Maryland, says that many researchers at his institution who have submitted grant applications have been asked by agency reviewers how their proposals relate to RDoC. \u201cIt\u2019s been used almost as a litmus test for whether a grant is fundable by the NIMH,\u201d he says. Bruce Cuthbert, who directs the NIMH\u2019s RDoC unit, rejects that claim. He says that only about half of the grants that the agency funds can be characterized as relying on RDoC. Cuthbert notes that the distinction between RDoC and non-RDoC research is not clear cut, and that researchers can study the biological mechanisms underlying mental illness without using the NIMH framework. Nature  could not check the validity of Cuthbert\u2019s estimate because grant applications submitted to the NIMH are confidential. But our analysis of the NIMH database shows that the number of awarded research grants that mention the  DSM  has plummeted since 2009. Mentions of some conditions defined in the  DSM , such as \u2018major depressive disorder\u2019, have also decreased. Meanwhile, the use of \u2018biomarker\u2019 and other words related to the RDoC framework has increased. Gordon says that several recent studies support the RDoC approach of studying traits and symptoms versus disorders. One showed that functional magnetic resonance imaging brain scans of 1,188 people with depression could be divided into four \u2018biotypes\u2019 that responded differently when treated with electrical brain stimulation ( A.\u00a0T. Drysdale et al. Nature Med. 23, 28\u201338; 2017 ). It suggests that people with the same diagnosis \u2014 depression \u2014 can have different underlying biology. Measuring RDoC\u2019s scientific impact is likely to be tricky, says Stephan Heckers, a psychiatrist and editor of  JAMA Psychiatry . When applying for an NIMH grant, he says, many people in his field \u2014 psychosis research \u2014 will simply add a few people with a different  DSM  diagnosis to their study to claim that the project spans disorders. \u201cThat is not really what RDoC is about,\u201d Heckers says. It is unclear how much the agency\u2019s adoption of RDoC has discouraged clinical researchers from seeking NIMH funding, or whether they are simply winning fewer grants. A 2014 analysis by Insel found that NIMH funding for clinical trials dropped from US$110\u00a0million in 2011 to $75\u00a0million in 2014. The US government\u2019s ClinicalTrials.gov database mirrors this: it shows that the number of clinical trials for which the NIMH was the primary sponsor dropped from 28 in 2001 to 5 in 2015. \n               Trust but verify \n             Whatever the cause of the drop in NIMH-funded clinical research, Gordon says that he would like to reverse it. As a first step, he has written several blogposts trying to clarify how researchers can adapt behavioural studies to examine biological mechanisms of mental illness. And he is also reconsidering some aspects of RDoC. \u201cOne of the major problems for RDoC is the top-down approach, where we base it on categories we believe are there,\u201d Gordon says. \u201cWe humans made them up and we are eminently fallible in putting things in categories.\u201d To devise a more data-driven approach, Gordon plans to piggyback on the US National Institutes of Health\u2019s Precision Medicine Initiative, which will track the health of 1\u00a0million Americans for 10\u00a0years. The programme launched this month, and Gordon says that the NIMH is planning to send participants a set of online behavioural tests that will measure traits such as mood and response to rewards. By integrating these with electronic health records and genetic data, the agency hopes to find groups of people with particular mental traits that could be included in studies to better link brain characteristics to behaviour. This effort could one day lead to a revision of RDoC, or even prompt the NIMH to abandon the framework altogether. \u201cRDoC is meant to be mutable,\u201d Gordon says. \u201cIt\u2019s meant to be changed when the evidence is there.\u201d But for now, he is withholding judgement on whether RDoC is a success. \u201cI think it\u2019s just too early to know,\u201d he says. \n                     Brain study seeks roots of suicide 2015-Nov-25 \n                   \n                     NIH rethinks psychiatry trials 2014-Mar-14 \n                   \n                     Psychiatry framework seeks to reform diagnostic doctrine 2013-May-10 \n                   \n                     Mental health: On the spectrum 2013-Apr-24 \n                   \n                     Research Domain Criteria \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22161", "url": "https://www.nature.com/articles/nature.2017.22161", "year": 2017, "authors": [{"name": "Lindsay McKenzie"}], "parsed_as_year": "2006_or_before", "body": "Flood of online manuscripts generates confusion about terms for distribution and reuse. Biology\u2019s zeal for preprints \u2014 papers posted online before peer review \u2014 is opening up a thorny legal debate: should scientists license their manuscripts on open-access terms? Researchers have now shared more than 11,000 papers at the popular bioRxiv preprints site. But where some researchers allow their bioRxiv manuscripts to be freely redistributed and reused, others have chosen to lock them down with restrictive terms (see \u2018Licence confusion\u2019). That split concerns Jessica Polka, the director of ASAPBio, a grass-roots organization that  advocates for preprints . Polka wants authors to choose permissive licences that would allow anyone to share or adapt the work, even for profit. \u201cWe want to maximize the public good of preprints,\u201d she says. The US National Institutes of Health also encourages open-access preprint licences.  But some researchers are wary of the approach, and that needs exploring, Polka says. So on 16 June, ASAPBio  announced the creation of a taskforce  to help understand attitudes towards preprint licensing. \"It's viewed as kind of a fraught issue,\" says Dick Wilder, associate general counsel at the Global Health Program of the Bill and Melinda Gates Foundation in Washington DC. Wilder is chairing the taskforce, which includes researchers, legal experts, funding agencies and publishers. \n             Open or closed \n           Authors automatically hold copyright on their preprint manuscripts. But by adding a licence to their preprint, they tell others how their work can be reused, and under what circumstances. At bioRxiv, for instance, scientists can choose from a spectrum of licences. This ranges from the most liberal CC-BY \u2014 which allows anyone to reuse work for any purpose, as long as they credit its source \u2014 to CC-BY-NC-ND, which bars commercial use and any \u2018derivative\u2019 works, such as translations or tools that distribute annotated versions of papers. (CC refers to Creative Commons, a non-profit organization in Mountain View, California, that constructed the licence terms.) Scientists may be troubled by the idea of their preprints being repackaged and sold for profit, but Daniel Himmelstein, a data scientist at the University of Pennsylvania in Philadelphia and a member of the ASAPBio taskforce, says that he would welcome the free publicity if his work was shared this way. And he says that most entrepreneurs looking to reuse preprints are developers who could benefit researchers by creating new tools for displaying, interacting with or sharing the work. According to statistics from bioRxiv, 29% of authors have decided to append no licence at all to their work. On the site, these are labelled: \u201cAll rights reserved. No reuse allowed without permission.\u201d Saskia Hagenaars, a geneticist at Kings College London says that her team chose this option because \u201cwe don't want people freely using the non-peer reviewed versions of our papers\u201d. Himmelstein, who follows bioRxiv licensing on his blog  Satoshi Village , says that he would like bioRxiv to remove that option. \u201cI think it\u2019s counter to the minimum requirements of healthy science literature,\u201d he says. Choosing no licence means that if bioRxiv disappeared, these papers could not be reposted elsewhere without the express permission of the authors, he adds. \n             Text-mining confusion \n           The bioRxiv website states that just by uploading papers to bioRxiv \u2014 no matter what licence is chosen \u2014 authors consent to text-mining of their work, a technique in which software crawls over thousands or millions of downloaded papers to pull out scientific insights, or to annotate key scientific terms. But researchers who want to text-mine preprints aren\u2019t always sure whether they can legally do this on restrictively licensed manuscripts, or whether they can redistribute the corpus of papers that they have been mining. John Inglis, the co-founder of bioRxiv, says that he\u2019s received queries about what is and isn\u2019t permitted, despite the site\u2019s stated terms. At the physics preprint server, arXiv, the most popular option is a default licence that gives arXiv a non-exclusive right to distribute articles \u2014 and says little else. Paul Ginsparg, a physicist at Cornell University in Ithaca, New York, says that all arXiv preprints can be freely text-mined, relying on the principle that text-mining is \u2018fair use\u2019 of the papers and does not breach US copyright law. It\u2019s not entirely clear, however, whether scientists in other nations can depend on this principle; other jurisdictions have differing views on whether text-mining breaches copyright, notes Michael Carroll, who directs the Program on Information Justice and Intellectual Property at the American University in Washington DC. One reason for researchers\u2019 hesitancy to choose open licences may be that some journals frown on them. Giulio Caravagna, a computational biologist at the University of Edinburgh, UK, decided not to openly licence his bioRxiv preprint because it gave his team \u201cfull rights to proceed further with submission to any journal that we want to target\u201d. The  Proceedings of the National Academy of Sciences USA  ( PNAS ), for instance, says it will only publish papers arising from preprints that don't have CC licenses, because it feels that these are not compatible with its own licensing terms. But Himmelstein has found a dozen CC-BY preprints that led to work published in  PNAS  \u2014 and the publisher says it has never enforced its rule. Jesse Bloom, an evolutionary and computational biologist at the Fred Hutchinson Cancer Research Center in Seattle, Washington, says that he didn\u2019t know about  PNAS \u2019s policy, but that if the journal were to reject his CC-BY preprints because of licensing terms, he\u2019d view it as \u201ctheir problem rather than ours\u201d. In his view, scientists and scientific journals \u201cshould focus on the quality of the work rather than spend their time worrying about publication licences\u201d. \n                   BioRxiv preprint server gets cash boost from Chan Zuckerberg Initiative 2017-Apr-26 \n                 \n                   Legal confusion threatens to slow data science 2016-Aug-03 \n                 \n                   Researchers opt to limit uses of open-access publications 2013-Feb-06 \n                 \n                   Creative Commons licenses \n                 \n                   ASAPBio initiative \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22130", "url": "https://www.nature.com/articles/nature.2017.22130", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "US vice-president to head group overseeing civilian and military space activities. The United States will revive the long-dormant National Space Council, a group meant to coordinate space policy among government agencies and departments. Vice-president Mike Pence, who will chair the council, announced its reinstatement on 7 June at NASA\u2019s Johnson Space Center in Houston, Texas. First constituted in 1958, the space council \u2014 or some iteration of it \u2014 has been active sporadically, most recently between 1989 and 1993. Since then, space policy has been mainly run out of the White House Office of Science and Technology Policy (OSTP) and NASA. Re-starting the council will better coordinate the country\u2019s space endeavours, Pence said. \u201cPresident Trump recognizes America needs a coherent and cohesive approach,\u201d he added. The council \u201cwill make sure America never again loses our lead in space exploration, innovation and technology\u201d. In theory, the National Space Council oversees US space policy at NASA and defence, intelligence and commerce agencies. In practice, however, it sometimes has had little power to change entrenched practices among various agencies \u2014 particularly in military affairs. \u201cAs long as Trump has Pence\u2019s back, and Pence decides to place a lot of emphasis on his role as chair of the space council, it has a potential to make a difference,\u201d says John Logsdon, a space-policy expert at George Washington University (GWU) in Washington DC. In its 1989\u20131993 incarnation, the council played a major part in developing then-president George H. W. Bush\u2019s plans to send astronauts to the Moon and Mars. It also worked on space issues with Russia after the collapse of the Soviet Union. \n               A full plate \n             The reinstated council will be successful if it coordinates the government\u2019s work with that of the burgeoning commercial space industry, says Logsdon. Private companies currently have a contract with NASA to ferry cargo up and down to the International Space Station, and will soon transport US astronauts. A council could strengthen commercial space connections outside of NASA. The council could also better coordinate diplomatic relationships with other space-faring countries, Logsdon says. \u201cThere\u2019s a full plate there to be eaten,\u201d he says. Whether US space agencies will get adequate funding to carry out such efforts is unclear. Speaking at Johnson Space Center, Pence said that \u201cNASA will have the resources and supports you need to continue to make history\u201d. But the White House has proposed trimming the agency\u2019s US$19.7-billion budget by roughly 3% for the next fiscal year to $19.1 billion, a relatively moderate reduction compared with the double-digit cuts outlined for other science agencies. Scott Pace, the head of the Space Policy Institute at GWU, is widely expected to be named as head of the space council\u2019s staff. Pace\u2019s extensive government experience includes roles at NASA and OSTP during the administration of George W. Bush. \n               Waiting on the White House \n             Trump has said little about NASA  other than to reiterate themes of American leadership in space, and to joke about recycled urine during a conversation in April with Peggy Whitson, then the commander of the International Space Station. Pence hinted in March that the council would be resurrected. Space-policy advisors to the Trump\u2013Pence campaign argued for its reinstatement last October, before Trump won the presidency. The new administration has yet to put its stamp on the agency. Trump has not named a new NASA chief. Although the agency continues to develop a heavy-lift rocket and crew capsule to take astronauts to deep space,  the \u2018Journey to Mars\u2019 that was pushed during the presidency of Barack Obama  is no longer ascendant. It remains unclear whether Trump\u2019s White House will work to send astronauts back to the Moon, on to Mars or to some other deep-space destination. (NASA has abandoned Obama\u2019s plan to bring an asteroid to orbit near the Moon and send astronauts to visit it there.) Pence made the space-council announcement at an event to introduce NASA\u2019s 12 new astronaut candidates. They include scientists such as Jessica Watkins, a geologist at the California Institute of Technology in Pasadena who works on Mars rovers, and Zena Cardman, a geobiologist at Pennsylvania State University in University Park.  \n                     Trump budget would slash science programmes across government 2017-May-23 \n                   \n                     NASA science chief: \u2018I have no worries about the resilience of this country\u2019 2016-Dec-15 \n                   \n                     The ultimate experiment: How Trump will handle science 2016-Nov-11 \n                   \n                     Obama\u2019s science legacy: a space race stalls 2016-Aug-22 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22163", "url": "https://www.nature.com/articles/nature.2017.22163", "year": 2017, "authors": [{"name": "Lindsay McKenzie"}], "parsed_as_year": "2006_or_before", "body": "App lets researchers rate life-sciences abstracts by swiping across a screen. Inspired by the dating app Tinder, which asks users to \u2018swipe right\u2019 across their screens to approve prospective matches, an app called  Papr  is inviting scientists to swipe to rate life-sciences preprints. And like other  recommendation algorithms , Papr also promises to learn from researchers\u2019 choices so that it can supply them with preprints they\u2019ll like. \u201cIt\u2019s relatively simple, but it seems to work pretty well,\u201d says Nick Strayer, a PhD student in biostatistics at Vanderbilt University in Nashville, Tennessee. He and fellow Vanderbilt biostatistician Lucy D\u2019Agostino McGowan added the swipe function and the recommender engine to Papr after a simpler version of the app was launched in October 2016 by Jeff Leek, a biostatistician at the Johns Hopkins Bloomberg School of Public Health in Baltimore, Maryland. The swipe functionality makes Papr \u201cway more interesting\u201d, says Leek in a  blogpost . Users see abstracts from bioRxiv preprints, and can swipe their screens in four directions to rate them: right if the manuscript seems \u2018exciting and probable\u2019; up for \u2018exciting and questionable\u2019, down for \u2018boring and probable\u2019 and left for \u2018boring and questionable\u2019. (On a desktop, users drag with their mouse.) Papr can also suggest connections with scientists who like the same preprints, by linking to their Twitter accounts \u2014 which could help scientists to meet new collaborators, says Strayer. So far, around 150 people have signed in to use the app, although many more are doing so anonymously, adds McGowan. Papr could collect interesting data, Strayer says. He and McGowan are thinking about releasing a leaderboard of the most popular papers, and also throwing preprints from the ArXiv physical-sciences server into the mix. Another idea is to allow users to click through from the app to read the full article, or even to use the app to identify hot topics in research. McGowan and Strayer have both been invited to work with Leek in his lab, but for now, they say, they are concentrating on their theses, and see Papr as a side-project. And Leek isn\u2019t taking Papr too seriously, either. \u201cThis app is provided solely for entertainment of the scientific community and may be taken down at any time with no notice because Jeff gets tired of it,\u201d adds a note on the app\u2019s website. \n                   Rate that journal 2015-Mar-30 \n                 \n                   How to tame the flood of literature 2014-Sep-03 \n                 \n                   Papr app \n                 Reprints and Permissions"},
{"file_id": "546335a", "url": "https://www.nature.com/articles/546335a", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Human fetuses have an immune system that acts differently from the adult version. A human fetus in its second trimester is extraordinarily busy. It is developing skin and bones, the ability to hear and swallow, and working on its first bowel movement. Now, a study published on 14\u00a0June in  Nature  finds that fetuses are also acquiring a functioning immune system\u00a0\u2014 one that can recognize foreign proteins, but is less inclined than a mature immune system to go on the attack ( N.McGovernet\u00a0al.Naturehttp://dx.doi.org/10.1038/nature22795;2017 ). The results add to a growing body of literature showing that the fetal immune system is more active than previously appreciated. \u201cIn general textbooks, you see this concept of a non-responsive fetus is still prevailing,\u201d says immunologist Jakob Michaelsson at the Karolinska Institute in Stockholm. But the fetal immune system is unique, he says. \u201cIt\u2019s not just immature, it\u2019s special.\u201d A developing fetus is constantly exposed to foreign proteins and cells, which are transferred from the mother through the placenta. In humans, this exposure is more extensive than in many other mammals, says immunologist Mike McCune at the University of California, San Francisco. As a result, laboratory mice have proved a poor model for studying the developing human fetal immune system. But fully understanding that development could reveal the reasons for some miscarriages, as well as explain conditions such as pre-eclampsia, which is associated with abnormal immune responses to pregnancy and causes up to 40% of premature births. And organ-transplant surgeons have long been interested in how a developing fetus and its mother tolerate one another without either of them launching an immune attack\u00a0\u2014 the hope is to find ways to suppress the immune system\u2019s response to transplanted organs.\u00a0 For Jerry Chan, an obstetrician and gynaecologist at the KK Women\u2019s and Children\u2019s Hospital in Singapore, understanding the fetal immune system was important for his goal of developing stem-cell treatments and gene therapies for genetic disorders in developing fetuses. Chan and his colleagues wanted to know whether there was a developmental stage at which such treatments could be given without the risk of the therapies themselves being attacked by the immune system.\u00a0 To do this, Chan teamed up with immunologist Florent Ginhoux at the Agency for Science, Technology and Research in Singapore to study dendritic cells, immune cells that break down foreign material and present fragments of it to other immune cells called T\u00a0cells. Some T\u00a0cells are then activated to target the foreign material for destruction. The team found that human fetuses have functional dendritic cells by 13\u00a0weeks of gestation. But although the cells behave much like the adult versions, their response to foreign human proteins differs: rather than mark the foreign material for annihilation, fetal dendritic cells are more likely to activate a special category of T\u00a0cell called regulatory T\u00a0cells, which suppress immune responses. This could reflect a need to avoid a catastrophic immune response against a mother\u2019s cells. \u201cYou don\u2019t want too much immune response in a developing fetus,\u201d says Ginhoux. \u201cIt is very dangerous\u00a0\u2014\u00a0this is a critical point in development.\u201d Previous studies had found specialized immune cells\u00a0\u2014\u00a0including T\u00a0cells and natural killer cells\u00a0\u2014\u00a0in fetuses as young as nine\u00a0weeks, says Ginhoux. But the dendritic-cell findings are particularly important because these cells orchestrate immune responses, says Michaelsson. Without them, he says, the body can\u2019t target specific foreign material for destruction. The results highlight the fact that the fetal immune system is not merely an immature, less-active version of its adult counterpart, but one that has its own distinct function, says transplant immunologist William Burlingham at the University of Wisconsin in Madison. Burlingham\u2019s laboratory had been studying fetal immune responses as a means of finding ways to help organ-transplant recipients tolerate their new organs without relying on immunosuppressive drugs. But a  political uproar in the United States during the past few years  over research using fetal tissue has made him shift much of his work to studying the newborn immune system, which tends to act more like the adult system. The  Nature  study highlights how this shift  could come at a price  for many areas of research, says McCune. \u201cIt\u2019s important for us to understand the function of the human fetal immune system so that we can treat fetuses that are not doing well,\u201d he says. \u201cAnd the analysis of adult and newborn cells is, as we now know, irrelevant. The fetal immune system is different.\u201d \n                     Secrets of life in a spoonful of blood 2017-Feb-07 \n                   \n                     US scientists fear new restrictions on fetal-tissue research 2017-Jan-04 \n                   \n                     The truth about fetal tissue research 2015-Dec-07 \n                   \n                     Bacteria found in healthy placentas 2014-May-21 \n                   Reprints and Permissions"},
{"file_id": "546461", "url": "https://www.nature.com/articles/546461", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Once the world's biggest DNA sequencer for research, BGI is now looking to medical applications to boost profits. China\u2019s genomics giant BGI, once the world leader in DNA sequencing for basic science, is going public \u2014 capping off a dramatic transformation into a mainly biomedical firm with a focus on reproductive health. A financial prospectus document released to support the initial public offering (IPO) details how BGI, squeezed by its rivals and the plummeting cost of sequencing, has been drawn to more-profitable pursuits, such as prenatal genetic testing, in China\u2019s expanding medical market. The shift is also in line with the  Chinese government\u2019s multibillion-yuan drive to promote precision medicine , an effort to use the reams of genomic and other medical data being created to tailor treatments. BGI is currently working out the details of the IPO, which was years in the making and approved by China\u2019s financial regulators in late May. The IPO is expected within a month and the firm hopes to raise 1.7 billion yuan (US$250 million). As the first genomics company to be listed in China, BGI will be a pioneer in the country\u2019s precision-medicine market, which is estimated to be worth 20 billion yuan by 2020. \u201cIt's a milestone for both BGI and the field,\u201d says Ruiqiang Li, who used to work for BGI and is now chief executive of competing genomics firm Beijing-based Novogene, which Li hopes to take public. \n               Income shift \n             BGI was established in 1999 as the Beijing Genomics Institute and the force behind China\u2019s contribution to the  Human Genome Project  \u2014 it sequenced a small, but symbolic, 1% of the genome. Over the next decade, it  produced a series of high-profile sequencing breakthroughs , including the genomes of  rice , the giant  panda , the cucumber, an ancient human and more than 1,000 species of gut bacteria. In 2010 \u2014\u00a0now based in Shenzhen and known simply as BGI \u2014 the company purchased 128 of the world\u2019s most-advanced genome-sequencing machines. Overnight it became the industry\u2019s most prolific player. The firm gained a  reputation as a genome factory . The number of studies based on BGI-sequenced genomes \u2014 paid for by scientists from all over the world, who acknowledged BGI scientists\u2019 contributions by making them co-authors \u2014 jumped from a handful to hundreds per year. But that number has plateaued, and it looks set to drop this year. According to the prospectus, BGI\u2019s income from research-driven sequencing dropped by more than one-quarter between 2014 and 2016, and now accounts for less than 20% of its business, down from 40% in 2014. Reproductive-health screening makes up the lion\u2019s share of the company's income, at 55% (see \u2018Focus on health\u2019). Services related to complex diseases \u2014\u00a0those caused by a combination of genetic and environmental factors \u2014 brings in 23%. The company would not comment on its operations, citing a \u201cquiet\u201d period mandated by the financial regulator before its stock-market debut. But its prospectus says that the move away from research-based sequencing is the result of the falling price of sequencing machines, which has allowed research institutes to set up their own facilities. Li says, however, that even though some institutions are trying to build their own facilities, the market for third-party research sequencing is growing. \u201cIt\u2019s not efficient and cost effective to maintain a small-scale sequencing lab,\u201d he says. \u201cMost such labs in China decided to discontinue their own platform operation and outsource sequencing to centralized sequencing centres.\u201d\u00a0 Still, sequencing for researchers isn\u2019t the business it used to be. The prospectus points out that in the early days, there was more low-hanging fruit \u2014 sequencing the whole genome of a plant or animal, for example, were large projects with big profit margins. Now, projects are smaller and less lucrative. And competition has intensified from companies such as Novogene, which says it has the largest sequencing capacity in the world. \n               Prenatal testing \n             \u201cThis shift seems to be market driven,\u201d says Dorret Boomsma of the VU University Amsterdam, who has used BGI sequences in studies of Dutch twins. \u201cApparently facilities for large-scale research sequencing are available on a more-competitive pricing, or nearer by, elsewhere.\u201d BGI\u2019s ability to keep pace in the research was also affected by its failure to develop an advanced sequencer based on technology that it bought in 2013 from Complete Genomics in Mountain View, California. It also suffered after the departure of its chief executive Jun Wang, who spearheaded many of BGI\u2019s research projects, but  left in 2015 to start his own company . Clinical sequencing in China, however, is booming, fuelled by the country\u2019s growing middle class, expanding health-care system and focus on precision medicine. Sales of BGI\u2019s non-invasive prenatal testing kit, NIFTY \u2014 which screens maternal blood to determine whether a fetus has chromosomal abnormalities such as Down\u2019s syndrome \u2014 passed the million mark in March 2016. And China\u2019s  move from a one-child to two-child policy in 2016  increased the birth rate among NIFTY\u2019s target demographic: women in their late 30s who are considered to be high risk for chromosomal abnormalities. According to an analysis by Chinese investment bank CITIC Securities, BGI has nearly 50% of the prenatal screening market in China, far ahead of its closest competitor. With the money raised from its IPO, the firm hopes to improve its reproductive and cancer-diagnosis technologies, and add other, similar, sequencing-based diagnostic services for other health conditions. It also plans to expand genetic consulting services and establish  cloud-computing platforms to crunch genomic data for precision medicine . Earlier this year, BGI struck a deal with Foxconn \u2014 the Taiwanese company that manufactures iPhones at its base in Shenzhen \u2014 to mass-produce sequencers, which BGI plans to sell to hospitals throughout China. Other sequencing companies will be watching closely to see how BGI fares in the nascent market. \u201cWe don\u2019t know the level of interest from investors. The industry is still relatively small, but it\u2019s fast growing and has a lot of potential,\u201d says Li. \n                     China\u2019s bid to be a DNA superpower 2016-Jun-22 \n                   \n                     China embraces precision medicine on a massive scale 2016-Jan-06 \n                   \n                     Gene-edited 'micropigs' to be sold as pets at Chinese institute 2015-Sep-29 \n                   \n                     Exclusive: Genomics pioneer Jun Wang on his new AI venture 2015-Jul-28 \n                   \n                     Visionary leader of China\u2019s genomics powerhouse steps down 2015-Jul-24 \n                   \n                     Chinese project probes the genetics of genius 2013-May-14 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22063", "url": "https://www.nature.com/articles/nature.2017.22063", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Uncertain location for Thirty Meter Telescope prompts soul-searching about its research value. Is second-best good enough? That\u2019s the question Canadian astronomers will confront this week as they analyze how relocating the planned Thirty Meter Telescope (TMT) could affect their science plans.  A study looking at the consequences of such a move , which researchers will present on 31 May at a meeting of the Canadian Astronomical Society in Edmonton, finds that they\u2019ll still be able to do most of what they want to do \u2014 but not everything. Legal challenges to the construction of the TMT on the Hawaiian mountain of Mauna Kea meant the international collaboration behind the facility had to consider an alternate site. But less than ideal observing conditions at their back-up site could keep scientists from pursuing what is likely to be one of the hottest topics in astronomy in the coming decade: investigating exoplanet atmospheres. The mega-telescope is \u201ca critical component of the Canadian astronomical landscape\u201d, says Michael Balogh, an astronomer at the University of Waterloo in Ontario. The country \u2014 one of six major international partners \u2014 has  committed Can$243 million  (US$180 million) to the project. \u201cIf we have to move, it\u2019s effectively a de-scope in the project,\u201d says Balogh. \n             A long, hard look \n           The back-up site, Roque de los Muchachos in La Palma, the Canary Islands, is lower in elevation than Mauna Kea, and its skies are more turbulent than those above the Hawaii mountain. That means that observing conditions are not quite as good; in particular, the extra atmosphere above La Palma interferes with much of the observing in mid-infrared wavelengths of light, the sweet spot for looking at exoplanet atmospheres. \u201cEveryone agrees that Mauna Kea is the best site,\u201d says Doug Welch, an astronomer at McMaster University in Hamilton, Ontario, who is on the TMT governing board. \u201cBut if it\u2019s impossible to develop there, there\u2019s still plenty of excellent science to be done.\u201d For instance, the TMT will have a built-in adaptive optics system to correct for turbulence in Earth\u2019s atmosphere; this will compensate for most of the blurriness of the skies above La Palma, Welch says. And adopting a flexible schedule, in which the telescope tackles different projects depending on what the sky conditions are like on a given night, would allow operators to squeeze the best science out of it. But if turbulence near the ground turns out to be worse than expected, then a TMT at La Palma won\u2019t perform as well as a leading competitor, the European Extremely Large Telescope that is under construction in Chile. A third mega-telescope, the Giant Magellan Telescope, is also being built in Chile. \n             Under pressure \n           So the pressure is on to build the TMT and start observing runs on it as quickly as possible. \u201cIn the end, these facilities need to justify themselves on their science,\u201d says Raymond Carlberg, an astronomer at the University of Toronto who left the TMT\u2019s governing board late last year in a dispute over the choice of La Palma as the alternative site. But time is running out to build the TMT in Hawaii. Project officials want to begin construction by April 2018, regardless of the location. In order to move forward on Mauna Kea, the facility needs a fresh construction permit; in the coming months, following 44 days of testimony from both sides, a retired judge is expected to make a recommendation to the state\u2019s board of land and natural resources. And if the board then issues a permit, the decision will almost certainly prompt an appeal to the state supreme court. To complicate matters further, a separate legal challenge to the University of Hawaii\u2019s right to sublease the mountaintop site to the TMT is a long way from being resolved. Wherever it ends up, the TMT will shape astronomy for decades to come, says Alan McConnachie, an astronomer at the NRC Herzberg research centre in Victoria, British Columbia. \u201cThe question the community has to figure out is, are we still excited about the science potential of the TMT?\u201d he asks. \u201cI think absolutely. The TMT is going to be transformative wherever it is.\u201d \n                   Embattled mega-telescope gets back-up site in Canary Islands 2016-Oct-31 \n                 \n                   Hawaiian court revokes permit for planned mega-telescope 2015-Dec-03 \n                 \n                   Hawaii prunes Mauna Kea telescope hub 2015-Jun-02 \n                 \n                   Crunch time for Canada\u2019s role in mega-telescope 2015-Mar-17 \n                 \n                   Thirty Meter Telescope \n                 \n                   CASCA/ACURA TMT Advisory Committee \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22024", "url": "https://www.nature.com/articles/nature.2017.22024", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Officials have signed off on an experimental vaccine in the Democratic Republic of the Congo, but the decision on whether to deploy it remains up in the air. Regulatory and ethics-review boards in the Democratic Republic of the Congo (DRC) have approved the use of an experimental Ebola vaccine to combat an  ongoing outbreak of the virus , officials announced on 29 May. If they decide to deploy the vaccine, called rVSV-ZEBOV, health-care workers will offer it to those at highest risk of contracting the disease. Uncertainties over the outbreak\u2019s magnitude mean that Congolese authorities and the World Health Organization (WHO) must determine whether the small number of confirmed cases justifies the cost and logistical complexity that comes with deploying the vaccine, says Marie-Paule Kieny, assistant director-general of health systems and innovation at the WHO\u2019s headquarters in Geneva, Switzerland. Officials have confirmed only two cases of Ebola since they started getting reports of people with Ebola-like symptoms in late April. There are 17 suspected cases in the DRC awaiting a diagnosis, as of an update from the WHO dated 28 May. Sixty-seven percent of the computer simulations run by officials predict that there will be no further cases in the next month. \n             Handle with care \n           Nonetheless, officials have spent the past two weeks preparing to transport the vaccine to the outbreak\u2019s epicentre in Likati, a remote part of the Bas-U\u00e9l\u00e9 province, a part of the country that borders the Central African Republic. Workers will need to use a combination of helicopters and motorcycles, because the heavily forested province \u2014 nearly twice the size of Ireland \u2014 doesn\u2019t have paved roads. Another option is to use small boats to traverse the region on narrow rivers. Furthermore, a lack of electricity in the area will require portable freezers capable of storing the vaccine doses at \u201380 \u00b0C. The WHO and the Congolese authorities will also need to train nurses on how best to roll out the immunizations, says Eugene Kabambi, a WHO communications officer based in Kinshasa, DRC. And communities must be educated about the vaccine so that there are no misunderstandings about its safety or its benefits, given the danger of Ebola. In the meantime, the Congolese Ministry of Health and the WHO have arranged for the deployment of two mobile laboratories in Bas-U\u00e9l\u00e9, where researchers with the Congolese National Biomedical Research Institute can run diagnostic tests for Ebola. And a group from the aid organization M\u00e9decins Sans Fronti\u00e8res (MSF, also known as Doctors Without Borders) has set up and staffed a 10-bed Ebola treatment unit near the outbreak\u2019s epicentre. \n             In case of emergency \n           In April, a WHO working group recommended the use of rVSV-ZEBOV should an outbreak occur, on the basis of  promising results from a clinical trial  conducted in 2015 during the Ebola crisis in Guinea 1 . There are 300,000 doses of the vaccine available, owing to an  agreement made in 2016  between the international organization Gavi, the Vaccine Alliance, and Merck, the pharmaceutical company that manufactures rVSV-ZEBOV. The key to Merck\u2019s vaccine is a protein expressed on the surface of the Zaire strain of Ebola, collected during a 1995 outbreak in Kikwit, DRC. This is nearly identical to the strain circulating in the country now. The protein triggers a person\u2019s immune system to produce antibodies that fight the virus. Should the vaccine be deployed, staff at MSF will vaccinate health-care workers in the hot zone and the initial group of people who had contact with those infected with Ebola, as well as a secondary group who had contact with the initial crowd. This \u2018ring-vaccination\u2019 strategy was used in Guinea in 2015 to protect those at highest risk of exposure. The infrastructure, including laboratories and equipment, and the personnel required to address the Ebola epidemic in the DRC won\u2019t come cheap. The Congolese government has estimated that its response will require US$14 million. But a humanitarian crisis in the Kasai region in central DRC is also draining resources from the government and international donors. The United Nations stated in April that it will cost at least $11 million to meet the immediate nutritional, health and educational needs of more than a million people who have been displaced by escalating conflicts in the region. \u201cEbola outbreaks are tragic but expected,\u201d says Mark Feinberg, president of the International AIDS Vaccine Initiative based in New York City. \u201cAnd this is an important opportunity to test how prepared countries are to decide whether or not they want to deploy new vaccines, and how, before they are licensed.\u201d \n                   Ebola vaccine could get first real-world test in emerging outbreak 2017-May-12 \n                 \n                   Unusual deal ensures Ebola vaccine supply 2016-Jan-20 \n                 \n                   How to beat the next Ebola 2015-Aug-05 \n                 \n                   Trial and triumph 2015-Aug-05 \n                 \n                   How Ebola-vaccine success could reshape clinical-trial policy 2015-Aug-04 \n                 \n                   Successful Ebola vaccine provides 100% protection in trial 2015-Jul-31 \n                 \n                   Nature  special: Ebola epidemic in West Africa \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22055", "url": "https://www.nature.com/articles/nature.2017.22055", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "May\u2019s sharpest science shots, selected by  Nature \u2019s photo team. \n             Inside the Palace \n           \n             Art ants \n           \n             Jupiter enhanced \n           \n             A passing lake \n           \n             Galactic spiral \n           \n             Gaia\u2019s vision \n           \n             Preserved protection \n           \n             Head start \n           \n             Support structure \n           \n             The view from above \n           \n                   Golden neurons, river piracy and bright nights 2017-Apr-28 \n                 \n                   Space ravioli, nuclear explosions and a synthetic sun 2017-Mar-31 \n                 \n                   Fake stars, panda suits and ants on treadmills 2017-Feb-24 \n                 \n                   Swimming starfish, a departing dinosaur and a lot of ice 2017-Jan-27 \n                 Reprints and Permissions"},
{"file_id": "546017a", "url": "https://www.nature.com/articles/546017a", "year": 2017, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "Genetic analysis reveals a close relationship with Middle Easterners, not central Africans. The tombs of ancient Egypt have yielded golden collars and ivory bracelets, but another treasure \u2014 human DNA \u2014 has proved elusive. Now, scientists have captured sweeping genomic information from Egyptian mummies. It reveals that mummies were closely related to ancient Middle Easterners, hinting that northern Africans might have different genetic roots from people south of the Sahara desert.\u00a0 The study, published on 30 May in  Nature Communications 1 , includes data from 90 mummies buried between 1380  bc , during Egypt\u2019s New Kingdom, and  ad  425, in the Roman era. The findings show that the mummies\u2019 closest kin were ancient farmers from a region that includes present-day Israel and Jordan. Modern Egyptians, by contrast, have inherited more of their DNA from central Africans. Archaeological discoveries and historical documents suggest close ties between Egypt and the Middle East, but \u201cit is very nice that this study has now provided empirical evidence for this at the genetic level\u201d, says evolutionary anthropologist Omer Gokcumen of the State University of New York at Buffalo. Egypt\u2019s searing climate and the ancient practice of embalming bodies  has made the recovery of intact genetic material daunting . The first DNA sequences thought to be from a mummy 2  were probably the result of modern contamination, and many scientists are sceptical 3  of  purported genetic information acquired from the mummy of King Tutankhamun 4 .\u00a0 The latest analysis succeeded by bypassing soft tissue \u2014 often abundant in Egyptian mummies \u2014 to seek DNA from bone and teeth. Researchers carefully screened the DNA to rule out contamination from anyone who had handled the mummies since their excavation a century ago in the ancient town of Abusir el-Meleq.\u00a0 \u201cMore than half of the mummies we studied had pretty decent DNA preservation,\u201d says co-author Johannes Krause, a palaeogeneticist at the Max Planck Institute for the Science of Human History in Jena, Germany.\u00a0 The team \u201csucceeds where previous studies on Egyptian mummies have failed or fallen short\u201d, says Hannes Schroeder, a palaeo\u00adgeneticist at the University of Copenhagen. Now, researchers can hope to answer questions such as whether immigration drove ancient-Egyptian population growth, adds Sonia Zakrzewski, a bioarchaeologist at the University of Southampton, UK.\u00a0 The scientists obtained information about variations in mitochondrial DNA, which is passed from mother to child, from 90 mummies. Because of contamination, the team was able to acquire detailed nuclear DNA, which is inherited from both parents, from only three mummies. Both types of genomic material showed that ancient Egyptians shared little DNA with modern sub-Saharan Africans. Instead, their closest relatives were people living during the Neolithic and Bronze ages in an area known as the Levant. Strikingly, the mummies were more closely related to ancient Europeans and Anatolians than to modern Egyptians. The researchers say that there was probably a pulse of sub-Saharan African DNA into Egypt roughly 700 years ago. The mixing of ancient Egyptians and Africans from further south means that modern Egyptians can trace 8% more of their ancestry to sub-Saharan Africans than can the mummies from Abusir el-Meleq.\u00a0 The new data can\u2019t explain why the ancient Egyptians were so tightly aligned with people from the Middle East. Was it the result of migration, or were the Stone Age hunter-gatherers of northern Africa genetically similar to those of the Levant? It\u2019s too early to tell, Krause says, but there\u2019s a better chance now of getting answers. \u201cThis is the first glimpse of the genetic history of Egypt,\u201d he says. \u201cBut it\u2019s really just the start.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Ancient DNA from hot climes yields its secrets 2015-Oct-13 \n                   \n                     Underwater archaeology: Hunt for the ancient mariner 2012-Jan-25 \n                   \n                     Ancient DNA: Curse of the Pharaoh's DNA 2011-Apr-27 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22090", "url": "https://www.nature.com/articles/nature.2017.22090", "year": 2017, "authors": [{"name": "Andrew Silver"}], "parsed_as_year": "2006_or_before", "body": "Private firm says its watchlist of untrustworthy journals will be objective and transparent \u2014 but not free. The blacklist is dead; long live the blacklist. Five months after  a widely read blog listing possible \u2018predatory\u2019 scholarly journals and publishers was shut down , another index of untrustworthy titles is appearing \u2014 although this version will be available only to paying subscribers. Scholarly-services firm  Cabell\u2019s International  in Beaumont, Texas, says that on 15 June it will launch its own list of predatory journals: those that deceive their authors or readers, for example by charging fees to publish papers without conducting peer review. The firm  described its work on 31\u00a0May , at the annual meeting of the Society for Scholarly Publishing in Boston, Massachusetts. The previous, now-defunct, list was run by academic librarian Jeffrey Beall of the University of Colorado Denver. Since 2010, he had tracked what he called \u201cpotential, possible or probable predatory scholarly open-access publishers\u201d and journals on his blog, attracting huge attention and some legal threats from publishers unhappy at their inclusion. But in January this year, Beall deleted the site, without saying why. Cached copies have been posted elsewhere online. By January, Cabell\u2019s was well into the process of designing its own blacklist, says project manager Kathleen Berryman. The company already publishes a \u2018whitelist\u2019 of trustworthy journals, to which about 800 institutions subscribe; websites such as the  Directory of Open Access Journals  provide other whitelists. But Berryman says there\u2019s also value in having a list to monitor for journals with bad business practices. As of 26 May, the blacklist contains about 3,900 journals, she says, with more to come. It will be provided as an add-on to subscribers to the company's whitelist. \n             Clear criteria \n           Berryman says the firm was aware of complaints that Beall\u2019s list wasn\u2019t objective and that his criteria for including journals weren\u2019t transparent. So Cabell\u2019s uses some 65 criteria \u2014 which will be reviewed quarterly \u2014 to check whether a journal should be on its blacklist, adding points for each suspect finding. Examples include fake editors, plagiarized articles and unclear peer-review policies, says Berryman, although she declined to provide all criteria, saying that the firm would present them later in the year. A team of four employees checks for evidence that journals meet the criteria by searching online or contacting authors and journals for verification. \u201cIt\u2019s pretty much as scientific as we can get at this point,\u201d she says. Some of the publishers and journals listed by Beall aren\u2019t on Cabell\u2019s list, says Berryman. And Cabell\u2019s has added new journals, including some that aren\u2019t open access. The firm declined to provide details of the differences between its list and Beall's, but says that it will clearly state all the reasons that a journal is on its list. Berryman hopes that will limit libel suits. Publishers or journals will be able to contact Cabell\u2019s to find out whether they are indexed, and will have the opportunity to appeal their status once a year. \n             Black and white \n           Some researchers say there\u2019s little value in a blacklist. Cameron Neylon, who studies research communications at Curtin University in Perth, Australia, says such lists require a lot of work and will always miss some journals. He thinks that researchers should rely on whitelists of trustworthy journals, and that their training should cover how to judge journal quality. But Natalia Zinovyeva, an economist at Aalto University in Helsinki who is studying the editorial processes of some of the journals that Beall once tracked, thinks Cabell\u2019s list will be \u201cextremely valuable\u201d to funding or hiring committees without a wide level of expertise, who could use it as a tool to help evaluate researcher CVs. And Beall, who was once an informal consultant for Cabell\u2019s, says he thinks blacklists are still useful as a timesaving tool for authors who are deciding where to publish. Cabell's will probably find managing its appeals process one of its most difficult tasks, he says. It\u2019s unclear how many institutions or people will sign up once the list is released, but pricing will vary by institution. Cabell\u2019s had originally planned to make the list free \u2014 and still hopes to do so eventually, Berryman says \u2014 but is charging to cover the costs involved in creating it.  Anyone wanting to produce their own watch list as a competing service will \u201cquickly realize how much work and time goes into this\u201d, says Berryman. \u201cI don\u2019t foresee us having competition.\u201d \n                   Controversial website that lists \u2018predatory\u2019 publishers shuts down 2017-Jan-18 \n                 \n                   Open-access index delists thousands of journals 2016-May-09 \n                 \n                   Backlash after Frontiers journals added to list of questionable publishers 2015-Oct-23 \n                 \n                   Rate that journal 2015-Mar-30 \n                 \n                   Investigating journals: The dark side of publishing 2013-Mar-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22036", "url": "https://www.nature.com/articles/nature.2017.22036", "year": 2017, "authors": [{"name": "Sara Reardon"}, {"name": "Jeff Tollefson"}, {"name": "Alexandra Witze"}, {"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Proposed cuts include 11% at the National Science Foundation, 18% at the National Institutes of Health and 30% at the Environmental Protection Agency. US President Donald Trump released a revised budget plan on 23 May that would cut science programmes across the federal government in 2018. Biomedical, public-health and environmental research would all be pared back. Those cuts, along with deep reductions in programmes for the poor, are balanced by a proposed 10% increase in military spending. This overall strategy echoes  the \u201cskinny budget\u201d outline that Trump released in March , which faced opposition in Congress. Earlier this month,  lawmakers approved a 2017 budget deal  that increased funding for key science agencies and ignored the president's push for cuts. \u201cThis budget is terrible, and we\u2019re confident that Congress will ignore it,\u201d says Jennifer Zeitzer, director of legislative relations at the Federation of American Societies for Experimental Biology in Bethesda, Maryland. Here,  Nature  breaks down the president's budget request. \n               National Institutes of Health \n             The National Institutes of Health (NIH) would face a cut of 18% in the Trump plan, from US$31.8 billion in 2017 to $26 billion in 2018. According to budget documents, this would be achieved by \u201cstructural changes\u201d to reduce the amount of overhead (known as indirect costs) that the agency pays to grant recipients. Under the current system,  individual research institutions negotiate with the government  to set the rate at which they are reimbursed for expenses such as administration and the construction and maintenance of facilities. The White House wants one rate for all grantees to mitigate \u201cthe risk for fraud and abuse\u201d. The budget would eliminate the $70-million Fogarty International Center in Bethesda, which coordinates with other NIH institutes to train researchers and health-care providers overseas. The rest of the cuts would be spread relatively evenly across the NIH\u2019s 26 remaining institutes and centres. The White House plan would create the $272-million National Institute for Research on Safety and Quality, which would receive another $107 million from an established trust fund on patient-centered outcomes research. The institute would study the outcomes of treatments and health services, taking on the role of the independent Agency for Healthcare Research and Quality in Rockville, Maryland, which would be eliminated. The Trump budget also includes $86 million for the NIH\u2019s arm of  the Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative . And it sets aside $100 million for the Precision Medicine Initiative:  a 10-year effort to track the health of 1 million Americans  that is scheduled to launch later this year. Congressman Tom Cole (Republican, Oklahoma), who chairs the US House of Representatives spending subcommittee that funds the NIH, has said that he does not expect that Congress will support Trump\u2019s proposed cuts. Other lawmakers from both major political parties  have also come out against the president\u2019s plan for the NIH . \n               Centers for Disease Control and Prevention \n             One bright spot for public health is Trump\u2019s proposal to establish an \u201cemergency response fund\u201d within the Department of Health and Human Services, which includes the Centers for Disease Control and Prevention (CDC) in Atlanta, Georgia. This would give the department the authority to move up to 1% of its budget to respond to emerging health threats, such as the recent outbreaks of the  Ebola  and  Zika  viruses. Much of this work would probably involve the CDC. Public-health officials have called for such a fund for years. But Georges Benjamin, executive director of the American Public Health Association in Washington DC, says that Trump\u2019s proposal is \u201ca shell game\u201d. The White House wants to slash more than $1.2 billion from the CDC\u2019s budget, with the largest cuts coming from public-health preparedness programmes. \u201cThey dramatically cut the actual operating funds and then create the capacity to go into your pocket, which has much less money in it,\u201d Benjamin says. \u201cIt\u2019s smoke and mirrors.\u201d \n               Food and Drug Administration \n             The Trump plan would cut government funding for the US Food and Drug Administration by 31% from the 2017 level, to $1.9 billion. That $845-million decrease would be offset by a $1.3-billion increase in the \u201cuser fees\u201d that companies pay the agency to review their products. The law that sets the agency's user-fee rate expires in September, and Congress is working on reauthorizing it. Draft legislation released jointly by the House and Senate in April would raise user fees by only $400 million per year. \n               National Science Foundation \n             The budget for the National Science Foundation (NSF) would be cut by about 11% from the 2016 level, to $6.7 billion. That would allow the agency to give out 8,000 new grants in fiscal year 2018, about 800 fewer than it awarded in 2016. Among the NSF\u2019s seven directorates, the largest cuts would come from social and behavioural sciences (down 10.4%, to $244 million), computer science (down 10.3%, to $839 million) and geosciences (down 10.1%, to $1.2 billion). Biology would see the smallest reduction \u2014 7.1%, to $672 million. The Office of Integrative Activities, which supports interdisciplinary research, would see the largest cut among the agency\u2019s main accounts. Its budget would drop by 26%, to $316 million. The agency\u2019s  Ocean Observatories Initiative, a collection of instrumented seafloor arrays , would be cut by almost 44%, to $31 million. The programme began full operations in June 2016, when real-time data began flowing in after nearly a decade of construction and development. \n               NASA \n             Trump requested $19.1 billion for NASA, a 2.8% decrease from the 2017 level. The agency's science directorate would receive $5.7 billion, a drop of nearly 1%. Within that directorate, funding for Earth science would drop by 8.7%, from $1.92 billion to $1.75 billion. The budget would eliminate five Earth-observing missions, for reasons such as redundancy with other measurements and steep technological challenges. Four of these programmes  were targeted for cuts in the March 'skinny budget' : Trump's latest budget would also eliminate support for an instrument intended to measure reflected sunlight and Earth's thermal radiation. The instrument is meant to fly on future weather satellites. Congress has already rejected Trump's plan to eliminate the PACE mission. Lawmakers set aside $90 million for the programme in the 2017 funding law enacted earlier this month. The White House proposal would increase support for planetary sciences by 4.5% compared to the 2017 level, to $1.93 billion. Notably, Trump included a $425-million request for a mission to fly past  Jupiter\u2019s moon Europa , a perennial darling of Congress. There is no mention of a follow-on lander mission, which some lawmakers have also argued for. The proposed budget also continues funding for  ongoing missions such as the Mars 2020 rover , but no additional money to begin developing a follow-on Mars orbiter to replace ageing ones that are currently in orbit. \u201cI\u2019m disappointed to see that,\u201d says Casey Dreier, director of space policy for the Planetary Society in Pasadena, California. \u201cWe\u2019re underinvesting in the infrastructure at Mars.\u201d Funding for NASA\u2019s astrophysics division would increase by 2.3% from the 2017 level, keeping the James Webb Space Telescope on track for an October 2018 launch. Heliophysics funding would remain flat as the Solar Probe Plus spacecraft, which is designed to swoop by the Sun, moves towards a launch next year. Robert Lightfoot, NASA\u2019s acting administrator, noted that the proposed science budget would support 60 operating missions and 40 that are under development. \u201cThis budget still includes significant Earth-science efforts, including 18 Earth-observing missions in space as well as airborne missions,\u201d he said in a statement. Elsewhere, NASA would continue to work on its heavy-lift rocket and crew capsule to take astronauts beyond low Earth orbit. Its education office would be eliminated entirely, however. \n               Department of Energy \n             The US Department of Energy would receive $28 billion under the president's plan, a 5.3% reduction from 2016. The department's research programmes would take a much larger hit, however, particularly those focused on clean-energy technologies. The Office of Science would see its budget cut by 16%, from $5.3 billion in 2017 to just under $4.5 billion in 2018. The biggest decreases by sheer dollar amount would come from basic energy sciences and biological and environmental research, but nearly all research programmes would feel the pinch. The lone exception is advanced scientific computing, which would receive a 16% boost to $722 million. Funding for advanced energy technologies would drop by nearly $2.2 billion, or 53%. That includes a proposed $1.4 billion cut to the Office of Energy Efficiency and Renewable Energy. The Advanced Research Projects Agency \u2014 Energy (ARPA-E), which was designed to pursue riskier projects that could lead to major breakthroughs, would see its budget drop by 93% compared to 2016, from more than $291 million to just $20 million. The biggest winner at the Department of Energy would be the National Nuclear Security Administration (NNSA), whose duties include overseeing the department's nuclear-weapons programme. The NNSA would see its budget increase by 11% compared to 2016, from $12.5 billion to $13.9 billion. Nearly $1.4 billion of that boost would go to the weapons programme, while nonproliferation efforts would be cut by nearly 8%, to $1.8 billion. \n               Environmental Protection Agency \n             The White House proposal would make good on promises to shrink and reorganize the US Environmental Protection Agency (EPA), which would see its budget cut by more than 30% to $5.7 billion. Trump would slash spending on pollution-control programmes and research and development, eliminating about 23% of the agency\u2019s roughly 15,000 staff members along the way. The budget would overhaul the EPA\u2019s regulatory agenda. It would eliminate funding to implement the agency's strategy to curb greenhouse-gas emissions from power plants \u2014  which is known as the Clean Power Plan  \u2014 and dozens of other pollution-control programmes. The EPA\u2019s Office of Research and Development, which conducts the bulk of the agency\u2019s research, would receive around $277 million, a reduction of 43% compared to 2017. That figure includes a cut of more than $50 million to the Air, Climate and Energy programme, which would be rebranded as the Air and Energy programme. Overall, the Office of Research and Development would lose 624 full-time positions, which is nearly 35% of its current staff. The budget would eliminate support for the Great Lakes and Chesapeake Bay restoration initiatives, and reduce programmes to help states and Native American tribes tackle pollution by cutting more than 23%, to $2.7 billion. Such programmes have been popular among lawmakers in Congress. A senior EPA official said that the proposed budget, if implemented, would lead to significant lay-offs and challenge the agency's ability to attract and maintain high-quality scientists. The official noted that Congress rejected major cuts to the agency in the 2017 funding deal approved earlier this month, however, and said that employees remain hopeful. \"People are hanging in there, with the belief that Congress will come through in the end,\" the official said. \n               US Geological Survey \n             The US Geological Survey would be cut by 13% from the 2017 level, to $922 million. That would include eliminating the entire $8.2-million federal contribution to the fledgling  earthquake early-warning system on the US west coast , which gives seconds of warning about incoming ground-shaking to hospitals, transportation networks and other public services. It is a \u201csmall, very cost-effective public safety project\u201d, says John Vidale, a seismologist at the University of Washington in Seattle who works on the system. He says that he felt \u201csurprise and dismay\u201d at its proposed termination. Other programmes would be tightened across the board. Wildlife research would drop by 22% from 2017 operating levels, to $35.5 million, while the project to study and mitigate volcanic hazards would be cut by 14%, to $22.4 million. Environmental-health programmes would drop by 20%, to $17.1 million; among the cuts would be $3.5 million to study the health impacts of pollutants in the Chesapeake Bay, Great Lakes and other regions. Mineral and energy resources would get a 2% increase, to $74.4 million. \n               National Oceanic and Atmospheric Administration \n             The National Oceanic and Atmospheric Administration (NOAA) would receive nearly $4.8 billion, a decrease of about 17%, or $987 million, compared to 2017. The majority of the cuts would come from the agency's research activities and satellites. The budget for the satellite programme would fall by $530 million to $1.8 billion compared to 2017. The proposal would cut funding for the Joint Polar Satellite System (JPSS) \u2014 a series of polar-orbiting probes that will collect weather and other environmental data \u2014 by $221 million. That includes a cut of 51%, or $189 million, for the fourth and fifth satellites in the series. The agency's Office of Oceanic and Atmospheric Research would be cut by $131 million, to $350 million. The White House proposal would also reduce the climate-research budget by more than 19%, to $128 million, while research focused on oceans, coasts and the Great Lakes would be cut by nearly 48%, to $99 million. The Trump plan would also cut various grant programmes that fund research at universities and other institutions. In particular, the budget would eliminate $75 million for a pair of grant programmes that are targeted at coastal research.  \n                     How Trump\u2019s science cuts could hurt states that voted for him 2017-May-17 \n                   \n                     Science wins reprieve in US budget deal 2017-May-01 \n                   \n                     Republican scientists negotiate the Trump era 2017-Apr-18 \n                   \n                     NIH research grants yield economic windfall 2017-Mar-30 \n                   \n                     Trump faces backlash on health-agency cuts 2017-Mar-17 \n                   \n                     US science agencies face deep cuts in Trump budget 2017-Mar-16 \n                   \n                     Nature  special: Tracking the Trump White House \n                   Related external links Reprints and Permissions"},
{"file_id": "546016a", "url": "https://www.nature.com/articles/546016a", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Parties promise more money for research, but scientists fear impact of split with European Union. Ahead of a UK election that will decide who leads the country\u2019s exit negotiations with the European Union, a remarkable consensus has emerged among the main national parties. All three have  pledged in their manifestos to spend more money on science . Each is \u201cputting science at the heart of their programme for the future of Britain\u201d, says Sarah Main, director of the London-based Campaign for Science and Engineering. Yet as the uncertainty of Brexit hangs over the future of British science, for many researchers the promises may seem more like consolation prizes. Almost a year after the country voted to leave the EU, scientists still don\u2019t know what the split will mean for funding and collaborations with EU colleagues \u2014 while non-British EU scientists remain unclear about their future residency status. Compared to many other major science nations, Britain spends relatively little on research and development (R&D): just 1.7% of its gross domestic product (GDP). By contrast, Germany spends 2.9%, and the United States 2.8%. But the governing Conservative Party \u2014 which polls suggest will win the 8 June election \u2014 has said it wants to raise UK spending to 2.4% within 10 years, with a longer-term goal of 3%. Labour, the main rival party, has promised 3% by 2030 and the Liberal Democrats, third in national polls, have set a \u201clong-term goal\u201d to double science spending. In theory, these targets would mean billions more for research. But the proportion of GDP spent isn\u2019t necessarily an indicator of a nation\u2019s research health, says Kieron Flanagan, a science-policy researcher at the Alliance Manchester Business School. \u201cSome wags have pointed out that the easiest way to achieve the 3% is by crashing the economy,\u201d he says. \u201cWhich is true, and it actually points to the meaninglessness of that kind of ratio.\u201d Much R&D spending comes through the private sector, over which the government has no direct control, he adds. \n               Research rhetoric \n             In recent decades, Labour has been a champion of research and innovation, and academia has been seen as a bastion of its support. The party set the country\u2019s most recent long-term research target: while in government in 2004, it promised to push R&D spending to 2.5% of GDP by 2014, although it failed to do so. But the Conservatives have gradually increased their focus on science. The words \u2018science\u2019 and \u2018research\u2019 \u2014 or variations of these \u2014 didn\u2019t appear in their manifesto in 2005, but garnered 28\u00a0mentions this year (see \u2018Political patter\u2019). And in the past year, the party \u2014 led by Prime Minister Theresa May, who took over after the Brexit vote \u2014 has  announced an extra \u00a32\u00a0billion (US$2.6 billion) per year in government spending on research  by 2020. \u201cThe Conservative Party put its money where its mouth is. There is clearly an upwards trajectory of support for science and research,\u201d says David Willetts, who was UK science minister from 2010 to 2014. Yet at the same time, May is pledging to  slash immigration , raising concerns about the country\u2019s attractiveness to overseas researchers and students. And the Conservatives are taking a hard line on Brexit negotiations. Whereas Labour has promised to immediately guarantee residency and other rights for EU citizens in the United Kingdom, and has said that it will seek to stay part of EU research programmes and the popular Erasmus student-exchange scheme, the Conservatives have made no such promises. They have, however, said that they want to maintain collaborations with European partners. John Unsworth, an energy research consultant who chairs the network Scientists for Labour, thinks the Conservative commitment to science is \u201cup and down\u201d, and more focused on its commercial aspects than on basic science. Of the three parties, only the Liberal Democrats explicitly oppose leaving the EU \u2014 a stance that is bringing them scientists\u2019 support, says Julian Huppert, a former biochemist who was Liberal Democrat Member of Parliament for Cambridge until he lost his seat in 2015. Huppert, who now works on science and technology policy at the University of Cambridge, is campaigning for re-election in that city. Many scientists are volunteering for his campaign, he says. With the Conservatives seemingly on course for victory, some scientists say that concerns over Brexit trump any other promises. \u201cI would not consider voting for any party hell-bent on pursuing Brexit whatever the cost, and without providing any analysis on the possible scenarios that we have for a Brexit future,\u201d says Anne Glover, a prominent biologist who was formerly the European Commission\u2019s chief science adviser, and is now dean for Europe at the University of Aberdeen. \u201cIt seems to me we had an evidence-free EU referendum and we are heading towards an evidence-free Brexit,\u201d she says. Additional reporting by Elizabeth Gibney. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Keep shouting to save science 2017-May-31 \n                   \n                     The most powerful man in UK science on his new role 2017-Feb-08 \n                   \n                     UK scientists excited by surprise \u00a32-billion government windfall 2016-Nov-23 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22091", "url": "https://www.nature.com/articles/nature.2017.22091", "year": 2017, "authors": [{"name": "Sarah McQuate"}], "parsed_as_year": "2006_or_before", "body": "Brain cells in monkeys are tuned to react to specific combinations of features, rather than to a whole face. People can pick a familiar face out of a crowd without thinking too much about it. But how the brain actually does this has eluded researchers for years. Now, a study shows that rhesus macaque monkeys rely on the coordination of a group of hundreds of neurons that pay attention to certain sets of physical features to recognize a face. The findings, published on 1 June in  Cell 1 , clarify an issue that has been the subject of multiple theories but no satisfying explanations. \u201cThe real cartoon view has been that individual cells are dedicated to respond to individual people,\u201d says David Leopold, a neuroscientist at the US National Institute of Mental Health in Bethesda, Maryland. But other theories suggested that  groups of neurons worked in concert to recognize a face . The latest results show that each neuron associated with facial recognition, called a face cell, pays attention to specific ranked combinations of facial features. \u201cWe have cracked the code,\u201d says study co-author Doris Tsao, a systems neuroscientist at the California Institute of Technology (Caltech) in Pasadena. \n             A leap forward \n           To start, Tsao and Le Chang, a neuroscientist also at Caltech, studied the brains of two rhesus macaque monkeys ( Macaca mulatta ) to determine the location of the animals\u2019 face cells. They showed the monkeys images of human faces or other objects, including bodies, fruit and random patterns. They then used functional magnetic resonance imaging to see which brain regions lit up when the animals saw a face. The team focused on those hotspots to see what the face cells were doing. Tsao and Chang used a set of 2,000 human faces with varying characteristics, such as the distance between the eyes or the shape of the hairline, for the monkeys to view. The neuroscientists then implanted electrodes into the macaques\u2019 brains to compare the responses of individual neurons to the facial differences. Tsao and Chang recorded responses from a total of 205 neurons between the two monkeys. Each neuron responded to a specific combination of some of the facial parameters.\u00a0 \u201cThey have developed a model that goes from a picture on a computer screen to the responses of neurons way the heck down in the visual cortex,\u201d says Greg Horwitz, a visual neurophysiologist at the University of Washington in Seattle. \u201cThis takes a huge step forward,\u201d he says, because the model maps out how each cell responds to all possible combinations of facial features, instead of just one. \n             Playing favourites \n           Tsao and Chang wondered whether, within the specific combination of characteristics that a face cell recognized, each neuron was better tuned to particular features than to others. They tested this idea by trying to recreate the faces the monkeys were shown, on the basis of each neuron\u2019s response to its cast of characteristics. Based on the strength of those signals, the neuroscientists could recreate the real faces almost perfectly. When the monkeys saw faces that varied according to features that a neuron didn\u2019t care about, the individual face cell\u2019s response remained unchanged. In other words, \u201cthe neuron is not a face detector, it\u2019s a face analyser\u201d, says Leopold. The brain \u201cis able to realize that there are key dimensions that allow one to say that this is Person A and this is Person B.\u201d Human brains probably use this code to recognize or imagine specific faces, says Tsao. But scientists are  still unsure about how everything is linked together . One message is clear for neuroscientists. \u201cIf their inclination is to think: \u2018We know how faces are recognized because there are a small number of face cells that sing loud when the right face is seen,\u2019 I think that notion should gradually go away, because it\u2019s not right,\u201d says Leopold. \u201cThis study presents a more realistic alternative to how the brain actually goes and analyses individuals.\u201d \n                   Monkeys seem to recognize their reflections 2015-Jan-09 \n                 \n                   Computer science: The learning machines 2014-Jan-08 \n                 \n                   Neuroscience: Through the eyes of a mouse 2013-Oct-09 \n                 \n                   Wasps clock faces like humans 2011-Dec-01 \n                 \n                   Celebrity shots probe face recognition 2004-Dec-13 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22095", "url": "https://www.nature.com/articles/nature.2017.22095", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Huge ocean-floor craters were caused by the expulsion of pressurized greenhouse gas thousands of years ago. Huge craters in the floor of the Arctic Ocean are the collapsed remains of methane domes which exploded after the last Ice Age as the glaciers above them retreated, research suggests. Even now, some 11,600 years after the last gas domes burst, methane is still seeping out of the sea floor. The methane explosions, which created craters up to 1 kilometre wide in an area that was once solid ice, but is now the northern Barents Sea off the coast of Norway, are not merely a geological curiosity. \u201cThese are processes that could take place in front of contemporary ice sheets,\u201d says Karin Andreassen, a marine geologist and geophysicist at the Centre for Arctic Gas Hydrate, Environment and Climate in Troms\u00f8, Norway, who led the study, published in  Science 1 . Methane is a potent greenhouse gas, so it is tempting to speculate that large seafloor explosions might contribute to global warming. But so far there is little evidence for this, as it is not clear if the gas reaches the atmosphere. Craters and smaller pockmarks have been spotted on sea floors around the world, but it\u2019s not always clear what causes them. To investigate, Andreassen and her team revisited a cluster of craters discovered in the 1990s, which researchers had already suggested may have been created by the retreat of glaciers 2 , 3 . Using high-resolution sonar surveys, the team identified around 100 craters that were at least 300 metres wide, as well as hundreds of smaller ones, in the space of 440 square kilometres. \n             Under the ice \n           The team also discovered mounds in the sea floor \u2014 known as pingos \u2014 created by methane gas that has pushed towards the surface. Seismic data revealed fractures in the sea bed and identified deep sources of hydrocarbons that could feed the area. Acoustic surveys show that methane is still seeping into the sea from around 600 spots. \u201cThe data set is beautiful,\u201d says Carolyn Ruppel, a geophysicist who heads the US Geological Survey\u2019s Gas Hydrates Project in Woods Hole, Massachusetts. Ruppel says the Norwegian team tied things together by simulating the evolution of the area with a detailed ice-sheet model. \u201cI think they really have nailed this area very well.\u201d The ice sheet covering what is now the Barents sea was around 2 kilometres thick at the height of the last glacial era, around 23,000 years ago, and its weight put pressure on the underlying floor. At the time, methane gas in the crust would have been squeezed into methane hydrates \u2014 deposits in which methane molecules are trapped in lattices of water ice. Hydrates are still common along many continental shelves. The hydrates beneath the Barents Sea were stable until the glacier began to retreat some 17,000 years ago, when falling pressure enabled methane to flow towards the sea-floor surface. This flow of methane created pingos, many of which would eventually burst. \n             Powerful pop \n           It remains unclear whether gas from the sea floor would have actually made it into the atmosphere, where it could contribute to global warming, says John Kessler, an oceanographer at the University of Rochester in New York. Kessler has found, for example, that microbes in the deep ocean consumed the methane released during the 2010 Deepwater Horizon spill in the Gulf of Mexico 4 , 5 . \u201cThe release of methane from the sea floor, even catastrophically, should not inherently imply a release to the atmosphere,\u201d he says. Andreassen\u2019s team has yet to calculate how much methane would have been released during this period, but she says the blowouts must have been powerful to create such massive craters. That increases the odds that some of the methane might have made it into the atmosphere, she says. \n                   Arctic 2.0: What happens after all the ice goes? 2017-Feb-08 \n                 \n                   Biogeochemistry: Long-term effects of permafrost thaw 2016-Sep-28 \n                 \n                   Climate science: Understand Arctic methane variability 2014-May-14 \n                 \n                   Japanese test coaxes fire from ice 2013-Apr-23 \n                 \n                   Centre for Arctic Gas Hydrate, Environment and Climate \n                 \n                   US Geological Survey\u2019s Gas Hydrates Project \n                 Reprints and Permissions"},
{"file_id": "546015a", "url": "https://www.nature.com/articles/546015a", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Studies to treat vision loss and Parkinson\u2019s disease are the first to proceed under new regulations. In the next few months, surgeons in the Chinese city of Zhengzhou will carefully drill through the skulls of people with Parkinson\u2019s disease and inject 4 million immature neurons derived from human embryonic stem cells into their brains. Then they will patch the patients up, send them home and wait.\u00a0 This will mark the start of the first clinical trial in China using human embryonic stem (ES) cells, and the first one worldwide aimed at treating Parkinson\u2019s disease using ES cells from fertilized embryos. In a second trial starting around the same time, a different team in Zhengzhou will use ES cells to target vision loss caused by age-related macular degeneration. The experiments will also represent the first clinical trials of ES cells under regulations that China adopted in 2015, in an attempt to ensure the ethical and safe use of stem cells in the clinic. China previously had no clear regulatory framework, and many companies had used that gap as an excuse to market unproven stem-cell treatments.\u00a0 \u201cIt will be a major new direction for China,\u201d says Pei Xuetao, a stem-cell scientist at the Beijing Institute of Transfusion Medicine who is on the central-government committee that approved the trials. Other researchers who work on Parkinson\u2019s disease, however, worry that the trials might be misguided. Both studies will take place at the First Affiliated Hospital of\u00a0Zhengzhou\u00a0University in Henan province. In the first, surgeons will inject ES-cell-derived neuronal-precursor cells into the brains of individuals with Parkinson\u2019s disease. The only previous trial using ES cells to treat Parkinson\u2019s began last year in Australia; participants there received stem cells from parthenogenetic embryos\u00a0\u2014\u00a0unfertilized eggs that are triggered in the lab to start embryonic development. In the other Zhengzhou trial, surgeons will take retinal cells derived from ES cells and transplant them into the eyes of people with age-related macular degeneration. The team will follow a similar procedure to that of previous ES-cell trials carried out by researchers in the United States and South Korea. Qi Zhou, a stem-cell specialist at the Chinese Academy of Sciences Institute of Zoology in Beijing, is leading both efforts. For the Parkinson\u2019s trial, his team assessed hundreds of candidates and have so far have picked ten who best match the ES cells in the cell bank, to reduce the risk of the patients\u2019 bodies rejecting the cells. The 2015 regulations state that hospitals planning to carry out stem-cell clinical work must use government-certified ES-cell lines and pass hospital-review procedures. Zhou\u2019s team completed four years of work with a monkey model of Parkinson\u2019s, and has met the government requirements, he says.\u00a0 Parkinson\u2019s disease is caused by a deficit in dopamine produced by brain cells. Zhou\u2019s team will coax ES cells to develop into precursors to neurons, and will then inject them into the striatum, a central region of the brain implicated in the disease.\u00a0 In their unpublished study of 15 monkeys, the researchers did not observe any improvements in movement at first, says Zhou. But at the end of the first year, the team examined the brains of half the monkeys and found that the stem cells had turned into dopamine-releasing cells. He says that they saw 50% improvement in the remaining monkeys over the next several years. \u201cWe have all the imaging data, behavioural data and molecular data to support efficacy,\u201d he says. They are preparing a publication, but Zhou says that they wanted to collect a full five years\u2019 worth of animal data.\u00a0 \n               Maturity concerns \n             Jeanne Loring, a stem-cell biologist at the Scripps Research Institute in La Jolla, California, who is also planning stem-cell trials for Parkinson\u2019s, is concerned that the Australian and Chinese trials use neural precursors and not ES-cell-derived cells that have fully committed to becoming dopamine-producing cells. Precursor cells can turn into other kinds of neurons, and could accumulate dangerous mutations during their many divisions, says Loring. \u201cNot knowing what the cells will become is troubling.\u201d But Zhou and the Australian team defend their choices. Russell Kern, chief scientific officer of the International Stem Cell Corporation in Carlsbad, California, which is providing the cells for and managing the Australian trial, says that in preclinical work, 97% of them became dopamine-releasing cells. Lorenz Studer, a stem-cell biologist at the Memorial Sloan Kettering Cancer Center in New York City who has spent years characterizing such neurons ahead of his own planned clinical trials, says that \u201csupport is not very strong\u201d for the use of precursor cells. \u201cI am somewhat surprised and concerned, as I have not seen any peer-reviewed preclinical data on this approach,\u201d he says.\u00a0 Studer\u2019s and Loring\u2019s teams are part of an international consortium that coordinates stem-cell treatments for Parkinson\u2019s. In the next two years, five groups in the consortium plan to run trials using cells fully committed to becoming dopamine-producing cells.\u00a0 Regenerative neurobiologist Malin Parmar, who heads one of the teams at Lund University in Sweden, says that the groups \u201care all rapidly moving towards clinical trials, and this field will be very exciting in the coming years\u201d. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Japanese man is first to receive 'reprogrammed' stem cells from another person 2017-Mar-28 \n                   \n                     China announces stem-cell rules 2015-Aug-26 \n                   \n                     Stem cells pass safety test in vision-loss trial 2015-Apr-30 \n                   \n                     Japanese woman is first recipient of next-generation stem cells 2014-Sep-12 \n                   \n                     Fetal-cell revival for Parkinson\u2019s 2014-Jun-11 \n                   \n                     China\u2019s stem-cell rules go unheeded 2012-Apr-11 \n                   \n                     Stem cells in translation \n                   \n                     Zhengzhou age-related macular degeneration trial \n                   \n                     Zhengzhou Parkinson\u2019s disease trial \n                   \n                     GForce-PD initiative \n                   Reprints and Permissions"},
{"file_id": "546018a", "url": "https://www.nature.com/articles/546018a", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Space mission will peer inside the densest matter in the Universe. For half a century, astronomers and physicists have looked at pulsars and asked \u2018how\u2019? How can something the size of a city pack in more mass than the Sun? How does matter arrange itself to achieve such mind-boggling densities? Answering these questions in the laboratory is impossible. But a space mission due to launch on 1\u00a0June could answer some of them. For the first time, astronomers will take a detailed peek into the heavy hearts of these mysterious spinning stars. \u201cIt is a big, big step forward to understand the property of the densest matter in the Universe,\u201d says Tetsuo Hatsuda, a theoretical physicist at the RIKEN Interdisciplinary Theoretical and Mathematical Sciences Program in Saitama, Japan. \u201cThe state of matter at super high density at the core of the neutron star has been one of the long-standing problems in nuclear physics and astrophysics since the first discovery of the pulsar.\u201d Pulsars are neutron stars that shoot out beams of radiation as they spin\u00a0\u2014\u00a0a feature that enabled their discovery in 1967. Neutron stars are formed from the collapsed remnants of exploded stars. And how matter arranges itself inside them has implications for the way in which particles interact through the fundamental forces, as well as for our understanding of black holes and other cosmic objects. \u201cThis might be the first time we get very tight constraints on what neutron stars look like on the inside,\u201d says Nathalie Degenaar, an astrophysicist at the University of Amsterdam (see \u2018Inside a neutron star\u2019). When it arrives at the International Space Station, NASA\u2019s Neutron Star Interior Composition Explorer (NICER), a washing-machine-sized box, will use X-rays coming from hotspots at the spinning stars\u2019 poles to calculate the size of the stars. Size matters, because a bigger star suggests a stiff core that is relatively able to withstand gravity\u2019s compression, which means that it is probably tightly packed with neutrons jostling against each other at higher pressure than that in atomic nuclei. A smaller, more compact star, meanwhile, would mean a soft interior, in which neutrons could be dissolved in a sea of their constituent quarks. Other, more exotic proposals include the core being made of \u2018hyperons\u2019, which incorporate heavier \u2018strange\u2019 quarks within them. Understanding the core will not only give physicists crucial information about the forces through which particles interact, it will also help to determine how much a neutron star can weigh before gravity overcomes pressure and it collapses into a black hole, says Zaven Arzoumanian, science lead for NICER and an astronomer at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland. A better understanding of ultra-dense matter will also improve physicists\u2019 models of the final moments of merging neutron stars, increasing the chance that gravitational-wave detectors on Earth, such as LIGO, might spot such events. NICER will pinpoint the stars\u2019 radii by studying how their huge gravitational fields bend the light they emit. Seen from the space station, the light is fainter when the beam points away, but remains visible because the star\u2019s gravitational field diverts some of the light back this way. The extent to which the light dims when the beam faces away tells astronomers about this field, and consequently the star\u2019s mass-to-radius ratio. Combined with a mass measurement\u00a0\u2014\u00a0derived by studying the X-rays\u2019 timing and energy, which are influenced by some of the star\u2019s other properties\u00a0\u2014\u00a0astronomers can derive the star\u2019s size more than twice as accurately as could previous missions. But to tease apart these complex effects, NICER needs to maximize the photons it collects, channelling them through 56\u00a0telescopes designed to observe at the red end of the X-ray spectrum, where many neutron stars are brightest. It then records their arrival time in a silicon detector, with an unprecedented accuracy of better than 100\u00a0nanoseconds. \u201cIts timing ability is crazy better than anyone\u2019s ever tried before,\u201d says Ronald Remillard, an astrophysicist at the Massachusetts Institute of Technology in Cambridge, who will use NICER to observe matter falling into black holes, once the craft has completed its primary pulsar mission. The mission will also test a new kind of navigation that could allow future spacecraft to pinpoint their location without having to rely on telescopes on Earth. Just as the Global Positioning System uses the ticks of satellites\u2019 atomic clocks to triangulate a receiver\u2019s position, pulsar navigation would use the arrival times of light from these regularly flashing stars. NICER will probe ten pulsars to test their use in such a system. If this is successful, NASA\u2019s planned Orion space missions may use pulsar-navigation technology as a back-up to conventional navigation, says Keith Gendreau, an astronomer at the Goddard Space Flight Center and the mission\u2019s principal investigator. \u201cWe could use pulsars as a way to navigate out into the Solar System and beyond.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Bizarre star could host a neutron star in its core 2014-Jan-07 \n                   \n                     Massive neutron star is exactly that 2010-Oct-27 \n                   \n                     Pulsar watchers race for gravity waves 2010-Jan-13 \n                   \n                     Neutron stars: A star powered by magnetism 1998-May-21 \n                   \n                     Blog post: Exoplanet satellite gets the nod from NASA \n                   \n                     NICER \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22098", "url": "https://www.nature.com/articles/nature.2017.22098", "year": 2017, "authors": [{"name": "Jeff Tollefson"}, {"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "What the United States' departure from the historic pact means for efforts to fight global warming. Nature  rounds up reaction from researchers around the world to US President Donald Trump's decision t o pull the United States out of the Paris climate agreement . \n             Jane Lubchenco, marine ecologist at Oregon State University in Corvallis and former administrator of the US National Oceanic and Atmospheric Administration: \n           Where to start? President Trump\u2019s decision to withdraw from the Paris Agreement shows a blatant disregard for the wishes of most Americans and business leaders, an irresponsible and callous dismissal of the health, safety and economic well-being of Americans, a moral emptiness in ignoring impacts to the poorest people in the US and around the world, and gross ignorance about overwhelming scientific evidence. Far from \u201cprotecting America\u201d as the president stated, withdrawing from Paris will make America more vulnerable and diminish its world leadership. It is terrifying that the individual who should be leading the rest of the world is so arrogant and irresponsible. Our collective future and that of much of the rest of life on Earth depends in part on confronting climate change and ocean acidification. Doing so requires global collective action. It\u2019s hard to imagine anyone consciously choosing to leave a legacy of impoverishment, economic disruption, increasingly bizarre weather, health impacts ranging from heat strokes to spread of diseases, rising sea levels and flooding \u2014 but that is just what the president has done. Moreover, the new path and the president\u2019s proposed budget would forego significant economic opportunities. Fortunately, mayors, governors, faith leaders, scientists and business executives understand what is at risk, respect the scientific evidence, and see the powerful economic potential and moral imperative in shifting to renewable energy, preparing to adapt to changes already under way, and investing in science and monitoring to guide future decisions. There is strong economic momentum to continue these actions, but they would have been accelerated and more effective with strong action and forceful leadership from the president. Alas, he has chosen instead to stick his head in the sand. \n             Jean-Pascal van Ypersele, climate scientist at the Catholic University of Louvain in Louvain-la-Neuve, Belgium, and former vice-chair of the Intergovernmental Panel on Climate Change (IPCC): \n           President Trump's decision to introduce a request to leave the Paris agreement in 2020 is regrettable. It negates both the results of (1) serious scientific analyses (many made by US scientists) about the urgency to address the climate change problem; and (2) the rigorous assessment made by the IPCC about the technical and socio-economic aspects of response options, including their significant co-benefits in other areas like air quality, energy security, health or job creation. President Trump's speech attempting to justify his decision was an amazing concentrate of some of the worst climate confusers' and fossil lobbyists' arguments. The United States has played a very important role over the years to foster and nurture quality scientific research about the causes and processes of climate change, the potential risks and the response options. It is a shame that this leadership by the US is temporarily lost. Others in Europe, Asia and emerging economies will most likely compensate for this loss, transforming a difficulty into an opportunity. Almost 150 countries, representing close to 85% of greenhouse-gas emissions, have now ratified the Paris agreement. Removing the US contribution from this total still leaves almost two-thirds of the emissions covered by the remaining countries, which have confirmed their plans to honour the agreement. This means that the transition to a low-carbon economy, now seen as an opportunity by many, will continue unabated, with or without the US. \n             Susanne Dr\u00f6ge, climate-policy researcher at the German Institute for International and Security Affairs in Berlin: \n           The US pull-out is bad news for the international climate process. The United Nations negotiations need to focus on implementation. This will become more difficult, also because it is unclear how Trump wants to renegotiate the agreement. Political attention is absorbed due to the US move, attention that is needed for much more important issues such as bringing climate action forward. \n             Thomas Stocker, former co-chair of climate science for the IPCC, and climate and environmental physicist at the University of Bern, Switzerland: \n           Trump\u2019s decision to ignore scientific facts of climate disruption and the high risks of climate-change impacts is irresponsible not only towards his own people but to all people and life on this planet. The US administration prefers old technology over innovation and transformation. It is rejecting the enormous benefits and returns that leadership in the next industrial revolution \u2014 decarbonization \u2014 has to offer. The United States is the second-biggest emitter of carbon dioxide worldwide (and has contributed, with Europe, 52% of the share of cumulative carbon emissions since industrialization). It is withdrawing from its historical responsibility to reduce greenhouse-gas emissions and lead the way forward. Given the continuous commitment of most countries to reduce emissions, and the firm leadership of Europe, China and Russia in shaping the transformation towards a decarbonized economy, the United States runs the risk of being left behind and missing one of the greatest economic opportunities of our time. \n             Susan Lozier, oceanographer at Duke University in Durham, North Carolina: \n           Trump\u2019s decision is as short-sighted as it is disheartening. The oceans already hold about 35% of the carbon dioxide that has been released to the atmosphere since the Industrial Revolution. Nothing good for the ocean and the life it contains comes from this storage. Whether you simply admire marine life or count on it for your livelihood, this decision shouldn\u2019t sit well. An already fragile ocean is further imperilled. \n             Kevin Anderson, deputy director of the\u00a0Tyndall Centre for Climate Change Research in Manchester, UK: \n           Beneath the veil of the low-carbon rhetoric of the Paris agreement, there is no evidence of a mitigation agenda even approaching the scale of our international obligations. Trump\u2019s ostensibly reckless decision can be used either as a further excuse for continued apathy or as a catalyst for transforming our comfortable rhetoric into meaningful and timely action. In that regard, Trump\u2019s ignorant blunderings can inadvertently be a force for good. Channelled positively, it could yet oblige the rest of us to forego our increasing reliance on speculative technologies and incremental carbon prices and begin to shape a mitigation agenda that is fit for purpose. We need to take Trump at face value. If he is successful in returning the US to a coal-based economy (and that looks unlikely), then the European Union needs to borrow his \u2018protectionist\u2019 cloak and put in place carbon standards for imported goods. Finally, let\u2019s keep Trump in context. US states and cities have considerable devolved powers \u2014 and many of their leaders continue to favour climate science. \n             Joeri Rogelj, energy researcher at the International Institute for Applied Systems Analysis in Laxenburg, Austria: \n           The US withdrawing from the Paris agreement is damaging for international collaborative efforts to limit climate change, but will likely be most damaging to the US economy itself. The US has decided to sideline itself, internationally, diplomatically and morally \u2014 not to prepare itself for the future, but to gaze into the past for a few more years. Many other major economies, including China and the European Union, have indicated their strong commitment to implementing the climate agreement. This signal will spur innovation and business development in these regions. However, the US government refuses to give US businesses such a clear sense of direction and is disregarding the most robust scientific evidence by doing so. By setting research, innovation and business priorities based on misleading short-term political goals, the US will miss the boat and might become a laggard in the global technology and innovation landscape. The climate issue is a global and a cumulative problem that was not solved in one go with the Paris agreement, but requires incremental updates and adjustments of climate action. To halt climate change, global carbon dioxide emissions need to be capped and annual emissions need to be brought to zero. One country failing on its commitments thus implies that deeper emissions cuts are required in other regions or later in the future. This makes the problem harder and less equitable to solve. \n             Oliver Geden, visiting research fellow at the Institute for Science, Innovation and Society, University of Oxford, UK: \n           The United States gave up climate leadership on the day of Trump's inauguration. In March, Trump announced his  rollback of Obama-era climate regulations . So it\u2019s been clear for some time that the US federal government is not going to act on climate change in the foreseeable future. Withdrawing from the Paris agreement is just another step, although a highly symbolic one. For now, it seems that this step reunites the rest of the world, but only on the symbolic level. It is quite easy for a government to declare that it will stick to the Paris agreement. But in a regime of bottom-up climate policy that still aims to achieve top-down temperature targets, other governments would need to step up and declare that they increase their mitigation pledges \u2014 and act accordingly. That's obviously the harder thing to do. \n             Katharine Hayhoe, director of the Climate Science Center at Texas Tech University in Lubbock: \n           The biggest loser from the decision could\u00a0be the United States itself. Why? Because although the Paris agreement is a climate treaty, a triumph for evidence-based decision-making, it\u2019s also much more: a trade agreement, an\u00a0investment\u00a0blueprint and a strong incentive for innovation in the energy and the economy of the future. Earlier this week, India broke its own record for the lowest bids for electricity from solar\u00a0power. Last month,  Ernst & Young listed its most attractive\u00a0markets for renewables : the United States came third, behind\u00a0China and India. And earlier this year, China announced a  US$360-billion investment in clean energy  to create 13 million new jobs. The US announcement shows that it will be\u00a0doing its best to turn back the clock, while the rest of the world accelerates into the future. It\u2019s true that federal policy is only one piece of the pie, and not even the biggest one. Cities, states and private industry have arguably played an even more important role in shaping US technological innovation, energy mix and carbon emissions over the past ten years, even under proactive federal climate policy. But Trump\u2019s announcement sends a strong message that the US would rather be one of only\u00a0two nations in the world that is not interested in preventing \u201cdangerous anthropogenic interference with the climate system\u201d. That other nation? War-torn Syria. (Note that Nicaragua is also opting out of the agreement \u2014 but in that case it\u2019s because it wants to do more, not less.) \n             Atte Korhola, climate-policy and environmental-change researcher at the University of Helsinki, Finland: \n           The US withdrawal from the Paris climate agreement is very disappointing and unfavourable for the United States and the rest of the world. Many climate scientists consider the Paris agreement insufficient for limiting warming to 2 \u00b0C, so the task will be all the harder now. However, international climate agreements have not been very effective so far in reducing emissions, so there is still hope that the United States will proceed on other fronts, such as through bilateral agreements, clean-tech development and investing in new \u2018negative emissions\u2019 technologies. But the plans by the Trump administration to cut more than 30% from the Environmental Protection Agency\u2019s budget and about 70% of the funding for renewable-energy research and development unfortunately don\u2019t point in this direction. The situation in all respects is quite depressing. The only hope is that the US states, cities and companies will continue their effective work to cut emissions. \n             Benjamin Santer, climate scientist at Lawrence Livermore National Laboratory in California: \n           In Shakespeare's  Julius Caesar , Brutus said these famous lines: \"There is a tide in the affairs of men. Which, taken at the flood, leads on to fortune; Omitted, all the voyage of their life is bound in shallows and in miseries.\" Today, the United States pulled out of  the Paris climate agreement  and missed the rising tide. Far from \"Making America Great Again\", this decision condemns the United States to becoming one of the 'has-beens' of history. We will become increasingly irrelevant to the rest of the world. They are going forward; we are going backward. \n             Hans Joachim Schellnhuber, director of the Potsdam Institute for Climate Impact Research in Potsdam, Germany: \n           It will not substantially hamper global climate progress if the US really quits the Paris agreement, but it will hurt the American economy and society alike.  China  and Europe have become world leaders on the path towards green development already and will strengthen their position if the US slips back at the national level. Innovative states such as California, the world's sixth-largest economy, will keep going for climate action, however. The Washington people around Trump hide in the trenches of the past instead of building the future. They fail to recognize that the climate wars are over, while the race for sustainable prosperity is on. \n             David Victor, climate-policy expert at the University of California, San Diego: \n           The odds of other countries renegotiating Paris are low to zero. The whole structure of the Paris agreement is to allow countries to set their own commitments. So there is nobody to negotiate with if a country needs to adjust. This claim that the problem with Paris is that the deal wasn\u2019t struck properly is a disingenuous argument that is not informed by how Paris actually works, nor by any reality about how the world actually crafts big complex deals. \n             Glen Peters, climate-policy expert at the Center for International Climate and Environmental Research in Oslo: \n           It seems that Trump and his advisers have completely misconceived what the Paris agreement is. All his reasons for pulling out were basically the concessions that forged the path to the creation of the Paris agreement. Paris is the agreement that Trump desires! The genius of Paris is to allow countries to put forward emission pledges that they feel they can meet (Nationally Determined Contributions). The US pledge was put forward by the US, alone. Countries are already enacting their emissions pledges, and \u2014 as could be expected by the design of the Paris agreement \u2014 most countries show signs of exceeding their conservative emissions pledges. China looks like it may peak its emissions a decade earlier than pledged. India has slowed down on coal consumption and sped up on solar deployment. Even the US has made great strides in the past decade, and was poised to make more. The irony is that Paris is working, because it is designed to be flexible to the national circumstances that Trump himself champions! \n             Myles Allen, climate scientist at the University of Oxford, UK: \n           The Paris agreement is far from perfect, and one of its problems, as we are seeing now, is the lack of any real penalty for pulling out. Talk of trade sanctions is pure hyperbole and the last thing the world needs right now. But perhaps it is time to think about a simple product label: \u201cMade in and sourced from regions that support the Paris climate agreement.\u201d With California and Oregon insisting they will abide by the terms of the Paris agreement anyway, we could then have an interesting discussion about whether and how this could be stuck on Californian orange juice \u2014 or computers containing Intel chips. Painful though it may be for the agreement\u2019s supporters, acknowledging that it isn\u2019t perfect must also be part of the response to this proposal to renegotiate the US terms of participation. Some, no doubt, will see this as just a distraction tactic. Others would argue that even to begin to negotiate would be to deliver Trump an ill-deserved political \u201cwin\u201d. But thinking beyond 2020, we will eventually need to work out how to make the agreement both more effective and more acceptable to nations, companies and individuals that own substantial fossil-fuel reserves \u2014 or the US won\u2019t be the last to leave. \n             Benjamin Sanderson, climate modeller at the National Center for Atmospheric Research in Boulder, Colorado: \n           Today's announcement that the US will depart from the Paris agreement is unfortunate, but it is no time for fatalism. From this point forward, there are now large uncertainties in global mitigation efforts over the coming years. The long-term evolution of the climate hinges on what other countries, and agents both within and outside of the US, do in response to the US departure from the agreement. A complete failure of the agreement at this point, with business-as-usual growth for another decade, would almost certainly commit the planet to significantly more warming than the Paris goals, and the human consequences of this would be catastrophic. However, some major remaining signatories have expressed a commitment to increasing mitigation goals, and within the US, many states, cities and some of the country's largest companies are committed to mitigation irrespective of the US participation in the agreement. Decisions made today are made in the context of confident projections of future warming with continued emissions, but clearly there is more to do to better characterize the human and economic consequences of delaying action on climate change and how to frame these issues in the context of other concerns. The role of the scientific community is more important than ever, both to continue to provide the best possible research to inform decisions, and to communicate any risks associated with further emissions in a publicly accessible fashion. \n                   Trump pulls United States out of Paris climate agreement 2017-Jun-01 \n                 \n                   Paris climate deal to take effect as EU ratifies accord 2016-Oct-04 \n                 \n                   Nations approve historic global climate accord 2015-Dec-12 \n                 \n                   Is the 2\u2009\u00b0C world a fantasy? 2015-Nov-24 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22092", "url": "https://www.nature.com/articles/nature.2017.22092", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Early clinical trial data suggest that combining medicines improves treatment. An approach to unleashing immune responses against cancer is showing promise in early clinical trials, and may boost the effectiveness of existing therapies. The experimental drugs target a protein called IDO, which starves immune cells by breaking down the crucial amino acid tryptophan. IDO can suppress immune responses and rein in potentially damaging inflammation. But it can also halt the body\u2019s natural immune response to cancer and allow tumours to grow unchecked. Some tumours even express IDO to shield themselves from the immune system. Researchers will present the latest round of clinical data from IDO-inhibiting drugs at the American Society of Clinical Oncology (ASCO) annual meeting in Chicago, Illinois, on 2\u20136 June. The results add to mounting evidence that IDO inhibitors boost the effectiveness of treatments called immunotherapies, which bolster immune responses against cancer. \u201cIt\u2019s almost like you\u2019re taking down a tumour force field,\u201d says Michael Postow, a cancer researcher at the Memorial Sloan Kettering Cancer Center in New York City. Over the past decade, immunotherapies have sparked a revolution in cancer research.  One class of drugs, called PD-1 inhibitors , can produce long-lasting remissions in people whose cancers have resisted every other available treatment. But such success stories are limited to a lucky few: tumours will shrink in less than one-third of those who take the drugs. One problem is that tumours express a host of proteins that shut down immune responses, so blocking PD-1 may simply allow another protein to step in. Researchers are frantically searching for ways  to boost the success rates of PD-1 inhibitors by combining them with drugs  that can block these other proteins. \u201cThere are ways around every single one of these checkpoint proteins,\u201d says immunologist Andrew Mellor of Newcastle University, UK. \u201cTherein lies the problem \u2014 and therein lies the solution.\u201d \n             Greater than the sum of its parts? \n           Pharmaceutical companies have been racing to test the effectiveness of combining experimental IDO-inhibiting drugs with approved PD-1 inhibitors. NewLink Genetics in Ames, Iowa, announced in April that combining its IDO-pathway inhibitor indoximod with an anti-PD1 drug shrank tumours in 31 of 60 people with advanced melanoma in the trial. And data to be presented at the ASCO meeting suggest that an IDO inhibitor called epacadostat, made by Incyte of Wilmington, Delaware, could boost response rates to anti-PD-1 drugs in lung and kidney cancers. Thirty-five percent of people with non-small-cell lung cancer responded to the combination. In kidney cancer, the combination shrank tumours in 47% of trial participants. Other companies are also testing IDO inhibitors \u2014 including a firm co-founded by cancer researcher Benoit Van den Eynde of the Ludwig Institute for Cancer Research in Brussels. In 2003, Van den Eynde\u2019s team became the first to demonstrate that IDO is expressed in human tumours 1 . His company, iTeos Therapeutics in Gosselies, Belgium, has partnered with the pharmaceutical giant Pfizer in New York City, and brought its IDO inhibitor into clinical trials last year. It is still early, cautions cancer immunologist Thomas Gajewski of the University of Chicago in Illinois, who has worked on clinical trials of IDO inhibitors. The trials so far have been small and lack a control group that received only PD-1 inhibitors. As a result, researchers can only compare the results of drug combinations with the historical success rates of PD1 inhibitors. And there is still a lot to learn about how IDO interacts with the immune system, or what effects an IDO inhibitor could have elsewhere in the body, says Michael Platten, an oncologist at the German Cancer Research Center in Heidelberg. IDO is expressed in many tissues. \u201cThis is still a relatively new field,\u201d says Platten. \u201cWe do not really understand the molecular mechanism.\u201d But an encouraging sign, adds Gajewski, is that so far, the combination of drugs to inhibit IDO and PD-1 seems to be relatively safe, and lacks the toxicity seen when PD-1 inhibitors are used with some other cancer drugs. \u201cIn some of the combinations, it looks like there\u2019s benefit beyond anti-PD-1 alone, but without toxicity,\u201d he says. \u201cFor me, that\u2019s really an opportunity.\u201d \n                   Tissue-independent cancer drug gets fast-track approval from US regulator 2017-May-24 \n                 \n                   Cell maps reveal fresh details on how the immune system fights cancer 2017-May-04 \n                 \n                   Promising cancer drugs may speed tumours in some patients 2017-Mar-31 \n                 \n                   Cocktails for cancer with a measure of immunotherapy 2016-Apr-13 \n                 \n                   Nature Outlook: Cancer Immunotherapy \n                 \n                   American Society of Clinical Oncologists annual meeting \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22093", "url": "https://www.nature.com/articles/nature.2017.22093", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Detection made from another black-hole merger \u2014 but physicists are now keen to see such waves from different types of event. It\u2019s starting to become routine. Gravitational waves \u2014 ripples in the fabric of space-time \u2014 have for the third time been picked up passing through Earth, as the result of a distant merger between two massive black holes. The detection, announced by researchers on 1 June, was made in January by the twin detectors of the Laser Interferometer Gravitational-Wave Observatory (LIGO) in Louisiana and Washington state. The observatory made its  historic first detection of gravitational waves  to global fanfare in September 2015, confirming Albert Einstein\u2019s prediction of the phenomenon made 100 years before. A  second signal came three months later , on Boxing Day. Researchers estimate that the bodies in the latest collision were slightly lighter than those in the first event: one had the mass of 31 Suns and the other 19. (The black holes in the second discovery were even more lightweight, at 14 and 8 solar masses.) But the latest merger is the most distant detected so far. The gravitational waves it produced took somewhere between 1.6 billion and 4.3 billion years to reach Earth \u2014 most probably around 2.8 billion years. The results are published in  Physical Review Letters 1 . The latest detection brought no surprise: it is more of the same \u2014 which is still a good thing, says Bruce Allen, managing director of the Max Planck Institute for Gravitational Physics (MPIGP) in Hanover, Germany, which is part of the LIGO collaboration. \u201cIt\u2019s very similar to the first one we saw, and that is good for our scientific credibility,\u201d he adds.\u00a0 Stuart Shapiro, who works on computer simulations of gravitational waves at the University of Illinois at Urbana\u2013Champaign, agrees. With this detection, \u201cwe truly have moved into the age of gravitational-wave astronomy\u201d, says Shapiro, who is not involved in the experiment. The event does offer one possible novelty: it yielded some hint about the way the black holes spin around their axes, which can reveal their origins. But researchers say that, in this instance, the information is largely inconclusive. Astrophysicists are now eager for LIGO to discover gravitational waves from other types of phenomenon, beyond black-hole mergers \u2014 for example, from the merging of neutron stars. As they presented the latest results at a press conference, LIGO researchers said that they are working on the analysis of at least six other \u2018candidate events\u2019, but declined to provide details. \n             Midnight call \n           The detection came about a month into an observation run that began on 30 November, following a nearly year-long shutdown of the detectors for maintenance and sensitivity upgrades \u2014 although the improvements that followed the upgrades were less dramatic than the team had hoped. The first LIGO scientist to spot the event on the morning of 4 January was Alexander Nitz, a gravitational-wave astronomer at the MPIGP. At the time, the Washington detector was being recalibrated, so its data were considered potentially unreliable. Nitz was using the data flowing in from the Louisiana detector to test a data-analysis algorithm that he had written. Normally, such tests are used to assess how a detector responds to background noise from the environment; researchers expect to find true gravitational-wave signals only when looking at data from two detectors simultaneously. But one event that was picked up by Nitz\u2019s algorithm made him do a double-take. \u201cThe moment I saw that, I think everything stopped for me,\u201d Nitz says. The plot had the hallmarks of the accelerating sinusoidal wave that is typical of two objects in the process of merging. Nitz immediately checked the Washington data, and found the same pattern. He then sent out an alert to the rest of the collaboration. \u201cHe woke us up in the middle of the night, which is what we love to do,\u201d says David Shoemaker, a physicist at the Massachusetts Institute of Technology in Cambridge and spokesperson for the LIGO Scientific Collaboration. \n             Spinning results  \n           The hint of information about the black holes' spins in the latest event has prompted much discussion among the collaboration about how much insight could be gleaned from it. In a typical pair of orbiting black holes, each object spins on its own axis, just like the planets in the Solar System. The two spins may (or may not) be aligned with each other, or with the axis of the orbital motion. An alignment of spins is a strong hint that the two black holes have existed together since their birth, each being the remnant of a star in a binary, or two-star, system, which could have existed anywhere in a galaxy. Conversely, a misalignment suggests that the two objects formed independently and then began orbiting each other at a later time. Simulations by Simon Portegies Zwart 2 , an astrophysicist at Leiden University in the Netherlands, suggest that this is what would happen if the black holes lived inside a dense stellar cluster. The data from the latest event slightly favour this cluster scenario, says LIGO co-deputy spokesperson Laura Cadonati, a physicist at the Georgia Institute of Technology in Atlanta. \u201cMisaligned spins is exactly what one would expect from a cluster origin of the black-hole binaries,\u201d Portegies Zwart says. \u201cIt is, in my opinion, exciting that the spins have now been found.\u201d Finding that typical black-hole binaries have misaligned spins would indeed provide evidence for the cluster origin of these binaries, says Daniel Holz, a LIGO member at the University of Chicago in Illinois. That \u201cwould be fantastic\u201d, he says, \u201ceven though it means some of my previous work would be of less interest\u201d. (Holz co-authored work last year suggesting that the cluster scenario was less likely than the binary-star origin 3 .) Both Holz and Allen, however, warn that the data are still consistent with aligned spins, and that it would be premature to draw any firm conclusion. \u201cI think, until we can observe spins and mass distributions of 100 or so of these systems, we won\u2019t be able to say where they come from,\u201d Allen says. The good news is that the data from LIGO will keep pouring in, Shapiro adds. Its current run is expected to continue until at least late August, after which a new round of sensitivity upgrades will begin. Some time this summer,  LIGO's sister observatory Virgo  should come online in Italy, and a fourth interferometer is due to start operations in Japan perhaps as early as next year. \u201cThe collective detections to date point the way to what will become a booming enterprise in the coming years.\u201d \n             \n                   The black-hole collision that reshaped physics 2016-Mar-23 \n                 \n                   Gravitational waves: How LIGO forged the path to victory 2016-Feb-16 \n                 \n                   Gravitational waves: 6 cosmic questions they can tackle 2016-Feb-09 \n                 \n                   Nature Special: Gravitational waves \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22097", "url": "https://www.nature.com/articles/nature.2017.22097", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Highly folded mouthparts help tubelip wrasses dodge venom and create a seal to feed. For hungry fish, corals make a difficult meal: venomous, coated with mucus and embedded in a razor-sharp, calcified skeleton. But one species, the tubelip wrass ( Labropsis australis ), has developed an unusual strategy to evade these stinging defences. The fish gives corals slime-covered kisses. The finding, published on 5 June in  Current Biology 1 , adds to scientists\u2019 understanding of how corals and the fish that feed on them affect each other. Wrasses that don\u2019t feed on corals have thin lips and protruding teeth that resemble a beak. But tubelip wrasses have elongated, fleshy lips that they use to suck up a reef\u2019s protective mucous coating. A scanning electron microscope reveals that the lips are furrowed with tiny channels and divots, soft and ribbed like gills on the underside of a mushroom. Those grooves contain mucous glands that can cover the wrasses\u2019 lips in protective slime. \u201cWe\u2019ve never seen anything like this,\u201d says David Bellwood, a marine biologist at James Cook University in Townsville, Australia, and a co-author of the paper. \u201cSelf-lubricating lips! Who would have predicted that?\u201d The snotty kiss probably serves a dual purpose. The mucus helps protect the lips from the corals\u2019 stinging cells; clownfish have a similar coating that protects them from the stinging anemones they call home. And in combination with the grooves, the mucus helps the tubelip wrasses to form a seal against jagged pieces of coral. This enables them to suck up their meal of the coral\u2019s mucus like someone drinking a milkshake through a straw. The seal is so strong that the kiss ends with an audible smacking sound. \n             Slimy suckers \n           \u201cCorals must be one of the hardest things on the planet to eat,\u201d says Bellwood, but numerous fish species have found a way 2 . These coral-feeding fish are an integral part of the reef ecosystem, says Shaun Wilson, a marine scientist at the Western Australia Department of Parks and Wildlife in Perth. They may help corals by eating diseased tissue. But they could also hurt the corals by carrying illnesses from one feeding spot to another. Bellwood compares the tubelips and other coral-eating fish to leeches or mosquitoes \u2014 harmless to a healthy ecosystem, but if there are too many of what he calls \u201cslimy suckers\u201d in an  unhealthy reef , they could stress the corals. Studying how these fish eat can help scientists understand their impact on reefs. So far, self-lubricating lips seem to be unique to tubelip wrasses. But that doesn\u2019t mean other fish haven\u2019t evolved similar feeding strategies \u2014 just that they haven\u2019t been found yet. \u201cI wouldn\u2019t be surprised if a small Amazonian catfish has independently come up with the same solution,\u201d says Bellwood. \u201cFish are marvellous beasts.\u201d \n                   Computers on the reef 2016-Aug-31 \n                 \n                   Corals worldwide hit by bleaching 2015-Oct-08 \n                 \n                   Animal behaviour: Inside the cunning, caring and greedy minds of fish 2015-May-26 \n                 \n                   Fish uses 'water tongue' to grab prey on land 2015-Mar-18 \n                 \n                   Bright spots among the world's coral reefs \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22106", "url": "https://www.nature.com/articles/nature.2017.22106", "year": 2017, "authors": [{"name": "Simon  Oxenham"}], "parsed_as_year": "2006_or_before", "body": "In turbulent times, voting should seem even more important \u2014 but in Europe, turnouts are lower than ever. In a year of pivotal elections across Europe \u2014 in  the Netherlands ,  France , the  United Kingdom  and Germany \u2014 voters are being  urged to turn up to the ballot box . Yet long-term data suggest that political apathy has risen steadily in Europe\u2019s citizens, says Simon Hix, a political scientist at the London School of Economics. Voter turnout across Europe is at its lowest point since suffrage rights were extended to the broader population, says Hix \u2014 a trend he illustrated this year in a series of charts that show how voting patterns have changed across the continent for the past 100 years. From the Second World War to the early 1980s, around 80\u201385% of the electorate turned out to vote. But since then, participation in national elections has fallen steadily to just under 65% (see 'The rise of Europe's non-voters'). Falling turnouts have been discussed at length, but Hix says that his plots \u2014 which  he tweeted in February , but are part of a continuing research project \u2014 are the first to chart how voting patterns of Europeans changed over such a long time period. \n             Cohort effect \n           Hix and his colleague Giacomo Benedetto, a politics researcher at Royal Holloway, University of London, collated voting data from national election records from 31 European countries back to 1918, when many more people gained voting rights in Europe after the First World War. To find out how political leanings had changed, the researchers allocated parties voted for to seven main \u2018families\u2019 ranging from \u2018radical left\u2019 to \u2018radical right\u2019; they also counted how many eligible voters abstained. To the researchers\u2019 surprise, they found that from around 1990, non-voters made up the single biggest block \u2014 in stark contrast to the past. \u201cWe expected that non-voters would increase as a proportion of all voters since the early 1990s, as we knew that turnout was low in the new democracies in central and Eastern Europe,\u201d says Hix. What they didn't expect is that when combined with the votes in Western Europe, non-voters would constitute the single largest block by the early 2000s. The rise of political apathy could be considered the strongest political trend of the latter part of the twentieth century, he suggests. Evidence from election studies \u2014 official surveys conducted just after national polls take place \u2014 in many advanced democracies since 1945 suggests that voting rates have fallen in young people, but remain high in the generation born in the years after the Second World War. \u201cPrevious generations valued democracy more, they fought wars and women argued to get the vote,\u201d says Hix. Younger generations take all this for granted and have become cynical, he says. He worries that society may be effectively returning itself to a state akin to pre-emancipation, when the vote was reserved for landed gentry. \n             Democracy paradox \n           Non-voting is on the rise across Europe and other advanced democracies, and usually has to do with protest, disillusionment and feelings of distance from democracy and elites, says Daniele Caramani, who studies comparative politics at the University of Zurich in Switzerland. But the rise is most dramatic in  Eastern Europe . That is a paradox because many countries there became democracies only after the fall of Communism in the early 1990s, says Caramani. \u201cOnly 20 years ago, these countries were under Communist dictatorships. They fought hard for the right to vote, then as soon as they had democracy they started abstaining,\u201d he says. \u201cIt\u2019s like if you come from a famine and all of a sudden you have enough food and you throw it in the garbage.\u201d Caramani suggests that the trend could be down to disillusionment with the old elites who were able to maintain their grip on power even after the fall of Communism. But an increase in abstention doesn\u2019t necessarily mean people are less interested in politics. \u201cTraditional forms of participation are in decline, but new ways such as on social media are picking up and may be resulting in a replacement effect,\u201d he says. In the United Kingdom \u2014 which holds its  next general election on 8 June  \u2014 the generational voting divide is particularly stark. The 1990s saw a huge decline in youth turnout there and the country \u201cnow leads the world with its gap in voter turnout between older generations and young people\u201d, says Abhinay Muthoo, an economist at the University of Warwick, UK. The difference in voting rates between UK people aged over 55 and those under 35 is about 35 percentage points \u2014 triple the average for countries in the Organisation for Economic Co-operation and Development,  according to preliminary work by Muthoo . One argument described by Muthoo suggests that the trend goes back to the mid-1980s, when a lot of people who traditionally voted one way or another stopped voting altogether because of disillusionment with the politics of the time, among other reasons. When these people stopped engaging, it\u2019s possible that their children didn\u2019t go out to vote either. \u201cPeople who get socialized into voting at an early age keep this habit,\u201d says Caramini. \u201cIt might be that people who are socialized now in a time of distrust of political parties may never vote when they get older, it\u2019s a generational effect that is well confirmed by research.\u201d \n             Far-right future? \n           Hix\u2019s further work also neatly illustrates a trend that has dominated political commentary over the past year: the rise of far-right movements. In Europe, the data show that this has been fuelled largely by voters in Eastern Europe. The proportion of votes for far-right parties in Europe now matches the levels of the early 1930s, he says. This could prove to be a growing issue, says Caramani. Alongside non-voters, far-right parties are the only faction that shows sustained signs of growth. \n                   UK election: science spending pledges overshadowed by Brexit 2017-May-31 \n                 \n                   French-election fears unite scientists in defence of liberal democracy 2017-Apr-18 \n                 \n                   French scientists focus on the big political picture 2017-Apr-18 \n                 \n                   Compare voting systems to improve them 2017-Jan-10 \n                 \n                   The polling crisis: How to tell what people really think 2016-Oct-19 \n                 \n                   After the Berlin Wall: Central Europe up close 2014-Nov-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22060", "url": "https://www.nature.com/articles/nature.2017.22060", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Cornerstone of modern science immortalized in concrete. A 1.5-tonne stone tribute to peer review is the latest addition to Moscow\u2019s rich cultural heritage. On 26 May, a good-humoured crowd of more than 100 people \u2014 including students, researchers and Russia\u2019s deputy minister of education and science \u2014 gathered outside Moscow\u2019s Higher School of Economics (HSE) to witness the unveiling of what is probably the world's first monument to  peer review . The sculpture takes the form of a die displaying on its five visible sides the possible results of review \u2014 \u2018Accept\u2019, \u2018Minor Changes\u2019, \u2018Major Changes\u2019, \u2018Revise and Resubmit\u2019 and \u2018Reject\u2019. Last year, the director of the HSE\u2019s Institute of Education, Isak Froumin, had asked his faculty for ideas about how to turn a useless block of concrete outside the university into something attractive and meaningful. HSE sociologist Igor Chirikov suggested having the awkward lump chiselled into the die tribute, called 'Monument to an Anonymous Peer Reviewer'. \u201cWhen I started working in academia I realized that there is an important role for peer reviewers, whose contribution is not always recognized,\u201d says Chirikov, who splits his time between Moscow and the University of California, Berkeley. \u201cAt the same time, I feel for researchers \u2014 it\u2019s hard to deal with rejection letters and, sometimes, nasty comments from reviewers.\u201d The idea struck a chord and Chirikov  quickly mobilized a crowdfunding campaign to make it a reality . Researchers from all over the world pledged more than US$2,500 to the project. The edges of each cube face are also carved with the titles of 21 papers; most are by the researchers who made the largest contributions to the funding campaign. The monument has a tongue-in-cheek air about it, but the tribute is sincere, says Chirikov. \u201cPeer review in academia is a story of love and hate\u201d \u2014 but reviewers are  \u201cinvisible heroes in science\u201d , he says. \u201cI thought that the monument would be the best way to pay tribute to their work.\u201d \n                   Gender bias distorts peer review across fields 2017-Mar-21 \n                 \n                   Journals invite too few women to referee 2017-Jan-25 \n                 \n                   Peer-review 'heroes' do lion's share of the work 2016-Nov-22 \n                 \n                   Open peer review finds more takers 2016-Nov-10 \n                 \n                   Moscow monument proposed to immortalize peer review 2016-Sep-12 \n                 \n                   Let\u2019s make peer review scientific 2016-Jul-05 \n                 \n                   Peer review: Troubled from the start 2016-Apr-19 \n                 \n                   The scientists who get credit for peer review 2014-Oct-09 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22109", "url": "https://www.nature.com/articles/nature.2017.22109", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Presence of particular microbes or enzymes could explain why some treatments are ineffective for certain people. In the quest for  personalized therapies , most research has focused on how an individual\u2019s genome controls their body\u2019s responses to drugs. However, there is increasing evidence that a  person\u2019s unique microbiome  \u2014 the population of bacteria and other microbes that live in their body \u2014 can be key to determining whether or not a drug works for their condition. Researchers now have evidence that healthy people metabolize some drugs in different ways depending on their microbial make-up. They presented their data on 4 June at the meeting of the American Society for Microbiology in New Orleans, Louisiana. Bacteria living in the human body will eat any nutrient that comes their way, whether it\u2019s food from the host\u2019s diet or a drug that the person is taking. But this dietary flexibility can become problematic if the microbes metabolize a drug into useless or toxic compounds. Computational biologist Leah Guthrie at the Albert Einstein College of Medicine in New York City discussed data on a chemotherapy drug called irinotecan, which causes severe diarrhoea in some patients. Previous research 1  in mice found that bacterial enzymes called \u03b2-glucuronidases can modify the chemical structure of irinotecan and other drugs. Normally, the liver detoxifies these treatments by adding a chemical group called glucuronidate. But the bacterial enzyme removes the group, turning the drug into a toxic compound. \n             Going with the gut \n           To see whether a person\u2019s microbiome affected how they metabolized drugs, Guthrie and her colleagues collected faecal samples from 20 healthy people. They treated the samples with irinotecan, and measured the compounds produced by bacteria in the samples as they interacted with the drug. The team found that 4 of the samples contained high levels of the toxic form of irinotecan, but found no significant differences between the bacterial species present in any of the samples. When the researchers analysed the proteins produced in the faecal samples, they found that those from people with high bacterial metabolisms contained strains that made more \u03b2-glucuronidases. These people also had increased levels of proteins that transport sugar into cells, which suggests they would be more likely to absorb the toxic compound and develop gastrointestinal problems. The researchers are now planning to collect samples from people with cancer who are taking irinotecan, to see whether this is the case, says study leader Libusha Kelly, a microbiologist at the Albert Einstein College of Medicine. It\u2019s a nice step towards understanding how gut-bacterial enzymes interact with drugs, says Matthew Redinbo, a structural biologist at the University of North Carolina at Chapel Hill who also studies irinotecan. \u201cOur biggest insight is to look at gut enzymes and think about them the same way as human\u201d enzymes, he says. Redinbo says that the liver processes many of the drugs given to patients using the chemical group removed by bacterial \u03b2-glucuronidases: this suggests that the microbiome\u2019s effects could be very far-reaching. His work in mice has found 2  that some \u03b2-glucuronidases make similar modifications to anti-inflammatory drugs that include ibuprofen, which can cause gut toxicity when administered over long periods of time. \n             Still a black box \n           Researchers have identified dozens of examples of gut bacteria that seem to modify therapeutic drugs, including some that treat Parkinson\u2019s disease and anxiety, says Emily Balskus, a biochemist at Harvard University in Cambridge, Massachusetts. She says that bacterial interference could also help to explain why animal models don\u2019t always predict drug toxicity in humans, because animals contain different microbes. But many questions remain. Few of the enzymes responsible for breaking down these drugs have been identified, and it\u2019s unclear how much gut bacteria vary among the human population. A paper published on 2 June in  Science 3 , for instance, found that the HIV-prevention drug tenofovir, which is applied to the vagina as a gel, was ineffective in women whose vaginas contained a type of bacterium called  Gardnerella . The bacteria quickly broke the drug down into an inactive compound, but the scientists don\u2019t yet know how the process works, or whether it can be halted. Eventually, Balskus says, clinicians may be able to screen people\u2019s microbiomes to determine whether a drug will work for them. If their gut microbiomes seem problematic, doctors could prescribe an enzyme inhibitor or put them on a diet that provides the bacteria with an alternate food source. Studies using a dietary intervention in mice have shown 4  some success in preventing gut bacteria from degrading a heart drug called digoxin. Redinbo wants to try the technique in people. His start-up biotechnology company, Symberix in Durham, North Carolina, plans to apply for permission to start a clinical trial in which researchers will give cancer patients a \u03b2-glucuronidase inhibitor alongside irinotecan. Still, it will be a long time before enough is known about bacteria\u2013drug interactions for physicians to be able to prescribe such therapies routinely. \u201cIt\u2019s staggeringly complex,\u201d says Redinbo. \n                   The curious case of the caterpillar's missing microbes 2017-May-18 \n                 \n                   Microbiome 'social network' revealed by gene swaps 2016-Jul-13 \n                 \n                   White House goes big on microbiome research 2016-May-13 \n                 \n                   Scientists bust myth that our bodies have more bacteria than human cells 2016-Jan-08 \n                 \n                   Use of personalized cancer drugs runs ahead of the science 2015-Sep-17 \n                 \n                   Personalized medicine: Time for one-person trials 2015-Apr-29 \n                 \n                   Microbiome therapy gains market traction 2014-May-13 \n                 Reprints and Permissions"},
{"file_id": "545277a", "url": "https://www.nature.com/articles/545277a", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Desperate farmers hope scientists can beat pathogen that is wrecking the US orange harvest. Fruit farmers in the United States have long feared the arrival of harmful citrus tristeza virus to their fields. But now, this devastating pathogen could be their best hope as they battle a much worse disease that is laying waste to citrus crops across the south of the country. The agricultural company Southern Gardens Citrus in Clewiston, Florida, applied to the US Department of Agriculture (USDA) in February for permission to use an engineered version of the citrus tristeza virus (CTV) to attack the bacterium behind citrus greening. This disease has slashed US orange production in half over the past decade, and threatens to destroy the US$3.3-billion industry entirely. The required public comment period on the application ended last week, and the USDA will now assess the possible environmental effects of the engineered virus. Field trials of engineered CTV are already under way. If the request is approved, it would be the first time this approach has been used commercially. It could also provide an opportunity to sidestep the regulations and public stigma attached to genetically engineered crops. \u201cThere\u2019s a real race on right now to try to save the citrus,\u201d says Carolyn Slupsky, a food scientist at the University of California, Davis. \u201cThis disease is everywhere, and it\u2019s horrible.\u201d The engineered virus is just one option being explored to tackle citrus greening. Other projects aim to edit the genome of citrus trees using CRISPR\u2013Cas9 to make them more resistant to the pest, or engineer trees to express defence genes or short RNA molecules that prevent disease transmission. Local growers have also helped to fund an international project that has sequenced citrus trees to hunt for more weapons against citrus greening. \u201cThere are great scientific opportunities here,\u201d says Bryce Falk, a plant pathologist at the University of California, Davis. \u201cWe need to take advantage of new technologies.\u201d Citrus greening is caused by species from the candidate bacterial genus  Candidatus  Liberibacter. Spread by sap-sucking, flying insects called Asian citrus psyllids ( Diaphorina citri ), the bacteria cause citrus trees to make bitter, misshapen fruits that have green lower halves. The disease is also widely known by its Chinese name,  huanglongbing . The first tree in the United States with symptoms was reported in Miami in 2005. \u201cWe had the \u2018uh-oh\u2019 moment,\u201d says Fred Gmitter, who breeds new citrus varieties at the University of Florida in Lake Alfred. Some researchers have had accidental success against the disease. Gmitter\u2019s team released a mandarin variety called Sugarbell just as the outbreak was getting under way. Although those trees have since become infected with  C.\u00a0 Liberibacter, farmers are able to reap a reasonable crop of sweet oranges if the plants receive proper pruning and nutrition. But it is difficult to build on that success: why the trees are relatively tolerant of the disease remains a mystery. For years, Southern Gardens Citrus has been genetically engineering plants to express genes taken from spinach that defend against the disease. The company says that the results of field trials suggest some degree of protection. But this approach will take many years to meet regulatory requirements for marketing a genetically modified crop. And consumers may not take kindly to a fruit or juice that comes from a genetically modified tree. So Southern Gardens Citrus added a different approach, and began the USDA approval process for engineered CTV in February. Instead of modifying the trees, the company wants to alter the genome of a harmless strain of CTV so that it produces the spinach defence gene. The company intends to graft tree limbs infected with the virus onto trees. In April, the USDA announced it would start work on an environmental impact statement, a process that typically takes about two years and will be needed before the department allows the modified virus to be used commercially. Because the virus does not alter the fruit, this approach may allow farmers to argue that the oranges are not genetically modified, and so avoid regulation and reduce public doubt. That is also the goal of separate projects looking for genes that confer disease resistance when switched off. If researchers can find such genes, they could use CRISPR to inactivate them. Nian Wang, a plant pathologist also at the University of Florida, is using this approach to edit orange trees, and hopes to know by 2019 whether they are disease-resistant. Others are using RNA interference in psyllids to switch off genes that allow the insects to transmit the bacteria. For now, one question dominates: whether the citrus industry will still be alive by the time these solutions make it to the groves. \u201cIt\u2019s an incredibly devastating disease,\u201d says Gmitter. \u201cGrowers needed answers ten years ago.\u201d \n                     Technology: The Future of Agriculture 2017-Apr-26 \n                   \n                     Plant biologists welcome their robot overlords 2017-Jan-25 \n                   \n                     Bioterror: The green menace 2008-Mar-12 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22094", "url": "https://www.nature.com/articles/nature.2017.22094", "year": 2017, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Acquisition could lead to new commercial services in scientific peer review. The owner of the vast science-citation database Web of Science \u2014 Clarivate Analytics \u2014 is buying up a firm that has gathered hundreds of thousands of peer-review records, in a deal that could lead to new ways of organizing scientific peer review and preventing peer-review fraud. Clarivate, a US company, said on 1 June that it had acquired Publons, a New Zealand-based start-up firm that encourages scientists to  share their peer review history  online to help gain credit for their reviewing activity. More than 150,000 researchers have registered with Publons, and they have shared details of some 800,000 peer reviews on its site. Although many journals request anonymous peer review, Publons privately verifies reviews, and publicly lists the number of reviews that scientists have conducted with particular journals. The firm also provides training for peer reviewers and collects post-publication reviews. The acquisition \u2014 financial details of which were not disclosed \u2014 might mean that Clarivate and Publons will sell science funders and publishers \u201cnew ways of locating peer reviewers, finding, screening and contacting them\u201d, says Jessica Turner, global head of the scientific and academic research business at Clarivate, headquartered in Philadelphia, Pennsylvania. Both firms already offer services that some journals use to find peer reviewers, she adds. Together, the companies now own large data sets that detail scientific authorship and citation patterns, as well as peer-review networks, across thousands of scholarly journals. That\u2019s a rare combination: competing science publishers tend to keep details of their favoured peer reviewers secret. Publons \u2014 which will continue to run as a stand-alone business \u2014 is particularly keen to help publishers tackle  fake peer review , says its co-founder Andrew Preston. The issue has led to  hundreds of retracted papers  over the past few years as journals have discovered  compromised review systems.  In such cases, authors typically suggest apparently genuine reviewers for their papers, but provide bogus e-mail addresses that they or their friends control, and from which they send in their own reviews. Because reviewers on Publons verify their e-mail addresses when they register with the site, the firm is effectively building a network of trusted, verified reviewers, with details of their peer-review record, Preston points out. \u201cWe can solve a lot of the inefficiencies that come out of the anonymous, siloed nature of peer review,\u201d he says. Publons data have already been used to analyse inefficiencies in peer review: one paper, for example, suggests that in 2015  just 20% of scientists undertook the majority of peer reviews. \n             Growing business \n           Many researchers may not be familiar with Clarivate Analytics by name. The company was officially launched as an independent firm just eight months ago. But it is influential in science because it holds the former intellectual-property and science division of Thomson Reuters, the multinational news and information company. Last year, two private-equity funds bought  that division in a US$3.55-billion deal , and in October, they  announced Clarivate as the name of the firm that would own it . The company owns other products alongside Web of Science, such as large patent databases and the ScholarOne system, which is used by some journals to manage their peer-review and publication processes.  Some industry observers had speculated that the private-equity funds would break up the division into parts to make a quick profit. But Turner says that they have invested in Clarivate and see \u201csignificant growth potential\u201d in its scientific and research business. \u201cPublons now find themselves at the heart of the rebuilding programme to support Clarivate\u2019s reinvention,\u00a0and a vital part of the system of reference and authority needed to maintain scholarly communication in a digital, networked age,\u201d says  David Worlock , a UK-based publishing consultant with knowledge of the deal. \u201cIf Clarivate can manage the next stages appropriately, then they have a chance to solve many of the issues around bringing pre- and post-peer review together,\u201d he adds. \n                   Peer-review 'heroes' do lion's share of the work 2016-Nov-22 \n                 \n                   Open peer review finds more takers 2016-Nov-10 \n                 \n                   \u2018Web of Science\u2019 to be sold to private-equity firms 2016-Jul-12 \n                 \n                   Publishing: The peer-review scam 2014-Nov-26 \n                 \n                   The scientists who get credit for peer review 2014-Oct-09 \n                 \n                   Fake peer review leads to retraction of 107 papers \n                 Reprints and Permissions"},
{"file_id": "545276a", "url": "https://www.nature.com/articles/545276a", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Famous bell-shaped pots associated with group of immigrants who may have displaced Neolithic farmers. Around 4,500 years ago, a mysterious craze for bell-shaped pottery swept across prehistoric Europe. Archaeologists have debated the significance of the pots\u00a0\u2014\u00a0artefacts that define the \u2018Bell Beaker\u2019 culture\u00a0\u2014\u00a0for more than a century. Some argue that they were the Bronze Age\u2019s hottest fashion, shared across different groups of people. But others see them as evidence for an immense migration of \u2018Beaker folk\u2019 across the continent. Now, one of the biggest ever ancient-genome studies suggests both ideas are true. The study,  posted on bioRxiv  on 9 May 1 , analysed the genomes of 170 ancient Europeans and compared them to hundreds of other ancient and modern genomes. In Iberia and central Europe, skeletons found near Bell Beaker artefacts share few genetic ties\u00a0\u2014\u00a0suggesting that they were not one migrating population. But in Britain, individuals connected to Beaker pots seem to be a distinct, genetically related group\u00a0that almost wholly replaced the island\u2019s earlier inhabitants (see \u2018Bell Beaker fashion\u2019). If true, this suggests that Britain\u2019s Neolithic farmers ( who left behind massive rock relics, including Stonehenge ) were elbowed out by Beaker invaders. \u201cTo me, that\u2019s definitely surprising,\u201d says Pontus Skoglund, a population geneticist at Harvard Medical School in Boston, Massachusetts, who was not involved in the research. \u201cThe people who built Stonehenge probably didn\u2019t contribute any ancestry to later people, or if they did, it was very little.\u201d Some archaeologists say that the study does not prove the scale of the British Beaker invasion, but agree that it is a major work that typifies how huge ancient-DNA studies are disrupting archaeology. It\u2019s \u201cgroundbreaking\u201d, says Benjamin Roberts, an archaeologist at Durham University, UK. \n               The Bell Beaker phenomenon \n             The variety of Beaker artefacts makes it hard to define them as emerging from one distinctive culture: many researchers prefer to call their spread the \u2018Bell Beaker phenomenon\u2019, says Marc Vander Linden, an archaeologist at University College London. The distinctive pots, possibly used as drinking vessels, are nearly ubiquitous; flint arrowheads, copper daggers and stone wrist guards are common, too. But there are regional differences in ceramics and burial style. And the immense, yet discontinuous, geographical range of Beaker sites\u00a0\u2014\u00a0from Scandinavia to Morocco, and Ireland to Hungary\u00a0\u2014\u00a0has sown more confusion. After a few hundred years, the pots vanish from the record. A 2004 analysis of strontium isotopes, which vary according to regional geochemistry, suggested that some Beaker-associated individuals did migrate in their lifetimes 2 . Past ancient-DNA studies have also hinted at a huge migration, linking Beaker-associated individuals in central Europe  to an influx of \u2018Steppe\u2019 peoples from what is now Russia and Ukraine 3 . The latest work, led by geneticists I\u00f1igo Olalde and David Reich at Harvard Medical School, involved 103 researchers at dozens of institutions, including Bronze Age archaeologists. Reich\u2019s team analysed more than 1\u00a0million DNA variants across the genomes of individuals who lived in Europe between 4700 and 1200  bc . The team declined to comment because the paper has not yet been published in a peer-reviewed journal. The analysis seems to dispel the idea of one \u2018Beaker people\u2019 arising from a specific source. Individuals in Iberia (which has been proposed as the wellspring for the culture) shared little ancestry with those in central Europe. Even Beaker-associated people in the same region came from different genetic stock. That pattern contrasts with  earlier upheavals in Europe driven by mass migrations , says Skoglund. Bell Beaker \u201cis the best example of something that is pots and not people\u201d that are spreading, he says. But in Britain, the arrival of Bell Beaker pots coincided with a shift in the island\u2019s genetics. Reich\u2019s team analysed the genomes of 19 Beaker individuals across Britain and found that they shared little similarity with those of 35 Neolithic farmers there. The pot-makers were more closely related to 14\u00a0individuals from the Netherlands, and had lighter-coloured skin and eyes than the people they replaced. By 2000\u00a0 bc , signals of Neolithic ancestry disappear from ancient genomes in Britain, Reich\u2019s team find \u2014 largely replaced by Beaker-associated DNA. Such turnover is \u201cpretty striking\u201d, says Garrett Hellenthal, a statistical geneticist at University College London  who has studied the peopling of the island through the genomes of living Brits . More data could reveal surprises, but the team makes a good case that Beaker folk replaced the region\u2019s early farmers, he says. Reich\u2019s team calculates that Britain saw a greater than 90% shift in its genetic make-up. But Roberts says he doesn\u2019t see evidence for such a huge shift in the archaeological record. The rise of cremation in Bronze Age Britain could have biased the finding, he cautions, because it might have eliminated bones that could have been sampled for DNA. Although archaeologists are excited to see  ancient DNA yield breakthroughs in problems that have vexed their field for decades , says Linden, he expects some push back against the latest study\u2019s conclusions. \u201cIt\u2019s not at all the end of the story.\u201d \n                     Farming invented twice in Middle East, genomes study reveals 2016-Jun-20 \n                   \n                     Source material 2016-May-25 \n                   \n                     Bronze Age skeletons were earliest plague victims 2015-Oct-22 \n                   \n                     DNA data explosion lights up the Bronze Age 2015-Jun-10 \n                   \n                     Steppe migration rekindles debate on language origin 2015-Feb-18 \n                   \n                     Minoan civilization was made in Europe 2013-May-14 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.21977", "url": "https://www.nature.com/articles/nature.2017.21977", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Researchers and manufacturers face possible jail time \u2014 or execution \u2014 for fraudulent submissions to nation's drug agency. Those who submit faked clinical trial data might now go to jail \u2014 and in extreme circumstances, be executed \u2014 under a new interpretation of China\u2019s criminal code, announced last month. The policy shift is one of a handful of measures that China is implementing both to speed up its notoriously slow drug-approval process and to keep dangerous and ineffective drugs off the market. This move \u201cis the strongest signal yet, to all the drug developers, clinical-trial managers and principal investigators and physicians, that China is now very serious about clinical data\u201d, says Dan Zhang, executive chairman of Beijing-based Fountain Medical Development, which helps companies to carry out clinical trials and itself stands to be held accountable by the policy change. A hint of the depth of the problem came after the China Food and Drug Administration (CFDA) in 2015 ordered companies to re-evaluate \u201cthe authenticity, integrity and compliance of clinical trial data\u201d in pending applications for new drugs. The agency told them that if CFDA examiners later found violations, the companies would not be able to submit other drugs for approval.  More than 80% of the applications were voluntarily withdrawn,  according to CFDA documents. One-quarter of the remainder was subsequently rejected because of problems with authenticity.\u00a0 The new policy will broaden current laws to cover submissions of clinical-trial data, says Liu Ye, a lawyer dealing with medical issues at Haishang Law Firm in Shanghai. Manufacturing and selling counterfeit versions of drugs was already a crime, but the submission of fake data in the approval process was unregulated territory, says Su Ling, director of the Institute of Drug Regulatory Science at Shenyang Pharmaceutical University and a venture partner for the investment fund Lilly Asian Ventures. The new policy was approved by a court review committee on 10 April and will go into effect when published by the high court, expected within a few months. It will make those who submit faked clinical-trial data guilty under the same law as counterfeiting. \n               Possible death penalty \n             Under that law, if the approved drug causes health problems, it can result in a 10-year prison term or the death penalty, in the case of severe or fatal consequences. Even if the drug is not approved and even if no one is harmed by an approved drug, those who break the law by submitting fake data may face three years in prison. The new policy also subjects those who submit fake clinical trial data to prosecution under a law that forbids bearing false testimony. The impact will depend on how the change is implemented, says Su. It still is not clear who among the large number of people involved in a trial would be held responsible for problematic data. Su also wonders how severe a judgment will be. \u201cWill falsified data for one patient break the law, or would it have to be 10 or 100?\u201d The first prosecution will clarify this, he says. \u201cThe government might make an example of someone.\u201d Some doubt that anyone will be executed under the new policy, but others say it could happen. In 2007,  China executed the former head of its drug agency  for accepting bribes to approve medicines, some of which ended up killing people. \u201cIt\u2019s a remote possibility, but if kids start taking bad vaccines, for example, and they die, I could see a real chance of this happening,\u201d says Zhang. Liu, however, says that it might be difficult to enforce. \u201cIf intent cannot be proven, the crime will not hold. Proving intent is very challenging,\u201d he says. Critics have long argued that the Chinese pharmaceutical industry is rife with problems. The flurry of application withdrawals last year happened for a variety of reasons, including poor documentation, \u201cuntruthful\u201d data and neglect of standard protocols, according to a CFDA official. \n               Cutting corners \n             Publications from Chinese clinical hospitals tell a similar tale, says John Ioannidis, a researcher in health policy at Stanford University in California. They often fail to document whether trials are double-blinded, whether the study goals are achieved, whether informed consent and ethics approval had been given and whether the test and control groups had been randomly selected to decrease bias. Studies have also found\u00a0that Chinese trials are much more likely to show a positive effect for a drug, even if the medicine had failed elsewhere. \u201cMost of these problems are the result of people trying to cut corners in order to get papers published in better journals and reap the resulting benefits,\u201d says Ioannidis. Su says the new policy will scare off many shams, whose applications clog up the approval process, and thus clear the way for valid drugs, which have been slow to get approval. There is typically a wait of four years or more for the CFDA to approve drugs that have already been approved in the United States or Europe. The CFDA has taken other steps to speed up the regulatory process and make it more rigorous. Between mid-2015 and the end of 2016, it quadrupled the number of staff by adding 450 new regulators, and it expects to add another 300 this year. And beginning in May, the Center for Drug Evaluation will be allowed to approve drugs to start clinical trials without getting a rubber stamp from the CFDA, its parent organization, which adds months to the process. Su even worries the efforts might \u201coverheat\u201d. People lacking drug development or regulatory experience could approve ineffective or even dangerous drugs, and that could be disastrous, he says. \n                     China embraces precision medicine on a massive scale 2016-Jan-06 \n                   \n                     China drugs head fired over article row 2013-Jun-18 \n                   \n                     Executed Chinese drug czar corrupted by system, observers say 2007-Aug-31 \n                   \n                     China's deadly drug problem 2007-Apr-04 \n                   \n                     Science in China special issue \n                   \n                     China Food and Drug Administration \n                   Reprints and Permissions"},
{"file_id": "545273a", "url": "https://www.nature.com/articles/545273a", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Rural and struggling areas have benefited from funding that is now at risk. In the heavily fished waters of the Gulf of Mexico, the red snapper has made a notable comeback. Strict US government regulations have helped to rebuild its stocks after overfishing caused a population crash in the 1980s and 1990s. Now the fish faces a new challenge: President Donald Trump, a Republican who  wants to cut roughly US$50\u00a0billion from the government\u2019s civilian agencies  in 2018. Trump\u2019s plan would eliminate the Missi-ssippi-based Sea Grant programme that is poised to oversee a $12-million study of red-snapper stocks. Its findings are meant to guide future management decisions, and to protect a fishery that hauls in billions of dollars per year for the Republican-dominated gulf states. Now the study\u2019s fate is uncertain\u00a0\u2014 along with those of many other government science programmes, including some that largely benefit the voters who propelled Trump into office. In 2014, about $35\u00a0billion \u2014 or nearly one-third of all federal research dollars \u2014 flowed to states that voted Republican in the most recent presidential election, a  Nature  analysis found (see \u2018Red state, blue state\u2019). Economists have documented how this type of government investment shores up local economies, says Mark Muro, a senior fellow and policy analyst at the Brookings Institution, a think tank in Washington DC. \u201cMany smaller communities have a huge amount to lose,\u201d he says. US politicians have long worked to spread federal research and development (R&D) largesse around the country. In 1862, Congress established the land-grant system of universities to teach agriculture and engineering, with many institutions located in newly established states. After the Second World War, politicians created a network of national labs, including  facilities in rural areas that had secretly worked on the atomic bomb during the war . Today, some federal agencies deliberately distribute funds to parts of the country beyond the elite research powerhouses. The National Science Foundation sets aside $160\u00a0million from its $6-billion research budget to award university grants to states that routinely receive less than 0.75% from the agency\u2019s ordinary funding channels. In recent years, the programme has seeded an optics industry in Montana and carbon-cycle research in Alaska. And in 2014, former US president Barack Obama created a national network of  institutions to develop advanced manu-facturing technologies . Manufacturing jobs in the United States fell by 32% between March\u00a01989 and September 2016, particularly in midwestern and \u2018rust belt\u2019 states. There are now 14 institutes in the \u2018Manufacturing USA\u2019 network, including a 3D-printing group in Youngstown, Ohio, and a lightweight-metals institute in Detroit, Michigan. An advanced-composites institute in Knoxville, Tennessee, works with wind-turbine and car manufacturers to make their products lighter and stronger. \u201cIt\u2019s given us access to tools and resources and people we didn\u2019t have before,\u201d says Gregory Haye, general manager of Local Motors in Knoxville, which made the first 3D-printed car. In January, an independent analysis by the Deloitte consulting firm found that Manufacturing USA is bringing together companies that would not otherwise connect. The US National Academy of Sciences is intrigued enough to plan a 23\u00a0May workshop that will assess the institutes\u2019 successes and where they should go next. Yet their funding remains uncertain, because they were a pet project of Obama\u2019s\u00a0\u2014 and because the programme\u2019s cost is expected to reach nearly $1.9\u00a0billion as more institutes launch. A related programme, the $130-million Manufacturing Extension Partnership for small manufacturers, is already on Trump\u2019s chopping block, notes William Bonvillian, who studies innovation policy at the Massachusetts Institute of Technology in Cambridge. So far, Trump has suggested only broad cuts to the federal budget; he is expected to release a more detailed 2018 spending proposal next week. But the president\u2019s themes are clear: even as he speaks about bolstering blue-collar jobs, he suggests cutting some research that underpins rural economies. \u201cThe current priorities are very much at odds with our view of what R&D and innovation strategies would benefit the economy,\u201d says Scott Andes, an analyst at Brookings. It is not clear  to what extent Congress will go along with Trump\u2019s plan , however. In the meantime, federal scientists in Colorado are in the middle of a ten-year experiment that could improve the profitability of a quintessentially American activity: ranching. Government researchers have been working on the prairies here since 1939, after overploughing and drought led to devastating dust storms. Now they are exploring whether beef producers and conservation biologists can develop grazing practices that benefit them both. Beginning in 2012, the group split ten short-grass pastures in half. On one side, ranchers graze cattle as they have traditionally. The other half is controlled by scientists, who manage the land for plant and bird biodiversity; they aim to establish a variety of range grasses and to help livestock better weather difficult years. So far, the cattle on the traditionally managed pastures are gaining weight faster than those on the scientifically managed pastures. But the real test of the experiment, which has cost a little over $3 million since 2012, will come if Colorado experiences a severe drought. That will show which of the two approaches works better to feed cattle through hard times. \u201cThe whole idea is to use science to inform management,\u201d says Hailey Wilmer, a rangeland scientist with the US Department of Agriculture\u2019s Agricultural Research Service in Fort Collins, Colorado, which oversees the work. This sort of federal investment could help the cattle country of the American West. \u201cI\u2019d take anything into consideration,\u201d says Jeff Wahlert, a rancher in Grover, Colorado, who runs cattle on the test pastures. \u201cThere\u2019s always something that you can try to help your operation.\u201d \n                     Science wins reprieve in US budget deal 2017-May-01 \n                   \n                     US science agencies face deep cuts in Trump budget 2017-Mar-16 \n                   \n                     Science economics: What science is really worth 2010-Jun-09 \n                   \n                     Nature  special: Tracking the Trump White House \n                   \n                     Mississippi\u2013Alabama Sea Grant Consortium \n                   \n                     USDA Central Plains Experimental Range \n                   \n                     Manufacturing USA \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21975", "url": "https://www.nature.com/articles/nature.2017.21975", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "DNA sequences from 100-year-old tumour samples could bolster childhood cancer research. Deep in the basement archives of London's Great Ormond Street Hospital for Children reside the patient records that cancer researcher Sam Behjati hopes will put the hospital's past to work for the future. On 2 May, he and his colleagues published the result: DNA sequences from the genomes of three childhood tumour samples collected at the facility almost a century ago 1 . Those historic cells help to address a modern problem: the small number of tumour samples from rare cancers that are available for researchers to sequence. Behjati knows this problem well. At the Wellcome Trust Sanger Institute in Hinxton, UK, he tracks  the genomic miswiring that can lead to rare childhood cancers . And as someone who also treats patients, he has been frustrated by the paucity of evidence backing up much of his practice. \u201cThe treatment regimens for children with rare cancers are essentially made up,\u201d Behjati says. \u201cIf you\u2019ve got three or four patients nationally, how are you ever going to conduct a reasonable clinical trial?\u201d To expand the pool of samples that he could sequence, he decided in 2014 to harness advances in genome sequencing that had already made it possible to sequence DNA from pathology samples a few decades old. The hospital's 165-year archive of samples and patient records provided the opportunity to see how far back in time he could go. \n               Rich resource \n             The work highlights the wealth of material that is available in such archives, says Danielle Carrick, a programme director at the US National Cancer Institute in Rockville, Maryland. Mining such archives can expand the options for studying rare conditions and understudied ethnic populations, she notes, and make large, population-scale studies possible. Researchers have analysed DNA from much older specimens: fragments of genome sequence have been used to study  ancient human populations from hundreds of thousands of years ago . But DNA tends to degrade over time, and cancer researchers need high-quality sequences to pinpoint the many individual mutations that can contribute to tumour growth. Great Ormond Street Hospital was founded in 1852 on the back of charitable donations raised chiefly by the author Charles Dickens. Behjati and pathologist Neil Sebire of the Great Ormond Street Hospital Institute of Child Health at University College London directed their team to begin searching its archive for samples from the 1920s, however, when the terminology used to classify tumours was more easily comparable to modern diagnoses. The team pored over the patient registry, a well-worn tome with patient names, numbers and diagnoses handwritten in a tiny, precise scrawl. The samples arrived in a small cardboard box filled with dozens of paraffin wax cubes roughly the size of fingernails, with patient numbers handwritten on the sides of each block. Within each chunk of wax was a sample that had been soaked in a solution containing formaldehyde to preserve the tissue and make it rigid. Sebire and his colleagues fished out the blocks they needed, took a thin slice of each and dyed the tissue red and pink with stains. The whole technique \u2014 the formaldehyde, the wax, the stains \u2014 is well over a century old, Sebire notes. What has changed dramatically, however, is cancer treatment. The children with cancer who came to Great Ormond Street in the 1920s had few options beyond surgery. Chemotherapy was still decades away. And in the absence of modern imaging methods, children who were diagnosed often had advanced disease, their tumours large enough to be felt by the physician. \n               Archive dive \n             Behjati hopes that those tumours will now help him and others to develop better options for future patients. The team picked three samples: a muscle cancer called rhabdomyosarcoma, a blood-vessel tumour called cellular capillary haemangioma and a lymphoma. After they confirmed the original diagnoses using the stained slices, his team extracted DNA from much of the remaining sample and sequenced 366 genes in each one. They found cancer-associated mutations in all three samples. He plans to keep searching through the Great Ormond Street Hospital collection, and then perhaps to mine the archives of other hospitals for relics of childhood cancers. As his collection grows, he will look for commonalities and potential drug targets. Childhood cancers might be particularly amenable to the approach, notes Sebire. The genomes of adult cancers are often scarred by hundreds of mutations; the genomes of childhood cancers, however, tend to contain far fewer alterations. This makes it easier for researchers to home in on those mutations that are most important, and to sift through the background noise of degraded DNA. But as these centuries-old samples find a modern use, the pathology techniques that were used to create them are on the wane, he adds. Not long from now, Sebire predicts, pathology labs will give up their microscopes altogether in favour of instruments that rapidly sequence DNA and proteins and identify metabolites. \u201cThe process hadn\u2019t really changed for over 100 years,\u201d he says. \u201cBut by the time I retire, I fully expect that you won\u2019t need to do what I do now.\u201d \n                     Cell maps reveal fresh details on how the immune system fights cancer 2017-May-04 \n                   \n                     An early start on tackling childhood cancers 2017-Mar-29 \n                   \n                     Cruel fusion: What a young man\u2019s death means for childhood cancer 2017-Mar-28 \n                   \n                     Cancer experts unveil wishlist for US government \u2018moonshot\u2019 2016-Sep-07 \n                   \n                     \u2018Pan-cancer\u2019 study unearths tumours\u2019 genetic trademarks 2013-Sep-26 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22020", "url": "https://www.nature.com/articles/nature.2017.22020", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Researchers welcome pre-election promises to raise R&D, implying billions more for science. UK scientists worried about how Brexit will affect their funding received a boost this week, when the country's three main national parties pledged long-term targets to raise research spending. The announcements came in party manifestos unveiled ahead of national elections in June. It's \u201ca surprise and a delight\u201d to see the promises, says Graeme Reid, a science-policy researcher at University College London. None of the manifestos makes detailed financial commitments to science. But each sets targets to substantially increase spending on research and development (R&D) as a proportion of the country\u2019s gross domestic product (GDP) \u2014 an indicator often taken as a measure of a nation\u2019s commitment to research. The United Kingdom spends\u00a01.7% of its GDP on research, less than the European Union\u2019s 2% average and well behind many\u00a0other developed nations (see 'Research spending gap'). The governing Conservative Party \u2014 which polls suggest should sweep the 8 June election \u2014 has promised to raise that figure to 2.4%\u00a0within 10 years, and to aim for a longer-term goal of 3%. The opposing Labour Party says it wants to hit 3% by 2030, and the Liberal Democrats \u2014 traditionally the country\u2019s third party \u2014 promise a \u201clong-term goal\u201d to \u201cdouble innovation and research spending across the economy\u201d. The pledges are aspirations that will take more than one term of Parliament to deliver, Reid notes. And a government by itself won\u2019t be able to achieve the targets, because they rely on business R&D investment rising in concert with public funding. But if the parties stick to their pledges, there should be billions of pounds more for British scientists. The London-based Campaign for Science and Engineering (CaSE) calculates that to reach the 3% target, the government would have to commit an extra \u00a36 billion (US$8 billion) per year to research funding, on top of its current \u00a36 billion and  an existing commitment to raise annual funds by \u00a32 billion by 2020 . That calculation assumes that for every pound spent by government on R&D, businesses will chip in twice as much \u2014 a 2:1 split that\u2019s typical internationally, CaSE says. \u201cThis is a significant and welcome commitment,\" says James Wilsdon, a research-policy specialist at the University of Sheffield, UK. \u201cIt\u2019s 13 years since we last heard such an ambitious GDP-linked target for R&D spending from a party of government.\u201d In 2004, the then-Labour government aimed for R&D funding to reach 2.5% of GDP by 2014, he notes, but the pledge was derailed by the financial crisis. A coalition of the Liberal Democrats and Conservatives that governed from 2010 to 2015 avoided setting a long-term goal. Researchers have often called for a 3% spending target. As far back as 2000, the European Union set itself the aim of raising its R&D funding to that level, but it is still nowhere near. Reid says there is not a huge amount of evidence on the optimum level of research spending, but what there is suggests that around 2.5% of GDP is best. The United Kingdom is far beneath that, so a political commitment to increase R&D spending is more important than fretting about which level to reach, he says. Not everyone thinks that an R&D spending measure is a useful target. William Lazonick, an economicist at the University of Massachusetts Lowell, says that a national overall R&D target ignores the fact that research spending is disproportionately concentrated within a few, high-spending sectors, such as the pharmaceutical industry. A 3% target is \u201cmuch too general\u201d, he says, and does not help assess spending in research-intensive sectors. And spending on R&D does not necessarily translate into economic productivity gains, he notes.\u00a0 \n                   The most powerful man in UK science on his new role 2017-Feb-08 \n                 \n                   UK scientists excited by surprise \u00a32-billion government windfall 2016-Nov-23 \n                 \n                   Nature  special: Brexit and science \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22016", "url": "https://www.nature.com/articles/nature.2017.22016", "year": 2017, "authors": [{"name": "Sarah McQuate"}], "parsed_as_year": "2006_or_before", "body": "Bright spots of light over land could help in the search for Earth-like exoplanets. Mysterious flashes of light that show up on satellite images of Earth's landmasses have puzzled researchers for a couple of years. Now, scientists have finally pinpointed the culprit: ice crystals floating high above the planet's surface. The finding could help refine ideas of how clouds regulate the Earth's temperature. And it could aid  scientists looking for Earth-like exoplanets  orbiting other stars. Glinting exoplanets may contain water and be \u201c potential Earth twins \u201d, says Tyler Robinson, a planetary scientist at the University of California, Santa Cruz, who wasn't involved in the study. Alex Kostinski, a physicist at Michigan Technological University in Houghton, and his colleagues solved the mystery using images from an instrument on board the Deep Space Climate Observatory (DSCOVR). The satellite launched in 2015 and is parked 1.5 million kilometres away from Earth. Space-based instruments have captured such glints before, but never from this distance, the team reported this week in  Geophysical Research Letters 1 . In fact, \u201cwe didn\u2019t expect to see it this far away\u201d, says Kostinski. \u201cIt\u2019s quite amazing.\u201d \n             A hint of sunlight \n           These flashes, which researchers call glints, occur when sunlight bounces off a smooth, mirror-like surface such as a body of water or flat ice crystals in a cloud. These reflections only occur at specific latitudes, where the angle of light from the Sun to Earth matches that between Earth and the observing spacecraft. Kostinski and his colleagues mapped out the latitudes at which glints could occur and the places where bright spots appeared over land on DSCOVR-produced images, and found that they matched. That suggested the flashes were glints and not lightning strikes or glitches in the instrument that produced the images. \u201cAt that point, we began to suspect ice crystals in clouds because they\u2019re flat,\u201d says Kostinski. \u201cBut how do you prove it?\u201d That\u2019s when the team turned to oxygen, which absorbs specific wavelengths of light as the rays travel through Earth\u2019s atmosphere. Because glints coming from a body of water travel through more oxygen than glints from a cloud, the researchers could use the different wavelengths of light in the images to estimate where the reflections originated. The absorption from glints on the DSCOVR images matched that expected from reflections off an object 5\u20138 kilometres off the ground. This suggested that mirror-like ice crystals in mid to high-altitude clouds were behind the mysterious flashes of light. \n             Extraterrestrial glints \n           Some of the flashes collected by a camera on DSCOVR were so bright that they temporarily overwhelmed the instrument\u2019s sensors, even at 1.5 million kilometres away. \u201cThat\u2019s a really strong signal,\u201d says Mark Swain, an astrophysicist at the Jet Propulsion Laboratory in Pasadena, California. \u201cThat\u2019s super exciting,\u201d he says, because it means these glints might be  bright enough to detect if they appear on exoplanets . These flashes could be a marker that helps researchers determine whether an exoplanet has water or not. These other worlds are so far away that any perceived glints would probably come from oceans or larger bodies of water, not from tiny ice crystals in the atmosphere, says Robinson. \u201cThe patch of the planet that has the ice cloud on it is likely going to be itsy-bitsy,\u201d he says \u2014 unless a planet is covered in ice clouds. Still, these results have got exoplanet researchers fired up. \u201cWhat\u2019s exciting to me is the potential for this effect with different materials other than water ice, and different types of exoplanet atmospheres,\u201d says Swain. Then the effect could \u201cbe stronger and that might have ramifications for how we study exoplanets in the future\u201d. \n                   Planet hunters seek new ways to detect alien life 2016-Jul-27 \n                 \n                   The truth about exoplanets 2016-Feb-17 \n                 \n                   The exoplanet files 2015-Nov-18 \n                 \n                   Climate scientists join search for alien Earths 2015-Apr-17 \n                 \n                   Exoplanet bounty includes most Earth-like worlds yet 2015-Jan-06 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22040", "url": "https://www.nature.com/articles/nature.2017.22040", "year": 2017, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Ethiopia\u2019s Tedros Adhanom Ghebreyesus to head agency amid calls for reform. The World Health Organization (WHO) has its first director-general from Africa. Ethiopia\u2019s Tedros Adhanom Ghebreyesus will take the top post at the agency from 1 July \u2014 succeeding Margaret Chan \u2014 after winning a 23 May vote by WHO member states at the World Health Assembly, their annual gathering in Geneva, Switzerland. Tedros is a public-health expert who has formerly been both a health minister and a foreign minister in Ethiopia\u2019s government, and he will lead the WHO for a 5-year term. He takes the helm troubled times: the WHO\u2019s core budget \u2014 its dues from its members \u2014 is falling, and it is now dangerously dependent on the voluntary contributions that make up the vast bulk of its spending and often come with strings attached by donors. The agency has also often been  criticized for its complex, bureaucratic and ineffective management structure . Chan has spent a decade (two terms) in office. Her leadership was criticized in 2014, when the agency was slow to respond to the Ebola epidemic in West Africa. That prompted  several outside reviews  and ongoing  reforms of ways the organization responds to disease outbreaks . Widespread horse-trading between the WHO\u2019s member states was expected during the secret ballot for the director-general position, at which new voting rules were applied. Previously, the post was picked by members of the WHO\u2019s Executive Board, a group representing 34 of the member states, and then rubber-stamped by the assembly. But in the new election, all member states have a single vote \u2014 giving small countries such as the Pacific island nation of Tuvalu the same voting weight as China or the United States. Tedros\u2019s victory was announced after around four hours of voting. He defeated the United Kingdom\u2019s David Nabarro \u2014 a physician who has led the United Nation\u2019s response to Ebola, bird flu, cholera in Haiti and other health crises \u2014 in a final vote-off. The third contender, Pakistan\u2019s Sania Nishtar, a physician cardiologist and a former health minister, was eliminated in the first round. \n                   Clock is ticking for WHO decision over Taiwan 2017-May-19 \n                 \n                   The time is ripe to reform the World Health Organization 2017-Jan-31 \n                 \n                   World Health Organization rethinks its response to disease outbreaks 2016-Dec-20 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22026", "url": "https://www.nature.com/articles/nature.2017.22026", "year": 2017, "authors": [{"name": "Adam Levy"}], "parsed_as_year": "2006_or_before", "body": "Microbes have been genetically engineered to sense red, green and blue light, and to produce pictures of what they 'see'. To show off the powers of synthetic biology, researchers have engineered a primitive kind of colour vision into bacteria \u2014 and got the microbes to paint pictures of what they see. The genetically modified  Escherichia coli  can sense red, green and blue (RGB) light, and they respond by producing a pigment of the corresponding colour. Projecting light on to a Petri dish of the bacteria leads them to create colour \u2018photographs\u2019, albeit ones with an exposure time of 18 hours. The RGB-sensitive  E. coli  make up a toy system that is a stepping stone to more complex biological programming, says Christopher Voigt, who led the study at the Massachusetts Institute of Technology in Cambridge and has pictures from the experiment hanging on his office wall. The work is published in  Nature Chemical Biology 1 . In 2005, a team led by Voigt  engineered  E. coli  to respond to light and produce a black pigment , creating black-and-white images 2 . That study required the insertion of four genes into the bacteria, including one that codes for a light-sensitive protein taken from a cyanobacterium and one for a protein that blackens a particular chemical. The RGB system uses 18 genes, including three that encode light-sensitive proteins. It \u201cgoes way beyond the original black and white system in terms of complexity\u201d, says Pamela Silver, a systems biologist at Harvard Medical School in Boston, Massachusetts. The wider aim, says Voigt, is to find ways to turn many types of gene on and off in bacteria using flashes of light of different colours. Researchers could then, for example, make the bacteria produce complex molecules on demand by using light to stop and start reactions. It may be easier and cheaper, at large scales, to stimulate microbes with light rather than bathing them in particular chemicals, says Voigt. He already has a catchy name for his light-sensitive systems: disco bacteria. \n                   Light-controlled genes and neurons poised for clinical trials 2016-May-19 \n                 \n                   Biology software promises easier way to program living cells 2016-Mar-31 \n                 \n                   Mantis shrimp's super colour vision debunked 2014-Jan-23 \n                 \n                   Bacterial films turn to photography 2005-Nov-23 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22039", "url": "https://www.nature.com/articles/nature.2017.22039", "year": 2017, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "These celestial bodies coalesce into objects shaped like giant red blood cells. Rocky planets, including Earth, endure violent beginnings. Giant impacts vaporize enormous chunks of protoplanets, surrounding them in a flattened halo of debris. Scientists believe that these  disks eventually condense to form planets . Now, improved computer simulations of planet formation suggest that many of these embryonic objects pass through a phase late in their adolescence in which they assume the shape of enormous red blood cells called synestia. Researchers led by planetary scientist Sarah Stewart at the University of California, Davis, published their description of these huge, spinning clouds of vaporized rock on 22 May in the  Journal of Geophysical Research: Planets 1 . The finding could help scientists to improve their understanding of planet formation, and lead to better explanations of how Earth\u2019s Moon formed. \u201cWe discovered that there\u2019s a different class of objects where the system is rotating so quickly, and it\u2019s so hot, that there\u2019s no actual boundary between what we used to call the planet and the disk,\u201d Stewart says. \n             Going for a spin \n           In her quest to build a better model of how planets form, Stewart and her co-author Simon Lock, a planetary scientist at Harvard University in Cambridge, Massachusetts, incorporated the effects of repeated impacts with other large objects, including other protoplanets, which usually occur in the later stages of planet assembly. In this phase, a  planet grows chaotically , because each collision releases incredible amounts of energy. If a growing planet experiences a glancing blow from a giant object, the collision can throw up a cloud of pulverized material and set both the planet and the cloud spinning. The researchers\u2019 model showed that the cloud eventually becomes a single, coherent structure shaped like a red blood cell. They estimate that these structures only last for a short period: hundreds or thousands of years. \u201cIt\u2019s a more detailed treatment that modifies the previous picture of how planets form,\u201d says Joshua Eisner, an astronomer at the University of Arizona in Tucson, who wasn\u2019t involved in the study. \u201cPeople have seen these kinds of structures in other contexts though, like for rapidly rotating stars or even Jupiter formation models.\u201d But rocky planet formation is much more complex, and previous models didn\u2019t include enough information to reveal fleeting structures such as synestia. \n             Moonstruck \n           A synestia probably wouldn't form for every planet, says Donald Korycansky, a planetary scientist at the University of California, Santa Cruz, who wasn\u2019t involved in the study. But he wouldn't be surprised if they turned out to be fairly common. In fact, a single planet could pass through the synestia phase multiple times if it is subjected to several giant impacts. In Stewart\u2019s simulations, more than half of the Earth-sized rocky planets withstand one giant impact as they form, and some can experience two or more such events. Once the impacts die down and a synestia begins to cool, it shrinks and particles start to settle. The rock and debris in the outer part of the structure condense and fall back on to the embryonic planet at the centre. Any leftover material that\u2019s far enough away from the growing planet could come together to form moons within a few thousand years. This is how Stewart and her colleagues think Earth\u2019s Moon formed. Current theories for the Moon\u2019s formation posit that a  Mars-sized object called Theia crashed into Earth  about 4.5 billion years ago. The ejected debris from Earth and Theia eventually coalesced into the Moon. However, this \u2018giant impact hypothesis\u2019 doesn\u2019t explain the  striking chemical similarities between Earth and the Moon . But a synestia could explain those similarities, Stewart says. She and her colleagues are currently working on modelling how Earth and its debris might have gone through a synestia phase generated by an impact with Theia. \n                   The truth about exoplanets 2016-Feb-17 \n                 \n                   Small rocks build big planets 2015-Aug-19 \n                 \n                   Puzzle of Moon\u2019s origin resolved 2015-Apr-08 \n                 \n                   Astronomy: Planets in chaos 2014-Jul-02 \n                 \n                   Lunar rock chemistry supports big-smash theory 2014-Jun-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22054", "url": "https://www.nature.com/articles/nature.2017.22054", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Treatment will be given on the basis of a tumour\u2019s molecular markers, rather than its location in the body. The US Food and Drug Administration (FDA) has issued its first approval of a cancer drug that targets tumours with specific mutations, regardless of where in the body the tumour first took root. This deviates from the agency\u2019s previous approach: although a drug\u2019s use may have been linked to the presence of a particular molecular marker, the FDA still required individual approvals to deploy that drug based on the tumour's location. The announcement on 23 May expands the use of pembrolizumab, manufactured by pharmaceutical giant Merck & Co. of Kenilworth, New Jersey. The drug boosts the body\u2019s ability to attack tumours  by blocking a protein called PD-1 , which normally holds the immune system in check. The FDA had previously approved pembrolizumab for use in several cancers, including lung and skin cancer. But physicians can now use it in any solid tumour that has a particular defect in its ability to repair damaged DNA. Researchers have been anticipating such marker-based approvals for roughly a decade, as the rise of molecular profiling \u2014 characterizing a tumour based on the genes and proteins that it expresses \u2014 has promised a shift in cancer treatment. Similar approvals may be on the horizon as companies begin to structure more of their clinical trials to gather data on a drug\u2019s effects across multiple tumour locations. \u201cIt\u2019s exciting,\u201d says cancer biologist Trever Bivona of the University of California, San Francisco. \u201cIt\u2019ll signal a very clear shift in the way the whole ecosystem operates: the FDA, the companies and the oncologists.\u201d \n             Location, location, location \n           Yet achieving this milestone has been more difficult than many cancer researchers initially expected. Despite early enthusiasm for the approach, researchers have come to respect the influence of a tumour\u2019s location on its response to treatment, says cancer researcher Ren\u00e9 Bernards of the Netherlands Cancer Institute in Amsterdam. \u201cIt was a case of irrational exuberance,\u201d he says. \u201cWhen push comes to shove, the clinical responses were not that impressive.\u201d Bernards speaks from experience. In 2010, researchers reported a successful trial of a drug called vemurafenib, which targets a mutated form of the protein B-RAF 1 . Subsequent studies found that the drug worked in 48% of melanomas with that mutation 2 . The results came as  cancer genome sequencing efforts were gathering steam , building massive catalogues of mutations found across different cancers. The vemurafenib success fuelled hopes that the drug would work in other cancers with the same B-RAF mutation. But in colon cancers with those mutations, the data were dismal: only about 5% of patients responded to the drug 3 . The episode has since become the poster child for the importance of location, Bernards says. His team studied cancer cells grown in culture, and found an additional pathway \u2014 active in colon-cancer cells but not in most skin-cancer cells \u2014 that could allow colon cancers to escape the effects of vemurafenib 4 . \u201cContext does seem to matter,\u201d he says. \u201cBig time.\u201d \n             Betting on markers \n           But the success of pembrolizumab shows that a marker-based approach can still work in some cases. In 2015, researchers reported that about 71% of trial participants whose tumours had a defect in their ability to repair damaged DNA benefited from pembrolizumab treatment, regardless of where those tumours were located 5 . The flaw disables a pathway that repairs mistakes made by the enzymes that copy DNA during cell division. Those mistakes create mutated proteins that can signal to the immune system that something is amiss, says James Eshleman, a pathologist at Johns Hopkins University School of Medicine in Baltimore, Maryland. Still, the landmark approval opens doors to other companies betting on this approach. Investigators at Loxo Oncology in Stamford, Connecticut, are betting that their drug larotrectinib will also be able to override location-specific cues. Larotrectinib targets TRK-fusion proteins, which are created when two genes fuse together. The resulting proteins spur tumour growth, and Loxo has been testing its drug in any tumour with the fusions. The company will report data from its trials on 3 June at the annual meeting of the American Society of Clinical Oncology in Chicago, Illinois.  It is unusual for companies to launch such \u2018tissue-agnostic\u2019 trials, says Bivona. But he expects the FDA approval to encourage more companies to try that route \u2014 particularly when researchers are targeting a rare molecular marker. Enrolling participants with the same marker across different tumour types will help boost the size of trials, he notes. \u201cYou can get a quicker readout on the effectiveness of the drug,\u201d says Bivona. \u201cPractically speaking, I would say this is the most important upside of this approach.\u201d \n                   Century-old tumours offer rare cancer clues 2017-May-10 \n                 \n                   Cell maps reveal fresh details on how the immune system fights cancer 2017-May-04 \n                 \n                   Promising cancer drugs may speed tumours in some patients 2017-Mar-31 \n                 \n                   Nature  Outlook: Cancer immunotherapy \n                 \n                   FDA announcement \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22057", "url": "https://www.nature.com/articles/nature.2017.22057", "year": 2017, "authors": [{"name": "Michele  Catanzaro"}], "parsed_as_year": "2006_or_before", "body": "Diego G\u00f3mez had faced up to eight years in jail in closely watched copyright case whose verdict has been appealed. A Colombian biologist who faced a criminal trial for posting another scientist\u2019s thesis online has been cleared of copyright violation \u2014 an offence that, under Colombian law, might have brought him a jail sentence. Diego G\u00f3mez Hoyos was handed down his \u2018not guilty\u2019 verdict on 24 May by a judge in Bogot\u00e1, although the prosecutor in the case has appealed the decision. \u201cI have been cleared. I am innocent,\u201d a delighted G\u00f3mez said after the verdict. \u201cWhen I received the news, after four years with so much uncertainty, which is an obstacle in personal and professional life, that was a great happiness. However, knowing that the prosecutor appealed brings uncertainty back.\u201d In 2011, G\u00f3mez, then at the University of Quind\u00edo in Armenia, Colombia, uploaded a scientist\u2019s 2006 thesis on amphibian taxonomy on the document-sharing network Scribd, hoping to help fellow students with their fieldwork. But two years later, he was notified that the author of the thesis was suing him.G\u00f3mez says that he removed the document immediately,  but he was still accused of violating copyright . And according to Colombia\u2019s laws, these charges were criminal in nature and punishable by up to eight years in jail. (The country\u2019s law was reformed in 2006 to meet the stringent copyright protection requirements of a free-trade agreement signed with the United States. Yet, although the United States has few criminal penalties for copyright infringement, Colombia allows for only a few exceptions.) The Karisma Foundation, a Colombian human-rights organization, took up G\u00f3mez\u2019s case, and launched the campaign \u2018 Sharing is not a crime \u2019 in support of him. And G\u00f3mez\u2019s lawyer tried \u2014 unsuccessfully \u2014 to settle the case as the trial dragged on. The whole case seemed \u201cout of proportion in a rather grotesque way\u201d, says Barend Mons, a molecular biologist at the Leiden University Medical Center in the Netherlands who is involved with the European Open Science Cloud, a data-sharing initiative. \n             'Preliminary results' \n           G\u00f3mez has always refused to reveal the name of the person suing him \u2014 saying that he does not want to put pressure on his accuser. But it is widely known that the thesis was authored by Andr\u00e9s Rymel Acosta Galvis, a biodiversity researcher, who in 2011 reported to the Colombian authorities that his work was being shared without his permission. The results in the thesis would have been valid only after peer review and needed further treatment, says Acosta, and he didn\u2019t want the preliminary results to be published. He adds that he has since produced four peer-reviewed publications from the work.Acosta says that he did not ask G\u00f3mez directly to remove the thesis because he was afraid of contacting an unknown person in Columbia for security reasons. G\u00f3mez says that he attempted to settle the situation with him first through lawyers in late 2013, and then through an apology letter that he sent directly to Acosta in the summer of 2014. But Acosta says that the story became public before he received G\u00f3mez\u2019s letter, and that he had received death threats by telephone and on social media. That, he says, spurred him to pursue the case to defend his rights. \n             Legal language \n           With G\u00f3mez cleared of the charge, \u201cfinally justice has been done\u201d, says Michael Carroll, who directs the Program on Information Justice and Intellectual Property at the American University in Washington DC. \u201cThis should have never been treated as a criminal matter. It\u2019s still evidence of a broken system when a situation like this has been treated as a criminal case and has gone on so long,\u201d he says. Carolina Botero, a lawyer at the Karisma Foundation, thinks the problem lies with the lack of clarity of Colombia\u2019s copyright law. Lawmakers have failed to make clear, she says, that commercial profit has to be involved to turn a breach of copyright case into a criminal matter. The key to the not-guilty verdict, says Botero, was the judge\u2019s finding that it was not proven that G\u00f3mez shared the thesis for economic gain, or with an intention to damage its original author. G\u00f3mez, who is 29 years old, is now based in Costa Rica, but is still affiliated with the University of Quind\u00edo and with the Colombian non-profit conservation organization ProCAT. \u201cThis is a very important precedent at the national level. It's a precedent for the fact that sharing for academic purposes, without making profit out of it, is a common practice,\u201d he says. \n                   Science publishers try new tack to combat unauthorized paper sharing 2017-May-10 \n                 \n                   Europe proposes copyright reform to help scientists mine research papers 2016-Sep-15 \n                 \n                   Nature blogpost: Student may be jailed for posting scientist\u2019s thesis on web \n                 Reprints and Permissions"},
{"file_id": "545397a", "url": "https://www.nature.com/articles/545397a", "year": 2017, "authors": [{"name": "Gabriel Popkin"}], "parsed_as_year": "2006_or_before", "body": "Firms seek to develop sophisticated instruments to compete with government offerings. Never have so many private eyes looked down at Earth. In the past decade, about a dozen companies have formed to launch Earth-observing satellites. Few have sought to compete with sophisticated government-built instruments, but that is changing. Private firms have begun to develop satellite radar systems and other advanced technologies in a bid to court scientists and other users, even as the US government is threatening to pare back its stable of satellites. Later this year, for example, the Finnish firm Iceye plans to launch a prototype radar instrument\u00a0\u2014 the first step, the company says, towards a constellation of 20\u00a0such probes. Until recently, commercial firms had shied away from pursuing radar satellites because they require heavy instruments and consume a lot of power. For some scientists,  the growing variety of commercial data  is enabling previously impossible research projects. But others fear that increasing reliance on private satellite observations could short-change science over time, by making data more costly or creating other barriers to access. \u201cIf you go the commercial way, you\u2019re going to shrink the user base and you\u2019re going to shrink the amount of knowledge you gain from it,\u201d says Matthew Hansen, a geo\u00adgrapher at the University of Mary\u00adland in College Park who uses some private data. Remote-sensing companies typically sell their data to the government and to businesses such as private weather forecasters and agri\u00adcultural firms. They have tended to focus on collecting data in just a few wavelength bands, to provide sharper and more frequent images than government spacecraft can. But various trends \u2014 the falling costs of components, the development of small satellites such as CubeSats and improved engineering and manufacturing processes \u2014 have allowed firms to pursue more-complex technologies. Several firms are looking to develop satellites equipped with radar, which can gather data at night and through cloud cover\u00a0\u2014 situations in which instruments relying on visible light falter. Iceye\u2019s planned constellation of probes should be able to image a given location many times a day, whereas existing radar-equipped satellites, such as the European Space Agency\u2019s Sentinel-1, return to a given spot only every few days. Other companies with radar projects in development include XpressSAR of Arlington, Virginia, and Urthecast of Vancouver, Canada. Some firms are beginning to explore hyperspectral imaging, which spans a wide range of wavelengths, allowing the detection of specific chemicals. In 2016, Satellogic of Buenos Aires launched two 35-kilogram satellites equipped with custom-designed cameras and light filters. Last month, the company became the first commercial supplier of hyperspectral data. Satellogic\u2019s goal is to fly about 300 satellites, together capable of imaging any location on Earth. And it has already begun to appeal to scientists. The company announced in January that it would give researchers free access to its 30-metre-resolution hyperspectral data. These span optical and near-infrared wavelengths and can help track water pollution and oil spills, and monitor the health of forests and crops. \u201cWe are receiving contacts from scientists all over the world,\u201d says Satellogic chief executive Emiliano Kargieman. But most commercial data must be purchased, and some scientists say the cost can limit their usefulness. Unless companies commit to making data archives available to all who need such information, they will freeze out many cash-strapped junior researchers and people in developing countries, Hansen says. And commercial data simply aren\u2019t good enough for many types of study, despite the technical advances. No commercial satellite matches the consistency and stability of the data collected by the US government\u2019s Landsat probes, which have monitored Earth since 1972. Government-funded missions also remain unparalleled in enabling scientists to push frontiers in basic research that may not have immediate applications, says Lorraine Remer, an atmospheric scientist at the University of Maryland in Baltimore. Remer is deputy project scientist for NASA\u2019s planned PACE satellite, and says that she does not know of any instrument aboard a commercial satellite that could produce hyperspectral data to rival those possible with the NASA mission. PACE\u2019s ocean-colour imager will enable researchers to identify specific types of aerosol particle in the air, and plankton types in the ocean. And governments typically provide the raw data that are used to create images, not just the images themselves, adds Andreas K\u00e4\u00e4b, a geoscientist at the University of Oslo who uses satellite data to study glacier movement. With commercial providers, \u201conce you ask for raw data, you quickly run into problems\u201d, he says. But commercial data may become more enticing if government support for Earth monitoring recedes. In the United States, President Donald Trump has  proposed axing three NASA missions  in 2018\u00a0\u2014\u00a0including PACE\u00a0\u2014\u00a0and scaling back a fourth. \u201cWe\u2019re looking at an unpredictable future for Earth-science funding in the US,\u201d Kargieman says. \u201cIf we have a capability among the private sector to step in and provide the data that will allow scientists to continue to do research, I think we should do so.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     US science agencies face deep cuts in Trump budget 2017-Mar-16 \n                   \n                     Race to provide commercial weather data heats up 2017-Feb-01 \n                   \n                     Mini satellites prove their scientific power 2014-Apr-16 \n                   \n                     Many eyes on Earth 2014-Jan-08 \n                   \n                     Microsatellites aim to fill weather-data gap 2012-Nov-28 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21963", "url": "https://www.nature.com/articles/nature.2017.21963", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "The Centers for Disease Control and Prevention stands to lose 12% of its budget through proposed cuts in the American Health Care Act. As Republican politicians in Congress push to repeal the health-insurance reforms enacted by former President Barack Obama, public-health advocates are worried about the fate of a US$900-million fund that supports preventive medicine and research programmes. The health-care overhaul legislation approved by the House of Representatives on 4 May, known as the \u201cAmerican Health Care Act\u201d, would terminate the Prevention and Public Health Fund by the end of 2018. That would save the government $ 119 billion between 2017 and 2026, the Congressional Budget Office said on 24 May. But it would eliminate a steady source of support for initiatives that have been shown to reduce deaths and chronic illness \u2014 including vaccination programmes, programmes to prevent diabetes and other chronic diseases and laboratories used in detecting and responding to infectious-disease outbreaks, lead contamination and other hazards. \u201cThese cuts will result in more people dying and higher health-care costs,\u201d says Tom Frieden, the former director of the US Centers for Disease Control and Prevention (CDC). And those effects could be magnified by any increase in the number of Americans without health insurance, says John Auerbach, president of the Trust for America\u2019s Health, an advocacy group in Washington DC. The Congressional Budget Office analysis concludes that 14 million people in the United States would lose health coverage under the House bill. In 2026, an estimated 23 million more people would be uninsured than would be under the country's current health care law. \n             Penny-wise, pound-foolish \n           The Obama health-care law created the preventive-care fund in 2010 to bolster the CDC\u2019s efforts to improve public health. But the agency\u2019s budget has decreased since then, so it has leaned more on the special fund to sustain and create public-health programmes. If the fund, which now accounts for 12% of the CDC\u2019s annual budget, is eliminated, the agency would struggle to support some of this work, says Frieden. Excluding the fund, the agency\u2019s budget has dropped by nearly $500 million since 2010, to $6.3 billion in 2017. Trump's proposed budget plan for 2018, released 23 May, would slash the CDC's overall budget by 17%, dropping it down to levels not seen since 2004. In 2016, for example, the preventive-care fund spent $324 million on programmes to educate healthcare providers and the public about vaccines, and to vaccinate children without health insurance. Axing this effort could be costly. The 16 measles outbreaks that struck the United States in 2011 cost up to $5.3 million to contain, according to a study published in  Vaccine  in 2014 1 . That figure does not include hospital bills for those infected. The fund also spent $52 million last year to strengthen states\u2019 capacity to monitor, prevent and respond rapidly to outbreaks of food-borne illness, influenza, hospital-acquired infections and other infectious diseases. The CDC estimates that containing such episodes cost the United States more than $120 billion every year. Since 2015, the agency has handled more than 750 of them. \u201cNo one talks about the loss of prevention funds,\u201d says Lawrence Gostin, a health-law and policy specialist at Georgetown University in Washington DC. \u201cThey talk about everything else, but the truth is that this is what keeps Americans safe, and losing funds for prevention is penny-wise and pound-foolish.\u201d The fate of the preventive-care fund now rests with the Senate, which is expected to write its own health-insurance reform bill later this year. But there are signs that the chamber might also take aim at the fund, which leading Republican senators involved in healthcare discussions have criticized as wasteful. Last year, for example, Senator John Cornyn of Texas complained at a Senate hearing that the fund had supported programmes to neuter pets and to encourage urban gardening and cycling.  \n                   Information on the Prevention and Public Health Fund from advocacy group, Trust for America's Health \n                 \n                   Information on the Prevention and Public Health Fund from the CDC \n                 \n                   Congressional Budget Office report on the American Health Care Act of 2017 \n                 Reprints and Permissions"},
{"file_id": "545396a", "url": "https://www.nature.com/articles/545396a", "year": 2017, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Dwindling infection rate makes reliable data hard to gather. Studies of thousands of pregnant women that were set up to probe the link between Zika and birth defects may not provide definitive answers because of a sharp drop in the number of new cases, researchers have warned. The unexpected development is making the disease harder to study, and threatens to hamper trials of experimental vaccines that might protect pregnant women in future outbreaks. \u201cWe\u2019re seeing few, if any, cases, particularly in southern Brazil, which we thought might be the next big area to be hit this year,\u201d says Oliver Brady, an epidemiologist at the London School of Hygiene and Tropical Medicine. Seventy countries have reported mosquito-borne Zika virus transmission since 2015, with the most intense epidemics sweeping South America and the Caribbean. Phylogenetic research suggests that the virus first entered Brazil in late 2013 or early 2014 (see  http://dx.doi.org/10.1038/nature22495 ), although it was not detected until mid-2015. The virus has been linked with a range of birth defects, including microcephaly, in the fetuses and newborns of women infected during pregnancy\u00a0\u2014\u00a0a pattern of abnormalities known as congenital Zika syndrome. But reliable data on the absolute risks are lacking, and gathering such information is one of the objectives of the affected studies. The two largest studies each intend to recruit 10,000 or more pregnant women. The Zika in Infants and Pregnancy (ZIP) study was launched last June by the US National Institutes of Health (NIH) and the Funda\u00e7\u00e3o Oswaldo Cruz-Fiocruz (Fiocruz), a national scientific agency in Brazil, and has so far recruited almost 3,000 women. The other study is just beginning to recruit. It is being carried out by the ZIKAlliance, a multidisciplinary consortium of 53 research centres that launched in December with \u20ac12 million ($13.5\u00a0million) from the European Union. Both trials are taking place across multiple sites in South America and the Caribbean. But with the drop in new cases (see \u2018Decline and fall\u2019), the ZIKAlliance is now reconsidering its plan. \u201cWe are going to be pragmatic, we are going to try, but if there are not enough infected cases, then there is little point,\u201d says the consortium\u2019s scientific coordinator Xavier de Lamballerie, a virologist at Aix-Marseille University and French national biomedical agency INSERM. The ZIKAlliance intends to capture what cases it can at its sites, and is considering focusing resources in sites where Zika has been rarer, such as Bolivia, where future flare-ups might be more likely. \u201cWe will track cases there where they are,\u201d he says, \u201cIt\u2019s a race against the clock.\u201d The ZIP study is similarly faced with low numbers of Zika cases, says Anthony Fauci, director of the NIH\u2019s National Institute of Allergy and Infectious Diseases (NIAID). \u201cThat\u2019s good for the population \u2014 if making it more difficult to get reasonable data for the study,\u201d he says. The low level of cases will also affect field trials of experimental vaccines, he adds. One such trial, the NIH VRC\u00a0705 phase\u00a0II trial, began in March and aims to enrol at least 2,490\u00a0volunteers in 7 countries in the Americas. But Fauci says that capturing enough data in an outbreak, where numbers of cases fluctuate from place to place and over time, and, at times, dry up altogether, is always an issue. \u201cThat\u2019s just a risk you accept,\u201d he says. \u201cSometimes a study that you think would take two years, winds up taking four or five years. But ultimately we hope that we can get some meaningful data.\u201d Epidemiologists say that they are unsure why the number of cases of the mosquito-borne disease has declined so steeply, and whether it will spike again in some region in South America or elsewhere. Often, the disease causes no symptoms, so most cases go undetected; it\u2019s possible that the rapid spread of the disease in the Americas has meant it has burnt itself out because enough people have become immune to the virus. Large-scale trials inevitably take time to organize. But delays incurred in obtaining ethical and other approvals in the trials\u2019 host countries have slowed the process further, as have a lack of clear rules for matters such as the shipping and ownership of samples. It\u2019s unlikely that Zika infection will disappear completely, however, says Fauci. \u201cOne doesn\u2019t know what is going to happen with the Zika situation and whether or not there will be flare-ups in one country more than another,\u201d he says. Spreading trial sites across different countries helps, he notes. \u201cWe try to build into the system enough flexibility, where you can assign slots depending on where the outbreak activity is.\u201d Researchers are still hopeful that despite lower than expected disease activity, the trials could produce useful results. Learning from other disease outbreaks such as Ebola, the main research agencies and groups involved in combating Zika last year agreed on common methodologies and designs for the latest studies. This means that the raw data from ZIP and the ZIKAlliance\u2019s study, as well as from other cohort studies, can be pooled to increase the sample size. \u201cIt\u2019s the first time that we have achieved such a degree of harmonization of research protocols at an international level,\u201d de Lamballerie says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @DeclanButlerNat \n               \n                     Brazil asks whether Zika acts alone to cause birth defects 2016-Jul-25 \n                   \n                     Zika raises profile of more common birth-defect virus 2016-Jul-05 \n                   \n                     Zika and birth defects: what we know and what we don\u2019t 2016-Mar-21 \n                   \n                     Zika virus: Brazil's surge in small-headed babies questioned by report 2016-Jan-28 \n                   \n                     ZIKAlliance \n                   \n                     Zika in Infants and Pregnancy (ZIP) study \n                   \n                     WHO Zika virus research agenda and protocols \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22027", "url": "https://www.nature.com/articles/nature.2017.22027", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "A deep ammonia plume and a powerful magnetic field are among the many surprises uncovered by the Juno mission. The sharpest look yet at Jupiter has revealed a number of surprises \u2014 including a surge of ammonia welling up from its gassy depths, a startlingly powerful magnetic field and what could be a large, but poorly defined, core. NASA\u2019s Juno mission began to capture these insights on 27 August last year, during the first of a series of close swoops past the planet. Preliminary results appeared on 25 May in  Science  and  Geophysical Research Letters . As  the first spacecraft to explore Jupiter in more than a decade , Juno \u201cis revolutionizing how we thought giant planets work\u201d, says Scott Bolton, a planetary scientist at the Southwest Research Institute in San Antonio, Texas, and the mission\u2019s principal investigator. \n             Into the clouds \n           Juno, which launched in 2011, has gathered stunning images of oval-shaped cyclones clustered around the giant planet\u2019s north and south poles. But it also probes beneath the cloud tops, using a microwave-emitting instrument that can see through the swirling storms and into the planet\u2019s heart 1 . Planetary scientists expected Jupiter\u2019s gases to be well mixed down to hundreds of kilometres beneath the cloudtops, but Juno revealed a patchy interior. The spacecraft found surprisingly low levels of ammonia in most places \u2014 but identified an ammonia-rich plume rising from the depths at Jupiter\u2019s equator. \u201cThat, frankly, has got a lot of people scratching their heads,\u201d says Leigh Fletcher, a planetary scientist at the University of Leicester, UK. Ammonia on Jupiter might be distributed similarly to water vapour on Earth, with higher humidity along the equator and lower levels at higher latitudes, says Cheng Li, a planetary scientist at NASA\u2019s Jet Propulsion Laboratory in Pasadena, California, who led one of the studies 2 . Similarly, Juno\u2019s magnetometer detected a powerful but patchy magnetic field \u2014 both stronger and more variable than models have suggested 3 . The magnetic flux is stronger near the equator, possibly because material inside the planet churns and distorts the magnetic field \u2014 similar to how sunspots are created, says Kimberly Moore, a planetary scientist at Harvard University in Cambridge, Massachusetts, and lead author of one of the papers 4 . \n             Thrown for a loop \n           Jupiter\u2019s magnetic field is also more complex than expected in the regions where it streams outward from the planet. \u201cRather than having one big wire carrying all the current, you\u2019ve got multiple little wires all spread out,\u201d says Fran Bagenal, a planetary scientist at the University of Colorado Boulder. This scattered pattern means that the structure and origin of Jupiter\u2019s northern and southern lights are more complicated than previously thought, because the electrically charged particles that produce them are flowing along a variety of paths. Other measurements from Juno hint that Jupiter has a surprisingly large core made of heavy elements. Each time Juno whizzes past the planet \u2014 just a few thousand kilometres above the cloudtops \u2014 Jupiter\u2019s gravitational tug nudges the spacecraft\u2019s orbit. Team scientists have analysed that nudge and calculated that the planet has a core that amounts to some 7\u201325 times the mass of the Earth 5 . The core could be both larger and more diffuse than expected, extending out to as much as half of Jupiter\u2019s 70,000-kilometre radius. Juno is taking longer to complete its mission than originally planned, because of  a glitch with two engine valves that has kept it looping around Jupiter every 53 days  rather than tightening its orbit down to 14 days. The spacecraft has completed 5 of 32 planned science fly-bys, and the next one will occur on 11 July, over the planet\u2019s Great Red Spot. \n                   Jupiter mission's computer glitch delays data-gathering 2016-Oct-20 \n                 \n                   Juno becomes first spacecraft to visit Jupiter in 21 years 2016-Jul-05 \n                 \n                   NASA\u2019s Juno spacecraft prepares to probe Jupiter\u2019s mysteries 2016-Jun-28 \n                 \n                   NASA's Juno site \n                 \n                   Southwest Research Institute's Juno site \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21976", "url": "https://www.nature.com/articles/nature.2017.21976", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Tom Insel will help to launch a company to analyse behaviour and mental illness using smartphone data. Eighteen months after leaving the US National Institute of Mental Health (NIMH) for Google\u2019s health-sciences division, psychiatrist Tom Insel is on the move again. The former NIMH director, who left Google on 5 May, is starting his own company. Insel\u2019s group, called Mindstrong, will try to infer a person\u2019s mental-health status by analysing how they use smartphones. Insel  stepped down as NIMH director in November 2015 , to start a mental-health programme within Verily,  Google\u2019s life-sciences group . One of the division\u2019s goals overlaps with that of Mindstrong: Verily intends to build tools, possibly including smartphone apps or computer programs, that can recognize characteristics of mental illness using a method known as digital phenotyping. The method analyses factors such as a user\u2019s word choice in communication, voice patterns when talking to digital assistants, physical movements and location data to determine their state of mind. If a smartphone could recognize when its owner was feeling suicidal, for instance, it could intervene by providing resources or alerting others. Insel says that Mindstrong, which is based in Palo Alto, California, takes a similar approach to gathering mental-health data. The company\u2019s other founders include Richard Klausner, a former director of the US National Cancer Institute, and Paul Dagum, who holds patents on at least three digital phenotyping methods. They assess cognitive function \u2014 which could be impaired in disorders such as Alzheimer\u2019s disease \u2014 from features such as misspellings and the length of time between keystrokes, according to the Mindstrong website. \n             A different direction \n           Insel says that a handful of companies, including Verily, are pursuing digital phenotyping. \u201cI love the idea of rethinking how we measure human behaviour and coming up with entirely new behavioural features\u201d of diseases including schizophrenia and depression, he says. New approaches to mental illness are especially important, because \u201cwe\u2019re not doing very well either on the diagnostic or therapeutic side\u201d. Verily has not yet launched any mental-health products, but Insel says that it has developed the initial parts of their program. \u201cI felt like Verily was at a point where it was big enough and successful enough I could walk away,\u201d he says. \u201cI knew in moving to Verily it would be a transitional job until I could figure out what I really wanted to do, and I\u2019ve had an entrepreneurial itch.\u201d Insel denies that his departure was due to any conflict with the company, which has lost several high-profile scientists in recent months, and says Verily is interested in collaborating with him in the future. In an 8 May blogpost announcing Insel\u2019s departure, Verily said that its mental-health efforts will continue in his absence. The company declined to comment on whether it plans to work with Mindstrong or whether Insel\u2019s position will be refilled. Insel says that Verily\u2019s mental-health effort will now be run by Danielle Schlosser, a clinical psychologist who Insel hired in August 2016. Schlosser, who remains affiliated with the University of California, San Francisco, has developed smartphone apps that try to increase motivation in people who lack it because of conditions including schizophrenia and depression. \n                   US mental-health chief: psychiatry must get serious about mathematics 2016-Oct-26 \n                 \n                   Why biomedical superstars are signing on with Google 2015-Oct-21 \n                 \n                   Director of US mental-health institute leaves for Google 2015-Sep-15 \n                 \n                   Psychiatry framework seeks to reform diagnostic doctrine 2013-May-10 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21962", "url": "https://www.nature.com/articles/nature.2017.21962", "year": 2017, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "New study informs a long-standing debate about how predators shape ecosystems. Dingoes can wreak havoc on Australia\u2019s sheep population, so the canines have been fenced off from a large section of the country. But new research suggests that excluding dingoes can lead to a population boom in their preferred prey: kangaroos. And this may, in turn, change the plant composition of the landscape. The finding is the latest addition in a long and contentious dispute about the ecological effects of dingoes on Australia\u2019s ecosystems. That debate is itself part of a wider discussion on  \u2018trophic cascades\u2019  \u2014 the idea that  top predators change the behaviour and numbers of herbivores , which then affect the vegetation and even the soil chemistry of a habitat. The latest research, published on 10 May in  Proceedings of the Royal Society B 1 , doesn\u2019t resolve the debate, but it does bring a more rigorous approach to a field criticized for relying on \u201cweak inference\u201d instead of controlled experiments 2 .\u00a0 The study was made possible by Australia\u2019s dingo-proof fence, one of the world\u2019s longest and most remote fences. It was built decades ago to keep the predators away from livestock. But the presence of the fence has also resulted in an inadvertent experiment, because \u201ctwo completely different ecological universes\u201d have emerged, according to ecologist Michael Letnic at the University of New South Wales in Sydney. Either side of the fence, there are obvious differences in the numbers of kangaroos, and in the kinds and amounts of plants. There is more grass on the dingo side, and more woody vegetation, such as trees and shrubs, on the kangaroo side. \n             Spotlighting the issue \n           To gauge how the dingoes are affecting the environment, Letnic and his colleague Timothy Morris, who conducted the work while at the University of New South Wales, estimated kangaroo and dingo numbers on either side of the fence. They did this by conducting night-time surveys of animal numbers using spotlights. The team also established 16 plots, each 11 metres square, with 8 on either side of the fence, and half of these being closed off to kangaroos, to probe how the herbivores affect the vegetation. On the dingo side of the fence, researchers spotted 85 of the canids and 8 kangaroos. On the kangaroo side, the team found a single dingo and more than 3,200 kangaroos. The plots on the dingo side of the fence showed no real differences in vegetation. But on the other side of the fence, the kangaroo-exclusion areas had about 12% more vegetation cover, implying that high numbers of the herbivores reduce the plant cover in a landscape. Fenced-off plots on the kangaroo side of the fence also had more soil carbon, phosphorus and nitrogen, suggesting that intense grazing outside the plots was changing the soil chemistry of the area. Letnic thinks that the kangaroos tend to move nutrients away from the grasslands \u2014 the animals rest under trees during the day, and so nutrients are deposited in wooded parts of the area when the kangaroos defecate. \n             Ongoing debate \n           Ben Allen, a wildlife ecologist at the University of Southern Queensland in Toowoomba, is the lead author of a review published in March that questions the rigour of research on trophic cascades 2 . And despite the fact that Morris and Letnic have a control component in the kangaroo-proof enclosures \u2014 unlike many trophic-cascade studies \u2014 Allen doesn\u2019t find the new work convincing. He says that some of the methods used, such as the spotlight counts, are too crude to provide accurate numbers. And he feels that alternative hypotheses, for example the presence of sheep in the area and differing water availability, haven\u2019t been adequately considered as explanations for the landscape-scale vegetation differences. Ultimately, the 12% difference in vegetation cover seems too small to affect the structure of the whole ecosystem, Allen says. Dingoes will certainly suppress kangaroo numbers, he adds. \u201cBut I don\u2019t agree that this is the driver of the whole system.\u201d Ecologists Matt Kauffman at the University of Wyoming in Laramie and Oswald Schmitz at Yale University in New Haven, Connecticut, agree that some researchers in the trophic-cascade field have become overenthusiastic. But both think that the new dingo work provides a clear signal that there\u2019s a link between the canines and the broader ecosystem. \u201cThis is the kind of experimental evidence that Allen and his group are calling for,\u201d says Schmitz. And they applaud the use of the kangaroo-exclusion plots. \u201cThat\u2019s one of the strengths of this study \u2014 that it is experimental,\u201d says Kauffman. \u201cWe are desperately trying to understand what it means when we lose large carnivores, and what it might mean in places where we restore them or they are re-establishing.\u201d \n                   An elegant chaos 2014-Mar-11 \n                 \n                   Rethinking predators: Legend of the wolf 2014-Mar-07 \n                 \n                   Iconic island study on its last legs 2014-Feb-11 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21961", "url": "https://www.nature.com/articles/nature.2017.21961", "year": 2017, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Homo naledi  fossils are dated to a few hundred thousand years ago, and may have overlapped with  Homo sapiens . An early human species with a curious mix of archaic and modern features lived in South Africa just a few hundred thousand years ago, researchers have found. Dubbed  Homo naledi , the species had a small, fist-sized brain similar to that of ancient hominin species that lived millions of years earlier. But it may also have overlapped with ancestors of  Homo sapiens , and, its discoverers contend, might even have made tools. H. naledi  was  uncovered in the Rising Star cave system in South Africa in 2013 , where a team led by palaeoanthropologist Lee Berger, at the University of Witwatersrand in Johannesburg, found a huge trove of ancient human bones and teeth. Now, Berger and his colleagues say that they have dated those remains to between 335,000 and 236,000 years ago, and that they have since discovered more of the species\u2019 skeletons. Their findings are detailed in three papers published in  eLife 1 , 2 , 3  on 9 May. The date is \u201castonishingly young for a species that still displays primitive characteristics found in fossils about 2 million years old\u201d, says Chris Stringer, an anthropologist at the Natural History Museum in London.The brain of  H. naledi  came close in size to that of very early members of the  Homo  genus, and of ancient australopiths \u2014 and was only slightly larger than that of a chimpanzee. Its curved fingers and its shoulder, trunk and hip joints also seem ancient, Stringer says. \u201cYet the wrist, hands, legs and feet look more like those of Neanderthals and modern humans, and the teeth are relatively small and simple, and set in lightly built jawbones.\u201d \n             Late to date \n           When Berger and his colleagues first announced  H. naledi , in September 2015, they had not yet dated its remains. Now, the team says that it has nailed down a date range using six methods \u2014 including comparing ratios of radioactive isotopes of uranium and thorium, and a technique called electron-spin resonance that measures changes over time in the energy states of electrons in crystals of tooth enamel. The approach looks \u201cvery good\u201d and the different methods are consistent, says Jean-Jacques Bahain, a specialist in fossil dating at the Department of Prehistory at the National Museum of Natural History in Paris. Although  H. naledi\u2019s  morphology looks old, the context in which the fossils were found and the extent of their fossilization shows that they are relatively young, says Fred Spoor, an evolutionary anatomist at University College London. After the discovery of  a 'hobbit' species called Homo floresiensis  in Indonesia  \u2014 a hominid with ancient-looking features that could be as young as 50,000 years old \u2014 it is less of a shock that \u201csomething [looks] so old at a young age\u201d, he says. Despite the young date for the  H.   naledi  fossils, in evolutionary terms, their morphological features suggest that they could still lie close to the origin of the genus  Homo , says Stringer \u2014 a date that\u2019s thought to be  as far back as 2.8 million years ago . \n             A mix of ancient and modern \n           According to Berger, the find also suggests that  H. naledi  was likely to have shared cognitive traits with modern humans, such as making and using tools; its modern-like hands were capable of manipulating tools, he says. Although no stone tools were found alongside  H. naledi , Berger contends that similarly aged tools from southern Africa could have been made by the species \u2014 and not early  Homo sapiens , as most archaeologists had assumed. \u201cArchaeologists will have to provide extraordinary evidence to show that they know who the maker of any other tools [in southern Africa] is. They have to prove it is not  Homo naledi ,\u201d he said. Stringer is more cautious. \u201cIt is certainly probable that H.  naledi \u2019s handiwork is out there,\u201d he says. \u201cBut until H.  naledi  fossils are found with associated tools, we won\u2019t know. I don\u2019t think we should rewrite the archaeological record of southern Africa yet.\u201d Berger has also suggested that the Rising Star cave discovery represents the oldest known deliberate body disposal \u2014 or burial \u2014 in human history. The new discovery of a second chamber in the cave system with more  H. naledi  remains makes that more likely, he says. But Stringer is doubtful. \u201cAlthough no other satisfactory explanation for the deposition of the remains has yet been proposed, many experts, including myself, consider such complex behaviour [burial of the dead] unlikely for a creature with a brain size close to that of a gorilla, particularly when a requirement for the controlled use of fire (for lighting) probably has to be added in,\u201d he says. The find shows there\u2019s much to discover in Africa, which remains largely unexplored, Stringer says. At around 300,000 years ago, there were probably at least three kinds of humans across the continent, including early  Homo sapiens , and  H.   naledi , he says. \u201cWho knows what else might be out there?\u201d \n                   Crowdsourcing digs up an early human species 2015-Sep-10 \n                 \n                   New species of early human discovered near fossil of \u2018Lucy\u2019 2015-May-27 \n                 \n                   Ethiopian jawbone may mark dawn of humankind 2015-Mar-04 \n                 \n                   Fossils raise questions about human ancestry 2011-Sep-08 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21950", "url": "https://www.nature.com/articles/nature.2017.21950", "year": 2017, "authors": [{"name": "Barbara Casassus "}], "parsed_as_year": "2006_or_before", "body": "Proposal to create integrated research university near Paris stymied by elite institutions\u2019 fears of losing autonomy. French ambitions to create a \u20ac5-billion (US$5.5-billion) science \u2018super-campus\u2019 near Paris by 2020 seem to be falling further apart, after a compromise scheme to save the troubled project was rejected by one of its creators. In 2010, the country\u2019s then-president Nicolas Sarkozy unveiled plans to make the cluster of private and public research labs in Saclay, 30 kilometres south-west of the capital,  into a large integrated research university  that by 2020 would shine in international rankings and would rival institutions such as the Massachusetts Institute of Technology. But the project, which encompasses 18 universities, research agencies and elite higher-education institutes called  grandes \u00e9coles , has attracted criticism for its apparent lack of strategy and governance. A 2016 Senate report said that the determination of institutions \u2014\u00a0in particular by the historic  grandes \u00e9coles \u2014  to maintain their own identities had destroyed the collective project. And in February,  a report  by France\u2019s government auditor declared that  plans were \u201cat a standstill\u201d . In an effort to move forwards, a small group of institutions has proposed an alternative structure for the cluster that bears little resemblance to the original vision; it would be a kind of half-way house between the existing loose cluster of institutions and a fully integrated university. At a meeting on 26 April, the heads of seven institutions presented the plan \u2014 finalized after 11 meetings and months of wrangling  \u2014  to the organizations in the cluster. The idea would be to create a \u2018hard core\u2019 integrated group to strengthen links in research and teaching between the establishments. Other members could have associate status until they decide to join (or not). \n             A different vision \n           Under the proposal, any universities at Saclay \u2014 including the large University Paris-Sud, which has a strong reputation for science \u2014 would give up their names and be absorbed into the University of Paris-Saclay, the umbrella research and teaching institution created for the project. The  grandes \u00e9coles  could keep their names and independent legal status for at least five years. But, in a sudden reversal, one of the institutions involved in the plan's creation refused to endorse the new structure. CentraleSup\u00e9lec, a  grande   \u00e9cole  and the larger of the two engineering schools in the group of seven, rejected the proposal shortly before the meeting \u2014 largely because it does not want to lose autonomy. \u201cIt was a bit surprising since the discussions had gone very smoothly until then,\u201d says Gilles Bloch, president of the University Paris-Saclay. But, he concedes, \u201cAll seven engineering schools at Saclay are reticent about institutional integration at the moment.\u201d Louis Schweitzer, head of the government\u2019s general commissariat for investments thinks that trying to launch the project with 18 establishments was over-ambitious \u2014 but he is optimistic that at least some of the schools will join in time. \u201cSome could even make the jump in the next year or two,\u201d he says. \u201cOnce the university achieves international recognition for its teaching and scientific excellence, it will become more attractive to the schools.\u201d But senator Michel Berson, who compiled the 2016 report, still takes a dim view of the integration project. In an  interview with French newspaper  Le Figaro , he said that the project was \u201ca deeply regrettable waste\u201d because the campus is already home to \u201cwhat is done best in France, or even Europe, in scientific research and cooperation\u201d. \n             Lone ranger? \n           The University of Paris-Sud seems prepared to forge its own path forward. In a  letter  to students and staff the day after the meeting, university president Sylvie Retailleau noted the reluctance of CentraleSup\u00e9lec and the other engineering schools, and suggested that Paris-Sud could become the sole \u2018founding\u2019 member of the Paris-Sacaly project. The university is already responsible for more than half of all research undertaken at Saclay, said Retailleau. Paris-Sud\u2019s enthusiasm might just help to keep the Paris-Saclay dream alive: its plan comes at a crucial time in terms of funding for the project. For the past five years, the cluster has received an annual \u20ac33 million in stimulus research grants from a state-funded \u2018excellence initiative\u2019 called IDEX that aims to reward the best research campuses in France. But in April last year, the initiative\u2019s international jury marked down the Paris-Saclay project for its vague structure and human-resources policy, and gave it 18 months to sort out its difficulties \u2014 or lose its funding. The cluster must go back to the jury in December to prove that it is still a deserving case. \u201cThe plan responds to the jury\u2019s concerns and the university is already highly rated on all scores, so I see no reason why the jury would withdraw the label when it announces its decision next March,\u201d says Schweitzer, whose department runs the excellence initiative. \u201cI believe their chances for keeping the label are very high, even if Paris-Sud is alone at the beginning.\u201d \n                   French auditors criticize \u20ac5-billion science super-campus near Paris 2017-Feb-08 \n                 \n                   Paris plans science in the suburbs 2010-Oct-20 \n                 Reprints and Permissions"},
{"file_id": "545144a", "url": "https://www.nature.com/articles/545144a", "year": 2017, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "By converting a defunct communications dish, astronomers are breaking ground on Earth and beyond. In a milestone for African astronomy, engineers have converted an old telecommunications dish in Ghana into the continent\u2019s first functioning radio telescope outside South Africa. The telescope, in Kuntunse near Accra, is the first of an array of such instruments expected to be built across Africa over the next five years, and forms part of long-term plans to develop the skills of astronomers on the continent. It made its first observations this year and will be formally opened later in 2017. \u201cIt\u2019s a moment of pride and joy that we have reached this far,\u201d says project manager T.\u00a0L.\u00a0Venkatasubramani (known as VenKAT). He says that science operations should begin next year. Once up and running, the Ghana telescope could be incorporated into the European Very Long Baseline Interferometry (VLBI) Network\u00a0\u2014 a cluster of far-apart radio telescopes that together act as one large instrument. But astronomers also want to use it in a separate African VLBI Network (AVN). For that, plans are under way to convert telecommunications dishes in Zambia, Madagascar and Kenya by mid-2019. The arrival of undersea cables around Africa\u2019s coast in the past decade has rendered these dishes obsolete for their original purpose. New telescopes could also be built in four other African nations by mid-2022. The AVN will develop the capacity for astronomy in countries that have never had a radio telescope, says Huib Jan van Langevelde, director of the Joint Institute for VLBI in Europe, based in Dwingeloo, the Netherlands, who has been involved in training and testing for the African network. But it will also contribute useful science, he notes. The Ghana telescope has begun observing methanol masers \u2014 radio emissions that can arise from a number of celestial phenomena \u2014 and pulsars. The AVN will fill in geographic gaps in the global VLBI, improving imaging by increasing the range of distances and possible angles between the telescopes in the network. The more telescopes there are in a VLBI network, the more detail astronomers can see. \u201cIf you look at the current VLBI network, we definitely do need antennas filling up the centre of Africa,\u201d says James Chibueze, a VLBI scientist and AVN operator who works with SKA South Africa in Cape Town, which is building part of the world\u2019s largest radio telescope, the Square Kilometre Array. Tony Beasley, director of the US National Radio Astronomy Observatory in Charlottesville, Virginia, says the AVN is a \u201cfantastic\u201d initiative for the Southern Hemisphere, where the VLBI at present shares use of an array in Australia. \u201cThe AVN would be a full-time array, would do a lot more science and is going to increase by an order of magnitude the amount of VLBI time available, and the southern skies thing is unique. We have lots of arrays in the Northern Hemisphere,\u201d he says. The AVN would also benefit from the technical advances made for the SKA and South Africa\u2019s radio-astronomy ambitions, says Beasley. \n               Tricky conversion \n             The AVN was the brain child of Michael Gaylard, a former director of South Africa\u2019s Hartebeeshoek Radio Astronomy Observatory who died in 2014. During two years of repairs to the observatory\u2019s telescope, Gaylard used Google Maps to scour the continent for old telecommunications dishes. When he saw the Kuntunse dish, he realized that it\u00a0\u2014\u00a0and others like it\u00a0\u2014\u00a0could be converted for astronomy. The switch has been difficult, says Chibueze. New telescopes are designed and built to set specifications, but during work on the Kuntunse dish, engineers and scientists have had to adapt their plans. And there have been issues with the stability of electrical power and Internet supply. The conversion has been in large part funded by South Africa, whose African Renaissance and International Co-Operation Fund and department of science and technology have contributed 122\u00a0million rand (US$9 million) to the project. From South Africa\u2019s point of view, the AVN would help to prepare the continent for the SKA: many hundreds of dishes, and even more antennas, are set to be built in Australia and South Africa. By the late 2020s, the SKA project also plans to construct other stations\u00a0\u2014\u00a0separate from the AVN\u00a0\u2014\u00a0in eight other African nations. Later this year, the AVN project and South Africa\u2019s SKA project office will be amalgamated into the South African Radio Astronomy Observatory, a unit of the National Research Foundation. The plan, however, is that Ghana and other African nations will ultimately own and operate their AVN telescopes. South Africa hasn\u2019t said whether it will fund further conversions. VenKAT says that it needs cost-sharing commitments from other African nations. \u201cWe must ensure the governance set-up is in place before we go in for the engineering,\u201d he says. \u201cIt\u2019s not just a South African do-and-deliver, but a joint programme.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Giant SKA telescope rattles South African community 2016-Jun-22 \n                   \n                     Telescope array could usher in astronomy revolution in Africa 2014-Jan-24 \n                   \n                     Astronomy in South Africa: The long shot 2011-Dec-14 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21949", "url": "https://www.nature.com/articles/nature.2017.21949", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Scientists are split over whether limiting grant support to individuals will help young researchers or hurt collaboration. A decision by the US National Institutes of Health (NIH) to  limit its grant support for individual researchers  has sparked concerns that the policy could discourage collaboration or divert funding from the best science. The move has alarmed some researchers who agree with the NIH\u2019s stated aim of freeing up money for  young scientists, who often struggle to obtain research grants . \u201cThis seems like tax reform to me: everybody agrees something needs to be done, but with any given scheme there's going to be winners and losers,\u201d says Jonathan Karn, an HIV researcher at Case Western University in Cleveland, Ohio. \u201cEveryone will feel that a threshold is great \u2014 as long as it\u2019s \u2018just above where I am\u2019.\u201d Under the policy, announced on 2 May, the NIH will assign a point value to each grant based on its complexity and size. Researchers will be limited to 21 points of funding at any one time \u2014 which NIH director Francis Collins says is the equivalent of three R01 grants, the type commonly given to individual projects. To win an additional grant, researchers with 21 points will need to adjust their existing load to stay under the limit. The NIH says that the plan will help to ease the increasingly stiff competition for its grants by freeing up about 1,600 additional awards each year. In 2016, the agency received 30,106 applications for R01 grants but handed out only 6,010. And the average age at which scientists win their first major NIH award is now 42,  up from 38 in 1980 . Fans of the new grant limit include Jungsu Kim, a neuroscientist at the Mayo Clinic College of Medicine in Jacksonville, Florida. He has applied for NIH grants many times since finishing his PhD ten years ago, but did not win any until late 2016 \u2014 when he scooped up four. That's enough to put Kim over the new 21-point threshold. Despite his good fortune, Kim still favours the cap, citing the numerous studies that demonstrate that beyond a certain point, more funding does not increase a scientist\u2019s productivity \u2014 and may even lower it. \u201cWe shouldn\u2019t respond [to the NIH plan] out of our personal feeling,\u201d he says. \u201cBased on such data, it is a good idea to limit funding.\u201d \n               Partner penalty? \n             Big questions remain, however, about how the agency will implement the grant limit, which it estimates will affect  just 6% of the researchers  it funds. Many of those scientists, and others who hope to one day join that elite club, say they want to ensure that the NIH does not create a one-size-fits-all system. Joanne Flynn, a microbiologist at the University of Pittsburgh, Pennsylvania, is worried that the policy will inadvertently discourage the sorts of collaboration that have aided her research on tuberculosis. When the NIH\u2019s extramural-research chief, Mike Lauer, unveiled an early version of the point system in January, he said that a scientist would receive seven points for each individual grant and six points for each collaborative grant. Flynn, who has five R01 grants, has developed a monkey model of tuberculosis that is one of only a few in the world. Because other labs lack the resources to manage animals carrying infectious diseases, researchers who want to study tuberculosis in monkeys tend to collaborate with Flynn\u2019s lab. \u201cWe work with a lot of people,\u201d she says. \u201cI don\u2019t have a single grant that is just me.\u201d Edward Fisher, a cardiologist at New York University who has seven R01 grants, shares Flynn\u2019s concern. When Fisher added two collaborators last year to one grant worth about US$372,000, he was left with only $170,000. \u201cIf that\u2019s going to count just as much [towards my point total], I might as well ditch my collaborators in the next round and go off on my own,\u201d he says. \n               Making it work \n             Lauer told  Nature  that the NIH is still deciding how to handle grants shared among multiple investigators, and how researchers with more than 21 points can lower their total. \u201cWe want the policy to be informed by discussions with stakeholders,\u201d he says. The NIH may institute the policy later this year, Lauer adds, but will phase it in without cancelling any existing grants. Jon Lorsch, director of the NIH\u2019s National Institute of General Medical Sciences (NIGMS), says that having clear guidelines for how many grants a researcher can receive will be helpful. Since 1998, the NIGMS has given extra scrutiny to applications from researchers with more than $750,000 total in grants, from the NIH and other sources. But Lorsch says that the institute's peer reviewers approve more of these applications than they deny. Similarly, in 2012 the NIH began to conduct special reviews of grant applications from labs with more than $1 million in agency support, but officials there have said that the policy has had little impact on what gets funded. \u201cOne has to be willing to have very difficult conversations with very famous scientists in order to enforce those kinds of guidelines,\u201d says Lorsch. \u201cHaving more concrete rules, as are being rolled out here, will make things much more transparent and enforceable.\u201d  \n                     NIH to limit the amount of grant money a scientist can receive 2017-May-03 \n                   \n                     Young, talented and fed-up: scientists tell their stories 2016-Oct-26 \n                   \n                     NIH plan to give ageing scientists cash draws scepticism 2015-Feb-11 \n                   \n                     Extra scrutiny for \u2018grandee grantees\u2019 2012-Feb-20 \n                   \n                     Mid-career crunch 2011-Mar-16 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21952", "url": "https://www.nature.com/articles/nature.2017.21952", "year": 2017, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "France's next president has vowed to ring-fence research budgets and boost innovation. French scientists say they\u2019re relieved and happy that their country\u2019s next president will be Emmanuel Macron, a 39-year-old former civil servant and economy minister who swept to victory in elections on 7 May. Macron intends to make cuts to public spending, but has said he will ring-fence the budgets for research and higher education, areas that he wants to make the central plank of a programme to boost innovation and cut unemployment. He has also pledged to invest in environmental and clean-energy measures. But his ability to implement these policies will depend heavily on the results of legislative elections in June. If he doesn't have enough support in France's parliament, the new president will find it hard to propose and pass new laws. For now, scientists who spoke to  Nature  say they are just pleased that Macron so decisively defeated his opponent Marine Le Pen, the leader of the nationalistic, far-right Front National party \u2014 gaining 66% of the vote to Le Pen\u2019s 34%. \"Macron\u2019s election comes as a huge relief to me; the alternative was just unimaginable,\" says Fr\u00e9d\u00e9ric Dardel, president of Paris Descartes University, one of the country's leading research universities. \"I am more than relieved, I am delighted to see that Emmanuel Macron has won the election by a wide margin,\" says Catherine Cesarsky, an astrophysicist at the CEA, France's atomic energy commission, near Paris. French research bodies rarely take overt positions on elections, but this one was different. France\u2019s academy of science, the heads of nine national research agencies and many prominent scientists had all made public appeals against Le Pen\u2019s party ahead of Sunday\u2019s head-to-head vote, arguing that the Front National\u2019s illiberal and anti-immigrant views threatened the tolerant, open and democratic environment in which science and evidence-based policy thrives. \"Unlike the Front National, Emmanuel Macron bears the republican and humanist values that we defend, and which constitute the DNA of universities,\" says Gilles Roussel, who heads France's Conference of University Presidents, which in April had called for a vote against Le Pen. Le Pen had also wanted to hold a referendum on whether France should remain in the European Union. By contrast, Macron and many French scientists are enthusiastic supporters of the EU. A Le Pen victory would have been a \"major disaster\" for European and international cooperation in science, says Dardel. \n             Young, thoughtful and \u2018open to discussion\u2019 \n           Researchers say they draw confidence from Macron\u2019s general outlook on science, innovation and the environment. He has said that he plans to invest money in training young people, on clean energy and environmental measures, and on modernizing agriculture, health care, transport and infrastructure. Research on these issues may receive extra funding, predicts Thierry Coulhon, a mathematician and president of the PSL Research University in Paris, who was also an adviser to the Macron campaign on research and higher education. Coulhon says that Macron aims to free up innovation in universities by decentralizing power and reducing bureaucracy; in particular, Macron intends to let universities hire lecturers and researchers without having to wait for a central administration in Paris to approve appointments. Coulhon expects that Macron\u2019s policies on France\u2019s national research agencies will be more about continuity, with less need for major reforms. Macron is familiar with the worlds of research and higher education, says Cesarsky, who is one of a group of scientists who before the election asked 11 presidential candidates about their plans for science. \"Macron's team appears genuinely open to discussion with the research community,\" says Dardel. \"We have a blank sheet in front of us, and if we can manage to get the right messages through, we could really move forward. There is a window of opportunity now, which the French scientific community should seize.\" \n             Majority needed \n           Although Macron will appoint a prime minister and government within days, he will need to win a majority in June\u2019s parliamentary elections to have a good chance of implementing his policies. Neither of the two major parties that have dominated French politics for decades had candidates in the final presidential run-off on 7 May. Macron heads a grassroots political movement called  En Marche\u00a0! , which he created only last year. The movement has no existing members of parliament, and voters who chose Macron to keep out Le Pen in the presidential race may support candidates from different parties in the parliamentary elections on 11 and 18 June. So Macron may end up with a coalition government, or become a 'lame-duck' president hobbled by a prime minister or government from another party. It\u2019s unclear whether the new parliament will recognize the importance of research and higher education, says Bernard Bigot, director-general of the multibillion-euro nuclear-fusion project ITER in St-Paul-lez-Durance, southern France. \"There's a large risk that other priorities will dominate,\" he says. Le Pen\u2019s defeat does not mean that the threat of the Front National has gone away, researchers caution. Her party may also make a strong showing in June\u2019s elections; the increasing influence of its ideas in French politics and society is also a concern. \"We remain worried because the ideas of the Front National continue to rise steadily and become more commonplace,\u201d says Roussel. But Macron's win provides hope, scientists say. \"With everything we have seen in the world recently, from the election of Trump, to Brexit and the rise of extremism in Europe, for the first time now we have a strong movement against,\" says \u00c9douard Br\u00e9zin, an emeritus theoretical physicist at the \u00c9cole Normale Sup\u00e9rieure in Paris and a former president of the CNRS, France's basic-research agency. \"I'm glad that this movement should come from France.\" \n                   French plan to create \u20ac5-billion science \u2018super-campus\u2019 in disarray 2017-May-05 \n                 \n                   French-election fears unite scientists in defence of liberal democracy 2017-Apr-18 \n                 \n                   French scientists focus on the big political picture 2017-Apr-18 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21978", "url": "https://www.nature.com/articles/nature.2017.21978", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "A difference in brain biology between the sexes might render males most vulnerable to autism. Cells that prune connections between neurons  in babies\u2019 brains as they grow are thought to have a role in autism spectrum disorder. Now, a study suggests that the number and behaviour of these cells \u2014 called microglia \u2014 vary in boys and girls, a finding that could help to explain why many more boys are diagnosed with autism and related disorders. Donna Werling, a neurogeneticist at the University of California, San Francisco, and her colleagues found that genes associated with microglia are more active in male brains than in female brains in the months before birth. \u201cThis suggests there is something fundamentally different about male and female brain development,\u201d she says. The research, to be presented on 13 May at the International Meeting for Autism Research in San Francisco, California, is still preliminary. Very little is known about how microglial trimming behaviour affects brain development. But the study by Werling\u2019s team \u201cis the kind of work that makes you say \u2018Wow, this is really interesting, and we should take it seriously\u2019\u201d, says Kevin Pelphrey, a neuroscientist at George Washington University in Washington DC. There are two to five times many males with autism as females. Although the disorder \u2014 whose cause remains elusive \u2014 is widely acknowledged to be underdiagnosed in girls, psychiatrists agree that there is a significant disparity between the numbers of male and female cases. It suggests that biological differences between the sexes are involved. Werling set out to find the biological reason why males have higher rates of autism than females. To do so, she and her colleagues examined how gene expression in brain tissue varied between men and women. Their initial prediction was that  genes previously linked to autism  would be expressed at higher levels in the men. But the team found no clear pattern of autism gene expression that separated men from women. However, genes that cause microglia to develop, or are turned on by the cells, were more active in the men 1 . In subsequent analyses, she and other researchers grouped the brain samples by age and found that the biggest difference in microglial gene expression between males and females occurs in the months before birth. Meanwhile, some of her colleagues were part of a group that reported last year in  Nature  that genes associated with microglia were expressed at higher levels in brain samples from people with autism than in people without the condition 2 . \n             Early days \n           Taken together, these results suggest to Werling that the higher activity of microglia in baby boys before birth makes them more sensitive to genes that have been associated with autism. Another possibility, she says, is that girls\u2019 less-active microglia may protect them from the effects of those genes. One way to think about this, she says, is to picture a Venn diagram in which one circle includes biological aspects of the brain that differ by sex, and the other includes aspects of the brain that differ between people with and without autism. \u201cWe think the biology that leads to a different risk of autism for males and females lives in that region of overlap,\u201d she says. Previous studies have also found signs that microglia could affect autism. In 2010, researchers reported in  Biological Psychiatry  that out of 13 brain samples from people with autism, 9 had microglial cells that were unusually large, dense or active, or stood out in other ways 3 . And in 2014, another team reported in  Nature Neuroscience  that mice that had low numbers of microglia early in life displayed behaviours reminiscent of autism, such as reluctance to interact with other mice 4 . Werling and her colleagues\u2019 most recent work fits with other studies that suggest that changes in the autistic brain are likely to occur before birth, says Simon Baron-Cohen, director of the Autism Research Centre in Cambridge, UK. Baron-Cohen, whose work has linked high levels of fetal testosterone to autism, suggests that future studies explore how testosterone and other sex hormones may operate through microglia to shape the developing brain. Even once the biological roots of autism are exposed, it could be years before scientists unravel how these translate into the varied symptoms of the disorder, such as delayed speech and a preoccupation with certain topics. Still, \u201cif we really understood what microglia were doing in the developing brain, we might be able to more fully understand how this particular cell type is involved in autism risk,\u201d Werling says, \u201cwith the end goal of developing therapeutics that target this specific slice of biology.\u201d \n                   Microbiology: Gut microbes augment neurodegeneration 2017-Apr-12 \n                 \n                   How to defeat dementia 2016-Nov-09 \n                 \n                   Autism study finds early intervention has lasting effects 2016-Oct-25 \n                 \n                   Monkeys genetically modified to show autism symptoms 2016-Jan-25 \n                 \n                   Microglia: The constant gardeners 2012-May-30 \n                 \n                   International Meeting for Autism Research \n                 \n                   Daniel Geschwind's neurogenetics program \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21966", "url": "https://www.nature.com/articles/nature.2017.21966", "year": 2017, "authors": [{"name": "Sarah McQuate"}], "parsed_as_year": "2006_or_before", "body": "Skeleton from South America enables palaeontologists to piece together the puzzle of baleen-whale evolution. The discovery of a whale fossil dating back to 36.4 million years ago has filled in a gaping hole in the evolution of baleen whales, a group that includes humpbacks ( Megaptera novaeangliae ) and blue whales ( Balaenoptera musculus ). The creature, named  Mystacodon selenensis , is the oldest baleen-whale relative yet found. The skeleton displays traits that place it firmly as the first baleen-whale relative known to emerge after an ancient group of whale ancestors called basilosaurids split into two: one branch led to the toothed whales, which include sperm whales ( Physeter macrocephalus ) and dolphins, and the other to baleen whales. Researchers reported their findings on 11 May in  Current Biology 1 . \u201cThis is the fossil that we\u2019ve been waiting for,\u201d says Nick Pyenson, a palaeontologist at the Smithsonian National Museum of Natural History in Washington DC. Whale fossils from this time period can answer a lot of questions that researchers have about the origins of living whale lineages, he says. They include the appearance of the earliest baleen whale ancestors. \n             Out to sea \n           The  first whales originated roughly 50 million years ago from land animals  that crawled into the sea, gradually trading in their legs for flippers. \u201cThere are so many changes from their terrestrial ancestors,\u201d says Olivier Lambert, a palaeontologist at the Museum of Natural Sciences in Brussels, and lead study author. \u201cIt\u2019s a nice example for evolution at work.\u201d Before now, the oldest known baleen-whale fossil was 34 million years old. But molecular and physical analyses indicated that whales were older than that. Then in 2010, Lambert and his team found and began excavating the  M. selenensis  skeleton from the Pisco Basin on Peru's southern coast. Scientists estimate that the ancient creature was roughly 4 metres long \u2014 about the size of a large bottlenose dolphin ( Tursiops truncatus ). To determine where  M. selenensis  fit in the whale family tree, the researchers compared characteristics such as the shape of its skull and pelvic bone to those of other fossil whales. The creature's flat snout resembles that of modern baleen whales. But its pelvic bone fit more with ancestral whales, complete with areas where the leg bones would typically slot in, says Lambert. \u201cSo, we think that this animal still had tiny legs protruding from the body.\u201d If you look at a basilosaurid, \u201cyou\u2019ll see little chicken legs back there\u201d, says Mark D. Uhen, a vertebrate palaeontologist at George Mason University in Fairfax, Virginia. Modern whales lack cavities for the hind limbs in their pelvic area. \n             Nice to eat you \n           M. selenensis  also had teeth, unlike modern baleen whales, which strain food out of seawater using keratin plates (called baleen) that hang from the roof of the mouth. Lambert and his colleagues think that  M. selenensis  might have sucked up its prey from the ocean floor. This wasn\u2019t unusual, however, because baleen-whale ancestors around that time sported a wide variety of dental and feeding mechanisms. \u201cThere\u2019s big toothed things, there\u2019s little toothed things and there\u2019s toothless things, all at once,\u201d says Uhen. But by around 23 million years ago, all the whales in this group had baleen, and \u201call these toothy things go away\u201d, he says. Researchers still don\u2019t know why baleen and filter-feeding won out over all other eating options in this particular lineage. But to answer that question, palaeontologists need to start taking a harder look at the specimens that they already have, says Pyenson. Finding more ancient whale fossils will help, too \u2014 so Lambert and his colleagues plan to head back to Peru to search for other individuals of this species. So far, most whale fossils have been found in the Northern Hemisphere. But with the emergence of  M. selenensis  and a variety of older fossils from the Southern Hemisphere,  researchers are turning their eyes to the south . \u201cWe thought we knew a lot about this time,\u201d says Pyenson. But \u201cwe really need to look in more detail at the Southern Hemisphere of this age if we want to learn more about this time in whale evolutionary history.\u201d \n                   Fossil of pregnant whale found 2009-Feb-03 \n                 \n                   The land-based ancestor of whales 2007-Dec-19 \n                 \n                   Chilean desert yields trove of whale fossils \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21931", "url": "https://www.nature.com/articles/nature.2017.21931", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Immune cells that encompass and invade tumours could dictate the success or failure of therapy. Detailed maps of the immune cells that surround tumours could suggest fresh therapeutic targets, point out biological markers that can be used to select the patients most likely to respond to a given therapy, and offer insights into the best time to start administering that treatment, according to two studies released on 4 May. The papers, published in  Cell 1 , 2 , reflect a growing appreciation by cancer researchers that a tumour\u2019s response to treatment is  often guided by the cells in its neighbourhood  \u2014  particularly the immune cells  that amass at its borders and invade its core.  The make-up of that population could determine the success of immunotherapy treatments, which unleash the immune system to fight cancer. And advances in the ability to  characterize those individual cells in unprecedented detail  are fuelling a push to catalogue them and learn more about how they dictate the progression of the disease. \u201cThese papers are really important,\u201d says Nick Haining, an immunologist and oncologist at the Dana\u2013Farber Cancer Institute in Boston, Massachusetts. \u201cThey put a flag in the ground, saying: here\u2019s the technology that makes it possible, and there\u2019s way more stuff here to learn than you would have thought.\u201d \n               It\u2019s complicated \n             One team, led by systems biologist Bernd Bodenmiller of the University of Zurich in Switzerland, mapped the immune response to a form of kidney cancer called clear cell renal cell carcinoma 2 . It focused on two kinds of immune cell, T cells and macrophages. Both can either mount or suppress an immune attack on a tumour, depending on the state that they are in and the proteins they express. Bodenmiller and his colleagues examined samples from 73 people with kidney cancer along with 5 samples of healthy tissue. They analysed 3.5 million cells for the expression of 29 proteins used to characterize macrophages, and 23 to characterize T cells. The results showed that populations of those T cells and macrophages are more varied than previously thought. The team also found that patients who had a particular combination of T cells and macrophages also tended to have fast-progressing cancers. The data show that the current practice of looking at only one or two proteins to infer the state of a T cell or macrophage misses important information, says Kai Wucherpfennig, an immunologist at the Dana\u2013Farber Cancer Institute. \u201cIt\u2019s very unlikely that a single marker is sufficient,\u201d he says. Another study, led by oncologist Miriam Merad of the Icahn School of Medicine at Mount Sinai in New York City, created an atlas of immune cells associated with early-stage lung cancer 1 . The team compared normal lung tissue and blood with tumour tissue, and found that the young tumours had already begun to alter the immune cells in their neighbourhood. This is a sign that cancer therapies that target the immune system need not be reserved for advanced stages of the disease, says Merad. \u201cIt suggests that already, we could act,\u201d she says. \u201cWe don\u2019t have to wait until the tumour has spread.\u201d \n               Just the beginning \n             Both studies are too small to change cancer treatment on their own. Ultimately, their importance is not in their immediate findings, but in the trend that they could unleash, says Haining. He likens them to the first papers to report the genome sequences of tumours \u2014 an effort that generated  large, international collaborations  and  thousands of sequences .  Wucherpfennig notes that Dana\u2013Farber, which already sequences its patients\u2019 tumour genomes, plans to start profiling the immune cells in their tumours as well. The analyses, set to begin in the coming months, will be much simpler than the detailed atlases reported today. But they will reflect growing respect for how an individual\u2019s immune response to a tumour affects their prognosis and should influence the treatment they receive, he says. Haining expects that attitude to spread over the next few years. \u201cWe need hundreds of patients across dozens of tumour types, profiled at the level of thousands of immune cells per sample,\u201d he says. \u201cThat\u2019s what we need in order to understand the biology in a way that simply counting heads of this type of immune cell or that type of immune cell didn\u2019t do.\u201d \n                     Hunt for cancer 'tipping point' heats up 2017-Apr-03 \n                   \n                     Promising cancer drugs may speed tumours in some patients 2017-Mar-31 \n                   \n                     The race to map the human body \u2014 one cell at a time 2017-Feb-20 \n                   \n                     Cocktails for cancer with a measure of immunotherapy 2016-Apr-13 \n                   \n                     Nature  Outlook: Cancer immunotherapy \n                   \n                     US National Cancer Institute: Cancer immunotherapy \n                   Reprints and Permissions"},
{"file_id": "545141a", "url": "https://www.nature.com/articles/545141a", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Algorithms help to produce precise maps of where people in developing countries live and work. Nigerian health officials won\u2019t have to rely on flawed, decade-old census data when they plan deliveries of the measles vaccine next year. Instead, they will have access to what may be the most detailed and up-to-date population map ever produced for a developing country. Created by the Bill & Melinda Gates Foundation in Seattle, Washington, and delivered to Nigerian officials on 1 May, the map is based on a detailed analysis of buildings in satellite imagery and more than 2,000 on-the-ground neighbourhood surveys. It is one of several projects that are leveraging remote-sensing data and modern computer-learning algorithms to chart human settlements around the globe with unprecedented precision. Researchers hope that these data will enable better management of public health, infrastructure and natural resources \u2014 and improve planning for emergencies. This is especially true in developing countries, where  census estimates are notoriously unreliable and outdated . \u201cIf you don\u2019t know how many people are where, you cannot have any kind of structured, organized plan for changing people\u2019s lives,\u201d says Budhendra Bhaduri, who heads the Urban Dynamics Institute at Oak Ridge National Laboratory in Tennessee and is a collaborator on the Gates Foundation project. Researchers have been laying the groundwork for these advanced maps for two decades. Oak Ridge began using satellite imagery in the late 1990s to improve population estimates; within a few years, it was creating daytime and night-time maps that showed where people in the United States lived and worked. But better algorithms and increased computing power have made it possible to apply this approach globally in the past several years. \u201cThe data was always there, but nobody was able to process it,\u201d says Martino Pesaresi, a remote-sensing expert at the European Commission\u2019s Joint Research Centre in Ispra, Italy. In 2014, Pesaresi\u2019s team used an automated system to map settlements across the world using images from US Landsat satellites. The group has since analysed selected imagery back to 1975, and is publishing annual updates with a resolution of 10 metres using optical and radar data from the European Sentinel satellites. Facebook has also joined the mapping push, after announcing plans in 2014 to expand Internet access worldwide using drones and satellites. The social-media giant purchased half-metre-resolution commercial satellite imagery of 30 countries, and developed an algorithm to identify human-built structures before partnering with Columbia University in New York City to overlay census data. Columbia has released population maps for eight of the countries and plans to finish the remainder within a few months. \u201cThe Facebook algorithm is finding exactly what they want to find, which is rural populations,\u201d says Greg Yetman, associate director for geospatial applications at Columbia\u2019s Center for International Earth Science Information Network. One advantage of this approach, he says, is that it doesn\u2019t require on-the-ground surveys like those conducted by the Gates Foundation. The Gates Foundation began its mapping project after encountering problems while distributing polio vaccines in Nigeria: millions of doses would be sent to areas where they weren\u2019t needed and would disappear, while other areas suffered shortages. The foundation teamed up with researchers at Oak Ridge and the University of Southampton, UK, in 2013 to produce the first high-resolution maps of Nigeria\u2019s northern states. The group completed those in 2015, and next month it group will make public its first country-wide map. The plot reveals villages that weren\u2019t included in Nigeria\u2019s most recent census, in 2006, and shows that many urban areas are more populated than the census data indicated, says Vince Seaman, an epidemiologist and interim deputy director of data and analytics for global develop-ment at the Gates Foundation. \u201cThis has the potential to change the whole game,\u201d he says. \u201cFor all of the  different vaccines in Nigeria , it could save US$1 billion in a space of a few years.\u201d What sets the foundation\u2019s project apart is how it places people on its map. Rather than relying on census data, Oak Ridge researchers used computer algorithms to identify different types of neighbourhood: neat street grids and large structures often indicate wealthier areas, whereas clusters of disorganized lines can be used to identify slums and informal settlements (see \u2018Picturing population\u2019). Researchers at the University of Southampton then used those data to design household-population surveys for each settlement type; the results of the surveys were used to calculate population densities. Seaman says it will cost between $1 million and $2 million per country to repeat this exercise elsewhere. The Gates Foundation is now working with the UK Department for International Development to expand its mapping project to Ethiopia and the Democratic Republic of the Congo. Seaman says that the goal moving forward must be to help developing countries collect census data referenced to geographic location to capture a true snapshot of their populations. Ethiopia is planning to do that later this year, with Nigeria following in 2018. Seaman hopes that the Gates Foundation mapping project will bolster those efforts. If it succeeds, he says, \u201cthat would make our stuff obsolete\u201d. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @jefftollef \n               \n                     What the numbers say about refugees 2017-Mar-01 \n                   \n                     Four steps to precision public health 2016-Dec-05 \n                   \n                     Polio eradication faces setback as Nigeria records first cases in two years 2016-Aug-12 \n                   \n                     Seven billion and counting 2011-Oct-19 \n                   \n                     WorldPop \n                   \n                     Oak Ridge National Laboratory \n                   \n                     Columbia University\u2019s Center for International Earth Science Information Network \n                   \n                     Bill and Melinda Gates Foundation \n                   \n                     Global Human Settlement Layer \n                   Reprints and Permissions"},
{"file_id": "545145a", "url": "https://www.nature.com/articles/545145a", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Rise in copyright breaches prompts industry to discuss ways to allow \u2018fair sharing\u2019 of articles. Ross Mounce knows that when he shares his research papers online, he may be doing something illegal\u00a0\u2014\u00a0if he uploads the final version of a paper that has appeared in a subscription-based journal. Publishers who own copyright on such papers frown on their unauthorized appearance online. Yet when Mounce has uploaded his paywalled articles to ResearchGate, a scholarly social network likened to Facebook for scientists, publishers haven\u2019t asked him to take them down. \u201cI\u2019m aware that I might be breaching copyright,\u201d says Mounce, an evolutionary biologist at the University of Cambridge, UK. \u201cBut I don\u2019t really care.\u201d Mounce isn\u2019t alone in his insouciance. The unauthorized sharing of copyrighted research papers is on the rise, say analysts who track the publishing industry. Faced with this problem, science publishers seem to be changing tack in their approach to researchers who breach copyright. Instead of demanding that scientists or network operators take their papers down, some publishers are clubbing together to create systems for legal sharing of articles\u00a0\u2014\u00a0called fair sharing\u00a0\u2014\u00a0which could also help them to track the extent to which scientists share paywalled articles online. Free article sharing is embedded in the way science works, says Mandy Hill, managing director of academic publishing at Cambridge University Press, UK. \u201cIt is important that, as publishers, we accept this and find ways to support fair sharing of content whilst ensuring the sustainability of the research publishing business,\u201d she says. But open-access advocates say that publishers\u2019 plans for fair sharing will not satisfy scientists who might object to \u2014 or be unaware of \u2014 copyright restrictions, and who increasingly expect to be able to make their papers available online for free. \n               Legal fatigue \n             The practice of uploading paywalled papers online seems to have ballooned in recent years\u00a0\u2014\u00a0in large part because of the popularity of sites such as ResearchGate, where millions of scientists share and view articles. Publishers are watching carefully. In April, a publisher-commissioned survey of more than 5,000\u00a0scientists by the research-impact service Kudos in Wheatley, UK, suggested that 57% had uploaded their own work to scholarly communication networks; 79% of those said they checked copyright policies before they did so, but 60% thought they should be allowed to upload their articles regardless of publisher or journal policies (see \u2018Copyright concerns\u2019). No-one knows the full extent to which researchers share paywalled papers online, but a study this February gave a hint. Information scientist Hamid Jamali at Charles Sturt University in Wagga Wagga, Australia, picked 500 papers at random from ResearchGate, and found that 392 were not open-access articles ( H.RJamaliScientometricshttp://dx.doi.org/10.1007/s11192-017-2291-4;2017 ). Some were versions that publishers allow authors to share, such as a peer-reviewed, unedited manuscript or a preprint. But more than 50% of the uploaded versions infringed publishers\u2019 copyright, Jamali found. A spokesperson for ResearchGate, which is based in Berlin, says that the company explicitly asks users to comply with publishers\u2019 policies when uploading papers, and to make sure they are not breaching copyright. But it says it has no way to monitor the extent to which users might upload unauthorized papers. Some scholarly publishers have reacted to the issue with litigation threats. In late 2013, for instance, science publisher Elsevier sent 3,000\u00a0notices under the US Digital Millennium Copyright Act to the scholarly network Academia.edu and other sites, demanding that they take down papers that breached Elsevier\u2019s copyright. The notices were also passed to individual scientists. Major infringements still prompt a legal reaction: Elsevier is currently suing Sci-Hub, a site that shares millions of paywalled research papers. Yet, when it comes to dealing with papers shared on social networks, some publishers are pulling back from litigation, says Matt McKay, a spokesperson for the International Association of Scientific, Technical and Medical Publishers (STM) in Oxford, UK. \u201cLegal action and take-down notices are no sustainable manner to remove unauthorized content from social research networks. Rather than relying on such blunt tools, we want to talk with these sites and find long-term solutions to the problem,\u201d he says. \n               Fair ways to share \n             In a 21 March teleconference organized by the STM, science publishers discussed efforts to let scientists share full texts of papers more easily without breaching copyright. (Springer Nature, which publishes  Nature , was one of the companies involved;  Nature \u2019s news team is editorially independent of its publisher.) Publishers contacted by  Nature \u2019s news team generally declined to discuss their evolving policies on article sharing in detail, but fair sharing typically means providing free links to the final versions of read-only, non-downloadable articles hosted on journal sites. Some publishers\u00a0\u2014\u00a0including Springer Nature and Wiley\u00a0\u2014\u00a0have adopted software that allows their authors to generate such links. An education drive in 2015 kicked off the fair-sharing discussion: the STM, following consultations with publishers and librarians, developed a website called \u2018How can I share it?\u2019 ( www.howcanishareit.com ) that details what different subscription journals allow in terms of archiving and sharing copyrighted articles online. (In general, many publishers permit the online sharing of peer-reviewed manuscripts, but not the final full text.) Scientists may not like publishers\u2019 systems for fair sharing, says Stevan Harnad, a web-science and cognition expert at the University of Southampton, UK, who encourages researchers to self-archive versions of articles online. \u201cSo publishers want to track what is happening? There is no reason they should retain such control,\u201d he says. In the long run, thinks Mounce, science will move to a system in which researchers can do what they want with their papers. \u201cOnly open access will cleanly and clearly solve the highly artificial \u2018problem\u2019 of not being allowed to share research with others,\u201d he says. But for the publishing industry, the question of how to enable sharing of paywalled articles without breaching copyright or alienating authors will only grow in significance, says Joseph Esposito, an independent publishing consultant in New York City who works with science publishers and scholarly societies. So far, he says, journal publishers don\u2019t seem to have lost much revenue because of scholarly networks. But publishers will have to adopt new strategies now to avoid \u201csubstantial losses\u201d in the near future, he says. Additional reporting by Richard Van Noorden. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @tomboy180463 \n               \n                     Initiative aims to break science\u2019s citation paywall 2017-Apr-06 \n                   \n                     \u2018You never said my peer review was confidential\u2019 \u2014 scientist challenges publisher 2017-Jan-23 \n                   \n                     Nature promotes read-only sharing by subscribers 2014-Dec-02 \n                   \n                     Online collaboration: Scientists and the social network 2014-Aug-13 \n                   \n                     Open access: The true cost of science publishing 2013-Mar-27 \n                   \n                     http://www.nature.com/news/specials/scipublishing/index.html \n                   \n                     STM consultation on article sharing \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21986", "url": "https://www.nature.com/articles/nature.2017.21986", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Legislation urges educators to \u2018teach the controversy\u2019 and allows citizens to challenge curricula. State and local legislatures in the United States are experimenting with new ways to target the topics taught in science classes, and it seems to be paying dividends. Florida\u2019s legislature approved a bill on 5 May that would enable residents to challenge what educators teach students. And two other states have already approved non-binding legislation this year urging teachers to embrace \u2018academic freedom\u2019 and present the full spectrum of views on evolution and climate change. This would give educators license to treat evolution and intelligent design as equally valid theories, or to present climate change as scientifically contentious. \u201cThe strategies of creationists have gotten more sophisticated,\u201d says Glenn Branch, deputy director of the  National Center for Science Education (NCSE) in Oakland, California. The first academic freedom bills popped up in the early 2000s, but until this year only three had become law: one in Mississippi in 2006, one in Louisiana in 2008 and another in Tennessee in 2012.Eleven bills designed to alter science-education standards have been proposed this year across the United States. A handful of those measures have either abandoned the traditional academic freedom model for more roundabout methods, or are using watered-down versions of it. \n             Back-door approach \n           The Florida legislation, for example, does not try to change state or district education standards. Instead, it enables any tax-paying resident of a given county to file complaints about the curriculum of the schools in their district. A complaint would trigger a public hearing to determine if the material in question is \u201caccurate, balanced, noninflammatory, current, free of pornography \u2026 and suited to students\u2019 needs\u201d, according to the legislation. \u201cBut who decides what \u2018balanced\u2019 and \u2018noninflammatory\u2019 mean?\u201d asks Joan Bertin, executive director of the National Coalition Against Censorship, based in New York City. Currently, instructional materials come from an approved list provided by the state, she says. State Representative Byron Donalds (Republican, Florida District 80), who sponsored the bill, does not think that it is anti-science. Instead, he says, it gives parents the power to hold school districts accountable for what their children are learning. \u201cOne of the key things about this bill, and why I think it passed, is that we didn\u2019t target any one subject matter.\u201d But to Branch, it seems clear what sorts of issues might come up. \u201cThe people pushing the bill have been complaining about evolution and climate change,\u201d he says. \u201cIt\u2019s obvious that a strong motivation is getting that out of the textbooks.\u201d Many groups, including the NCSE, Florida teachers\u2019 organizations and local school boards, have called for Governor Rick Scott to veto the bill; without his approval, it will not become law. But science advocates say that a veto doesn\u2019t seem likely given Scott\u2019s known beliefs \u2014 such as his scepticism about climate change. Branch worries that the success of the Florida bill could open the door to measures in other states that adopt the same back-door approach to altering science education by means of broader academic censorship. \n             Missing information \n           Already this year, Indiana and Alabama have both passed non-binding legislation urging teachers to embrace academic freedom. Although they don\u2019t require educators to \u2018 teach the controversy \u2019 and treat topics including evolution and climate change as scientifically contentious, Branch says that the legislation encourages teachers to \u201cmis-educate\u201d students. Other states, including Oklahoma and South Dakota, also introduced academic-freedom bills this year. Oklahoma\u2019s passed in the Senate, but was never voted on in the House, and could be revived next year. South Dakota\u2019s passed in the Senate, but was defeated in the House. Both bills were closer to becoming law than similar state legislation has been in years past. Idaho\u2019s House and Senate education committees temporarily altered the state\u2019s science standards in February to remove mentions of human impacts on the environment \u2014 including climate change. Those standards could be made permanent in 2018 if the full legislature passes a final review bill. Branch says it\u2019s unlikely that more legislation altering state science education standards will be introduced in 2017. Most state-level bills are introduced by late spring. And he\u2019s not sure why these bills now seem more likely to pass. It could be due to renewed anti-evolution and anti-climate change sentiment; confidence that a country led by US president Donald Trump \u2014 who has expressed doubts about climate change \u2014 is more hospitable to such views; or an increase in climate-change denial. Alternatively, the phenomenon could be a statistical anomaly that will vanish by next year. Regardless of the reason, all is not lost, says Branch. \u201cIt cuts both ways, I think. The opponents of science education may feel newly invigorated \u2014 but so do its defenders.\u201d \n                   Help to fight the battle for Earth in US schools 2015-Mar-10 \n                 \n                   Evolution makes the grade 2013-Jul-03 \n                 \n                   Tennessee \u2018monkey bill\u2019 becomes law 2012-Apr-11 \n                 \n                   Evolution advocate turns to climate 2012-Jan-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21989", "url": "https://www.nature.com/articles/nature.2017.21989", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "The Democratic Republic of the Congo has reported nine suspected cases of infection in recent weeks. An outbreak of the Ebola virus has emerged in the Democratic Republic of the Congo (DRC), the World Health Organization (WHO) said on 12 May. Congolese authorities have reported nine suspected cases of Ebola infection in the past three weeks; the WHO has confirmed one, and tests are pending on others. Now health officials are considering whether to deploy an experimental Ebola vaccine against the outbreak, for the first time since the WHO gave it preliminary approval in April. The aid group M\u00e9decins Sans Fronti\u00e8res (MSF, also known as Doctors Without Borders) is discussing a potential vaccination campaign with the Congolese government, an MSF spokesperson says. That would require the approval of the WHO, which has not decided whether to call on the approved experimental vaccine or others in development, says WHO spokesperson Tarik Ja\u0161arevi\u0107. Still, he says, \u201cwe are taking this [outbreak] seriously because Ebola is always serious\u201d. The  most recent outbreak of the virus, in West Africa from 2014 to 2016 , killed 11,325 people; there have been several known outbreaks in the DRC, but none has been as severe as the West African one. There are now 12 candidate Ebola vaccines in development. None is yet approved for sale, in part because the candidates were not ready for testing until the West African Ebola crisis was on the wane. But on 27 April, the WHO\u2019s advisory group on immunization recommended that an experimental vaccine called rVSV-SEBOV be deployed promptly should an Ebola outbreak arise. Developed by the Public Health Agency of Canada and licensed by the drug companies NewLink Genetics of Ames, Iowa, and Merck of Kenilworth, New Jersey,  rVSV-ZEBOV showed promise in a study published in  The Lancet  last December 1 . The trial included 11,841 people in Guinea in 2015, near the end of the Ebola outbreak there. None of the 5,837 people who received the vaccine had developed the disease ten days after vaccination. But there were 23 cases among the thousands of other people included in the trial. \n             A look ahead \n           The deployment of rVSV-ZEBOV may be warranted in the DRC, because the vaccine is based on the Zaire strain of Ebola \u2014 the same strain that is driving the current outbreak, says Anthony Fauci, director of the US National Institute of Allergy and Infectious Diseases. If public-health authorities decide to proceed, there is a supply of rVSV-ZEBPV at the ready: Gavi, the Vaccine Alliance,  signed an agreement with Merck in 2016 to purchase 300,000 doses of vaccine  for use in future outbreaks. Historically, outbreaks in the DRC have never approached the unprecedented severity of the West Africa epidemic. The most recent Ebola outbreak in the DRC occurred in the Bas-Uele province \u2014 the site of the current episode \u2014 and killed 49 people over 3 months. The gap in severity is due in part to the DRC\u2019s infrastructure and geography. Whereas people, and the viruses they carry, travel fluidly between Guinea, Sierra Leone and Liberia, rough roads impede movement in many parts of the DRC. This means that outbreaks there kill people, but fizzle out without spreading very far. The DRC also benefits from Ebola expertise that its doctors and researchers have built up over the years. Jean-Jacques Muyembe-Tamfum, director-general of the National Institute for Biomedical Research in Kinshasa, is well known among Ebola experts for curbing the DRC\u2019s first outbreak, in 1976, and many thereafter. He works to engage affected communities immediately, to build their trust in medical teams and to help them understand the importance of not touching others in checking the spread of the virus. Muyembe-Tamfum \u201cis probably out there already\u201d, says David Heymann, an infectious-disease epidemiologist at the London School of Hygiene and Tropical Medicine. He recalls how Muyembe-Tamfum \u2014 who could not be reached for comment \u2014 helped to contain past outbreaks by telling village chiefs that Ebola was an evil spirit, which passes to people when they touch the infected. \u201cMuyembe talks with people in a way that they will understand quickly,\u201d Heymann says. \u201cHe does whatever he believes is effective, and it is.\u201d \n                   Unusual deal ensures Ebola vaccine supply 2016-Jan-20 \n                 \n                   How to beat the next Ebola 2015-Aug-05 \n                 \n                   Trial and triumph 2015-Aug-05 \n                 \n                   How Ebola-vaccine success could reshape clinical-trial policy 2015-Aug-04 \n                 \n                   Successful Ebola vaccine provides 100% protection in trial 2015-Jul-31 \n                 \n                   Nature  special: Ebola epidemic in West Africa \n                 \n                   World Health Organization statement on Ebola in the Democratic Republic of the Congo \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21919", "url": "https://www.nature.com/articles/nature.2017.21919", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Snap general election triggers compromises in legislation overhauling how Britain\u2019s science is funded. A controversial and wide-ranging shake-up of the United Kingdom\u2019s research and higher-education landscape has been completed, amid a huge rush by the country\u2019s parliament to push through legislation. The urgency comes courtesy of a \u2018snap\u2019 general election announced this month by UK Prime Minister Theresa May, which will trigger an early dissolution of Parliament. The reforms were passed on 27 April with a number of concessions made by the government in a bid to push through the bill, which might otherwise have died as a result of the early shutdown. The legislation, which set out sweeping changes to the way in which research is funded and how universities are governed, elicited huge debate among scientists and university leaders when it was proposed in May 2016. For scientists, the headline change, which is now law, is the merging of the various UK research-funding bodies into a new  centralized agency called UK Research and Innovation, or UKRI . The agency will be responsible for distributing Britain\u2019s \u00a36-billion (US$7.8-billion) research budget when it comes into being in 2018. Senior researchers had  publicly clashed  over the proposals \u2014 and the  creation of UKRI in particular . Some said that the changes would strengthen UK science at a time when it is threatened by  Britain\u2019s looming exit from the European Union . Others called the reform at best unnecessary and at worst  a threat to researchers\u2019 autonomy . In February, the government made  concessions on a number of issues that had been worrying scientists . It added safeguards for institutional autonomy and, unusually, wrote into the legislation a long-held principle in UK science funding called the Haldane principle, which states that decisions on research funding should be protected from political interference. \n             Further concessions \n           The government\u2019s original legislation, proposed in the country\u2019s lower chamber, the House of Commons, was heavily scrutinized and amended by the upper chamber, the House of Lords, where a number of members are senior university figures. The bill\u2019s passing means that both houses have now agreed on the legislation \u2014 but the rush prompted a series of new compromises from the government. Among the biggest of the latest concessions is the promise of a review of the new Teaching Excellence Framework, which will assess the quality of university instruction \u2014 an initiative proposed by the government but questioned by the Lords. The review will scrutinize the metrics used in the framework and whether it is affecting the ability of university staff to do research. Julia Goodfellow, the president of umbrella group Universities UK, said in a statement that the bill would provide \u201cstability during a time of uncertainty\u201d. The latest compromises address many concerns relating to the original bill, she notes. \u201cIn particular, we\u2019re pleased with changes which protect university independence and standards.\u201d \n                   UK scientists welcome changes to controversial research reforms 2017-Feb-28 \n                 \n                   Leading scientists clash over sweeping UK research reforms 2016-Oct-13 \n                 \n                   Oppose the UK Higher Education and Research Bill 2016-Oct-04 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21988", "url": "https://www.nature.com/articles/nature.2017.21988", "year": 2017, "authors": [{"name": "Hannah Hoag"}], "parsed_as_year": "2006_or_before", "body": "Binding pact aims to ease access to field sites and shipment of samples across national borders. Fairbanks, Alaska Researchers working in the Arctic will face less red tape, under an  agreement  signed by representatives of the eight Arctic nations at a meeting in Fairbanks, Alaska, on 11 May. The legally binding document should help to ease rules that can hinder data collection and obstruct the transport of analytical equipment, data and samples across national borders. The pact is also designed to give scientists better access to government science facilities \u2014  including ice-breaking ships  \u2014 and to terrestrial,  coastal , atmospheric and  marine areas  for field research. \u201cIt will break through the bureaucratic logjams that one finds when trying to work in the Arctic,\u201d says Evan Bloom, director of the US State Department\u2019s office of ocean and polar affairs. He is also the co-chair of the Arctic Council task force that drew up the agreement, which was signed by Canada, Denmark, Finland, Iceland, Norway, Sweden, Russia and the United States. Scientists working in the far north often need to clear several layers of approval, dealing with review by national, regional and local authorities. \u201cThere are visas, permits for equipment, permits for taking your ship into other nations\u2019 waters, and so on,\u201d says Jan-Gunnar Winther, director of the Norwegian Polar Institute in Troms\u00f8. \u201cIf there are many permissions that need to be handled by different authorities, it takes that much longer \u2014 sometimes too long.\u201d Doing research in Russia can be particularly challenging, some scientists told  Nature . They described struggles to import equipment to the country, including satellite phones and instruments that tap into the Global Positioning System, and times when they had to leave samples and data behind. \u201cIt\u2019s heartbreaking to have permits and bureaucracy block progress,\u201d says Cheryl Rosa, deputy director of the US Arctic Research Commission, a biologist and veterinary surgeon who studies marine-mammal health. Rosa worked with hunters in Chukotka, Russia, in 2011, to study toxins in grey whales ( Eschrichtius robustus ), but has been unable to take her samples back to the United States for analysis. \u201cI still have many samples sitting in a freezer there,\u201d she says. The agreement could ease such impasses, but only if participating countries follow through on their commitments, says Winther. \u201cIf this is going to be helpful for scientists,\u201d he says, \u201cit does of course have to be implemented.\u201d \n                   Huge Arctic report ups estimates of sea-level rise 2017-Apr-28 \n                 \n                   Arctic 2.0: What happens after all the ice goes? 2017-Feb-08 \n                 \n                   What\u2019s killing the world\u2019s shorebirds? 2017-Jan-04 \n                 \n                   Incredibly thin Arctic sea ice shocks researchers 2016-Dec-14 \n                 \n                   Arctic river flood plains are home to hidden carbon 2016-Sep-26 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21990", "url": "https://www.nature.com/articles/nature.2017.21990", "year": 2017, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "Objects unearthed at Native American burial site are remnants of an ancient space rock. Washington DC Blackened and irregular, the prehistoric beads found in a centuries-old Illinois grave don\u2019t look like anything special. But the latest analysis 1  shows that they were fashioned from an exotic material: the shards of a meteorite that fell to Earth more than 700 kilometres from where the beads were found. The link between the Anoka meteorite, which landed in central Minnesota, and the Illinois beads confirms that \u201c2,000 years ago, goods and ideas were moved hundreds of miles across eastern North America\u201d, says Timothy McCoy, co-author of the analysis and curator-in-charge of meteorites at the National Museum of Natural History in Washington DC. The beads were made by people of the Hopewell culture, which flourished in the US Midwest from 100  bc  to 400  ad  \u2014 spreading from its epicentre in Ohio to as far as Mississippi. The culture is known for  sprawling ceremonial earthworks  and for objects made of non-local materials such as mica. The iron beads were discovered in 1945 in a Hopewell grave near Havana, Illinois, alongside more than 1,000 shell and pearl beads. Together, they indicate that the grave\u2019s occupant was of high rank, says archaeologist Bret Ruby of the Hopewell Culture National Historical Park in Chillicothe, Ohio, who was not involved with the analysis. \u201cYou\u2019ve got to open a lot of clams to find 1,000 pearl beads.\u201d Scientists have known for decades that the grave\u2019s 22 iron-nickel beads came from a meteorite, but they didn\u2019t know which one. Earlier research 2 , 3  had ruled out the Anoka, an iron-nickel meteorite found in 1961 during the digging of a cesspool near Anoka, Minnesota. \n             Meteorite match \n           Then a second chunk of the Anoka space rock was unearthed in 1983, and McCoy\u2019s museum bought it. When they examined it under the microscope, McCoy and his colleagues could see that the meteorite contained micrometre-sized granules of iron enriched with nickel, just as the beads do. Analysis by mass spectroscopy and other techniques showed the beads\u2019 chemical composition is a near-perfect match for the Anoka meteorite, the team reports in the  Journal of Archaeological Science 1 . The team also noticed that the Anoka meteorite is shot through with bands of a brittle mineral called schreibersite. Hopewell artisans could have broken up the lump of iron-nickel along the bands, McCoy says. He made his own bead by repeatedly heating a chunk of the Anoka in a wood fire to some 600 \u00baC, hammering it flat with a stone and then hammering the sheet into a cylindrical bead. Making the beads \u201cprobably took quite a while\u201d, he says. \u201cYou wonder how many failed experiments there were.\u201d The study makes a strong case for the connection between the Anoka meteorite and the beads, says Diane Johnson of the Open University in Milton Keynes, UK, who has studied Egyptian  meteoritic artefacts  and is not part of McCoy\u2019s team. She notes that the Hopewell techniques are similar to those of  the ancient Egyptians, who manufactured almost identically designed tube-shaped beads  some 3,000 years earlier. The analysis is useful because it draws a path from one spot in the Hopewell world to another, says archaeologist Brad Lepper of the Ohio History Connection in Columbus, a non-profit historical and research group. \u201cThe more dots on the map we can identify, the clearer the sense of the networks of interaction,\u201d he says. Lepper and Ruby agree that the Havana Hopewell people probably didn\u2019t engage in anything as mundane as trade to get their chunk of extraterrestrial object. It may have been a gift to cement an alliance, or an offering from religious pilgrims. Perhaps a shaman on a quest found it and transported it, by foot or boat, to Havana. Whatever its path, Ruby says, \u201cit does point to complexity in their society that we tend not to attribute to people living 2,000 years ago\u201d in the Americas. \n                   Rock samples suggest meteor caused Tunguska blast 2013-Jun-10 \n                 \n                   Iron in Egyptian relics came from space 2013-May-29 \n                 \n                   The quasicrystal from outer space 2012-Jan-03 \n                 \n                   Mammoth tusks show up meteorite shower 2007-Dec-12 \n                 \n                   Buddhist \u2018Iron Man\u2019 found by Nazis is from space \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21886", "url": "https://www.nature.com/articles/nature.2017.21886", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Broken mastodon bones hint that  Homo sapiens  wasn\u2019t the first hominin to get to the New World. Ancient humans settled in North America around 130,000 years ago, suggests a controversial study \u2014 pushing the date back more than 100,000 years earlier than most scientists accept. The jaw-dropping claim, made in  Nature 1 , is based on broken rocks and mastodon bones found in California that a team of researchers say point to human activity. Their contention, if correct, would force a dramatic rethink of when and how the Americas were first settled \u2014 and who by. Most scientists subscribe to the view that  Homo sapiens  arrived in  North America less than 20,000 years ago . The latest study raises the possibility that another hominin species, such as  Neanderthals  or a group known as  Denisovans , somehow made it from Asia to North America before that and flourished. \u201cIt\u2019s such an amazing find and \u2014 if it\u2019s genuine \u2014 it\u2019s a game-changer. It really does shift the ground completely,\u201d says John McNabb, a Palaeolithic archaeologist at the University of Southampton, UK. \u201cI suspect there will be a lot of reaction to the paper, and most of it is not going to be acceptance.\u201d The study focuses on ancient animal-bone fragments found in 1992 during road repairs in suburban San Diego. The find halted construction, and palaeontologist Tom Dem\u00e9r\u00e9 of the San Diego Natural History Museum led a five-month excavation. His crew uncovered teeth, tusks and bones of an extinct relative of elephants called a  mastodon  ( Mammut americanum ), alongside large broken and worn rocks. The material was buried in fine silt left by flowing water, but\u00a0Dem\u00e9r\u00e9 felt the rocks were too large to have been carried by the stream. \u201cWe thought of some possible explanations for this pattern, and the process we kept coming back to was that humans might be involved,\u201d he says. Attempts in the 1990s to date the site suggested that the ivory was some 300,000 years old, but Dem\u00e9r\u00e9 was sceptical: the method his colleagues used was problematic, and the age seemed so improbable for humans to be living in California. \n             Challenging consensus \n           Over the past decade, archaeological research and studies of modern and ancient DNA have reached  a consensus view on the peopling of the Americas : humans from Asia  crossed the Bering land bridge  into Alaska some 20,000 years ago and reached the southern tip of South America around 14,000\u201315,000 years ago 2 . Some archaeologists, however, maintain that humans arrived earlier. They point to sites containing rocks that resemble stone tools as well as large animal bones that have damage apparently inflicted by humans. Dem\u00e9r\u00e9's co-authors Kathleen Holen and her husband Steven Holen, archaeologists at the Center for American Paleolithic Research in Hot Springs, South Dakota, have put forward several sites in the US Midwest as evidence for a human presence in the Americas up to 40,000 years ago 3 . But many scientists have viewed these claims with scepticism. After hearing about the San Diego mastodon, the Holens visited Dem\u00e9r\u00e9 in 2008 to see the boxed-up remains. \u201cWe were looking at something very, very old, but it had the same fracture patterns that we had seen before,\u201d says Kathleen Holen. The bones looked as though they had been set on a large \u2018anvil\u2019 stone and struck with a \u2018hammer\u2019 rock. The team contends that the rocks recovered from the site were used either to extract the mastodon\u2019s bone marrow or for making more-delicate bone tools. There are no obvious cut marks on the mastodon bone, suggesting that the animal wasn\u2019t killed or butchered for its meat. Using refined dating methods, the researchers tried again to determine the age of the site. They couldn\u2019t use radiocarbon dating on the mastodon remains because the bones lacked carbon-containing collagen protein. A second method was too imprecise. A third technique, which measures relative levels of radioactive uranium and thorium in bone, suggested that the remains are 130,000\u00a0years old. \u201cI\u2019m sure that many of our colleagues are going to be quite sceptical. I would expect that. This is far, far older than most archaeologists expect hominins to be in North America,\u201d says Steven Holen. \u201cI say that even for myself.\u201d Alistair Pike, an archaeological scientist at the University of Southampton who specializes in uranium dating, notes that the team\u2019s method relies on simplified models of how uranium seeps from groundwater into bone, but he sees no obvious flaws in the dating work. \u201cAt face value, these results are about as good as it can get,\u201d he says. Collecting ancient DNA from the remains and determining the animal\u2019s evolutionary relationship to other mastodons could also help to establish the site's age, notes Pontus Skoglund, a population geneticist at Harvard Medical School in Boston, Massachusetts, who works on ancient DNA. If the discovery holds up, he adds, \u201cit would be one of the most Earth-shattering revisions of our view of the peopling of the world\u201d. \n             Eyebrow-raising claim \n           Before invoking humans, however, the researchers need to better rule out the possibility that natural forces broke the rocks and bones, says David Meltzer, an archaeologist at Southern Methodist University in Dallas, Texas. \u201cIf you are going to push human antiquity in the New World back more than 100,000 years in one fell swoop, you\u2019ll have to do so with a far better archaeological case than this one.\u201d McNabb would like to see the breakage patterns analysed in more detail. He finds it \u201ccurious\u201d that the site yielded no other traces of human presence, such as the shaped stone tools that are typically found at much older animal-butchery sites in Africa. Erella Hovers, an archaeologist at the Hebrew University of Jerusalem who reviewed the paper for  Nature , says she raised her eyebrows when the manuscript arrived in her inbox: \u201cI was like, \u2018Uh, really?\u2019\u201d. But after revisions that elaborated on the dating work and demonstrated that hitting modern elephant bones with large rocks produces damage patterns similar to those seen on the mastodon bones, she is now convinced that hominins created the California site. \u201cThis is mind-boggling,\u201d says Hovers, who also wrote  a commentary accompanying the study . \u201cIt leaves a ton of questions because we know nothing else, except that there were some sort of people there at this time.\u201d \n             Who were the first Americans? \n           If humans or their ancient relatives were responsible, there are several candidates. The ancestors of modern non-African humans  left the continent less than 100,000 years ago , but earlier migrations out of Africa might have reached North America, Dem\u00e9r\u00e9 and his co-authors say. They point to  100,000-year-old  Homo sapiens -like teeth  from China and to hints that some indigenous groups in South America carry trace ancestry from  a possible earlier migration into the Americas . Chris Stringer, a palaeoanthropologist at the Natural History Museum in London, favours Denisovans or Neanderthals, which both lived in southern Siberia at least 100,000 years ago. Yet there is no evidence that either group could survive the epic Arctic voyage across from Siberia to Alaska. \u201cMany of us will want to see supporting evidence of this ancient occupation from other sites before we abandon\u00a0the conventional model of a first arrival by modern humans within the last 15,000 years,\u201d Stringer says. \u201cWe\u2019re going to start looking,\u201d says Dem\u00e9r\u00e9, who has his eye on another California site that his team excavated a few years ago. Steven Holen hopes that other scientists will join the search. \u201cKeep your eyes open for this kind of material when you\u2019re out in the field,\u201d he says. \u201cDon\u2019t just say \u2018This can\u2019t be\u2019.\u201d Read the related News & Views article:  'Unexpectedly early signs of Americans' Reprints and Permissions"},
{"file_id": "nature.2017.21853", "url": "https://www.nature.com/articles/nature.2017.21853", "year": 2017, "authors": [{"name": "Sara Reardon"}, {"name": "Nicky Phillips"}, {"name": "Alison Abbott"}, {"name": "Barbara Casassus"}, {"name": "Ewen Callaway"}, {"name": "Alexandra Witze"}, {"name": "Corie Lok"}, {"name": "Emiliano Rodriguez Mega"}], "parsed_as_year": "2006_or_before", "body": "Nature  reported from marches in cities including Sydney, Washington DC and Paris, as people took to the streets in support of science. Tens of thousands of people gathered on Saturday in Washington DC, and at least 600 other cities around the world, in what may have been one of the largest-ever demonstrations in support of scientific research and evidence-based policymaking. The March for Science was organized shortly after US President Donald Trump\u2019s inauguration in January, largely in response to widespread alarm about his administration's attitude toward science. Trump has repeatedly called global warming a \u201choax\u201d and promised to  roll back numerous environmental protection laws . And in March, the White House released a budget proposal that included  double-digit cuts to agencies such as the Environmental Protection Agency and the National Institutes of Health. More than 100 scientific societies and advocacy organizations have endorsed the march,  but it has also proved controversial . Critics charge that march organizers have diluted the event\u2019s message by focusing on challenges that the scientific community faces, such as the inclusion of racial minorities, rather than advocating for science itself. Many are also concerned that the protest casts science as a partisan issue, although event organizers and supporters have pushed back, insisting that the marches aren't political. Nature  reported from science marches around the world. \n               Mexico City \n             Under a dazzling sun on Paseo de la Reforma, one of Mexico City\u2019s widest avenues, PhD student Adhemar Liquitaya grabs his megaphone to cheer up the crowd of thousands marching towards the city\u2019s main square, the Z\u00f3calo. \u201cAlert! Alert! The fight for science in Latin America is passing through!\u201d For Liquitaya, the fight is personal. In January 2017, the National Council of Science and Technology (Conacyt), the government agency in charge of implementing scientific and technological policies, reduced the amount of money offered to graduate students like him. \u201cIf I struggled before with paying my rent and buying groceries, now I\u2019m being forced to tighten my belt even more,\u201d said Liquitaya, who studies biochemistry at the National Autonomous University of Mexico (UNAM) in Mexico City. Patricia Ram\u00edrez Romero, a hydrobiologist from the Metropolitan Autonomous University in Mexico City, also worries about the toll recent funding policies are taking on Mexican science and technology. As the coordinator of a graduate programme in energy and the environment, she sees that the youngest scientists are the most affected. \u201cIt truly is a shame that Conacyt has cut off all scholarships for those who wish to pursue a master\u2019s degree abroad,\u201d she said. \u201cThe situation just keeps getting worse. We need a change.\u201d Others were worried about scientific collaborations between Mexico and the United States. Ariel Rivers, an American entomologist at the International Maize and Wheat Improvement Center near Mexico City, held a sign decorated with monarch butterflies that read: \u2018These migrants need science, not a wall'. The monarch represents cooperation between our two countries, she said, but that connection may now be in jeopardy. \u201cA lot of projects that I work on receive funding from the Mexican government but also the American government,\u201d Rivers said. \u201cI\u2019m worried about the long-term stability of that funding.\u201d \u201cDonald Trump\u2019s anti-science attitudes have been very damaging for both our countries,\u201d said Antonio Lazcano, an evolutionary biologist at UNAM. But still, he sees some hope. \u201cMexico and the United States won\u2019t be torn apart, not even by the continental drift. We\u2019re neighbours for good.\u201d \n               Boston, Massachusetts \n             Hundreds of scientists across Boston started their morning by rallying on campuses including Harvard University, the Massachusetts Institute of Technology and Boston University, before heading downtown towards the main science march on Boston Common. The rally at Harvard Medical School began with event organizers and speakers leading marchers in a protest song, accompanied by an accordion. But many in the crowd only hesitantly chimed in. The researchers and medical staff from Harvard and the surrounding research hospitals were clearly unaccustomed to belting out protest songs. \u201cThis is a new activity for me,\u201d said Thomas Michel, a biochemist, physician and amateur musician at Brigham and Women\u2019s Hospital and Harvard Medical School who wrote the song and played the accordion. He hasn\u2019t been politically active since he was as a teenager in the 1970s. \u201cThat\u2019s probably true of many scientists,\u201d he said. \u201cWe haven\u2019t done it in a long time, if ever.\u201d But he felt compelled to take action after an Iranian scientist was not able to start his postdoc in Michel\u2019s lab after he had his US visa suspended in January, just weeks before he was set to fly to Boston. \u201cAlthough my passion is for science and medicine, I have a responsibility as a citizen of this country to speak out when I see injustice and help communicate the importance of science,\u201d Michel said. \u201cScience is the best way of overcoming our prejudices and learning new things,\u201d said Dany Adams, a developmental biologist at Tufts University in Medford, Massachusetts. \u201cWe have to show politicians that science is what is keeping us healthy and is an important engine for the economy.\u201d Clifford Woolf, a neurobiologist at Boston Children\u2019s Hospital, led a group of dozens of fellow neuroscientists at the Harvard rally, all wearing blue bandanas around their heads. \u201cOur science impacts the world and the world impacts us, and we can\u2019t ignore it,\u201d Woolf said. \u201cWe have to get involved and stand up for what we do.\u201d \n               Washington DC \n             Although rain drenched the crowd at the start of the march in Washington DC, the weather didn't dampen the spirits of the enthusiastic attendees. People dressed as dinosaurs, superheroes and other colourful figures roamed the National Mall while others held up signs of support for scientific issues, including research reproducibility and the White House\u2019s Office of Science and Technology Policy (OSTP). \u2018The OSTP website is still blank. SAD!\u2019 read one sign. The movement\u2019s flagship march also boasted well-known speakers such as climate scientist Michael Mann, from Pennsylvania State University in University Park, and Christiana Figueres, executive secretary of the\u00a0UN Framework Convention on Climate Change. Scientists flocked from around the United States to march in the nation\u2019s capital. Karen Schroeder, a chemist at a printing company called Kustom Group, travelled from Walton, Kentucky, where she says she got \u201ca lot of crap\u201d from conservative co-workers about marching for science. \u201cIt\u2019s been difficult living there and dealing with the pro-Trump and anti-science vitriol I hear a lot of,\u201d she says. \u201cBut the fact that all this funding is getting cut affects everybody.\u201d Janine Schroeder, Karen\u2019s sister, attended with friends from her Christian church in Arlington, Virginia, and had a different motivation. \u201cI really do believe God made all of this,\u201d she says, referring to the planet. \u201cIt\u2019s our job to take care of this Earth. If you don't fund these programmes to take care of it, then we\u2019re not doing our job as stewards.\u201d Casey Acklin, a neuroscientist from Jackson Laboratory in Bar Harbor, Maine, carried a sign encouraging people to \u201cwear uncertainty like a badge of honor\u201d. Politicians tend to jump to conclusions in an effort to give answers to their voters, he says, even if the science is still in question. \u201cI would love to see a world where people are a little more comfortable being uncertain,\u201d he says. Siblings Eli and Gwenden Dueker came to the march dressed as the Wonder Twins \u2014 characters from the animated 1970s TV show  Super Friends  \u2014 sporting purple jumpsuits and yellow capes. Eli, an environmental microbiologist at Bard College in Annandale-On-Hudson, New York, says he feels a duty to engage with the public and policies. \u201cI feel like as a scientist, I don't get the luxury of stepping away [from] being a citizen myself,\u201d he says. \u201cPretending like science is divorced from people is probably one of the reasons we\u2019re in this mess to begin with.\u201d \n               Denver, Colorado \n             Science is crucial for understanding and protecting the planet, said local television meteorologist Mike Nelson. And \u201cscientists need to be rock stars\u201d, he told a cheering crowd gathered in Civic Center Park in the mile-high city of Denver, Colorado. A mix of science and environmental advocates and professional scientists had collected under the gold-plated dome of the state capitol as a cold and drizzly morning gave way to sunnier skies for the city\u2019s march for science. \"Science is not perfect but it is the best tool we have to face the challenges of the future,\" Colorado governor John Hickenlooper, a former geologist, told the crowd. He spoke over the chants of anti-fracking activists; Hickenlooper supports the practice of fracking. \"Climate change cannot be reversed by silencing scientists.\" \u201cI\u2019m here because we can\u2019t have science being defunded,\u201d said R. A. Varney, a palaeoecologist with the PaleoResearch Institute in Golden, Colorado. Varney, sporting a bowtie, was staffing the institute\u2019s mobile archaeological analytical laboratory in an educational area of the park. \u201cWe called them yesterday to get a slot here. We gotta do something,\u201d he said. \u201cWe wouldn\u2019t be anywhere without science,\u201d said Shannon Harris, a senior at Metropolitan State University of Denver who is studying biology. It was her first time marching for any cause, and she carried a handmade sign decorated with viruses, bacteria and other microorganisms she had studied in her classes. \u201cI really believe in vaccination,\u201d she said, pointing at a carefully rendered syringe on her poster. \u201cI want people to recognize how important science is.\u201d \u201cWe should be thinking about the march as a way to reach out beyond ourselves,\u201d said Marith Reheis, a geomorphologist and palaeoclimatologist who is retired from the US Geological Survey. She spoke about the importance of government funding for the sciences while staffing a table for the Colorado Scientific Society, headquartered in Lakewood, of which she is president. \u201cWe need to think about our grandchildren,\u201d she said. \u201cI have several.\u201d \n               London \n             Clouds, a light shower and bursts of sunshine greeted an estimated 12,000 people who packed the streets of west London in the city\u2019s march for science today. \u201cWhat do we want? Science! When do we want it? After peer review!\u201d was a popular chant, as the crowd wound its way towards Westminster. Science funding was very much on the mind of Curtis Moon, who is working on his master's degree in biosystematics at the Natural History Museum, not far from where the march began. He, like many of today\u2019s participants, is worried about UK science funding once the country leaves the European Union. His homemade sign read \u2018WTF?! Where\u2019s the funding?!\u2019 Tracy Underwood is a medical physicist at University College London (UCL), who is funded through a Marie Curie fellowship, an EU programme that supports graduate students and early-career scientists. She sported a sign that read \u2018Girls just want to have funding\u2019, and hopes the march will make the public more aware of the need to  maintain access to such programmes after Brexit . Overt party politics was mostly absent from the march, even though UK Prime Minister Theresa May had announced a snap general election just a few days before the march. But Peter Brooks, an accountant with a PhD in chemistry, came to support the Liberal Democrat party under a banner of balloons. \u201cBrexit is going to vastly damage our ability to collaborate internationally,\u201d he said. But many more marchers were more concerned with the devaluation of a science-based worldview in the United States and the United Kingdom. \u201cThe political situation is against evidence, fact, peer review and against the truth,\u201d said Matthias Pfeifer, a molecular biologist at Imperial College London. \u201cIf this turns into a world where we can\u2019t say what is true, it will be difficult for us.\u201d Antibiotic resistance was the cause that motivated Lucy Young, a cancer biologist at UCL who came dressed as Dolly the sheep and carried a sign that read: \u2018You are the result of 3.8 billion years of science. Act like it\u2019. \n               Paris \n             About 5,000 people of all ages marched for science under grey skies in Paris today, carrying as many if not more banners in English than in French. \u00a0 \u2018Sticking your head in the sand is not a solution to global warming. Your ass will still get very hot\u2019, proclaimed the sign held aloft by Fr\u00e9d\u00e9ric Bayer, a nutrition engineer who now works for a scientific communications agency Prot\u00e9ines in Paris. \u2018Peer reviewed, not politician skewed\u2019, declared another sign carried by Sarah Arnaud, manager of the European Infravec 2 project at the Pasteur Institute, also in Paris.  The police estimated that between 4,700 to 5,200 people participated in the march. It kicked off with a brass band rendition of 'Sweet George Brown' and continued with a string of speeches and impassioned declarations before the procession set off to Place Saint-Michel in the heart of the Latin Quarter. The march stopped off at the Jussieu campus of the Pierre and Marie Curie University and the Coll\u00e8ge de France on the way. More than 150 French scientific and other bodies officially supported the marches\u00a0in 23\u00a0towns and cities around France, which come the day before the first of two rounds of voting in the presidential election. The run-off\u00a0is on 7 May. \u201cFor the first time, all players in the scientific world in France will march to promote the message that \u2018science is a pillar of democracy\u2019,\u201d the organizers told the press on Tuesday. The idea is to raise awareness among the general public and garner their support for science. \u201cWe must explain to citizens that science is much, much more fragile than is believed,\u201d said Alain Fuchs, president of the National Centre for Scientific Research, the main French public basic research agency. The spread of belief over truth, he says, \u201cis extremely serious, even in France\u201d.\u00a0 Fuchs marched today because science is under threat in the United States, and \u201c we fear we might go the same way , if hints from politicians are anything to go by\u201d, he told  Nature . \n               Munich, Germany \n             Scientists in Germany, where research funding is generous and stable and respect for the environment is strong, have little to complain about. But according to estimates, about 3,000 people gathered at one of the ancient gates to Munich\u2019s historic city centre to participate in the march today. The Munich event was one of 19 planned for towns and cities throughout the country. Attendees came to show solidarity with researchers elsewhere, and because of fears that the world trend towards populism might start to sideline science in their country too. Moritz Hertel from the Max Planck Institute for Ornithology in Seewiesen, who studies brain plasticity, carried an umbrella decorated with dangling pictures of brains. \u201cThe line between pseudoscience and science isn\u2019t always clearly delineated in our society,\u201d he said. \u201cScience needs to play a stronger role in policy-making \u2014 this is particularly important during this election year in Germany.\u201d High-school student Kim Luu, who wishes to study physics at university, said she was concerned that even in Germany some people don\u2019t take the problem of climate change seriously enough. Non-scientists were also out in force, enjoying the good-humoured atmosphere, the rap artists and the drummers. Software developer Jason Reed turned up in a T-shirt that declared \u2018There is no alternative to facts\u2019. \u201cScience has to make a stand,\u201d he said, his three children dancing around him, \u201cand we do so as a family.\u201d Another marcher who laughed that she knew little about science held her large and solemn greyhound in her arms. He sported a grey rain jacket bearing the slogan: \u2018I [heart] scientists\u2019. \n               Sydney, Australia \n             Cognitive scientist Robin Litt had been planning to attend Sydney\u2019s March for Science anyway. But when the visiting American postdoc heard that US vice-president Mike Pence would also be in the city on 22 April, she was even more determined to march in solidarity with researchers in her home country. \u201cKnowing Pence was going to be here, I wanted to feel like I was taking part in something,\u201d says Litt, of Macquarie University in Sydney. The city's march was one of 10 events held in Australia on Saturday. Organizers estimate more than 10,000 people took part across the country. Direct political interference in US science isn\u2019t new, said public-health researcher Simon Chapman, speaking to a crowd of about 3,000 in Sydney\u2019s central business district. But President Trump\u2019s plans to cut the budgets of major science programs is unprecedented, said the retired University of Sydney professor. \u201cMany researchers here today have colleagues living in Trump\u2019s America who fear for their careers and their future.\u201d \u201cIt\u2019s important for scientists to get more involved in what\u2019s going on in the world,\u201d said Nadia Santini, a plant ecologist at the University of New South Wales in Sydney. She decided to march because she felt it was important for researchers to speak out against misinformation and to promote the vital role science plays in society. Santini attended the march with her husband, Tim Mercer, a geneticist at the Garvan Institute of Medical Research in Sydney, and their young daughter, Estela. \u201cIt\u2019s important for her to be here, and see that we want to have a voice,\u201d she said. \u201cShe wants to be a scientist when she\u2019s older,\u201d said Mercer. Fear for future generations compelled schoolteacher Peter Macinnis and his wife Christine, a retired schoolteacher, to participate in Saturday\u2019s event. \u201cWe decided to march today because we want a future for our grandchildren,\u201d Macinnis said. He hopes the global events will convince politicians that the public values science. \u201cAlso, it\u2019s my birthday today and I can think of no better way than to come out and riot on the streets,\u201d he said. \n                     How the March for Science splits researchers 2017-Apr-18 \n                   \n                     French scientists focus on the big political picture 2017-Apr-18 \n                   \n                     Nature supports the March for Science 2017-Apr-11 \n                   \n                     Scientists join massive protest against Trump 2017-Jan-22 \n                   \n                     Is Donald Trump pushing more scientists towards political activism? 2016-Dec-13 \n                   Reprints and Permissions"},
{"file_id": "544405a", "url": "https://www.nature.com/articles/544405a", "year": 2017, "authors": [{"name": "Barbara Fraser"}], "parsed_as_year": "2006_or_before", "body": "How Peruvian coastal deserts respond to rains will aid future disaster response. Torrential rains pummelled Peru\u2019s northern coastal desert in February and March, triggering floods that killed at least 113 people and destroyed some 40,000\u00a0homes. As families grapple with their losses and government officials tally the cost of repair and reconstruction, scientists are gearing up for an unusual opportunity to study ecosystems that go decades without much rain. The rains were spurred by an unusual \u2018coastal\u2019 El Ni\u00f1o climate pattern, in which warm water pooled off the coast of southern Ecuador and northern Peru \u2014 more so than  during the much larger 2015\u201316 El Ni\u00f1o . Rains fell in both countries, but the human toll was highest in Peru\u2019s normally parched northern desert. In the now-greening land, plants are growing, bird populations are shifting and rivers are moving sediments and pollution in ways they haven\u2019t done for two decades. What scientists learn as they descend on the region could aid conservation efforts and help people and government officials to prepare for severe weather events. \u201cExcept for the impacts on the people,\u201d says biologist Juan Torres of La Molina National Agrarian University in Lima, \u201cthis is a meteoro\u00adlogically enchanting moment.\u201d Once roads are passable, Torres will visit field sites that he studied after the powerful 1997\u201398 El\u00a0Ni\u00f1o, which also soaked the region. At that time, Torres found wild relatives of domesticated crops \u2014 including tomatoes, peppers, potatoes and squash \u2014 that had sprouted from dormant seeds. This year, he will again catalogue wild plants, along with the crops that farmers choose to grow on lands made fertile by the flooding. Part of the northern desert is irrigated farmland, but there are also patches of a dry forest that has been devastated in recent years by industrial agriculture, urban sprawl and the charcoal trade. Oliver Whaley at the Royal Botanic Gardens, Kew, in London, has studied Peru\u2019s dry forests for 25 years, and hopes that the rain will bring respite to the ecosystem. One important tree species, known locally as huarango ( Prosopis  spp.), has been in rapid decline, in part because of pressure from insects and a fungus. The floods may have washed the insect pests away. Peruvian botanist Ana Ju\u00e1rez will survey the area further with Whaley in May, but has not seen any insects on the trees near her since the rains. That\u2019s a good sign, but the ongoing destruction of the dry forest seems to have exacerbated erosion and flooding from the storms. Soil carried by the floods surged down normally tranquil rivers.  Satellite images  show the Tumbes and Chira rivers overflowing and spreading nutrient-rich sediment over swathes of farmland. That\u2019s what the rivers are supposed to do, says Jorge Abad, a civil engineer at the University of Engineering and Technology in Lima. But these floods caused damage because the rivers have been channelled, dammed and dredged without considering sediment flow, he says, adding that better modelling would allow engineers to improve flood control and reduce future disaster risk. The rains have also washed rubbish, metals and chemicals from towns, mining operations and farmlands into the Pacific Ocean. That worries Carlos Zavalaga of the Scientific University of the South in Lima, who studies the seabirds that live along the Peruvian coast. Warm coastal waters can drive out schools of Peruvian anchovies ( Engraulis ringens ), robbing guano-producing birds of their main food supply and leading them to hunt elsewhere. As of February, two-thirds of the Guanay cormorants ( Phalacrocorax bougainvillii ) at Punta San Juan, on the south-central coast, had abandoned their nests. Besides the impact on the ecosystem, losing these birds will reduce the accumulation of guano, which is still mined in the area. Zavalaga plans to survey the situation in the coming weeks and to analyse bird blood and feathers for contaminants from the washout. No one predicted this year\u2019s disaster until it was too late. Scientists had  expected the major El Ni\u00f1o of 2015\u201316 , but that system\u2019s effects were muted in South America. And even though this year\u2019s rainfall is comparable to that due to the large 1997\u201398 El Ni\u00f1o, the causes are different. That raises questions for climate scientists, says Rodney Mart\u00ednez, an oceanographer at the International Center for Research on the El\u00a0Ni\u00f1o Phenomenon in Guayaquil, Ecuador. He says that scientists need a better understanding of these atypical coastal El Ni\u00f1os, which may also have occurred in the 1920s and 1970s, and how they relate to larger ocean cycles. But studies could be undermined by a lack of funding. Ocean-monitoring buoys set by Peruvian and Ecuadorian scientists after the 1997\u201398 El Ni\u00f1o were vandalized and never repaired, and the Pacific-wide Tropical Atmosphere Ocean instrument array is  suffering from deterioration and budget cuts . \u201cWhat we\u2019ve seen in Ecuador and Peru is resounding evidence of the importance of managing ecosystems for the prevention of extreme events,\u201d Mart\u00ednez says. \u201cThat still is not fully included in risk management.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Monster El Ni\u00f1o probed by meteorologists 2016-Jan-20 \n                   \n                     Hunting the Godzilla El Ni\u00f1o 2015-Oct-20 \n                   \n                     Forest ecology: Splinters of the Amazon 2013-Apr-17 \n                   \n                     Hydropower threatens Andes\u2013Amazon link 2012-Apr-19 \n                   \n                     Monitoring of the Andean Amazon Project \u2014 images of flooding in Peru \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21910", "url": "https://www.nature.com/articles/nature.2017.21910", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "For the first time, researchers have identified DNA of human relatives without the need to find their bones, opening new window into the past. Bones and teeth aren\u2019t the only ways to learn about extinct human relatives. For the first time, researchers have recovered ancient-human DNA without having obvious remains \u2014 just dirt from the caves the hominins lived in. The technique opens up a new way to probe prehistory.\u00a0 From sediments in European and Asian caves, a team led by geneticist Viviane Slon and molecular biologist Matthias Meyer, both at the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany, sequenced genomes of cell structures called mitochondria from Neanderthals and another hominin group, the Denisovans. Their work is published in  Science 1 . \u201cIt\u2019s exciting to see that you can end up with a whole pile of ancient-human DNA from just dirt,\u201d says Michael Bunce, an evolutionary biologist at Curtin University in Perth, Australia. Slon and Meyer are not the first to decode ancient dirt. Palaeogeneticist Eske Willerslev of the Natural History Museum of Denmark in Copenhagen pioneered the approach in 2003, to find out about the plants and animals that populated prehistoric environments 2 , 3 . Using the technique, he and his team  revealed that Greenland was once richly forested 4 . But Slon and Meyer are the first to use the technique on hominin DNA. \n             Dirt detectives \n           Isolating the genetic material of ancient peoples from dirt isn't easy. The DNA is exceedingly rare in the soil compared with that from plants, animals, fungi and microbes. It is also easy to mix it up with DNA from human excavators, for instance. To improve the odds, Slon and Meyer\u2019s team collected sediments from sites at which tools or the remains of Neanderthals or Denisovans had previously been found. They looked at seven caves, including two in southern Siberia.  The team analysed the sediment samples with techniques that \u2018fish out\u2019 mammalian mitochondrial DNA, which is more abundant in cells than the DNA in the nucleus. To make sure that they weren\u2019t looking at modern genetic material, the researchers analysed only the short sequences with chemical damage typical of ancient DNA. The team recovered nine ancient-hominin mitochondrial genomes of varying completeness, from four of the sites. Neanderthal DNA was present in all four caves. Sequences of Denisovans, however, turned up only in a chamber of the southern Siberian cave  where remains of the enigmatic group were first identified. \n             But when? \n           Determining when these individuals lived is tricky. DNA attached to dirt can be picked up by water, then seep through the soil of archaeological sites and end up in a geological layer containing much older material \u2014 potentially confounding efforts to date it. So the researchers tried to demonstrate that the DNA they recovered hadn't been displaced into older layers. In Siberia's Chagyrskaya Cave, the researchers found abundant animal DNA in geological layers that contained animal bones and stone tools and none in older layers that lacked any sign of human or animal presence. That means it's likely that hominin DNA didn't move through layers either, they suggest. But Robin Allaby, an evolutionary geneticist at the University of Warwick in Coventry, UK, isn\u2019t convinced. He thinks that the large amount of DNA recovered from some sites is evidence that lots of different material might have mixed and settled in a particular layer. \u201cYou can identify the hominins, but dating them becomes a bit of an issue,\u201d he says. The exact source of the DNA is also unclear. Bodily fluids, faecal matter, hair and bone are all possibilities, says Slon. Whatever the source, the discovery of hominin DNA in soil should mean that the many archaeological sites that show signs of hominin habitation but lack obvious remains can now be probed genetically. For example, Slon\u2019s team identified Neanderthal DNA in soil from the Trou Al\u2019Wesse cave in Belgium, where archaeologists have found tools probably made by Neanderthals, but have never recovered bones. \n             Underwater settlements \n           Researchers have high hopes for dirt DNA. Allaby\u2019s team is sequencing sea-floor sediments off the coast of England,  in search of suspected ancient settlements that might now be submerged . Cool, constant ocean temperatures are ideal for preserving DNA, and Allaby thinks genetic material found under water could reveal details of human migrations out of Africa and  into Australasia  and  the Americas . Mikkel Winther Pedersen, a molecular palaeoecologist at the University of Cambridge, UK, and his colleagues last year decoded animal DNA from the soil of archaeological sites in Greenland, documenting bowhead whale hunting 4,000 years ago 5 . Pedersen hopes the latest study will change how field archaeologists excavate sites. \u201cSave the dirt,\u201d he advises, \u201ceven though you don\u2019t necessarily want to use it.\u201d There may be a Neanderthal genome lurking in it, after all. \n                   Plant and animal DNA suggests first Americans took the coastal route 2016-Aug-10 \n                 \n                   Oldest ancient-human DNA details dawn of Neanderthals 2016-Mar-14 \n                 \n                   Ancient DNA dispute raises questions about wheat trade in prehistoric Britain 2015-Nov-03 \n                 \n                   Ancient DNA reveals how wheat came to prehistoric Britain 2015-Feb-26 \n                 \n                   Human evolution: The Neanderthal in the family 2014-Mar-26 \n                 \n                   Ancient DNA reveals secrets of human history 2011-Aug-09 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21876", "url": "https://www.nature.com/articles/nature.2017.21876", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "November tremor sparked slow, deep movements in Earth\u2019s crust that increase the chances of a similar severe quake within a year. DENVER, COLORADO The consequences of a magnitude-7.8 earthquake that struck New Zealand on 14 November 2016 are still rippling through the country. The quake, which killed two people and caused billions of dollars of damage, ruptured a complex set of geological faults near the surface. It also triggered slow-motion movement as deep as 40 kilometres in Earth\u2019s crust, some of which continues to this day, scientists report. That deep \u2018slow slip\u2019 is worrying, because it adds to the risk of another big quake. \u201cThis earthquake is special,\u201d says Bill Fry, a seismologist at GNS Science, a government-owned Earth-science research organization in Lower Hutt, New Zealand. He and others described their findings last week in Denver, Colorado, at a meeting of the Seismological Society of America. The November Kaikoura tremor is a rare example of a large quake triggering widespread slow slip. And what researchers have learned from this tremor could illuminate the seismic risk in other regions that experience slow slip, such as Japan and the US\u2013Canadian Pacific Northwest. \n               A dangerous boundary \n             A spate of large earthquakes has rattled New Zealand in the past decade, including one in 2011  that devastated the city of Christchurch . But the Kaikoura\u00a0tremor stands out for its geological complexity. It began near the north end of New Zealand\u2019s South Island and ripped northward for more than 170 kilometres 1 . At least 21 separate faults broke along the way. Landslides buried roads and the shaking damaged buildings in the central business district of Wellington 2 . The earthquake immediately triggered slow-slip movement in at least three separate areas, according to GNS Science. The regions stretched from off the east coast of the North Island to the northern part of the South Island. In each case, the Australian and Pacific plates of Earth\u2019s crust ground against one another extremely slowly, at a dangerous interface known as a subduction zone. Most of the slow slip ceased within weeks, although a little of it continues. Cumulatively, the plate motions have released as much energy as a magnitude-7.3 earthquake would have. These patches of Earth\u2019s crust have slipped slowly before \u2014 but never all at once, said GNS Science seismologist Anna Kaiser at the meeting. The areas in motion surround a section that experiences no slow slip at all. This region, extending east of Wellington, may be locked and building up stress that could break in the next large quake. Seismologists have observed slow-slip movement in other subduction zones,  in some cases coming before large tremors , including the devastating magnitude-9 Tohoku quake in Japan in 2011. How the two phenomena relate to one another is not entirely clear. \u201cWe\u2019re at the very early stages of trying to understand the relationship between slow-slip events and earthquakes,\u201d says Laura Wallace, a geophysicist at GNS Science and the University of Texas at Austin. \n               Peering into the future \n             The revelations from New Zealand could alter future planning in quake-prone areas. Earthquake forecasts look at past seismic activity and calculate the probability of tremors of a certain magnitude within a certain time period. They typically do not include the effects of slow slip. But after the Kaikoura quake, GNS scientists added that movement into their own calculations and found a 5% chance of a similar quake within a year. That is a relatively low probability, but is still six times higher than it was before the quake. With the New Zealand government busy retrofitting buildings and roads in preparation for future quakes, researchers are working to quantify what they do and do not know. For instance, seismic-risk models typically consider the rupture of one fault at a time \u2014 but after Kaikoura, geologists now realize they need to plan for the possibility of the simultaneous rupture of multiple faults. \u201cThis just really emphasizes that that needs to be done,\u201d says Matt Gerstenberger, a GNS seismologist who works on the national seismic-hazard model. Researchers will gain greater insight into slow-slip movement late this year and next, when several project teams descend on the region. In November, the  JOIDES Resolution  ship will begin the first of two expeditions to drill into the slow-slip area off the New Zealand coast. A ship-borne seismic survey, to begin in early 2018, will provide a 3D look at where the slow slip is happening. And a bevy of new ocean-bottom seismometers will track the shaking as the plates continue to move. \u201cIt will be the best-imaged slow-slip area, anywhere in the world,\u201d Wallace says. \u201cWe\u2019re trying to apply everything we can to this.\u201d \n                     \u2018Zombie volcano\u2019 slowly grows beneath New Zealand 2016-Jun-03 \n                   \n                     In Japan, small shakes presage big quakes 2016-Jan-28 \n                   \n                     Hellish conditions a scientific gold mine for drilling project 2015-Dec-17 \n                   \n                     Dissecting New Zealand's deadly quake 2011-Feb-22 \n                   \n                     GeoNet \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21869", "url": "https://www.nature.com/articles/nature.2017.21869", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Protests sparked by the destruction of three key fossil-hunting areas result in a temporary halt of phosphate mining. Palaeontologists are fighting to save a site in China that contains fossils of some of the earliest animals on record. This month they gained a temporary halt to the phosphate mining that has already destroyed some fossil beds. The threatened site is part of the Doushantuo geological formation in the Weng\u2019an region of Guizhou province in southern China. It is rich in minerals that preserve soft tissues and cellular structures and became famous in the late 1990s, after scientists began finding well-preserved fossils of sponges and  embryos of other unusual animals , dating to around 600 million years ago. These discoveries challenged the theory that virtually all major animal lineages emerged  during the \u2018Cambrian explosion\u2019  some 540 million years ago 1 , 2 . Microscopic fossils assumed to be embryos that were excavated from Doushantuo have, more recently, sparked debates over the origins of bilateral symmetry in animals. \u201cWe may never find a comparable site and may lose the chance to truly understand early animal evolution on Earth,\u201d says Dave Bottjer, a palaeobiologist at the University of Southern California in Los Angeles, who estimates that just 5% of the site\u2019s fossils have been recovered. \u201cIf nothing is done, it will be a great loss,\u201d he says. On a visit to Doushantuo this month, palaeontologist Zhu Maoyan of the Nanjing Institute of Geology and Paleontology was stunned to find a newer fossil site, opened in 2015, completely stripped of fossil-bearing sediment by phosphate mining. The locale that produced the area\u2019s first fossils had been destroyed years ago. And a third key fossil-hunting area, which produced most of the new fossils found in the formation in the past 15 years, was buried by a landslide that had been triggered by mining in 2014. \u201cIt is really a disaster,\u201d says Zhu. Phosphate miners operated in Doushantuo before the palaeontologists got there and, to some extent, enabled discoveries by churning up fresh rocks, says Andrew Knoll, a palaeontologist at Harvard University in Cambridge, Massachusetts, who worked there in the 1990s. \u201cBut if mining has accelerated to the point that the Weng\u2019an beds will soon be completely mined out, the benefits of fresh exposure are moot.\u201d The pace of mining has increased dramatically over the past two years, says Zhu. Over the past two decades, he and others had tried to convince the local government that the sites needed protection. But Zhu says he now realizes that these efforts, often hampered by miscommunication and high turnover of local-government officials, were not enough. \n               Fossil activism \n             Zhu and his colleagues turned to more forceful action. He organized a workshop, held on 2\u20133 April in Weng\u2019an, and invited scientists, including Bottjer, to make a case for preserving the site. The coalition scored an early victory. Several days after the workshop, local-government officials ordered a halt to mining in the area, while they work out a strategy. Zhu says that measures are likely to include finding other sites for mining. He hopes eventually to get a central fossil-hunting zone, 1.2 square kilometres in area, closed to mining and designated a national geological park. A solution that has been successful elsewhere is to have miners work in tandem with scientists, says Knoll. \u201cIt wouldn\u2019t be difficult to employ a geologist to mine the main fossiliferous beds, which are not very thick, and store samples, possibly tons of them, for future research.\u201d But the hullaballoo might have created another problem, says Shuhai Xiao, a geobiologist at Virginia Tech, in Blacksburg, who worked at Doushantuo in the 1990s. Zhu's appeals have drawn attention from Chinese media, raising the site's profile among black market dealers. \u201cSo far, this site has not been on the radar of fossil dealers,\u201d he says. \u201cBut this may change if there is a public demand for specimens from this site.\u201d \n                     What sparked the Cambrian explosion? 2016-Feb-16 \n                   \n                     Enigmatic fossils are neither animals nor bacteria 2011-Dec-22 \n                   \n                     Scans peer inside fossil embryos 2006-Aug-09 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21912", "url": "https://www.nature.com/articles/nature.2017.21912", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "April\u2019s sharpest science shots, selected by  Nature \u2019s photo team. \n             A golden reflection \n           \n             Cassini looks back \n           \n             Drawing in the deep \n           \n             Science, j'\u00e9cris ton nom \n           \n             Operation IceBridge \n           \n             Damsels not in distress \n           \n             Night lights \n           \n             River piracy \n           \n             Cuban crabs \n           \n                   Space ravioli, nuclear explosions and a synthetic sun 2017-Mar-31 \n                 \n                   Fake stars, panda suits and ants on treadmills 2017-Feb-24 \n                 \n                   Swimming starfish, a departing dinosaur and a lot of ice 2017-Jan-27 \n                 Reprints and Permissions"},
{"file_id": "544401a", "url": "https://www.nature.com/articles/544401a", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Major investment in regenerative medicine enters its last stage \u2014 and the money might run out before treatments are ready. When California voters approved US$3\u00a0billion in funding for stem-cell research in 2004, biologists flocked to the state, and citizens dreamed of cures for Parkinson\u2019s disease and spinal-cord injuries. Now, the pot of money \u2014\u00a0one of the biggest state investments in science \u2014\u00a0is running dry before treatments have emerged, raising questions about whether Californians will pour billions more into stem-cell research. If they don\u2019t, that could leave hundreds of scientists without support, and strand potentially promising therapies before they reach the market. \u201cIt\u2019s an issue of great concern,\u201d says Jonathan Thomas, chair of the board for the California Institute for Regenerative Medicine (CIRM) in Oakland. CIRM is now doling out its final $650\u00a0million, and its leaders are seeking money from the private sector to carry projects beyond 2020, when the money will run out. Advocates are also surveying voters to determine whether a new request for funding stands a chance in state elections next year. But critics argue against this way of funding research. California voters saw major opportunities for stem cells in 2004 when they passed Proposition 71, which included an agreement to create the corporation that became CIRM. The move was a reaction to then-US president George W. Bush\u2019s decision in 2001 to restrict federal funds for work on human embryonic stem cells. Since CIRM rolled out its first grants in 2006, it has funded more than 750 projects and reported alluring results from clinical trials. In March, a trial partially funded by CIRM showed that nine out of ten children born with severe combined immunodeficiency \u2014 or \u2018bubble-boy disease\u2019 \u2014 a potentially lethal condition in which a person\u2019s immune system does not function properly, were doing well up to eight years after treatment ( K.\u00a0L.\u00a0Shawet\u00a0al.J.Clin.Invest.http://doi.org/b6bp;2017 ). They no longer need injections to be able to go to school, play outside or survive colds and other inevitable infections. A dozen facilities constructed by CIRM have helped to push California to the forefront of research on ageing and regenerative medicine. Many grant recipients were early-career academics who had not been able to enter the stem-cell field previously because of the federal restrictions \u2014 which were loosened in 2009 \u2014 and the high cost of getting started in this kind of work. That barrier makes it difficult for researchers to gather the preliminary data typically required to win grants from the US National Institutes of Health (NIH). To milk its remaining $650 million, CIRM partnered last year with the contract-research organization QuintilesIMS in Durham, North Carolina, to carry out clinical trials. CIRM leaders hope that this move will help to guide 40 novel therapies into trials by 2020. Bob Klein, the property developer who put Proposition 71 on the ballot and established CIRM, isn\u2019t waiting for the money to run out. He leads an advocacy group, Americans for Cures, which will soon poll voters to see whether they would approve another $5 billion in funding. If it looks like at least 70% of Californians support that plan, he\u2019ll start a campaign to put another initiative on the ballot in 2018. Klein hopes that Californians will rise in support of science at a time when the Trump administration has proposed drastic cuts to the NIH budget. If public enthusiasm is not so strong, Klein says, he\u2019ll aim for the 2020 elections, when voter turnout should be higher because it will coincide with the next presidential race. Currently, CIRM\u2019s leaders are seeking other sources of support. \u201cThe majority of our projects will not be ripe for interest from big pharma and the venture-capitalist community by the time we run out of funds,\u201d Thomas says. He has been courting large philanthropic foundations and wealthy individuals to raise money to continue the work. John Simpson, who directs stem-cell oversight work at the advocacy group Consumer Watchdog in Santa Monica, California, plans to oppose any effort to extend CIRM. \u201cI acknowledge their scientific advances, but we should not let a flawed process go further,\u201d he says. Simpson dislikes the model of using a vote to secure research funding through public bonds, because then the state lacks budgetary control. Oversight of CIRM has been a problem in the past. In 2012, the US Institute of Medicine found that some scientists vetting grant proposals for CIRM had conflicts of interest. In response, CIRM altered its procedures \u2014 but the public still felt betrayed. Jim Lott, a member of the state board that oversees CIRM\u2019s finances, says that he is not satisfied with the changes. He also argues that CIRM may not have been strategic enough in directing research. \u201cSome people say if they had a better focus, they might have achieved cures.\u201d But researchers argue that expectations for cures after only a decade are unrealistic, given the typical pace of drug development. \u201cIt would be a catastrophe for California if people say CIRM did not do what it was expected to do,\u201d says Eric Verdin, president of the Buck Institute for Research on Aging in Novato, California. \u201cThey\u2019ve built the foundation for the field and attracted people from around the world \u2014 you can\u2019t just now pull the plug.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Stem cells: Hope on the line 2014-Jul-02 \n                   \n                     Funding windfall rescues abandoned stem-cell trial 2014-Jun-03 \n                   \n                     Stem-cell boss urges communication 2011-Jun-29 \n                   \n                     Stem cells: The impatient advocate 2010-Dec-01 \n                   \n                     Blog post: Scientific panel recommends changes to California\u2019s stem cell institute \n                   \n                     California Institute for Regenerative Medicine \n                   \n                     Americans for Cures \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21917", "url": "https://www.nature.com/articles/nature.2017.21917", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "A promising treatment that uses MDMA could help people suffering with post-traumatic stress disorder. Psychologists have occasionally given people psychedelic drugs such as LSD or magic mushrooms to induce altered states, in an attempt to treat mental illness. Today, many of those drugs are illegal, but if clinical trials testing their efficacy yield positive results, a handful could become prescription medicines in the next decade. The furthest along in this process is MDMA \u2014 a drug sold illegally as ecstasy or Molly \u2014 which is showing promise in the treatment of  post-traumatic stress disorder  (PTSD). Last week, at the Psychedelic Science 2017 conference in Oakland, California, researchers presented unpublished results from phase II trials involving a total of 107 people diagnosed with PTSD. The trial treatment involved a  combination of psychotherapy and MDMA  (3,4-methylenedioxymethamphetamine). The US Food and Drug Administration (FDA) reviewed these data in November, which were not released to the public at the time. The agency recommended that the researchers move forward with phase III trials, the final stage before potential approval of the drug. At the conference, researchers affiliated with the non-profit organization that is sponsoring the trials, the Multidisciplinary Association for Psychedelic Studies (MAPS) in Santa Cruz, California, presented some of their latest resutls. They used a cinically validated scale that assesses PTSD symptoms such as frequency of nightmares and anxiety levels. More than one year after two or three sessions of MDMA-assisted therapy, about 67% of participants no longer had the illness, according to that scale. About 23% of the control group \u2014 who received psychotherapy and a placebo drug \u2014 experienced the same benefit. Researchers leading those trials are now training a cadre of therapists to deliver a form of psychotherapy tailored for use with MDMA, in preparation for the phase III trials. They consider this component essential. \u201cI\u2019ve seen people in my practice who took MDMA at a party and weren\u2019t prepared for the memories that came up, and it was really harmful for them,\u201d says Michael Mithoefer, a psychiatrist in Charleston, South Carolina, and a principle investigator in the MDMA trials. About 8% of the US population will experience PTSD at some point in their lives. And up to half of participants enrolled in clinical trials to treat PTSD fail to respond to therapies including serotonin-reuptake inhibitors \u2014 a class of drugs often used as antidepressants \u2014 and cognitive behavioural therapy. \u201cThe results I\u2019ve seen so far with MDMA are so much better than anything I\u2019ve seen so far,\u201d Mithoefer says. \n             Therapeutic sweet spot \n           PTSD treatment commonly involves getting a patient to repeatedly recall traumatic events, to extinguish the fear associated with the experience 1 . But that method can fail if patients can't describe the memory because they have walled it off. Other people have such a charged emotional response that the recollection causes harm. \u201cBecause of this stress, many patients will drop out of treatment,\u201d explains Daniel Zuj, a research psychologist at the University of Tasmania in Launceston, Australia, who is not involved in the MDMA trials. In the 1990s, scientists demonstrated in rodents and humans that MDMA was reasonably safe when taken a few times in a controlled setting. The FDA permitted researchers to move forward with clinical trials exploring the drug as a treatment for PTSD. Studies suggest that MDMA reduces the fear response 1 , and triggers the release of serotonin and other neurotransmitters that induce a feeling of well-being 2 . In this way, individuals may recall events multiple times, in detail, without panicking. \u201cMDMA provides a sweet spot where therapeutic change can happen,\u201d says Mithoefer. \u201cIt affects neural networks so that people\u2019s experiences are not hijacked by fear.\u201d \n             Sustained results \n           Investigators with MAPS hope to enrol up to 300 people with PTSD to participate in the upcoming phase III trials. The researchers will spend this year training therapists from 14 clinics across North America and Israel to deliver the MDMA-assisted psychotherapy. They developed their approach by combining modern PTSD therapy with techniques used by LSD researchers in the 1960s. Two therapists supervise the patient while he or she is under the influence of the drug; this lasts five to eight hours for MDMA. It\u2019s essential that people feel they are in a safe, comfortable setting with someone who can oversee the experience, says Alicia Danforth, a clinical psychologist at the Harbor\u2013UCLA Medical Center in Torrance, California, who is involved in MAPS-sponsored trials studying MDMA\u2019s effects on social anxiety in adults with autism. During his conference presentation, Mithoefer played a video of a former US marine under the influence of MDMA recounting the time his military jeep exploded during a tour in Iraq. The soldier, positioned on a narrow bed between Mithoefer and his wife Annie, a psychiatric nurse, describes the panic that accompanies his memories. But then, he says, an inner-voice assures him that he\u2019ll be all right. \u201cI feel things come up and then blow away like sand,\u201d the marine says. Michael Mithoefer says it\u2019s been five years since the marine\u2019s session. \u201cWe are still in touch,\u201d he says, \u201cand that effect has lasted.\u201d \n                   The mental-health crisis among migrants 2016-Oct-10 \n                 \n                   Magic-mushroom drug lifts depression in first human trial 2016-May-17 \n                 \n                   Vaccine hope for post-traumatic stress 2015-Jun-12 \n                 \n                   No link found between psychedelics and psychosis 2015-Mar-04 \n                 \n                   MDMA keeps severe stress at bay 2012-Nov-20 \n                 \n                   Party drug could ease trauma long term 2010-Apr-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21911", "url": "https://www.nature.com/articles/nature.2017.21911", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Report prompts warnings that the polar region is 'unravelling'. The Arctic is warming more than twice as fast as the rest of the planet, suggests a huge assessment of the region. The warming is hastening the melting of Arctic ice and boosting  sea-level rise . The report, compiled by more than 90 scientists, documents the myriad  changes already under way across the Arctic  because of climate change \u2014 from declining sea ice and melting glaciers to shifting ecosystems and weather patterns. From 2011 to 2015, the assessment finds, the Arctic was warmer than at any time since records began around 1900 (see 'Arctic warming'). Sea ice continues to decline , and the extent of snow cover across the Arctic regions of North America and Eurasia each June has halved as compared to observations before 2000. The findings come from the  Snow, Water, Ice, and Permafrost in the Arctic report , a comprehensive assessment compiled every few years by the Arctic Monitoring and Assessment Programme, the scientific body that reports to the governments that make up the Arctic Council, a forum for issues affecting the region. The last assessment came out  in 2011 . \n             Observation to action \n           \u201cThe take-home message is that the Arctic is unravelling,\u201d says Rafe Pomerance, who chairs a network of conservation groups called Arctic 21 and was a deputy assistant secretary of state for environment and development under US President Bill Clinton. \u201cThe fate of the Arctic has to be moved out of the world of scientific observation and into the world of government policy.\u201d The report increases projections for  global sea-level rise , which takes into account all sources of melting including the Arctic. Their new minimum estimates are now almost double those issued by the Intergovernmental Panel on Climate Change (IPCC)  in 2013  for some emissions scenarios. In fact, the latest calculations suggest that the IPCC's middle estimates for sea-level rise should now be considered minimum estimates. In one scenario, which assumes that carbon emissions rise slightly above the goals set by the 2015 Paris climate agreement \u2014 but still see a considerable reduction \u2014 sea levels would increase by at least 0.52 metres by 2100, compared with 2006, the Arctic report says. Under a business-as-usual scenario, the minimum increase would be 0.74 metres. Although aggressive reductions in greenhouse-gas emissions will make a crucial difference by the end of the century, dramatic changes are still likely over the next few decades, says Morten Skovg\u00e5rd Olsen, who coordinated the assessment and leads the Danish Ministry of Energy, Utilities and Climate\u2019s Arctic programme. \u201cThe Arctic that you will have by mid-century will be very different from the Arctic that we see today,\u201d he says. \n                   Incredibly thin Arctic sea ice shocks researchers 2016-Dec-14 \n                 \n                   Low Arctic ice, Monsanto takeover, and the longest lightning strike 2016-Sep-21 \n                 \n                   Speedier Arctic data as warm winter shrinks sea ice 2016-Mar-01 \n                 \n                   Climate science: Understand Arctic methane variability 2014-May-14 \n                 \n                   Global warming: Improve economic models of climate change 2014-Apr-04 \n                 \n                   Climate science: Vast costs of Arctic change 2013-Jul-24 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21929", "url": "https://www.nature.com/articles/nature.2017.21929", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Authors of high-profile paper strongly criticized by Swedish ethics panel. Update:  Science  has  retracted  the paper by Ekl\u00f6v and L\u00f6nnstedt. The authors of a high-profile paper about the dangers of fish consuming small particles of plastic say that they will retract their study, after an investigation found them \u201cguilty of scientific dishonesty\u201d and raised the possibility that some of the research described \u201cwas not conducted\u201d. Limnologist Peter Ekl\u00f6v and marine biologist Oona L\u00f6nnstedt, both at Uppsala University in Sweden, continue to strongly defend themselves against allegations made about their work, which was published in  Science 1 . But in a statement to  Nature \u2019s news team, Ekl\u00f6v and L\u00f6nnstedt said that they have decided to retract the paper. \u201cScience has to rest on solid ground and the results of this study, even if they are correct, will not be trusted as long as a suspicion of misconduct remains,\u201d they say. \u201cThus, we decided that we would not have the endurance to keep defending the paper, and hence decided to retract it.\u201d  Science  says it is in the process of retracting the study. The controversy centres on a  2016 paper  in which the authors reported experiments showing that fish that ate tiny 'microplastics' grew more slowly and were more likely to be eaten by predators. Soon after the paper\u2019s publication, a group of researchers raised a complaint about the study. They said that not all the data underlying the results were available. And some of the critics who worked at the same research station as L\u00f6nnstedt \u2014 on Gotland, a Baltic Sea island \u2014 said that there were discrepancies between experiments described in the study and eyewitness reports of the researchers\u2019 activities.\u00a0 Uppsala University investigated those allegations last year and found no evidence of misconduct. But an expert group of Sweden\u2019s Central Ethical Review Board was also tasked with investigating the allegations, and in a statement dated 21 April, said that the paper should be recalled. It also describes Uppsala\u2019s conclusions as \u201cremarkable\u201d. \n             Missing data \n           In its report, the expert panel says that several questions were \u201crepeatedly put\u201d to Ekl\u00f6v and L\u00f6nnstedt about the case, and it found the researchers\u2019 answers to be \u201cin all essentials deficient\u201d, \u201cat times contradictory\u201d and that they often raised further questions. The paper\u2019s assertion that an animal-ethics committee had approved their specific experiments \u201cis not consistent with the truth\u201d, and by stating that they had approval, the panel says, Ekl\u00f6v and L\u00f6nnstedt have committed scientific dishonesty. The panel was also concerned about the lack of available original data for the experiments and this contributed to its \u201cscientific dishonesty\u201d finding. Ekl\u00f6v and L\u00f6nnstedt had said last year that a laptop containing the study's data was stolen, and that there had been problems with back-ups.  An \u2018expression of concern\u2019 was added  by  Science  to the paper last December to note the issue of missing data.\u00a0 But the fact that the authors \u201cproduced no more than weak fragments of the original data and no original traceable data files\u201d also \u201cleads to suspicion that the research was not conducted, at least not to the reported extent\u201d, says the panel. The report is critical of  Science , too. The experiments, as described in the paper, seem to lack adequate control experiments, it says, and \u201cit is remarkable that the article, given these deficiencies, was accepted by the journal  Science \u201d. In a statement to  Nature 's news team,  Science  said that its reviewers assess both the data presented in manuscripts and whether appropriate controls were done. \u201cIf the review process had raised red flags about the controls,\u201d says the statement, \u201cfurther revision would have been requested by the editors before the paper could be accepted for publication.\u201d Ekl\u00f6v and L\u00f6nnstedt, meanwhile, say that the investigation report \u201cincludes many errors\u201d. For instance, they say they did have an ethical permit covering the experiments they undertook, and the fact that the laptop was stolen, and data not properly backed up \u201cwas an unfortunate mistake and not dishonesty\u201d. \n             Path forward \n           Uppsala said in a statement that it will consider the findings of the expert panel before making a decision on whether to take action. Commenting on the contrasting findings of the two investigations, it says that the probes \u201cproceed from different regulatory frameworks and cover different quantities of material\u201d \u2014 but notes that the investigations agree that the data were inadequately backed up. Timothy Clark, an ecologist at the University of Tasmania in Hobart, Australia, and one of the initial group of critics, is concerned that Uppsala is focusing on inadequate data back-up rather than what he considers the more serious issues, such as the suggestion that experiments were not carried out to the extent reported. Still, Clark feels partially vindicated by the report's findings: \u201cI think the overwhelming emotion is relief that it didn\u2019t follow a similar path to what the Uppsala University preliminary investigation concluded.\u201d \n                   Bottles, bags, ropes and toothbrushes: the struggle to track ocean plastics 2016-Aug-17 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21835", "url": "https://www.nature.com/articles/nature.2017.21835", "year": 2017, "authors": [{"name": "Sara Reardon"}, {"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Congress gives National Institutes of Health a big boost and avoids cuts to research agencies sought by Trump. Funding for US science agencies will stay flat or even increase over the next several months, under a US$1-trillion spending deal announced on 30 April. The plan devised by Congress, which covers the remainder of the 2017 budget year, avoids the  sharp cuts to science proposed by US President Donald Trump . The biggest winner is the National Institutes of Health (NIH), whose budget would rise by $2 billion compared with the 2016 level, for a total of $34 billion. The National Science Foundation would remain steady at just under $7.5 billion, and NASA\u2019s budget would rise by about 2%, to $19.7 billion. And the Environmental Protection Agency, which Trump wants to cut by 31% in fiscal year 2018, would receive roughly $8.1 billion, a decrease of about 1% from 2016. \u201cFrom our perspective this is a great package, so we can put [fiscal year 2017] behind us and move on with our lives,\u201d says Jennifer Zeitzer, director of legislative relations at the Federation of American Societies for Experimental Biology in Bethesda, Maryland. \n             Let's make a deal \n             But that does not mean that scientists can breathe easily just yet: the largely positive 2017 deal does not necessarily indicate how Congress will handle funding for 2018, says Michael Lubell, a physicist at City College of New York in New York City. Lawmakers \u201chave a year to fall in line [with the president] if they want to\u201d, he says. Trump\u2019s 2018 budget request, released in March,  seeks an 18% cut for the NIH  and a 5.6% cut to the Department of Energy. It also proposes to eliminate  the Advanced Research Projects Agency-Energy (ARPA-E), which funds high-risk, high-reward research , along with a global-health research centre at the NIH and the Sea Grant education and research programme at the National Oceanic and Atmospheric Administration (NOAA). \n             Breaking down the budget \n           The 2017 deal formulated by Congress would fund the government until 30 September. Its provisions include: \u201cThis isn\u2019t anything like what the Trump administration had sought,\u201d says Matthew Hourihan, director of the research-and-development budget and policy programme at the American Association for the Advancement of Science in Washington DC. \u201cThis is clearly Congress reasserting its own priorities.\u201d The House of Representatives is expected to vote on the measure as early as 3 May, with the Senate to follow. Then lawmakers will turn their attention to plans for the 2018 budget year. The White House is expected to release a full budget request in late May that is likely to include the same massive cuts to civilian programmes, and increases for military spending, as the \u201cskinny budget\u201d it released in March.  \n                   Trump faces backlash on health-agency cuts 2017-Mar-17 \n                 \n                   US science agencies face deep cuts in Trump budget 2017-Mar-16 \n                 \n                   Trump and Republicans take aim at environmental agency 2017-Mar-10 \n                 \n                   US Earth scientists plan for uncertain future under Trump 2016-Dec-20 \n                 \n                   US science agencies face budget limbo 2016-Sep-06 \n                 \n                   Nature  special: Tracking the Trump White House \n                 \n                   2017 budget deal: legislative text \n                 \n                   2017 budget deal: legislative summary \n                 Reprints and Permissions"},
{"file_id": "545016a", "url": "https://www.nature.com/articles/545016a", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Scientists offer more detail on flagship programme to harness quantum effects in devices. As China and the United States threaten to corner the market on quantum technologies, Europe is slowly waking up to the opportunity with investment of its own. A year ago, the European Commission  announced that it would create a \u20ac1-billion (US$1.1-billion) research effort in the field , and it should start to invite grant applications later this year. But scientists coordinating the project say that they are already concerned because industry partners seem reluctant to invest. Members of an advisory group steering the Quantum Technology Flagship, as the project is called, gave details of how it will work at a meeting on 7 April at the Russian Centre of Science and Culture in London. The project aims to exploit the bizarre behaviour shown by quantum systems to develop new technologies, such as super-secure communication systems and miniature, ultra-accurate sensors. But the programme is playing catch-up. Many labs in rival regions are already developing quantum technologies, including at large firms such as Google and Microsoft. \u201cEurope cannot afford to miss this train,\u201d says Vladimir Buzek, a member of the advisory group and a physicist at the Research Center for Quantum Information of the Slovak Academy of Sciences in Bratislava. \u201cThe industry here, to my taste, is really waiting too long,\u201d he said at the meeting. Launched in April 2016 as part of an apparently unrelated initiative in cloud-computing, the quantum project is the European Commission\u2019s latest decade-long, billion-euro initiative. Yet, the two previous EU mega-projects\u00a0\u2014\u00a0the  Graphene Flagship  and the  Human Brain Project , both announced in 2013\u00a0\u2014\u00a0have yet to fully prove their value. The latter has been  plagued by disputes over its leadership . And both have had difficulty drumming up complementary investment from member states, says Tommaso Calarco, a physicist at the Centre for Integrated Quantum Science and Technology at the Universities of Ulm and Stuttgart in Germany, and another adviser on the steering committeee. The Quantum Technology Flagship will work differently, he says. Rather than run largely as a closed consortium selected at the project\u2019s outset, it will operate with open calls throughout. He says that this should ensure high levels of competition, and offer the flexibility to fund the best researchers throughout. And he hopes that it will encourage member states to invest nationally to make stronger bids for funding. Some European countries show signs of supporting the project. Hungary, Austria and Germany have all announced their own national quantum-technology programmes since the flagship\u2019s launch. The German initiative, called QUTEGA, is currently in a pilot form, but is likely to be worth around \u20ac300 million over 10 years. Initial projects include miniaturized magnetic sensors, which pick up tiny electric currents and could be used to monitor the brain during surgery, as well as small, transportable, high-precision atomic clocks, says Gerd Leuchs, a physicist at the Max Planck Institute for the Science of Light, Erlangen, and coordinator of the project. \n               Product potential \n             The European flagship will focus on four quantum technologies: communication, computing, sensing and simulation. It will also incorporate basic science. Although Europe produces some of the best research in these fields, other regions file more patents, says Martino Travagnin, who, along with his colleagues at the European Commission\u2019s Joint Research Centre in Ispra, Italy, has analysed patenting in quantum technologies. China currently dominates in quantum communication, which uses quantum properties of particles to develop shared secret keys for encryption. The country holds the most patents in the field and is already trialling both a  quantum-communication satellite  and a 2,000-kilometre secure  ground-based link . And the United States leads on patents in quantum computing and ultra-sensitive sensors. Companies are involved with the EU project, Buzek told the meeting, with 12 representatives on the expert group. \u201cBut industry seems like it\u2019s just waiting for what the academy is going to produce, and then at some point, it\u2019s willing to take the result,\u201d he said. Although EU companies might lack the cash to dive into quantum technologies, as their US counterparts have done, smaller companies could invest in producing crucial components, he said. \n               Brexit problems \n             One problem facing the quantum-flagship scheme is the possible loss of the United Kingdom, one of Europe\u2019s strongest research communities in quantum technology. (Following the Brexit vote, the United Kingdom is scheduled to leave the European Union in 2019, the year in which the first projects kick off.) The United Kingdom is one of the few nations to involve relevant companies in the research, Calarco points out, through its \u00a3350-million (US$450-million)  UK National Quantum Technologies Programme.  He hopes that the United Kingdom will be able to continue in some capacity\u00a0\u2014\u00a0either by paying into the European funding pot, as Switzerland does, or through a match-funding model. The timing of the project should also play in its favour, he notes. A UK government commitment to underwrite funding for existing EU projects means that the early years of investment will be guaranteed. The next round should start sufficiently long enough after the Brexit negotiation for a solution to have emerged. \u201cGiven the circumstances, this is the best timing we could imagine,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Chinese satellite is one giant step for the quantum internet 2016-Jul-27 \n                   \n                     Europe plans giant billion-euro quantum technologies project 2016-Apr-21 \n                   \n                     Physics: Unite to build a quantum Internet 2016-Apr-12 \n                   \n                     Troubled billion-euro Brain Project unlocks more funding 2015-Nov-02 \n                   \n                     Graphene booms in factories but lacks a killer app 2015-Jun-17 \n                   \n                     Four UK hubs to make 'spooky' quantum physics useful 2014-Dec-02 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21930", "url": "https://www.nature.com/articles/nature.2017.21930", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "US agency creates point system to address imbalance in distribution of research funds. For the first time, the US National Institutes of Health (NIH) will restrict the amount of funding that an individual scientist can hold at any one time, on the basis of a point system. The move,  announced on 2 May , is part of an ongoing effort to make obtaining grants easier for early- and mid-career scientists, who  face much tougher odds  than  their more-experienced colleagues . \u201cBecause scientific discovery is inherently unpredictable, there are reasons to believe that supporting more researchers working on a diversity of biomedical problems, rather than concentrating resources in a smaller number of labs, might maximize the number of important discoveries that can emerge from the science we support,\u201d NIH director Francis Collins wrote in a blogpost. In doing so, he added, the policy could improve \u201creturns on taxpayers\u2019 investments\u201d. According to the agency, just  10% of grant recipients win 40% of the agency\u2019s research money . Advocacy organizations and groups that advise the NIH director have been urging the agency to address this inequality for more than a decade. They are also concerned that increasing competition for grant money drives researchers to spend more time on paperwork and personnel issues associated with grants, and less time in the lab. The latest NIH policy does not set a hard limit on the number of grants or the dollar amount of funding that an individual researcher can receive \u2014 an acknowledgement that some topics are inherently more expensive than others to study. Rather, Collins says, the agency will introduce  a metric  called the Grant Support Index (GSI), which assigns a point value to each type of grant on the basis of its complexity and size. \n             Adding it up \n           Researchers will be limited to 21 points\u2019 worth of funding \u2014 the equivalent of three R01 grants, the most common type awarded to individuals \u2014 at a time. Researchers with more than 21 points who are seeking an extra grant will need to explain to the NIH how their existing grants can be adjusted to accommodate the new one and so stay under the point limit. Collins expects the policy to free up 1,600 new awards while affecting only 6% of NIH-funded investigators whose current grants would exceed the new limit. The NIH will determine how to implement the point system \u201cover the next few months\u201d, he says, after consulting its advisory councils and the broader scientific community. Howard Garrison, deputy executive director for policy at the Federation of American Societies for Experimental Biology in Bethesda, Maryland, welcomes the move. \u201cLooking at ways to fund more investigators is a healthy approach,\u201d he says. Yet he acknowledges that the policy is likely to be controversial. \u201cI think the people who are successful at writing grant applications are very talented people,\u201d he says. \u201cI don\u2019t think anyone will say they\u2019re not doing good work. But NIH has to look at the system as a whole.\u201d Sally Rockey, a former director of the NIH Office of Extramural Research, agrees. Often, she says, NIH reviewers give good rankings to grants from labs that have had funding for years to work on a particular subject, which may cause fresh ideas from upstart labs to be overlooked. \u201cIf you reach down to those you can take science in a whole new direction,\u201d says Rockey, who now directs the Foundation for Food and Agriculture Research in Washington DC. But she acknowledges that implementing the point limit is likely to be tricky. Scientists could theoretically game the system by collaborating on grants, rather than applying for them as individuals. And reviewers might balk at passing on a high-quality proposal because an applicant has reached the NIH limit, if the agency's objective is to fund the best science. \u201cTrying to deal with the optics of it all, I think, is really important,\u201d Rockey adds. \n             A better balance? \n           Several analyses  by NIH officials  and outside researchers 1 , 2  have shown that scientists\u2019 productivity increases with their funding \u2014 to a point.  Productivity tends to diminish  once a researcher receives grants of more than US$700,000 per year, according to an analysis by Jeremy Berg, former director of the NIH\u2019s National Institute of General Medical Sciences. The NIH has considered ways to address the issue in the past. In 2008, two agency advisory panels recommended that an investigator spend no less than 20% of his or her time on a given grant, which would limit the number of simultaneous grants a person could hold to five. But these recommendations were never implemented. Rockey says that the NIH would not be able to enforce the 20% limit because researchers could have funding from other sources. Instead, the agency introduced an extra layer of review in 2012 for grant applications from researchers who control more than $1 million in funding at any given time \u2014 about 5% of grant recipients when that policy was enacted. \n                   Young, talented and fed-up: scientists tell their stories 2016-Oct-26 \n                 \n                   Extra scrutiny for \u2018grandee grantees\u2019 2012-Feb-20 \n                 \n                   Mid-career crunch 2011-Mar-16 \n                 \n                   222 NIH grants: 22 researchers 2008-Mar-19 \n                 \n                   Nature  special: Young scientists \n                 \n                   NIH announcement \n                 Reprints and Permissions"},
{"file_id": "545017a", "url": "https://www.nature.com/articles/545017a", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Ketamine can ease depression in hours, but researchers might have misjudged how it works. The anaesthetic ketamine \u2014 a hallucinogenic club drug also known as Special\u00a0K \u2014 has tantalized researchers who are seeking new ways to treat depression. The drug  can lift a person\u2019s mood in hours , even when depression is severe. But several \u2018ketamine-like\u2019 medications have failed to alleviate depression in clinical trials over the past decade. Now, some researchers think they know why. Emerging evidence suggests that scientists have misunderstood how ketamine fights depression. So they might have attempted to mimic the wrong biological mechanism when designing drugs to improve mood while avoiding the disorienting ketamine high. On 20 May, researchers at a meeting of the Society of Biological Psychiatry in San Diego, California, will present results suggesting that some of ketamine\u2019s power comes from its ability to affect brain cells called glia, which support neurons. Their finding adds to recent studies contradicting a long-held idea that the drug works mainly by blocking proteins called NMDA receptors, on the surface of brain cells, which transmit signals between those cells. At the upcoming meeting, a team led by neuroscientist Mark Rasenick of the University of Illinois at Chicago will report on tests of antidepressant drugs in cultured rat glial cells. All of the drugs that the researchers studied caused a cluster of proteins to shift position in the glial cells\u2019 membranes, signalling to the cells to form new connections with their neighbours. But ketamine produced this effect in 15 minutes, as compared to 3 days for conventional antidepressants. Moreover, drugs that block NMDA receptors but are not antidepressants did not show the effect at all. This suggests that ketamine\u2019s ability to bind to NMDA receptors might not be its primary weapon against depression. Rasenick\u2019s team is not the first to suggest a different target for ketamine. A paper published in  Nature  in May 2016 concluded that one of ketamine\u2019s breakdown products \u2014 not the drug itself \u2014  probably lifted depression in mice 1 . And this compound affected cell proteins called AMPA receptors, instead of NMDA receptors. The team behind the study plans to test the breakdown product in clinical trials later this year. But study co-author Carlos Zarate, a psychiatrist at the US National Institute of Mental Health in Bethesda, Maryland, says that it is too early to abandon the NMDA-receptor hypothesis, and more data are needed. Others agree. \u201cWe have to be careful not to interpret [the latest] clinical findings as definitively negative,\u201d says Gerard Sanacora, a psychiatrist at Yale University in New Haven, Connecticut. Rodent studies have shown, for example, that blocking NMDA receptors can have an antidepressant effect 2 . And there could be more-prosaic explanations for why so many ketamine-like drugs that target NMDA receptors \u2014 including candidates from the drug giants Roche, Pfizer and AstraZeneca \u2014 have failed in clinical trials. Participants might have received doses that were too small or infrequent to buoy their moods. And in trials with control groups, the placebo effect can make it difficult to determine whether a psychiatric drug is working. \n               Ketamine copycats \n             Creating an effective substitute for ketamine remains the goal  for many researchers. Although a growing number of physicians prescribe ketamine for their patients, the drug must be administered intravenously. It can also produce disorienting \u2018out of body\u2019 feelings, and it has the potential for abuse. The companies that are still testing drugs to inhibit NMDA receptors are trying to make sense of the latest findings on ketamine and its would-be imitators. \u201cWe do need to tease all this apart,\u201d says David Nicholson, chief research-and-development officer at Allergan in Parsippany, New Jersey. In February, Allergan began treating around 500 people with a molecule called rapastinel, which binds to NMDA receptors and showed promising results in earlier trials. Yet, the most enduring mystery involves ketamine itself, as researchers try to untangle what makes the drug so potent. Alan Schatzberg, a psychiatrist at Stanford University in California suspects that ketamine could act against depression in many ways: jump-starting the process by some as-yet-unknown mechanism, perhaps, and then blocking NMDA receptors to permanently rewire the brain. Schatzberg also points out that ketamine can act similarly to morphine and rapidly bind to opioid receptors in the brain, which could explain why its effects are apparent within hours. And some studies have found that people with depression are more likely to benefit from ketamine if they do experience that out-of-body feeling, suggesting that it might be related to the drug\u2019s main mechanism 3 . In the meantime, the hunt continues for drugs that can replicate ketamine\u2019s mood-boosting power. That could be difficult, says Steven Levine, a psychiatrist and president of Ketamine Treatment Centers in New York City. \u201cKetamine is a dirty, dirty drug,\u201d he says. \u201cIt goes a lot of places, it does a lot of things.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Sara_Reardon \n               \n                     How club drug ketamine fights depression 2016-May-04 \n                   \n                     Rave drug holds promise for treating depression fast 2015-Jan-07 \n                   \n                     Club drug finds use as antidepressant 2006-Aug-07 \n                   \n                     Society of Biological Psychiatry\u2019s 72nd Annual Scientific Meeting \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21933", "url": "https://www.nature.com/articles/nature.2017.21933", "year": 2017, "authors": [{"name": "Sarah McQuate"}], "parsed_as_year": "2006_or_before", "body": "Sounds of traffic and industry invade over half of protected areas. Tourists who visit national parks and other protected areas in the United States hope to gain a respite from the sights and sounds of their everyday lives. But evading human soundscapes isn\u2019t easy. Many protected areas are surprisingly noisy, a new study finds, and that can interfere with more than just the peace and quiet visitors seek. Noise generated by humans \u2014 including that from development activities, traffic and the extraction of natural resources \u2014  threaten the survival  of plant and animal species across the country 1 , researchers report on 4 May in  Science . \u201cI was frankly shocked to learn how noisy humans have made some of the most remote places on the continent,\u201d says Charlie Zender, an atmospheric physicist at the University of California, Irvine, who was not involved in the research. \n             Noisy neighbours \n           To investigate the noise in protected areas, Rachel Buxton, an acoustic ecologist at Colorado State University in Fort Collins, and her team used data routinely collected by the US National Park Service (NPS) that map sound levels across the country. The information included over 1.5 million hours of recordings from 492 protected sites across the United States, such as city parks and remote areas. To determine how much noise came from human activity, the researchers made a background noise model that eliminated all potential sounds created by people, such as aeroplane or car noises. The researchers then compared their estimates of wild soundscape noise levels to the NPS maps, allowing them to determine the extent to which human-made sounds added to noise levels in the protected areas. This study \u201chas really put noise on the map\u201d, says Clinton Francis, an ecologist at California Polytechnic State University in San Luis Obispo, who was not involved with the study. Previous research has shown that  noise pollution affects the behaviour of animals , including how they search for food 2 , 3 . But this work is much wider in scope, looking at the breadth of sound exposure across the contiguous United States, Francis says. The researchers found that 63% of the protected areas were twice as loud as they should be. \u201cSo if you used to be able to hear a bird song at 100 feet [30 metres], now you could only hear it at 50 feet,\u201d Buxton says. Some areas were even louder: 21% were more than 10 times louder than background levels. In those regions, \u201cyou can only hear that bird at about 10 feet\u201d, she says. Many of these spaces are critical habitats for endangered species. The team found that sound levels were doubled compared to the background model in 58% of these environments, and that plants and invertebrates in these areas experience high noise levels. For plants, this happens through indirect effects such as the altered behaviour of pollinators, plant-eating species or animals that disperse seeds. \n             Managing magnificence \n           Francis would like to see follow-up studies looking at the impact of loud noise levels on species in protected areas. For instance, noise pollution is known to influence how animals disperse pi\u00f1on pine tree seeds in New Mexico 4 . There is some good news, however. About one-third of the protected areas the team analysed still had undisturbed natural soundscapes \u2014 which is good for the plants and animals in those areas, and can also have health benefits for people who visit 5 . And the researchers found that, overall, protected regions were often quieter than the unprotected spaces directly surrounding them. In addition, areas with the highest levels of protection, deemed \u2018wilderness areas\u2019, were the quietest. So  designating an expanse as protected  seems to keep the sound turned down. The researchers hope that their results can influence policy decisions to better manage sound in these spaces. But for now, \u201creally listen when you go to a park,\u201d says Buxton. \u201cListen to everything from just the flow of the river to these magnificent choruses of birds and bugling elk. Not only does that enhance your experience, it\u2019s important for your health.\u201d \n                   Marine life needs protection from noise pollution 2015-Sep-11 \n                 \n                   Conservation: A to-do list for the world's parks 2014-Nov-05 \n                 \n                   Electronics' noise disorients migratory birds 2014-May-07 \n                 \n                   Conservation biology: The end of the wild 2011-Jan-12 \n                 \n                   Frog serenade foiled 2009-Aug-25 \n                 Reprints and Permissions"},
{"file_id": "545014a", "url": "https://www.nature.com/articles/545014a", "year": 2017, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Ancient rock art research could piece together how the peoples who lived in the region some 5,700 years ago interacted. Scientists have directly dated Stone Age rock paintings in southern Africa reliably for the first time. Their work reveals that early hunter-gatherer peoples created art at three sites in the region, some 5,700 years ago (A. Bonneau  et al. Antiquity    91,  322\u2013333; 2017). And the findings open the door for archaeologists and other researchers to date thousands more rock paintings in this part of Africa \u2014 and so piece together the lives and development of ancient people there. The study focused on paintings in present-day Botswana, South Africa and Lesotho created by the San people, whose direct descendants still live in the area. The San have been much studied, but many mysteries remain about how they lived, and how they interacted with other groups \u2014 such as early farmers. \u201cIf we are able to date depictions of livestock and material goods associated with incoming groups, we may be able to start unravelling the nature of interactions between groups in this early contact,\u201d says David Pearce, an archaeologist and director of the Rock Art Institute at the University of the Witwatersrand in Johannesburg, South Africa, and a co-author of the latest study. Just under 2,000 years ago, Pearce says, pastoral and farming people independently arrived in South Africa, where they came into contact with hunter-gatherer groups such as the San. \u201cWe know relatively little about these groups because of the paucity of archaeology.\u201d Rock paintings show that these groups interacted, but, because the paintings were discovered at sites that contain no other artefacts, they have not been reliably dated. \u201cWhat we\u2019ve been doing previously existed out of time,\u201d says Pearce. He adds that, although \u201cwe know a lot about what the paintings mean\u201d, scientific techniques have not been widely applied to archaeological findings in the region. Many experts had assumed that the black paint used in African pictures was based on manganese compounds and that the rock art would therefore have contained too little carbon to be reliably dated, he says. As a result, techniques developed in Europe and elsewhere have not previously been applied in Africa. Yet southern African rock art is highly influential. \u201cIt was ethnographies of San bushmen art that provided many of the models for social interpretation of the art we still use today,\u201d says Alistair Pike, an archaeologist at the University of Southampton, UK, who was not involved in the research. And pictures left by the San and others could help researchers to put dates on other significant events, including the development of early religious rituals. Dating rock pictures is itself a tricky art. Extracting useful samples damages paintings, and it is hard to distinguish original materials from modern contaminants. Over the years, compounds that contain carbon build up on top of the pictures and interfere with radiocarbon dating. And it\u2019s not enough to know that a sample contains carbon: charcoal used in paint, for example, could pre-date a painting by centuries and so affect the result of the carbon tests. \n               Pigments of the imagination \n             \u201cWhile doing the characterization of the different paints, we realized that the San people used three different materials to make black paints: charcoal, soot and carbon-blacks, which are burnt fat or grease,\u201d says Adelphine Bonneau, a postdoctoral researcher at Laval University in Quebec, Canada, who is lead author on the study. Soot and carbon-blacks would have had to be produced a few hours before being used \u2014 and that meant they could be tested to give an accurate date. It was this fact that formed the basis of her team\u2019s multi-stage technique. First, Bonneau and her colleagues took tiny samples \u2014 less than one square millimetre \u2014 and determined their chemical composition. If they found testable carbon, the researchers took a larger sample. They cleaned away centuries of accumulated surface compounds such as calcium oxalate, which contaminate test results, and then carbon-dated the sample. Georges Sauvet, an archaeologist with the Emile Cartailhac Prehistoric Art Research and Study Center at the University of Toulouse-Jean Jaur\u00e8s in France, questioned the efficacy of the cleaning process, saying: \u201cThey seem to be reticent to show clearly that they have totally removed the calcium oxalate, and I don\u2019t know why.\u201d Pike welcomed the technique and the results, but warned that it might not be suitable for older sites with more organic contaminants. \u201cWere these paintings older, I would be more cautious in accepting these results,\u201d he says. But young sites made from similar materials could be dated using this method. \u201cI hope that the team are able to continue to provide dates for paintings in Africa,\u201d Pike adds. \u201cThe earliest forms of symbolic expression are known from Africa, so perhaps there are older paints in Africa that have yet to be found, or yet to be dated.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Archaeology: Unexpectedly early signs of Americans 2017-Apr-26 \n                   \n                     Prehistoric Native Americans farmed macaws in 'feather factories' 2017-Apr-10 \n                   \n                     Involve social scientists in defining the Anthropocene 2016-Dec-07 \n                   Reprints and Permissions"},
{"file_id": "545013a", "url": "https://www.nature.com/articles/545013a", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Alfredo Fusco denies claims that his research lab hired a photo studio to manipulate images. More than five years ago, Italian police began investigating allegations of research misconduct in papers by Alfredo Fusco, a prominent cancer scientist in Naples. Researchers frustrated by the case\u2019s slow progress have now told  Nature  that there is strong evidence that dozens of papers may contain manipulated data \u2014 and that a commercial photography studio was called in to cut and paste images. They say they are speaking out about the magnitude of the allegations because of their increasing impatience with the slow pace of investigations by police and by academic authorities. The failure to resolve the affair is harming Italian science, they say. Fusco, who works at the University of Naples,  has been under investigation since 2012 , when bioinformatician Enrico Bucci told police that several of Fusco\u2019s papers contained images of electrophoretic gels \u2014 used to separate molecules \u2014 in which sections seemed to have been cut and pasted to mimic the presence or absence of particular molecules. Since then, the catalogue of papers under suspicion has grown, and the Naples public prosecutor who is handling the case has told  Nature  that \u201cit is clear that some images have been manipulated\u201d. Stefania Buda says she still needs \u201csome more months\u201d to decide whether or not to launch criminal charges against Fusco. Data manipulation would not in itself be a criminal offence, say experts close to the investigation; a criminal charge would revolve around the alleged use of fraudulent data to acquire funding. Perhaps the most unusual allegation is that a local photographic studio was regularly asked to alter scientific images before publication, say scientists at the University of Naples who do not wish to be identified. This claim was first reported in 2013 in an Italian newspaper, after a police raid on Fusco\u2019s labs in which computers and lab books were confiscated. Meanwhile, Bucci, who now runs research-integrity consultancy Resis in Turin, Italy, has separately examined 380 papers co-authored by Fusco between 1985 and 2015, and says he now thinks that 95 of them contain manipulated figures. Fusco denies all these allegations. \u201cWe have not intentionally manipulated any publication,\u201d he told  Nature  in an e-mail. Although ten of his papers have already been retracted, and ten corrected, any image alterations that may have occurred in his papers were \u201cmistakes\u201d made as figures were assembled, Fusco says. \u201cI was not aware of it, since I do not participate in the assembling of the figures,\u201d he adds. The drawn-out nature of the investigation is particularly worrying for the Italian Association of Cancer Research (AIRC) in Milan, a charity that had been funding Fusco but suspended its grant payments four years ago after hearing about the investigation. \u201cThis is an issue of great concern and embarrassment to us,\u201d says Federico Caligaris-Cappio, the AIRC\u2019s scientific director. \u201cIt\u2019s important that these allegations are fully aired and finally resolved, one way or the other \u2014 so we can get certainty.\u201d Fusco previously held advisory positions with the AIRC, but as a result of the investigation he is now excluded from them. Since 2002, the AIRC has awarded him more than \u20ac4\u00a0million (US$4.4 million) in grants and stipends. \u201cOnce we have an answer from the court on whether or not any of the allegations are correct, we will discuss whether we want to try to reclaim any part of this money,\u201d says Caligaris-Cappio. \n               Naples investigation \n             Details of how the University of Naples has approached the affair also raise questions about Italian academia\u2019s oversight of misconduct allegations. Bucci says he went to police about Fusco\u2019s papers in 2012 because the university had no procedures for handling misconduct allegations. After newspaper reports about the resulting police raid, the university did set up an internal investigation committee in 2013. Its chair, Roberto Di Lauro, had himself co-authored papers with Fusco. The committee members examined nine of Fusco\u2019s publications. Their unpublished report, which  Nature  has seen, says that they saw no evidence of misconduct. It adds that the papers could not in any case have influenced grant decisions. But that report has been heavily criticized by an ethics committee of the Italian National Research Council (CNR), which the University of Naples asked to examine its investigation-committee procedures. In its own confidential report, which  Nature  has also seen, the CNR flags Di Lauro\u2019s apparent conflict of interest \u2014 he co-authored seven papers with Fusco before 1999 and two after 2011. It also criticizes the committee\u2019s decision to analyse images with the naked eye, instead of using commonly available software. And the report decries the apparent downplaying of any consequences of the claimed data manipulation. Di Lauro told  Nature  that he had disclosed his co-authorship to the internal committee, whose report indicates that members unanimously discounted it as a conflict of interest. He says the committee didn\u2019t use software to check the images so as to avoid unnecessary duplication of the ongoing police investigation. Gaetano Manfredi, rector of the University of Naples since 2014, says that once the outcome of the criminal investigation is known, he will initiate a new independent investigation into possible scientific misconduct. In the meantime, the university has decided that Fusco\u2019s papers must be approved by his department head before submission, he says. And the university has set up a system for investigating misconduct allegations. The entire saga \u201chas been damaging for the scientific community and for the institutions in Italy\u201d, says Gerry Melino, a cell biologist who was involved in the investigation, and who has positions at the University of Leicester, UK, and the University of Rome Tor Vergata. Melino is editor-in-chief of two journals that have retracted Fusco\u2019s papers. He says that the long wait for the affair to be resolved is making life difficult for many in the research community, particularly Fusco\u2019s co-authors. \u201cIt is in the general public interest to see this sad episode concluded one way or another.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alison_c_abbott \n               \n                     Problematic images found in 4% of biomedical papers 2016-Apr-22 \n                   \n                     Image search triggers Italian police probe 2013-Dec-04 \n                   \n                     Call the cops 2013-Dec-04 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21999", "url": "https://www.nature.com/articles/nature.2017.21999", "year": 2017, "authors": [{"name": "John McQuaid"}], "parsed_as_year": "2006_or_before", "body": "Critics say that changes to advisory groups at the Environmental Protection Agency and Department of Interior could restrict or paralyze them. An article by    Scientific American . The US Environmental Protection Agency (EPA) surprised many people in 2015 when it announced its scientists had found hydraulic fracturing for natural gas had no \u201cwidespread, systemic impacts\u201d on the nation\u2019s drinking water. Some independent studies had shown the opposite. The EPA\u2019s 47-member Science Advisory Board (SAB) \u2014 a panel of outside experts, mostly academics \u2014 studied the report\u2019s evidence and found it did not justify that rosy conclusion. As complaints mounted, the EPA changed the words, saying the language was not \u201cquantitatively supported\u201d and \u201cdid not clearly communicate the findings of the report\u201d. It turned out the phrases about little water impact had been added after a meeting at the White House with officials from the administration of President Barack Obama, which strongly backed the natural gas industry. Keeping agency science in line with the evidence is the principal job of this advisory group and hundreds of similar boards across the federal government. But this month, under President Donald Trump, that is changing. Administration officials began acting to reconfigure several boards to make them friendlier to industry, driven by the belief that current board scientists are too beholden to regulatory agencies. The EPA dismissed half of the 18 members of its Board of Scientific Counselors (BOSC). Members typically serve two three-year terms but these people had only served one. EPA administrator Scott Pruitt \u201cbelieves we should have people on this board who understand the impact of regulations on the regulated community\u201d, spokesman J. P. Freire told  The New York Times . For the larger SAB, Trump\u2019s proposed budget cuts its operating funds by 84%. In addition, the Department of the Interior announced last week it was reviewing the scope of 200 of its own advisory committees. More members from \u201cthe regulated community\u201d \u2014 chemical and energy companies and manufacturers \u2014 could prevent the committees from spotting problems such as the fracking report, says Robert Richardson, an ecological economist at Michigan State University in East Lansing who was one of the BOSC members let go. Or industry members could paralyze the boards, observers say, preventing them from making any decisions. \n             Clean slate? \n           Steven Milloy, who advised the Trump transition team at EPA, says he would like to see all boards \u201cflushed and restocked\u201d with new people. In addition to the nine cut BOSC members, four others retired after two terms. Eight of the departing group are university professors, three work for government agencies or laboratories, one works for a scientific foundation and one for an engineering consulting company. Until new members are appointed, the White House\u2019s strategy for the board will not be entirely clear. But the EPA and other agencies have  already launched aggressive efforts to roll back regulations  and  marginalize disciplines such as climate science . Even if new members do not swing the entire board in an anti-regulatory direction, they could simply prevent action, says Wendy Wagner, a professor at the University of Texas at Austin School of Law and co-author of the book  Bending Science: How Special Interests Corrupt Public Health Research  (Harvard University Press, 2012). Boards operate by consensus, debating scientific evidence and coming to agreement. \u201cIf the deck is stacked, and you have people appointed to represent certain views, it could just mean they end up blabbing at each other and nothing happens,\u201d Wagner says. Milloy, a longtime critic of environmental and health regulations who founded the website JunkScience.com, argues university scientists on the boards are just as compromised as any industry representative. He and other conservatives say receiving research grant money from the EPA is a corrupting influence. This is also the position taken by Representative Lamar Smith (Republican, Texas),  chair of the House of Representatives Committee on Science, Space and Technology , who this spring sponsored a bill disqualifying EPA grant recipients from serving on advisory committees. Although EPA ethics rules already prohibit scientists with current agency grants from being on these committees, even former grant recipients are pawns for the agency, Milloy and Smith claim. But no study has shown receiving EPA grants systematically influences scientists to produce skewed results, says Wagner, who has studied the academic literature on research and conflicts of interest. More generally, she and others note that although no organization is free of institutional biases, the EPA\u2019s scientific grant programs are rigorous and respected throughout the scientific community. Industry-funded research, meanwhile, has been used to deny dangers of well-established risks such as smoking and climate change. The conservative complaint about EPA science, Wagner says, \u201chas an Alice in Wonderland upside-down quality to it\u201d. \n             Outlook hazy \n           Legally, there is nothing to stop the Trump administration from appointing anybody it likes to agency science boards. The Federal Advisory Committee Act (FACA), which governs most of them, does not spell out qualifications for membership. (Some committees such as the EPA\u2019s Clean Air Scientific Advisory Committee are governed by their own statutes with stricter service rules.) \u201cAll FACA says is you need \u2018balanced representation'. It says nothing about conflicts of interest or scientific integrity,\u201d Wagner says. \u201cIf you wanted science advisory boards stripped down, with minimal constraints, anything goes, legally you could do that.\u201d Practically speaking, though, it is not that simple. The EPA ethics rules that bar scientists with grants from serving on these committees also prohibit panel members from industry from working on issues affecting their companies, says the current chair of the BOSC, Deborah Swackhamer, a professor of science, technology and public policy at the University of Minnesota in Minneapolis. That is because \u201cif there is a conflict of interest about your employer being a regulated entity like a chemical company, then it will be harder for the board to be considered independent if it is talking about the toxicity of chemicals,\u201d Swackhamer says. The rules have made it difficult to recruit board members from industry, she adds, and that explains the prevalence of university members. According to Wagner, it is unclear whether these conflict of interest rules can be easily eliminated, amended or ignored. Given the obstacles, a broad effort to stack advisory boards with industry representatives could simply go nowhere, says Granger Morgan, a professor of engineering and public policy at Carnegie Mellon University in Pittsburgh, Pennsylvania. Morgan is a former SAB member who was targeted for removal at the beginning of the Reagan administration in a move to make it more industry-friendly, mirroring the Trump efforts today. Morgan ultimately stayed on. \u201cThe reality was, nothing much happened,\u201d he says. \u201cThe SAB didn\u2019t meet much\u2026. They [Reagan officials] just didn\u2019t ask for advice.\u201d The controversy in creating more industry-friendly boards may make Trump appointees hesitate, he says. Andrew Rosenberg, a marine scientist and director of the Center for Science and Democracy at the Union of Concerned Scientists in Cambridge, Massachusetts, is more pessimistic. The EPA moves to dismiss board members may make good potential candidates think twice about joining, he says. \u201cYou\u2019re telling high-level, really accomplished scientists: \u2018We don\u2019t want you. We don\u2019t want to hear from you.\u2019 Well, why waste your time?\u201d This article was originally published by  Scientific American  on 16 May 2017. \n                   Science wins reprieve in US budget deal 2017-May-01 \n                 \n                   Republican scientists negotiate the Trump era 2017-Apr-18 \n                 \n                   How Trump plans to wipe out Obama-era climate rules 2017-Mar-28 \n                 \n                   US science agencies face deep cuts in Trump budget 2017-Mar-16 \n                 \n                   Trump and Republicans take aim at environmental agency 2017-Mar-10 \n                 \n                   Nature  special: Tracking the Trump White House \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21894", "url": "https://www.nature.com/articles/nature.2017.21894", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Money will be used to develop open-source platform and help put articles in web-friendly formats. BioRxiv, the hub for preliminary versions of biology research papers, has announced that it will begin receiving \u201csignificant\u201d financial support from the Chan Zuckerberg Initiative (CZI), a philanthropic effort  started by Facebook co-founder Mark Zuckerberg and his physician wife Priscilla Chan . The multi-year funding package \u2014 terms of which have not been disclosed \u2014 will pay for staff, technology development and other infrastructure at bioRxiv, says John Inglis, the executive director of Cold Spring Harbor Laboratory Press and co-founder of  the 3-year-old site , which posted its 10,000th manuscript last week. Chan and Zuckerberg created the CZI in 2015, and a year later made  a US$3-billion commitment  to support basic research with the aim of curing, preventing and managing \u201call disease\u201d in their children's lifetime. \u201cThey\u2019re interested in anything that accelerates the pace of research, and bioRxiv was on their radar from the beginning,\u201d says Inglis. At the top of Inglis\u2019s wish list is an automated tool to translate scientific papers posted to bioRxiv, often as word-processor files or PDF documents, into more web-friendly formats, such as XML. That would make papers more readable on smartphones and tablets, but also more amenable to text mining \u2014 an approach increasingly used in scientific analyses. Inglis intends to create application programming interfaces, or APIs, to make bioRxiv content more accessible to other software developers. He is also eager for bioRxiv to collaborate with a start-up acquired in January by the CZI called Meta, which uses artificial intelligence to probe the scientific literature. \n               Open-source software \n             BioRxiv currently relies on commercial software from HighWire Press. However, any software developed with CZI funding will be open source, says Inglis. And, he adds, \u201cwe are committed to moving toward an open-source platform\u201d for the rest of the site. That move would satisfy one of the requirements of a  central life-sciences preprint service , which has been called for by funders such as the US National Institutes of Health and the Wellcome Trust. Jessica Polka, director of ASAPbio, a grass-roots organization leading the charge for a central preprint site, welcomes news of the CZI investment. She says the deal between bioRxiv and the CZI will be a boon to the preprint ecosystem. \u201cWe share the same goals of promoting efficient and rapid scholarly communication,\u201d she says. \n                     Heavyweight funders back central site for life-sciences preprints 2017-Feb-13 \n                   \n                     'Riskiest ideas' win $50 million from Chan Zuckerberg Biohub 2017-Feb-08 \n                   \n                     When a preprint becomes the final paper 2017-Jan-20 \n                   \n                     Big biology projects warm up to preprints 2016-Nov-30 \n                   \n                     Facebook couple commits $3 billion to cure disease 2016-Sep-21 \n                   \n                     Biologists urged to hug a preprint 2016-Feb-16 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21817", "url": "https://www.nature.com/articles/nature.2017.21817", "year": 2017, "authors": [{"name": "Sarah McQuate"}], "parsed_as_year": "2006_or_before", "body": "Each scale on an ocellated lizard coordinates its colour with its neighbours. As adults, ocellated lizards ( Timon lepidus ) sport a convoluted pattern of black and green on their backs. Colour patterns aren\u2019t rare in animals, but the ocellated lizard develops its labyrinthine palette in an unusual way. Researchers found that some scales on the lizard\u2019s back change colour during the transformation from juvenile to adult after detecting the colour of neighbouring scales. The team described these scales as decision-making units in a study 1  published on 12 April in  Nature . A set of mathematical rules called  Turing equations  describes how many animals, including lizards, develop stripes or spots. The resulting 'Turing patterns' are continuous across the organism and are determined independently of other biological features, such as lizard scales. But the backs of adult ocellated lizards have a discrete pattern that is linked to individual scales. (The scales on this species are made of clear keratin, so the colours of the underlying skin shine through: each is either black or green.) \u201cThat\u2019s what makes the paper exciting,\u201d says systems biologist James Sharpe of the Centre for Genomic Regulation in Barcelona, Spain. \u201cBiology tends to be rather flexible and squishy, and this is digital and discrete.\u201d \n             Self-determination \n           To investigate this phenomenon, Michel Milinkovitch, a biophysicist at the University of Geneva in Switzerland, and his colleagues took high-resolution photographs of the backs of three male lizards. The researchers began when the animals were two weeks old and continued until the lizards were three or four years old. The team used the images to track the fates of about 5,000 hexagonal scales across the back of each reptile. As each lizard aged, the overall pattern on their backs went from brown with white spots to a convoluted pattern of green and black. Roughly 1,500 scales changed colour, such that green scales had four black and two green neighbours, whereas black scales had three black and three green neighbours. This \u2018mind the neighbours\u2019 behaviour reminded Milinkovitch of a process called a  cellular automaton . Cellular automatons, first described in terms of computer science, are self-replicating units that perform calculations. In ocellated lizards, this means that an individual scale sums up information from the ones around it \u2014 how many are black and how many are green \u2014 and makes a decision about its own colour. \u201cWe could have stopped there,\u201d says Milinkovitch. But he wondered why the lizards don\u2019t follow the Turing-pattern rules that govern the markings on most other animals. \n             Connecting the dots \n           To find out, the team focused on the lizards\u2019 skin cells. Lizards and fish have skin composed of various cell types that generate different colours. And researchers know that zebrafish skin cells, for example, interact with each other to establish Turing patterns. Milinkovitch and his team modelled the interactions between colour cells on the basis of equations derived from zebrafish data and compared their results to the patterns on the lizards\u2019 skin. They found that ocellated lizard skin is thick under each scale, which provides room for cells to interact. But between scales, the skin is thin, with less room for cells to connect. The decreased thickness limits the colour to within individual scales on the lizards\u2019 back. This suggests that animal skin bumpiness can disrupt a continuous Turing pattern. Researchers have shown that cellular automata can create larger Turing patterns, such as those seen on seashells, says Milinkovitch. But the latest study describes the first time that scientists have observed the opposite: small Turing patterns that feed into large cellular automata. The development of colour patterns in animals is usually described qualitatively, says Devi Stuart-Fox, an evolutionary biologist at the University of Melbourne in Australia. The ocellated lizard\u2019s patterning probably helps the animal to blend into its environment. \u201cBut when you can show that there are general mathematical principles that can describe biological processes,\u201d she says, \u201cit provides a nice conceptual framework to understand what\u2019s happening.\u201d Read the  related  News & Views . \n                   Deciphering the genes that give mammals their stripes and patterns 2016-Nov-02 \n                 \n                   Why lizards may inherit the Earth 2013-Dec-11 \n                 \n                   Snowflakes made easy 2004-Dec-31 \n                 \n                   Patterns shape ant cemeteries 2002-Jul-09 \n                 \n                   Pattern of life 2000-May-30 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21799", "url": "https://www.nature.com/articles/nature.2017.21799", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Real-time analysis of wireless communications data could improve weather forecasts around the world. Meteorologists have long struggled to forecast storms and flooding at the level of streets and neighborhoods, but they may soon make headway thanks to the spread of mobile-phone networks. This strategy relies on the physics of how water scatters and absorbs microwaves. In 2006, researchers demonstrated that they could  estimate how much precipitation was falling  in an area by comparing changes in the signal strength between communication towers 1 . Accessing the commercial signals of mobile-phone companies was a major stumbling block for researchers, however, and the field progressed slowly. That is changing now, enabling experiments across Europe and Africa. The technology now appears ready for primetime. It could lead to more precise flood warnings \u2014 and more accurate storm predictions if the new data are integrated into modern weather forecasting models. Proponents also hope to use this approach to expand modern weather services in developing countries. The  newest entry into this field  is ClimaCell, a start-up company in Boston, Massachusetts, that launched on 2 April. The 12-person firm says that it can integrate data from microwave signals and other weather observations to create more accurate short-term forecasts. It notes it can provide high-resolution, street-level weather forecasts three hours ahead, and will aim to provide a six-hour forecast within six months. The company has yet to make information on its system public or publish it in peer-reviewed journals. ClimaCell will start in the United States and other developed countries, but plans to move into developing countries including India later this year. \u201cThe signals are everywhere, so basically we want to cover the world,\u201d says Shimon Elkabetz, ClimaCell\u2019s chief executive and co-founder. \n               Coming online \n             But the fledgling company faces competition from researchers in Europe and Israel who have tested systems at multiple scales, including countries and cities, over the past several years. The scientists recently formed a consortium to advance the technology using open-source software. Coordinated by Aart Overeem, a hydrometeorologist at the Royal Netherlands Meteorological Institute in De Bilt, the group is seeking nearly \u20ac5 million (US$5.3 million) from the European Commission to create a prototype rainfall-monitoring system that could eventually be set up across Europe and Africa. \u201cThere is a lot of evidence that this technology works, but we still need to test it in more regions with large data sets and different networks,\u201d Overeem says. Although ClimaCell has made bold claims about its programme, Overeem says he cannot properly review the company's technology without access to more data. \u201cThe fact that a start-up company and commercial investors are willing to put money into this technology is good news, but I believe there is room for all,\u201d says Hagit Messer, an electrical engineer at Tel Aviv University in Israel, who led the 2006 study. She is part of the research consortium led by Overeem. Previous projects by members of the consortium that tested the technology have met with success. In 2012, for instance, Overeem and his colleagues showed that the technology could be applied at the country level using commercial microwave data in the Netherlands 2 . And in 2015, the Swedish Meteorological and Hydrological Institute (SMHI), headquartered in Norrk\u00f6ping, launched a prototype real-time \u2018microweather\u2019 project in Gothenburg. It collects around 6 million measurements in the city each day in partnership with the telecommunications company Ericsson and a cellular tower operator. The result is a minute-by-minute estimate of rainfall on a 500-metre-resolution map that encompasses the city.\u00a0 \n               A brave new world \n             Jafet Andersson, an SMHI hydrologist, says that the project has helped to advance the technology. For example, he notes that microwave data often overestimate rainfall by as much as 200\u2013300%. But the team has worked out how to correct for that bias without relying on reference measurements from rain gauges or ground-based radar. This will make it easier to extend the technology to developing countries. \u201cIt will take some time, but we are in the process of industrializing it on a country scale, or even a global scale,\u201d Andersson says. Researchers with the consortium have deployed the technique in African countries that do not have access to ground-based radar and extensive rain-gauge networks. A team led by Marielle Gosset, a hydrologist at the French Institute for Development Research in Toulouse, demonstrated a proof-of-concept system in Burkina Faso 3  in 2012 and has since branched out to other countries including Niger. Working with French telecoms giant Orange, and with funding from the World Bank and the United Nations, her team hopes to expand into Morocco and begin using real-time microwave data in Cameroon this year. The technology is attracting interest in Africa because conventional weather-monitoring systems such as radar are too expensive, Gosset says. Weather forecasts based on microwave signals give developing countries a similar system, but for less money, she says. Access to commercial data is getting easier, too. Researchers say that telecommunication companies are beginning to see the value of releasing the data, and the consortium plans to create a central repository for processing the information. Project scientists hope to create a model that will enable a smooth partnership with the industry.  \u201cI think that this door is just about to open,\u201d says Andersson.\u00a0 \n                     Race to provide commercial weather data heats up 2017-Feb-01 \n                   \n                     Quest for climate-proof farms 2015-Jul-21 \n                   \n                     Climate-adaptation effort cuts hunger in African villages 2015-Mar-13 \n                   \n                     Microsatellites aim to fill weather-data gap 2012-Nov-28 \n                   \n                     Insuring against climate 2009-Jul-22 \n                   \n                     UN Global Partnership for Sustainable Development Data. \n                   \n                     Swedish Meteorological and hydrological institute microweather project \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21770", "url": "https://www.nature.com/articles/nature.2017.21770", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "The gut microbes of young killifish can extend the lifespans of older fish \u2013 hinting at the microbiome\u2019s role in ageing. It may not be the most appetizing way to extend life, but researchers have shown for the first time that older fish live longer after they consumed microbes from the poo of younger fish. The findings were posted to the bioRxiv.org preprint server on 27 March 1  by Dario Valenzano, a geneticist at the Max Planck Institute for Biology of Ageing in Cologne, Germany, and his colleagues. So-called \u2018young blood\u2019 experiments that  join the circulatory systems of two rats  \u2014 one young and the other old \u2014 have found that factors coursing through the veins of young rodents can improve the health and longevity of older animals. But the new first-of-its-kind study examined the effects of 'transplanting' gut microbiomes on longevity. \u201cThe paper is quite stunning. It\u2019s very well done,\u201d says Heinrich Jasper, a developmental biologist and geneticist at the Buck Institute for Research on Aging in Novato, California, who anticipates that scientists will test whether such microbiome transplants can extend lifespan in other animals. Life is fleeting for killifish, one of the shortest-lived vertebrates on Earth: the fish hits sexual maturity at three weeks old and dies within a few months. The  turquoise killifish  ( Nothobranchius furzeri ) that Valenzano and his colleagues studied in the lab inhabits ephemeral ponds that form during rainy seasons in Mozambique and Zimbabwe. Previous studies have hinted at a link between the microbiome and ageing in a range of animals. As they age, humans 2  and mice 3  tend to lose some of the diversity in their microbiomes, developing a more uniform community of gut microbes, with once-rare and pathogenic species rising to dominance in older individuals 4 . The same pattern holds true in killifish, whose gut microbiomes at a young age are nearly as diverse as those of mice and humans, says Valenzano. \u201cYou can really tell whether a fish is young or old based on its gut microbiota.\u201d \n               Faecal snacks \n             To test whether the changes in the microbiome had a role in ageing, Valenzano\u2019s team \u2018transplanted\u2019 the gut microbes from 6-week-old killifish into middle-aged 9.5-week-old fish. They first treated the middle-aged fish with antibiotics to clear out their gut flora, then placed them in a sterile aquarium containing the gut contents of young fish for 12 hours. Killifish don\u2019t usually eat faeces, Valenzano notes, but they would probe and bite at the gut contents to see whether it was food, ingesting microbes in the process. The transplanted microbes successfully recolonized the guts of the fish that received them, the team found. At 16 weeks of age, the gut microbiomes of middle-aged fish that received 'young microbes' still resembled those of 6-week-old fish.  The young microbiome \u2018transplant\u2019 also had dramatic effects on the longevity of fish that got them: their median lifespans were 41% longer than fish exposed to microbes from middle-aged animals, and 37% longer than fish that received no treatment (antibiotics alone also lengthened lifespan, but to a lesser extent). And at 16 weeks \u2014 old age, by killifish standards \u2014 the individuals that received young gut microbes darted around their tanks more frequently than other elderly fish, with activity levels more like 6-week-old fish. By contrast, gut microbes from older fish had no effect on the lifespans of younger fish, Valenzano and his team report. \n               Immune system effects \n             Exactly how microbes influence lifespan is hazy, Valenzano says. One possibility is that immune systems wear out with age, allowing harmful microbes to out-compete more beneficial bacteria. A microbiome transplant might, then, reset a middle-aged fish\u2019s microbiome. Components of a more youthful microbiome could also promote longevity by somehow influencing the functioning of the immune system itself, Valenzano adds. \u201cThe challenge with all of these experiments is going to be to dissect the mechanism,\u201d says Jasper. \u201cI expect it will be very complex.\u201d His laboratory is attempting microbiome swaps in differently aged fruit flies to test the impact on lifespan. Robert Beiko, a bioinformatician who studies microbial communities at Dalhousie University in Halifax, Canada, hopes to get funding to see whether microbiome swaps influence ageing in mice, too. He also wonders whether an individual\u2019s own microbiome, sampled and preserved early in life, can extend its lifespan when reintroduced later. In humans, faecal transplants  can help to treat some recurring infections , but Valenzano says it is far too early to consider the procedure for life extension. \u201cI wouldn\u2019t go that far. This is really early evidence that this has a potential positive effect.\u201d \n                     Scientists swab C-section babies with mothers' microbes 2016-Feb-01 \n                   \n                     Short-lived fish may hold clues to human ageing 2015-Dec-03 \n                   \n                     Microbiology: Microbiome science needs a healthy dose of scepticism 2014-Aug-20 \n                   \n                     Microbiome therapy gains market traction 2014-May-13 \n                   Reprints and Permissions"},
{"file_id": "544145a", "url": "https://www.nature.com/articles/544145a", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Fermilab experiment to measure muon magnetic moment more precisely might reveal unknown virtual particles. In the search for new physics, experiments based on high-energy collisions inside massive atom smashers are coming up empty-handed. So physicists are putting their faith in more-precise methods: less crash-and-grab and more watching-ways-of-wobbling. Next month, researchers in the United States will turn on one such experiment. It will make a super-accurate measurement of the way that muons, heavy cousins of electrons, behave in a magnetic field. And it could provide evidence of the existence of entirely new particles. The particles hunted by the new experiment, at the Fermi National Laboratory in Batavia, Illinois, comprise part of the virtual soup that surrounds and interacts with all forms of matter. Quantum theory says that short-lived virtual particles constantly \u2018blip\u2019 in and out of existence. Physicists already account for the effects of known virtual particles, such as photons and quarks. But the virtual soup might have mysterious, and as yet unidentified, ingredients. And muons could be particularly sensitive to them. The new Muon g\u22122 experiment will measure this sensitivity with unparalleled precision. And in doing so, it will reanalyse a muon anomaly that has puzzled physicists for more than a decade. If the experiment confirms that the anomaly is real, then the most likely explanation is that it is caused by virtual particles that do not appear in the existing physics playbook\u00a0\u2014 the standard model. \u201cIt would be the first direct evidence of not only physics beyond the standard model, but of entirely new particles,\u201d says Dominik St\u00f6ckinger, a theorist at the Technical University of Dresden, Germany, and a member of the Muon g\u22122 collaboration. Physicists are crying out for a successor to the standard model\u00a0\u2014\u00a0a theory that has been fantastically successful yet is known to be incomplete because it fails to account for many phenomena, such as the existence of dark matter. Experiments at the Large Hadron Collider (LHC) at CERN, Europe\u2019s particle-physics lab near Geneva, Switzerland, have not revealed a specific chink, despite performing above expectation and carrying out hundreds of searches for physics beyond the standard model. The muon anomaly is one of only a handful of leads that physicists have. Measurements of the muon\u2019s magnetic moment\u00a0\u2014\u00a0a fundamental property that relates to the particle\u2019s inherent magnetism\u00a0\u2014\u00a0could hold the key, because it is tweaked by interactions with virtual particles. When last measured 15\u00a0years ago at the Brookhaven National Laboratory in New York, the muon\u2019s magnetic moment was larger than theory predicts. Physicists think that interaction with unknown particles, perhaps those envisaged by a theory called supersymmetry, might have caused this anomaly. Other possible explanations are a statistical fluke, or a flaw in the theorists\u1fbd standard-model calculation, which combines the complex effects of known particles. But that is becoming less likely, says St\u00f6ckinger, who says that new calculation methods and experimental cross-checks make the theoretical side much more robust than it was 15\u00a0years ago. \u201cWith this tantalizing result from Brookhaven, you really have to do a better experiment,\u201d says Lee Roberts, a physicist at Boston University in Massachusetts, who is joint leader of the Muon g\u22122 experiment. The Fermilab set-up will use 20 times the number of muons used in the Brookhaven experiment to shrink uncertainty by a factor of 4. \u201cIf we agree, but with much smaller error, that will show definitively that there\u2019s some particle that hasn\u2019t been observed anywhere else,\u201d he says. To probe the muons, Fermilab physicists will inject the particles into a magnetic field contained in a ring some 14 metres across. Each particle has a magnetic property called spin, which is analogous to Earth spinning on its axis. As the muons travel around the ring at close to the speed of light, their axes of rotation wobble in the field, like off-kilter spinning tops. Combining this precession rate with a measurement of the magnetic field gives the particles\u2019 magnetic moment. Since the Brookhaven result, some popular explanations for the anomaly\u00a0\u2014\u00a0including effects of hypothetical dark photons\u00a0\u2014\u00a0seem to have been ruled out by other experiments, says St\u00f6ckinger. \u201cBut if you look at the whole range of scenarios for physics beyond the standard model, there are many possibilities.\u201d Although a positive result would give little indication of exactly what the new particles are, it would provide clues to how other experiments might pin them down. If the relatively large Brookhaven discrepancy is maintained, it can only come from relatively light particles, which should be within reach of the LHC, says St\u00f6ckinger, even if they interact so rarely that it takes years for them to emerge. Indeed, the desire to build on previous findings is so strong that to avoid possible bias, Fermilab experimenters will process their incoming results \u2018blind\u2019 and apply a different offset to each of two measurements that combine to give the magnetic moment. Only once the offsets are revealed will anyone know whether they have proof of new particles hiding in the quantum soup. \u201cUntil then nobody knows what the answer is,\u201d says Roberts. \u201cIt will be an exciting moment.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Physicists hunt for dark forces 2012-Apr-03 \n                   \n                     Particle physics: Two is the magic number 2004-Feb-19 \n                   \n                     Particle physics: Precision precession 2001-Mar-01 \n                   \n                     Muon g\u22122 experiment \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21818", "url": "https://www.nature.com/articles/nature.2017.21818", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "The goal is to compare these engineered organs to animal models, with an eye towards replacing animal testing. The US Food and Drug Administration (FDA) has started testing whether livers-on-a-chip \u2014 miniature models of human organs engineered to mimic biological functions \u2014 can reliably model human reactions to food and food-borne illnesses. The experiments will help the agency to determine whether companies can substitute chip data for animal data when applying for the approval of a new compound, such as a food additive, that could prove toxic. It is the first time that a regulatory agency anywhere in the world has pursued organs-on-chips as an alternative to animal testing. Suzanne Fitzpatrick, senior adviser for toxicology in the food-safety division of the FDA, announced the move on 11 April in a blog post. Although the chips were designed for testing drugs, Fitzpatrick\u2019s division wants to use them to see how individual organs process products such as dietary supplements and cosmetics. They will also be able to test how food-borne pathogens affect specific organs. FDA food-safety scientists will first evaluate the human-liver chip, before moving on to kidney, lung and intestine models. The chips are made by Emulate, a biotechnology company in Boston, Massachusetts. The miniature organs contain multiple types of human liver cells grown on a scaffold, and continuously pump a blood-like fluid through the system to deliver nutrients and remove waste. Emulate chief executive Geraldine Hamilton says that they can also add immune system components to the chip to test how it affects liver metabolism. \n             A long way to go \n           \u201cI'm excited that people are willing to try this new technology out,\u201d says Lawrence Vernetti, a toxicologist at the University of Pittsburgh in Pennsylvania, who is developing a different kind of liver-on-a-chip. Some aspects of animal metabolism are markedly different from humans: chocolate, for instance, is toxic to dogs. Although animals are usually good models for predicting toxicity issues in humans, he says, they are not fool-proof. If the long-term goal is to reduce the number of animals used for testing, \u201cwe have to come up with a system where regulators in science will trust the answers that will come out of it\u201d, Vernetti says. Vernetti says that he is surprised by how quickly regulators have begun testing the devices, but he says that the decision is timely because of increasing pressure from the public to minimize the use of animals in research. In 2013, for instance, the European Union banned the sale of cosmetics that have been tested on animals. \u201cYou just can\u2019t stop testing these things \u2014 you have to give an alternative,\u201d Vernetti says. \u201cThese human-on-chip devices might be a nice answer.\u201d The announcement is a victory for animal-rights activists. \u201cAnimals don\u2019t have to suffer through poisoning tests to improve health care for humans, and we\u2019re thrilled that the FDA is taking action,\u201d says Kathy Guillermo, senior vice-president of People for the Ethical Treatment of Animals (PETA) in Norfolk, Virginia, in a statement to  Nature . Still, it will be some time before organs-on-chips replace animal testing entirely. Hamilton points out that even if the human-liver chip processes a toxin without incident, there could be unforeseen effects on other organs, such as the heart. Although researchers are working towards ways to link as many as ten chips together, eliminating animal research entirely \u201cis not in our sights right now\u201d, Hamilton says. \u201cWe have a lot to do between now and then.\u201d \n                   The boom in mini stomachs, brains, breasts, kidneys and more 2015-Jul-29 \n                 \n                   \u2018Organs-on-chips\u2019 go mainstream 2015-Jul-15 \n                 \n                   Biodefence researchers seek 'Homo chippiens' 2015-Feb-17 \n                 \n                   FDA Voice: \u2018Organs-on-Chips\u2019 Technology: FDA Testing Groundbreaking Science \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21839", "url": "https://www.nature.com/articles/nature.2017.21839", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Male scientists in the United Kingdom report teaching less than their female counterparts, while women and minorities tend to feel disadvantaged in their careers. Female academics report spending more time on teaching and public-engagement tasks, and less time on research, than their male counterparts, according to a survey of UK university staff in science-based subjects. The study of 2,495 male and 2,374 female academics at 43 UK institutions, published by the London-based charity Equality Challenge Unit (ECU) on 5 April, found that the gender difference was small but statistically significant. This was the case even when the effects of factors such as age, seniority and contract type were accounted for. The finding echoes past research, which found that teaching and non-research-related administrative tasks have a greater impact on women\u2019s careers than men\u2019s, says Elizabeth Pollitzer, director of Portia, a non-profit organization in London that seeks to address gender issues in science. If men spend more time on research, this could improve their career prospects when research productivity is used as a proxy for scientific merit, \u201cwhich is nearly always\u201d, says Pollitzer. It could also help to explain why many bibliometric studies have reported lower research productivity for women than for men, she adds. In interviews following up on the survey, academics suggested that women\u2019s increased focus on teaching and public engagement might put them at a disadvantage, not only because these activities take time away from research, but also because they carry less academic prestige. Time allocation was self-reported, so it may not accurately reflect real workload, says Meg Urry, an astronomer at Yale University in New Haven, Connecticut, and an advocate for women\u2019s advancement in science. The results could instead reflect the fact that women, more than men, place a high priority on teaching, says Urry. But no one knows what balance of teaching and research is best for science overall, she adds. The report recommends that institutions examine whether there is a gender difference in how responsibilities are allocated within departments and examine whether their current workload allocation systems are benefiting all staff. The authors also recommend that promotion criteria should include performance in teaching and other non-research academic areas. \n             Promotion bias \n           Significant differences emerged in men and women\u2019s perceptions of how much support and encouragement they receive. Women were more likely to report that men have better access to professional development, such as mentoring, than women have, and that men receive more invitations to conferences. Men tended to see no such advantage for themselves. Similarly, almost half of men \u2014 47.3% \u2014 believed that neither gender found it easier to obtain a senior post; just 23% of women agreed. Meanwhile, 59.7% of men reported that they had been encouraged or invited to apply for a promotion or a higher-grade job, compared with 48.8% of female respondents. Academics who belong to more than one minority group, reported being at the greatest disadvantage. Black or minority-ethnic women were the least likely to be in a senior position, such as the head of their school, division or department, and also the least likely to report having been formally invited for promotion or encouraged to undertake activities that would develop their careers. The survey is the first in the long-standing Athena Survey of Science, Engineering and Technology (ASSET) series to describe how gender and four other characteristics \u2014 ethnicity, sexual orientation, disability and age \u2014 intersect. \u201cThe survey shows clearly the heavier impact of multiple categories of disadvantage,\u201d says Urry. \u201cWomen do worse than men, people of colour do worse than white people and women of colour get a double whammy. Ditto with respect to the LGBTQ community, the disabled and other minority groups.\u201d \n                   Equality Challege Unit\u2019s ASSET 2016 report \n                 Reprints and Permissions"},
{"file_id": "544149a", "url": "https://www.nature.com/articles/544149a", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "NASA\u2019s Cassini probe will go where no spacecraft has gone before \u2014 between a planet and its rings. After 13 years  exploring Saturn and its moons , NASA\u2019s Cassini spacecraft has just 5 months left to live. But it will go out with a scientific bang. On 22 April, Cassini will slingshot past Titan, Saturn\u2019s largest moon, for the last time. Four days later, the probe will hurtle into the unexplored region between the giant planet and its rings. Cassini will thread that 2,400-kilometre-wide gap 22 times before its kamikaze dive into Saturn\u2019s atmosphere on 15 September. This unprecedented journey promises to yield fresh discoveries for the venerable spacecraft. \u201cIt will be like a whole new mission,\u201d says Linda Spilker, Cassini\u2019s project scientist at NASA\u2019s Jet Propulsion Laboratory (JPL) in Pasadena, California. \u201cThere are fundamental new scientific measurements to make.\u201d Those include the first direct tastes of particles in Saturn\u2019s rings, and of its upper atmosphere; the best measurements yet of the planet\u2019s magnetic and gravitational fields, which could answer long-standing questions such as how fast the planet rotates and  how old its rings are ; and the sharpest look yet at the inner rings. It all begins with the spacecraft\u2019s final fly-by of Titan, the 127th such close encounter. Cassini will scan the moon\u2019s methane lakes one last time, looking for waves, bubbles or other phenomena roiling the surface. Earlier fly-bys have revealed changes in the lakes over time, and the final pass is the last chance to look for seasonal shifts, says Sarah H\u00f6rst, a planetary scientist at Johns Hopkins University in Baltimore, Maryland. Titan\u2019s gravitational pull will fling Cassini into its \u2018grand finale\u2019 orbits, plunging between Saturn\u2019s innermost ring and the planet\u2019s cloud tops (see \u2018Cassini: the final frontier\u2019). The spacecraft will turn its main antenna forward, to act as a protective shield against any errant ring particles as it whizzes along at 110,000 kilometres per hour.\u00a0 Since November, the probe has been climbing higher relative to Saturn\u2019s equatorial plane, providing a new vantage point on the planet\u2019s outer rings. The upcoming inner dives will also reveal spectacular new details, says Carolyn Porco, a planetary scientist at the University of California, Berkeley, who leads the mission\u2019s imaging team.  High-resolution photographs have captured mysterious propeller-shaped gaps that ripple through some of the farther-out rings, probably formed by unseen moonlets. \u201cThe rings really are changing before our eyes,\u201d says Jeffrey Cuzzi, a planetary scientist at NASA\u2019s Ames Research Center in Moffett Field, California. Cassini\u2019s remote-sensing instruments will get their closest look yet at the rings, on sides both lit and unlit by the Sun. Measurements will show how the chemical make-up of the ring particles varies from place to place \u2014 information that is crucial for researchers who are trying to tease out which compounds pollute the rings\u2019 otherwise pure ice. And scientists might finally unravel the rings\u2019 biggest mystery \u2014  how old they are and how they formed . Between May and July, Cassini will make its most precise measurements of Saturn\u2019s gravitational field; by tracking the spacecraft\u2019s motion as it flies between the planet and the rings, mission scientists expect to improve their calculations of the mass of the rings by an order of magnitude. A relatively high mass would suggest that the rings were ancient, perhaps formed by a big moon ripped apart billions of years ago. Lighter-weight rings would suggest a more recent formation, perhaps from a visiting comet that disintegrated. Other fundamental measurements will tackle the giant planet itself. On the grand-finale orbits, Cassini\u2019s magnetometer will measure Saturn\u2019s magnetic field close to the planet. There, it is roughly ten times stronger \u2014 and more complex and scientifically interesting \u2014 than in areas already probed, says Marcia Burton, a planetary scientist at JPL. Those data should shed light on long-standing mysteries such as the depth of Saturn\u2019s metallic hydrogen core \u2014 which powers its magnetic field \u2014 and how quickly the planet rotates. Observations by the Voyager spacecraft in the 1980s suggested that one rotation takes just under 11 hours. But the numbers are different when measured in the northern and southern hemispheres, which hints that something more complicated is going on. \u201cIt is hard to imagine how the grand-finale orbits could not lead to a huge improvement in our understanding of Saturn\u2019s magnetic field,\u201d Burton says. On 15 September, with its tanks almost out of fuel, mission controllers will steer Cassini directly into Saturn. But the craft will still radio back observations of the gases that make up Saturn\u2019s atmosphere. \u201cEven in its final moments, Cassini will be doing groundbreaking science,\u201d says H\u00f6rst. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     Dust reveals ancient origin for Saturn's rings 2014-Aug-19 \n                   \n                     First hints of waves on Titan's seas 2014-Mar-17 \n                   \n                     Saturn's rings formed by destruction of giant moon 2010-Oct-05 \n                   \n                     Blog post: Cassini probe captures view of Earth from Saturn \n                   \n                     Cassini mission \n                   Reprints and Permissions"},
{"file_id": "544148a", "url": "https://www.nature.com/articles/544148a", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "The lasting effects of stress and fear of deportation are beginning to emerge. Alondra Garcia will never forget the day that US immigration officers tore apart her family\u2019s house in Ann Arbor, Michigan, looking for her stepfather\u2019s passport. She was 11 years old. One of the intruders dangled his handcuffs in front of her face, saying, \u201cIf I feel like it, I can handcuff your mom right now and you\u2019ll stay by yourself.\u201d Garcia and her mother were undocumented immigrants from Mexico; her stepfather, a Honduran who was also in the United States illegally, was detained that day and later deported. For months, Garcia shivered every time she heard a knock at the door. Now, at 18, she worries about what would happen to her younger brother if the government sent her mother back to Mexico. US President Donald Trump  has pledged to crack down on illegal immigration  by deporting more people. As a result, Garcia says, \u201cI\u2019m scared of everywhere right now.\u201d Her story is not uncommon. More than 2.7\u00a0million undocumented immigrants were deported during former president Barack Obama\u2019s first seven years in office. But Trump\u2019s plans to tighten US border controls have exacerbated the fear and uncertainty felt by many immigrants and their families. Researchers are only beginning to understand the long-term mental and physical damage wrought by such stress \u2014 especially for children. \u201cProlonged exposure to serious stress \u2014 known as toxic stress \u2014 can harm the developing brain and negatively impact short- and long-term health,\u201d the American Academy of Pediatrics warned in January, after Trump signed an executive order directing the government to hire thousands of extra immigration and border-patrol agents and to deport more people who are undocumented. \u201cThe message these [immigrant] children received today from the highest levels of our federal government exacerbates that fear and anxiety,\u201d the academy said. Some research suggests that children of immigrants begin to feel the harmful effects of stress even before they are born. In 2008, nearly 900 US immigration agents raided a meat-processing plant in Postville, Iowa, a small town with a large Latino population. They arrested almost 400 undocumented workers on charges of identity theft and fraud, and ultimately deported about 300 of them. When Nicole Novak, an epidemiologist at the University of Michigan in Ann Arbor, and her colleagues examined the birth certificates of more than 52,000 Iowa children, they found 1 that Latina mothers across the state were 24% more likely to give birth to undersized babies in the year after the raid than in the year before. The weight of non-Latino white babies stayed constant, suggesting that Latino populations were uniquely stressed by the incident. \u201cThese are women giving birth to US citizens, and this [stress] will impact their health and life chances,\u201d says Kate Strully, a medical sociologist at the State University of New York at Albany. Low birth weight is associated with developmental delays, behavioural problems and an increased risk of chronic disease. And some studies suggest 2  that extreme stress  can alter a child\u2019s DNA in ways that change gene expression  and  can be passed down to future generations . Strully and her colleagues are now examining millions of birth certificates nationwide to learn whether similar birth-weight patterns emerge when individual states enact laws targeting undocumented immigrants. Arizona, for instance, permits police officers to check the immigration status of people they stop, detain or arrest. For some researchers, the topic is personal. At the University of New Mexico in Albuquerque, undocumented students are recording the emotional and mental challenges of immigrants in their own communities. \u201cThis is for undocumented students to give something back,\u201d says Josue De Luna Navarro, a team leader who is studying engineering. Like his collaborators, he has a legal status known as deferred action for childhood arrivals (DACA), which gives temporary residency to people who entered the United States illegally as kids. \u201cWe\u2019re always in fight or flight mode,\u201d De Luna Navarro says. \u201cWe never really get a moment to just breathe.\u201d Beyond the fear of deportation, DACA students must cope with being ineligible for federal financial aid, loans and some jobs. Still, direct research on undocumented people remains difficult. For ethical reasons, most researchers do not ask study participants about their citizenship status, and many immigrants hesitate to seek medical care or register with the government, which limits relevant public data. But circumstances sometimes provide natural experiments. In 2013, US government immigration agents conducted raids in Washtenaw County, Michigan, where social scientist William Lopez was running a health study. The 151 people who answered the survey after the raids reported worse general health than the 325 who had already completed it, says Lopez, of the University of Michigan. Many said that after the raids, they were too afraid to leave their homes for food or medical care, and displayed symptoms of post-traumatic stress disorder 3 . Some researchers worry that Trump\u2019s crackdown could also disrupt long-running studies of immigrant health, such as one in central California run by the University of California, Berkeley. For 17\u00a0years, the programme has followed 600\u00a0children of farmworkers, most of whom are Mexican and many of whom are probably not legal residents, says study leader Brenda Eskenazi, a neuropsychologist at Berkeley. In the past year, the researchers have for the first time added questions about fear of deportation to their interviews. They have also begun distributing brochures that outline participants\u2019 rights if federal agents come to the door. Says Eskenazi, \u201cWe\u2019re really concerned about these people.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Sara_Reardon \n               \n                     Hunted, haunted, stateless and scared: the stories of refugee scientists 2017-Mar-01 \n                   \n                     Immigrant and minority scientists shaken by Trump win 2016-Nov-22 \n                   \n                     The mental-health crisis among migrants 2016-Oct-10 \n                   \n                     Poverty linked to epigenetic changes and mental illness 2016-May-24 \n                   \n                     Stress alters children's genomes 2014-Apr-07 \n                   \n                     CHAMACOS study \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21801", "url": "https://www.nature.com/articles/nature.2017.21801", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Linguists, anthropologists and political scientists take to Capitol Hill to defend their research. Evan Bradley has spent 14 years studying linguistics. But his mastery of the relationship between music and tonal languages such as Mandarin Chinese was of little use during Bradley's recent trip to Washington DC, as he tried to decipher the lingo of bureaucrats in the US Congress. He was one of 70 social scientists who descended on Capitol Hill on 29 March in an attempt to convince politicians that social science deserves government support \u2014 despite a renewed push by leading Republicans to shrink research funding. For social scientists such as Bradley, the stakes are high. US President Donald Trump  has proposed sweeping cuts to major science agencies , including the National Institutes of Health and the Environmental Protection Agency. And  the powerful chair of the House of Representatives\u2019 science committee , Texas Republican Lamar Smith, wants to shift 70% of the National Science Foundation (NSF) budget into just four research areas \u2014 mathematics and physical sciences, computing, engineering, and biology \u2014 and reduce support for the agency\u2019s social-science and geoscience divisions. \u201cIn the past, I\u2019ve done armchair activism \u2014 you know, \u2018hashtag activism\u2019,\u201d says Bradley, who works at Pennsylvania State University's Brandywine campus in Media. But this year, he says, \u201cI felt it was important to get involved on the ground.\u201d His trip to Capitol Hill was organized by the Consortium of Social Science Associations (COSSA). For the past three years, the group has invited linguists, anthropologists, sociologists and political scientists from across the country in Washington DC, for a brief training session before a whirlwind day of meeting with members of Congress and their aides to advocate for science funding. This year, participation set a record: 70 researchers attended the training before fanning out to meet with 80 members of Congress. \n             Baby steps \n           For many of the participants, it was the first time they\u2019d spoken to an elected official. Emily Beaulieu, a political scientist at the University of Kentucky in Lexington, met an aide to one of her state\u2019s two senators: Republican Rand Paul, who publishes frequent reports detailing government programmes that he considers wasteful. Science, including social science, is often a target. During their meeting, Paul\u2019s aide said that the senator supports science \u201cif it isn\u2019t wasteful\u201d, Beaulieu says. \u201cOf course, sometimes you don\u2019t know what the application or significance of scientific research will be until it\u2019s done,\u201d she adds. Rebecca Eissler, a graduate student in political science at the University of Texas at Austin, met an aide to Smith. Given Smith\u2019s history with the social sciences, she didn\u2019t expect it to go well. At first, she says, the meeting was awkward, and the aide was non-committal. But when Eissler and her fellow researchers asked how they could help Smith\u2019s staff, the atmosphere improved. \u201cWe had a discussion about the merits of good science,\u201d says Eissler \u2014 who notes that she and the aide still disagree about what constitutes \u2018good science\u2019. Many of the proposals to cut funding for social science are familiar to research advocates, but have never managed to garner enough support to become law. Now the shifting political winds have given them new life. For example, Smith  has long argued  that  the NSF should focus on science that supports the US national interest  \u2014 and by his definition,  that does not include social science . With Republicans now controlling the White House and both chambers of Congress, Smith\u2019s proposal could finally become reality. That would be devastating for US anthropologists, for whom the NSF is a major source of research grants, says Ed Liebow, executive director of the American Anthropological Association in Arlington, Virginia. And even some researchers who might benefit from such a plan say that they find it worrisome. \u201cI don\u2019t think it\u2019s a good thing,\u201d says Scott Collins, an ecologist at the University of New Mexico in Albuquerque and a former NSF programme director. \u201cWe\u2019re not out here to eat our own. Science is interdisciplinary.\u201d That message resonates with Beaulieu, who was inspired by her day of meetings with politicians. Social scientists \u201crealize that we\u2019re a part of a broader research community\u201d, she says, \u201cand we need to be heard\u201d. \n                   US science agencies face deep cuts in Trump budget 2017-Mar-16 \n                 \n                   Trump and Republicans take aim at environmental agency 2017-Mar-10 \n                 \n                   How Republicans reshaped the House science committee 2016-Oct-19 \n                 \n                   Reproducibility will not cure what ails science 2015-Sep-09 \n                 \n                   US lawmakers advance controversial science-policy bill 2015-May-21 \n                 \n                   Public spending: US Congress replies on NSF scrutiny 2015-Apr-01 \n                 \n                   Social scientists hit back at grant rules 2013-Nov-12 \n                 \n                   Republicans put 'national interest' requirement on US science agency 2013-Nov-05 \n                 \n                   National science furore 2013-Jun-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21847", "url": "https://www.nature.com/articles/nature.2017.21847", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Nature  asked members of the scientific community whether or not they plan to march on 22 April \u2014 and why. Calls from US President Donald Trump to  roll back environmental regulations  and  slash funding for health, environmental and research agencies  have raised alarm in the scientific community. Earlier this year, a commenter on the social-media website Reddit made an off-hand remark about the need for scientists to march on Washington DC. That thread has since grown into an international movement. The March for Science now includes more than 500 events \u2014 including marches, rallies and teach-ins \u2014 planned for locations around the world. But support for the march, set to occur on 22 April, has been far from unanimous. Some, who think that science should remain non-partisan, are concerned that the movement will politicize it. Others have voiced concerns about diversity and inclusiveness.  Nature  spoke with people around the world about the reasons they will or won\u2019t attend a March for Science event. The answers below have been edited for length and clarity. \n             Kellie Dean is a lecturer at University College Cork in Ireland, specializing in biochemistry and cell and molecular biology. \n           \u201cI am going so I can stand up for evidence-based policies and the scientific method. I also support robust funding of science and transparent reporting of scientific results. The current wave of \u2018anti-science\u2019 rhetoric goes against everything that I am trying to do as a scientist and an educator. I keep telling my students that I\u2019m going because science is worth protecting: for them, and for all of us.\u201d \n             Nathan Gardner is a postdoc at the University of Chicago School of Medicine in Illinois, where he studies protein science. \n           \u201cI am not going to the March for Science, because some people in America view science as leftist. Maybe it\u2019s because [former US vice-president] Al Gore launched \u2018An Inconvenient Truth\u2019. I\u2019ve seen articles from right-wing outlets that are framing the march as focusing on gender equality and identity politics. I think it could easily politicize science because, even though the march\u2019s mission statement isn\u2019t anti-Trump, the marchers seem anti-Trump.\u201d \n             David Leaf is a cell biologist who teaches at Western Washington University in Bellingham. \n           \u201c I am deeply concerned about the anti-scientific stance of the Trump administration, and the effects of their policies that disregard research on the environment, human health and the US economy. I hope that the march will send a message to Congress that there are a significant fraction of voters who consider supporting science and scientists to be high priority.\u201d \n             Danielle Peltier is an undergraduate student studying geology, anthropology and chemistry at New Mexico State University in Las Cruces. \n           \u201cI want to share why science is important \u2014 not only in education and everyday lives, but in politics and world issues. As someone whose field is palaeontology, which involves evolution, I want to help people understand that science and religion are not mutually exclusive. I live in New Mexico. I\u2019m from a smaller town, which is usually more conservative and very, very religious. I want to share that science isn\u2019t partisan and doesn\u2019t take sides. I wanted to go to the march in Washington DC, but since I couldn\u2019t go, I joined the local planning committee here. I\u2019m trying to be as active as I can.\u201d \n             Xieergai Jiang is a student at Tacoma Community College in Washington, where he is working on an associate\u2019s degree in science, and plans to pursue a future degree in bioengineering. \n           \u201cNot once in my life have I thought of myself as someone who would go to marches, protests or pickets. But science has been, is and will be the reason that humanity moves forward. It is the voice of reason inside the huge organism we call the human race, and I will not let this voice be unheard. I hope this march will bring public attention to science. I want it to be a subject of discussion at dinner tables, coffee shops, classrooms and any other social place. I don\u2019t care if the publicity is positive or negative. Any publicity is good publicity.\u201d \n             Tesfay Teamir is a PhD student in physics at Bilkent University in Ankara, Turkey. He supports the march, but cannot attend because there are currently no marches scheduled in Turkey. \n           \u201cGetting funds to participate in important scientific activities is already difficult for people from developing countries. Even if you get the funds, it can be difficult to get the visa. One of the objectives of the scientific community is to disseminate science, and these barriers test that. I was offered the chance to present an abstract on my research at the American Physical Society meeting in March. But I could not go because the United States embassy in Ankara rejected my visa because I am from Ethiopia in Africa.\u201d \n             Taylor Tobin is a graduate student in astronomy at the University of Illinois at Urbana-Champaign. \n           \u201cInitially I was planning on going, but now I'm not so sure. I agree that we need to fight to hold this administration accountable about the truth and, specifically, climate change. But the way many of the March branches have bungled inclusion and the needs of scientists as a diverse set of humans has given me second thoughts. Associated leaders of certain branches have been actively harassing women of color on social media, and I've seen people label the push for equity and inclusion in the March as divisive. But if you shy away from inclusivity, that's divisive, too. I've heard that the Champaign-Urbana March is making efforts towards equity, so I'll probably go to that one. I do plan on making multiple signs to hold up: some about truth in science, and some about equity and inclusion. They're both big problems that need to be addressed.\u201d \n             Luke Schwerdtfeger is a PhD student in neurobiology at Colorado State University in Fort Collins. \n           \u201cThose who remain silent in the face of national policy that attacks scientific creativity and discovery will only contribute to further public opposition to the scientific community. We must, as scientists, have our voices heard on a national level, not just in speaking to like-minded individuals.\u201d \n                   Nature supports the March for Science 2017-Apr-11 \n                 \n                   Scientists join massive protest against Trump 2017-Jan-22 \n                 \n                   Is Donald Trump pushing more scientists towards political activism? 2016-Dec-13 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21865", "url": "https://www.nature.com/articles/nature.2017.21865", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "A series of odd findings have theorists hoping for new particles. The latest in a series of anomalies spotted in five-year-old data from the Large Hadron Collider (LHC) could point the way to an entirely new elementary particle, physicists hope. The most recent finding,  reported at an 18 April seminar at CERN , Europe's particle-physics lab near Geneva, may turn out to be a statistical fluctuation that fades as new data are analysed. But it is intriguing because it seems to chime with  previously-reported oddities . And it matches the predictions of new physics that some theorists had already made based on those earlier reports. Particular short-lived particles called B-mesons, created when the LHC smashes protons together, seem to be decaying in unexpected ways, Simone Bifani at the University of Birmingham, UK, told physicists at the CERN seminar. The standard model of particle physics predicts that pairs of matter-antimatter particles should be among the B-mesons\u2019 decay products: and specifically that electron-positron pairs and muon-anti-muon pairs should be found in roughly equal numbers. (The muon is a heavy cousin of the electron). But researchers see more of the electron-positron pairs, Bifani said, based on data collected at the collider\u2019s LHCb experiment. This could just be a statistical fluke, says Guy Wilkinson, a physicist at the University of Oxford, UK, and the spokesperson for LHCb. In the latest study, researchers looked at two separate groups of data from LHCb on B-meson decays, and in each case found an anomaly with a statistical significance below 2.5 sigma (a measure of statistical confidence). That falls far short of the 5 sigma threshold usually needed to claim a \u2018discovery\u2019.\u00a0 But the LHCb has already spotted  a number of similar anomalies to do with meson decay , Wilkinson notes, and in particular with various types of B-mesons. None are yet statistically significant, but they point in the same direction. \u201cThere have been strange things happening over the last five years,\u201d he says. Some LHC physicists are not so sure that the announcement was worth the buzz it has received among researchers. CERN physicist Andr\u00e9 David, for example, tweeted that \u201cpiling up a sigma here and a sigma there\" does not make for a discovery. \n             Short-lived new particles? \n           Still, theorists had already been positing new physics based on the earlier findings. And excitingly, the latest B-meson decay results are consistent with these ideas, says theorist David Straub at the Technical University of Munich, Germany. Straub posted  a paper to the arXiv website  yesterday analyzing the latest meson-decay results; five other theory papers have also been posted, and more are likely to follow. \u201cThe community was watching these results with quite some interest,\u201d says Juan Rojo, a theorist at the Free University of Amsterdam. The most obvious way to explain the results \u2014 if they are not a statistical fluke \u2014 is that as B-mesons decay, novel particles not predicted in physics\u2019 standard model make a fleeting appearance that affect the decay products, the six papers agree. One possibility\u00a0is that there could be a heavier cousin of a particle known as the Z boson, called Z'. Another explanation is the existence of a \u2018leptoquark\u2019, a boson that would share some properties with both leptons and quarks. Neither of these particles occurs in theorists' favourite schemes for extending the standard model, but researchers say that if they exist, the LHC's bigger experiments \u2014 ATLAS and CMS \u2014 should be able to create them directly, rather than looking at their effects on the decays of other particles. The LHCb's latest analysis is entirely based on data from the LHC\u2019s first run, which ended in early 2013 when the collider shut down for an upgrade. Since the collider reopened in 2015 for its second run, LHCb and the other experiments have bagged considerably more data. Several more studies of B-meson decay are now under way. So, before the end of the year, the mystery might be solved. \"We have enough data on tape to validate or disprove these effects. The truth will out,\" says\u00a0Wilkinson. \n                   Hopes for revolutionary new LHC particle dashed 2016-Aug-05 \n                 \n                   Hint of new boson at LHC sparks flood of papers 2015-Dec-24 \n                 \n                   LHC signal hints at cracks in physics' standard model 2015-Sep-03 \n                 \n                   Forsaken pentaquark particle spotted at CERN 2015-Jul-14 \n                 Reprints and Permissions"},
{"file_id": "544277a", "url": "https://www.nature.com/articles/544277a", "year": 2017, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Threat of a far-right president galvanizes researchers to put politics first. It is the strangest French presidential election that mathematician C\u00e9dric Villani can remember. \u201cIt has been like no other,\u201d he says: \u201chectic, hysterical, and full of twists and turns\u201d. With a few days left before Sunday\u2019s first round of voting, any of four candidates could still reach next month\u2019s second round, a head-to-head run-off between the leading pair. But with many voters undecided,  and turnout hard to predict , much could still change. For scientists in France, the presidential contest is often a chance to debate research and science-related issues. When Nicolas Sarkozy was elected a decade ago, for example, university reforms and environmental policy featured prominently in the campaigns. But this time, science has barely been mentioned\u00a0\u2014\u00a0elbowed out by political scandals and the rise of Marine Le Pen\u2019s far-right Front National party. Le Pen has dominated much of the discussion about the election \u2014 to the dismay of those who oppose her nativist and nationalistic policies. Critics say that Le Pen, and the co-opting by mainstream parties of many of her themes, poses a serious threat to the pluralism and values of France\u2019s liberal democracy. As a consequence, many researchers in France have told  Nature  that they are less concerned, in this election, about candidates\u2019 stances on scientific issues than they are about broader political issues, and that their focus is stopping Le Pen and the spread of her ideas. Le Pen has consistently led polls of first-round voting intentions, along with Emmanuel Macron, who heads En Marche!, a centrist movement that he created last year: each has around 22\u201323% of poll support. Jean-Luc M\u00e9lenchon, a far-left candidate of the party La France Insoumise, has surged in recent weeks to around 19\u201320% \u2014 catching up with Fran\u00e7ois Fillon, the official candidate of the main centre-right party, Les R\u00e9publicains. Trailing below 10% is Beno\u00eet Hamon, the official candidate of the main centre-left Parti Socialiste. Since Le Pen took the helm of the Front National six years ago, she has professionalized and invigorated the party machinery, and tried to present a softer image, says Daniel Stockemer, a political scientist at the University of Ottawa. But the party founded by her father, Jean-Marie Le Pen, in the early 1970s remains extremist and illiberal, says Stockemer: \u201cThe core programme is the same; all that has changed is its communication strategy.\u201d For all the political jitters, a Le Pen victory is \u201cimpossible\u201d, Stockemer thinks. Le Pen\u2019s core electorate still consists largely of people with extremist right-wing views, he says, which puts a ceiling on the number of voters she can attract in a head-to-head run-off. \u201cThe Front National is not the catch-all party that is needed to win a presidential election,\u201d he says. Villani, who directs the Henri Poincar\u00e9 Institute in Paris, also highlights the threat that Le Pen poses to the European Union. She has promised to renegotiate France\u2019s terms of membership with the EU, and to hold a referendum on the country\u2019s place in the bloc and on leaving the euro currency. Last month, in response, Villani joined the campaign of Macron\u00a0\u2014\u00a0the most pro-European candidate. Macron is also widely considered best placed to roundly defeat Le Pen in a head-to-head. Le Pen has a vision of a society closed in upon itself, while researchers tend to have an international outlook, says \u00c9douard Br\u00e9zin, an emeritus theoretical physicist at the \u00c9cole Normale Sup\u00e9rieure in Paris and former president of the French National Centre for Scientific Research (CNRS). \u201cAny French retreat from Europe would be far more significant than Brexit,\u201d adds Br\u00e9zin. As well as holding numerous interviews,  Nature  e-mailed more than 3,500 scientists in France, requesting them to take part in an anonymous online survey. The results, from 173 researchers who had replied by 17 April, are far from a representative poll of scientists\u2019 voting intentions, but reflect a trend among some French researchers to veer to the left of the political spectrum. They show Macron as the clear frontrunner, well ahead of M\u00e9lenchon and Hamon, and even further ahead of Fillon, with almost no support for Le Pen. Asked expressly to comment on research policy priorities for France\u2019s next president, survey respondents said they would like to see more funding for basic and long-term research; more science on topics directly relevant to citizens, such as agriculture and the environment; and a simplification of complex grant-application procedures. In fact, continuity is the most likely outcome for France\u2019s research policies after the elections, says R\u00e9mi Barr\u00e9, a science-policy expert and an emeritus researcher at the National Conservatory of Arts and Crafts in Paris. Reforms instigated under the presidencies of Jacques Chirac and Nicolas Sarkozy, and refined under Fran\u00e7ois Hollande\u00a0\u2014\u00a0such as efforts to give universities more independence from the state \u2014 are likely to carry on. Economic constraints mean that the next president and government will probably have little opportunity to raise research budgets significantly, he says.\u00a0 \n                 Tweet \n                 Follow @NatureNews \n                 Follow @DeclanButlerNat \n               \n                     French scientists focus on the big political picture 2017-Apr-18 \n                   \n                     A question of science 2012-Apr-18 \n                   \n                     Science high on French political agenda 2007-May-30 \n                   \n                     French election: The candidates respond 2007-Apr-18 \n                   \n                     France sleepwalks into chaos 2002-Apr-25 \n                   \n                     Emmanuel Macron, En Marche! \n                   \n                     Marine Le Pen, Front National \n                   \n                     Jean-Luc M\u00e9lenchon, La France insoumise \n                   \n                     Beno\u00eet Hamon, Parti Socialiste \n                   \n                     Fran\u00e7ois Fillon, Les R\u00e9publicains \n                   Reprints and Permissions"},
{"file_id": "544280a", "url": "https://www.nature.com/articles/544280a", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Conservative academics face a growing tension between their politics and the liberal atmosphere on many US campuses. When physicist Michael Stopa decided to run for the Massachusetts state senate in 2010, he didn\u2019t expect much encouragement from his \u201coverwhelmingly liberal\u201d colleagues at Harvard University in Cambridge. He was acutely aware of his minority status as a conservative Republican on campus, and avoided talk of politics in his role as a staff scientist in a nanotechnology lab. Then the university newspaper wrote about Stopa\u2019s campaign \u2014 and closeted Republicans around campus began to reveal themselves with quiet messages of support. \u201cA lot of people snuck over and said, \u2018Hey, I hear you\u2019re a Tea Party guy. I am too,\u2019\u201d says Stopa, who lost the election and eventually left academia, but has stayed active in Republican politics. He rejects the idea that his party is anti-science, arguing that \u201cyou can find rubes and lunatics on either side\u201d of the US political divide. But that idea has become a hard sell on many US university campuses, putting Republican researchers in an uncomfortable position, despite their party\u2019s history of strong support for science. Between 1976 and 2013, one study found, US government research and development spending was highest under Republican presidents ( S. Kushi  J. Sci. Pol. Gov.    7 , 2015 ). Yet during that period, party leaders rejected mainstream climate science, opposed environmental protections and sought to ease regulation of medicines. Republicans\u2019 anti-science reputation seems to have deepened under President Donald Trump, who has embraced \u2018alternative facts\u2019 and proposed steep spending cuts for the National Institutes of Health (NIH) and Environmental Protection Agency (EPA), among others. On 22 April, thousands of protesters are expected to attend the March for Science in Washington DC. Organizers describe the event \u2014 one of more than 500 planned for around the globe \u2014 as non-partisan, but it has sparked concern that it could politicize science and alienate Republican politicians. Many Republican scientists who spoke to  Nature  say that they don\u2019t talk politics in the lab, because they are afraid that discussing economic policy or the role of government could damage their friendships or even their careers. And some worry that by supporting the party of Trump, who has been accused of racism and misogyny, they risk being tarred by association. \u201cIt\u2019s become increasingly difficult over the past few decades for scientists to call themselves Republican as part of their core identity,\u201d says Katharine Hayhoe, an atmospheric scientist at Texas Tech University in Lubbock\u00a0\u2014\u00a0and an evangelical Christian who has spoken about her experiences as a member of a minority group in science. \u201cThe Republican party has been moving further and further away from recognizing the neutrality of science,\u201d she says. \u201cNow it\u2019s reached a peak.\u201d The small body of research on US scientists\u2019 political affiliations suggests that Republicans are indeed a minority in universities. A 2009 poll of the American Association for the Advancement of Science\u2019s members, who are mostly academics, found that only 6% identified as Republican. Fifty-five per cent of respondents said they were Democrats and 32% were independents. And a 2014 survey by researchers at the University of California, Los Angeles, found that outside of mathematics, economics and engineering, academic scientists in the United States overwhelmingly identified as liberal. \n               Campus divide \n             The causes of this ideological divide are murky. Politically conservative scholars may drop out of academia because they feel unwelcome, or just because they are drawn to jobs with better pay and shorter training periods, says Richard Alley, a Republican and a geologist at Pennsylvania State University in University Park. What is clear is that conservative and liberal scientists have trouble engaging with each other, says a biologist at a public university in the midwestern United States, who asked to remain anonymous to protect her career. Only one person at her university has ever asked her why she is a Republican, she says. \u201cFor most of my colleagues, anyone who is a conservative must fall somewhere on the continuum between stupid and evil,\u201d the biologist says. The situation has worsened since Trump took office in January, she adds. \u201cWhat you believe has come to be a stand-in for whether you are a good person.\u201d Then there is John Tellis, a chemist at the biotechnology company Genentech in South San Francisco, California. When Tellis was studying for his PhD at the University of Pennsylvania, he tried not to reveal his Republican views. Now, ironically, the election of a Republican president has made it easier for him to talk about politics with his co-workers, he says, because they share his distaste for Trump. Encouraging political diversity among scientists could improve research by helping people to see beyond their own views and prejudices, says Richard Freeman, a labour economist at Harvard who studies gender and racial diversity in science. He notes that Republicans are not alone in staking out political positions contrary to mainstream science. Surveys show that Democrats tend to be more sceptical than Republicans about the safety of genetically modified organisms and nuclear power, even though many studies have concluded that the technologies are safe. The parties\u2019 ideological differences translate into different priorities for government science funding. When Republicans control the government, they tend to increase the military\u2019s research and development budget \u2014 which includes programmes that support academic scientists in a broad range of disciplines. By contrast, Democrats tend to increase the budgets of the EPA, NASA and the Department of Commerce, which includes the National Oceanic and Atmospheric Administration. Scientists could build bridges with conservative politicians by improving their relationship with the military, Freeman says, which is \u201c100% pro-science\u201d. Although many of its political boosters are sceptical of global warming, the military has spent billions of dollars on green-energy technology over the past decade. The Pentagon has also warned that climate change could cause water and food shortages and unrest in unstable regions of the world. Others say that people who dismiss all Republicans as anti-science should look deeper into the party\u2019s history. Republican president Richard Nixon created the EPA in 1970, Alley notes. And Republican congressman Newt Gingrich led an effort in the late 1990s to double the NIH budget. \u201cThere\u2019s a long tradition of support,\u201d he says, \u201ceven if it\u2019s the other way right now.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Sara_Reardon \n               \n                     Is Donald Trump pushing more scientists towards political activism? 2016-Dec-13 \n                   \n                     The scientists who support Donald Trump 2016-Oct-18 \n                   \n                     Science should keep out of partisan politics 2014-Dec-02 \n                   \n                     Science must be seen to bridge the political divide 2013-Jan-02 \n                   \n                     Science must be seen to bridge the political divide 2013-Jan-02 \n                   \n                     Biology and ideology: The anatomy of politics 2012-Oct-24 \n                   Reprints and Permissions"},
{"file_id": "544278a", "url": "https://www.nature.com/articles/544278a", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Chemists will navigate molecular wagons along a tiny golden track. Six teams from three continents are preparing for a unique race on a polished gold track in the south of France this month. But this is no luxurious supercar event: competitors will be racing single molecules. In 36 hours, they aim to move them a distance of 100 nanometres \u2014 about one-thousandth the width of a human hair\u00a0\u2014\u00a0on a laboratory track held in a vacuum and chilled to a few degrees above absolute zero. The contest is being billed as the world\u2019s first nanocar race, and the aim is to get people excited about  nanotechnology and molecular machines , says co-organizer Christian\u00a0Joachim, a chemist who works at the Centre for Materials Elaboration and Structural Studies in Toulouse, where the event will take place. He and Gw\u00e9na\u00ebl Rapenne, a chemist at the University of Toulouse-Paul Sabatier, developed the contest after Joachim realized\u00a0\u2014\u00a0following an interview with a journalist\u00a0\u2014\u00a0that nanocars attracted much more public attention than did his research on fundamental aspects of nanotechnology. The race may also provide scientific insights for the contestants, who want to learn more about how their individual molecules interact with surfaces. That may help in the design of catalysts and, in the longer term, further the aim of creating molecular-scale technologies for transporting cargo or information, participants say. \u201cIt\u2019s a gigantic experiment, performed by many people at the same time,\u201d Joachim says. ( Nature Nanotechnology,  which is independent of  Nature \u2019s news team, is a sponsor of the race.) \n               Driving with electrons \n             The term nanocar is actually a misnomer, because the molecules involved in this race have no motors. (Future races may incorporate them, Joachim says.) And it is not clear whether the molecules will even roll along like wagons: a few designs might, but many lack axles and wheels. Drivers will use electrons from the tip of a scanning tunnelling microscope (STM) to help jolt their molecules along, typically by just 0.3\u2009nano-metres each time\u00a0\u2014\u00a0making 100\u2009nanometres \u201ca pretty long distance\u201d, notes physicist Leonhard Grill of the University of Graz, Austria, who co-leads a US\u2013Austrian team in the race. Contestants are not allowed to directly push on their molecules with the STM tip. Some teams have designed their molecules so that the incoming electrons raise their energy states, causing vibrations or changes to molecular structures that jolt the racers along. Others expect electrostatic repulsion from the electrons to be the main driving force. Waka Nakanishi, an organic chemist at the National Institute for Materials Science in Tsukuba, Japan, has designed a nanocar with two sets of \u2018flaps\u2019 that are intended to flutter like butterfly wings when the molecule is energized by the STM tip (see \u2018Molecular race\u2019). Part of the reason for entering the race, she says, was to gain access to the Toulouse lab\u2019s state-of-the-art STM to better understand the molecule\u2019s behaviour. Eric Masson, a chemist at Ohio University in Athens, hopes to find out whether the \u2018wheels\u2019 (pumpkin-shaped groups of atoms) of his team\u2019s car will roll on the surface or simply slide. \u201cWe want to better understand the nature of the interaction between the molecule and the surface,\u201d says Masson. Simply watching the race progress is half the battle. After each attempted jolt, teams will take three minutes to scan their race track with the STM, and after each hour they will produce a short animation that will immediately be posted online. That way, says Joachim, everyone will be able to see the race streamed almost live. \n               Nanoscale races \n             Chemists have previously created tiny nanocars with wheels and axles\u00a0\u2014\u00a0as well as molecular rotors and switches. The  2016 Nobel Prize in Chemistry, awarded to creators of nanomachines , has renewed interest in the field. However, the Nobel prizewinners worked mainly with large numbers of molecules in solution, Joachim says, whereas the researchers in this race are focusing on the interactions between single molecules and solid surfaces. But cars on the nanoscale behave nothing like their real-life counterparts, making it hard to find uses for the machines. At these scales, electrostatic forces dominate and random thermal vibrations constantly shake molecules around. Consequently, nano-machines may end up behaving in un-expected or unpredictable ways, Grill says. The Toulouse laboratory has an unusual STM with four scanning tips\u00a0\u2014\u00a0most have only one\u00a0\u2014\u00a0that will allow four teams to race at the same time, each on a different section of the gold surface. Six teams will compete this week to qualify for one of the four spots; the final race will begin on 28\u00a0April at 11\u2009a.m. local time. The competitors will face many obstacles during the contest. Individual molecules in the race will often be lost or get stuck, and the trickiest part may be to negotiate the two turns in the track, Joachim says. He thinks the racers may require multiple restarts to cover the distance. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @dcastelvecchi \n               \n                     World\u2019s tiniest machines win chemistry Nobel 2016-Oct-05 \n                   \n                     The tiniest Lego: a tale of nanoscale motors, rotors, switches and pumps 2015-Sep-02 \n                   \n                     The struggle for control 2013-Dec-04 \n                   \n                     Nanocar Race \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21873", "url": "https://www.nature.com/articles/nature.2017.21873", "year": 2017, "authors": [{"name": "Sarah McQuate"}], "parsed_as_year": "2006_or_before", "body": "Analysis reveals that female researchers are over-represented on the social-media site and that mathematicians and life scientists are less likely to use it. In the first broad look at the behaviour of thousands of scientists on Twitter, researchers have found that  women are better represented on the social-media site  than on scientific papers. The team also noted that scientists tended to stick with researchers in their area of expertise while on the social-media site. The study 1 , published last week in  PLOS ONE , is a more representative look at how scientists use the site than previous work, says Kaitlin Costello, an information scientist at Rutgers University in New Brunswick, New Jersey, who was not involved in the paper. Past studies have targeted specific fields or groups of researchers to analyse their behaviour on Twitter. To find a broad range of tweeting researchers, Cassidy Sugimoto, an information scientist at Indiana University Bloomington, and her colleagues started with a list of scientific titles from the US Bureau of Labour Statistics and Wikipedia. They then combed Twitter lists for people with these titles. This initial search generated a group of \u201cseed\u201d scientists. The team then searched lists that contained these seed researchers, looking for more people with scientific titles. \n             Making the list \n           Sugimoto and her colleagues repeated the process until they stopped finding new researchers on the Twitter lists. They ended up with 45,867 scientists from around the world. The team used this list in their analysis of who the scientists were, what they were tweeting about and  who was in their Twitter networks . They found that social and information scientists were over-represented on Twitter, compared with the US workforce, but mathematicians and life scientists were under-represented. The team also found that the ratio of female to male scientists on Twitter (0.62) was greater than the ratio of female to male authors on US-based scientific papers (0.43). \u201cThis is a really interesting finding,\u201d Sugimoto says. Male scientists tend to have their papers cited more than female scientists, and there are more male full professors than female ones at US universities, she notes. So Twitter \u201cmay have more participation from women than we would expect\u201d. The team also explored how scientists connect with other researchers by looking at when people follow, retweet and mention each other. Scientists mostly interact with others from their field, Sugimoto found, mirroring what happens in academia. \n             Socializing scientists \n           When the team looked at what the scientists were sharing on Twitter, the top 20 websites included  other social-media platforms , such as Instagram, Facebook and YouTube. News sites including  The New York Times  and  The Guardian  also made the list. The only scientific URL in the top 20 was nature.com. \u201cThe majority of tweets are personal,\u201d says Sugimoto, and this doesn\u2019t surprise her. \u201cIt\u2019s about your coffee. It\u2019s the news. It\u2019s politics. It\u2019s not necessarily scientific in nature.\u201d But Costello has an alternative explanation. Scientists link to news stories about research studies to bypass the paywall that many scientific articles hide behind, she says, adding that it\u2019s a way to communicate results to everyone. In the future, Sugimoto hopes to expand her method to catch more scientists and to see how they interact with the public. \u201cI think it\u2019s a really exciting and promising methodology,\u201d says Jason Priem, an information scientist and co-founder of the non-profit organization Impactstory, based in Sanford, North Carolina. The company tracks the reach of scientific studies, data and webpages online. \u201cIt\u2019s about being able to put your finger on the pulse of science, to get out and listen to what\u2019s happening on the scientific street corner.\u201d \n                   How Facebook, fake news and friends are warping your memory 2017-Mar-07 \n                 \n                   The dark side of social media 2017-Feb-15 \n                 \n                   Science and sexism: In the eye of the Twitterstorm 2015-Nov-11 \n                 \n                   Conference tweeting rule frustrates ecologists 2015-Aug-19 \n                 \n                   Online collaboration: Scientists and the social network 2014-Aug-13 \n                 \n                   Nature  special: Women in science \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21848", "url": "https://www.nature.com/articles/nature.2017.21848", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Mice treated with a protein from umbilical cord plasma improved their performance on memory tests. A protein found in young human blood plasma can improve brain function in old mice. The finding, published on 19 April in  Nature , is the first time a human protein has been shown to have this effect 1 . It\u2019s also the latest evidence that infusions of \u2018young blood\u2019 can reverse symptoms of ageing, including memory loss, decrease in muscle function and metabolism, and loss of bone structure. For decades, researchers have studied the  effects of young blood on ageing in mice through a technique called parabiosis , in which an old mouse is sewn together with a younger one so that they share a circulatory system. Until now, the rejuvenating properties of young blood had only been demonstrated in mouse-to-mouse transfers. Nevertheless, the work has inspired ongoing clinical trials by at least two companies\u00a0in which elderly people are infused with blood from younger adult donors and then tested for physical improvements. One of the clinical trials is sponsored by a company that neuroscientist Tony Wyss-Coray, at Stanford University in California, is involved with \u2014 he's the chair of their scientific advisory board. As part of his work, he and fellow neuroscientist Joseph Castellano, also at Stanford, have started testing plasma collected from the umbilical cords of newborn babies. Their goal is to find out how very young human blood might affect the symptoms of ageing. \n             Mysterious influence \n           Infusing this human plasma into the veins of elderly mice, they found, improved the animals\u2019 ability to navigate mazes and to learn to avoid areas of their cages that deliver painful electrical shocks. When the researchers dissected the animals\u2019 brains, they found that cells in the hippocampus \u2014 the region associated with learning and memory \u2014 expressed genes that caused neurons to form more connections in the brain. This didn't happen in mice treated with blood from older human donors. The researchers then compared a slate of 66 proteins found in umbilical cord plasma to the proteins in plasma from older people, and to proteins identified in the mouse parabiosis experiments. They found several potential candidates, and injected them, one at a time, into the veins of old mice. The team then ran the animals through the memory experiments. Only one of these proteins, TIMP2, improved the animals\u2019 performance. It did not, however, result in regeneration of brain cells that are lost during normal ageing. Injections of human umbilical cord plasma lacking TIMP2 had no effect on memory. The researchers don\u2019t yet know how TIMP2, which is known to be involved in maintaining cell and tissue structure, exerts its effect on memory. And although it is expressed in the brains of young mice, TIMP2 has never before been linked to learning or memory. Wyss-Coray suspects that the protein functions as a 'master regulator' of genes involved in the growth of cells and blood vessels, and that increasing its levels affects many pathways simultaneously. \n             Black box \n           \u201cI think it\u2019s a beautiful paper,\u201d says Michal Schwartz, a neuroimmunologist at the Weizmann Institute of Science in Rehovot, Israel. And she is intrigued that the researchers could elicit an effect in the mice without injecting plasma into the brain. Schwartz suspects that TIMP2 may be altering the immune system or metabolism in a way that affects the brain indirectly. Lee Rubin, a stem-cell researcher at Harvard University in Cambridge, Massachusetts, agrees. In 2014, Rubin \u2014 who is on the same company's scientific board as Wyss-Coray \u2014 and his lab found that young mouse blood contained higher levels of a  protein called GDF11 , and that injecting GDF11 into the body stimulated blood-vessel growth in the brain 2 . They have since found that GDF11 never enters the brain, and suspect that TIMP2 could be indirectly affecting the brain by acting on systems throughout the body. Pinning down how TIMP2 influences the brain is the next priority, say Wyss-Coray and Castellano. In particular, Wyss-Coray wants to know whether the protein is specifically affecting ageing or general cell health. \u201cIt\u2019s a bit of a black box experiment, because they don\u2019t know what's happening,\u201d says Philip Landfield, a neuroscientist at the University of Kentucky in Lexington. The most promising aspect, he says, is the potential for translating it into a therapy. Infusions of young plasma \u2014 pooled from thousands of donors \u2014 could be one potential treatment for age-related diseases, including Alzheimer\u2019s disease. Alternatively, elderly patients may one day receive a cocktail of proteins such as GDF-11 and TIMP2, or drugs that mimic their effects. But developing such drugs would take many more years than treating patients with serum, Wyss-Coray says. \u201cAt a big picture level, this [new study] is exciting because it reinforces the notion that there are single, \u2018good\u2019 factors in young blood.\u201d \n                   'Young blood' anti-ageing mechanism called into question 2015-May-19 \n                 \n                   Ageing research: Blood to blood 2015-Jan-21 \n                 \n                   Blood hormone restores youthful hearts to old mice 2013-May-10 \n                 Reprints and Permissions"},
{"file_id": "544281a", "url": "https://www.nature.com/articles/544281a", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Partnerships see some success in eliminating illnesses, but challenges, such as access to treatments, remain. As a physician in Tanzania, Upendo Mwingira has little to offer people suffering from elephantiasis, an incurable condition characterized by swollen, wrinkled limbs. \u201cWhen they enter the clinic, they smell, their wounds are oozing and, as a doctor, the best thing I can do is help them accept their situation,\u201d says Mwingira, who directs the neglected-tropical-diseases division of Tanzania\u2019s Ministry of Health in Dar es Salaam.\u00a0 But patients with the condition have become an increasingly rare sight in her clinics. A  global effort to curb  the disease that results in elephantiasis, called lymphatic filariasis, has sent the number of new cases plummeting in Tanzania and at least 18 other countries. Seven more nations, including Cambodia and Sri Lanka, have in the past year eliminated it. The prevalences of other neglected tropical diseases that affect the world\u2019s poorest people have been dropping too. But health officials are not resting on their laurels. Even as they celebrate these victories, they are meeting this week in Geneva, Switzerland, to ramp up their efforts to combat the diseases. They will make plans to treat the hundreds of millions of people who still need it, and to come up with ways to reach communities located far from health services. Several groups will also announce extra funding to fight neglected diseases. The Bill & Melinda Gates Foundation in Seattle, Washington, plans to commit another US$335 million to the cause, and the UK Department for International Development (DFID) will contribute \u00a3360 million (US$450 million). Neglected tropical diseases affect roughly 1 billion people worldwide and kill about 534,000 each year, according to the US Centers for Disease Control and Prevention (CDC). But drug companies and science agencies in rich countries tend to ignore these maladies because they almost exclusively afflict the world\u2019s poorest people. The Gates Foundation threw its energy into fighting these illnesses starting in 1999, when it realized that a relatively small investment could dramatically improve millions of lives, says cofounder Bill Gates. It estimates that a package to treat or prevent several neglected diseases costs around $0.50 per person. \n               Better together \n             Gates told  Nature  that recent successes are the result of global partnerships between governments, companies and nongovernmental organizations that have formed over the past decade. Multiple groups, including the Gates Foundation, the US Agency for International Development (USAID) and the DFID, signed a global agreement in 2012 called the London Declaration on Neglected Tropical Diseases to eliminate or reduce the prevalence of ten neglected diseases by 2020. Five of the targeted diseases, such as lymphatic filariasis and leprosy, can be prevented with drugs. Treatments are the only option for the other five, including visceral\u00a0leishmaniasis (or  kala-azar)  \u2014 a potentially fatal disease spread by sandflies \u2014 and river blindness. Pharmaceutical companies have been donating drugs for these illnesses for more than a decade, but the lack of reliable distribution systems has often kept people from receiving treatment. Since 2006, USAID has been trying to fix that issue. One way is by funding nongovernmental organizations that ensure community workers in remote towns have the tools that they need to treat the ill. As a result, more than 1.6 billion treatments, worth an estimated US$11.1 billion, have gone to 31 countries. More than 300 million people who required preventive treatments for at least one neglected disease five years ago no longer need them because transmission has dramatically slowed, thanks to mass drug administration, according to the World Health Organization. Cases of treatable diseases are dropping, too: since 2005, kala-azar has decreased by 82% in India, Nepal and Bangladesh. Sleeping sickness has plummeted in Africa by 89% since 2000. \n               Rough road ahead \n             But to stamp out the ten conditions listed on the London Declaration, millions of people around the world still require treatments and cures. Scientists could help to speed up progress by considering the challenges in places where neglected diseases occur, says David Molyneux, a parasitologist at the Liverpool School of Tropical Medicine, UK. For example, strategies to train and pay health workers to spot early signs of infection might save more lives than sequencing parasitic genomes.\u00a0 And simple tests for detecting several neglected diseases would also be advantageous for people around the world, says Tom Frieden, a former CDC director. All of this work requires money, which might be a problem if the US Congress approves President Donald Trump's  request to cut the budget of the state department and USAID by 37% . \u201cAny drop of funding in this area will lead to more death and more suffering,\u201d Gates says. However, the partnerships formed over the past five years provide a kind of safety net. And the fact that the United Nations chose alleviation of poverty as its first Sustainable Development Goal \u2014 a list of targets for 2016\u201330 made by global leaders to improve the world \u2014 gives researchers such as Molyneux hope. \u201cUnless you are going to do something about these diseases, people in poverty will continue to be constrained by poverty.\u201d \n                     US foreign aid saves money as well as lives 2017-Apr-13 \n                   \n                     Trump immigration ban upends international work on disease 2017-Feb-01 \n                   \n                     WHO plans for neglected diseases are wrong 2014-Feb-19 \n                   \n                     Projects set to tackle neglected diseases 2014-Jan-07 \n                   \n                     Road map unveiled to tackle neglected diseases 2012-Jan-30 \n                   \n                     Open-source science takes on neglected disease 2010-Feb-04 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21728", "url": "https://www.nature.com/articles/nature.2017.21728", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Funnel plots are a popular tool in spotting when scientists in a field leave out negative study results, but one researcher says the method is flawed. How can you tell if scientists in a certain field are publishing only positive results and throwing away dull findings? Many meta-researchers \u2014 who analyse rafts of studies to try to come up with reliable conclusions \u2014 use a graphical tool called a funnel plot to sift through the studies, checking for publication bias towards interesting findings. But statistically-minded academics took to Twitter last week to debate the utility of these plots, with some\u00a0saying that they should have no place in the toolbox of meta-researchers. The prompt for this was a  21 March blogpost  from Uri Simonsohn, who studies decision-making and methodology at the University of Pennsylvania in Philadelphia, which argued that the funnel plot test is flawed because of a key assumption. \u201cI was expecting it to be a low-key post, but it got tons of attention,\u201d says Simonsohn, who has developed a method called  p -curve that also looks for publication bias. Making a funnel plot involves plotting the sample size of a published scientific study against the size of the effect that the study measures. In many cases, bigger studies will yield a more precise estimate of the effect size, so the graph should \u2014 all things being equal \u2014 look like an inverted funnel, because the larger studies will cluster closer to the \u2018true\u2019 effect size and the smaller studies will be spread more widely. \n             Violating assumptions \n           However, if researchers have been selectively publishing positive results, the funnel plot will be asymmetrical, because the perceived \u2018less interesting\u2019 negative results on one side of the graph will not be in the literature. And this asymmetry is sometimes claimed as evidence of publication bias in a given area. But Simonsohn\u2019s blogpost points out that the funnel plot relies on the assumption that there is no relationship between the effect size and the sample size. Using simulated data, he shows that you can generate an asymmetrical funnel plot by violating this assumption, and therefore that an asymmetrical funnel plot does not necessarily stem from publication bias. Hard numbers on the use of funnel plots are difficult to find, but Simonsohn thinks that some people are missing this point and so are misusing funnel plots to diagnose publication bias. His advice to someone thinking of using one is to do so only if the studies being analysed actually compare like with like on crucial variables such as population size and the hypothesis being tested. \u201cI don\u2019t think that happens in psychology. Maybe in medicine it does,\u201d he says. Although funnel plots are well established in medical meta-analysis \u2014 they were formalized and popularized by  a 1997 paper  in the  British Medical Journal  (BMJ) 1  \u2014 they took longer to catch on in other fields, such as psychology, so academics in these areas could be less aware of the underlying assumptions. \n             Eyeballing asymmetry \n           Many researchers also note that even judging whether a funnel-test curve is asymmetrical needs to be done correctly. Just eyeballing the shape isn\u2019t enough: rather, follow-up mathematical tests should be applied to a curve to measure its degree of asymmetry. But not everyone agrees with Simonsohn\u2019s stark conclusions. Joe Hilgard, who researches video games at the University of Pennsylvania and has an interest in meta-analysis, wrote a response entitled \u201cFunnel plots, done correctly, are extremely useful\u201d. Hilgard told  Nature  that the tool can be \u201ctremendously informative and tremendously useful \u2026 but you really have to\u00a0pay careful attention to the data you put into it\u201d. The problem identified by Simonsohn can be mitigated, he suggests, by splitting data into what he calls \u201chomogeneous subgroups\u201d. For example, studies that examine a possible link between violent video games and aggression could be split into those that look at behavioural outcomes, those that look at affective outcomes and those that look at cognitive outcomes. By categorizing studies in this way, the assumption questioned by Simonsohn becomes more reasonable, Hilgard says. Simonsohn says that he agrees in theory, but that, in practice, he thinks \u201cit is very difficult to generate, at least in psychology, lists of studies that are truly homogeneous\u201d. Marcus Munafo, who researches addictive behaviour at the University of Bristol, UK, points out that what Simonsohn calls a \u201ccrazy assumption\u201d \u2014 that effect size and sample size are unrelated \u2014 is actually acknowledged as a possible flaw in the  BMJ  paper that presented the funnel plot to the world. Munafo, who has worked with one of the authors of that original paper, says: \u201cMy hunch is that probably most people haven\u2019t read the original paper [and] don\u2019t carefully consider the assumptions underlying the test. But I\u2019m not sure funnel plots are particularly unique in that.\u201d Responding to criticism that his blog post highlights what is in the original  BMJ  article, Simonsohn says that what he sees as a \u201cfatal flaw\u201d in the funnel plot is listed there merely as one of many possible defects . \u201cIf \u2026 you mention it among many other superficial flaws, you are kind of hiding the flaw,\u201d he says. Richard Morey, a psychological researcher at Cardiff University, UK, who has previously written about  how funnel plots can be asymmetrical without their being any publication bias , has another reason to avoid the tool: everyone knows already that publication bias exists. \u201cIn the ideal case, they often tell you what you already know,\" he says. \"We know there\u2019s publication bias. We don\u2019t need a test to tell that.\" Reprints and Permissions"},
{"file_id": "nature.2017.21754", "url": "https://www.nature.com/articles/nature.2017.21754", "year": 2017, "authors": [], "parsed_as_year": "2006_or_before", "body": "March\u2019s sharpest science shots, selected by  Nature \u2019s photo team. \n             Synthetic sun \n           \n             Secret snaps \n           \n             Space ravioli \n           \n             Six years later \n           \n             Snapping bloodsuckers \n           \n             Half sunk, a shattered visage lies \n           \n             Wellcome back \n           \n             Ice and fire \n           \n             Animals in action \n           \n                   Fake stars, panda suits and ants on treadmills 2017-Feb-24 \n                 \n                   Swimming starfish, a departing dinosaur and a lot of ice 2017-Jan-27 \n                 \n                   2016 in pictures: The best science images of the year 2016-Dec-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21759", "url": "https://www.nature.com/articles/nature.2017.21759", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "'Pre-cancer' genome atlas proposed to track tumours as they turn from benign to dangerous. Databases worldwide are rapidly swelling with the sequences of thousands of cancer genomes. Now, some scientists are advocating that researchers shift their focus back in time: to study the DNA of tumours in their adolescence, before they commit to being cancerous. At the American Association for Cancer Research (AACR) annual meeting in Washington DC, researchers gathered on 2 April to discuss the growing call to sequence the genomes of pre-cancerous lesions \u2014 abnormal growths that sometimes progress into full-blown cancers. The results could help researchers to determine which tumours warrant treatment and could aid the development of therapies to block cancers on the path to malignancy. It is a project that is now near the top of the cancer research wish list, says oncologist Elizabeth Jaffee of the Sidney Kimmel Comprehensive Cancer Center at Johns Hopkins University in Baltimore, Maryland. \u201cThis is something that has really taken off throughout the cancer community,\u201d she says. The idea could be one of the next 'big science' projects for cancer. The idea is to borrow some tactics \u2014 such as coordination among scientists and sequencing centres \u2014 from  The Cancer Genome Atlas , one of the first and biggest  cancer genome efforts , which characterized the genomes of 33 cancers using samples from more than 11,000 people. But the new 'Pre-Cancer' Genome Atlas would also study cancers over time. It would ideally include multiple snapshots of the same tumour as it developed, in the hope that researchers will be able to determine what changes pushed it across a tipping point to become cancerous. \n             Snapshots over time \n           Individual laboratories have already embraced this concept. Pulmonologist Avrum Spira of Boston University in Massachusetts has been studying the origins of lung cancer by sequencing samples from people with pre-cancerous lesions in their airways. Such biopsy samples are typically taken every 6 or 12 months. Lung cancer, he says, seemed a logical testing ground for the sequence-over-time approach. It is the most common cause of cancer death worldwide. \u201cThe major reason: we almost always detect it late,\u201d he says, adding that as his team carried out the sequencing, \u201cit hit us that this could be a paradigm that applies to other cancer types\u201d. Thomas Kensler, who studies cancer prevention at the University of Pittsburgh in Pennsylvania, points to recent advances in characterizing thyroid cancer that have led to genetic tests to distinguish which tumours warrant treatment. \u201cNot every lump in the thyroid is necessarily destined to be a cancer,\u201d he says. At the AACR meeting, cancer researcher and physician Rafael Bejar of the University of California in San Diego presented his ideas for extending the model to include liquid tumours such as leukaemias. Normal blood is derived from many stem cells, and genetic sequencing can match blood cells to the stem cells from which they were derived. So if a blood test reveals that one lineage of stem cells is beginning to take over the population, it could be an early sign of cancer \u2014 and subsequent monitoring could reveal if the disease takes hold. But a coordinated effort, says Bejar, could boost the impact of these individual projects. Last September, advisers to the  US Cancer Moonshot initiative  \u2014 an effort to double the pace of cancer research in five years \u2014 included a pre-cancer genome project among  the schemes they recommended for investment . And Spira says that the project was discussed at a US National Cancer Institute meeting in late March, and will be taken up again at a meeting in June. What the community wants next, say advocates of the programme, is a firm financial commitment to take the project from concept to reality. \u201cThere\u2019s a lot of enthusiasm,\u201d Bejar says. \u201cPeople are moving forward.\u201d \n                   DNA typos to blame for most cancer mutations 2017-Mar-23 \n                 \n                   US Cancer Moonshot must strike a balance between research and prevention 2016-Nov-22 \n                 \n                   The science myths that will not die 2015-Dec-16 \n                 \n                   Change the cancer conversation 2015-Apr-01 \n                 \n                   End of cancer-genome project prompts rethink 2015-Jan-05 \n                 \n                   Antioxidants speed cancer in mice 2014-Jan-29 \n                 \n                   Nature Supplement: Cancer prevention \n                 \n                   Nature Special: Cancer genomics \n                 \n                   US National Cancer Institute: Sceening and early detection research \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21756", "url": "https://www.nature.com/articles/nature.2017.21756", "year": 2017, "authors": [], "parsed_as_year": "2006_or_before", "body": "People are set to march in more than 420 cities on 22 April. The  March for Science  is scheduled to take place in Washington DC on 22\u00a0April, with  satellite marches  set for more than 427 other cities around the globe. The protest aims to attract researchers and those who are interested in science \u201cto support and safeguard the scientific community\u201d. Nature  wants to know how scientists \u2014 from undergraduate students to tenured professors \u2014 feel about the march. Tell us whether you\u2019re attending, the reasons for your decision and whether our reporters can contact you for further information. \n                   US science agencies face deep cuts in Trump budget 2017-Mar-16 \n                 \n                   Trump and Republicans take aim at environmental agency 2017-Mar-10 \n                 \n                   Scientists join massive protest against Trump 2017-Jan-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21769", "url": "https://www.nature.com/articles/nature.2017.21769", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Website contains thousands of 3D stem cell images and could eventually help with better understanding diseases like cancer. No two stem cells are identical, even if they are genetic clones. This stunning diversity is revealed today in an enormous publicly available online catalogue of 3D stem cell images. The visuals were produced using deep learning analyses and cell lines altered with the gene-editing tool CRISPR. And soon the portal will allow researchers to predict variations in cell layouts that may foreshadow cancer and other diseases. The  Allen Cell Explorer , produced by the Allen Institute for Cell Science in Seattle, Washington, includes a growing library of more than 6,000 pictures of  induced pluripotent stem cells  (iPS) \u2014 key components of which glow thanks to fluorescent markers that highlight specific genes. The Cell Explorer complements ongoing projects by several groups that chart the uniqueness of single cells at the level of DNA, RNA and proteins. Rick Horwitz, director of the Allen Institute for Cell Science, says that the institute\u2019s images may hasten progress in stem cell research, cancer research and drug development by revealing unexpected aspects of cellular structure. \u201cYou can\u2019t predict the outcome of a football game if you know stats on all the players but have never watched a game.\u201d \n             Looking skin deep \n           The project began about a year ago with adult skin cells that had been reprogrammed into an embryonic-like, undifferentiated state. Horwitz and his team then used CRISPR\u2013Cas9 to tag genes that resulted in structures that glowed. The genes included those that code for proteins that highlight actin filaments, which help cells to move and maintain their shape. It quickly became clear that the cells, which were all genetic clones from the same ancestor, varied in the placement, shape and number of their components, such as mitochondria and actin fibres. Computer scientists analysed thousands of the images using deep learning programs and found correlations between cellular structures. They then used that information to predict where the structures might be when the program was given just a couple of clues, such as the position of the nucleus. The program \u2018learned\u2019 by comparing its predictions to actual cells. The deep learning algorithms are similar to those that companies use to predict people\u2019s preferences, Horwitz says. \u201cIf you buy a chainsaw at Amazon, it might then show you chain oil and plaid shirts.\u201d The 3D interactive tool based on this deep learning capability should go live later this year. At the moment, the site shows a preview of how it will work using side-by-side comparisons of predicted and actual images.\u00a0 Benjamin Freedman, a cell biologist at the University of Washington in Seattle, looks forward to playing with the Cell Explorer\u2019s predictive function once the Allen Institute team has taught their algorithm to recognize more iPS cells that have been changed genetically or chemically. For example, Freedman says he could delete a gene related to kidney disease in one of the fluorescently tagged stem cells from the Allen Institute and see how the mutation affects the glowing structure. Then he could use the site\u2019s modelling tool to determine how other cellular components might be altered. \u201cUltimately,\u201d Freedman says, \u201cwe want to understand processes at the cellular level that cause disease in the kidney as a whole.\u201d \n             Filling in the holes \n           In the coming months, Allen Institute researchers will update the site with images of stem cells at different stages of cell division, and as they transform into distinct cell types, such as heart and kidney cells. Catching cells at different time points can be crucial to identifying fundamental processes, says Horwitz. The Allen Institute\u2019s visual emphasis on stem cells dovetails with a number of efforts to catalogue other aspects of cells. For example, the London-based charity  Cancer Research UK  is creating interactive virtual-reality models of breast cancer cells in tumours. And an international effort called the  Human Cell Atlas  seeks to define all human cell types in terms of their molecular profiles, including DNA sequences, RNA transcripts and proteins. Aviv Regev, a computational biologist at the Broad Institute in Cambridge, Massachusetts, who is working on the Human Cell Atlas, says that the Allen Cell Explorer complements her project by focusing on the look of cellular features as opposed to how genes, RNA and proteins interact within the cell. \u201cThe community is accepting that there are a lot of differences between cells that we thought were the same until recently,\u201d she says, \u201cso now we\u2019re taking an unbiased approach to learn about pieces in the puzzle we didn\u2019t know existed before.\u201d \n                   How bioinformatics tools are bringing genetic analysis to the masses 2017-Feb-28 \n                 \n                   The race to map the human body \u2014 one cell at a time 2017-Feb-20 \n                 \n                   Global initiative seeks 1,000 new cancer models 2016-Jul-11 \n                 \n                   How iPS cells changed the world 2016-Jun-15 \n                 \n                   Allen Institute for Cell Science \n                 \n                   Human Cell Atlas \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21766", "url": "https://www.nature.com/articles/nature.2017.21766", "year": 2017, "authors": [{"name": "Claudio Angelo"}], "parsed_as_year": "2006_or_before", "body": "After years of austerity, researchers fear that the latest dramatic cut will destroy the country's science. Brazilian scientists have been left horrified by a 44% slash to the federal science budget, announced by the country's government on 30 March. This will leave the Ministry of Science,Technology, Innovations and Communications (MCTIC) with its lowest budget in at least 12 years at just 2.8 billion reais, equivalent to US$898 million \u2014 a 2.2 billion reais cut from the 5 billion reais of funding that the government had originally proposed for 2017 (see \u2018Drastic cuts\u2019). The cut is part of a general trimming of 42 billion reais from the federal budget, which amounts to 28% over all government departments \u2014 so the cut to science is particularly severe. President Michel Temer says the measure was a tough but necessary response to Brazil\u2019s escalating fiscal deficit. The country faces the worst recession in its history, and recovery has been much slower than expected: gross domestic product growth predictions for 2017 were revised down from 1.4% to 0.5% last month. Researchers argue that science has already taken too heavy a toll from the economic crisis. Since 2014, a  series of funding cutbacks  has meant abandoning a flagship exchange programme to enable Brazilian students to visit leading institutions abroad, and major projects \u2014 such as the Sirius synchrotron, a 1.75 billion reais machine \u2014 have been put in jeopardy. The number of research  papers published in Brazil is also declining , according to one preliminary estimate from 2016. Adding to those woes, Temer demoted the science ministry as he took office in May 2016 and  fused it with the communications ministry . And a constitutional amendment passed by the new government has  capped federal spending  to inflation-level rises for 20 years, killing hopes that the tide may turn any time soon. \n             Fleeing scientists \n           The new budget is \u201can atomic bomb strike on Brazilian science\u201d, says physicist Luiz Davidovich, president of the Brazilian Academy of Sciences. He warns that the cuts will cripple research and development for decades to come. \u201cWere we at war, one could think this was a strategy by a foreign power to destroy our country. But instead it\u2019s us doing this to ourselves.\u201d Sidarta Ribeiro, head of the Brain Institute at the Federal University of Rio Grande do Norte in Natal, Brazil, holds a similar apocalyptic view, saying: \u201cThis is an act of war against the future of Brazil. Scientists will flee the country.\u201d He cites the case of Suzana Herculano-Houzel, a renowned neuroscientist who shut down her laboratory in 2016 and left Brazil for the United States. \u201cIf I hadn\u2019t foreign money for research I\u2019d be shutting down myself,\" he adds. Fernando Peregrino , president of  CONFIES , the Brazilian association of science funding agencies and university foundations, agrees. \u201cThere will be a huge break-up of teams which will be hard to rebuild,\u201d he says. \u201cWe\u2019ve climbed another step down.\u201d Scientists were concerned about funding before the announcement. Davidovich and  Helena Nader , president of the Brazilian Society for the Advancement of Science (SBPC), pre-emptively wrote letters  to Temer  and  to Henrique Meirelles , the minister of finance, warning of the impact of a potential cut on an already tight science budget. \u201cThe government has acted without listening to the State. It shows an utter shortsightedness,\u201d Nader says. The MCTIC told  Nature  that it has already started to gauge the full impact of the cuts. According to the ministry, actions to mitigate them will be announced shortly. Ribeiro says the drastic cutbacks may have one silver lining: they may fuel the 22 April March for Science in Brazil. The SBPC formally joined this month\u2019s march, inspired by the Trump-resistance movement in the United States, and has been calling on scientists all around Brazil to join. \u201cWe need to paint for war and occupy public spaces,\u201d says Ribeiro. \u201cRespectfully, but consistently.\u201d \n                   Brazil\u2019s scientists battle to escape 20-year funding freeze 2016-Nov-18 \n                 \n                   Political upheaval threatens Brazil\u2019s environmental protections 2016-Nov-08 \n                 \n                   Brazil's scientists start street protests against ministry merger 2016-Jun-10 \n                 \n                   Demotion of science ministry angers beleaguered Brazilian researchers 2016-May-12 \n                 \n                   Brazilian science paralysed by economic slump 2015-Sep-30 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21763", "url": "https://www.nature.com/articles/nature.2017.21763", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Scientists face tough decisions when the latest gene-editing findings don\u2019t match up with the results of other techniques. It seemed like the perfect plan. Jason Sheltzer, a cancer biologist at Cold Spring Harbor Laboratory in New York, was on the hunt for genes involved in tumour growth. He and his colleagues planned to disable genes using  the popular gene-editing tool CRISPR\u2013Cas9 , then look for changes that reduced the rate at which cancer cells multiply. But they needed a control gene that would yield that same effect. The literature suggested that the gene  MELK  was ideal: there was ample evidence that it is important in cancer-cell proliferation, and clinical trials are under way to test drugs that inhibit the MELK protein. But disabling the gene using CRISPR\u2013Cas9 yielded no effect. \u201cThat threw a monkey wrench into our experiments,\u201d says Sheltzer. \u201cIt brought everything to a halt.\u201d With that result, Sheltzer and his team joined an expanding club of laboratories that have been forced to re-evaluate and repeat experiments, as the spread of CRISPR\u2013Cas9 uncovers potential errors in data collected using older techniques. On 3 April, Sheltzer's team presented the findings at the American Association for Cancer Research annual meeting in Washington DC. The results have also been published in the journal  eLife 1 . \u201cThere\u2019s a whole lot of work to be done, just basically repeating the same screens that people had done\u201d with other methods, says Michael Bassik, a molecular biologist at Stanford University in California. \u201cAnd, I think it\u2019s fair to say, to get much better data.\u201d \n             Scale of the problem \n           Nathan Lawson, a molecular biologist at the University of Massachusetts Medical School in Worcester, was one of the first to systematically characterize the problem. In 2015, he and his colleagues reported their efforts to compare results from two methods in zebrafish: knocking out genes using a gene-editing technique called zinc finger nucleases, and reducing gene expression using molecular tools called morpholinos. They found that half of the 20 genes they tested yielded different results 2 . An additional trawl through genetic databases and the morpholino literature revealed that 80% of results from published morpholino experiments were not reproducible in genetic mutants 2 . Some zebrafish researchers said they welcomed the paper because it forced the community to confront a problem that had only been noted anecdotally. Others were not so happy. \u201cI got some people who told me I ruined the field,\u201d says Lawson. Similar conflicts have cropped up in other organisms. In the model plant  Arabidopsis thaliana , the use of CRISPR\u2013Cas9 showed that a protein previously thought to mediate the effects of the plant hormone auxin does not have that function 3 . In fruit flies and human cells, large screening studies have turned up widespread discrepancies between results obtained using RNA interference (RNAi) \u2014  a technique that reduces gene expression  \u2014 and those from genetic mutants 4 . Both methods have their limitations, notes Lawson. RNAi occasionally alters the expression of genes  other than its desired target . And meddling with the cell\u2019s internal RNA-processing machinery can sometimes affect other cellular systems that involve RNA. CRISPR\u2013Cas9 gene editing, meanwhile, requires breaking strands of DNA \u2014 which can trigger other responses in the cell, including cell suicide. And the technique can also sometimes  cut DNA at unintended sites . \n             Back to basics \n           Conflicting results from RNAi and genetic screens do not always mean that one approach was right and the other was wrong, cautions Bassik. Some cells might respond differently to a genetic change that wipes out expression of a gene, as is often the goal with CRISPR\u2013Cas9, compared to how they respond to reducing the expression to very low levels with RNAi. But often, he adds, the culprit behind the discrepancy can be tracked back to  RNAi\u2019s potential for off-target effects . And concerns about that have had researchers flocking to reproduce old results. In the case of  MELK , the CRISPR\u2013Cas9 results are particularly concerning because they could undermine the scientific foundation for a clinical trial. But Sheltzer\u2019s team showed only that MELK does not seem to have a role in cancer-cell division, notes Carlos Moreno, a cancer researcher at Emory University in Atlanta, Georgia. It is possible that other aspects of MELK, such as its purported role in making cancer cells more resistant to radiation[5], are still valid, he says. And many successful drugs have been developed on the back of a faulty scientific hypothesis, he adds. The MELK inhibitors in clinical trials might work through some other mechanism, for instance. \u201cThat would be no reason to stop a trial if the trial is showing positive effects,\u201d he says. \u201cIt\u2019s important not to throw the baby out with the bathwater.\u201d \n                   Enzyme tweak boosts precision of CRISPR genome edits 2016-Jan-06 \n                 \n                   RNA interference rebooted 2014-Apr-22 \n                 \n                   Cancer screen yields drug clues 2012-Mar-28 \n                 \n                   Special: CRISPR \n                 Reprints and Permissions"},
{"file_id": "544016a", "url": "https://www.nature.com/articles/544016a", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Debate grows over a molecule implicated in animal navigation. For decades, scientists have wondered how animals can navigate huge distances using the weak signals of Earth\u2019s magnetic field. So, interest was piqued in 2015 when two teams released papers in quick succession describing the functions of a protein found in animals that seemed to sense magnetic fields. But the claims have proved controversial, and questions have been piling up. The basic science behind the discovery was reported by Xie Can, a biophysicist at Peking University in Beijing, and his colleagues. In a paper in  Nature Materials 1 , they claimed that a  protein in animal cells forms a structure that responds to magnetic fields , and so might help in navigation. In the same year, a group led by Zhang Sheng-jia, then at Tsinghua University in Beijing, had published a paper in  Science Bulletin 2  reporting that the same protein could offer a powerful means of controlling brain cells. An academic battle has long raged between Xie and Zhang, but mounting evidence has cast doubt on both of their discoveries. Several researchers have challenged Xie\u2019s claims that the protein reacts to magnetic fields. And last month, Xie co-authored a paper in  Frontiers in Neural Circuits 3  disputing Zhang\u2019s work on the protein\u2019s potential to magnetically control cells. This has all given rise to serious questions about the role of the molecule at the centre of the dispute. In their 2015 paper 1 , Xie and his colleagues reported that a protein called IscA1 forms a complex with another protein, Cry4, that explains how organisms pick up magnetic cues. The study found that this complex incorporates iron atoms, which gives it magnetic properties, and has a rod-like shape that aligns with an applied magnetic field. Two months earlier, Zhang had described using IscA1 to control neurons and muscle cells in worms 2 . Zhang learned of IscA1\u2019s properties and obtained his IscA1 samples from Xie, and so the fact that his team published first was an early source of tension in what quickly became a  bitter dispute . Officials from both Tsinghua University and Peking University asked  Science Bulletin  to retract Zhang\u2019s paper. And that November, Zhang  lost his position  at Tsinghua \u2014 for reasons that the university did not specify. Doubts about Xie\u2019s research have emerged since then. Michael Winklhofer, a geophysicist at the University of Oldenburg in Germany, examined Xie\u2019s data and found that the complex would be too weakly magnetic to sense Earth\u2019s field 4 . Markus Meister, a biophysicist at the California Institute of Technology in Pasadena, raised similar concerns: Xie had reported that the complex would contain only 40 iron atoms, but Meister argues that the smallest known naturally occurring iron-based magnet has 1\u00a0million iron atoms packed into a smaller space 5 . David Keays, a neuroscientist at the Institute of Molecular Pathology in Vienna, has also questioned the study. He says that IscA1 and Cry4 are found throughout many tissues, whereas one would expect them to be sequestered in specific areas if they were functioning as parts of a magnetic-field receptor. \u201cSensory receptors, whether they be taste, hearing or photo-receptors, tend to have a restricted expression pattern,\u201d he says. Collaborators of Xie say that they have been able to reproduce some of his findings, and Xie told  Nature  that he stands by his results. He disputes the contention that the magnetic properties of IscA1 would be too weak by saying that Cry4 might boost its effect. \u201cThe data are what they are,\u201d he says. \u201cThis may expand our knowledge of molecular magnets.\u201d The challenge to Zhang\u2019s paper has been more pointed. Zhang claimed to have transferred IscA1 into worm neurons and then used a magnetic field to induce the cells to take up calcium. The ability to manipulate such a basic cell function could promise neuroscientists a powerful tool that is less invasive than opto-genetic techniques, which use light-sensitive proteins to control neurons in living animals. But last month, Xie, Tsinghua University neuroscientist Lu Bai and Lu\u2019s student Pang Keliang reported 3  carrying out experiments under various conditions, including some almost identical to those used by Zhang. They found no change in calcium flowing into cells in any of the cases. The authors conclude that the \u201cfindings cast serious doubts\u201d that IscA1 alone could influence the activity of neurons, as Zhang had claimed. Several scientists outside China also told  Nature  that they could not reproduce Zhang\u2019s results.  Nature  tried to reach Zhang through multiple e-mails and phone calls to Shenzhen University in China, where he now has a position, but he did not respond to requests for comment. (Neither  Nature Materials , which is editorially independent from  Nature \u2019s news team, nor  Science Bulletin  responded to requests for comment about criticism of the papers.) Meanwhile, even as his critics become increasingly aggressive, Xie says he has convincing data that demonstrate the reaction of an IscA1 complex to a magnetic field, and that he plans to publish them within a year. \u201cWe are more and more confident \u2014 100% sure \u2014 that we are right about this,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Discovery of long-sought biological compass claimed 2015-Nov-16 \n                   \n                     Neuroscientist fired after dispute over magnetic-protein research 2015-Nov-05 \n                   \n                     Chinese scientists row over long-sought protein that senses magnetism 2015-Sep-21 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21800", "url": "https://www.nature.com/articles/nature.2017.21800", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Publishers agree to release proprietary data on references in millions of papers. Want to find out whether your articles are more highly cited than others? To get at the underlying data,  you\u2019ll have to pay . For decades, reliable, structured records of papers\u2019 authors and reference lists have been kept proprietary in two subscription databases, the Web of Science and Scopus. Only researchers with access to these databases have been able to confidently trace citation patterns in the scholarly record and analyse the impact of particular research fields or institutions. But citation data could soon emerge from behind their paywalls. The  Initiative for Open Citations (I4OC)  aims to allow anyone to access science papers\u2019 reference lists and to build analytical services on top of those raw data. The venture, started last year by the Wikimedia Foundation in San Francisco, California and five other partners, announced at its official launch on 6 April that 29 organizations, including some of the world\u2019s largest scientific publishers, have now agreed to openly release citation data. \u201cFor the first time in history, swathes of scholarly citation data from the largest publishers \u2014 data that constitutes the very fabric of scientific knowledge \u2014 become available to the public with no copyright restrictions whatsoever,\u201d says Dario Taraborelli, head of research at the Wikimedia Foundation. All science publishers already deposit their citation data at a non-profit organization,  Crossref , which the industry established in 2000. But until recently, only around 1% of that data had been freely available, Taraborelli says. Now, as a result of I4OC\u2019s efforts, some 40% of the data are free. \u201cOur aim is to reach 100% coverage soon and to see more publishers and open-data organizations join the initiative,\u201d he says. \n             Spot and fix errors \n           Publishers committed to the project include two of the initiative\u2019s co-founders: eLife and the Public Library of Science (PLOS). Other large publishers involved include EMBO Press, Wiley, Taylor & Francis and Springer Nature (the publishers of  Nature ). But Dutch publishing giant Elsevier, which contributes an estimated 30% of citation data on Crossref, is not yet on board. Elsevier also owns Scopus. (Web of Science is owned by Clarivate Analytics, which bought it from Thomson Reuters last year.)\u201cWe are aware of the initiative but want to learn more before making a decision on whether to participate,\u201d says Tom Reller, vice-president of corporate relations with Elsevier in New York.Making citation data open should have many advantages, says Catriona MacCallum, advocacy director with PLOS in Oxford, UK. In particular, she says, it should be easier to spot and fix errors in openly accessible citation records than it is to correct inaccuracies in closed commercial databases. The launch of I4OC means that any publisher, funder or researcher will be able to calculate the impact of their papers free of charge, potentially using new kinds of citation-based indicators that commercial firms don\u2019t yet provide. But the drive for open records has a long way to go, MacCallum says. The records on CrossRef are raw data, not organized or structured so that non-experts can query them in useful ways (such as asking for the highest-cited paper published by a particular university in a particular year). \u201cBuilding a structured database for users to be able to query and make full benefit of the data might take a few years,\u201d she adds. Still,  open-knowledge projects such as Scholia  are already starting to integrate information to provide on-the-fly profiles of researchers, research topics, scholarly works and journals. And the open citation data from CrossRef is a critical resource for these services, says Finn \u00c5rup Nielsen, a data scientist at the Technical University of Denmark at Kongens Lyngby. I4OC can\u2019t yet compete, in terms of coverage, with subscription databases that sell curated bibliographic records. \u201cThese databases are orders of magnitude larger than what we can provide today,\u201d says Taraborelli. But he hopes that, in the long run, open-data management by a large set of players will outperform services by commercial providers.  Wikipedia ultimately overtook the popularity of services offered by Encyclopaedia Britannica , he notes. \u201cI think the Wikipedia story teaches us something compelling about what commons-based communities can achieve,\u201d he says.  \n                   Beat it, impact factor! Publishing elite turns against controversial metric 2016-Jul-08 \n                 \n                   Rate that journal 2015-Mar-30 \n                 \n                   The top 100 papers 2014-Oct-29 \n                 \n                   Publishing: Open citations 2013-Oct-16 \n                 \n                   I4OC \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21752", "url": "https://www.nature.com/articles/nature.2017.21752", "year": 2017, "authors": [{"name": "Elie Dolgin"}], "parsed_as_year": "2006_or_before", "body": "More than 30% of biomedical studies funded by the US government are later cited in commercial patents. US President Donald Trump wants to gut government funding for biomedical research, but an analysis suggests that projects backed by the country\u2019s National Institutes of Health (NIH) have much broader economic benefits than suspected. Between 1980 and 2007, 8.4% of NIH grants led directly to a patent, researchers report today in  Science 1 . But more than three times that number \u2014 30.8% \u2014 produced a scientific article that was later cited in a commercial patent for a drug, device or other medical technology. That indirect benefit was more pronounced for patents related to drugs sold in the United States, with less than 1% of NIH grants leading directly to patents but 5% spawning papers that were mentioned in a patent related to a drug that reached the market. Politicians tend to focus on  how often academic researchers obtain patents or create companies  based on their work, says Marty Grueber, research director for the consulting firm TEConomy Partners in Cleveland, Ohio. But the analysis shows that research supported by the NIH has a surprisingly big indirect impact on patent activity \u2014 a proxy for overall economic benefit. \u201cWhether we focus on scientific or technological advancement, these findings underscore the value of investing in a diverse portfolio of work,\u201d said Mike Lauer, the NIH\u2019s deputy director for extramural research, in a statement. The  Science  analysis comes at a pivotal moment for the agency. Trump has proposed  cutting the NIH\u2019s roughly US$32-billion budget by 18% , or $5.8 billion, in 2018. And the president is rumoured to be pushing for a $1.2-billion cut from the agency\u2019s 2017 budget. Although it\u2019s not clear whether Congress will accept Trump\u2019s plans,  the proposals have made researchers nervous . \n               Waste not \n             Lawmakers who want to shrink the budget of science-funding agencies often single out studies that they view as wasteful. In January, for example, Republican Senator Jeff Flake of Arizona lampooned the NIH\u2019s decision to spend $817,000 on a study about the evolution of proteins found in primate saliva \u2014 one of 50 projects that the senator highlighted in a report called \u2018Wastebook: PORK\u00e9mon Go\u2019. But it\u2019s exactly this kind of basic research that can yield unexpected commercial windfalls, says study co-author Danielle Li, an economist at Harvard Business School in Boston, Massachusetts. \u201cJust because a grant doesn\u2019t seem to scream, \u2018I\u2019m going to be extremely commercially relevant\u2019 or \u2018I\u2019m going to cure cancer\u2019 doesn\u2019t mean it might not cure cancer,\u201d she says. The study by Li and her colleagues, which examined more than 365,000 grants issued between 1980 and 2007, also considered whether funding for basic or applied research triggered more patents. The scientists sliced and diced the definition of \u2018basic research\u2019 every way they could think of, but in each of their analyses, basic and applied research were equally likely to be cited in patents. \u201cTheir findings here demonstrate that there is commercial value to funding basic science,\u201d says Ross DeVol, chief research officer at the Milken Institute, an economics think tank in Santa Monica, California. \u201cThat may be the most important piece of this, to be quite frank.\u201d \n               Paper trail \n             Li\u2019s study builds on a 2015 report in which Grueber showed that every $100 million the NIH hands out in grants leads to about six new patents 2 . Those estimates, however, omitted the knock-on effects of scientific papers \u2014 which are, after all, the main output of the academic system. When Li and her colleagues included the impact of papers later cited by patents, they found that the average number of patents produced by a $100-million boost in NIH funding went up to 23. The researchers then used a series of rough calculations to extrapolate the commercial impact of those patents. As they report in a companion paper currently under review at an economics journal 3 , each $1 in NIH funding generates an estimated $1.40 in drug sales \u2014 a figure that doesn\u2019t include the economic benefit accrued through the development of devices, surgical techniques, public-health improvements or other non-pharmaceutical applications of NIH-supported research. From an economic standpoint, \u201cwe\u2019re under-investing overall\u201d in biomedical research, says Pierre Azoulay, an economist from the Massachusetts Institute of Technology\u2019s Sloan School of Management in Cambridge, and Li\u2019s co-author on both studies. \u201cThe idea that we\u2019re going to get to a better place by cutting [the NIH budget] is ridiculous.\u201d \n                     Trump faces backlash on health-agency cuts 2017-Mar-17 \n                   \n                     US science agencies face deep cuts in Trump budget 2017-Mar-16 \n                   \n                     Trump's pick for US health secretary has pushed to cut science spending 2016-Nov-29 \n                   \n                     US science agencies face budget limbo 2016-Sep-06 \n                   \n                     Does innovation always come from science? 2015-Oct-28 \n                   \n                     Science economics: What science is really worth 2010-Jun-09 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21761", "url": "https://www.nature.com/articles/nature.2017.21761", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "But the child's parents have decided to forego long-term monitoring by researchers. When a US fertility clinic revealed last year that it had created a baby boy  using a controversial technique that mixes DNA from three people , scientists were quick to raise the alarm. Some objected on ethical grounds, and  others questioned the scientific claims  made by the clinic\u2019s leader, physician John Zhang. Now, after months of intense debate and speculation, Zhang\u2019s team has provided more details about the child\u2019s conception, in a paper published on 3 April in  Reproductive Biomedicine Online 1 . But major questions remain about the long-term health of the boy, and whether the experiment will ultimately advance reproductive medicine. Techniques to create \u2018three-parent babies\u2019 seek to offer mothers a way to have a child without passing on metabolic diseases caused by faulty mitochondria, the structures that provide energy to cells. Researchers do this by exchanging the diseased mitochondria of a prospective mother with those of a healthy, unrelated donor:  the \u2019third parent\u2019 . In this case, a team led by Zhang, who works at the New Hope Fertility Center in New York City, removed the nucleus from a healthy donor egg and replaced it with a nucleus taken from the egg cell of a woman who carries a rare neurological disease called Leigh syndrome, leaving the donor\u2019s healthy mitochondria intact. The scientists then fertilized the modified egg with the father\u2019s sperm before implanting it into the mother\u2019s uterus. The resulting baby was born in April 2016. The paper reports new details about the procedure, such as the method used to transfer the mitochondria: freezing and heating the embryo before using an electrical pulse to fuse the mother's nucleus into the donor egg. The study also reveals that some diseased DNA from the mother was carried over inadvertently into the donor egg, which could have long-term repercussions for the child's health. Other scientists welcomed the new information. \u201cCertainly, this is a landmark study,\u201d says Dietrich Egli, a stem-cell scientist at the New York Stem Cell Foundation. \n               Genetic legacy \n             But the big question remaining is whether the child's health will be affected by the traces of the mother's mitochondrial DNA that he carries, which could prompt some of his mitochondria to function improperly. The percentage of affected mitochondria can differ between tissues. Zhang's paper reveals that just 2% of the mitochondrial DNA of cells in the boy\u2019s urine came from the mother, but that figure rose as high as 9% in cells from the child\u2019s circumcised foreskin. Organs such as the heart or brain are impossible to test without invasive surgery. Scientists don't know what amount of diseased mitochondria would cause noticeable symptoms, or even disease, in a child created using genetic material from two women. But studies in mice have shown that mixtures of mitochondria can result in neurological disorders or metabolic conditions 2 . It is not clear how these results will compare to the outcome of mitochondrial replacement in people. \u201cWhatever we learn in a person will be completely new,\u201d Egli says. But the answers are not likely to come from the child born in Zhang's clinic. The study says that the baby\u2019s parents have refused any further mitochondrial testing on the baby unless there is a medical need. It is not clear whether the family was ever asked to consent to long-term medical monitoring; Zhang and New Hope did not respond to  Nature 's request for comment on the matter. The value of the experiment will be limited if scientists cannot track the boy as he grows, Egli says. \u201cIt looks like a rush to use this as a treatment and telling patients that this is the treatment, during a time when we still know very little about what the outcomes are.\u201d \n               Advise and consent \n             Government regulations and other guidelines for human research generally require that people be allowed to withdraw from experiments. When this happens, it can make it hard to determine whether a treatment is safe, says Alta Charo, a bioethicist at the University of Wisconsin\u2013Madison. In this case, she says, it is unclear whether the parents received enough information to appreciate how long-term follow-up could benefit their child as well as science. A three-page editorial 3  accompanying the study notes that the researchers had the baby's parents sign a consent form acknowledging that their egg was undergoing an experimental technique. But the form only described the procedure superficially, and did not inform the couple of  the potential risks of using this method to create a child . Because the boy could not give consent, \u201cthe duties were even higher for clinicians and participants to protect the best interest of the future child\u201d, says Rosario Isasi, a legal scholar at the University of Miami in Florida. In his paper, Zhang says that the parents received \u201ccautious counselling for mitochondrial replacement therapy\u201d. He told  Nature  that his team will continue to test the technique, using eggs from prospective mothers who are between 42 and 47 years of age. They want to explore whether mitochondria from younger donors\u2019 cells may stimulate the older eggs' ability to be fertilized and develop normally. \n                     Historic decision allows UK researchers to trial \u2018three person\u2019 babies 2016-Dec-15 \n                   \n                     Reports of \u2018three-parent babies\u2019 multiply 2016-Oct-19 \n                   \n                     \u2018Three-parent baby\u2019 claim raises hopes \u2014 and ethical concerns 2016-Sep-28 \n                   \n                     Three-person embryos may fail to vanquish mutant mitochondria 2016-May-19 \n                   \n                     The hidden risks for \u2018three-person\u2019 babies 2015-Sep-23 \n                   \n                     Reproductive medicine: The power of three 2014-May-21 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21755", "url": "https://www.nature.com/articles/nature.2017.21755", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Early studies fuel scientists\u2019 determination to understand how immunotherapy may sometimes make disease worse. Powerful drugs that unleash the immune system hold the promise to wipe out cancer for some people with advanced disease. But two recent studies 1 , 2  suggest that  these therapies, called PD-1 inhibitors , may backfire in some patients \u2014 speeding cancer\u2019s spread. Now scientists want to find out why. The latest studies are too small to justify a change in how physicians treat patients. But the research has prompted calls for bigger clinical trials to explore how immunotherapy drugs that are intended to rein in tumours could instead spur them on. \u201cWith these small numbers, you\u2019re always stuck being a little unsure,\u201d says Elad Sharon, a cancer researcher at the US National Cancer Institute in Bethesda, Maryland. What\u2019s needed, he says, is larger studies that make tumour images available for analysis by outside scientists. He would also like to see cancer researchers reach beyond their specialty. \u201cWhat we should be doing probably is more cross-pollinating with other branches of medicine that look at the immune system,\u201d he says. Over the past five years, immunotherapies  have revolutionized the treatment of some stubborn cancers . Although some of these treatments  come with severe side effects , the unwanted effects of PD-1 inhibitors are relatively mild compared with those of many other cancer drugs. This has led some physicians to give PD-1 inhibitors to people with cancer who have tried all other treatments -- even if the immunotherapy has not been shown definitively to work for their disease, says cancer researcher and physician Razelle Kurzrock of the University of California in San Diego. \u201cEven if there\u2019s a small chance of a response, the response itself can be so good,\u201d she says. \u201cWe\u2019ve developed the attitude: let\u2019s go ahead and try it.\u201d But one day Kurzrock compared notes with a colleague and found that each of them had a patient whose tumours had grown unusually fast during treatment with PD-1 inhibitors. Her colleague came back a few days later and noted that the patients shared the same rare genetic alteration: extra copies of the cancer-driving genes  MDM2  or  MDM4 . \n               Warning signs \n             Kurzrock began asking around, collecting anecdotes about people \u2014 and even about laboratory mice \u2014 whose tumours had advanced rapidly after treatment with an immunotherapy. Even after collecting examples from several sources, she felt nervous about releasing her results. \u201cWe thought, \u2018Who\u2019s going to publish this? They\u2019re not going to believe us,\u2019\u201d she says. Meanwhile, researchers at the Gustave Roussy Institute in Villejuif, France, had stumbled on the same problem. Charles Fert\u00e9, an oncologist at the institute, recalls attending a meeting in which several physicians reported bizarre responses to PD-1 treatment. \u201cSome friends and colleagues were saying, \u2018I treated lung patients with that drug and the tumour completely exploded in two weeks\u2019,\u201d says Fert\u00e9. Fert\u00e9 and his colleagues decided to launch a systematic study of tumour growth in their patients. Last November, they published their results: of 131 people who received anti-PD-1 therapies, 9% developed what the investigators called \u201chyperprogressive\u201d disease, with accelerated tumour growth 1 . The phenomenon appeared to be more common in people over the age of 65. On 28 March, Kurzrock and her colleagues published their data from 155 people treated with PD-1 inhibitors and other immunotherapies 2 . Six of the people had extra copies of  MDM2  or  MDM4  and 10 had mutations in a gene called  EGFR , which is associated with cancer. The team did not see any correlation between age and rapidly worsening disease, but they did notice that tumours grew faster in four of those with the extra  MDM2  or  MDM4  genes, and in two of the people with  EGFR   mutations. \n               The hunt continues \n             Both teams are still trying to understand how immunotherapy might backfire in cancer patients. Kurzrock speculates that the drugs could be unleashing proteins called \u201cgrowth factors\u201d that stimulate certain tumours. Sharon, who was not involved in either study, wonders if clues could be gleaned from research on the PD-1 protein\u2019s effects on infectious diseases. Early studies found that blocking the protein could stimulate immune responses against some viruses, but suppressed responses to the mycobacterium that causes tuberculosis. For now, Sharon says there is still not enough evidence to say for sure that the rapid tumour growth can be pinned on immunotherapy. The measures that Ferte\u2019s team used to study tumour growth have not yet been widely tested for use in clinical studies, he notes. \u201cWhat if this happens with other drugs as well, and we just weren\u2019t looking for it?\u201d he says. \u201cI would like to see more evidence.\u201d Fert\u00e9 agrees that the evidence against immunotherapy is not strong enough to warrant dramatic changes in how patients are treated. \u201cI would still prescribe it for older patients,\u201d he says. \u201cBut we will pay special attention.\u201d  \n                     Cruel fusion: What a young man\u2019s death means for childhood cancer 2017-Mar-28 \n                   \n                     Cocktails for cancer with a measure of immunotherapy 2016-Apr-13 \n                   \n                     Immune cells boost cancer survival from months to years 2014-Dec-10 \n                   \n                     Cancer treatment: The killer within 2014-Apr-02 \n                   \n                     Sizing up a slow assault on cancer 2013-Apr-03 \n                   \n                     Nature Outlook: Cancer immunotherapy \n                   \n                     US National Cancer Institute: Immunotherapy \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21779", "url": "https://www.nature.com/articles/nature.2017.21779", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Academics protest over government's 'dual use' research programme \u2014 which received a big funding boost. The Japanese science community is pushing back against government attempts to enlist academic scientists into research with possible military applications. The Science Council of Japan, an advisory body to the cabinet, representing some 850,000 Japanese scientists, released a  statement on 24 March  calling on scientists to boycott military research and for universities and research organizations to evaluate the threats posed by such work. Since the end of the Second World War, Japan has remained staunchly pacifist.  The council\u2019s statement comes as Japan\u2019s government has dramatically increased funding for a programme through which scientists can apply for grants covering 'dual use' research: the development of technologies for civilian or commercial purposes, but which could also have a military use. The programme\u2019s budget was \u00a5300 million (US$2.7 million)  when it launched in 2015 , before doubling the next year. In the financial year starting in April 2017, spending will balloon to \u00a511 billion to cover projects to be selected in August. The programme is run by the defence ministry's Acquisition, Technology and Logistics Agency (ATLA). Last year, it funded a range of projects, including research on new lasers, on micro-bubble coatings to reduce friction on ships, and on films for cloaking devices. Yuko Ito, a science-policy expert at the Japan Science and Technology Agency, thinks that the programme was established partly in response to rescue efforts following  the Fukushima nuclear disaster  in 2011. Problems arose, for example, when Japanese robots were unable to function in the highly radioactive conditions. But Morihisa Hamada, a geochemist at the Japan Agency for Marine-Earth Science and Technology in Yokohama, sees a more nefarious\u00a0driver \u2014 the economic policies of Prime Minister Shinzo Abe, known as  Abenomics . In 2014, as part of a move to boost the economy through deregulation, Abe's party dropped the country\u2019s ban on exporting weapons. \u201cEnlisting the cutting-edge technology of universities and research institutes to produce military arms more cheaply and then sell them abroad is part of the Abenomics growth strategy,\u201d says Hamada. \n             Balancing interests \n           Neither Hamada nor Takashi Onishi, president of the Science Council of Japan, take issue with specific projects funded in the programme\u2019s first two years. But the council is concerned that grant winners are selected by defence-ministry officials, without any external committee. The dual-use programme will ultimately impinge on \u201cthe freedom and autonomy of scientific research\u201d, its statement says. Atsushi Sunami, a science-policy researcher at the National Graduate Institute for Policy Studies in Tokyo who has advised the government and military on science and technology matters, says that ATLA wants to ensure that the researchers funded by the dual-use programme can stick to basic research and publish their findings \u2014 but has not clarified how it will achieve such openness. Sunami says he has suggested to the government that they bring in outside experts to design and operate their programme. More than a dozen universities,\u00a0including the University of Tokyo, Nagoya University and Waseda University, have charters, guidelines or presidential decrees that forbid or dissuade researchers from accepting dual-use grants, notes Hamada, who has attempted to organize resistance against the programme since its launch. Some, including the University of the Ryukyus, Niigata University, Tohoku University and Kyoto University, have announced such policies in the last two years with specific reference to the defence ministry\u2019s dual-use programme. Hamada says the council\u2019s statement should put even more pressure on universities to avoid dual-use research. It seems that individual scientists are voting with their feet, too, says Hamada. There were 109 applicants for the programme in 2015, but only 44 in 2016. \u201cWe helped to get the word out about the dangers of military-academic research,\u201d he says. \u201cThe spirit of peace is strongly rooted in our society.\u201d Yet critics of dual-use research will face an uphill struggle, says Sunami. Cash-strapped universities need new sources of funding, and university researchers are already working closely\u00a0with companies that are in business with the defence ministry. \u201cToday\u2019s science cannot be separated completely from dual-use technology,\u201d he says. \u201cIt\u2019s a global trend.\u201d \n                   Peaceful European Union starts to fund military research 2016-Dec-21 \n                 \n                   Military technology: Death by remote control 2016-Jun-29 \n                 \n                   South Korean scientists fight plan to scrap military exemptions 2016-Jun-13 \n                 \n                   Military technology: Laser weapons get real 2015-May-27 \n                 \n                   Japanese academics spooked by military science incursions 2015-May-05 \n                 \n                   Nature special: Beyond the bomb: Science and the military \n                 \n                   \n                       Science Council of Japan statement \n                     \n                 \n                   \n                       Science Council of Japan \n                     \n                 \n                   \n                       Acquisition, Technology and Logistics Agency \n                     \n                 \n                   No military research campaign \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21753", "url": "https://www.nature.com/articles/nature.2017.21753", "year": 2017, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "Teenage mother who lived 12,000 years ago was malnourished but still roamed widely. For more than 12,000 years, the adolescent girl\u2019s bones lay deep in a Mexican cave. Now analysis of her skeleton is revealing details of her harsh existence in the early Americas \u2014 which probably included pregnancy and childbirth before death at a young age. The bones show that the girl,  whom researchers nicknamed Naia , is likely to have travelled long distances on foot, but didn\u2019t carry much on her journeys. The skeleton also reveals that Naia experienced severe and repeated nutritional stress that scarred her bones and teeth, according to results presented on 30 March at a meeting of the Society for American Archaeology in Vancouver, Canada. \u201cShe\u2019s telling us a story,\u201d says James Chatters, an archaeologist with Applied Paleoscience in Bothell, Washington, and principal investigator of the research on Naia, a project of Mexico\u2019s National Institute of Anthropology and History in Mexico City. \u201cIt was a very hard life.\u201d Naia has already helped to illuminate the origins of the first Americans. In 2014, Chatters and his colleagues reported that her DNA confirms the idea that  a single group of Asian emigrants  gave rise to both the earliest American settlers and modern Native Americans 1 . For that work, divers examined Naia in the water-filled cavern in the Yucat\u00e1n Peninsula where she was discovered in 2007. But intruders subsequently tampered with her remains. To prevent further meddling, the bones were gently carried out of the cave in 2014 and 2016 \u2014 which also gave scientists easier access to the specimens. \n               Rail-skinny skeleton \n             Roughly half of Naia\u2019s bones were recovered, including an intact skull, both arms and one leg, making her among the most complete of the handful of New World skeletons that are more than 12,000 years old. Her bones reveal a teenager aged 15\u201317 at her death, which was probably the result of a fall into the deep pit where she was found. She was \u201crail-skinny\u201d, Chatters said, with one upper arm bone only as thick as his little finger. Naia\u2019s slight build might have been linked to nutritional stress. Her shin bone and knee are striped with lines etched by halting growth, perhaps as a result of too little food, or health problems \u2014 such as parasite infections \u2014 that prevented her from absorbing nutrients. Irregularities in her teeth reinforce the suggestion that her nutrition was \u201crather limited quite often\u201d, Chatters says. A small portion of Naia\u2019s pelvis broke off when she plummeted into the pit, and was lost. But her remaining pelvic bones are pitted in a way often seen in young, slight woman who have given birth. That\u2019s a strong indicator she had gone through labour, and the healing of the bone means that she gave birth well before her death, says Chatters, who is collaborating with scientists at the Autonomous University of of Yucat\u00e1n in M\u00e9rida, Mexico. Naia\u2019s upper-arm muscles were not heavily developed, judging by the smoothness of the bones where those muscles were once attached. She didn\u2019t routinely grind seeds, work animal skins or carry heavy loads \u2014 common tasks during her time. But Naia's shin- and thighbone show that her legs were heavily muscled, meaning that she probably roamed widely over the landscape. The team\u2019s analysis was competent and thorough, says Gary Haynes, an archaeologist at the University of Nevada, Reno. He thinks Naia\u2019s thinness might be due to \u201cenvironmental changes of the time [that] were making life harder and harder by removing resources, or making them less dependable\u201d. \u201cWe get the sense that the lives of the first Americans were wonderful and easy,\u201d Chatters says. \u201cWell, it isn\u2019t necessarily the case.\u201d \n                     Plant and animal DNA suggests first Americans took the coastal route 2016-Aug-10 \n                   \n                     \u2018Ghost population\u2019 hints at long-lost migration to the Americas 2015-Jul-21 \n                   \n                     Bone DNA reveals humanity\u2019s trek into South America 2015-Apr-29 \n                   \n                     Mexican skeleton gives clue to American ancestry 2014-May-15 \n                   \n                     Ancient migration: Coming to America 2012-May-02 \n                   \n                     Website on Hoyo Negro cave excavation project, including Naia skeleton \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21798", "url": "https://www.nature.com/articles/nature.2017.21798", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "The Klosneuviruses contradict the theory that viruses make up a distinct domain of life, but not everyone is convinced. Evolutionary biologists have never known what to make of viruses, arguing over their origins for decades. But a newly discovered group of giant viruses, called Klosneuviruses, could be a missing link that helps to settle the debate \u2014 or provokes even more discord. In 2003, researchers reported that they had found giant viruses, which they named Mimiviruses, with genes that suggested their ancestors could live outside a host cell 1 . The discovery split researchers into two camps. One group thinks viruses started out as self-sufficient organisms that became trapped inside other cells, eventually becoming parasitic and jettisoning genes they no longer needed. Another group views viruses as particles that snatched genetic material from host organisms over billions of years. A study 2  published on 6 April in  Science  provides evidence for the latter idea, that viruses are made up of a patchwork of stolen parts. But it has already sparked controversy, and is unlikely to settle the raucous debate. After the Mimivirus discovery, some researchers developed a theory that put viruses near the root of the evolutionary tree. They proposed that viruses comprised a \u2018fourth domain\u2019 alongside bacteria, eukaryotes \u2014 organisms whose cells contain internal structures such as nuclei \u2014 and bacteria-sized organisms called archaea. Mimiviruses, which at 400 nanometres across are about half the width of an  E. coli  cell and can be seen under a microscope, were unique in that they contain DNA encoding the molecules that translate RNA messages into proteins. Normal viruses make their host cells produce proteins for them. The team that discovered Mimiviruses thought the ability to make their own proteins suggested that these viral giants were once part of an ancient free-living cell type that may no longer exist 2 . \u201cThey reinitiated the debate about the living nature of viruses, and of their relationship with the \u2018cellular\u2019 world,\u201d says evolutionary biologist Jean-Michel Claverie of Aix-Marseille University in France, a co-author of the original Mimivirus paper. \n             Filling in the gaps \n           The question could be resolved by comparing genome sequences from viruses with those of their eukaryotic hosts. But Mimiviruses contain only a few eukaryote-like genes \u2014 which isn\u2019t enough for researchers to perform a statistical analysis on them. The difficulty is compounded by the fact that viral genomes mutate very quickly. Klosneuviruses may fill this gap. Their genomes contain code for dozens of enzymes and other molecular machinery used in protein translation. Some of these parts have never been seen before in any virus, including Mimiviruses. \u201cThey\u2019re kind of this missing link we haven\u2019t had before,\u201d says study co-author Tanja Woyke, a microbiologist at the Joint Genome Institute in Walnut Creek, California. Woyke and her colleagues discovered the Klosneuviruses by accident while studying how bacteria break down sewage at a treatment plant in Austria. They sequenced the genomes in their samples to identify the organisms present, and found four genomes similar to those of Mimiviruses. Using sophisticated software to trace the evolutionary history of their mystery genomes, the researchers found that the translation genes seemed to have been picked up one by one over billions of years. Evidence they say supports the idea that viruses stole parts of their genomes. It's possible, however, that both ideas on the origin of viruses are correct, says Frederik Schulz, a bioinformatician at the Joint Genome Institute and a co-author on the new study.  \n             Debating domains \n           It\u2019s unclear which eukaryotic organisms donated their genes to the Klosneuvirus group. And because they haven't identified the host, the researchers can't grow the virus yet. The viruses do not seem to infect the same type of amoeba as Mimivirus and other known giant viruses. Claverie points out that the majority of the Klosneuviruses\u2019 translation machinery does not match that of any other known organism. And he worries that the computational model used to extrapolate the viruses\u2019 ancestry could pick up leftover pieces of DNA in the sample, potentially contaminating the data. \u201cI am waiting to see a real virus isolated with its host in a tube, before I would believe any of their evolutionary interpretations,\u201d he says. David Moreira, an evolutionary biologist at the University of Paris South, doesn\u2019t think that\u2019s necessary. He says that plenty of evolutionary work can be done on a genome alone, and he is glad to see more papers coming to the conclusion that viruses are not a fourth domain of life. Mimivirus co-discover Didier\u00a0Raoult, a microbiologist at Aix-Marseille University, says this latest discovery won\u2019t settle the debate, but it\u2019s a nice find nevertheless. \u201cWe\u2019re finding a part of the world that has been completely ignored, and need to be patient.\u201d \n                   Giant virus resurrected from 30,000-year-old ice 2014-Mar-03 \n                 \n                   Giant viruses open Pandora's box 2013-Jul-18 \n                 \n                   The challenge of microbial diversity: Out on a limb 2011-Aug-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21802", "url": "https://www.nature.com/articles/nature.2017.21802", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "US Food and Drug Administration says firm can provide consumers with information on genetic risks. The US Food and Drug Administration (FDA) has approved the first at-home genetic test that can help to determine a person\u2019s risk of developing certain diseases. Today\u2019s long-awaited action allows the consumer-genetics firm 23andMe to market a test for 10 genetic conditions, including Alzheimer\u2019s and Parkinson\u2019s diseases, to consumers \u2014 and paves the way for a wave of do-it-yourself diagnostic tests. The company says that it will begin offering the new service in the coming months. \u201cIt\u2019s a watershed moment for us and the FDA,\u201d says Kathy Hibbs, chief legal and regulatory officer at 23andMe, which is based in Mountain View, California. \u201cWe are all really tired and really happy.\u201d Since 2006, people have been sending small vials of spit to the company, which analyses the DNA within the saliva to provide genetic insights into its customers\u2019 ancestry and traits, such as hair colour. The company once offered DNA testing that described a person\u2019s risk of developing 240 health conditions, but  the FDA ordered 23andMe to halt the service in 2013 . The agency was concerned that consumers would rely on the company\u2019s information to make medical decisions, despite uncertainty about its accuracy. Two years later, in 2015,  the FDA eased those restrictions , allowing 23andMe to reveal whether its customers carried genetic glitches that could cause any one of 36 diseases in their children. Such tests do not provide information about a person\u2019s own disease risk, however. Today\u2019s ruling allows 23andMe to tell its customers whether they possess genetic mutations that are strongly associated with a small group of medical conditions; these include Parkinson\u2019s disease, late-onset Alzheimer\u2019s disease, coeliac disease and a hereditary blood-clot disorder called thrombophilia. But this testing is not equivalent to a medical diagnosis, because lifestyle, family history and environment also influence a person\u2019s risk of developing disease. Hank Greely, a bioethicist at Stanford University in California, worries that consumers might not understand the limits of the test results without help from a genetic counsellor or a physician \u2014 particularly as 23andMe expands the medical conditions that it covers, and other companies begin to offer similar services. \u201cI\u2019m not a big fan of cutting out the middleman when the middleman is a trained professional and most of the country doesn\u2019t understand much about health,\u201d Greely says. Still, he is pleased by the FDA\u2019s decision because it could reduce companies\u2019 incentive to look for loopholes in the US government\u2019s rules for genomic tests. Since 2010, the agency has sent letters to more than 20 firms suggesting that their products be regulated as medical devices. \u201cThis shows that working with the FDA can be a route forward,\u201d Greely says. \u201cSilicon Valley has a neurosis about the FDA and regulation, and that is not helpful \u2014 particularly in healthcare, where lives are at stake.\u201d  \n                   Out of regulatory limbo, 23andMe resumes some health tests and hopes to offer more 2015-Oct-27 \n                 \n                   Scientists hope to attract millions to 'DNA.LAND' 2015-Oct-09 \n                 \n                   Consumer DNA firms get serious about drug development 2015-Apr-28 \n                 \n                   Regulation: The FDA is overcautious on consumer genomics 2014-Jan-15 \n                 \n                   The FDA and me 2013-Dec-03 \n                 \n                   23andMe ordered to halt sales of DNA tests 2013-Nov-25 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21791", "url": "https://www.nature.com/articles/nature.2017.21791", "year": 2017, "authors": [{"name": "Henry Nicholls"}], "parsed_as_year": "2006_or_before", "body": "Funds approved for plan to round up last 30 vaquitas into protective 'sea pens'. An ambitious effort to save a diminutive porpoise called the vaquita has received the official clearance to move forward. The vaquita (Phocoena sinus) is found only in Mexico\u2019s Gulf of California, where there are just 30 of them left. On 3 April, the Mexican government announced that it would give US$3 million to the  VaquitaCPR  (conservation, protection and recovery) plan to save them. A further $1 million was donated on the same day by the  Association of Zoos and Aquariums  in Silver Spring, Maryland. The project, which will use dolphins specially trained by the US Navy to corral as many vaquitas as possible so they can be put into protective pens in their natural habitat, also got the green light to start from the Mexican government. The funds have come too late for work to start in the next suitable window, in May; after that, the gulf gets too choppy. But conservationists hope to start when conditions improve again in October. The vaquita population has crashed over the past two decades. The first dedicated survey, in 1997, revealed that there were 567 individuals in the gulf \u2014 but by 2015, this figure had plummeted to just 59.  The latest estimate , from 2016, suggests approximately 30 vaquitas remain. The alarming decline is largely down to the porpoises drowning in gill nets set to capture huge, bass-like fish called totoaba ( Totoaba macdonaldi ). So in 2015, the Mexican government banned the use of gill nets for two years and offered compensation to fishers. \n             Black market \n           But with the totoaba\u2019s swim bladder fetching tens of thousands of dollars on the black market in China, the fishing has continued apace. \u201cThe price is just like drugs,\u201d says Lorenzo Rojas-Bracho, a marine conservation biologist at the National Institute of Ecology and Climate Change in Ensenada, Mexico, and chair of the International Committee for the Recovery of the Vaquita (CIRVA). \u201cAs long as there\u2019s that amount of money, there\u2019s a market.\u201d Conservationists fear that the vaquita will share the fate of the Yangtze River dolphin, or baiji ( Lipotes vexillifer ), whose probable extinction was discovered by a 2006 expedition. \u201cWe did not anticipate going out on that survey and not seeing a single baiji, and not hearing a single whistle,\u201d says Barbara Taylor, a conservation biologist at the US National Oceanic and Atmospheric Administration\u2019s Southwest Fisheries Science Center in La Jolla, California, and a member of CIRVA. \u201cMy resolve was stiffened not to repeat that with vaquita.\u201d\u00a0 The first challenge will be to locate some vaquitas in the 2,000-plus square kilometres of the gulf where they are known to live. Previous acoustic data, which tracked the animals' sonar clicks will give an idea of their whereabouts, but vaquitas roam singly or in pairs, and are difficult to spot. They also tend to swim away from motorized vessels, which is why two US Navy dolphins trained to echolocate porpoises have been enlisted. \u201cThe Navy dolphins can easily follow them along like golden retrievers and let us more easily keep track of where the animals are, to let the capture team have their best opportunity to be in the right place at the right time,\u201d says Taylor. And once spotted, a vaquita must be safely captured and transported to the proposed holding site, north of San Felipe on the west coast of the gulf. \n             High risk \n           Several designs of holding pen are being tested. The first pens will be up to 10 metres in diameter and up to 3 metres deep, and will keep the vaquitas away from gill nets, says Rojas-Bracho. If the plans succeed, a more permanent facility will be built. The scientists hope that the vaquitas will adjust to captivity and even breed in the pens. Bold rescue operations have worked before: the last 27 California condors ( Gymnogyps californianus ) were taken into captivity in the 1980s, and their numbers grew enough for some condors born in captivity to have been released back into the wild. The vaquita team hopes to learn from these experiences, but much is uncertain. \u201cNo one has ever tried to catch vaquita to keep them alive,\u201d says Randall Wells at the Chicago Zoological Society in Illinois, and a member of the VaquitaCPR consortium. \u201cThere is so much of this that is being done for the first time. It\u2019s all high risk.\u201d Others outside the project are hopeful. David Wildt, a senior scientist at the Smithsonian Conservation Biology Institute in Washington DC, thinks the rescue could work. He notes that it is a \u201chuge challenge\u201d, adding that there is \u201cnothing to be lost, and lots to be gained\u201d. \n                   Endangered-porpoise numbers fall to just 250 2010-Jun-08 \n                 \n                   Acoustic sensors for rare porpoise 2008-Nov-26 \n                 \n                   Endangered porpoise worse off than thought 2007-Nov-16 \n                 \n                   The International Union for Conservation of Nature on vaquitas \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21652", "url": "https://www.nature.com/articles/nature.2017.21652", "year": 2017, "authors": [{"name": "Sara Reardon"}, {"name": "Jeff Tollefson"}, {"name": "Alexandra Witze"}, {"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "The Environmental Protection Agency and the National Institutes of Health are big losers \u2014 but planetary science at NASA stands to gain. When it comes to science, there are few winners in US President Donald Trump\u2019s first budget proposal. The plan, released on 16 March, calls for double-digit cuts for the Environmental Protection Agency (EPA) and the National Institutes of Health (NIH). It also lays the foundation for a broad shift in the United States\u2019 research priorities, including a retreat from environmental and climate programmes. Rumours of the White House proposal have swirled for weeks, alarming many researchers who depend on government funding \u2014 and science advocates who worry that the Trump administration\u2019s stance will jeopardize US leadership  in fields ranging from climate science  to cancer biology. It is not clear, however, how much of the plan will survive negotiations in Congress over the coming months. \u201cCutting [research and development] funding from our budget is the same as cutting the engines off an airplane that\u2019s too heavy for take-off,\u201d says Jason Rao, director of international affairs at the American Society for Microbiology in Washington DC. The greatest threats to the United States, he says, are those presented by infectious diseases, climate change and energy production \u2014 none of which can be addressed effectively without scientific research. The White House proposal is also notable for what it does not mention. The barebones document omits detail about many programmes and even entire agencies, including the National Science Foundation (NSF). The president is expected to release a fuller budget request in May. \n               Call for NIH reorganization \n             The Trump budget would cut funding for the NIH by 18%, to $25.9 billion, making it one of the hardest-hit research agencies. The document also calls for a reorganization of the NIH\u2019s 27 institutes \u2014 including the elimination of the smallest, the Fogarty International Center \u2014 but offers no further detail beyond a pledge to \u201crebalance Federal contributions to research funding\u201d. Mick Mulvaney, the director of the White House Office of Management and Budget, expanded slightly on the matter during a 16 March press briefing. \u201cWe think there\u2019s been mission creep\u201d at the NIH, he said. \u201cWe think they do things that are outside their core functions.\u201d That did not sit well with biomedical research advocates. \u201cWe\u2019re pretty upset,\u201d says Jennifer Zeitzer, director of legislative relations at the Federation of American Societies for Experimental Biology in Rockville, Maryland. But she is sceptical that Congress, which generally supports biomedical research, will embrace Trump\u2019s vision for the NIH. Fear over potential spending cuts has been pervasive at the NIH\u2019s National Cancer Institute, according to a scientist contractor there. That is especially true among researchers who work on epidemiological studies that require continued funding to collect data without interruption over many years. \u201cEveryone is worried, but everybody has to work,\u201d says the contractor, who is not authorized to speak about the agency. The Trump proposal would also create a fund within the Department of Health and Human Services, the NIH\u2019s parent, to respond to public health emergencies such as the spread of the Zika virus. Scientists and public health experts have called for such a fund for years, but advocates say that starting one while cutting research and prevention programmes would be counterproductive. \u201cIt\u2019s cheaper to prevent a public health crisis than to treat one after the fact,\u201d says Keith Martin, executive director of the Consortium of Universities for Global Health in Washington DC. \n               Shrinking the EPA \n             The biggest swing of the budget axe \u2014 across the entire budget plan \u2014 is aimed at the EPA. The White House hopes to slash the agency\u2019s US$8.2-billion budget by 31%, and lay off about 3,200 of the agency\u2019s 15,000 staff. The EPA\u2019s Office of Research and Development would have its funding reduced by half, from $483 million to $250 million. The proposed cuts, combined with the Trump administration\u2019s  hostility toward climate and environmental regulations , have sparked fear throughout the agency. \u201cPresident Trump is always talking about creating jobs, but he is talking about cutting 3,000 people at the EPA,\u201d says one EPA biologist who is not authorized to talk to the press. \u201cHe doesn\u2019t even blink an eye.\u201d The biologist, who studies chemicals that affect the endocrine system in fish and potentially in people, is part of a programme that Trump wants to eliminate. To her, the reason for this seems clear: if there\u2019s no science to point out potential problems, there won\u2019t be any more regulations. But Jonathan Adler, who heads the Center for Business Law and Regulation at Case Western Reserve University School of Law in Cleveland, Ohio, says that drastically reducing the EPA\u2019s budget would undercut the Trump administration\u2019s efforts to overhaul environmental policy. Because the agency\u2019s decisions can be overruled or modified by federal courts, the only way to fundamentally reorient programmes is to work with Congress to change the law or rewrite regulations. And that requires staff and money, he says. \u201cIf you cut an agency too much, all you\u2019ve really done is hand the agency\u2019s priorities over to the courts and litigants,\u201d Adler says. \u201cAnd I\u2019m not really sure that\u2019s what the Trump administration wants.\u201d \n               Trimming energy and environment programmes \n             The White House wants to cut 5.6%, or $1.7 billion, from the Department of Energy (DOE). The plan would eliminate the Advanced Research Projects Agency-Energy,  which funds \u2018high-risk, high-reward\u2019 research . And it would slash $900 million, or about 20%, from the department\u2019s Office of Science, which supports research on topics such as high-energy physics, energy, climate change and biology. \u201cCutting the NIH and the DOE this dramatically is surprising,\u201d says Matthew Hourihan, director of research-and-development budget and policy programme at the American Association for the Advancement of Science in Washington DC. \u201cThese are basic science agencies, and there tends to be bipartisan agreement on their value.\u201d The Trump plan does not include an overall funding target for the National Oceanic and Atmospheric Administration (NOAA). But it would eliminate the agency\u2019s long-running, $73-million Sea Grant programme, which supports 33 US colleges and universities that conduct research, education and training about ocean and coastal topics. The budget expresses support for the agency\u2019s \u201ccurrent generation\u201d of weather-satellite programmes, but it offers almost no detail on funding levels. It also pledges to expand the use of commercial data in NOAA weather models and mentions \u201csavings\u201d that could be achieved by delaying the launch of at least one environmental satellite. An earlier, leaked White House budget document proposed a $510 million cut to the agency\u2019s $2.3 billion satellite division, as part of a broader 17% drop in NOAA\u2019s overall funding. \u201cWhile the details are hard to find in this budget, it appears that climate research and climate observing systems are being cut by at least 20%\u201d across the government, says David Titley, NOAA\u2019s chief operating officer from 2012\u20132013 and the former oceanographer of the Navy. \u201cAlthough we don\u2019t know the exact extent of the cut, if you are being led to the gallows and no one is making eye contact with you, it is not a good sign.\u201d NOAA officials are looking at how to restructure the satellite programme in line with such cuts, but those efforts are hampered by the fact that the Trump administration has yet to appoint any senior leaders at the agency. \u201cIt\u2019s not yet clear what trajectory we are taking,\u201d says one senior NOAA official, who declined to be named because he was not authorized to speak publicly. \n               To Europa \u2014 and beyond? \n             In contrast, the White House proposed a cut of just under 1% for NASA. But the Trump plan appears poised to shift the agency\u2019s research priorities, calling for NASA to focus on \u201cdeep-space exploration rather than Earth-centric research\u201d. Within the agency's science directorate \u2014 which encompasses astrophysics, Earth science, heliophysics and planetary sciences \u2014 the planetary division is expected to gain the most. Its budget would grow from $1.6 billion to $1.9 billion. And the White House proposal would accelerate NASA\u2019s plans to explore Jupiter\u2019s moon Europa. For years, lawmakers led by Representative John Culberson (Republican, Texas)  inserted money into NASA\u2019s budget  for a Europa mission \u2014 overriding the judgment of the space agency during the administration of president Barack Obama. NASA is now developing a spacecraft called the Europa Clipper to launch in the 2020s. Its goal is to fly by Europa multiple times, mapping its surface and looking for any signs that life might exist in an ocean beneath the moon\u2019s icy shell. The White House plan would also explicitly cancel the  Obama-era plans to drag an asteroid into lunar orbit  for astronauts to study up-close. And it would cut spending on Earth-science research from $1.9 billion this year to $1.8 billion, eliminating funding for four missions \u2014 including the Orbiting Carbon Observatory-3, which is intended to continue NASA\u2019s efforts  to monitor carbon dioxide concentrations in the atmosphere from space . Also on the chopping block are the Earth-observing instruments aboard the Deep Space Climate Observatory, or DSCOVR. The primary purpose of the satellite, which launched in 2015,  is to track space weather  \u2014 but it was first proposed as an Earth-monitoring mission in the late 1990s by former vice-president Al Gore. Mulvaney, the White House budget director, was blunt when asked about the cuts to climate research in Trump\u2019s plan. \u201cWe\u2019re not spending money on that any more,\u201d he said. \u201cWe consider that to be a waste of your money to go out and do that.\u201d But planetary science\u2019s gain does not necessarily come at the expense of other NASA science divisions, argues Casey Dreier, director of space policy for the Planetary Society, an advocacy group in Pasadena, California. \u201cOn a certain level you have limited resources and you have to make priorities,\u201d he says. \u201cSome divisions growing while others shrink is common among different administrations.\u201d Dreier is not a fan of trimming NASA\u2019s overall budget, however. \u201cNASA is given tasks by the nation,\u201d he says. \u201cWe need to give NASA the resources that will allow them to be successful.\u201d Last month, Trump told Congress that American footprints on distant worlds are not too big a dream \u2014 but those footprints cannot be made without funds, Dreier notes. \n               In the dark at the NSF \n             In a surprising omission, the NSF is not mentioned anywhere in the Trump budget document. Although the $7.5-billion agency has traditionally attracted bipartisan support in Congress, Republican lawmakers have sought in recent years  to limit the NSF\u2019s geoscience and social-science divisions . The Trump plan adds more uncertainty for the agency, which is already struggling to cope with the federal hiring freeze that the president instituted in January. The NSF is scheduled to move its headquarters later this year, and an internal survey suggests that 17% of its 2,000 staff plan to leave within the next two years because of this. The hiring freeze would prevent the agency from replacing many of these employees if they do leave. \u201cI know two individuals who have put off retirement to help out during the hiring freeze,\u201d says a programme director, who asked for anonymity to prevent retaliation. \u201cWe don\u2019t know if they\u2019ll stay past the move, or if some of the people who plan on retiring will put it off.\u201d Overall, the programme director says, \u201cmorale is low\u201d. \n               Next stop: Capitol Hill \n             It is not clear how Congress, which must approve any federal spending plan, will react to the budget proposal. Although the president\u2019s fellow Republicans hold majorities in the House of Representatives and the Senate, some have indicated that they will oppose aspects of the Trump budget. Senator Lisa Murkowski, a Republican from Alaska, told Alaska Public Radio on 13 March that she would fight rumoured cuts to NOAA\u2019s satellite programmes. Other Republican lawmakers have expressed scepticism about the Trump administration\u2019s plan for drastic cuts at the EPA. \u201cThey are proposing nothing less than a dismantlement of several decades of bipartisan support for foundational environmental protections,\u201d says Elgie Holstein, a former budget official under president Bill Clinton who works for the Environmental Defense Fund, an advocacy group in New York City. \u201cThere are going to be a lot of Republicans, as well as Democrats, on Capitol Hill scratching their heads.\u201d So far, the non-political \u2018career\u2019 employees at the agency are trying to remain calm and take a conciliatory approach with Trump\u2019s political appointees. \u201cWe\u2019ve got four years with this administration, so we are trying to educate rather than confront,\u201d says one senior career official. Waleed Abdalati, a former chief scientist at NASA, offers similar advice to researchers who are worried about potential cuts to Earth-science programmes at NOAA and NASA. \u201cRumors are counterproductive,\u201d he says. \u201cRather than complain about what hasn\u2019t happened, we should advocate for what should happen.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Trump and Republicans take aim at environmental agency 2017-Mar-10 \n                   \n                     How the fallout from Trump's travel ban is reshaping science 2017-Mar-02 \n                   \n                     Trump agenda threatens US legacy of science diplomacy 2017-Jan-27 \n                   \n                     Stopgap spending bill leaves US scientists in limbo 2016-Dec-07 \n                   \n                     Obama makes risky bid to increase science spending 2016-Feb-10 \n                   \n                     White House budget proposal \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21696", "url": "https://www.nature.com/articles/nature.2017.21696", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Environment and heredity might not contribute as much to cancer risk as researchers thought. Nearly two-thirds of the mutations that drive cancers are caused by errors that occur when cells copy DNA, mathematical models suggest. The findings, published in  Science  on 23 March 1 , are the latest argument in a long-running debate over how much the environment or intrinsic factors contribute to cancer. They also suggest that many cancer mutations are not inherited and could not have been prevented by, for example, making different lifestyle choices. It\u2019s a finding that could change how researchers wage the \u201cwar on cancer\u201d, says study co-author Bert Vogelstein, a geneticist at the Sidney Kimmel Comprehensive Cancer Center in Baltimore, Maryland. Researchers have tended to emphasize the role of environmental factors in generating cancer mutations, he says. \u201cIf we think of the mutations as the enemies, and all the enemies are outside of our border, it\u2019s obvious how to keep them from getting inside,\u201d Vogelstein explains. \u201cBut if a lot of the enemies \u2014 in this case close to two-thirds \u2014 are actually inside our borders, it means we need a completely different strategy.\u201d That strategy would emphasize early detection and treatment, in addition to prevention, he says.  \n             Bad code \n           Each time a cell divides, it provides an opportunity for errors to crop up during DNA replication. In 2015, Vogelstein and one of his co-authors, mathematician Cristian Tomasetti of Johns Hopkins University in Baltimore, created a stir with an analysis 2  that looked at possible explanations for why some cancers occur more often than others. They concluded that differences in the number of stem-cell divisions in an organ correlated with the frequency of cancers in that area. There aren't as many stem cell divisions in areas with less common cancers, including in the brain, than in sites with more common cancers such as colorectal cancer. There were fears that the study\u2019s conclusions could undercut prevention efforts, and it sparked hundreds of follow-up papers 3 . \u201cIt reignited a debate about how much  cancer is due to environmental factors ,\u201d says Robert Noble, who specializes in mathematical models of cancer at the Swiss Federal Institute of Technology Zurich in Basel. Vogelstein counters that the study never intended to challenge efforts to combat known causes of cancer, such as cigarette smoking and sun exposure, which can create cancer-causing mutations. Epidemiological studies suggest that about 42% of cancers are preventable, he says, and his results do not contradict that. (Because his study looks at the number of cancer-causing mutations \u2014 and it typically takes more than one such mutation to cause cancer \u2014 the numbers are not directly comparable.) The latest study addresses two criticisms of the 2015 paper. It expands the analysis beyond the United States, to include databases of cancer incidence from 69 different countries, and it includes two common cancers \u2014 breast and prostate \u2014 that were omitted from the first study. The results of the expanded analysis support the conclusions from the earlier paper, says Tomasetti. He and his colleagues then calculated the relative contribution of the environment, heredity and random DNA-replication errors to cancer-causing mutations. The team used data from a UK cancer database and, in some cases,  cancer genome sequencing efforts,  and looked for mutations that are indicative of particular environmental exposures.\u00a0 The researchers found that these percentages vary from cancer to cancer. In some lung tumours, for example, environmental factors account for 65% of all cancer-causing mutations, whereas replication errors comprise only 35%[1]. Yet in prostate, brain and bone cancers, more than 95% of cancer drivers are caused by random DNA-copying errors. Overall, calculations across 32 cancers indicated that about 66% of cancer-driving mutations are due to random DNA replication errors, with only 29% due to environmental factors and 5% to inherited mutations. \n             Coming into focus \n           The method the authors used is sound, says Noble, although they did have to rely on a number of assumptions to simplify the analysis. Yusuf Hannun, director of the Stony Brook Cancer Center in New York, worries that the study underestimates the contributions of environmental and heritable factors because researchers do not yet know how to fully predict these on the basis of sequence and epidemiological data. For example, although it may be possible to estimate how much smoking contributed to someone\u2019s lung cancer, it would be more difficult to fully capture the impact of air pollution or exposure to radon, he says. And overall, Noble says, the controversy has served a purpose by galvanizing the field to develop better models of cancer\u2019s causes. \u201cA lot has come out of this debate,\u201d he says. \u201cIt\u2019s been very useful.\u201d Vogelstein hopes that the results will alleviate some of the guilt felt by patients and their families \u2014 especially parents of children with cancer \u2014 about their condition. Many turn to the Internet for answers, and are greeted with a common message: something in their lifestyle or genes caused the disease. \u201cThey need to understand that these cancers would have occurred no matter what they did,\u201d he says. \u201cWe don\u2019t need to add guilt to an already tragic situation.\u201d \n                   Cancer studies clash over mechanisms of malignancy 2015-Dec-16 \n                 \n                   Big science: The cancer genome challenge 2010-Apr-14 \n                 Reprints and Permissions"},
{"file_id": "543476a", "url": "https://www.nature.com/articles/543476a", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Yves Meyer wins the Abel Prize for role in theory with data applications from digital cinema to pinpointing gravitational waves. French mathematician Yves Meyer has won the 2017 Abel Prize for his \u201cpivotal role\u201d in establishing the theory of wavelets\u00a0\u2014\u00a0data-analysis tools used in everything from pinpointing gravitational waves to compressing digital films. The prize of 6 million Norwegian kroner (US$710,000)\u00a0\u2014\u00a0hailed as the Nobel prize of mathematics\u00a0\u2014\u00a0was announced by the Norwegian Academy of Science and Letters on 21\u00a0March. Following the tradition of the Nobels, Meyer learnt that he was the winner only when he received a call on the morning of the announcement. \u201cThere are not many examples of mathematical discovery that have directly influenced society so much,\u201d says Jean-Michel Morel, an applied mathematician and Meyer\u2019s colleague at the \u00c9cole Normale Sup\u00e9rieure Paris\u2013Saclay. Wavelet-based computer algorithms are among the standard tools used by researchers to process, analyse and store information. They also have applications in medical diagnostics, where they can help to speed up magnetic resonance imaging, for example; and in entertainment, to encode high-resolution films into files of manageable size. After groundbreaking work\u00a0\u2014\u00a0dubbed the wavelet revolution\u00a0\u2014\u00a0spearheaded by Meyer in the 1980s, textbooks in many disciplines had to be radically rewritten, Morel says. Wavelets are an extension of the mathematical toolkit of Fourier analysis, named after Joseph Fourier, who initiated the field in the 1800s. He discovered that a complex waveform can be broken down into simpler, sine-wave components. That is, a piece of information such as a musical note or a seismic signal can be expressed in a compact way using Fourier techniques. Although mathematically elegant, Fourier\u2019s original formulae did not easily apply to many types of real-world data, explains John Rognes, a mathematician at the University of Oslo who chairs the Abel Committee. Fourier\u2019s techniques were helpful for steady signals, such as a continuous note played on a violin. But they were not efficient for sifting a noisy data set to extract transient signals\u00a0\u2014\u00a0such as the \u2018chirp\u2019 of two black holes colliding, which the Laser Interferometer Gravitational-wave Observatory picked up in 2015. In the 1900s, researchers developed algorithms that made Fourier analysis more practical for applications such as seismology. Among these were waveforms that could replace sinusoidal waves while being of finite duration, invented in 1981 by French geophysicist Jean Morlet at CNRS in Marseilles. He called them  ondelettes \u00a0\u2014\u00a0wavelets in English. But until Meyer entered the field, these tools did not have the full power of Fourier\u2019s theory. Meyer made his serendipitous encounter with Morlet\u2019s wavelets in 1982, while waiting for a photocopier at the \u00c9cole Polytechnique in Paris, where he then worked. A colleague was copying a paper on Morlet\u2019s wavelets, and the two struck up a conversation. Meyer, a researcher in functional analysis, was so captivated that he took the first train to Marseilles to talk to Morlet and his colleagues. He decided overnight to change fields. \u201cIt was like a fairy tale,\u201d Meyer said in a 2011 interview (see  go.nature.com/2n71lot ). \u201cI felt I had finally found my home.\u201d By 1986, Meyer had created the first set of wavelets that were at least as powerful as Fourier\u2019s waves ( P. G. Lemari\u00e9 & Y. Meyer  Rev. Matem. Iberoam.    2, 1\u201318; 1986 ). And in the following years, while at the University of Paris Dauphine, he acted as the hub of a network of mathematicians, engineers, physicists and computer scientists who seemed to make new discoveries every week, Morel recalls. \u201cHe was communicating to people who don\u2019t even talk the same mathematical language,\u201d says Morel. \u201cAll of these people had pieces of the puzzle.\u201d He adds that a \u201cnice, clean, general theory emerged\u201d that included,\u00a0and improved upon,\u00a0the tools used to make Fourier analysis more practical. For example, Meyer\u2019s work showed that tools invented for processing signals could be applied to data compression. Meyer\u2019s desire for crossing borders between disciplines stemmed from his childhood in the melting pot of colonial Tunis, where he was \u201cobsessed\u201d, he said in the 2011 interview, by wanting to cross ethnic frontiers. People who know Meyer describe a man of generosity and rectitude, Morel says. He leads an ascetic life, split between office and home, where he lives with his wife, and is \u201cthe most welcoming, naive, modest person.\u201d Indeed, on learning about his award, Meyer said: \"I am at the same time happy, surprised and slightly guilty.\" \n                 Tweet \n                 Follow @NatureNews \n                 Follow @dcastelvecchi \n               \n                     Fermat's last theorem earns Andrew Wiles the Abel Prize 2016-Mar-15 \n                   \n                     'Beautiful mind' John Nash adds Abel Prize to his Nobel 2015-Mar-25 \n                   \n                     Chaos-theory pioneer nabs Abel Prize 2014-Mar-26 \n                   \n                     Interview with Yves Meyer, European Mathematical Society Newsletter, June 2011. \n                   \n                     The Abel Prize \n                   Reprints and Permissions"},
{"file_id": "543473a", "url": "https://www.nature.com/articles/543473a", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Immersive experience set to become accessible to all. \u201cIt feels like the entire universe is within a sphere that is maybe within a couple metres\u2019 radius,\u201d says topologist Henry Segerman at Oklahoma State University in Stillwater. He is describing,\u00a0not an LSD trip, but his experience of exploring a curved universe in which the ordinary rules of geometry do not apply. Segerman and his collaborators have released software allowing anyone with a virtual-reality (VR) headset to wander through this warped world, which they previewed last month in two papers on the arXiv.org preprint server 1 , 2 . To explore the mathematical possibilities of alternative geometries, mathematicians imagine such \u2018non-Euclidean\u2019 spaces, where parallel lines can intersect or veer apart. Now, with the help of r elatively affordable VR devices , researchers are making curved spaces \u2014 a counter-intuitive concept with implications for Einstein\u2019s theory underlying gravity and  also for seismology  \u2014 more accessible. They may even uncover new mathematics in the process. \u201cYou can think about it, but you don\u2019t get a very visceral sense of this until you actually experience it,\u201d says Elisabetta Matsumoto, a physicist at the Georgia Institute of Technology in Atlanta. Traditional, Euclidean geometry rests on the assumption that parallel lines stay at the same distance from each other forever, neither touching nor drifting apart. In non-Euclidean geometries, this \u2018parallels postulate\u2019 is dropped. Two main possibilities then arise: one is spherical geometry, in which parallel lines can eventually touch, in the way that Earth\u2019s meridians cross at the poles; the other is hyperbolic geometry, in which they diverge. Both Matsumoto and Segerman are part of Hyperbolic VR, a collaboration that is bringing hyperbolic spaces to the masses. Their team, which includes a collective of mathematician-artists in San Francisco, California, called eleVR, will unveil their efforts at an arts and maths conference this summer. In the 1980s, mathematician Bill Thurston revolutionized the study of 3D geometries, in part by imagining himself wandering around them. Mathematicians have since developed animations and even flight simulators that show an inside view of non-Euclidean spaces. But compared with those visualizations, which were displayed on a computer screen, VR has the advantage that it reproduces the way in which light rays hit each eye. In Euclidean space, staring at a point at infinity means that the lines of sight of the two eyes track parallel lines. But in a hyperbolic world, those two paths would veer apart, says Segerman, forcing a different response from the viewer. \u201cHere, if you look at a point at infinity, you have to cross your eyes slightly.\u201d To our \u201cEuclidean brain\u201d, that makes everything feel kind of close, he says. But the smallness is deceptive. One of the oddest facts about hyperbolic space is its sheer vastness. Whereas in Euclidean space the surface area within a given radius grows as fast as the square of the radius, and the volume grows as fast as its cube, in hyperbolic space areas and volumes grow much (exponentially) faster relative to the radius. One consequence is that a user roaming a planet in the hyperbolic world finds much more to visit within walking distance. So far, there is not much to do in the eleVR world, apart from exploring tilings made of geometric shapes such as pentagons and dodecahedra. But the team plans to build hyperbolic houses and streets, as well as interactive experiences such as playing a non-Euclidean version of basketball. The researchers hope that their open-source software will become popular with science museums and the growing legion of consumer VR enthusiasts. Others are bringing hyperbolic space to VR, too. Daan Michiels, a mathematician at the University of Illinois at Urbana\u2013Champaign, developed a virtual hyperbolic universe as a student project in 2014. And David Dumas, a topologist at the University of Illinois in Chicago, and his students created a racquetball game in a virtual hyperbolic space, in which a ball sent in any direction eventually comes back to the starting point. Virtual reality could soon join a long tradition of visualization and experimental tools that have helped mathematicians make discoveries. Visualizing fractals, for instance, led to discoveries about the underlying mathematics. \u201cFiguring how to make use of [virtual reality] as a research tool is just starting now,\u201d says Dumas. Matsumoto says that the team would also like to create VR experiences for even more exotic geometries. In some such spaces, parallel lines might stay at a constant distance from each other if they go in one direction, but converge or diverge in another direction. And walking around a circle might lead to a place that\u2019s up or down relative to the starting point, like going up or down a spiral staircase. Visualizing such geometries could be especially useful as a mathematical tool, she says, because \u201cvery few people have thought of visualizing them at all\u201d. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @dcastelvecchi \n               \n                     Long-awaited mathematics proof could help scan Earth's innards 2017-Feb-10 \n                   \n                     Low-cost headsets boost virtual reality\u2019s lab appeal 2016-May-11 \n                   \n                     Mathematics: The reluctant celebrity 2004-Jan-29 \n                   \n                     eleVR \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21697", "url": "https://www.nature.com/articles/nature.2017.21697", "year": 2017, "authors": [{"name": "Cassandra Willyard"}], "parsed_as_year": "2006_or_before", "body": "\u2018Breakthrough\u2019 technique used to piece together genome sequence of Zika vector,  Aedes aegypti,\u00a0 10 years after publication of draft sequence. As the Zika virus  raced across the Western Hemisphere  in 2015 and 2016, geneticists eager to battle the outbreak felt crippled. The genome sequence of the  Aedes aegypti  mosquito that spreads Zika was incomplete and consisted of thousands of short DNA fragments, hampering research efforts. With help from a new technique for stitching together genome sequences, scientists have finally \u2018assembled\u2019 the genome of  A. aegypti  as well as that of  Culex quinquefasciatus , a mosquito that transmits West Nile virus. Their method, which was also used to construct a human genome with 99% accuracy, is described in  Science  on 23 March 1 . Each genome cost less than US$10,000. Another team published  a draft  A. Aegypti  genome  in 2007 2 \u00a0but struggled with its assembly. The new study places 94% of the genomes of the two mosquitoes on to three large chromosomes. \u201cIt would not have been possible to get a mosquito genome of this quality without this breakthrough,\u201d says Leslie Vosshall, a mosquito researcher at Rockefeller University in New York City. \n             Some assembly required \n           Current sequencing technologies require DNA to be diced into short snippets. Because these snippets overlap, computers can piece them together to form continuous strings of letters. But in regions of the genome with a great deal of variation across a species, or long stretches of repetitive DNA, this trick doesn\u2019t work. \u201cIt\u2019s like a puzzle that\u2019s missing a few pieces from the box,\u201d says Daniel Neafsey, a population geneticist\u00a0at the Broad Institute in Cambridge, Massachusetts. This challenge can be overcome with time and money, as evidenced by the $2.7-billion  Human Genome Project . But Erez Lieberman Aiden, a geneticist at Baylor College of Medicine in Houston, Texas, who led the new research, wanted a workaround. By looking at how chromosomes fold, Aiden and his colleagues created maps that show how frequently different stretches of the genome come into contact with one another, a method called \u2018Hi-C\u2019. Using these Hi-C maps as guides, researchers can infer the proximity of different genome fragments.\u00a0 Scientists first showed that Hi-C can be used to guide genome assembly in 2013 3 \u00a0and have since used the technique to assemble the genomes of several animal species 4 . These efforts relied on longer strings of letters, whereas the new method works on short sequences, lowering costs. \n             Ghost genes \n           David Severson, a mosquito researcher at the University of Notre Dame in Indiana who coordinated the initial  A. aegypti  genome project, calls the team\u2019s effort \u201cphenomenal\u201d. He has long been frustrated by the lack of an assembled genome. \u201cI\u2019ve been waiting to work with something like this for probably twenty years,\u201d he says. Knowing the location of individual genes, and their positions relative to one another, will help scientists to formulate new questions about how genes combine to influence traits. But even this improved genome isn\u2019t perfect: it omits millions of DNA letters, and some small stretches are likely in the wrong orientation. The  Aedes  Genome Working Group, which formed last year in the wake of the Zika outbreak, is working hard to construct an even more complete and accurate genome. The group, led by Vosshall, is coordinating with Aiden\u2019s team. These improved genomes will help mosquito researchers to study genes that were previously absent because they occurred in difficult-to-assemble regions of the genome. These genes were \u201clike a ghost\u201d, Neafsey says. \u201cEven if you know functionally the gene should be there, you don\u2019t have the means to study it.\u201d \n                   Rio fights Zika with biggest release yet of bacteria-infected mosquitoes 2016-Oct-26 \n                 \n                   \u2018Platinum\u2019 genome takes on disease 2014-Nov-18 \n                 \n                   Genome builders face the competition 2011-Mar-23 \n                 \n                   Human genomics: The genome finishers 2009-Dec-16 \n                 \n                   Mosquito genome leaves researchers itching for more 2007-May-17 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21703", "url": "https://www.nature.com/articles/nature.2017.21703", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Study is the latest in the long-running dispute over which lineage \u2014 sponges or comb jellies \u2014 is the oldest branch in the animal tree. Evolutionary biologists have battled for years over which animal lineage came first \u2014 sponges or  comb jellies . The answer could transform how scientists understand the evolution of the human nervous system, digestive system and other complex traits. A study published on 16 March in  Current Biology , sides with the sponges, using an unprecedented array of genetic data to deduce that they were the first to branch off from the animal tree of life 1 . Sponges are simple creatures that lack a head, nerves and guts, so the conclusion makes intuitive sense. But big data doesn\u2019t necessarily lead to better answers, some researchers warn. \u201cThey\u2019ve got a large data set, but almost certainly this is not the final word,\u201d says David Hillis, an evolutionary biologist at the University of Texas at Austin who was not involved with the project. \u201cThis is just such a tough problem to solve.\u201d Peering back through 600 million years of transformation is hard. It seems that every animal descends from ancestors on one of five branches near the base of the tree. But these five groups look very different from one another today. There are sponges, comb jellies, cnidarians (including sea anenomes, corals and jellyfish), bilaterally symmetrical animals (such as humans and clams) and obscure, microscopic worms called placozoans.\u00a0 \n             Battle of the branches \n           For the better part of the past century, zoologists arranged these branches according to their judgements of what was simple and what was complex. Sponges fell to the bottom branch, and bilaterally symmetrical animals resided higher up. But in 2008, a genetic analysis published in  Nature  put comb jellies, rather than sponges, near the root of the evolutionary tree 2 . This arrangement rattled evolutionary biologists because it upended the idea that animal complexity increased over time. It implied that  nerves and other characteristics evolved independently in different lineages , and were subsequently lost in sponges. Since then, studies have supported or contradicted the rearrangement, but all have been plagued by problems. In the most recent study 1 , the authors attempt to resolve one of the biggest challenges in building evolutionary trees based on DNA comparisons. Some genomes evolve faster than others, and fast-evolving genomes from unrelated animals can converge on a similar sequence. \u201cBy chance, lineages accumulate genetic similarities not due to a shared history but due to random change,\u201d explains Micha\u00ebl Manuel, an evolutionary biologist at the Institute of Biology Paris-Seine, and the study\u2019s senior author. This problem is called long-branch attraction, because mathematical models depict genetic changes as additional lengths on the branches of the diagrams they produce. Long branches can cluster together on a tree as a result of these convergences, or because their genetic sequences are so unlike others in the tree. Either way, the clustering suggests that two lineages are related when they\u2019re not. Manuel suspects that the long branches of non-animals such as fungi attract the comb-jelly lineage because, for unknown reasons, comb-jelly genomes have accumulated an unusual number of changes over time. \n             Flip-flopper \n           To skirt such long-branch attraction, Manuel and his colleagues analysed 1,719 genes from an unparalleled range of species. It took computing power from Canada, Germany, Belgium and France to crunch the numbers. The team also tested several mathematical models that accounted for biological phenomena, including the fact that certain genetic changes are more likely than others. They chose a model called CAT, partly because of how well it reproduced sections of the animal tree that have already been confirmed. The results from the\u00a0CAT model placed sponges on the earliest branch of the animal family tree. Some other models that the team used had put comb jellies at the base. \u201cThe fact that the results flip-flop with different models is a bad sign,\u201d says Hillis, who was not involved with the work. Casey Dunn, an evolutionary biologist at Brown University in Providence, Rhode Island who also was not involved in the study, agrees. \u201cUnfortunately, this is telling us that adding more species data isn\u2019t moving the needle on the problem.\u201d In the future, Hillis suggests, biologists should explore genomic data that are less prone to long-branch attraction, because the chance of random convergence is lower. For instance, genes rarely insert themselves into other genes, but it happens. Hillis concedes that finding a solution will not be easy. \u201cBut this tree really matters,\u201d he says. \u201cIt changes how we understand major things that happened in evolution.\u201d \n                   What sparked the Cambrian explosion? 2016-Feb-16 \n                 \n                   Evolutionary biology: Excitation over jelly nerves 2014-May-21 \n                 \n                   Genome reveals comb jellies' ancient origin 2013-Jan-08 \n                 \n                   Ancient sea jelly makes tree of life wobble 2011-Sep-07 \n                 \n                   Sponge genome goes deep 2010-Aug-04 \n                 \n                   Broad phylogenomic sampling improves resolution of the animal tree of life 2008-Mar-05 \n                 \n                   Center for Biodiversity and Theory Modeling \n                 \n                   CreatureCast \n                 \n                   Who is our most distant animal relative? A blog by Casey Dunn \n                 Reprints and Permissions"},
{"file_id": "543475a", "url": "https://www.nature.com/articles/543475a", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "The indigenous people \u2014 known for their click languages \u2014 are the first in Africa to draft guidelines for researchers. The San people of southern Africa are among the most-studied indigenous groups in the world. Legions of researchers have investigated their hunter-gatherer lifestyles, click languages and ancient rock art, and San individuals were some of the first from Africa to have their whole genomes sequenced. But some San want a greater say in such research. On 2 March, three communities in South Africa issued their own research-ethics code\u00a0\u2014\u00a0thought to be the first from any indigenous group in Africa. Although the rules will carry no legal weight, their authors hope that scientists will feel compelled to submit proposals for research in San communities to a review panel of community members. And the San may refuse to collaborate with institutions whose staff do not comply, the rules warn. The code was developed by traditional leaders of the !Xun, Khwe and !Khomani groups of San, which represent around 8,000 people in South Africa. \u201cWe\u2019ve been bombarded by researchers over the years,\u201d says Hennie Swart, director of the South African San Institute in Kimberley, which helped to develop the code. \u201cIt\u2019s not a question of not doing the research. It\u2019s a question of doing it right.\u201d The impetus for the ethics code was the 2010 publication, in  Nature 1 , of  the first human genome sequences from southern Africa : those of Archbishop Desmond Tutu, winner of the 1984 Nobel Peace Prize, and four San men from Namibia. The Namibian government and ethics committees at the scientists\u2019 universities in Australia, South Africa and the United States approved the study. The researchers also filmed the San men giving verbal consent with the help of a translator. But some San leaders were upset that the team did not consult them, and were concerned about how the researchers obtained informed consent from the San men, according to Roger Chennells, a human-rights lawyer based in Stellenbosch, South Africa, who helped draft the code (see  go.nature.com/2nwyj1m ). The study was a \u201cmassive catalyst\u201d, he says. The paper also used terms, including \u201cBushman\u201d, that some San individuals consider offensive. \u201cNo other recent research has been perceived as being so insulting and arrogant to San leaders,\u201d says Chennells. He anticipates that communities in Namibia and Botswana will formally adopt the code in the future. Until then, researchers working with those communities will be encouraged to take note of the code, adds Chennells. However, Stephan Schuster, a genome scientist who co-led the study while at Pennsylvania State University in State College, asks whether the views of San leaders in South Africa are representative of other San groups. \u201cWhy would a San council in South Africa know what we are doing in northern Namibia?\u201d asks Schuster, who is now at the Nanyang Technological University in Singapore. After the genome paper came out, San leaders held workshops with scientists, ethicists and lawyers to draft research guidelines. The TRUST Project, a European effort to promote global research ethics, funded the drive. The process for endorsing research under the guidelines is still taking shape, says Swart, but researchers will be encouraged to submit proposals to the South African San Council. The council \u201cundertakes not to unduly curb or hinder good research\u201d, adds Chennells. Both Chennells and Swart hope that the research code will achieve the same influence as guidelines for working with Aboriginal communities in Australia. There, researchers must typically gain approval from groups that represent local or regional indigenous communities. A 2011 study 2  reporting the  first genome of an Aboriginal Australian  (taken from an early-twentieth-century hair sample) was nearly scrapped because the scientists had not initially sought the endorsement of an Aboriginal group. \u201cWe are learning from Australians,\u201d says Swart. \u201cIf researchers want to work among the San and that\u2019s the protocol, they should honour it. That\u2019s what social justice is all about,\u201d says Himla Soodyall, a geneticist at the University of the Witwatersrand in Johannesburg, South Africa, who co-authored a 2012 paper 3   analysing the genomes of San individuals . That team sought permission for its research from the South African San Council and another San organization, the Working Group of Indigenous Minorities in Southern Africa. The researchers communicated their findings to San communities and told individuals what they had learnt about their genetic ancestry. Emma Kowal, an anthropologist at Deakin University in Melbourne, Australia, who works on indigenous research ethics, thinks the code will encourage scientists to consider the interests of San communities. \u201cOur experience in Australia is that researchers will come to the table and change the way that they practise,\u201d she says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @ewencallaway \n               \n                     Geneticists attempt to heal rifts with Aboriginal communities 2016-Sep-21 \n                   \n                     African neighbours divided by their genes 2012-Sep-20 \n                   \n                     Hunter-gatherer genomes a trove of genetic diversity 2012-Jul-26 \n                   \n                     Africa yields two full human genomes 2010-Feb-17 \n                   \n                     San Code of Research Ethics \n                   Reprints and Permissions"},
{"file_id": "543474a", "url": "https://www.nature.com/articles/543474a", "year": 2017, "authors": [{"name": "Mark Zastrow"}], "parsed_as_year": "2006_or_before", "body": "President\u2019s impeachment creates opportunity to shift how nation supports basic research. When South Korea\u2019s Constitutional Court removed scandal-ridden President Park Geun-hye from office on 10 March, citizens rejoiced in the streets \u2014 and many scientists breathed a sigh of relief. Her downfall has inspired a public appetite for broad governmental reforms, including changes in how the country supports scientific research. Many in the research community hope to end South Korea\u2019s decades-long focus on applied research and shift more resources to basic science. It is unclear whether, or how, the next administration will change the status quo, but scientists are seizing this opportunity to speak up. \u201cIt seems there\u2019s a general consensus amongst the candidates that government support of basic science should increase,\u201d says Doochul Kim, president of the Institute for Basic Science (IBS), a network of government-funded research centres based in Daejeon.\u00a0 There is a growing sense that the current focus on applied research is inadequate if the nation is to keep up with scientific advances in the rest of the world. This feeling was reinforced last March when AlphaGo, an artificial intelligence (AI) developed by Google\u2019s DeepMind in London, beat Korean grandmaster Lee Sedol at the game of Go.  Lee\u2019s loss shocked the country , sparking widespread fear that South Korea was losing its technological edge. Park scrambled to respond, calling the development of AI and other \u2018smart\u2019 technologies the \u201cfourth industrial revolution\u201d. She proposed investing US$860 million in AI and opening a new government research centre partnered with corporations including Samsung, LG Electronics, Hyundai Motor and Korean Internet giant Naver. But critics charged that it was a reiteration of the old way of doing things. Many argued that taking technologies developed elsewhere and improving on them would not be enough to keep South Korean science competitive. \u201cThe fourth industrial revolution is based on basic science,\u201d says Kim. \u201cMathematics, algorithms, computer science \u2014 it\u2019s all basic science.\u201d South Korea ranks near the top of the world in research and development spending by fraction of gross domestic product. Yet since the 1960s, when South Korean dictator Park Chung-hee started investing heavily in applied research, the lion\u2019s share of government money has gone to scientific institutes with industry partners. This left academic researchers with a relatively small pool of grant funding (see \u2018Budget breakdown\u2019). \u201cFor Park Geun-hye\u2019s government, science was just part of making money and growing the economy,\u201d says Sang-Mook Lee, a marine geophysicist at Seoul National University. An outspoken critic of the administration, Lee testified before parliament in 2014 at the invitation of the opposition party to  advocate for using Korean research ships for basic science  rather than searching for deep-sea minerals. During the 2012 presidential campaign, Park Geun-hye made science and technology a signature issue. She promised to boost spending on basic science from 35.2% of the government\u2019s research budget in 2012 to 40% by 2017. She also pledged to create a science ministry that would build a \u2018creative economy\u2019 of start-ups and transform the country into a technological leader. But in practice, the ministry often supported applied research at government institutes. A close look at what \u2018basic research\u2019 includes reveals that a lot of the money still goes to what is essentially applied research, says Hyungsub Choi, a historian of science and technology at Seoul National University of Science and Technology. \n               End of an era \n             With Park\u2019s removal, some researchers see an opportunity to shift the distribution of funds. \u201cIn some sense, President Park\u2019s impeachment marks the real end of Korea\u2019s developmental decades since the Park Chung-hee era,\u201d says So Young Kim, a science and technology political scientist at the Korea Advanced Institute of Science and Technology in Daejeon. But how things will play out politically is not clear. Park\u2019s successor will be chosen in a special election on 9 May. The current front-runner is liberal Moon Jae-in, a former human-rights lawyer and the runner up in the 2012 election. Public opinion polls predict a shift in power, ending nearly a decade of rule by the conservative Liberty Korea Party, formerly the Saenuri party. The prospects for increased support for basic science are encouraging, says Doochul Kim. Established in 2011, and modelled after Germany\u2019s Max Planck Institute and Japan\u2019s RIKEN, the IBS is South Korea\u2019s flagship effort in basic research. There are currently 28 research centres within the IBS, but the original plans called for 50. With conservatives now out of favour, the IBS must win multipartisan support to secure its expansion, says So Young Kim. Whatever the future of scientific research looks like in South Korea, it\u2019s clear that scientists are trying to change course. Some have taken matters into their own hands: a crowdfunding project to study health issues affecting transgender people in South Korea recently raised nearly 15 million won (US$13,300), exceeding its target by half. Conventional funding routes have proved difficult for research that is not intended for economic growth, says Tae-Woong Yoon, chair of Engineers and Scientists for Change (ESC), and a systems engineer at Korea University in Seoul. The ESC promotes research for social progress and sustainability, and led the crowdfunding campaign. The group, founded last year, seeks to establish a funding route that is not controlled by companies or political parties, says Yoon. He is not waiting for the next administration to create change. \u201cI think it\u2019s up to us,\u201d Yoon says. \u201cWe are dedicated and we really want to improve the situation here.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Why South Korea is the world\u2019s biggest investor in research 2016-Jun-01 \n                   \n                     South Korea trumpets $860-million AI fund after AlphaGo 'shock' 2016-Mar-18 \n                   \n                     The Go Files: AI computer wraps up 4-1 victory against human champion 2016-Mar-15 \n                   \n                     South Korean survey ships open up to science 2015-Jan-06 \n                   \n                     South Korean research centre seeks place at the top 2012-May-17 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21702", "url": "https://www.nature.com/articles/nature.2017.21702", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Long-lost images could offer insight into rare and moving stars. \u2018Lost\u2019 images from astronomy journals are being rediscovered through a citizen-science project that launched on 22 March \u2014 a potential boon to researchers looking for changes\u00a0in the Universe.  'Astronomy Rewind'  harnesses volunteers\u00a0to digitize, map and make searchable observations featured in papers from journals of the American Astronomical Society (AAS)\u00a0dating back to around 1850. \u201cTurning historical scientific literature into searchable, retrievable data is like turning the key to a treasure chest,\u201d said Alyssa Goodman, an astronomer at the Harvard-Smithsonian Center for Astrophysics (CfA) in Cambridge, Massachusetts, announcing the project, in a statement. Learning about time-variable celestial objects, such as stars that erupt as novae more than once or hurtle across their galaxies, requires observing them over long periods of time. But observations published in journals before roughly 1995 \u2014 when the AAS went digital \u2014 are rarely indexed in online image databases. And few journal images, even today, are stored in a way that makes them easily searchable, says Goodman. \n             Power of the people \n           Astronomy Rewind is designed to tap into\u00a0humans\u2019 prowess, relative to computers, at recognizing astronomical images among scanned journal pages, which are a mixture of text and multiple graphics. The project is hosted on\u00a0 the \u2018Zooniverse\u2019 platform , a citizen-science web portal that includes more than 1 million volunteers. Contributors \u2014 five for every page to ensure reliability\u00a0\u2014 identify image types and look for text that gives the orientation, scale and coordinates of each object. So far, \u2018zoonizens\u2018 have taken to Astronomy Rewind with zeal, processing an entire batch of more than 6,500 images, which organizers had anticipated would take months, in a single day. \u201cThe Zoonizens reaction to this project has astonished us all \u2014 in a good way,\u201d says Goodman. \u201cIt's a great project, and essential for time-variable astronomy amongst other things,\u201d says Tim O'Brien, an astrophysicist at the University of Manchester, UK. The images could help scientists to spot the\u00a0movement of runaway stars ejected from their clusters. The project should also boost the number of known recurrent novae \u2014 white dwarfs that repeatedly shed matter in explosive bursts, and of which only ten are known in the Milky Way. The most recently\u00a0discovered of these was found in 2009 by astronomers trawling through archival data, which is painstaking work, says Matt Darnley, an astrophysicist at Liverpool John Moores University, UK. Stephan Geier, an astronomer at the University of T\u00fcbingen, Germany, says that the initiative could help astronomers to find new examples of other fleeting or fast-moving phenomena. But he is sceptical about how much can be gleaned from scanned images \u2014 for example, information on a star's brightness \u2014 without the original photographic plates. Goodman says that the project should also provide a window into science history, by revealing which celestial objects have drawn scientists\u2019 interest over the past 150 years, and in what ways. \u201cScholars will be able to investigate, over a long time baseline, how astronomers\u2019 focus changed,\u201d she says. \n                   Rise of the citizen scientist 2015-Aug-18 \n                 \n                   Citizen science: People power 2010-Aug-04 \n                 \n                   See new galaxies \u2014 without leaving your chair 2007-Jul-11 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21730", "url": "https://www.nature.com/articles/nature.2017.21730", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "World-first transplant, used to treat macular degeneration, represents a major step forward in movement to create banks of ready-made stem cells. On 28 March, a Japanese man in his 60s became the first person to receive cells derived from induced pluripotent stem (iPS) cells donated by another person.\u00a0 The surgery is expected to set the path for more applications of iPS-cell technology, which offers the versatility of embryonic stem cells without their ethical taint. Banks of iPS cells from diverse donors could make stem-cell transplants more convenient to perform, while slashing costs. iPS cells are created by removing mature cells from an individual (for example, from their skin) and reprogramming these cells back\u00a0to an embryonic state. They can then be coaxed into a type of cell useful for treating a disease. In the latest procedure, performed on a man from the Hyogo prefecture of Japan, skin cells from an anonymous donor were reprogrammed into iPS cells and then turned into a type of retinal cell, which was in turn transplanted onto the retina of the\u00a0patient, who has age-related macular degeneration. Physicians hope that the cells will stop the progression of the disease, which can lead to blindness. \n             A move from self-donation \n           In September 2014 at the Kobe City Medical Center General Hospital,  a Japanese woman underwent a similar procedure to receive retinal cells derived from iPS cells . But these were reprogrammed from cells taken from her own skin. Cells prepared in the same way for a second patient were found to contain genetic abnormalities, and were never implanted.\u00a0Cells from macular degeneration patients, who tend to be elderly, might have also accumulated genetic defects that could increase the risk of the procedure. The team decided to redesign the study according to new regulations, and so no more participants were recruited. This month, however, the researchers reported that the Japanese woman fared well 1 . The introduced cells remained intact one year after surgery, and her vision had not declined, as would usually be expected with macular degeneration. In Tuesday's\u00a0procedure \u2014 performed at the same hospital and by the same surgeon, Yasuo Kurimoto \u2014\u00a0doctors used iPS cells that had been taken from a donor\u2019s skin cells, reprogrammed and banked. Japan\u2019s health ministry approved the study, which plans\u00a0to enrol a total of five patients, on 1 February.\u00a0 Using iPS cells developed from a donor does not offer an exact genetic match, which raises the prospect of immune rejection. But Shinya Yamanaka, a Nobel-prizewinning stem-cell scientist at Kyoto University\u00a0who pioneered iPS cells, has contended that banked cells should be a close enough match for most applications. \n             Banking on the future \n           Yamanaka is establishing an iPS cell bank, which depends on matching donors to recipients on the basis of three genes that code for human leukocyte antigens (HLAs) \u2014 proteins on the cell surface that are involved in triggering immune reactions. His\u00a0iPS Cell Stock for Regenerative Medicine currently has cell lines from just one donor. But by March 2018, he and his colleagues hope to create HLA-characterized cell lines from 5-10 different donors, which should match 30\u201350% of Japan\u2019s population. Use of these ready-made cells could extend the option of stem-cell transplants across an entire population, says Masayo Takahashi, an ophthalmologist at the RIKEN Center for Developmental Biology in Kobe, who devised the iPS cell protocol deployed in Tuesday's transplant. Banked cells are available immediately \u2014 in contrast to a wait of several months for cultivation of a patient\u2019s own cells \u2014 and are much cheaper. At a press conference after the procedure, Takahashi said that the surgery had gone well, but that success cannot be declared\u00a0without monitoring the fate of the introduced cells. She plans to make no further announcements about patient progress until all five procedures are finished. \u201cWe are at the beginning,\u201d she says.  \n                   Mars\u2019s frozen pole, Sweden\u2019s climate plan and a stem-cell trial in Japan 2017-Feb-08 \n                 \n                   How iPS cells changed the world 2016-Jun-15 \n                 \n                   Japan stem-cell trial stirs envy 2014-Sep-16 \n                 \n                   Japanese woman is first recipient of next-generation stem cells 2014-Sep-12 \n                 \n                   Stem cells cruise to clinic 2013-Feb-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21704", "url": "https://www.nature.com/articles/nature.2017.21704", "year": 2017, "authors": [{"name": "Sid Perkins"}], "parsed_as_year": "2006_or_before", "body": "Long-sought features may help researchers to improve models of solar activity and predict space weather. Huge ripples in Earth\u2019s atmosphere called Rossby waves help to steer the planet's jet streams and weather patterns. Now, a study in  Nature Astronomy  offers the best evidence yet that similar large-scale features also exist on the Sun 1 . Rossby waves were discovered in Earth\u2019s atmosphere in the late 1930s. Driven by a planet's rotation, they\u2019ve been seen in the atmospheres of other planets, as well as in Earth\u2019s oceans. In theory, these waves can form in any rotating fluid, says Scott McIntosh, a solar physicist at the National Center for Atmospheric Research in Boulder, Colorado and lead study author. Researchers have long sought evidence of Rossby waves on the Sun, he says. And an enhanced understanding of these features and their movements could help scientists to better predict the formation of sunspots and the eruption of solar flares. \n             Staring at the Sun \n           In the past, astronomers have been hampered in their search for the waves by their limited view of the Sun, because only one side can be viewed from Earth. But three solar probes \u2014 part of NASA's Solar Dynamics Observatory and its  Solar Terrestrial Relations Observatory  (STEREO) mission \u2014 were positioned for several years to give scientists a 360\u00b0 view of the Sun\u2019s atmosphere, or corona. (Astronomers lost communication with one STEREO probe after it slid behind the Sun in mid-2014.) The team concentrated on patterns of hot, bright features called brightpoints that pepper the Sun\u2019s corona and can be used to track the roiling motions of material deeper in the solar atmosphere, says McIntosh. Using data gathered by the probes from June 2010 to May 2013, researchers identified well-defined brightpoint clusters that moved westward, on average, at a speed of about 3.25 metres per second in the Sun\u2019s northern hemisphere and at about 2.65 m s \u20131  in its southern hemisphere. The brightpoint clusters moved westward faster than underlying portions of the solar atmosphere, which is a hallmark of Rossby waves, McIntosh notes. The researchers have named the patterns 'Rossby-like waves' because they relate to magnetic activity of the Sun's plasma, not just fluid motion. \u201cIt\u2019s no real surprise that we\u2019ve found them on the Sun,\u201d says McIntosh. \u201cIt\u2019s just that recently, for the first time in human history, we\u2019ve been able to see the entire surface of the Sun at once,\u201d not just the side facing Earth \u2014 thanks to the positioning of the solar probes. The team\u2019s findings are the first strong evidence for Rossby waves on the Sun, says Mihalis Mathioudakis, an astrophysicist at Queen\u2019s University Belfast, UK. \u201cThis is a neat result, if these features are indeed Rossby waves,\u201d says Joseph Gurman, an astrophysicist at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland. The full view of the Sun\u2019s surface at all latitudes and longitudes \u201chas provided a unique opportunity to discover things we hadn\u2019t seen before\u201d. \n             Cosmic weather patterns \n           Brightpoints are linked to increased magnetic activity, so a better understanding of their formation, evolution and movement might help researchers to fine-tune models of solar activity, says McIntosh. That, in turn, could lead to better predictions of benign solar processes such as the development of sunspots. But it could also help predict the onset of potentially devastating solar storms \u2014 massive eruptions of highly charged particles, called  coronal mass ejections  (CMEs), into space. If particularly strong CMEs strike Earth, they can cripple communications satellites and knock out power grids across wide regions. Some studies suggest that the cost of these ' space weather ' hazards could be around US$10 billion per year. \u201cIf researchers can identify active regions on the Sun and have some confidence in how they would evolve, then that could give people some warning,\u201d says Todd Hoeksema, a solar physicist at Stanford University in California. But predicting space weather \u201cmay not be quite as straightforward as it is on Earth\u201d, says Richard Morton, a solar physicist at Northumbria University in Newcastle-upon-Tyne, UK. The complex interaction of strong magnetic fields and fluid flow in the Sun's atmosphere might mean that long-term solar activity trends are easier to predict than are short-term developments, such as where a solar flare might occur on a given day. Nevertheless, McIntosh and his team hold out hope. Monitoring the Sun\u2019s weather patterns and understanding their origins are vital to boosting the accuracy of space weather predictions to protect our technological society, they say. \n                   Space-weather forecast to improve with European satellite 2017-Jan-18 \n                 \n                   US sharpens surveillance of crippling solar storms 2016-Sep-20 \n                 \n                   Solar eruptions combine to cause super storms 2014-Mar-18 \n                 \n                   Probe spots enormous convection currents on the Sun 2013-Dec-05 \n                 \n                   Plasma jets key to enduring solar mystery 2011-Jan-06 \n                 \n                   NASA\u2019s The Solar Dynamo \n                 \n                   Scott McIntosh \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21712", "url": "https://www.nature.com/articles/nature.2017.21712", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Researchers create models of organs such as a uterus and cervix in the laboratory. In the quest to study human reproduction, scientists have built a rudimentary model of the female system in the lab. Every 28 days, the 'ovary', cultured on a small plastic chip, releases an egg and starts producing hormones to prepare for pregnancy. The hormones travel through a series of tiny channels that mimic Fallopian tubes and into a uterus-like chamber made of human tissue. The system, described in a study 1  published on 28 March in  Nature Communications , is the latest in a  series of organs-on-chips  \u2014 miniature devices seeded with human tissues and cells that are engineered to model biological functions. Researchers hope that the synthetic reproductive system will provide another avenue for studying diseases such as cervical cancer, and allow them to test new contraceptives and fertility treatments before being used in people. There is no good animal model for the 28-day human reproductive cycle, says Teresa Woodruff, a reproductive scientist at Northwestern University in Chicago, Illinois, and a co-author of the study. The artificial system fills an \u201curgent unmet need for us\u201d, she says. \n             All together now \n           Woodruff and her colleagues named their system Evatar \u2014 a portmanteau of Eve and avatar. It contains five \u2018organs\u2019 linked together by a blood-like liquid carrying hormones, cell signalling molecules and drugs. The Fallopian tubes, uterus and cervix are made from human tissues obtained from women undergoing hysterectomies. The ovaries, however, are from mouse tissue, because healthy ovaries are rarely removed from women. Tissue for the fifth \u2018organ\u2019, the liver, which metabolizes drugs, comes from humans. To start the reproductive cycle, the researchers added follicle-stimulating hormone to the Evatar system, which drove the mouse ovaries to produce oestrogen. Fourteen days later, the researchers added luteinizing hormone, which stimulated the ovaries to release an egg and begin to produce progesterone. The egg stayed in the ovary chamber, but a second chamber lined with tissue from human Fallopian tubes began to act as though the egg were passing through it. (In the model, as in women, the tissue in the Fallopian tubes contain hair-like structures called cilia, which beat back and forth to waft the egg to the uterus.) The third and fourth chambers, lined with human uterine and cervical tissue, respectively, then produced receptors for the hormones. The researchers connected Evatar to a human liver-on-a-chip, which can metabolize drugs that the researchers are testing. \n             Forming connections \n           \u201cI think this is as an extraordinarily important, beautiful piece of work,\u201d says John Wikswo, a physiologist at Vanderbilt University in Nashville, Tennessee. He has been leading an effort to link at least 10 organ systems together to  form a complete human-on-a-chip . The simulated organs in the Evatar system function correctly only when the right amounts of signalling factors and hormones are carried in the right amount of fluid, he says, and each organ plays a part. Jon Hennebold, a reproductive scientist at Oregon Health and Science University in Portland, says that the main advantage of the new system is that it will allow researchers to quickly screen several drugs at once, testing them for toxicity and for their effects on the reproductive system. But he says that even an integrated set of organs-on-chips can\u2019t entirely replace animal or clinical studies, because it is impossible to know which organs will be relevant in a disease or during drug treatments. Woodruff says that her lab is planning to study various diseases by seeding the Evatar system with cells from people with conditions such as ovarian cancer, or by infecting Evatar with human papilloma virus, which can cause cervical cancer. The group is also making a male reproductive system called Adatar, and a testis\u2013prostate system called DudeKube. The researchers plan to eventually link these systems with 10 other organs, including brains-on-a-chip, which produce signalling steroids and hormones, and the surprisingly complex system of human fat-on-a-chip, which can affect metabolism, the immune system and the reproductive cycles. \n                   The boom in mini stomachs, brains, breasts, kidneys and more 2015-Jul-29 \n                 \n                   \u2018Organs-on-chips\u2019 go mainstream 2015-Jul-15 \n                 \n                   Biodefence researchers seek 'Homo chippiens' 2015-Feb-17 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21725", "url": "https://www.nature.com/articles/nature.2017.21725", "year": 2017, "authors": [{"name": "Jane J. Lee"}], "parsed_as_year": "2006_or_before", "body": "Video confirms the cephalopod feeds on gelatinous creatures. Using rare video footage from a deep-diving robot, marine biologists have for the first time identified the diet of the elusive \u2018seven-arm\u2019 octopus. The discovery, published on 27 March in  Scientific Reports 1 , provides insight into the habits of the shy cephalopod ( Haliphron atlanticus ), which was spotted nearly four years ago eating an egg-yolk jellyfish ( Phacellophora camtschatica ). But it also helps to scramble the idea that gelatinous creatures such as jellyfish are nutritional dead-ends \u2014  a reputation that is slowly being overturned . \u201cIt\u2019s an unusual observation, but it\u2019s not as surprising as you might think,\u201d says Mike Vecchione, a marine zoologist with the US National Oceanic and Atmospheric Administration in Washington DC. The dominant organisms in the deep sea are gelatinous, he explains. \u201cSo it makes sense that other things eat them.\u201d \n             Over easy \n           Scientists from the Monterey Bay Aquarium Research Institute (MBARI) spotted the female octopus in July 2013 off the coast of California \u2014 only the team's third sighting of the species in 27 years. The seven-arm octopus actually has eight arms, but the male carries one tucked in a sac beneath its eye, giving rise to its common name. The species is part of a larger group of octopuses that are known for their close interactions with jellies and other gelatinous creatures, says Steve Haddock, a marine biologist at MBARI in Moss Landing, California, and one of the authors of the study. Some species of octopus in this group live inside jellyfish or salps \u2014 gelatinous, barrel-shaped animals related to vertebrates (including people). Others brandish the stinging tentacles of the Portuguese man-of-war and other gelatinous animals, possibly to use in catching prey.  Haliphron atlanticus  was the last one in the group that didn\u2019t seem to be interacting with jellies \u2014 until now, Haddock says. Researchers corroborated their seven-armed-octopus footage with the gut contents of preserved museum specimens collected in the 1970s and 1990s. Every one of the preserved octopuses had the remnants of animals such as jellies and salps in its stomach, says Haddock. Despite the fact that female  H. atlanticus  can grow up to 4 metres long, the species doesn\u2019t require as much energy to stay alive as other octopuses do. \u201cThey\u2019re running on a slower clock,\u201d Haddock says. So eating low-calorie jellies works for them, especially if they focus on nutritious parts such as the stomach, an area that was missing from the egg-yolk jelly in the 2013 video. \n                   The secret lives of jellyfish 2016-Mar-22 \n                 \n                   'Octomom' sets gestation record 2014-Jul-30 \n                 \n                   Deep-sea squid uses tentacles to attract prey 2013-Aug-28 \n                 \n                   Marine ecology: Attack of the blobs 2012-Feb-01 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21724", "url": "https://www.nature.com/articles/nature.2017.21724", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "The parasitic fish could be the first case of growth-dependent sex determination. Sex is determined by chromosomes in mammals and by temperature in many reptiles. But for sea lampreys \u2014 eel-like creatures that dine on blood \u2014 the growth rate of their larvae seems to control whether they are male or female. They are the first creatures known to undergo sex determination in this way. Researchers know next to nothing about sex determination in sea lampreys ( Petromyzon marinus ) and have long been puzzled by the observation that some adult populations are mostly male, and others female. The fish begin their lives as larvae with undifferentiated sexual organs. After a year or so, they develop gonads, and after a few more years \u2014 the timing can vary \u2014 they metamorphose into adult sucker-mouthed parasites. A team led by biologist Nick Johnson, at the US Geological Survey in Millersburg, Michigan, identified lamprey habitats in and near streams leading to the Great Lakes. Some areas were productive, with lots of food, whereas others were unproductive sites with little food. After taking measures to ensure no wild lamprey were present, they released between 1,500 and 3,000 wire-tagged larval lamprey into each of the study sites. The researchers recaptured the tagged lamprey and checked their sex after the larvae had metamorphosed into adults and migrated upstream. They found that lamprey in productive streams with lots of food were larger, reached maturity earlier and were more likely to be female. But in unproductive sites, smaller, male lamprey dominated, Johnson\u2019s team reports in a paper published on 29 March in  Proceedings of the Royal Society B 1 . \n             Food for females \n           Johnson thinks that lampreys\u2019 peculiar sex-determination system could have to do with larval density or nutrient availability. Larval lamprey grow larger when there are a lot of nutrients around, and eggs take a lot of energy to create. In a high-nutrient environment, it would make sense to produce eggs, explains Johnson. Rike Stelkens, a zoologist at Stockholm University, is not surprised that lamprey seem to\u00a0have such a bizarre mechanism of sex determination. \u201cFish have a crazy range of sex-determination types,\u201d she says. \u201cSome are influenced entirely by genes, others entirely by the environment. The finding that a life-history trait like growth rate affects sexual development makes sense.\u201d Fisheries scientists have a keen interest in lamprey's sex lives. Understanding their sex determination could help to control invasive lamprey that, since the 1930s, have followed human-made shipping channels into the Great Lakes. In \u201ca perfect storm of invasion\u201d, the parasitic lamprey have decimated native fish populations, according to Marc Gaden, communications director at the Great Lakes Fishery Commission in Ann Arbor, Michigan. Today, fisheries officials in the United States and Canada work to keep invasive lamprey populations in check, but it\u2019s time-consuming and costly. A better understanding of larval growth rates could save money by enabling them to focus control efforts on streams dominated by females, which produce more offspring, Gaden says. Lampreys and other jawless fish also  branched off from the vertebrate family tree \u00a0early in evolutionary history, notes Margaret Docker, an evolutionary biologist at the University of Manitoba in Winnipeg, Canada. \u201cUnderstanding sex determination in\u00a0lampreys\u00a0will help us understand the evolution of sex determination in vertebrates.\u201d \n                   Fossils rewrite history of penetrative sex 2014-Oct-19 \n                 \n                   Chicken's split sex identity revealed 2010-Mar-10 \n                 \n                   Evolution: Mouth to mouth 2009-Sep-09 \n                 \n                   Immune systems evolved more than once 2004-Jul-07 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21714", "url": "https://www.nature.com/articles/nature.2017.21714", "year": 2017, "authors": [{"name": "Alison Abbott"}, {"name": "Ewen Callaway"}, {"name": "Daniel Cressey"}, {"name": "Elizabeth Gibney"}, {"name": "Inga Vesper"}], "parsed_as_year": "2006_or_before", "body": "The months between the Brexit vote and this week's triggering of Article 50 have been a turbulent time for scientists \u2014 and things show no sign of calming. When the United Kingdom  voted to leave the European Union  on 23 June last year, the decision  triggered a period of intense soul-searching and uncertainty , not least for a research community with strong and long-standing financial and social links to the continent. Worries about science funding,  residency rights  and even about  racist attacks  took root in laboratories across the country. But the vote also marked the beginning of a phoney war: little of substance could be done or said by the government until it triggered the previously obscure \u2018Article 50\u2019 clause, in the EU\u2019s governing treaty, to start the official process of leaving (see 'A slow divorce'). On 29 March, Theresa May will do just that.  Nature  has spoken to eight people whose lives have been changed by the \u2018leave\u2019 vote, to see what their experiences tell us about how science will progress, post-Brexit. Simone Immler: I\u2019m moving to Britain, despite Brexit Ian Chapman: I spend half of my time dealing with Brexit Gerry Gilmore: I\u2019m probably out of a job, but my concern is for the next generation Jernej Ule: I may leave the UK \u2014 if I have to Marino Zerial: Come to Germany, where funding is good Anna Scaife: All we have left is uncertainty Mike Galsworthy: Scientists need to offer their vision for Brexit Dominic Shellard: Now is not the time for academics to feel powerless \n               I\u2019m moving to Britain, despite Brexit  \n             \n               Simone Immler, evolutionary biologist, Uppsala University, Sweden \n             On 10 June last year, Immler interviewed for her dream job, a permanent position studying the evolution of sex, at the University of East Anglia (UEA) in Norwich, UK. Immler, who is Swiss, and her Israeli husband both run labs at Uppsala University \u2014 but the UEA was dangling a pair of positions in front of them. Then, two weeks later, the United Kingdom voted to leave the EU. \u201cWe said, \u2018This can\u2019t be true\u2019,\u201d Immler recalls. But after reassurance from friends in the United Kingdom that the nation would still be welcoming to immigrants, she and her husband, evolutionary biologist Alexei Maklakov, decided to make the leap. Their family moved to the United Kingdom this month. Despite uncertainties over the outcome of Article 50 negotiations, Immler is taking a \u2018glass-half-full\u2019 perspective. She hopes that the United Kingdom will follow the example of Israel, a non-EU country that pays into funding bodies such as the European Research Council, from which both she and her husband receive support. She will maintain a lab in Uppsala for another year, so that graduate students and postdocs can continue their projects there. But as a former postdoc at the University of Sheffield, UK, she knows the benefits of free movement across Europe, and worries that she will struggle to draw graduate students and postdocs from a large pool of young scientists. \u201cI\u2019m generally optimistic,\u201d Immler says. \u201cIt would have to come to extreme measures for us to leave again. Life would have to become very difficult for non-Brits in Britain, and we\u2019re still hopefully quite far from that.\u201d \n               I spend half of my time dealing with Brexit  \n             \n               Ian Chapman, chief executive officer, Culham Centre for Fusion Energy, Abingdon, UK \n             The morning after the United Kingdom\u2019s referendum on its membership in the EU, as other staff at the UK national laboratory for fusion-energy research walked around in a daze, Chapman was hastily making plans. His interview for a job to head the centre \u2014 which hosts the EU-funded Joint European Torus (JET) \u2014 was just days away, and the centre\u2019s future was suddenly up in the air. \u201cI\u2019d made a load of preparations for things I wanted to say, and then I summarily had to rip them all up and start again,\u201d he says. Chapman got the job. He is now tasked with leading JET through the tumult and managing a skittish staff of around 550. The physicist estimates that at least half of his time is spent dealing with the impact of Brexit. His main goal is to keep JET \u2014 a facility that holds the world record for fusion power \u2014 running beyond the end of its current contract in December 2018. Another is to maintain the United Kingdom\u2019s involvement in the International Thermonuclear Experimental Reactor (ITER) in southern France, for which JET is a test bed. Both tasks got harder in January, when the UK government announced that, as part of the country\u2019s withdrawal from the EU, it would also pull out of the European Atomic Energy Community (Euratom), the body that distributes EU fusion funding and manages the United Kingdom\u2019s membership of ITER.  \n               boxed-text \n             The decision wasn\u2019t a complete surprise, says Chapman. But it came without warning or an obvious plan for how to maintain the United Kingdom\u2019s fusion programme after the nation leaves Euratom. Chapman is now collecting data to help the government to work out the implications of various ways forward, which range from becoming an associate member of Euratom to funding an independent programme of research. He also fills his hours by settling staff members\u2019 nerves. Scientists at JET are preparing for a 2019 dress rehearsal of a fuel mix that ITER will eventually use, which should see JET break its own fusion record \u2014 but it may never happen. Routine negotiations to extend JET\u2019s contract are on ice. The uncertainty has not yet triggered a mass exodus, says Chapman, but some top-level staff members have accepted positions elsewhere, and candidates have rejected job offers, citing questions over JET\u2019s future. Despite these uncertainties, Chapman thinks that the government understands what is at stake and says that it has been responsive. But the United Kingdom\u2019s fusion community needs a concrete signal from the government \u2014 and soon. \u201cThere\u2019s a time window beyond which the disquiet will ratchet up, and we will start to haemorrhage capacity,\u201d says Chapman. \u201cThat will be hugely damaging, for us as an organization and for the entire fusion community.\u201d \n               I\u2019m probably out of a job, but my concern is for the next generation  \n             \n               Gerry Gilmore, experimental philosopher, University of Cambridge, UK \n             Brexit is likely to put Gilmore out of one of his jobs. As scientific coordinator of Opticon, EU's Optical Infrared Coordination Network for Astronomy, he plans to hand control of the centre to an institution in an EU member state. \u201cIt\u2019s not even a question of us making that decision,\u201d he says. \u201cThe UK government made the decision. Now, every grant coordinated from the UK has to leave.\u201d Opticon makes telescope time available to scientists across Europe and develops telescope technology, including real-time observation, electronic controls and superfast cameras. Because the consortium is funded by the European Union, Gilmore fears that the United Kingdom will lose access to the brain power that it needs to stay ahead in a competitive field. Opticon also helps to set the long-term strategic agenda of telescope-based research and infrastructure across the EU, and Gilmore worries that the United Kingdom will soon have little say in such matters. Gilmore\u2019s European Research Council grant is also on the line as a result of Brexit, but his main concerns lie with young researchers. He fears that the next generation of UK scientists will have to shape their careers in a greatly diminished environment, as will European researchers who could lose access to UK universities. Universities such as Cambridge also stand to lose funding if no deal granting them access to Horizon 2020, the European Commission\u2019s research-funding programme, is negotiated. Opticon received \u20ac8.5 million (US$9.2 million) from the EU between 2013 and 2016 alone. Even if the UK government tops up national research funding to compensate for the loss of European programmes, Gilmore says, it can never replace the inspiration that British scientists gain from working with European colleagues. \u201cIt\u2019s simple \u2014 if the UK leaves the EU, its scientists leave,\u201d he says. \u201cIt\u2019s just an incredibly stupid decision.\u201d \n               I may leave the UK \u2014 if I have to  \n             \n               Jernej Ule, molecular biologist, Francis Crick Institute, London \n             Later this year, Ule\u2019s laboratory will welcome a rare specimen \u2014 a Brit. The rest of his team hail from Switzerland, Spain, France, Italy, elsewhere in Europe and beyond, and Ule is a Slovenian citizen who has lived in the United Kingdom for a decade. \u201cMy identity is European, not Slovenian or English,\u201d he says. \u201cI don\u2019t want to choose countries \u2014 it\u2019s a bit too narrow for how I work.\u201d Last August, Ule\u2019s group was  among the first to move into the Francis Crick Institute , a  gleaming new \u00a3700-million ($880-million) super-lab \u00a0in central London. The researchers still feel a buzz when they arrive for work, but \u201cwhen it comes to Brexit, the conversation turns a bit gloomy\u201d, Ule says. Brexit\u2019s threat to freedom of movement is a hot topic in the lab, as is continued access to EU funding. Half of the group receives money from the European Research Council, and Ule fears the financial hit if the United Kingdom loses access to EU research funding after Brexit. But  even if national funders make up the lost cash , Ule says, vying with Europe\u2019s top researchers for EU grants also helps the lab to stay at the cutting edge. \u201cNational funding agencies don\u2019t care if you\u2019re the second best, as long as you\u2019re the best in the UK,\u201d he says. Ule doesn\u2019t plan to leave Britain, but says that could change if a \u2018hard Brexit\u2019 \u2014 which may put an end to EU citizens\u2019 easy passage to and from the country \u2014 puts limits on the openness he feels his lab represents. \u201cIf it\u2019s something that goes against my principles, then I would consider going elsewhere.\u201d \n               Come to Germany, where funding is good  \n             \n               Marino Zerial, director, Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany \n             Brexit could be a boon for European research, at least in the short term, predicts Zerial. \u201cThe UK is becoming less attractive to do research, and so more people are going to consider countries in mainland Europe \u2014 particularly Germany, where the funding is so good.\u201d Germany\u2019s research and development spending relative to its gross domestic product is among the highest in Europe. Zerial expects to see an increase in applications to the large, international graduate school that is jointly run by his institute with the Technical University of Dresden, as well as in applications for postdoc and group-leader positions. \u201cIt\u2019ll be to our benefit.\u201d But Brexit will hurt European science in the long run, he says. \u201cWhen you lose an important piece of the European science landscape like the UK, it makes the European community weaker.\u201d He worries that there could be fewer funding opportunities in the United Kingdom for collaborative research with institutes in mainland Europe \u2014 and that remaining opportunities might face much more bureaucracy. \u201cEuropean Union funding, whatever its weaknesses, supports loads of projects, and the community treasures very much the collaborations involved,\u201d he says. \n               All we have left is uncertainty  \n             \n               Anna Scaife, astrophysicist, University of Manchester, UK \n             \u201cPeople treat you differently now,\u201d says Scaife. Since the referendum, her European colleagues have been wary about starting new collaborations, owing to the uncertainty that now hangs over potential projects with UK citizens. This cautiousness extends to both sides. Scaife and her colleagues are hesitant to participate in EU calls for proposals. She fears that she might become a liability to her colleagues\u2019 applications to Horizon 2020,\u00a0because of the extra risk of having a British institution on board. \u201cThat would be the worst thing \u2014 to see a project lose, and worry that you might be responsible,\u201d she says. Brexit is a constant topic of discussion in Scaife\u2019s department, which works closely with many European organizations, including CERN, Europe\u2019s particle-physics laboratory near Geneva, Switzerland, and the Atacama Large Millimetre Array in Chile, an international facility run in large part by the European Southern Observatory. Without access to EU funding and the expertise of European colleagues, Scaife worries that the United Kingdom will be sidelined in future projects. \u201cOur networks, our contacts will continue to be able to collaborate. All we have left is uncertainty.\u201d But what hurts Scaife most is seeing European colleagues being made to feel unwelcome in their UK home. Some areas of greater Manchester voted \u2018leave\u2019 by a large margin, and since the referendum, many international researchers have been subjected to anti-European and anti-immigrant abuse, she says. \u201cThese people contribute to the intellectual capital of our country, so it is hard to understand that hostility. And colleagues find it very distressing.\u201d\u00a0 For Scaife, the idea that extra spending from the UK government could make up for shortfalls in EU funding and the loss of the United Kingdom\u2019s welcoming culture is preposterous. She says that collaboration is the lubricant that drives the nation\u2019s ideas machine. Without access to the brightest people, and without creating a positive environment for European scientists, she warns, the United Kingdom is playing a dangerous game of isolationism. \n               Scientists need to offer their vision for Brexit  \n             \n               Mike Galsworthy, co-founder, Scientists for EU \n             On the night of the Brexit referendum, Galsworthy watched the results come in from the \u2018Britain Stronger In Europe\u2019 campaign war room. A former research-policy analyst, Galsworthy had co-founded Scientists for EU to ensure that scientists\u2019 voices were prominent in campaign efforts to persuade Britons to vote \u2018remain\u2019. When he returned from a television interview around midnight, after the results had begun to swing pro-Brexit, the mood had grown decidedly grimmer, Galsworthy says \u2014 \u201cand it stayed grimmer\u201d. Galsworthy, who works full time for Scientists for EU, was ready for the outcome. \u201cMy main concern was to document what this means for the UK science community,\u201d he says. Within a few weeks, Scientists for EU had collected more than 400 complaints from the research community: infrastructure and hiring freezes, foreigners turning down jobs in the United Kingdom \u2014 \u201cdozens of stories of impact\u201d, Galsworthy says.  Despite being on the losing side of the referendum, Galsworthy considers that his campaign to give scientists a louder voice has been successful. Before the 2015 general election, science was not on the political agenda, he says. \u201cScience is certainly on the political radar now.\u201d The UK government has tried to address scientists\u2019 concerns by announcing \u00a32 billion ($2.5 billion) per year of new funding for research by 2020, and guaranteeing support of existing EU research grants, also up to 2020, that might be jeopardized by Brexit. But more broadly, the government has tarnished the United Kingdom\u2019s image in the eyes of many scientists in Britain and beyond, Galsworthy says. Researchers\u2019 concerns were not alleviated when Prime Minister Theresa May said, in a recent speech, \u201cIf you believe you're a\u00a0citizen of the world, you're a\u00a0citizen\u00a0of nowhere.\u201d \u201cThis was something that doubled down on the hurt of Brexit and the fracturing that it caused, and went straight to the identity of the science community,\u201d says Galsworthy. \u201cShe was oblivious.\u201d With the terms of Britain\u2019s exit from the EU still deeply uncertain, he now hopes to galvanize researchers to offer their own vision for what science in the United Kingdom and Europe should look like. Brexit, he maintains, is an existential threat to the region\u2019s role as a global hub for science \u2014 \u201cunless we can be smart enough to sidestep this\u201d. \n               Now is not the time for academics to feel powerless  \n             \n               Dominic Shellard, vice-chancellor, De Montfort University, Leicester, UK \n             The morning after the UK voted to leave the EU, Shellard called a meeting at De Montfort University. A thousand people turned up at just a few hours\u2019 notice. \u201cThere were lots of very distressed people,\u201d he says. \u201cThere were staff who were in tears. One Polish student asked me whether I could write him a letter. I said, \u2018What do you need a letter for?\u2019. He said \u2018I\u2019m going home to Poland this weekend and I need a letter to give to the border guards at Heathrow to let me back into the country.\u2019\u201d Like many university vice-chancellors in the United Kingdom, Shellard does not want the nation to leave the EU. As in other UK universities, significant percentages of his staff, his students and his research funding come from the EU. In the wake of the vote, the university sector has been wracked with nerves about all three of these elements being damaged. Whereas some vice-chancellors have taken to writing to newspapers or issuing pleas for protection, Shellard launched a campaign he called #LoveInternational, to reassure existing and potential staff and students from the EU, as well as to protect their residency rights. His tactics included holding a 24-hour vigil in support of EU staff and students \u2014 and more broadly against intolerance globally. Shellard also toured Europe, talking to concerned people in Nicosia, Warsaw, Stockholm, Vilnius and Berlin. Similar to many in academia, Shellard stresses the need for universities to obtain certainty on three key issues: the rights of EU nationals residing in the United Kingdom, the status of EU students at UK universities, and European research funding. However, he doubts that universities will be at the top of the government\u2019s priority list now that negotiations are starting. His message to the academic community is this: instead of waiting for someone else to do something, \u201cYou can make a difference. You can engage. You mustn\u2019t feel impotent.\u201d \n                     Scientists should not resign themselves to Brexit 2017-Jan-04 \n                   \n                     UK government gives Brexit science funding guarantee 2016-Aug-15 \n                   \n                     E-mails show how UK physicists were dumped over Brexit 2016-Aug-05 \n                   \n                     Lessons from Brexit 2016-Jul-25 \n                   \n                     UK scientists in limbo after Brexit shock 2016-Jun-28 \n                   \n                     How scientists reacted to the Brexit 2016-Jun-24 \n                   \n                     Nature special: Brexit and science \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21699", "url": "https://www.nature.com/articles/nature.2017.21699", "year": 2017, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Emphasis on innovation overshadowed by funding freeze for key research councils. The budget that Canadian Prime Minister Justin Trudeau\u2019s government released on 22 March lives up to his promises to emphasize innovation, and to encourage links between industry and academia. But it also presents scientists with a depressing, and unexpected, freeze on the main funding streams for basic research. \u201cThis budget is really focused on innovation and skills,\u201d science minister Kirsty Duncan told  Nature . \u201cLast year we had over $2 billion for science, and this year over a billion for innovation. This is a government that respects research and science.\u201d The plan promises to establish \u201cInnovation Canada\u201d, a new central platform to co-ordinate and simplify support for Canadian entrepreneurs. And there will be Can$950 million (US$710 million) available over five years to support \u201csuperclusters\u201d: areas dense with companies and academics, similar to California\u2019s Silicon Valley, that are designed to push forwards innovative industries such as clean tech. But critics note that much of this money isn\u2019t new; the Can$950 million, for example, is re-allocated from pots set aside in last year\u2019s budget. And there is little in this year\u2019s announcement for basic research. In particular, no mention is made of annual budgets for Canada\u2019s three major research councils, which deal with the natural, health and social sciences. This means that they will have no budget increase at all this year. \u201cThe tri-councils get something every year for cost of inflation. I can\u2019t remember when they got nothing,\u201d says James Woodgett, a biomedical researcher and director of research of the Lunenfeld-Tanenbaum Research Institute in Toronto. \u201cIt sends the wrong message, especially with what\u2019s going on in the US.\u201d \n               Missing pieces \n             The flat funding for the three research councils is odd given  the emphasis that Trudeau\u2019s middle-left Liberal government has placed on science . The prime minister\u2019s first budget, released last year, injected badly needed cash into those granting agencies, more than doubling the meagre annual increases they had received under the former Conservative government. Trudeau\u2019s government is probably sticking to the status quo while it waits for the results of the Fundamental Science Review, an independent assessment of the country\u2019s systems for supporting science, says Paul Davidson, president of the Ottawa-based advocacy group Universities Canada. That analysis will be released in the coming months, the budget notes. \u201cIn the interim, the granting councils can continue to do their work at current levels,\u201d Davidson says. The budget does set aside Can$2 million to fund the post of chief government science adviser. The decision to create that post,  which will provide independent scientific advice to ministers , was  one of the Liberal party\u2019s main campaign promises  \u2014 and a big hit in the science community. So far, the government has moved slowly to fill the position. A search that began in December will produce the first adviser later this spring \u2014 about a year and a half after the Liberals took power \u2014 Duncan says. Two million dollars is \u201cabout right\u201d for the office, says Kathleen Walsh, executive director of the non-profit science-advocacy group Evidence for Democracy in Ottawa. A few other budget points also bring good news. There is Can$80 million to replace the ageing Sidney Centre for Plant Health, which was rescued from closure under the Conservatives in 2012. Another Can$125 million will fund a Pan-Canadian Artificial Intelligence Strategy, to bolster the country\u2019s lead in computing fields such as deep learning. The budget also includes money for training programmes, including Can$50 million to teach children computer coding and Can$221 million to help university graduates find jobs. \n               Trumping the United States \n             A new set of 25 \u2018Canada 150\u2019 research chairs have been established to mark the country\u2019s 150th birthday. Although this comes from an established pool of money, the positions will help to attract leading researchers to Canada from abroad, says Davidson. \u201cThose chairs are an important tool when you\u2019re looking at what\u2019s happening post-Brexit and post-Trump,\u201d he says, referring to  unease over immigration policies and funding in the United Kingdom   and the United States . \u201cThe number of hits on our job site has doubled since November.\u201d And whereas US President Donald Trump  has proposed cutting US government support for climate-change research , Trudeau\u2019s budget introduces several climate programmes. They include Can$73.5 million for a new Canadian Centre for Climate Services to improve access to climate science, and Can$83.8 million over five years to integrate traditional knowledge of climate change \u2014 including that of the First Nations \u2014 and enhance the resilience of northern communities. The lack of major increases in funding comes in the face of challenging finances. The Liberals campaigned on a promise to keep deficits below Can$10 billion a year, but their first budget pushed it to more than Can$25 billion. This year\u2019s budget stretches the deficit to Can$28 billion. \u201cIf I\u2019m being generous, I\u2019d say we weren\u2019t expecting a lot [for science], but we didn\u2019t get anything,\u201d says Woodgett. \u201cI\u2019m pretty disappointed.\u201d  \n                     Help wanted: Canada begins search for chief science adviser 2016-Dec-05 \n                   \n                     Scientific challenges loom for Canada\u2019s popular prime minister 2016-Oct-25 \n                   \n                     Nine years of censorship 2016-May-03 \n                   \n                     Canada\u2019s top scientist faces tough challenge 2015-Dec-22 \n                   \n                     Canadian election brings hope for science 2015-Oct-20 \n                   \n                     Canadian budget pushes applied research 2015-Apr-22 \n                   Reprints and Permissions"},
{"file_id": "543163a", "url": "https://www.nature.com/articles/543163a", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Analysis paints picture of diets, medicine and possible intimacy with humans. The Neanderthals of El Sidr\u00f3n Cave in northern Spain lived hardscrabble lives. But before they died some 50,000 years ago, they dined on mushrooms, moss and pine nuts. One individual may even have used plants and moulds to treat his ailments. This intimate portrait is revealed in an analysis of DNA from the hardened tooth plaque of five Neanderthals 1 . The study also reconstructs the first microbiomes from an extinct hominin species, and hints at intimacy \u2014 perhaps kisses \u2014 between humans and Neanderthals. \u201cIt really paints a different picture, almost of their personalities, of really who they were,\u201d says Laura Weyrich, a palaeomicrobiologist at the University of Adelaide in Australia who co-led the study. Tina Warinner, an archaeological geneticist at the Max Planck Institute for the Science of Human History in Jena, Germany, praises the team\u2019s microbiome reconstructions. The fact that the mouths of Neanderthals seem to have been colonized by microbes that are rare in humans today means that \u201cwe're really just scratching the surface of the human microbiome\u201d, she says. Co-authors Alan Cooper at the University of Adelaide, and Keith Dobney at the University of Liverpool, UK, first tried to sequence DNA from the calcified layer of plaque (known as calculus) on the teeth of ancient humans more than two decades ago. The pair had hoped to learn about diet and diseases in the past, but trace contamination clouded any attempts to identify ancient microbes and foods. Improvements in ancient DNA analysis, however, have allowed these trace sequences to be identified and have led to a bonanza of  research into ancient plaque . \n               Woolly rhinoceros \n             In a 2013 study, the team sequenced preserved plaque to uncover upheavals in the human oral microbiome after major dietary shifts including the large increase in starch owing to the advent of settled farming some 10,000 years ago, and the introduction of processed flours and sugar into some human diets during the industrial revolution of the nineteenth century 2 . Weyrich\u2019s team compared plaque DNA from Neanderthals from El Sidr\u00f3n and from the Spy cave in Belgium. The analysis revealed that whereas Spy denizens seemed to consume woolly rhinoceros and wild sheep, El Sidr\u00f3n\u2019s foraged for plants. Both ate mushrooms. However, Herv\u00e9 Bocherens, a palaeobiologist at the University of T\u00fcbingen, Germany, is unconvinced that the plaque DNA identifies meals and dietary differences. Databases of plant and animal DNA tend to lack the extinct species that Neanderthals would have eaten, and previous studies have suggested that both groups ate meat. \u201cAt the moment I would not consider the conclusion robust,\u201d he says. \n               Swapping spit \n             The El Sidr\u00f3n Neanderthals probably also used plants to self-medicate. DNA from poplar trees (parts of which contain salicyclic acid, historically used in aspirin), and  Penicillium  mould (the source of penicillin) turned up on one individual\u2019s teeth. Weyrich suspects that they were trying to treat a visible tooth abscess and a stomach infection caused by the bacterium  Enterocytozoon bieneusi . Genetic evidence of a microbe called  Methanobrevibacter oralis  offers another insight, because it is also found in the mouths of modern humans. Genome comparisons suggest that the microbe\u2019s modern lineage split from the Neanderthal one hundreds of thousands of years after the hominins\u2019 last common ancestor lived. This suggests the archaebacterium was transmitted between them. \u201cIf you\u2019re swapping spit between species, there\u2019s kissing going on, or at least food sharing,\u201d says Weyrich, \u201cwhich would suggest that these interactions were much friendlier and much more intimate than anybody ever possibly imagined.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @ewencallaway \n               \n                     Famous ancient iceman had familiar stomach infection 2016-Jan-07 \n                   \n                     Bacteria bonanza found in remote Amazon village 2015-Apr-17 \n                   \n                     Archaeology: The milk revolution 2013-Jul-31 \n                   \n                     Neanderthals ate their greens 2012-Jul-18 \n                   \n                     Plague genome: The Black Death decoded 2011-Oct-26 \n                   \n                     Plague genome: The Black Death decoded 2011-Oct-25 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21580", "url": "https://www.nature.com/articles/nature.2017.21580", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Artificial-intelligence programs harness game-theory strategies and deep learning to defeat human professionals in two-player hold 'em. A complex variant of poker is the latest game to be mastered by artificial intelligence (AI). And it has been conquered not once, but twice, by two rival bots developed by separate research teams. Both algorithms plays a \u2018no limits\u2019 two-player version of Texas Hold 'Em. And each has in recent months hit a crucial AI milestone: they have beaten human professional players. The game first fell in December to DeepStack, developed by computer scientists at the University of Alberta in Edmonton, Canada, with collaborators from Charles University and the Czech Technical University in Prague. A month later, Libratus, developed by a team at Carnegie Mellon University (CMU) in Pittsburgh, Pennsylvania, achieved the feat. Over the past decade the groups have pushed each other to make ever better bots, and now the team behind DeepStack has formally published details of its AI in  Science 1 . But the bots are yet to play each other. Nature  looks at how the two AIs stack up, what the accomplishments could mean for online casinos and what\u2019s left for AI to conquer. \n               Why do AI researchers care about poker? \n             AIs have mastered several board games, including chess and  the complex-strategy game Go . But poker has a key difference from board games that adds complexity: players must work out their strategies without being able to see all of the information about the game on the table. They must consider what cards their opponents might have and what the opponents might guess about their hand based on previous betting. Games that have such \u2018imperfect information\u2019 mirror real-life problem-solving scenarios, such as auctions and financial negotiations, and poker has become an AI test bed for these situations. Algorithms have already cracked simpler forms of poker: the Alberta team essentially solved a  limited version of two-player hold \u2019em poker in 2015 . The form played by DeepStack and Libratus is still a two-player game, but there are no limits on how much an individual player can bet or raise \u2014 which makes it considerably more complex for an AI to navigate. \n               How did the human-versus-AI games unfold? \n             Over 4 weeks beginning in November last year, DeepStack beat 10 of 11 professional players by a statistically significant margin, playing 3,000 hands against each. Then, in January, Libratus beat four better professionals who are considered specialists at the game, over a total of around 120,000 hands. The computer ended up almost US$1.8 million up in virtual chips. \n               What are the mathematics behind the algorithms? \n             Game theory . Both AIs aim to find a strategy that is guaranteed not to lose, regardless of how an opponent plays. And because one-on-one poker is a zero-sum game \u2014 meaning that one player\u2019s loss is always the opponent\u2019s gain \u2014 game theory says that such a strategy always exists. Whereas a human player might exploit a weak opponent\u2019s errors to win big, an AI with this strategy isn\u2019t concerned by margins \u2014 it plays only to win. That means it also won't be thrown by surprising behaviour. Previous poker-playing algorithms have generally tried to work out strategies ahead of time, computing massive \u2018game trees\u2019 that outline solutions for all the different ways that a game could unfold. But the number of possibilities is so huge \u2014 10 160  \u2014 that mapping all of them is impossible. So researchers settled for solving fewer possibilities. In a game, an algorithm compares a live situation to those that it has previously calculated. It finds the closest one and \u2018translates\u2019 the corresponding action to the table. Now, however, both DeepStack and Libratus have found ways to compute solutions in real time \u2014 as is done by computers that play chess and Go. \n               How do the approaches of the two AIs compare? \n             Instead of trying to work out the whole game tree ahead of time, DeepStack recalculates only a short tree of possibilities at each point in a game. The developers created this approach using  deep learning , a technique that uses brain-inspired architectures known as neural networks (and that helped a computer to  beat one of the world\u2019s best players at Go ). By playing itself in more than 11 million game situations, and learning from each one, DeepStack gained an \u2018intuition\u2019 about the likelihood of winning from a given point in the game. This allows it to calculate fewer possibilities in a relatively short time \u2014 about 5 seconds \u2014 and make real-time decisions. The Libratus team has yet to publish its method, so it\u2019s not as clear how the program works. What we do know is that early in a hand, it uses previously calculated possibilities and the \u2018translation\u2019 approach, although it refines that strategy as the game gives up more information. But for the rest of each hand, as the possible outcomes narrow, the algorithm also computes solutions in real time. And Libratus also has a learning element. Its developers added a self-improvement module, which automatically analyses the bot's playing strategy to learn\u00a0how an opponent had exploited its weaknesses. They then use the information to permanently patch up holes in the AI\u2019s approach. The two methods require substantially different computing power: DeepStack trained using 175 core years \u2014 the equivalent of running a processing unit for 175 years or a few hundred computers for a few months. And during games it can run off a single laptop. Libratus, by contrast, uses a supercomputer before and during the match, and the equivalent of around 2,900 core years. \n               Can they bluff? \n             Yes. People often see bluffing as something human, but to a computer, it has nothing to do with reading an opponent, and everything to do with the mathematics of the game. Bluffing is merely a strategy to ensure that a player\u2019s betting pattern never reveals to an opponent the cards that they have. \n               OK, so which result was more impressive? \n             It depends on whom you ask. Experts could quibble over the intricacies of both methods, but overall, both AIs played enough hands to generate statistically significant wins \u2014 and both against professional players. Libratus played more hands, but DeepStack didn\u2019t need to, because its team used a sophisticated statistical method that enabled them to prove a significant result from fewer games. Libratus beat much better professionals than did DeepStack, but on average, DeepStack won by a bigger margin. \n               Will the two AIs now face off? \n             Maybe. A sticking point is likely to be the big difference in computing power and so the speed of play between the AIs. This could make it difficult to find rules to which both sides can agree. University of Alberta computer scientist Michael Bowling, one of the developers of DeepStack, says that his team is up for playing Libratus. But Libratus developer Tuomas Sandholm at CMU says that he first wants to see DeepStack beat Baby Tartanian8, one of his team\u2019s earlier and weaker AIs. Bowling stresses that the match would carry a big caveat: the winner might not be the better bot. Both are trying to play the perfect game, but the strategy closest to that ideal doesn\u2019t always come out in head-to-head play. One program could accidentally hit on a hole in the opponent\u2019s strategy, but that wouldn\u2019t necessarily mean that the strategy overall has more or bigger holes. Unless one team wins by a substantial margin, says Bowling, \u201cmy feeling is it won\u2019t be as informative as people would like it to be\u201d. \n               Does this mean the end of online poker? \n             No. Many online poker casinos forbid the use of a computer to play in matches, although top players have started to train against machines. \n               Now that computers have slain another AI milestone, what\u2019s left to tackle? \n             There are few mountains left for the AI community to climb. In part, this is because many of the games that remain unsolved, such as bridge, have more complicated rules, and so have made for less obvious targets. The natural next move for both teams is to tackle multiplayer poker. This could mean almost starting from scratch because zero-sum game theory does not apply: in three-player poker, for instance, a bad move by one opponent can indirectly hinder, rather than always advantage, another player. But the intuition of deep learning could help to find solutions even where the theory doesn\u2019t apply, says Bowling. His team\u2019s first attempts to apply similar methods in the three-player version of limited Texas Hold \u2019Em have turned out surprisingly well, he says. Another challenge is training an AI to play games without being told the rules, and instead  discovering them as it goes along . This scenario more realistically mirrors real-world problem-solving situations that humans face. The ultimate test will be to explore how much imperfect-information algorithms really can help to tackle messy real-world problems with incomplete information, such as in finance and cybersecurity. \n                     What Google\u2019s winning Go algorithm will do next 2016-Mar-15 \n                   \n                     Google AI algorithm masters ancient game of Go 2016-Jan-27 \n                   \n                     Game-playing software holds lessons for neuroscience 2015-Feb-25 \n                   \n                     Game theorists crack poker 2015-Jan-08 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21573", "url": "https://www.nature.com/articles/nature.2017.21573", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Diamond-based imaging system uses magnetic resonance of electrons to detect charged atoms and peer at chemical reactions in real time. A quantum microscope that uses a sensor built from diamonds could allow researchers to study such nanoscale mysteries as how DNA folds in a cell, why drugs work or how bacteria metabolize metals. Crucially, the microscope can image individual ions in a solution and reveal biochemical reactions as they occur \u2014 without interfering in the process. The team behind the system described the results in a 14 February preprint on the arXiv server 1 . Researchers have long wanted an imaging system for molecular structures that works like hospital magnetic resonance imaging (MRI) machines, which reveal structures inside the human body without harming them. The idea behind a quantum MRI \u2014 which images at the quantum level using electron spins \u2014 is to do the same for chemical reactions including those involving metal ions. Current magnetic resonance techniques can only reveal structures measuring 10 micrometres or more, and the only way to detect metal ions inside a cell is to add reactive chemicals or freeze the cell so it can be imaged under powerful microscopes \u2014 procedures that kill the cell. A hospital MRI machine works by placing a patient inside a magnetic field, such that protons in the body's atoms align with the machine's magnet. The machine then sends radio pulses through the body area being imaged, which knocks the protons out of alignment. When these pulses are switched off, the protons realign and emit electromagnetic waves at a particular frequency. If the frequency emitted by the body's tissues matches that of sensors in the machine, the two frequencies will resonate like guitar strings tuned to the same note. The machine uses this resonance to reconstruct an image of the body. A team led by physicists Lloyd Hollenberg and David Simpson at the University of Melbourne, Australia, wanted to use this technique to detect metal ions in cells. Some metal ions can be harmful to cells, whereas others are necessary for biochemical reactions, such as those involved in metabolism. The catch is that an MRI sensor needs to be about the same size as the item being imaged, which is currently impossible when trying to look at a single atom. \n               Flawed diamonds \n             To make their quantum MRI microscope, the researchers used 2-millimetre-wide diamonds that contained  atomic-sized flaws in their crystal structure . These flaws are sensitive to changes in magnetic fields and can be 'tuned' to resonate with the spin of the molecule or ion that is being detected. When the diamond's flaws are illuminated with a green laser, the diamond fluoresces red, and the brightness of that fluorescence depends on the strength and direction of an applied magnetic field. Hollenberg, Simpson and their colleagues used a diamond that had an array of flaws in specific locations just below its surface and placed it at the end of a microscope next to a sample. The researchers tuned the defects to a frequency that resonated with the spin of an ionized form of copper that is missing two electrons (Cu 2+ ). By touching the diamond probe to the surface of a sample containing copper ions, the resonance between the two stimulated fluorescence in the diamond flaws. The researchers used a computer program to examine the colour coming off the diamond flaws and to reconstruct an image of the sample, revealing the precise location of each copper ion. Next, the researchers flooded the sample with an acid that adds an electron to Cu 2+ , turning it into Cu + . As they added the acid, they imaged the sample and watched the Cu 2+  spin pattern disappear. The pattern then reappeared over the course of an hour as the sample was oxidized to Cu 2+  on exposure to air. Such a method could one day allow researchers to watch biochemical reactions as they occur in cells.\u00a0 Because the method is non-invasive, it could theoretically be used to image the interior of living cells \u2014 something that Simpson and Hollenberg's team is working towards. The main obstacle is that the diamond probe needs to be physically close to the sample to produce a signal. But the team says that the current method will still be useful for understanding drug mechanisms and investigating proteins found on the cell membrane. The researchers are also trying to adapt the system so it can detect different metals, including iron. Friedemann Reinhard, a physicist at the Technical University of Munich in Germany, praises the work. \u201cThe innovations here bring it a lot closer to the application,\u201d he says. His group is also working with diamond microscopy, creating a system that could image molecules in 3D. He adds that although the new technique still needs improvements, such as the ability to find copper ions in low-concentration solutions, it is \u201cdefinitely a great step ahead\u201d. \n                     Microscopy: Hasten high resolution 2014-Nov-26 \n                   \n                     Quantum physics: Flawed to perfection 2014-Jan-22 \n                   \n                     Nanothermometer takes the temperature of living cells 2013-Jul-31 \n                   \n                     Imaging hits noise barrier 2013-Jul-10 \n                   \n                     Diamond defects shrink MRI to the nanoscale 2013-Jan-31 \n                   \n                     Quantum magnetic resonance microscopy \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21549", "url": "https://www.nature.com/articles/nature.2017.21549", "year": 2017, "authors": [{"name": "Gautam  Naik"}], "parsed_as_year": "2006_or_before", "body": "Editor asked to resign from journal for saying he\u2019ll review only papers whose data he can see. An editor on the board of a journal published by the prestigious American Psychological Association (APA) has been asked to resign in a controversy over data sharing in peer review. Gert Storms \u2014 who says he won\u2019t step down \u2014 is one of a few hundred scientists who have vowed that, from the start of this year, they will begin rejecting papers if authors won\u2019t publicly share the underlying data, or explain why they can\u2019t. The idea, called the  Peer Reviewers\u2019 Openness Initiative , was launched by psychologists hoping to increase transparency in a field beset by reports of fraud and dubious research practices. And the APA, which does not ask that data be made available to peer reviewers or shared openly online, seems set to become an early testing ground for the initiative\u2019s influence. With Storms\u2019 situation still unresolved, the society\u2019s council of editors will discuss whether it should change its policies at a meeting in late March. Storms, a psychologist at the Catholic University of Leuven in Belgium and a consulting editor for the APA\u2019s  Journal of Experimental Psychology: Learning, Memory, and Cognition , accepted an invitation last year to review a study for the journal, and pointed out his new open-data policy. The journal's editor, Robert Greene, wrote back to say that Storms\u2019s stance set \u201ca terrible precedent\u201d because it was unfair to the author of the paper and opposed the APA\u2019s policies and the guidelines followed by other reviewers. \u201cGiven that your policy conflicts with that of the journal, I think that it's best that you step down from the editorial board,\u201d he wrote. Storms refused, writing that he would continue to do what he thought was necessary to \u201cprevent sloppy science\u201d. And he forwarded his correspondence to other editors at the journal. Two of them, Robert Hartsuiker and Marc Brysbaert, both psychologists at Ghent University in Belgium, wrote to Greene saying that they, too, would quit if Storms was forced to resign. \"The policy of asking people to leave rather than inviting a discussion and getting critical voices \u2014 I found that quite inappropriate,\" said Hartsuiker. Greene, a psychologist at Case Western Reserve University in Cleveland, Ohio, notes that Storms\u2019 stance is inconsistent with APA rules and that all submissions to the society\u2019s journals ought to be treated in the same way. \u201cAt this point we're just letting things lie and I am not removing [Storms] from the editorial board. We'll see what happens at the council of editors,\u201d he adds. The APA's journals publisher, Rose Sokol-Chang, declined to comment on Storms' case. \"While we support open sharing of data when it can be ethically shared, we leave the decision of whether to do so to the author,\" she added. \n               Psychology\u2019s data strife \n             The conflict marks the latest effort by some psychologists to change their discipline\u2019s policies on data sharing. The APA, in common with many publishers in the field, asks authors to make their data available to others after publication. But as far back as 2006, a study found 1  that 73% of psychologists were unwilling or unable to do so, even though they had agreed to share. Calls for change gathered force after 2011, when the full extent of years of research fraud by Dutch psychologist  Diederik Stapel  came to light. In that case, an investigative committee noted that Stapel often refused to share his scientific data with colleagues, including his co-authors. Further fraud scandals followed , and psychologists have since taken the lead on efforts to  revisit earlier work ,  questioning statistical data  and showing that some  textbook findings in the field are hard to replicate . Simine Vazire, a psychologist at the University of California, Davis, says that data should be made available on publication and also to reviewers, even if it is on a confidential basis. Without such transparency, assessing a study \u201cis like buying a used car without being able to look under the hood\u201d, she says. But by 2012, only 38% of researchers publishing in four APA journals shared their data when asked, Storms and others reported in a 2015 paper 2  titled \u2018Are we wasting a good crisis? The availability of psychological research data after the storm\u2019. Eric-Jan Wagenmakers, a psychologist at the University of Amsterdam and one of the founders of the Peer Reviewers' Openness Initiative, says he has surveyed 600 researchers in the field to understand barriers to data sharing. The main explanations that they gave were: data sharing is an uncommon practice in the field; researchers prefer to share data only on request; it is time consuming; and researchers have never learned how to share data properly. Wagenmakers\u2019 survey results have not yet been published. Despite prolonged pressure, the APA hasn\u2019t changed its data policies for years, says Jelte Wicherts, a psychologist at Tilburg University in the Netherlands who co-authored the 2006 review and has since criticized the APA\u2019s policies and psychology\u2019s data-sharing standards. \"My hope is they will change their view relating to the openness of data,\u201d he says. \n                     Stat-checking software stirs up psychology 2016-Nov-25 \n                   \n                     Psychologists argue about whether smiling makes cartoons funnier 2016-Nov-03 \n                   \n                     Over half of psychology studies fail reproducibility test 2015-Aug-27 \n                   \n                     Nobel laureate challenges psychologists to clean up their act 2012-Oct-03 \n                   \n                     Report finds massive fraud at Dutch universities 2011-Nov-01 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21618", "url": "https://www.nature.com/articles/nature.2017.21618", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "EPA chief Scott Pruitt denies carbon dioxide\u2019s impact on the climate, and promises deregulation. The heat is on the US Environmental Protection Agency. President Donald Trump\u2019s administration and Republicans in Congress have begun to reshape the agency\u2019s policies on everything from climate change to the use of scientific data in policy-making. On 9 March, Republicans on the House of Representatives\u2019 Science, Space and Technology Committee approved bills that would bar scientists with current EPA grants from serving on agency advisory committees and require that all scientific data used to justify new regulations be made public. That would be a significant hurdle for an agency that often relies on data that is proprietary or must remain confidential to protect the privacy of participants in public-health studies. On the same day,  EPA chief Scott Pruitt  said that he does not believe that carbon dioxide is \u201ca primary contributor\u201d to global warming \u2014 contravening the longstanding scientific consensus. \u201cWe don\u2019t know that yet,\u201d Pruitt said in a televised interview. \u201cWe need to continue the debate and continue the review and the analysis.\u201d The developments \u2014 along with leaked documents that suggest the White House will seek a 25% cut in the EPA\u2019s budget for fiscal year 2018 \u2014 have put agency scientists on edge. One senior EPA official, who declined to be named because he was not authorized to speak publicly, says there is a void of reliable information within the agency. He and most of his colleagues are getting their information about the EPA\u2019s future from press accounts. The situation is particularly difficult for young scientists, who have been asking him whether their postdoctoral fellowships will be extended \u2014 or whether they need to start looking for new jobs. The unnamed official\u2019s advice so far is simple: stay the course. \u201cA lot of things can happen,\u201d he says. \u201cIt\u2019s way too early for people to start jumping out windows.\u201d \n             Follow the money \n           Trump is due to release a budget outline next week for the 2018 spending year. A White House document leaked this week suggests that, along with seeking to slash the EPA\u2019s overall budget, the Trump administration will also propose a sharp decrease in research funding and a 20% reduction in the agency\u2019s staff of 15,000. Although Congress has been friendly to Trump\u2019s policies so far, the president\u2019s first budget plan could still face challenges in the Senate, where Republicans hold a narrow majority. \u201cNobody is expecting an increase, but it\u2019s not clear at all that these cuts will make it through Congress,\u201d says Jeff Ruch, executive director of Public Employees for Environmental Responsibility, an activist group in Silver Spring, Maryland. Then there are the legal battles looming. Environmentalists and some progressive states are gearing up to challenge the EPA as it rolls back environmental regulations. At the top of the list are  two landmark climate regulations developed under former president Barack Obama : one,  now on hold pending a lawsuit , would reduce emissions from power plants; the other, already in place, sets aggressive fuel-efficiency requirements for vehicles up to 2025. \u201cThey want to roll back the rules, cut the budget and paralyse the institution,\u201d says David Doniger, director of the climate and clean air programme at the Natural Resources Defense Council, an environmental group based in New York City. \u201cThis is going to be a long fight, but I think there\u2019s a very good chance of blocking their moves so that a future administration can put Humpty Dumpty back together again.\u201d \n             Advice wanted? \n           And there is the pair of bills approved on 9 March by the House Science, Space and Technology Committee \u2014 setting the stage for the full House to consider the measures. Both bills are ostensibly intended to bolster science and transparency within the agency. One would prohibit the EPA from developing new regulations unless the underlying scientific data is made public. The second would require broader membership on the EPA Science Advisory Board, which critics say would clear the way for greater industry representation. It would subject the board\u2019s reports to public review, prevent scientists who have current EPA grants from serving on the advisory board, and bar advisory-board members from seeking EPA funding for three years after their board service ends. The science committee\u2019s chairman,  Republican Lamar Smith of Texas , says that an open and honest scientific process is \u201clong overdue\u201d at EPA. But environmentalists and scientists say that the two bills would make it harder for the EPA to solicit solid scientific advice and develop regulations. In particular, the first bill would require the agency to make public all kinds of data, including health data that the EPA often doesn\u2019t have the legal right to release, says Yogin Kothari, who tracks legislation for the Union of Concerned Scientists\u2019 Center for Science and Democracy in Washington DC. \u201cThe science that the agency relies on should be public, but you don\u2019t need the underlying data,\u201d Kothari says. \u201cIt really is a way to just prevent the agency from doing anything.\u201d \n                   Regulatory reform puts US waters in jeopardy 2017-Mar-01 \n                 \n                   Science and the US Supreme Court: The cases to watch in 2017 2017-Feb-01 \n                 \n                   Rumours swirl about Trump's science adviser pick 2017-Jan-20 \n                 \n                   US Earth scientists plan for uncertain future under Trump 2016-Dec-20 \n                 \n                   The ultimate experiment: How Trump will handle science 2016-Nov-11 \n                 \n                   How Republicans reshaped the House science committee 2016-Oct-19 \n                 \n                   Nature  special: Tracking the Trump White House \n                 \n                   US EPA Clean Power Plan \n                 \n                   US EPA automobile emissions standards \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21619", "url": "https://www.nature.com/articles/nature.2017.21619", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Scott Gottlieb may face scrutiny over potential conflicts of interest. President Donald Trump has nominated Scott Gottlieb \u2014 a conservative pundit, physician and venture capitalist \u2014 to head the US Food and Drug Administration (FDA). Gottlieb, who serves on the board of several pharmaceutical companies, is a vocal critic of the health-care reforms instituted by former president Barack Obama. At times, he has also characterized the FDA as standing in the way of innovation, slowing patients' access to new drugs and limiting physicians' autonomy. The criticisms are based on experience: Gottlieb has worked at the agency before, including as deputy commissioner for medical and scientific affairs under former president George W. Bush. Gottlieb, who was nominated on 10 March, would have to be confirmed by the US Senate before taking office again. \u201cScott Gottlieb is not the worst choice that Mr. Trump could make for the FDA commissioner,\u201d says Jaydee Hanson, a senior policy analyst at the Center for Food Safety, a consumer-activist group in Washington DC. Hanson notes that although Trump pledged during his campaign to do away with food-safety regulations that require too many inspections, Gottlieb at least has argued that more needs to be done to ensure the safety of imported food. The FDA appointment has been closely watched by the pharmaceutical industry and consumer activists alike:  reducing regulation is one of Trump's top priorities . In a 28 February speech to Congress, Trump promised to \"slash the restraints\" on drug approval, complaining about the \u201cslow and burdensome approval process\u201d at the FDA. But Gottlieb is a more conventional choice to lead the FDA than some of Trump\u2019s other choices of agency heads. He is a fellow of the American Enterprise Institute, a conservative think tank in Washington DC, where he has argued that some aspects of the Affordable Care Act, Obama\u2019s signature health-care reform law, were predicated on misconceptions about US health-care economics. He is also a partner at New Enterprise Associates, a large venture-capital firm headquartered in Chevy Chase, Maryland, and Palo Alto, California. The firm\u2019s investments include life-sciences companies. In addition to his service on pharmaceutical company boards, Gottlieb is a consultant for London-based pharmaceutical giant GlaxoSmithKline. If confirmed, he would not be the first FDA commissioner who has come to the agency carrying potential conflicts of interest. Robert Califf, a cardiologist who stepped down as FDA head in January, was also  scrutinized for the ties to industry  he forged over decades of running clinical trials in partnership with pharmaceutical companies. \n             Deep background \n           In public statements, Gottlieb has argued that the FDA sometimes puts its drive for statistical rigour and well-designed clinical trials before the needs of patients. During a 2013 forum on drug approvals, Gottlieb pointed to an instance in which the FDA demanded a randomized, placebo-controlled clinical trial to evaluate a drug for a devastating rare genetic disorder called Hunter syndrome. The agency wanted the drug\u2019s developer to enroll 96 patients in the trial \u2014 20% of the US population that has the condition \u2014 and to measure impacts on clinical symptoms that took years to show up. \u201cWhat we can\u2019t have is an FDA that\u2019s ruled by statistics over medicine,\u201d he said. \u201cAmericans deserve a less cautious FDA, and an FDA that actively embraces advances in science.\u201d That stance, and others, has drawn wide support for Gottlieb from the drug industry. A February survey by the investment bankers Mizuho Securities USA in New York City found that 72% of executives from 53 drug companies surveyed preferred Gottlieb to Trump's other rumoured candidates for FDA chief. Last year, when asked about the FDA\u2019s efforts to regulate  certain medical tests  that  are becoming more complex and integral to patient care , but are not now subject to agency oversight. Gottlieb said that to regulate all such diagnostic tests would slow innovation and make the tests more expensive. \u201cWill the public-health benefits of having FDA oversight outweigh that impact of regulation,\u201d he said. \u201cI think that\u2019s an open question.\u201d But in the same interview, Gottlieb acknowledged that some complex tests could merit regulation, and suggested that the FDA pinpoint those for regulation without trying to encompass the whole field. Whether and how the FDA will regulate these tests remains an open question: the agency has proposed guidelines outlining how it might do so, but has not yet finalized them. A new commissioner could be influential in their final form, says Michael Carome, director of the health research group at Public Citizen, a consumer-activist group in Washington DC. The next commissioner could shape how industry can promote its drugs for uses other than those for which the drug was approved \u2014 another area in which the agency has yet to issue final guidance to industry. The FDA commissioner will also be in a position to influence the next reauthorization of the FDA\u2019s user fees, which is due to come before Congress later this year. That reauthorization, which takes place every five years, could be an opportunity for Congress to influence the FDA\u2019s oversight on issues such as medical testing, or to speed up the FDA\u2019s review of new drugs, says Carome. \u201cA commissioner who supports a deregulatory approach could substantially influence that,\u201d he says. \u201cThey play a very important role in framing that legislation.\u201d  Sara Reardon contributed reporting. \n                   Gene-edited cows, rogue clinics, speedier drug approvals: the challenges facing Trump's FDA chief 2017-Jan-06 \n                 \n                   US regulators try to tame 'wild west' of DNA testing 2015-Feb-20 \n                 \n                   Clinical-trial specialist could be next FDA chief 2015-Feb-12 \n                 \n                   Home-brew tests need regulation 2014-Aug-05 \n                 \n                   Regulation: The FDA is overcautious on consumer genomics 2014-Jan-15 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21617", "url": "https://www.nature.com/articles/nature.2017.21617", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "The 1.6-billion-year-old specimens hold promise for settling long-running debate. The debate over the origin of the lineage that led to multicellular life \u2014 and thus plants and animals \u2014 has raged for decades. To identify when these \u2018eukaryotes\u2019 emerged, researchers need well-preserved fossils, complete with characteristics such as complex internal structures surrounded by membranes. Now, a newly discovered set of specimens that are about 1.6 billion years old may help to reveal the truth. Stefan Bengtson, a palaeobiologist at the Swedish Museum of Natural History in Stockholm who led the team that made the discovery, thinks that these fossils could represent the oldest red algae, and therefore the oldest eukaryotic specimens, found so far. If they are indeed red algae, they could also push back the date for the origin of photosynthetic algae and plants by several hundred million years 1 . The researchers found three sets of these fossils, which are described in a study 2  published on 14 March in  PLoS Biology , in a region of central India. The first set is arranged like a stack of coins and is probably a colonial bacterium that the authors name  Denaricion mendax . The other two, which team calls  Rafatazmia chitrakootensis  and  Ramathallus lobatus , look like long filaments separated into smaller chambers. People have found older fossils that might be eukaryotes, says Bengtson. But so far, no one has been able to see their internal structures to confirm that. Based on X-ray images of the fossils, researchers found what look like complex, well-preserved structures inside  Rafatazmia . These include what could be a plant-like cell wall and internal dividers called septa. According to Bengtson, the septum\u2019s structure shows that these fossils are definitely red algae, and are therefore eukaryotic and capable of photosynthesis. \n             Seeing the light \n           If that\u2019s true, these fossils will help researchers to narrow down the age of a major evolutionary event, says Debashish Bhattacharya, an evolutionary biologist at Rutgers University in New Brunswick, New Jersey. That would be the point in time at which an  organism engulfed photosynthetic cyanobacteria . But instead of being destroyed, those cyanobacteria eventually evolved into the cellular machinery responsible for photosynthesis in eukaryotes. Current estimates for when this first happened range from 600 million 3  to 1.5 billion years ago 1 . However, Bhattacharya isn\u2019t sure that these fossils truly represent the ancestor at the base of the red-algal evolutionary tree, as Bengtson and his colleagues suggest. Bhattacharya thinks it more likely that the fossils represent a very ancient side branch. But they are certainly red algae of some kind, and definitely eukaryotic, Bhattacharya says. Nicholas Butterfield, a palaeobiologist at the University of Cambridge, UK, on the other hand, is not persuaded. The specimens may share characteristics with red algae, he says, but it would take more than a few septa to convince him that they are true eukaryotes. Perhaps additional similar finds, or the discovery of structures that are definitively eukaryotic, such as an irregularly shaped cell wall, he says. Still, the palaeobiologist thinks that these new fossils are better than some specimens other researchers have put forth as examples of the oldest eukaryotes. It can be difficult to pinpoint exactly where ancient fossils lie on the tree of life because, billions of years ago, many organisms were superficially similar. \u201cThat\u2019s the problem with this field,\u201d says Butterfield. \u201cYou stand back and squint, and say \u2018well, the fossil kind of looks like X.\u2019\u201d Bengtson acknowledges that it\u2019s difficult to peg his fossils\u2019 exact place. \u201cWe can never prove their affinity with 100% certainty,\u201d he says. \u201cBut we are very confident we have made the best guess.\u201d \n                   Claims of Earth's oldest fossils tantalize researchers 2016-Aug-31 \n                 \n                   Debate bubbles over the origin of life 2012-Feb-13 \n                 \n                   New candidates for oldest fossils 2011-Aug-21 \n                 \n                   Indian fossil find resolves fraud accusations 2009-Apr-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21635", "url": "https://www.nature.com/articles/nature.2017.21635", "year": 2017, "authors": [{"name": "Barbara Casassus"}], "parsed_as_year": "2006_or_before", "body": "Popular leader will be forced to retire at 65 \u2014 but senior staff have other ideas. Scientists at the Pasteur Institute in Paris just don\u2019t give up. Following a string of failed attempts to keep their president Christian Br\u00e9chot on after he reaches the mandated retirement age, leading researchers have continued to agitate quietly in his favour \u2014 even though the institute\u2019s board of directors has made what seems to be a final decision on the matter and is starting a search for Br\u00e9chot\u2019s successor. Scientists say Br\u00e9chot has done a great deal to shake up and modernize the institute \u2014 which focuses on biomedical and infectious-diseases research \u2014 since he took over as president in 2013. He should be allowed to stay on to continue his reforms when his four-year term finishes in September, they argue. The problem is that Br\u00e9chot turns 65 in July, and the Pasteur\u2019s age-limit statutes dictate that he cannot remain as president after reaching retirement age. The politicking for Br\u00e9chot has been going on for months: last June, the Pasteur's general assembly (a kind of governing body that includes scientists) decided to dissolve the Pasteur\u2019s board, after the board indicated that it wouldn\u2019t change the age-limit rules. A new board was formed, and researchers' campaigning culminated in a vote this January, at which two-thirds of the board voted for a compromise that would have permitted the president\u2019s term to be extended by one or two years. But the support for that proposal \u2014 suggested by board chairman Christian Vigouroux \u2014 was not enough to save Br\u00e9chot, because it did not gain the 75% of the vote needed to change the rules. \n             Last stand? \n           Researchers are undaunted. In mid-February, after the vote, about 40 top scientists at the Pasteur signed a letter delivered to Vigouroux that backs his plan,  Nature  has learned. The signatories include all 11 heads of the Pasteur\u2019s scientific research departments, and all 18 members of the French Academy of Sciences who work at the Pasteur. But no one who  Nature  contacted wanted to talk publicly about the last-ditch appeal \u2014 because, one researcher said, news of a continuing crisis over the Pasteur\u2019s leadership might tarnish the institute\u2019s image and its fundraising prospects. On 22 February, more than 1,500 Pasteur Institute staff attended a meeting with Vigouroux, at which he said he could not flout the board\u2019s vote, but that he would not rule out asking for another vote if more board members decided to back his proposal. \u201cOpinions would have to be almost unanimous before I would seek another vote,\u201d he said. \u201cBut for the moment, no one who voted against the compromise has told me they have changed their mind.\u201d \u201cUnless the board acts to extend the director\u2019s term, the matter will be dropped,\u201d says one signatory to the letter who does not want to be named. In his view, researchers are becoming discouraged, and feel that they are losing the fight. \n             Br\u00e9chot criticized \n           Not everyone praises Br\u00e9chot's time in office. On 15 March, the French satirical weekly newspaper  Le Canard Encha\u00een\u00e9  reported details of an unpublished joint report by three French government inspectorates (audit and consulting bodies) \u2014 in finance, social affairs and education \u2014 that criticizes Br\u00e9chot's tenure. The report, which  Nature  has also seen, says that Br\u00e9chot's organization of the Pasteur \u201cfostered a fragmentation of structures\u201d and \u201ccreated organizational risk zones\u201d at the institute. Vigouroux, who says that the Pasteur board will disuss the issue at its next meeting at the end of March, notes that the report pinpoints some \u201climited dysfunction\u201d in the institute, notably on some areas of spending and in aspects of the Pasteur's risk-management and compliance with safety procedures. (That refers, in particular, to a 2014 episode in which the Pasteur Institute admitted it could not account for the whereabouts of some 2,000 vials containing samples from the 2003 outbreak of the respiratory disease SARS; and also to the unauthorized import of an inactivated form of the virus that causes Middle East respiratory syndrome (MERS) on a flight from Korea to the Pasteur in 2015.) Br\u00e9chot says that it is normal for such a report to contain criticisms, and that the Pasteur Institute has already started to implement some of its recommendations. \u201cPeople have suggested that the report has been leaked to make sure there are no fresh attempts to keep me on,\u201d he says. A spokesperson for the social-affairs inspectorate declined to comment on when, or if, the report would be published. \n                   Controversial head of French agricultural agency speaks out 2016-Oct-27 \n                 \n                   French agency head resigns in cancer row 2007-Oct-17 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21639", "url": "https://www.nature.com/articles/nature.2017.21639", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "The discovery helps to identify dormant infected cells and could one day lead to a cure. Attempts to cure HIV have been thwarted by a particular type of immune-system cell that can hide the virus. These long-lived infected T cells can evade detection by the body for years, and are hard to find, study and kill. Reliably identifying these  covert reservoirs  is top of the wish-list for HIV researchers, but they've had limited success. That may soon change with the identification of a protein called CD32a. It sits on the surface of T cells that are infected, but lie dormant. Researchers reported their findings on 15 March in  Nature 1 . Like a police sketch of a criminal, the protein provides a way to distinguish these sleeper T cells from other immune-system cells. And it provides hope that scientists could target these silent, infected cells and destroy them. Antiretroviral drugs prevent the virus from spreading throughout the body and the immune system targets cells that are actively transcribing viral DNA. But because a small fraction of infected T cells lie dormant, the viral genome within remains silent and neither the drugs nor the immune system detects the intruder. Known as the 'latent reservoir', these cells become a problem if a patient stops taking antiretroviral therapy. They can slowly awaken, allowing the virus to replicate freely.  \n             Shock and kill \n           \u201cSince 1996, the dream has been to kill these na\u00ad\u00adsty cells in hiding, but we had no way to do it because we had no way to recognize them,\u201d says Monsef Benkirane, a virologist at the University of Montpellier in France, and lead author on the study. In 2012, HIV researchers attempted a new approach to targeting dormant, infected T cells. Called 'shock and kill', the therapy was supposed to  kick-start viral replication in these latently infected T cells . In theory, the immune system and HIV drugs should then be able to locate and attack the cells. However, results up to now have been unimpressive in patients, says Steven Deeks, a virologist at the University of California, San Francisco, perhaps because the drugs used to shock the cells have failed to stimulate enough of the HIV reservoir to show itself. Virologists lack even basic knowledge of the reservoir, because latently infected cells are exceedingly hard to find in the body. It was Benkirane\u2019s quest to solve that problem that led him and his team to the CD32a protein marker. The researchers exposed resting T cells to fluorescently tagged HIV in the lab, and searched for differences in gene expression between cells infected by the marked virus, and those that weren\u2019t. A subset of the quiescent infected cells turned on a gene, which coded for CD32a, that was almost undetectable in uninfected cells. The researchers also determined that the protein is not expressed at significant levels in cells actively producing HIV. Using an antibody that sticks to CD32a, the researchers then pulled cells expressing the protein out of human blood samples from HIV-infected people. As expected, these were quiescent T cells harbouring HIV. \u201cYou absolutely could not have done that before now,\u201d Benkirane says. \n             Exposure \n           Deeks hopes that the new protein target, or biomarker, accelerates research on a cure, in the same way that tests to measure the amount of virus in a sample helped to develop antiretroviral therapy in the late 1990s. The next steps will be to replicate the findings by screening blood from patients of different genders, ethnicities, ages and stages of the disease, says Tony Fauci, director of the US National Insitute of Allergies and Infectious Disease in Bethesda, Maryland. Scientists will also test tissues that HIV usually infects, including the gut and lymph nodes. The ultimate goal, if CD32a turns out to be a reliable marker, is to use it to target drugs to the latent cells. For now, Fauci is excited but cautious about the potential of CD23a. His hesitancy comes from two decades of research searching for a cure that has proved elusive. \u201cI really hope this is correct,\u201d he says. \u201cThe fact that this work has been done by such competent investigators, and the data looks good, makes me optimistic.\u201d See the related News & Views article, ' Finding latent needles in a haystack '. \n                   Hopes of HIV cure in 'Boston patients' dashed 2013-Dec-06 \n                 \n                   Bid to cure HIV ramps up 2013-Jun-26 \n                 \n                   Infant's vanquished HIV leaves doctors puzzled 2013-Mar-05 \n                 \n                   Dormant HIV gets rude awakening 2012-Jul-27 \n                 \n                   Drug brings HIV out of hiding 2012-Mar-08 \n                 \n                   Lab page of Monsef Benkirane \n                 \n                   Cure research at the NIH \n                 Reprints and Permissions"},
{"file_id": "543295a", "url": "https://www.nature.com/articles/543295a", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Geologists unearth signs of major volcanic events stretching back 3 billion years. Enormous volcanoes vomited lava over the ancient Earth much more often than geologists had suspected. Eruptions as big as the biggest previously known ones happened at least 10 times in the past 3 billion years, an analysis of the geological record shows. Such eruptions are linked with some of the most profound changes in Earth\u2019s history. These include the biggest mass extinction, which happened 252 million years ago when volcanoes blanketed Siberia with molten rock and poisonous gases. \u201cAs we go back in time, we\u2019re discovering events that are every bit as big,\u201d says Richard Ernst, a geologist at Carleton University in Ottawa, Canada, and Tomsk State University in Russia, who led the work. \u201cThese are magnificent huge things.\u201d Knowing when and where such eruptions occurred can help geologists to pinpoint ore deposits, reconstruct past supercontinents and understand the birth of planetary crust. Studying this type of volcanic activity on other planets can even reveal clues to the geological history of the early Earth. Ernst presented the findings this month to an industry consortium that funded the work (see \u2018Earth\u2019s biggest eruptions\u2019). He expects to make the data public by the end of the year, through a map from the Commission for the Geological Map of the World in Paris. \u201cThis will probably be the defining database for the next decade,\u201d says Mike Coffin, a marine geophysicist at the University of Tasmania in Hobart, Australia. Surprisingly, the ancient eruptions lurk almost in plain sight. The lava they spewed has long since eroded away, but the underlying plumbing that funnelled molten rock from deep in the Earth up through the volcanoes is still there. \n               Telltale tips \n             Ernst and his colleagues scoured the globe for traces of this plumbing. It usually appears as radial spokes of ancient squirts of lava, fanned out around the throat of a long-gone volcano. The geologists mapped these features, known as dyke swarms, and used uranium\u2013lead dating to pinpoint the age of the rock in each dyke. By matching the ages of the dykes, the researchers could connect those that came from a single huge eruption. During their survey, they found evidence of many of these major volcanic events. Each of those newly identified eruptions goes into Ernst\u2019s database. \u201cWe\u2019ve got about 10 or 15 so far that are probably comparable to the Siberian event,\u201d Ernst says, \u201cthat we either didn\u2019t know about or had a little taste, but no idea of their true extent.\u201d They include a 1.32-billion-year-old eruption in Australia that connects to one in northern China. By linking dyke swarms across continents, scientists can better understand how Earth\u2019s crust has shuffled around over time, says Nasrrddine Youbi, a geologist at Cadi Ayyad University in Marrakesh. Technically, the eruptions are known as \u2018large igneous provinces\u2019 (LIPs). They can spew more than one million cubic kilometres of rock in a few million years. By comparison, the 1980 eruption of Mount St Helens in Washington state put out just 10 cubic kilometres. These large events also emit gases that can change atmospheric temperature and ocean chemistry in a geological blink of an eye. A modelling study published last month suggests that global temperatures could have soared by as much as 7\u2009\u00b0C at the height of the Siberian eruptions ( F.\u00a0Stordal  et\u00a0al. Palaeogeogr. Palaeoclimatol. Palaeoecol.   471,  96\u2013107; 2017 ). Sulfur particles from the eruptions would have soon led to global cooling and acid rain; more than 96% of marine species went extinct. But the picture of how LIPs affected the global environment gets murkier the further back in time you get, says Morgan Jones, a volcanologist at the University of Oslo. Uncertainties in dating grow, and it becomes hard to correlate individual eruptions with specific environmental impacts. \u201cIt\u2019s at the limit of our understanding,\u201d he says. On average, LIPs occur every 20\u00a0million years or so. The most recent one was the Columbia River eruption 17 million years ago, in what is now the northwestern United States. Discovering more LIPs on Earth helps to put the geological history of neighbouring planets in perspective, says Tracy Gregg, a volcanologist at the University at Buffalo in New York. She and Ernst will lead a meeting on LIPs across the Solar System at a planetary-science meeting in Texas next week. Venus, Mars, Mercury and the Moon all show signs of enormous eruptions, Gregg notes. On the Moon, LIP-style volcanism started as early as 3.8 billion years ago; on Mars, possibly 3.5\u00a0billion years ago. But without plate tectonics to keep the surface active, those eruptions eventually ceased. \u201cOther planetary bodies retain information about the earliest parts of planetary evolution, information that we\u2019ve lost on Earth,\u201d Gregg says. \u201cThey can give us a window into the early history of our own planet.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     World's deadliest volcanoes identified 2015-Mar-03 \n                   \n                     Earth science: Under the volcano 2013-Dec-09 \n                   \n                     Triassic extinction tied to massive lava spills 2013-Mar-21 \n                   \n                     Why big eruptions don't always fuel mass extinctions 2009-Apr-21 \n                   \n                     Large Igneous Provinces Commission \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21615", "url": "https://www.nature.com/articles/nature.2017.21615", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "To work out how the yeast genome evolved, bioengineers are recreating it. Evolutionary biologist Stephen Jay Gould once pondered what would happen if the cassette \u201ctape of life\u201d were rewound and played again. Synthetic biologists have tested one aspect of this notion by engineering chromosomes from scratch, sticking them into yeast and seeing whether the modified organisms can still function normally. They do, according to seven papers published today in  Science  that describe the creation, testing and refining of five redesigned yeast chromosomes 1 , 2 , 3 , 4 , 5 , 6 , 7 . Together with  a sixth previously synthesized chromosome 8 , they represent more than one-third of the genome of the baker\u2019s yeast  Saccharomyces   cerevisiae.  An international consortium of more than 200 researchers that created the chromosomes expects to complete a fully synthetic yeast genome by the end of the year. The work the team has already done could help to optimize  the creation of microbes to pump out alcohol, drugs, fragrances and fuel . And it serves as a guide for future research on how genomes evolve and function. \u201cThe amazing thing here is that they are figuring out how to tweak the genome \u2014 not just synthesize it \u2014 through a design-build-test-learn cycle,\u201d says Jack Newman, co-founder of Amyris Biotechnologies in Emeryville, California. The approach is similar to one that computer scientists might take when trying to understand a computer code written a decade ago, he adds, although the task is much harder with genomes that have undergone millions of years of evolution. Yeast originated more than 50 million years ago, when the  Saccharomyces  lineage branched off from other fungi. \n               Building blocks \n             In 2010, geneticist Craig Venter and his team revealed 9   the first synthetic genome , a stripped-down version of the genetic code from a bacterial parasite,  Mycoplasma mycoides . Four years later, a team led by Jef Boeke, a yeast geneticist at New York University Langone Medical Center in New York City, synthesized 8  a chromosome from yeast, a more complex organism that is classified as a eukaryote \u2014 a group that also includes plants, worms and people. Venter\u2019s goal was to realize  the smallest genome needed to sustain life , but Boeke sought to explore fundamental questions about evolution, such as whether yeasts could have evolved through alternate routes. He turned the query into a hypothesis testable with synthetic biology: how much can you change a genome and still have a working organism? To look for an answer, Boeke assigned each of  S. cerevisiae \u2019s 16 chromosomes to teams of collaborators, spread across the United States, United Kingdom, China, Singapore and Australia. Each was to create a chromosome that was stable yet evolvable, and would keep yeast functioning as usual. The teams used computer programs to design the codes of their respective chromosomes. They omitted some sequences found in naturally occurring yeast chromosomes, such as repetitive parts of the genome, in hopes of increasing the stability of the synthetic versions. And they endowed their creations with a mechanism that mimics the random variation that drives evolution. When this scrambling system is triggered, it can shuffle, duplicate and delete genes at random. A team led by researchers at the Pasteur Institute in Paris documented 2  dramatic structural changes in the nucleus of the synthetic yeast \u2014 even as it continued to thrive, making proteins and reproducing. \u201cIt seems like we can really kind of torture the genome in complicated ways and frequently the yeast shrugs its shoulders and grows like normal,\u201d Boeke says. \n               Future plans \n             Some teams in the consortium invented techniques to rapidly identify errors in synthetic chromosomes 3 , 4 . Another group, led researchers at Tianjin University in China, optimized techniques to remove bugs in the genetic sequences of the chromosomes, in one instance by using the gene-editing tool CRISPR\u2013Cas9 5 . \u201cConsidering that they synthesized 536,024 base pairs in that chromosome and only used CRISPR to mess around with 45 of them is kind of refreshing,\u201d says George Church, a geneticist at Harvard University in Cambridge, Massachusetts. \u201cIt makes you feel like maybe this is the next big thing.\u201d Genome synthesis is unlikely to displace tools such as CRISPR, which allow scientists to add or subtract a limited number of genes in an organism, he says. But it may become the favoured method for applications that require complicated genetic changes. This includes engineering yeast and other microbes to produce fragrances and other materials; manufacturers that rely on such microbes could use synthetic genomes to make those organisms more resilient to harmful viruses, for example. \u201cIf you took those [microbe] strains offline and reprogrammed their code, then put them back in, the viruses would be so far out of touch they couldn\u2019t come back,\u201d Church says. \u201cIt would be like going back to the Middle Ages and giving one country hydrogen bombs.\u201d Several groups have launched efforts to synthesize genomes from species such as the bacterium  Escherichia coli  \u2014 and from people. Boeke is confident that his consortium will create a fully synthetic yeast genome by the year\u2019s end. The team has already created several additional chromosomes, and is debugging and testing them. The group\u2019s latest results will encourage others to dream big, Church says: \u201cThey\u2019ve been able to induce radical changes in the code, so it emboldens you to be even more radical.\u201d \n                     \u2018Radically rewritten\u2019 bacterial genome unveiled 2016-Aug-18 \n                   \n                     \u2018Minimal\u2019 cell raises stakes in race to harness synthetic life 2016-Mar-24 \n                   \n                     Synthetic biology lures Silicon Valley investors 2015-Nov-04 \n                   \n                     First synthetic yeast chromosome revealed 2014-Mar-27 \n                   \n                     Researchers start up cell with synthetic genome 2010-May-20 \n                   \n                     NatureJobs blog: Painting with yeast \n                   \n                     Synthetic Yeast 2.0 \n                   \n                     GP-write Grand Challenge \n                   \n                     Yeast Art (from the Boeke lab) \n                   Reprints and Permissions"},
{"file_id": "543300a", "url": "https://www.nature.com/articles/543300a", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "The massive project will intercept \u03b3-ray showers in an unexplored energy band. Set high on a mountain plain in China, an ambitious observatory will offer a unique perspective on the origins of cosmic rays, high-energy particles that rain down on Earth. Construction has started on the project, which will probe, for the first time, ultra-high-energy \u03b3-rays \u2014 bursts of radiation thought to be produced alongside cosmic rays in our Galaxy, but whose origins are easier to track. The 1.3-square-kilometre site near Daocheng in Sichuan, close to Tibet, received the go-ahead in January, after an environmental report convinced the government that construction would not harm the threatened white-lipped deer ( Cervus albirostris ) and other animals in a nearby nature reserve. Now, contractors are installing infrastructure for the 1.2-billion-yuan (US$174-million) Large High Altitude Air Shower Observatory (LHAASO). \u201cThis will be the leading project to clarify questions of cosmic-ray physics,\u201d says Giuseppe Di Sciascio, a particle physicist at the National Institute for Nuclear Physics (INFN) in Rome. Di Sciascio, along with researchers from a number of countries, including Switzerland, Russia and Thailand, hopes to collaborate on the project. Chief among the physics questions that LHAASO will investigate is what accelerates cosmic rays\u00a0\u2014\u00a0charged particles such as protons or atomic nuclei\u00a0\u2014\u00a0to such high energies. Some cosmic rays that hit Earth have energies millions of times greater than the energies produced by the most powerful human-made particle accelerator, the Large Hadron Collider near Geneva, Switzerland. Scientists have proposed certain celestial phenomena, such as black holes or supernovae, as origins, but no one has confirmed this conclusively. Magnetic forces can alter the direction of charged particles as they pass through space, which makes their paths untraceable. But \u03b3-rays\u00a0\u2014\u00a0which have no charge\u00a0\u2014\u00a0shoot straight. Scientists suspect that some of the mechanisms that emit high-energy \u03b3-rays might also be the ones that launch cosmic rays; hence, they hope to track back the path of falling \u03b3-rays to pinpoint a cosmic-ray producer. \u201c\u03b3-rays can point straight back to the source,\u201d says Cao Zhen, project director for LHAASO and an astroparticle physicist at the Institute of High Energy Physics in Beijing. Around 180 sources of high-energy \u03b3-rays have been identified, but none has been confirmed to also produce cosmic rays. But LHAASO will be the first to hunt for the highest-energy \u03b3-rays\u00a0\u2014\u00a0those in the peta-electronvolt (10 15  eV) range. \u201cLHAASO will open a new window into the \u03b3-ray sky as the first observatory in this range,\u201d says Avi Loeb, a theoretical astrophysicist at Harvard University in Cambridge, Massachusetts. Cao says that one-quarter of each of the arrays will be installed in 2018, and he expects to obtain first results\u00a0\u2014\u00a0likely to be an analysis of the Crab Nebula\u00a0\u2014\u00a0in 2019. The observatory is set for completion in January 2021. LHAASO\u2019s dense configuration of detector arrays and its location give it an unprecedented ability to spot ultra-high-energy \u03b3-rays, says Di Sciascio. Earth\u2019s upper atmosphere absorbs these rays, which splinter into \u2018air showers\u2019 of lower-energy particles. Because LHAASO is more than 4.4\u00a0kilometres above ground, its detectors will be able to capture much of the shower before it decays to much lower energies.\u00a0 The observatory has more than 5,000 \u2018scintillator\u2019 detectors (see \u2018Catching rays\u2019), which convert \u03b3-radiation into light that can be measured to identify the original energies of the incoming particles. LHAASO will also include 80,000 square metres of surface water pools to take advantage of the Cherenkov effect \u2014 in which particles travelling faster than the speed of light in a particular medium emit light. This phenomenon occurs when particles from \u03b3-ray showers travel through air or water. The surface pools will be equipped with photo-multiplier tubes to detect the bluish light, and scientists can use these data to calculate a particle\u2019s energy and direction. By combing data from different particles, they try to recreate the original \u03b3-ray. LHAASO\u2019s surface water array is  four times larger than the High Altitude Water Cherenkov  (HAWC) \u03b3-ray Observatory\u2019s detector pool in the Pico de Orizaba National Park in Mexico, which has identified dozens of \u03b3-ray sources since 2015. Cao hesitates to put numbers on what LHAASO might detect, but says that scientists expect it to bring the number of known \u03b3-ray sources into the thousand range. Another kind of detector will also help LHAASO to spot \u03b3-rays in the peta-electronvolt range: 1,171 underground water tanks that will pick out muons, which, unlike other particles, can penetrate into Earth. Gamma-ray showers contain fewer muons than cosmic-ray showers, which helps researchers to pick out \u03b3-ray events. \u201cIf we see lots of muons, we know it\u2019s background \u2014 a cosmic-ray shower \u2014 and we reject it,\u201d says Cao. LHAASO will also search for cosmic-ray showers directly, and has dedicated 12 telescopes to the task. They will harness the Cherenkov effect to enable scientists to calculate the energy and composition of cosmic rays. Di Sciascio says that LHAASO could establish the maximum energies that cosmic events in the Milky Way can produce, because its detection capabilities reach the highest energy ranges thought to be emitted by such events. He hopes that LHAASO will settle an ongoing debate over these energy limits. LHAASO\u2019s layout and its wide variety of detectors \u201cmake us confident that all these questions will be faced with unprecedented sensitivity\u201d, he says. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Daring Chinese telescope is poised to transform astronomy 2016-Sep-26 \n                   \n                     Spain and Chile chosen to host \u03b3-ray telescope 2015-Jul-16 \n                   \n                     Astronomy: To catch a cosmic ray 2014-Oct-01 \n                   \n                     High-energy \u03b3-ray astronomy comes back to Earth 2013-Jun-20 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21620", "url": "https://www.nature.com/articles/nature.2017.21620", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "University takes on US National Institutes of Health over animals used for Alzheimer\u2019s research. Like a zombie that keeps on kicking, legal battles over mutant mice used for Alzheimer\u2019s research are haunting the field once again \u2014 four years after the last round of lawsuits. In the latest case, the University of South Florida (USF) in Tampa has sued the US National Institutes of Health (NIH) for authorizing the distribution of a particular type of mouse used in the field. The first pre-trial hearing in the case is set to begin in a federal court on 21 March. The university holds a patent on the mouse, but the NIH has contracted the Jackson Laboratory, a non-profit organization in Bar Harbor, Maine, to supply the animals to researchers. The USF is now claiming that it deserves some of the money that went to the contractor. If the suit, filed in December 2015, is successful, it could set a precedent for other universities, cautions Robert Cook-Deegan, an intellectual-property scholar at the Washington DC centre of Arizona State University in Tempe. And that would threaten the affordability of and access to lab animals used to investigate Alzheimer\u2019s disease more broadly. \u201cIt feels greedy to me,\u201d Cook-Deegan says. \u201cIf other universities start doing this, all it does is push up the cost of research tools.\u201d The mice, on which the USF filed a patent in 1997, express mutated forms of two genes 1 . These modifications help researchers to study how amyloid plaques develop in the brain, and enable them to investigate behavioural changes that manifest before those plaques appear. The current suit has dredged up uncomfortable memories of a similar case that centred on other types of mutant mice used in Alzheimer\u2019s-disease research. In 2010, the Alzheimer\u2019s Institute of America (AIA), based in St Louis, Missouri, sued the Jackson Laboratory directly. But the NIH eventually stepped in because it had contracted the Jackson Lab to distribute the mice. That move shifted the lawsuit to the federal government \u2014 a more costly and formidable defendant to take on in court. The AIA dropped its case in 2011, and lawsuits that it had filed against other biomedical companies were eventually tossed out as well. But these cases exacted a toll: all together, they amounted to some 18.7 cumulative court years in 6 jurisdictions, involved at least 98 lawyers and produced 1,143 court filings 2 . The lawsuits also raised concerns that the AIA would sue researchers who had used the mice in question. This was a fear that, the Jackson Lab argued, hindered researchers from sending mouse strains to facilities such as theirs for maintenance and distribution. \n               Courting complications \n             Nevertheless, the USF decided to pick up where the AIA left off, by suing both the NIH and the Jackson Lab in 2015 over its double-mutant mice. If the university is successful, it could entice others to follow suit, says Tania Bubela, a legal scholar at the University of Alberta in Edmonton, Canada.\u00a0 But such lawsuits could risk damaging an academic institution\u2019s reputation, Bubela adds. \u201cWhether other universities are crazy enough to follow the lead of the University of South Florida is another question,\u201d she says. \u201cI can\u2019t imagine more research-intensive universities engaging in this kind of behaviour.\u201d Two researchers formerly at the USF who are listed as inventors on the university\u2019s double-mutant-mouse patent \u2014 neuroscientists Karen Duff, now at Columbia University in New York City, and John Hardy, now at University College London \u2014 declined to comment specifically on the current lawsuit. A lawyer for the USF also did not comment on the case. But Hardy says: \u201cI do think these things are better sorted out without recourse to lawyers and the courts.\u201d The case is unlikely to set Alzheimer\u2019s research back if access to the mice is restricted as a result of the lawsuit, says neuroscientist Sangram Sisodia of the University of Chicago in Illinois. Several alternative models have been developed since the  Nature  publication in 1998 that first described the USF double-mutant mouse 1 . In 2001, for example, a team led by neuroscientist David Borchelt at the University of Florida in Gainsville described a way of introducing the two mutated genes in one step 3 . \u201cIt saved a lot of time and money,\u201d says Sisodia. Sisodia\u2019s team developed a double-mutant mouse 4  similar to the USF\u2019s version before Hardy and Duff described their mutants. Did Sisodia want to patent his mice? \u201cNo,\u201d he says: \u201cNot interested.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @heidiledford \n               \n                     Broad Institute wins bitter battle over CRISPR patents 2017-Feb-15 \n                   \n                     Patent dispute threatens US Alzheimer's research 2011-Apr-05 \n                   \n                     Mouse patent sparks 'uncivil' spat 2009-Jun-03 \n                   \n                     Patent suit on Alzheimer's mouse rejected\u2026 2000-Jun-29 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21572", "url": "https://www.nature.com/articles/nature.2017.21572", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Hundreds of researchers pick through clinical trial from a major blood-pressure study, to the dismay of some who collected the information. When a prestigious medical journal challenged scientists to analyse data from a pivotal blood-pressure study in search of new findings, hundreds of researchers around the world rushed to sign up. The contest, sponsored by the  New England Journal of Medicine , offered scientists a rare opportunity to access detailed trial data that  otherwise might have remained proprietary for another year  \u2014 if not indefinitely. But the competition, whose winners were announced on 7 March, also illustrates  the tension between speeding access to data  and protecting the interests of those who laboured to collect them. Jackson Wright, a pharmacologist at Case Western Reserve University in Cleveland, Ohio, spent nearly a decade designing and carrying out the blood-pressure trial featured in the data challenge. The landmark study, funded largely by the US National Institutes of Health (NIH), revealed a surprising benefit of lowering blood pressure below the usual targets \u2014 and had the potential to reshape the treatment of millions of patients. Wright's team, which grew to include researchers at 102 institutions, published preliminary results in the  New England Journal of Medicine  in late 2015 1 . In November 2016, the NIH and the journal made the data from the trial available for the data-challenge competition; Wright says the researchers were not given a vote in the decision because they conducted the trial under a contract with the NIH. Now one-third of the 60 papers that Wright's team had planned to publish are in jeopardy of being scooped.  \u201c I think the incentives to do these trials will be dramatically lessened if this is going to be the expectation going forward,\u201d he says. \u201cIt's a huge time commitment.\u201d But others favour making data from trials publicly available as soon as possible. Doing so, they argue, opens up the possibility of a wide range of additional analysis, and speeds up analyses that can yield important clinical insights. \u201cClinical trial data are quite valuable, but usually they're kept locked away,\u201d says Sandosh Padmanabhan, a participant in the competition who researches cardiovascular genomics at the University of Glasgow, UK. \u201cEverybody who does clinical trials needs to open up their data for everybody to use.\u201d \n               Sprinting ahead \n             The Systolic Blood Pressure Intervention Trial (SPRINT) studied 9,361 people who had elevated blood pressure and an increased risk of cardiovascular disease. The goal was to find out whether there was any benefit \u2014 or harm \u2014 of choosing a systolic blood-pressure goal lower than 140 mm Hg. About half of the participants received standard therapy pegged to the 140 mm Hg limit; the other half were treated more intensively, with a goal of forcing their blood pressure below 120 mm Hg. SPRINT, which began enrolling patients in 2010, was halted in August 2015 when an interim analysis showed that patients receiving intensive therapy were 43% less likely to die from cardiovascular causes such as heart attack or stroke than those on the standard regimen. Three months later, SPRINT investigators published their results in the  New England Journal of Medicine 1 . Although SPRINT\u2019s blood-pressure intervention had been halted, the team continued to collect data until July 2016, and is still validating those data before carrying out final analyses. The SPRINT investigators expected to have two years after the final data were collected to conduct those analyses, says Wright. Instead, the NIH and the journal made the data available for its competition in November 2016. Wright worries that hundreds of researchers are now picking through the data while the SPRINT investigators are still busy closing down the trial. \u201cOthers who had nothing to do with the trial are able to publish a lot faster than we are,\u201d he says. \u201cThe return on investment is dramatically reduced for the investigators in SPRINT, no question.\u201d \n               Data frenzy \n             The team that won the data competition was led by Noa Dagan, chief data officer at Clalit Research Institute in Tel Aviv, Israel. The researchers used the data to develop a program to help clinicians determine the risk of intensive blood-pressure treatment to patients, on the basis of their age, gender and other parameters. In second place was a team of medical students at Boston University in Massachusetts that looked at the impact of blood-pressure treatment on patients with chronic kidney disease \u2014 a particular concern because intensive therapy has been thought to place stress on the kidneys. The 143 participants who advanced to the final stages of the data challenge embarked on a wide range of analyses. Padmanabhan tried to determine whether patients who combined more than four blood-pressure medicines were at higher risk of dying, and found a hint that they might be. He says that clinicians have written him to say that the analysis has influenced how they approach treating their patients. All of the analyses submitted as part of the challenge should be considered preliminary, says  New England Journal of Medicine  editor-in-chief Jeffrey Drazen. The studies generate new hypotheses to test, he says, but are working with the earlier, incomplete data set. As a result, the SPRINT team\u2019s analyses, which will be based on the final data, are not entirely at risk, he adds. \u201cI\u2019m very grateful to the SPRINT team,\u201d says Drazen. \u201cA lot of interesting ideas have come from this.\u201d \n                     Tracker flags up failures to report clinical trials 2016-Nov-03 \n                   \n                     Europe\u2019s drug regulator opens vaults of clinical-trials data 2016-Oct-20 \n                   \n                     US toughens rules for clinical-trial transparency 2016-Sep-16 \n                   \n                     Stop the privatization of health data 2016-Jul-20 \n                   \n                     SPRINT Data Analysis Challenge \n                   \n                     Systolic Blood Pressure Intervention Trial (SPRINT) \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21588", "url": "https://www.nature.com/articles/nature.2017.21588", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Policy reinstates restrictions on immigration from six countries but exempts current visa-holders. US President Donald Trump has signed a revised version of his controversial travel ban. The policy, issued on 6 March, exempts citizens of Iraq and people who were issued US visas before 27 January \u2014 including those with green cards. Like the first order,  which Trump signed on 27 January , the revised policy bars citizens of Iran, Libya, Somalia, Sudan, Syria and Yemen from entering the US for 90 days. Trump administration officials told reporters today that the ban is intended to protect the United States from terrorism, but it is not clear whether that reasoning will stand up to legal scrutiny. The first travel ban has been blocked indefinitely by federal courts, pending an ongoing lawsuit, and the revised ban seems certain to face similar challenges. Many scientists affected by the first policy have struggled to understand whether it is safe for them to leave the United States to visit family, attend scientific conferences or  conduct research . The revised policy might not offer these people much comfort, says Stefano Bertuzzi, executive director of the American Society for Microbiology in Washington DC. \u201cI think there\u2019s so much uncertainty that even if they could [travel], I don\u2019t think they would,\u201d he says. \n             Waiver worries \n           There are many scientists whose movements will still be restricted under the new ban, which takes effect on 16 March. Among them are researchers who need to renew their visas, or those who are working or studying in the United States on a single-entry visa, says Brendan Delaney, an immigration lawyer at Leavy, Frank & Delaney in Bethesda, Maryland. Although the 6 March order allows US immigration officials to grant waivers on a case-by-case basis, he adds, it is not clear how this process would work \u2014 or how often such exceptions would be allowed. Those for whom a waiver may be appropriate,  the order says , include \u201clanded Canadian immigrants\u201d and people with busines or professional obligations in the United States. Some scientific societies worry that the ban will be seen as a sign that the United States does not welcome foreigners \u2014 even those who are not from the six banned countries. \u201cIt\u2019s not a chilling effect \u2014 it\u2019s a reality,\u201d says Benjamin Corb, director of public affairs at the American Society for Biochemistry and Molecular Biology in Rockville, Maryland. Already, some international students and scientists  have begun to reconsider working or studying in the United States,   Nature  has reported. At the same time, the Trump administration has moved to restrict the popular H-1B visa available to highly skilled immigrants, including many scientists. On 3 March, the government moved to suspend \u201cpremium processing\u201d for the visas, which allows employers to pay a fee to have a visa application processed in 15 days instead of the usual 3\u20136 months. The suspension takes effect on 3 April and could last up to six months. \n                   How the fallout from Trump's travel ban is reshaping science 2017-Mar-02 \n                 \n                   Academics must protest against Trump\u2019s travel ban \u2014 but they should do so productively 2017-Feb-07 \n                 \n                   Trump immigration ban upends international work on disease 2017-Feb-01 \n                 \n                   Obama science adviser: Trump immigration ban \u2018an abomination\u2019 2017-Jan-30 \n                 \n                   Meet the scientists affected by Trump\u2019s immigration ban 2017-Jan-29 \n                 \n                   Trump agenda threatens US legacy of science diplomacy 2017-Jan-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21616", "url": "https://www.nature.com/articles/nature.2017.21616", "year": 2017, "authors": [{"name": "Anna Nowogrodzki"}], "parsed_as_year": "2006_or_before", "body": "A rare find in land animals reveals a new way to glow. Under normal light, the South American polka dot tree frog ( Hypsiboas punctatus ) sports a muted palette of greens, yellows and reds. But dim the lights and switch on ultraviolet illumination, and this little amphibian gives off a bright blue and green glow. The ability to absorb light at short wavelengths and re-emit it at longer wavelengths is called fluorescence, and is rare in terrestrial animals. Until now, it was unheard of in amphibians. Researchers also report that the polka dot tree frog uses fluorescent molecules totally unlike those found in other animals. The team published the find on 13 March in  Proceedings of the National Academy of Sciences 1 . Because fluorescence requires the absorption of light, it doesn\u2019t happen in total darkness. That makes it distinct from bioluminescence, in which organisms give off their own light generated through chemical reactions. Many ocean creatures fluoresce, including  corals ,  fish , sharks and one species of sea turtle (the hawksbill turtle,  Eretmochelys imbricata ). On land, fluorescence was previously known only in parrots and some scorpions. It is unclear why animals have this ability, although explanations include communication, camouflage and mate attraction. The researchers first thought that they might find red fluorescence in these frogs, because they contain a pigment called  biliverdin . Normally, biliverdin turns the amphibian's tissues and bones green. However, in some insects, says Carlos Taboada, a herpetologist at the University of Buenos Aires in Argentina, proteins bound to biliverdin emit a faint red fluorescence. But in the polka dot tree frog, biliverdin turned out to be a red herring. \n               Dressed to impress \n             When Taboada and his colleagues trained a UVA flashlight (or black light) on polka dot tree frogs collected near Santa Fe, Argentina, they were astonished to find the animals gave off an intense greenish-blue glow instead of a faint red. \u201cWe couldn\u2019t believe it,\u201d says study co-author Juli\u00e1n Faivovich, a herpetologist who is also at the University of Buenos Aires. Three molecules \u2014 hyloin-L1, hyloin-L2 and hyloin-G1 \u2014 in the animals\u2019 lymph tissue, skin and glandular secretions were responsible for the green fluorescence. The molecules contain a ring structure and a chain of hydrocarbons, and are unique among known fluorescent molecules in animals. The closest similar molecules are found in plants, says study co-author Norberto Peporine Lopes, a chemist at the University of S\u00e3o Paulo in Brazil. The newly described fluorescent molecules emit a surprising amount of light, providing about 18% as much visible light as a full Moon \u2014 enough for a related species of frog to see by. Almost nothing is known about the polka dot tree frog\u2019s visual system or photoreceptors, so Taboada plans to study these to determine whether the frogs can see their own fluorescence. \u201cI think it\u2019s exciting,\u201d says marine biologist David Gruber of Baruch College, part of the City University of New York, who with his colleague discovered fluorescence in hawksbill sea turtles in 2015 (ref.  2 ). \u201cIt opens up many more questions than are answered,\u201d he says \u2014 including the ecological and behavioural function of fluorescence. Faivovich wants to look for fluorescence in the 250 other tree frog species that have translucent skin like the polka dot tree frog. He hopes he\u2019s not the only one: \u201cI'm really hoping that other colleagues will be very interested in this phenomenon, and they will start carrying a UV flashlight to the field,\u201d he says. \n                     Radiant reefs found deep in the Red Sea 2015-Jun-24 \n                   \n                     Fish flaunt neon glow 2014-Jan-08 \n                   \n                     First fluorescent protein identified in a vertebrate 2013-Jun-13 \n                   \n                     Green glow deciphered 2009-Apr-25 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21540", "url": "https://www.nature.com/articles/nature.2017.21540", "year": 2017, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "The insects show sophisticated learning for non-bee related tasks, and can even improve on what they are taught. Bees quickly master an insect version of football \u2014 with a sweet reward at the end \u2014 just by watching another bee handle the ball, suggesting that the tiny pollinators are capable of sophisticated learning, says a study in  Science 1 . Bumblebees watched a fellow bee tugging a ball into a goal, which earned the athlete a gulp of sugar water. The observing bees could soon do the task themselves. They even figured out how to nab the reward with less effort. \u201cThey\u2019re not just blindly copying. They\u2019re doing something better,\u201d says study co-author and behavioural ecologist Olli Loukola of Queen Mary University of London. Previous research has shown that insects are capable of advanced cognitive tasks. But this is the first time that insects have shown they can become adept at actions far removed from the job of being a bee, the study authors say. The fact the creatures learned a complex skill by watching their fellow bees rather than by undergoing long, incremental training was also another first. Loukola and his colleagues schooled a select group of buff-tailed bumblebees ( Bombus terrestris ) to move a wooden ball to the centre of a platform to earn a sweet treat. These bees then strutted their stuff while observed by test bees. After three observation sessions, a test bee was allowed to control the ball. They achieved their goal almost every time, implying that they had picked up on social cues while watching the trained bees. Bees without the benefit of instruction scored around 30% of the time. \n             Social learning \n           To push the bees\u2019 abilities, the researchers presented each instructor bee with three balls. Two had been glued in place and only one \u2014 the farthest from the goal \u2014 rolled freely. The instructors lugged that one to the goal. Test bees watched these sessions and were then presented with three freely rolling balls. Instead of copying the instructors by moving the farthest ball, test bees took the easy way out: they moved the closest one. That impresses neuroethologist Ken Cheng of Macquarie University in Sydney, Australia. \u201cIt sure looks like what would be called goal emulation,\u201d or actions in pursuit of a goal rather than rote imitation, he says. If so, \u201cthat\u2019s fairly sophisticated\u201d. Tomer Czaczkes at the University of Regensburg in Germany, is less convinced. He suspects that rather than benefiting from social learning, the test bees might have learned that the ball and target are \u201cinteresting, and so end up interacting with the ball closest to the centre of the platform\u201d. Study co-author Clint Perry, a cognitive neuroethologist at Queen Mary, points out that bees tutored by a fellow insect outperformed bees without role models: one group watched as the ball was moved by a magnet, and another group was given no demonstration at all. \u201cSocial information helped tremendously,\u201d he says. \u201cIt really pushes the idea that small brains aren\u2019t necessarily simpler,\u201d Perry says. \u201cThese miniature brains can accomplish a lot more than we thought.\u201d \n                   Animal behaviour: Inside the cunning, caring and greedy minds of fish 2015-May-26 \n                 \n                   Bees build mental maps to get home 2014-Jun-02 \n                 \n                   Are honeybees gullible? 2008-Jun-24 \n                 \n                   Fruitflies evolve number sense \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21502", "url": "https://www.nature.com/articles/nature.2017.21502", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "The US Patent and Trademark Office issues a verdict in legal tussle over rights to genome-editing technology. The US Patent and Trademark Office (USPTO) has upheld a series of patents granted to the Broad Institute of MIT and Harvard for the  CRISPR\u2013Cas9 gene-editing  technology. The hotly anticipated decision could conclude  a contentious battle  between the Broad Institute in Cambridge, Massachusetts, and the University of California over intellectual-property rights to the potentially lucrative technology. Although the Broad was awarded its patents first, the University of California was the first of the two to apply for a patent on the technology. The California contingent also argues that its team in Berkeley invented the technique before investigators at the Broad. Lawyers representing the University of California  filed for an \u2018interference\u2019 proceeding , in an effort  to have the Broad\u2019s patents thrown out . But on 15 February, patent judges determined that there was no interference, meaning that the Broad\u2019s invention is distinct from that of the University of California, and the Broad patents will stand. The University of California\u2019s patent application will now be referred back to an examiner, but legal challenges could continue. \n               Outlook hazy \n             Throughout the interference proceeding, which was announced in January 2016, the Broad\u2019s lawyers argued that the University of California\u2019s patent application did not specify how CRISPR\u2013Cas9 editing could be adapted for use in eukaryotic cells \u2014 such as those in mice or people. The Broad\u2019s patents did make that distinction: as a result, the lawyers argued, the two patent families would not overlap. The strategy would give the Broad control of what are likely to be  the most lucrative applications of CRISPR\u2013Cas9 gene editing  in plants, livestock and humans. In the wake of the USPTO decision, however, officials at the University of California said that its patent would nevertheless cover the use of CRISPR\u2013Cas9 in all cells: eukaryotic or otherwise. One of the inventors on that patent, molecular biologist Jennifer Doudna of the University of California, Berkeley, likened the situation to licensing permission to someone who wants to use green tennis balls. \u201cThey will have a patent on the green tennis balls,\u201d she said, referring to the Broad patents. \u201cWe will have a patent on all tennis balls.\u201d Even so, stock in Editas Medicine \u2014 a biotechnology firm in Cambridge, Massachusetts, that has licensed the patents from the Broad Institute \u2014 surged shortly after the USPTO verdict was announced. \u201cWe are pleased with the USPTO\u2019s decision,\u201d said Editas president Katrine Bosley in a statement. \u201cThis important decision affirms the inventiveness of the Broad\u2019s work.\u201d \u201cI think this decision is fair,\u201d says Catherine Coombes, a patent lawyer at intellectual-property specialists HGF in York, UK. The University of California\u2019s invention would cover the design of the RNA molecule that guides the key step in CRISPR\u2013Cas9 gene editing, directing the Cas9 enzyme to a specific site in the genome. But getting that system to work in eukaryotes was an additional inventive step, Coombes says. \n               Double trouble \n             At a press conference soon after the decision was released, University of California attorney Lynn Pasahow said that the team had not yet decided whether it would appeal. The two teams could also still reach a settlement, notes Kevin Noonan, a partner at the law firm McDonnell Boehnen Hulbert & Berghoff in Chicago, Illinois. The patent battle was unusually fierce, given that inventors on both sides worked for academic institutions, and their inability to settle the case before moving to an interference proceeding surprised some. For now, the USPTO decision creates uncertainty for companies that may want to use the technology in eukaryotic cells, says Noonan. \u201cEverybody gets to keep their patents,\u201d he says. \u201cThis is maximum uncertainty for people because you don\u2019t know if you have to get licences from both sides.\u201d If companies are forced to seek licences from both sides, the cost of commercializing CRISPR\u2013Cas9 gene editing could increase, he adds. \u201cThese things should be able to be settled between universities,\u201d says Noonan. \u201cThis will give a lot of fodder for those who think universities shouldn\u2019t be in the patenting business.\u201dDoudna argued at the press conference that the patent battle had not hampered research, given the speed with which researchers had taken up the technique and companies had rushed to commercialize it. At the University of Delaware in Newark, technology-transfer officer Joy Goswami started to follow the patent case when a large company wavered over whether to license some of his university\u2019s patents on applications of CRISPR\u2013Cas9 in agriculture. The uncertainty around the patent landscape probably contributed to the hesitation, he says \u2014 but such uncertainty is not uncommon in biotechnology, particularly in the first few years after a hot invention. \u201cI don\u2019t know if this is a big impact,\u201d he says. \u201cIn general, I can tell that there has been a sense of cautiousness.\u201d \n                     CRISPR heavyweights battle in US patent court 2016-Dec-06 \n                   \n                     Titanic clash over CRISPR patents turns ugly 2016-Sep-21 \n                   \n                     The quiet revolutionary: How the co-discovery of CRISPR explosively changed Emmanuelle Charpentier\u2019s life 2016-Apr-27 \n                   \n                     How the US CRISPR patent probe will play out 2016-Mar-07 \n                   \n                     Bitter fight over CRISPR patent heats up 2016-Jan-12 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21550", "url": "https://www.nature.com/articles/nature.2017.21550", "year": 2017, "authors": [{"name": "Cassandra Willyard"}], "parsed_as_year": "2006_or_before", "body": "World Health Organization publishes list that it hopes will focus development of antibiotics. The World Health Organization (WHO) has for the first time released a list of drug-resistant bacteria that pose the greatest  threat to human health  \u2014 and for which new antibiotics are desperately needed. The agency's aim in listing these 'priority pathogens' is to steer funds towards development of the most crucial antimicrobials. Researchers say the list is a useful reminder of the danger of bacteria that are becoming  resistant to antibiotics . The list ranks 12 bacteria or bacterial families and is topped by carbapenem-resistant  Acinetobacter baumannii . This obscure bacterium causes a severe infection for which almost no treatments exist, and mainly affects people who are already critically ill. (It is resistant to carbapenem antibiotics, a  \u2018last resort\u2019 antibiotic  used only when all other treatments have failed.) The ranking also includes well-known bacteria, such as those that cause pneumonia and gonorrhoea (see 'Threat list'). Antibiotic resistance kills an estimated 700,000 people each year worldwide, and some experts predict that number to reach 10 million by 2050 if efforts are not made to  curtail resistance  or develop new antibiotics. Despite an urgent need for these drugs, the once-robust development pipeline for antibiotics now produces little more than a trickle of compounds. As of September 2016, about 40  new antibiotics  were in clinical development for the US market, compared with hundreds of cancer drugs. \n               Threat list \n               Many pharmaceutical companies see antibiotics as a losing proposition. \u201cMost infections are still sensitive to existing drugs,\u201d says Allan Coukell, who oversees an antibiotic-resistance initiative at the Pew Charitable Trusts in Washington DC. \u201cAnd if you have a new antibiotic, you do really want to hold it in reserve for those resistant infections.\u201d That means the market for new antibiotics is relatively small, and companies might not sell enough of the medicine to recoup their costs. \n               Ranking deadliness \n             To create the list, a small team comprising WHO experts and researchers in the Division of Infectious Diseases at the University of T\u00fcbingen, Germany, used pre-existing catalogues as a starting point, including a 2013 list from the US Centers for Disease Control and Prevention and a 2016 Canadian version. The team considered factors such as the pathogens\u2019 deadliness, their level of resistance and how easily they spread. They excluded microbes that can be addressed effectively by other measures, such as good sanitation or vaccination. That gave them a list of 20 bacteria from 12 families. To rank them, the team handed data on each to 70 experts from around the world \u2014 but they did not provide the pathogens' names, in an effort to avoid bias. Coukell says the WHO\u2019s list is useful, but it doesn\u2019t mean that drug developers are going to start at the top and work their way down. Antibiotic development poses scientific and economic challenges, and in terms of drug discovery, \u201cthe low-hanging fruit has been plucked\u201d, says Brad Spellberg, an infectious-disease specialist at the Keck School of Medicine at the University of Southern California, Los Angeles. Gram-negative bacteria, which take the top three spots on the WHO list, pose a particular challenge. These microbes have a double cell membrane, which makes it difficult for drugs to gain entry in high enough concentrations to kill them off. We need to work out how we can get compounds to breach that barrier, says Kim Lewis, a biochemist at Northeastern University in Boston, Massachusetts.  On the financial side, several new initiatives aim to make antibiotic development more appealing. The  US 21st Century Cures Act , signed into law in December 2016, includes a streamlined approval pathway for antibiotics that treat life-threatening infections. Last year also saw the launch of  CARB-X, a public\u2013private partnership  funded by the United States and the United Kingdom that aims to stimulate preclinical development of new antibiotics. Incentives such as these might help to spark activity, but Michael Gilmore, director of Harvard Medical School\u2019s Infectious Disease Institute in Boston, worries that any system that relies on profit-driven drug companies to develop new antibiotics is doomed to fail. \u201cThe bottom line is that the economic model doesn\u2019t work,\u201d Gilmore says. \n                     Use antimicrobials wisely 2016-Sep-07 \n                   \n                     Antibiotics funding splurge gets mixed reception 2016-Jul-28 \n                   \n                     Dramatic rise seen in antibiotic use 2015-Sep-17 \n                   \n                     Policy: An intergovernmental panel on antimicrobial resistance 2014-May-22 \n                   \n                     Antibiotic resistance sweeping developing world 2014-May-06 \n                   \n                     WHO warns against 'post-antibiotic' era 2014-Apr-30 \n                   \n                     Antibiotic resistance: The last resort 2013-Jul-24 \n                   \n                     Pew trusts: A Scientific Roadmap for Antibiotic Discovery \n                   \n                     UK report on antimicrobial resistance \n                   \n                     CDC report on antibiotic threats \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21575", "url": "https://www.nature.com/articles/nature.2017.21575", "year": 2017, "authors": [{"name": "Brian Switek"}], "parsed_as_year": "2006_or_before", "body": "Genomic study of extinction in progress may give insights into modern conservation. Isolated on an island in the Arctic Ocean, not only were the world\u2019s last woolly mammoths on their way out, but they were also swamped with \u2018bad genes\u2019, possibly losing their sense of smell and acquiring strange translucent coats. A study 1  published today gives a rare insight into how genomes change as a population is dying out. Towars the end of the last Ice Age, around11,700 years ago, woolly mammoths ranged through Siberia and the colder stretches of North America. But by about 4,000 years ago, the mainland mammoths had gone and only a small population remained on Wrangel Island off the Siberian coast. In a paper in  PLOS Genetics , biologists Rebekah Rogers and Montgomery Slatkin at the University of California, Berkeley, compare the complete genome of a mainland mammoth ( Mammuthus primigenius ) that lived about 45,000 years ago with that of a Wrangel Island mammoth from just 4,300 years ago, when a mere 300 woolly mammoths were left. The sequences were made available by Love Dal\u00e9n at the Swedish Museum of Natural History in Stockholm. \u201cAs I looked at the sequence data,\u201d says Rogers, \u201cit became very clear that the Wrangel mammoth had an excess of what looked like bad mutations.\u201dSome of these changes are only visible to a geneticist\u2019s eye. Compared with the mainland mammoth, in the Wrangel Island specimen some parts of the genome had been deleted and there were too many instances of sequences called stop codons \u2014 which tell the body when to stop making proteins \u2014 among other changes to the DNA. But some of the changes would also have been visible in the mammoth\u2019s behaviour and appearance.Rogers and Slatkin found that genes related to smell and urinary proteins, which in modern elphants are important for eliciting behaviours like mate choice or signalling social status [chk] were shut down by the mutations. These might be related, the researchers hypothesize, because a duller sense of smell was hitched in a feedback loop to the loss of proteins related to mammoth social status and mate selection. Changes to the Wrangel mammoths\u2019 coats would have been even more obvious. Rogers and Slatkin propose that a mutation in a part of the genome called  FOXQ1  would have given the mammoths a \u2018satin\u2019 coat, marked by fur that is the same colour as normal but is shiny and translucent. \n             Reduced competition \n           What happened on Wrangel wasn\u2019t a matter of inbreeding, Rogers says \u2014 the genetic signal is different. \u201cWhat did happen was that the population was simply small,\u201d she says, and \u201cunder these circumstances any mammoth was better than no mammoth at all\u201d, so natural selection did not operate in the usual way. This allowed unhelpful mutations to rack up, following a previously identified phenomenon called nearly neutral genome evolution. \u201cBad mutations that would normally be weeded out weren\u2019t removed from the population because of reduced competition,\u201d says Rogers. \u201cIsolation and reducing population size have long been recognized as important factors causing endangerment,\u201d says palaeontologist Ross MacPhee of the American Museum of Natural History in New York City, but the recognition of the mammoth\u2019s \u201cgenetic meltdown\u201d is a sign of how far studies of ancient DNA have come, and the work that still lies ahead. The changes on Wrangel Island took place after mammoths had already been wiped out on the mainland. Tracking the downfall of the larger population is an ongoing effort, says MacPhee. \u201cWith additional specimens, drawn from other times and parts of the woolly mammoths\u2019 enormous range, we may get a better picture of the genetic load that this species was labouring under at the end of its tenure.\u201d Still, MacPhee adds, the study \u201cis maybe telling us something very important about what happens in populations already under severe threat because of diminished range and numbers\u201d. \n             Endangered mammals \n           Further genetic research will provide more details. Although he points out that no single animal or genome can tell the entire story, MacPhee notes that \u201cit is not unreasonable to think that maybe human hunting, climate change or any other external factor on the table was insufficient to cause complete losses at the end of the Pleistocene unless there was some powerful cofactor operating within the animals themselves\u201d. As dramatic as genetic meltdown sounds, Rogers says that it\u2019s difficult to tell whether the increase in bad mutations contributed directly to the final extinction of the woolly mammoth. Yet the findings have implications for the survival of the mammoths\u2019 elephant cousins and other endangered mammals. Rogers notes that it\u2019s better to prevent a species from becoming endangered in the first place than to try to recover its genetic diversity after a sharp plummet. \u201cEven though we can improve the number of individuals in endangered populations,\u201d she says, \u201ctheir genomes may still bear the hallmarks of genomic meltdown, which will be difficult to undo.\u201d \n                   Elephant history rewritten by ancient genomes 2016-Sep-16 \n                 \n                   Stem-cell plan aims to bring rhino back from brink of extinction 2016-May-03 \n                 \n                   Fishing for fossils in the North Sea 2015-Sep-23 \n                 \n                   Ancient wolf genome pushes back dawn of the dog 2015-May-21 \n                 \n                   Mammoth genomes provide recipe for creating Arctic elephants 2015-May-01 \n                 \n                   Center for Theoretical Evolutionary Genomics, University of California Berkeley \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21541", "url": "https://www.nature.com/articles/nature.2017.21541", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "February\u2019s sharpest science shots, selected by  Nature \u2019s photo team. \n             Super sack \n           \n             Faking it \n           \n             Lake light \n           \n             In orbit around a distant sun \n           \n             World Press Photo 2017 \n           \n             Dancing octopus \n           \n             Between Blossoms \n           \n             Running fast, going nowhere \n           Animals on treadmills have  a long and distinguished history  in science. Hansj\u00fcrgen Dahmen, Matthias Wittlinger and their colleagues tweaked an existing design that uses a spherical ball suspended in a jet of air to track the path and walking behaviour of an animal atop the globe. In a  paper published last week 3 , the team describes using the treadmill to analyse the behaviour of  Cataglyphis  desert ants. \n             Fashion world abuzz \n           \n                   Swimming starfish, a departing dinosaur and a lot of ice 2017-Jan-27 \n                 \n                   An expensive dodo, an even more expensive telescope, and a \u2018fog rainbow\u2019 2016-Dec-01 \n                 \n                   Martian clouds form, a frozen ship heads home and an orangutan goes climbing 2016-Oct-28 \n                 \n                   2016 in pictures: The best science images of the year \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21571", "url": "https://www.nature.com/articles/nature.2017.21571", "year": 2017, "authors": [{"name": "Inga  Vesper"}], "parsed_as_year": "2006_or_before", "body": "Amendments aim to protect autonomy and the independence of research funders from political interference. UK scientists who had  vigorously protested against a planned shake-up of the way their country\u2019s research is funded  say they\u2019re largely reassured after the government announced amendments to the plans. Science minister Jo Johnson announced a package of changes last week that look likely to smooth the way for the reforms to become law \u2014 although not everyone is satisfied. The proposed reforms would bring the country\u2019s separate research councils together under a  single, central funder , called United Kingdom Research and Innovation (UKRI), and would create a government body to regulate what UK universities teach. The latest changes are designed to soothe fears of excessive government control over what gets funded and taught in British universities, policy experts say. Most unusually, Johnson has suggested writing into law a long-held principle in UK science funding, termed the Haldane principle \u2014 that research-funding decisions should be protected from political interference. \u201cDecisions on individual research proposals are best taken following an evaluation of the quality and likely impact of the proposals (e.g. a peer review process),\u201d the revised law notes. \u201cWe applaud the government\u2019s intention to recognize that those best able to decide what should be funded are not always politicians,\u201d says Naomi Weir, deputy director of the London-based Campaign for Science and Engineering. \u201cIt is such a difficult thing to put in legislation, and it\u2019s good that the government is trying to do that.\u201d Among other amendments, the changes include promises to maintain the autonomy of universities and, according to government documents, \u201cspecify the freedoms of academic staff to question and test received wisdom, and to put forward new ideas and controversial or unpopular opinions\u201d. The changes show that the government has listened to scientists before \u201ctinkering further\u201d with the UK research-funding system, says James Wilsdon, who studies research policy at the University of Sheffield, UK, and who also chairs a lobby group, Campaign for Social Science. \u201cThis is a serious and substantial package of amendments that should go a long way to assuaging any lingering concerns,\u201d he adds. \n             Point of principle \n           Many policy experts note that the government has not been quick to make amendments to its proposals. Criticisms were first heard in October 2016. The draft legislation passed easily through the country\u2019s lower chamber of Parliament, the House of Commons, but has encountered fiercer resistance this year in the upper chamber, the House of Lords, many members of which have a science or education background. \u201cI am pleased with the amendments,\u201d says John Krebs, a member of the House of Lords and a zoologist at the University of Oxford, UK, who last year had warned against adopting the reforms. He says that incorporating the Haldane principle is \u201ca significant and welcome concession\u201d, and that he is reassured by other amendments designed to protect the research councils\u2019 autonomy and to make sure that the allocation of research funding to the various councils remains transparent. But another House of Lords scientist, Martin Rees \u2014 an astrophysicist at the University of Cambridge, UK, who has criticized the idea of creating UKRI \u2014 says he still worries that the new body will have too much power over what gets funded. The law will see its next hearing in the House of Lords on 6 March \u2014 and further changes might be suggested at that stage. After that, any changes have to be agreed again by the House of Commons. But the mood among UK universities is that the reforms will now go through, says Andy Westwood, a policy expert at the University of Wolverhampton, UK. Ironically, says Westwood, the writing into law of the Haldane principle could end up serving the government more than it does researchers, because it hammers out an agreed meaning for what has until now been a vague principle of independence that could be called upon whenever researchers felt threatened by government interference.\u201cHaldane was probably more powerful when it was not enshrined, because academics could always shape it to fit their argument,\u201d Westwood says. \n                   The most powerful man in UK science on his new role 2017-Feb-08 \n                 \n                   The head of Britain\u2019s powerful new funding body deserves a chance 2017-Feb-08 \n                 \n                   Leading scientists clash over sweeping UK research reforms 2016-Oct-13 \n                 \n                   Oppose the UK Higher Education and Research Bill 2016-Oct-04 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21536", "url": "https://www.nature.com/articles/nature.2017.21536", "year": 2017, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "An international group offers guidance to help reduce pain and suffering in animals destined for culling. Every year, trained professionals kill millions of wild animals in the name of conservation, human safety and to protect agriculture and infrastructure. Commercial pest-control operators, government agents and conservationists trap beavers, poison cats,  shoot wolves  and gas rabbits in their warrens with varying levels of ethical oversight. Now, animal-welfare experts and conservationists are making a bid to ensure that these animals get the same consideration given to pets and even to  lab animals that are killed . People use methods such as carbon dioxide gas, drowning and painful poisons, to kill non-native or \u2018pest\u2019 animals, says Sara Dubois, chief scientific officer for the British Columbia Society for the Prevention of Cruelty to Animals in Vancouver, Canada. She considers these methods inhumane. But no one bats an eye, she says, because those animals are considered \u2018bad\u2019. Dubois is the lead author of a set of guidelines published on 9 February in the journal  Conservation Biology 1 . The authors\u00a0\u2014 a group of animal-welfare experts, conservationists and government researchers from around the world\u00a0\u2014 hope the principles will become a model for the ethical review of projects that include killing wild animals. The guidelines are the result of a 2015 workshop in Vancouver. The document incorporates the latest findings in animal-welfare science, which tries to quantify the pain and suffering animals experience in different situations, including when they are killed. It says that control actions should only be undertaken if they support a clear, important and achievable goal. In addition, just because an animal is non-native or considered a \u2018pest\u2019 or \u2018feral\u2019, is, by itself, not reason enough to get rid of them. \n               Not the same \n             The principles are sound, says Bruce Warburton of Landcare Research, a government-owned research company in Lincoln, New Zealand. He was not involved in creating the guidelines, but has studied the animal-welfare impacts of pest control for two decades. Warburton adds that the principles would reduce the number of available animal-control tools and would be likely to incur a cost, at least initially. Matt Heydon, a species-protection expert at Natural England, a government advisory group based in York, UK, says the principles tend to favour animal welfare a little more than do the ones his organization uses, but are broadly similar. \u201cWe approach the issue with a slightly greater emphasis on biodiversity, although animal welfare is also very important to us,\u201d he says. The US Department of Agriculture\u2019s division of Wildlife Services kills millions of animals each year to protect agriculture and address other human\u2013animal conflicts. A spokesperson noted that it already follows \u201ceuthanasia guidelines from the American Veterinary Medical Association, whenever practicable.\u201d And Australia\u2019s Department of the Environment and Energy says it follows similar versions of the principles reported in the new paper. \n               No good option \n             No set of guidelines can provide easy answers to the toughest calls. Brushtail possums (Trichosurus vulpecula) are a native Australian species regarded as an invasive pest in New Zealand. They are often killed using anticoagulants, which are the worst poisons in terms of welfare, says Ngaio Beausoleil, an animal-welfare researcher at Massey University in Palmerston North, New Zealand and an author on the paper. Animals that ingest anticoagulants bleed to death over the course of days or weeks. But the poison\u2019s use is safer for pets and children because it takes so long to kill. If a child accidentally eats bait laced with an anticoagulant, there is still time to get them to a hospital and administer the antidote. With faster-acting and more humane poisons such as cyanide, a family pet that inadvertently ate it could die before anyone could do anything about it. A third option, Beausoleil says, is to re-evaluate the  need for killing the possums at all . Island Conservation, a non-profit organization based in Santa Cruz, California, also uses anticoagulants when eradicating rodents in order to save endangered seabirds and other vulnerable island species, says Gregg Howald, the organization\u2019s North American regional director and an author on the paper. But the organization is actively working on replacing or refining their method for a more humane approach. The new guidelines are a call to innovators around the world, he says. \u201cBring us something that will work; we will be the first to adopt it.\u201d \n                     Behind New Zealand\u2019s wild plan to purge all pests 2017-Jan-11 \n                   \n                     Wolf cull will not save threatened Canadian caribou 2015-Jan-20 \n                   \n                     Best way to kill lab animals sought 2013-Aug-06 \n                   \n                     UK official defends badger cull 2013-Jun-06 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21539", "url": "https://www.nature.com/articles/nature.2017.21539", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "3D reconstructions show a 'crown of thorns' shape stemming from a region linked to consciousness. Like ivy plants that send runners out searching for something to cling to, the brain\u2019s neurons send out shoots that connect with other neurons throughout the organ. A new digital reconstruction method shows three neurons that branch extensively throughout the brain, including one that wraps around its entire outer layer. The finding may help to explain how the brain creates consciousness. Christof Koch, president of the Allen Institute for Brain Science in Seattle, Washington, explained his group\u2019s new technique at a 15 February meeting of the  Brain Research through Advancing Innovative Neurotechnologies initiative  in Bethesda, Maryland. He showed how the team traced three neurons from a small, thin sheet of cells called the claustrum \u2014 an area that Koch believes acts as the seat of consciousness in mice and humans 1 . Tracing all the branches of a neuron using conventional methods is a massive task. Researchers inject individual cells with a dye, slice the brain into thin sections and then trace the dyed neuron\u2019s path by hand. Very few have been able to trace a neuron through the entire organ. This new method is less invasive and scalable, saving time and effort. Koch and his colleagues engineered a line of mice so that a certain drug activated specific genes in claustrum neurons. When the researchers fed the mice a small amount of the drug, only a handful of neurons received enough of it to switch on these genes. That resulted in production of a  green fluorescent protein  that spread throughout the entire neuron. The team then took 10,000 cross-sectional images of the mouse brain and used a computer program to create a 3D reconstruction of just three glowing cells. \n               Well connected \n             The three neurons stretched across both brain hemispheres, and one of the three wrapped around the organ\u2019s circumference like a \u201ccrown of thorns\u201d, Koch says. He has never seen neurons extend so far across brain regions. The mouse body contains other long neurons, such as a nerve projection in the leg and neurons from the brainstem that thread through the brain to release signalling molecules. But these claustrum neurons seem to connect to most or all of the outer parts of the brain that take in sensory information and drive behaviour. Koch sees this as evidence that the claustrum could be coordinating inputs and outputs across the brain to create consciousness. Brain scans have shown that the human claustrum is one of the most densely connected areas of the brain 2 , but those images do not show the path of individual neurons. The claustrum is a good brain region in which to test the new technique because it has been extensively studied in mice and consists of only a few cell types, says James Eberwine, a pharmacologist at the University of Pennsylvania in Philadelphia.  \n               Taking stock \n             \u201cIt\u2019s quite admirable,\u201d Rafael Yuste, a neurobiologist at Columbia University in New York City, says of the method. He doesn\u2019t think that the existence of neurons encircling the brain definitively proves that the claustrum is involved in consciousness. But he says that the technique will be helpful for census efforts that identify different cell types in the brain, which many think will be crucial for understanding how the organ functions. \u201cIt\u2019s like trying to decipher language if we don't understand what the alphabet is,\u201d he says. Yuste and Eberwine would like to see 3D reconstructions of individual neurons compared to analyses of the genes expressed in those neurons. This may offer clues as to the type and function of each cell. Koch  plans to continue mapping neurons  emanating from the claustrum, although the technique is too expensive to be used to reconstruct all of these neurons on a large scale. He would like to know whether all the region\u2019s neurons extend throughout the brain, or whether each neuron is unique, projecting to a slightly different area.\n \n                     Crumb of mouse brain reconstructed in full detail 2015-Jul-30 \n                   \n                     Neurotechnology: BRAIN storm 2013-Nov-06 \n                   \n                     Whole human brain mapped in 3D 2013-Jun-20 \n                   \n                     Allen Institute aims to crack neural code 2011-Mar-29 \n                   \n                     NIH BRAIN Initiative Multi-Council Working Group Meeting \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21576", "url": "https://www.nature.com/articles/nature.2017.21576", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "People living in the area thousands of years ago may have changed the forest around them in ways that are still visible today. The Amazon has long been held up as an example of untamed wilderness. But  people have lived in the world\u2019s largest rainforest for thousands of years , hunting, gathering and farming 1 . Researchers have debated how much of an  influence human activities have had on the Amazon  for years. And now, a study describes the extent to which ancient peoples changed the distribution of trees in the forest around them. The paper 2 , published on 2 March in  Science , finds that many domesticated trees and palms are five times more likely to be represented in the Amazon than are non-domesticated ones. The researchers also found that the domesticated-plant distributions throughout the rainforest closely track the locations of pre-Columbian settlements. They suggest that this pattern could help other scientists to discover as yet unknown ancient settlements in the Amazon. \u201cIt\u2019s not enough to study the environmental conditions that structure these communities of trees and palms,\u201d says Carolina Levis, a palaeoecologist at Wageningen University in the Netherlands and the lead author of the study. \u201cWe need to ask \u2018what are the human influences in these communities?\u2019\u201d \n             A cornucopia \n           Levis and her team used data from the Amazon Tree Diversity Network \u2014 a group of researchers who share information on palms and trees in the Amazon \u2014 to estimate biodiversity in the rainforest. So far, scientists have used the network to identify 4,962 palm and tree species in the Amazon. Of the 85 domesticated species, Levis discovered that about 20 of them, such as Brazil nuts ( Bertholletia excelsa ) and cocoa plants ( Theobroma cacao ), were over-represented. The researchers wanted to know whether this was because of human influence or the environment. So they compared the distribution of domesticated species to more than 3,000 known pre-Columbian archaeological sites and likely settlement areas, including near the banks of rivers. Domesticated species were much more likely to thrive where ancient people had lived than were non-domesticated species. The associations were strongest in the southwestern and eastern Amazon, which hosted large pre-Columbian populations. All told, about 20% of the species variation in the Amazon seemed to be driven by human influences, whereas 30% of the variation seemed to be due to environmental factors such as soil composition. \n             Old versus new \n           This doesn\u2019t necessarily mean that ancient human actions were solely responsible for the distribution of domesticated plants, cautions Crystal McMichael, a palaeoecologist at the University of Amsterdam. \u201cIt\u2019s quite well known that ancient people and modern people both settle in similar areas.\u201d So it\u2019s possible that more modern groups influenced the ecosystems we see today as much as ancient ones, she adds. Human actions could also have created conditions that favoured domesticated plants over their wild brethren, says Mark Bush, an ecologist at the Florida Institute of Technology in Melbourne. And the domesticated species could re-colonize disturbed areas more easily than non-domesticated ones without any help from people. When people abandoned Mayan sites in Central America,  Brosimum  trees re-colonized the area. But for years, researchers thought the Mayans had planted them deliberately. Levis and her team could be observing a similar phenomenon, Bush says. Levis acknowledges that their study didn\u2019t separate out the effects of modern peoples from their ancestors. But Bush and McMichael agree that irrespective of the cause, the distribution of plants in the Amazon follows modern and ancient human settlements. Levis and McMichael are in the process of developing a model to use that pattern to find areas where people may have lived thousands of years ago. Ultimately, says Levis, this research shows that the Amazon is not an untamed jungle, but an ecosystem that humans have been a part of for ages, and their actions have left their mark on the land. \u00a0\u201cPeople want to preserve pristine forests for conservation and to preserve life,\u201d she says. \u201cBut if this is true, if people enriched the forests by domesticating palms, that is also a cultural artefact.\u201d The trees that live in these populated areas may be relics of a vibrant past. \n                   Deforestation spikes in Brazilian Amazon 2016-Nov-30 \n                 \n                   Amazon ecology: Footprints in the forest 2013-Oct-09 \n                 \n                   Amazon plant discovery could yield green cash crop 2013-May-02 \n                 \n                   Forest ecology: Splinters of the Amazon 2013-Apr-17 \n                 \n                   Amazonia 1492: pristine forest or cultural parkland? 2003-Sep-19 \n                 \n                   Amazon Tree Diversity Network \n                 Reprints and Permissions"},
{"file_id": "543017a", "url": "https://www.nature.com/articles/543017a", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Lawsuits in India and Argentina seek to reduce drug costs by allowing generic versions of antiviral treatments. The liver disease hepatitis C is the new battleground for lawsuits intended to slash the cost of life-saving medicines. In February alone, five suits were filed in India and Argentina claiming that the latest class of antiviral drugs does not warrant the 20-year patent monopoly that manufacturers have sought in those countries. In the 2000s, successful challenges to patents on HIV drugs gave poor nations access to high-quality \u2018generic\u2019 copies of the medications at rock-bottom prices. Now, buoyed by that success, activists are applying the same strategy to a fresh wave of hepatitis\u00a0C drugs. They note that the standard 12-week course of treatment costs more than the average annual salary for millions of people in middle-income countries. Public-health experts say that expanding access to the drugs would have immediate benefits. Roughly 177.5 million adults worldwide are infected with the hepatitis C virus, which can cause liver cancer and cirrhosis if left untreated \u2014 but the latest antiviral medications have revolutionized care. The first to reach the market was sofosbuvir, sold under the name Sovaldi by Gilead Sciences of Foster City, California; clinical trials of the drug in combination with other medications have shown a cure rate of 95% or more. \u201cIf these medicines were made widely available, you could make a plan to eliminate this disease,\u201d says Brook Baker, a law specialist at Northeastern University in Boston, Massachusetts. As the world\u2019s main supplier of generic drugs, India is at the centre of the current patent fight. Patient advocates celebrated when the country\u2019s patent office rejected Gilead\u2019s application for a basic patent on sofosbuvir in January 2015, on the grounds that it was not scientifically inventive enough to warrant exclusivity, despite its clear medical advantages. But an Indian court overturned the decision last May \u2014 and that verdict in turn is now being contested. Four of the lawsuits filed in February target other Indian patents on sofosbuvir and two related drugs, Gilead\u2019s velpatasvir (sold in combination with sofosbuvir under the name Epclusa) and Daklinza (daclatasvir) from Bristol-Myers Squibb in New York City. The fifth challenges Gilead\u2019s application to patent sofosbuvir in Argentina. \u201cThe science behind sofosbuvir doesn\u2019t merit these patents,\u201d says Tahir Amin, director of the Initiative for Medicines, Access and Knowledge in New York City. The activist group is involved in a dozen ongoing lawsuits related to patents for hepatitis\u00a0C drugs \u2014 including the cases in India and Argentina, and others in Brazil, the European Union, Egypt and Ukraine. Some of the suits argue that sofosbuvir, velpatasvir and daclatasvir are not sufficiently inventive to warrant a patent. Others challenge Gilead\u2019s attempts to obtain additional patents on sofosbuvir by modifying it slightly, to extend the company\u2019s intellectual-property rights \u2014 a practice called evergreening. \u201cThis battle is about trying to ensure that Gilead has the shortest possible monopoly,\u201d says Leena Menghaney, who runs a drug-access campaign in South Asia for the charity M\u00e9decins Sans Fronti\u00e8res, which is supporting the lawsuits. Gilead notes that it has taken steps to reduce the cost of its antiviral medications for hepatitis\u00a0C \u2014 offering tiered pricing for sofosbuvir and other drugs, on the basis of factors such as a nation\u2019s economic status and the volume of medicine that it requires. The list price for a 12-week course of sofosbuvir is US$84,000 in the United States, $50,000 in Turkey and Canada, about $6,000 in Brazil and just $900 in Egypt. Gilead has also licensed 11\u00a0manufacturers in India to produce cheaper generic versions of its hepatitis C drugs for sale in 101\u00a0developing countries. The generic medications retail for $300\u2013$900 per treatment course in countries where they are permitted; in return, Gilead receives a 7% royalty payment to keep its access-to-medicines programme running. This system draws on lessons that Gilead learnt during lawsuits and protests over access to HIV medications in the early 2000s, says Clifford Samuel, Gilead\u2019s senior vice-president of access operations and emerging markets. \u201cWe got a tremendous amount of criticism in the early days of our HIV programme, and it refined us,\u201d he says. But that does not appease Amin, who says that Gilead\u2019s deals with generic-drug manufacturers do not reduce the cost of its hepatitis\u00a0C medications in middle-income countries. One analysis published last year found that sofosbuvir and related drugs are too pricey for those nations ( S.\u00a0Iyengar  et\u00a0al. PLoS Med.    13,  e1002032; 2016 ). Using these drugs to treat every person infected with hepatitis\u00a0C in Poland would cost 1.6 times the country\u2019s annual expenditure on medicines for all conditions. The price of one course of treatment is equal to about six years of earnings for the average Pole. Gilead intends to protect its patents in high- and middle-income countries, while working to improve access to drugs through discounts and tiered pricing. \u201cWe need revenue to put back into the development of drugs for other diseases,\u201d Samuel says. The company has already recouped its original investment in sofosbuvir. It acquired the drug in 2011 when it bought Pharmasset, a biotechnology company in Princeton, New Jersey, for $11.2 billion. Since sofosbuvir hit the market in 2014, the drug and two similar medications have earned Gilead $46 billion. Menghaney expects the first hearings in the new wave of patent lawsuits to come in six months to a year. But she\u2019s already looking to new frontiers. \u201cI hope these battles in developing countries lead people to challenge weak patents and evergreening patents in the United States,\u201d she says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @amymaxmen \n               \n                     America's drug problem 2016-Nov-14 \n                   \n                     What new GSK patent policy means for the developing world 2016-Apr-05 \n                   \n                     Activists sound alarm on tiered drug prices 2014-May-20 \n                   \n                     Hepatitis C drugs not reaching poor 2014-Apr-15 \n                   \n                     United States to approve potent oral drugs for hepatitis C 2013-Oct-30 \n                   \n                     Indian court rejects Novartis patent 2013-Apr-01 \n                   \n                     India says no to HIV drug patents 2009-Sep-03 \n                   \n                     Nature Outlook : Hepatitis C \n                   \n                     Initiative for Medicines, Access & Knowledge \n                   \n                     Doctors without Borders Access Campaign \n                   \n                     Gilead\u2019s programme on viral hepatitis \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21527", "url": "https://www.nature.com/articles/nature.2017.21527", "year": 2017, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Authorities and researchers ramp up their efforts to tackle the invasive fall armyworm. African nations are gearing up to battle an invasive crop pest called the fall armyworm, which has been rapidly spreading across the continent since its arrival there just over a year ago. The caterpillar has wreaked destruction on staple crops including maize (corn), millet and sorghum. Experts warn that Europe and Asia could be next. Officials gathered for an emergency meeting \u2014 organized by the regional Africa office of the Food and Agriculture Organization (FAO) of the United Nations \u2014 in Harare, Zimbabwe, earlier this month to coordinate their response. Sixteen countries agreed to urgent plans to boost the region\u2019s capacity to manage crop pests. \u201cThe meeting in Harare was basically aimed largely at strengthening preparedness for the countries,\u201d says Joyce Mulila-Mitti, the FAO\u2019s crops officer for southern Africa. Affected countries are assessing their preparedness for other new invasive pests. Researchers are also launching studies to understand the behaviour of the pest in new environments, as well as its susceptibility to insecticides. The fall armyworm ( Spodoptera frugiperda)  originates in Central and South America. It was first identified in West Africa in January 2016, and has since moved to at least 12 countries on the continent, reaching 7 of them in the past 2 months alone. The pest is the larval form of the fall armyworm moth, and has a voracious and indiscriminate appetite \u2014 munching its way through more than 100 different plants, including leafy crops. At least 290,000 hectares of cropland across 4 countries have already been destroyed, officials reported at the Harare meeting. They cautioned that this was an underestimate and the exact figure is probably much higher. \n               Changing ecology \n             The fall armyworm is a serious problem in the countries where it is endemic. The FAO estimates that Brazil alone spends US$600 million each year to control infestations. Africa has its own species of armyworm,  Spodoptera exempta , which also devours the leaves of maize plants. But the invasive fall armyworm is especially worrisome because it also eats a plant's reproductive parts, eating through the maize cob itself, resulting in even more crop loss. African scientists are now mobilizing their efforts to study fall armyworm as it moves across different regions. \u201cAlthough the basic biology of the insect remains similar, confrontation of the pest by different environmental conditions and host plant ranges may cause the pest to react differently,\u201d says Johnnie van den Berg, a zoologist at North-West University in Potchefstroom, South Africa. Van den Berg and two colleagues will head research on the ecology of the pest in South Africa. This will include studies into the efficacy and management of the fall armyworm on a form of genetically modified (GM) maize called  Bt  maize. This GM crop is widely grown in the country, and the hope is that it may be more resistant to the pest than conventional maize \u2014 as experience in Brazil  has demonstrated . The ecology study will examine the fall armyworm\u2019s behaviours on locally grown plants other than maize, and investigate how it fares in South Africa\u2019s dramatically varying climate zones. The researchers will also study the efficacy of commercially available insecticides that have had to be rushed through an ongoing emergency-registration process to tackle the fall armyworm. \n               Probable spread \n             \u201cIt is likely that the fall armyworm will spread from its current distribution throughout sub-Saharan Africa fairly rapidly,\u201d warns Ken Wilson, an ecologist at Lancaster University, UK. \u201cFrom there, it is but a hop, skip and jump to southern Europe.\u201d Because the caterpillar can live on such a wide variety of plants, it is likely to persist year-round in southern Europe. So it is \u201cnot unreasonable\u201d to expect it to migrate through to Eastern Europe and Asia or to be transported there by agricultural export, adds Wilson, who will be working with the University of Zambia in Lusaka to assess the damage caused by the fall armyworm. Although no one knows how the insect found its way into Africa, increased trade and climate change are the likely culprits, say experts. The drought linked to the El Ni\u00f1o weather system of 2014\u201316, followed by the current high rainfall associated with the related La Ni\u00f1a system, created the \u201cperfect conditions\u201d for armyworm outbreaks in Africa, says Wilson. \u201cWith global climate change, we can probably expect more of these fluctuations in temperature and rainfall,\u201d he says. \u201cIn addition, with increased global trade and travel, we can expect greater movement of pests within and between continents.\u201d This could be exacerbated by food shortages that stimulate great movement of agricultural produce. Mulila-Mitti notes that the FAO has observed a rise in the spread of invasive species, particularly in sub-Saharan Africa. Last year, a team led by ecologist Dean Paini of Australia\u2019s Commonwealth Scientific and Industrial Research Organisation in Canberra analysed 1,300 invasive species, along with countries\u2019 main crops and international trade routes.  The study 1  found that sub-Saharan African countries were the most vulnerable to invasive species. \n                     No saturation in the accumulation of alien species worldwide 2017-Feb-15 \n                   \n                     Rapid evolution of dispersal ability makes biological invasions faster and more variable 2017-Jan-27 \n                   \n                     Massive yet grossly underestimated global costs of invasive insects 2016-Oct-04 \n                   \n                     Global threats from invasive alien species in the twenty-first century and national response capacities 2016-Aug-23 \n                   \n                     Crop pests and pathogens move polewards in a warming world 2013-Sep-01 \n                   \n                     FAO Regional Office for Africa \n                   \n                     Ken Wilson \n                   \n                     Johnnie van den Berg \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21586", "url": "https://www.nature.com/articles/nature.2017.21586", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Ride-sharing algorithm finds untapped potential to cut costs and reduce emissions in cities around the world. It makes sense that sharing a taxicab would be practical in places such as Manhattan in New York, where lots of people are always looking for a ride. But the same approach might also work in vastly different cities across the world, potentially lowering both transport costs and emissions, suggests a network-theory study 1 . Ride-hailing companies such as Uber and Lyft give customers the option to share journeys with others who are heading to similar destinations. Traditional taxi firms could in principle do the same, if they were linked up through the right technology \u2014 algorithms that match customers with other nearby passengers. Researchers led by Carlo Ratti, an architect and engineer at the Massachusetts Institute of Technology (MIT) in Cambridge, crunched taxi-ride data from Manhattan, Singapore, Vienna and San Francisco in California. They found that although these cities have differing layouts, all four have vast untapped potential for mass ride sharing 1 . \n             Stranger danger \n           Ratti and his team built an abstract network of trips, which were connected to each other if they were potentially shareable - that is, without causing delays to either party of more than 5 minutes. They then calculated what would happen to the number of shareable rides (as a fraction of the total) if any of those cities were to experience a drop in taxi use. This simulated what might happen in cities with a similar layout to one of the four examined with actual data, but where either the average demand for mobility is lower, or fewer cars are available, or both. They found that shareability follows a \u2018universal\u2019 law, with different cities showing the same curve when the feasibility of cab-sharing is plotted against demand. \u201cAlthough these four cities superficially look different, their shareability curves look the same,\u201d says Steven Strogatz, a mathematician at Cornell University in Ithaca, New York, who is a co-author on the latest study. \u201cIt\u2019s amazing to me that it works as well as it does.\u201d Even with a small drop in demand, the shareability of rides remains high in all four cities. This suggests that mass adoption of ride sharing should be possible not only in the four locations in the study, but in lots of other cities across the world, Strogatz says. The researchers published the results on 6 March in  Scientific Reports 1 . It's an extension of work that Ratti and his collaborators published in 2014. Using data on taxi rides from Manhattan, where all yellow cabs are tracked using the Global Positioning System, they calculated that most rides that start and end in Manhattan could have picked up more than one customer 2 . Crucially, the researchers found the 5-minute threshold for what they call a \u2018shareable\u2019 ride. And ride sharing could also slash the total number of miles driven each year by Manhattan's fleet of taxis by 40% \u2014 so cutting emissions, too. Lu\u00eds Bettencourt, a physicist who studies complex systems at the Santa Fe Institute in New Mexico, says that the study is interesting, although the mathematical law the authors found might not be quite as universal as they believe. Bettencourt adds that he would have liked to see a model that includes more social and economic factors in shareability, such as safety (whether riding with a stranger might be perceived as dangerous) and pricing. \u201cFor example, if the price differential between a non-shared and a shared ride is small, I may prefer not to share,\u201d Bettencourt says. \n             Virtuous cycle \n           Ratti is the head of the Senseable City Lab at MIT, an interdisciplinary research centre that now has a collaboration with Uber. As a follow-up to the latest study (which was not funded by Uber), he says that his team is now analysing data the company collected from cities around the world to examine shareability. Future studies might also take into account a possible virtuous cycle that could kick in once there is mass adoption of ride sharing, Ratti says. \u201cIf people share more rides, traffic will be reduced because vehicle occupancy will increase. With less traffic, travel time will decrease, increasing the potential for further ride sharing.\u201d Strogatz, however, worries about possible unintended consequences, such as lost jobs for taxi drivers or cuts in bus services. Already, some US cities are reportedly considering  cuts to the availability of public transportation , under the assumption that stranded customers can instead use a ride-hailing company. He says: \u201cSometimes I worry, are we doing the devil\u2019s work here?\u201d Reprints and Permissions"},
{"file_id": "nature.2017.21581", "url": "https://www.nature.com/articles/nature.2017.21581", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "David Latchman says he did not have direct involvement in images at the heart of criticized papers from his group. A leading UK academic has spoken publicly for the first time about a byzantine saga involving allegations of research misconduct in papers that stemmed from his research group at University College London (UCL). Geneticist David Latchman has told  Nature  that although he did not scrutinize some of the papers sufficiently to detect errors, he also did not produce or directly supervise any of the images at the heart of the allegations.\u00a0 \u201cIn my view, the investigation should focus on those actually involved in preparing the questionable figures and those directly involved in supervising their production,\u201d he says. In some cases, he says, he remained a co-author on work that began in his UCL laboratory even after he no longer had a substantial role. The allegations, made in 2013, have prompted two inquiries by UCL, one of which is ongoing. So far, researchers have retracted two of the papers and corrected five more. The events have attracted attention largely because of Latchman\u2019s prominence: he is the chief academic and administrative officer at Birkbeck, University of London, and was formerly dean of UCL\u2019s Institute of Child Health, where he still holds a part-time research role. \n             Mystery tipster \n           The affair became public in January 2015, after researchers retracted the first of the papers and corrected two more. \u2018Clare Francis\u2019,  a well-known pseudonymous tipster , had made allegations of misconduct concerning papers from Latchman\u2019s group. In February 2015, a second paper was retracted. The retraction notes issues with the \u201cmisuse and re-use of western blot bands\u201d \u2014 images showing the results of a standard technique used to detect proteins \u2014 and says that in some cases the same image had been used to show different things. It also says that corresponding author Anastasis Stephanou, who used to work in Latchman\u2019s lab, \u201cregrets the inappropriate figure manipulations of which the co-authors were completely unaware\u201d. UCL had convened a panel of scientists to investigate the papers. The panel produced a report, which UCL declined to release but which has been leaked to  Nature  anonymously. The report states that a 'screening panel' looked into 28 papers on which Latchman was a co-author, 14 of which were co-authored by Stephanou. The panel found evidence of misconduct in eight of those papers and recommended they be retracted. Of those eight, two have been retracted and five corrected; three of the corrections came last week. The papers were published between 2001 and 2010 and are on a range of subjects, including cardiology and human genetics. \n             \u2018No case to answer\u2019 \n           In September 2015, the university released a statement saying: \u201cUCL confirms that the conclusion of its investigation is that Professor Latchman has no case to answer in relation to research misconduct. Professor Latchman has accepted that there were procedural matters in his lab that required attention.\u201d Stephanou\u2019s employment at UCL ended that month, and he is now at the European University Cyprus in Nicosia. The move was unrelated to the inquiries, he says. But just a month later, Latchman says, UCL told him that it had started a second inquiry, in response to more Clare Francis allegations. The university has confirmed that this inquiry is ongoing. \u201cAll proceedings are conducted under the presumption of innocence,\u201d it says. \u201cIn all cases, I did not produce any of the figures in the papers criticized or directly supervise their production,\u201d Latchman says. \u201cI greatly regret that in common with the other authors and the reviewers, I did not detect the errors in these papers,\u201d he adds. Latchman notes that two papers were retracted. On why some papers were corrected, rather than retracted as recommended by the university screening panel, Latchman says that he requested retractions in three of these cases. In two of those, co-authors requested corrections instead; in another, the experiment in question was repeated so that \u201ca correction was appropriate\u201d, says Latchman. For the other two corrected papers, he says that the journals said corrections were appropriate and he agreed. For the final paper, which has been neither retracted nor corrected, Latchman says a retraction has been requested. Stephanou says he did not prepare any of the images that the panel flagged as problematic . He stands by the decision to correct \u2014 rather than retract \u2014 some papers, because in these cases the \u201cfigures didn\u2019t really affect the overall conclusions\u201d. He acknowledges that there were \u201cgenuine mistakes\u201d. In the cases where he was a corresponding author, \u201cI should have been more careful\u201d in looking at some of the figures, he says. \n             New misconduct procedures \n           In its report, the screening panel recommended that the matter should skip formal investigations and proceed \u201cdirectly to UCL\u2019s relevant disciplinary process or other internal process\u201d. UCL declined to comment on the report, or why its recommendations were not taken forward. Commenting would be \u201cunfair and prejudicial to the conduct of the current investigation\u201d, it says. The second inquiry has progressed to a formal \u2018investigation panel\u2019, says UCL, a step that the first review did not reach. \u201cThe Investigation Panel will ensure the full and fair exploration of the allegations in the context of research.\" Latchman urges UCL to move \u201cspeedily\u201d to complete its investigations. \u201cIt is now over three years since UCL was first contacted about these allegations,\u201d he says. In February 2016, UCL established a new procedure for dealing with misconduct allegations \u2014 after a review looking at ways to clarify the role of screening panels and reduce the time taken by that stage of investigations. UCL says these changes in part reflect lessons learnt from dealing with the allegations against Latchman: \u201cThe updates are aimed at expediting the screening process, setting out a clearer process for handling multiple respondents and clarifying the role of the screening panel.\u201d \n                   The image detective who roots out manuscript flaws 2015-Jun-12 \n                 \n                   Science journals crack down on image manipulation 2009-Oct-09 \n                 Reprints and Permissions"},
{"file_id": "543016a", "url": "https://www.nature.com/articles/543016a", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Signals have progressed from astronomical peculiarity to mainstream research area. One of the most perplexing phenomena in astronomy has come of age. The fleeting blasts of energetic cosmic radiation of unknown cause, now known as  fast radio bursts  (FRBs), were first detected a decade ago. At the time, many astronomers dismissed the seemingly random blasts as little more than glitches. And although key facts, such as what causes them, are still largely a mystery, FRBs are now accepted as a genuine class of celestial signal and have spawned a field of their own. The passage was marked this month by the first major meeting on FRBs, held in Aspen, Colorado, on 12\u201317\u00a0February. As well as celebrating a fleet of searches for the signals, the meeting\u2019s 80 delegates grappled with how best to design those hunts and pin down the signals\u2019 origins and precise distances. The trajectory mirrors that of astronomers 20\u00a0years ago when they were getting to grips with \u03b3-ray bursts, which are now a staple of astronomical observation, says Bing Zhang, a theoretical astrophysicist at the University of Nevada, Las Vegas. \u201cThe meeting has really focused the field a lot,\u201d says Sarah Burke Spolaor, an astronomer at West Virginia University in Morgantown. Debates continue over how to root out detection bias and coordinate observations and on what can be learnt by studying patterns in the existing FRB population. The first FRB was co-discovered 1  in 2007 by astronomer Duncan Lorimer at West Virginia University. He found in archived pulsar data a\u00a05-millisecond radio frequency burst that was so bright it couldn\u2019t be ignored. Astronomers have since seen 25 FRBs. All are brief radio signals, lasting no more than a few thousandths of a second. They seem to come from sources across the sky and beyond our Galaxy. Some last longer than others, and the light from a few is polarized. A discovery last year caused further excitement. Astronomers reported 2  that  they had found a repeating FRB \u00a0\u2014 a surprise, because all the other signals had been one-off blips. And in January this year, its  origin was identified 3 : a faint, distant dwarf galaxy around 780\u00a0megaparsecs (2.5\u00a0billion light years) away, in a star-forming region that also hums with a steady radio source. The repeater has gone some way to focusing the FRB field, says Edo Berger, an astronomer at Harvard University in Cambridge, Massachusetts. Astronomers have now observed nearly 200 signals from it; details of 20 have been published. It bolsters the hypothesis that the signals are extragalactic, something most FRB researchers now agree on, and its location is reshaping theories about possible causes. Dwarf galaxies host fewer stars than most, so  tracking an FRB to one  is surprising, says Berger. He thinks that the unusual environment is more than coincidence, and that FRBs may come from super-powerful magnetars \u2014 dense, magnetic stars thought to form after an abnormally massive explosion, such as an extremely energetic supernova. Studies suggest that such events seem to be more common in dim dwarf galaxies, he says. Others think the bursts might come from active galactic nuclei, regions at the centres of some galaxies that are thought to host supermassive black holes. Streams of plasma from these could comb nearby pulsars to produce FRBs, says Zhang, which could also explain a recent, although tentative, observation of a  faint \u03b3-ray burst  coinciding with an FRB. At the meeting, some astronomers proposed reversing the search strategy, and looking for FRBs in similarly strange galaxies, as well as trying to locate the origin of single bursts when they occur. And heated debate arose over whether all FRBs are likely to come from the same kind of source as the repeater, and so whether astronomers might detect repeated signals from all FRBs if they look for long enough. \u201cThe answer was definitely maybe,\u201d says Burke Spolaor. But there could be different kinds of sources, leaving open the question of how much one repeater can teach about FRBs in general, she adds. \n               Cutting bias \n             A major issue is how to avoid bias. The fact that they were discovered by researchers looking for pulsars\u00a0\u2014 small, dense, rotating stars \u2014 could bias the generation of theories about FRBs: astronomers might be drawn to models involving objects similar to pulsars. Detection bias is also an issue, in part because many FRB searches are piggy-backed onto those that are optimized for finding sources within the Milky Way that repeat regularly, rather than sporadic extragalactic events. The more astronomers look, the more they find FRBs in unexpected locations and with unusual features. To ensure that astronomers are seeing a representative sample, they need to look for signals across a broader range of frequencies, says Burke Spolaor. They should also pay more attention to the polarization of FRB light, she adds, which can provide clues about the environment of the source. About 30 telescopes are looking for FRBs, and dedicated searches are increasing. The conference buzzed with excitement about the  Canadian Hydrogen Intensity Mapping Experiment (CHIME) , a radio telescope in Canada that should start hunting for FRBs later this year and could see as many as a dozen a day. But observations need to be better coordinated, says Berger. Delegates planned efforts to automatically release FRB results in real time for follow-up by other telescopes, as is already done for other kinds of fleeting astronomical signal. Although FRBs remain a mystery, the field has surged forward since Lorimer  identified the first burst . The fact that the community now agrees, for instance, that the bursts are extragalactic is a big step forward. Lorimer\u2019s wife, West Virginia University astrophysicist Maura McLaughlin, initially doubted they were even extraterrestrial, Lorimer told the meeting. \u201cThe community was quite sharply divided about it, even in our own household. We\u2019ve come a long way since then.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Long-sought signal deepens mystery of fast radio bursts 2016-Nov-17 \n                   \n                     Why ultra-powerful radio bursts are the most perplexing mystery in astronomy 2016-Jun-28 \n                   \n                     Fresh confusion over origins of enigmatic radio-wave blasts 2016-Mar-02 \n                   \n                     Microwave oven blamed for radio-telescope signals 2015-May-08 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21507", "url": "https://www.nature.com/articles/nature.2017.21507", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Rift through Larsen C ice shelf has grown to 175 kilometres, and collapse of nearby ice shelves could offer a glimpse of its future. A massive crack in Antarctica\u2019s fourth-biggest ice shelf has surged forward by at least 10 kilometres since early January. Scientists who have been monitoring the 175-kilometre rift in the Larsen C ice shelf say that it could reach the ocean within weeks or months, releasing an iceberg twice the size of Luxembourg into the Weddell Sea. The plight of Larsen C is another sign that  global warming is destabilizing ice  along the eastern Antarctic Peninsula and raising sea levels. But scientists' studies of the rift also illuminate how far glaciology has come since the collapse of the ice shelf\u2019s northern siblings: Larsen A in 1995 and Larsen B in 2002, which occupied separate embayments further out along the peninsula. \u201c Larsen B was a turning point  in our understanding,\u201d says Ala Khazendar, a geophysicist at NASA\u2019s Jet Propulsion Laboratory in Pasadena, California. \u201cIt was the biggest collapse of its kind up to that point, and it served to demonstrate how ice shelves regulate the movement of ice from the interior of the ice sheet to the ocean.\u201d For decades beforehand, researchers had debated the extent to which ice shelves buttress glaciers on land \u2014 acting like corks that slow the land ice\u2019s inevitable march to the sea. The late Bob Thomas, a NASA glaciologist who helped to popularize the idea, went so far as to uncork a bottle of wine and pour some out to demonstrate the effect during his talks. Satellite data collected after Larsen B collapsed largely settled the debate 1 , 2 . The speed at which glaciers connected to Larsen A and B flowed to the sea increased \u2014 by up to a factor of eight \u2014 after those ice shelves disintegrated, says Eric Rignot, a glaciologist at the University of California, Irvine. \u201cSome of [the glaciers] have slowed down a little bit, but they are still flowing five times faster than before,\u201d he notes. Khazendar and his colleagues have also found that two glaciers flowing into Larsen B started to accelerate before its collapse, as the ice shelf weakened.  Since Larsen B\u2019s collapse, ice-sheet modellers have tweaked their simulations to better reflect the forces driving glacial flow and to help quantify this corking effect \u2014 bolstering confidence that limited observations from the Larsen ice shelves could be applied more broadly. Researchers are now looking back to the history of Larsen A and B (see 'Cracking up') to understand what the future might hold for Larsen C, which covers 50,000 square kilometres with ice up to 350 metres thick. Many fear that the expanding crack is a sign that Larsen C has begun a long decline that will inevitably end in its total collapse. How soon that could come after the iceberg breaks off is an open question. \n               Shock waves \n             The effects of a collapse could be felt far beyond Antarctica. The glaciers that flow into Larsen C contain enough water to raise the global sea level by about a centimetre \u2014 and they are likely to flow faster to the ocean in the absence of an ice shelf. In comparison, global sea levels are rising by about 3 millimetres a year, and a recent study estimated that one-third of that comes from ice loss in Antarctica and Greenland 3 . Satellite images show that Larsen C has been receding since the 1980s, and radar measurements suggest that its ice is also thinning, Rignot says. Scientists have also seen meltwater ponds forming on the ice shelf\u2019s surface\u00a0 4 ; the same sort of ponds  probably hastened the disintegration of Larsen B  by carving holes in the ice and expanding cracks. The ice sheet is protected, to some degree, from rapid collapse by favourable seafloor geometry. A pair of underwater ridges that surround Larsen C create friction that slows the flow of ice to the ocean. Still, the parallels with the decline of Larsen B are striking, says Adrian Luckman, a glaciologist at Swansea University, UK, who heads a team that has monitored the Larsen C ice crack for several years. Larsen B experienced a major iceberg-calving event in 1995, followed by gradual retreat and then complete collapse seven years later. Larsen C may follow a similar pattern, he says, although it\u2019s not clear how soon collapse might follow the imminent calving event. For now, researchers are anxiously watching the expanding ice rift. Chris Borstad, a geophysicist at the University Centre in Svalbard, Norway, is particularly interested in Larsen C\u2019s \u2018suture zones\u2019 \u2014 areas where glacial ice flows off land and merges. The ice is softer in these areas, which are often held together by ice that freezes from below. Dozens of significant cracks run into one of these zones on Larsen C, and then stop, he says. The current crack was among them, but it somehow broke through in 2014 and has continued to expand ever since. It's not clear why the crack made it through the soft ice, and whether other rifts will follow suit in the coming years. \u201cWe don\u2019t know why, but there\u2019s something very effective about these boundaries for stopping cracks, and that may be the key,\u201d Borstad says. \u201cTo answer that question, we really need to get out there into the field.\u201d \n                     2017 sneak peek: What the new year holds for science 2016-Dec-22 \n                   \n                     Satellite system tracks glaciers' flow in real time 2016-Dec-16 \n                   \n                     Antarctic model raises prospect of unstoppable ice collapse 2016-Mar-30 \n                   \n                     Chain reaction shattered huge Antarctica ice shelf 2013-Aug-09 \n                   \n                     Glaciers are flowing faster 2004-Sep-23 \n                   \n                     Project MIDAS \n                   \n                     National Snow and Ice Data Center \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21614", "url": "https://www.nature.com/articles/nature.2017.21614", "year": 2017, "authors": [{"name": "Dalmeet Singh Chawla"}], "parsed_as_year": "2006_or_before", "body": "Campaign on Wikipedia seeks to track down photos of female scientists and those from minority ethnic groups. Hilda Bastian was organizing a Wikipedia edit-a-thon for the US National Institutes of Health in 2015 to highlight the work of women scientists when she realized how difficult it was to find photos of them. \u201cI scanned through thousands of digitized photos in image galleries, went through Wikipedia pages, and looked for obituaries in journals. It had a big impact on me,\u201d says Bastian, who is based in Washington, DC and is an editor for PubMed Health, a health-information service from the US National Library of Medicine. Bastian noticed a \"stark bias\" towards photos of men and white women scientists. \u201cI could feel my own image of scientists in history changing. Who we see affects us,\" she says. So for Black History Month in February, she decided to  track down  copyright-free photos of African American women researchers and add them to their respective Wikipedia pages. Her project has continued into March \u2014 Women\u2019s History Month \u2014 and now includes scientists from other under-represented backgrounds. She also just launched an associated Twitter account,  @MissingSciFaces . \u201cIt\u2019s so important for all of us to prevent invisibility in the historical and social record of scientists who always had the odds most stacked against them,\u201d Bastian  writes in a blogpost on 6 March for PLOS, for which she is a contributor. \u201cIt's remarkable how easy it is to overlook women,\u201d says Alice Dreger, a historian of science, who has  tweeted approvingly  about the project. \u201cIt is important to recognize the success of women in science, as well as the struggles they continue to face.\u201d \n             http://blogs.plos.org/absolutely-maybe/2017/03/06/how-to-guide-help-find-missing-scientists-faces/ \n           \n             Matilda effect \n           Bastian wants others to help her, and has  written a guide for sourcing images . A lot of material is available online, she writes, but it requires some digging. She recommends sifting through Google Images, Flickr Commons, Newspapers.com, or even approaching the researchers or their families or taking photos of female scientists at conferences. She notes that getting copyright-free images is one problem facing the project: only public-domain images can go into a Wikipedia page, for example, via the site's repository Wikimedia Commons. Lenny Teytelman, cofounder and chief executive of the open-access scientific-methods repository  Protocols.io , says that Bastian\u2019s project aims to address a phenomenon known as the \u2018 Matilda Effect \u2019 \u2014 a bias against women in which their work is attributed to their male colleagues. \"While the Matilda Effect is about the bias against women, I have no doubt that the bias against scientists from under-represented groups is even more severe,\" he says. Bastian's effort is a small step, but it is \"a very concrete and actionable how-to guide\" to redressing the balance, he says. This month, Bastian plans to systemize lists of African American women scientists on Wikipedia, and to encourage others to help identify people. Ultimately, she says, \u201cIt will be a success if it\u2019s no longer my personal project.\u201d \n                   Women postdocs less likely than men to get a glowing reference 2016-Oct-03 \n                 \n                   Gender bias found in Earth-science society journals 2016-Sep-29 \n                 \n                   Researchers debate whether female computer coders face bias 2016-Feb-15 \n                 \n                   Science and sexism: In the eye of the Twitterstorm 2015-Nov-11 \n                 \n                   Inequality quantified: Mind the gender gap 2013-Mar-06 \n                 \n                   Women in science: Women\u2019s work 2013-Mar-06 \n                 \n                   Women in science: Clogging the leaky pipeline \n                 \n                   Black History Month blog by Hilda Bastian: \n                 \n                   How to find Missing Scientists\u2019 Faces \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21598", "url": "https://www.nature.com/articles/nature.2017.21598", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "\u2018Leaky pipeline\u2019 stands the test of time, with overall progress for women in research continuing at a crawl. Although women are publishing more studies, being cited more often, and securing more coveted first-author positions than they were in the mid 1990s, overall progress towards gender parity in science varies widely by country and field. This is according to a  massive report  released on 8 March that is the first to examine such a broad swath of disciplines and regions of the world over time (see 'Slowly but surely'). The report 1  by the publisher Elsevier found that despite their moderate advances, women still published fewer articles than men, and were much less likely to be listed as first or last authors on a paper. Citation rates, however, were roughly equal: although female authors were cited slightly less than male authors, work authored by women was downloaded at slightly higher rates. Elsevier used data from Scopus, an abstract and citation database of more than 62 million documents. The report\u2019s authors broke the data down into 27 subject areas, and compared them across 12 countries and regions and two 5-year blocks of time: 1996\u20132000 and 2011\u201315. The report included only researchers who were listed as an author on at least one publication within either of the two five-year periods. Although women might be publishing less research, the citation rates indicate that their work is equally scientifically important, says Holly Falk-Krzesinski, vice-president of global academic and research relations at Elsevier who is based in San Diego, California. However, Cassidy Sugimoto, an information scientist who studies gender disparities at Indiana University Bloomington, notes that she would expect to see men and women cited at similar ratios because many papers have multiple authors representing more than one gender. The small number of female first authors, she says, reflects the inequalities that still exist in science today. \u201cI think this report does a tremendous job of demonstrating and reinforcing that the leaky pipeline is still in effect,\u201d says Sugimoto, referring to the decline seen in the proportion of women at succesive stages in research. \u201cWe see an increase in the number of women researchers and an increase in the number of women first authors, but those rates are not progressing equally. We have a pipeline problem, and time is not erasing it.\u201d \n             No easy fix \n           But patching that pipeline has proved extremely difficult. Women must overcome a number of barriers in science, says Sugimoto, ranging from conscious and unconscious  sexism  to expectations of women\u2019s roles in child care and care for the elderly. In response to its own findings, Elsevier has been addressing issues of  gender imbalance on its journal boards  by setting benchmarks for the number of men and women included on them. But Sugimoto cautions that simply putting women in positions to review papers may not solve the problem: in some studies, she says, women in science were just as likely to discriminate against other women when hiring as men were 2 , although other studies have failed to find such hiring bias 3 . This report confirms the results of many past studies on gender disparities in research, says Shulamit Kahn, an economist at Boston University in Massachusetts who studies gender differences in science. But the multinational, multidisciplinary scope of this study allows for more in-depth analysis, she says. Although the overall proportion of women in science has grown, the rates have hardly been equal across countries or disciplines. In Japan, the proportion of female researchers rose by only 5% between the two study periods, whereas in Brazil, it rose by 11%. Women were also represented unequally in different scientific fields. Although they were strongly represented in life and biomedical sciences,  few women specialized in the physical sciences . And when the report analysed patent data from the World Intellectual Property Organization, they found that only 14% of people filing patent applications in 2011\u201315 were women (see 'Patent pattern'). \u201cWhat our report demonstrates is that gender disparities aren\u2019t the same all over. What works to fix them in one place and one field might not work in another,\u201d says Falk-Krzesinski. \n                   Women postdocs less likely than men to get a glowing reference 2016-Oct-03 \n                 \n                   Gender bias found in Earth-science society journals 2016-Sep-29 \n                 \n                   Researchers debate whether female computer coders face bias 2016-Feb-15 \n                 \n                   Science and sexism: In the eye of the Twitterstorm 2015-Nov-11 \n                 \n                   Bibliometrics: Global gender disparities in science 2013-Dec-11 \n                 \n                   Inequality quantified: Mind the gender gap 2013-Mar-06 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21508", "url": "https://www.nature.com/articles/nature.2017.21508", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "A host of detailed cell atlases could revolutionize understanding of cancer and other diseases. The first time molecular biologist Greg Hannon flew through a tumour, he was astonished \u2014 and inspired. Using a virtual-reality model, Hannon and his colleagues at the University of Cambridge, UK, flew in and out of blood vessels, took stock of infiltrating immune cells and hatched an idea for an unprecedented tumour atlas. \u201cHoly crap!\u201d he recalls thinking. \u201cThis is going to be just amazing.\u201d On 10 February, the  London-based charity Cancer Research UK  announced that Hannon\u2019s team of molecular biologists, astronomers and game designers would receive up to \u00a320 million (US$25 million) over the next five years to develop its interactive virtual-reality map of breast cancers. The tumour that Hannon flew through was a mock-up, but the real models will include data on the expression of thousands of genes and dozens of proteins in each cell of a tumour. The hope is that this spatial and functional detail could reveal more about the factors that influence a tumour\u2019s response to treatment. The project is just one of a string that aims to build a new generation of cell atlases: maps of organs or tumours that describe location and make-up of each cell in painstaking detail. Cancer Research UK awarded another team up to \u00a316 million to make a similar tumour map that will focus on metabolites and proteins. Later this year, the US National Institute of Mental Health will announce the winners of grants  to map mouse brains in extraordinary molecular detail . And on 23\u201324 February, researchers will gather at Stanford University in California to continue planning the Human Cell Atlas, an as-yet-unfunded effort to map every cell in the human body. \n               Cell by cell \n             \u201cThis is a very hot topic,\u201d says Ido Amit, who studies the genomics of the immune system at the Weizmann Institute of Science in Rehovot, Israel. \u201cIt\u2019s all location, location, location. The community knows this has to be the next step.\u201d Over the past few years, researchers have flocked to techniques that allow them to sequence the full complement of RNAs \u2014 tens of thousands of them \u2014 in individual cells. These RNAs can reveal which genes are expressed, and provide clues as to a cell\u2019s unique function within an organ or tumour. But sequencing methods typically require that the cells first be plucked from the tissue in which they live. That destroys valuable information about where the cells were and what neighbours they interacted with \u2014 information that could hold new clues to a cell\u2019s function and how it can go awry in diseased tissue. \u201cThere is a lot of  excitement and promise with single-cell sequencing technologies ,\u201d says Nicola Crosetto, a molecular biologist at the Karolinska Institute in Stockholm. \u201cBut when we think of cancer and complex physiological tissues, we need to be able to put that information into spatial context.\u201d Techniques are emerging to do so. On 6 February, Amit and Shalev Itzkovitz, also at the Weizmann Institute, and their colleagues reported that they had created a cell-by-cell map of mouse liver lobules, complete with RNA sequences from each cell 1 . The lobules of the liver are conventionally divided into concentric layers; the team found unique gene-expression patterns in cells lying at the interface between two layers. \u201cThis region of the tissue is not just a transition zone,\u201d says Itzkovitz. \u201cIt\u2019s a new zone with a specified function.\u201d \n               Peering at proteins \n             Meanwhile, Hannon has teamed up with biophysicist Xiaowei Zhuang at Harvard University in Cambridge, Massachusetts, who has developed a method that encodes RNAs with binary barcodes that can be read within cells using imaging techniques. The technique detects thousands of RNAs in a single cell simultaneously, without dissociating it from its neighbours. \u201cEvery time I look at the images with the barcodes sticking out, it reminds me of the movie  The Matrix ,\u201d Zhuang says. The molecular cartography of RNA is simple in comparison to working with proteins and other molecules. Josephine Bunch of the National Physical Laboratory in Teddington, UK, and her colleagues are developing tumour atlases with detailed information about small molecules, such as lipids, drugs and metabolites, as well as large molecules such as proteins. The methods will allow her team to assess about 50 proteins per sample. That may sound less impressive than the thousands of RNAs measured by other techniques, but information about 50 proteins \u2014 which can be selected to suit specific tissues \u2014 present in different combinations is enough to identify major cell types and gauge key molecular pathways operating in them, says Garry Nolan, a molecular biologist at Stanford University. Proteins offer a more direct view into the function of a cell than does RNA, he notes, and can better allow researchers to link their data to previously published cell atlases dating back decades. Whatever the methods that make it to the top, researchers will also need to develop new ways of displaying the data, says Hannon. \u201cVirtual reality is very powerful,\u201d he says. \u201cBut the amount of information is going to be so vast, we\u2019re going to need new ways of interacting with information.\u201d \n                     Brain-data gold mine could reveal how neurons compute 2016-Jul-13 \n                   \n                     The visualizations transforming biology 2016-Jul-04 \n                   \n                     Microsoft billionaire takes on cell biology 2014-Dec-08 \n                   \n                     Genomics: The single life 2012-Oct-31 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21439", "url": "https://www.nature.com/articles/nature.2017.21439", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Proposed solution to geometry puzzle allows an object\u2019s structure to be determined from limited information. Mathematicians say that they have solved a major, decades-old problem in geometry: how to reconstruct the inner structure of a mystery object \u2018 X \u2019 from knowing only how fast waves travel between any two points on its boundary. The work has implications in real-world situations, such as for geophysicists who use seismic waves to analyse the structure of Earth\u2019s interior. \u201cWithout destroying \u2018 X \u2019, can we figure out what\u2019s inside?\u201d asked mathematician Andr\u00e1s Vasy of Stanford University in California, when he presented the work in a talk at University College London (UCL) last week. \u201cOne way to do it is to send waves through it,\u201d he said, and measure their properties. Now, Vasy and two of his collaborators  say that they have proved 1  that this information alone is sufficient to reveal an object\u2019s internal structure. \n               Looking inwards \n             The problem is called the boundary-rigidity conjecture. It belongs to the field of Riemannian geometry, the modern theory of curved spaces with any number of dimensions.  Albert Einstein  built his  general theory of relativity  \u2014 in which mass warps the geometry of space-time \u2014 on this branch of mathematics. Mathematicians already knew that the way in which curvature varies from place to place inside a \u2018Riemannian manifold\u2019 \u2014 the mathematical jargon for curved space \u2014 determines the shortest paths between any two points. The conjecture flips things around: it says that knowing the lengths of the shortest paths between points on a boundary essentially determines the curvature throughout. (The geometry is therefore said to be \u2018rigid\u2019.) Thus, by measuring how fast waves travel inside a space, one could work out the shortest paths, and theoretically, the overall structure. The conjecture dates back to at least 1981, when the late mathematician Ren\u00e9 Michel 2  formulated certain technical assumptions about the spaces for which it should be true. (It is not true for Riemannian manifolds in general.) Vasy\u2019s co-author Gunther Uhlmann, a mathematician at the University of Washington in Seattle, has been working on this problem since the late 1990s, and he and a collaborator had already solved it for two-dimensional Riemannian manifolds \u2014 that is, curved surfaces 3 . Now, Vasy, Uhlmann and Plamen Stefanov, who is at Purdue University in West Lafayette, Indiana, have solved it for spaces that have three or more dimensions, as well. \n               Layer by layer \n             In Einstein\u2019s space-time, curvature produces  gravitational lensing , a phenomenon familiar to astronomers, in which the path of light bends around massive objects such as stars. Similar mathematics apply to conventional lensing, or refraction: light rays or sound waves shift direction when the medium through which they are travelling changes. In the case of seismic waves \u2014 generated by events such as  earthquakes  \u2014 the differing properties of Earth at varying depths mean that the shortest path for such waves is usually not a straight line, but a curved one. Since the early 1900s, geophysicists have used this fact to map the planet\u2019s internal structure, and this is how they discovered the mantle and the inner and outer cores. Those discoveries were rooted in mathematical treatments that had some simplifying assumptions. Until now, it was not clear that one could fully determine Earth\u2019s structure using only wave travel times. But that is what Vasy and his team\u2019s proof shows \u2014 and the geophysical problem was a key motivation for solving the conjecture. Their assumption, which differed from Michel\u2019s, was that the curved space, or manifold, is structured with concentric layers. This allowed them to construct a solution in stages. \u201cYou go layer by layer, like peeling an onion,\u201d says Uhlmann. For practical applications, this means that researchers will not only know that there is a unique solution to the problem; they will also have a procedure to calculate that solution explicitly. The three mathematicians circulated their 50-page paper among a small pool of experts and then posted it in the arXiv repository. Depending on the feedback they get, the authors hope to submit it to a journal in the coming weeks. \n               From theory to reality \n             Vasy says that the work could be helpful to people who develop medical-imaging techniques such as ultrasound,\u00a0as well as to seismologists. But applying the theory to real geophysical data will not happen immediately, says Maarten de Hoop, a computational seismologist at Rice University in Houston, Texas. One difficulty is that the theory assumes that there is information at every point. But in reality, data are collected only at  relatively sparse locations . Uhlmann says that he is working on that problem with colleagues who specialize in numerical analysis. The improved mathematical approach probably won\u2019t drastically change our picture of Earth\u2019s structure yet, says de Hoop. But it could lead to a better understanding of known features, such as the mantle plumes underneath Iceland or Hawaii, and perhaps, to the discovery of new ones, he says. As with every meaty mathematical result, \u201cit will take a while to come to grips with it\u201d and to vet the proof thoroughly, says Gabriel Paternain, a mathematician at the University of Cambridge, UK. Experts are taking the claim seriously, in part because it builds on a technical step from a linear form of the problem that the community had already accepted as a breakthrough 4 , adds UCL mathematician Yaroslav Kurylev. So far, says Paternain, the impression is \u201cexcellent\u201d. \n                     'Beautiful mind' John Nash adds Abel Prize to his Nobel 2015-Mar-25 \n                   \n                     Global seismic network takes to the seas 2014-Mar-12 \n                   \n                     Geometer wins maths 'Nobel' 2009-Mar-26 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21504", "url": "https://www.nature.com/articles/nature.2017.21504", "year": 2017, "authors": [{"name": "Jason Bittel"}], "parsed_as_year": "2006_or_before", "body": "The plants keep waterborne pathogens in check, potentially benefitting people and coral reefs. Seagrass meadows are the most widespread coastal ocean environment in the world. And new research finds that these plants can reduce the load of bacteria, such as  Enterococcus , in the surrounding seawater by up to 50%. What\u2019s more, coral reefs also show a 50% reduction in the prevalence of disease when seagrasses live nearby. The plants act as nurseries that shelter young animals, and  provide permanent homes  for creatures including fish and manatees. Seagrass meadows are also superstars when it comes to carbon sequestration. But the new findings, published 16 February in the journal  Science 1 , add a healthcare component to the long list of ecosystem services seagrasses provide.\u00a0 \u201cThis study touches on something that is often ignored or forgotten,\u201d says Lina Mtwana Nordlund, a marine and environmental researcher at Stockholm University in Sweden. And that\u2019s the ability of seagrasses to help ameliorate the effects of terrestrial pollution on the marine environment. Researchers didn\u2019t investigate the mechanism by which seagrasses neutralize bacteria. But lead study author C. Drew Harvell, a marine ecologist at Cornell University in Ithaca, New York, explains several ways in which it could happen. Oxygen produced by the plants could kill certain bacteria, filter-feeding animals living in seagrass meadows might strain out pathogens, or microbes could end up physically stuck to seagrass blades. \u201cSince seagrasses remove sediment and particulates from the water, it is not a stretch to expect bacteria and surface associated pathogens to also be removed from the overlying waters,\u201d says Frederick Short, director of SeagrassNet, a global monitoring and information network for seagrass meadows. \u201cIt\u2019s a major finding to have convincing data on yet another important function of seagrass habitat.\u201d \n             Sick to their stomachs \n           A mass illness at a workshop in 2011 inspired Harvell to look into the effect seagrass meadows could have on pathogens. While conducting a program on coral health with several other scientists in Indonesia, everyone who went into the water, including Harvell, came down with amoebic dysentery. One researcher caught typhoid fever. This is because relatively small islands like those found in the Spermonde Archipelago, where the dives took place, can have thin, poor soil that does not hold on to wastewater. Since the island communities often lack basic sanitation systems,  human waste and the accompanying bacteria  can wind up in the waves. The research team returned in 2014 to take their samples and found that bacterial levels in some areas were about ten times higher than what the US Environmental Protection Agency considers safe. Amounts were lower in areas with seagrass meadows. The team also found drastic reductions in coral disease levels in areas with nearby seagrasses. \u201cI think this research is a huge contribution to helping us understand the demise of coral reefs occurring in many locations,\u201d says Esther Peters, a marine biologist studying coral disease at George Mason University in Fairfax, Virginia. \u201cI did not have any idea that seagrasses could be so important to corals by reducing potential bacterial pathogens.\u201d \n             In a decline \n           While the study\u2019s findings are promising, Nordlund would like to see the research conducted on a larger scale, with a broader range of seagrass species and densities. Different species range in size from hovering just a centimeter or two above the seabed to towering several meters into the water column. And their roots penetrate to different depths depending on the species and sediment makeup. This would probably result in some variation in the amount of bacterial scrubbing any given species might be capable of, Nordlund says. Nevertheless, Short is pleased to see the results of the study, especially since  seagrass habitats are in decline  around the world \u2014 mostly from human actions including pollution, runoff and damage from boats. \u201cIt may help to convince people worldwide of the need to protect and restore seagrasses,\u201d he says. \n                   A hard sell 2015-Apr-29 \n                 \n                   Add coastal vegetation to the climate critical list 2011-May-18 \n                 \n                   Vital marine habitat under threat 2009-Jun-29 \n                 \n                   Divers carry pathogens in their wetsuits 2006-May-25 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21470", "url": "https://www.nature.com/articles/nature.2017.21470", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Agency narrows possible targets for the first-ever sample return from the red planet. The future of NASA's Mars programme is taking shape. The agency has narrowed \u2014 from eight to three \u2014 the list of potential landing sites for its 2020 rover,  which will scoop up Martian rock and soil  in the hope of one day returning them to Earth. NASA shortlisted the sites on 10 February, at the end of  a three-day workshop in Monrovia, California  to hash out where the spacecraft will go. The final decision, due a year or two before launch, will be one of the most momentous in Mars exploration. The  rocks that the Mars 2020 rover collects  are likely to dictate the scientific questions that will be tested for decades to come. \u201cWhat if this is the only set of samples that we ever return from a known place on Mars?\u201d asks Briony Horgan, a planetary scientist at Purdue University in West Lafayette, Indiana. Until now, the only Mars rocks that researchers have studied are meteorites,  which reach Earth stripped of their original geological context . The three landing sites still in contention include Jezero crater, which was once home to an ancient Martian lake and which could preserve the remains of microbial life, if that ever existed on Mars. \u201cYou've got a large river bringing water and sediment into a very large lake, comparable to Lake Tahoe,\u201d says Timothy Goudge, a planetary scientist at the University of Texas at Austin. Jezero scored highest on a community vote of scientists attending the workshop. Other possible targets are Northeast Syrtis, where hot waters once circulated through the crust and could have supported life, and Columbia Hills,  the area explored for years by NASA's Spirit rover . \n               Rocky road \n             Unlike Jezero and NE Syrtis, Columbia Hills did not score highly in the community vote. And in another advisory report this week, a group of scientists on the 2020 project explicitly recommended against revisiting the site. That report argued that sending the 2020 rover to Columbia Hills was unlikely to resolve confusion over whether its silica rocks, which resemble hydrothermal deposits on Earth, could be linked to life. But Matthew Golombek, a planetary scientist at the Jet Propulsion Laboratory in Pasadena, California, says that Columbia Hills, like Jezero and NE Syrtis, presents a prime opportunity to explore possible past Martian life. The 2020 rover will carry scientific instruments that could tackle questions about the silica rocks there better than Spirit could, he says. \u201cIt's the only location on Mars that we know of that had a hot spring,\u201d says Golombek, who co-chairs the site-selection process. He noted that Columbia Hills also has a variety of other geological features nearby, such as an ancient lava flow from which samples could be dated to provide a much-desired absolute age for Martian rocks. The Columbia Hills choice is likely to be controversial. Horgan says that she is \u201cdisappointed\u201d that the site-selection committee went against the recommendations of the workshop and the advisory panel on Columbia Hills, although she is happy about the Jezero and NE Syrtis picks. NASA wants a landing site where water once flowed, to increase the chance that the rover will discover evidence of any past life \u2014 such as organic compounds, biomarker molecules or even microfossils. But the site should also be easy to traverse, because the rover will need to begin drilling quickly to collect at least 20 rock samples in roughly two years. \u201cWe have to be able to get to the stuff,\u201d Abigail Allwood, an astrobiologist at the Jet Propulsion Laboratory, told the meeting. \n               Left behind \n             That requirement, along with other challenges, knocked Holden crater off the list of possibilities. The rover would have had to drive large distances around that site to collect different types of geological samples. And as the southernmost location on the longlist, it would have exposed sample tubes to strong sunlight and high temperatures, which could have compromised future tests. Also out of the running is Eberswalde crater, which scored third in the community vote but is also far south and gets quite hot, Golombek says. Jezero crater offers the same sort of ancient-lake environment without the risk posed by high temperatures, he argues. And the community\u2019s fourth choice of Mawrth Vallis, although rich in clays, is not as clearly connected to a possibly once habitable environment, he says. Nili Fossae, where an orbiting spacecraft had seen methane rising from Mars, and Southwest Melas, another ancient lake, also fell off the list. Neither scored as highly as the top candidates for the potential for science return. NASA has neither designed nor budgeted for how to get the Martian rock samples back to Earth. So the 2020 rover will drill and collect the samples, then lay them down on the Martian surface for an as-yet-unplanned mission to retrieve.  The European Space Agency  is launching its own Mars rover in 2020 , to Oxia Planum. China also plans to send one that year, when the alignments of Earth and Mars are favourable for launching missions between the two. \n                 Additional reporting by Erin Ross. \n               \n                     The $2.4-billion plan to steal a rock from Mars 2017-Jan-18 \n                   \n                     NASA plans Mars sample-return rover 2014-May-13 \n                   \n                     ExoMars scientists narrow down landing sites 2014-Apr-02 \n                   \n                     NASA's Mars 2020 mission \n                   \n                     Landing-site workshop \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21472", "url": "https://www.nature.com/articles/nature.2017.21472", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Capacity has grown threefold in the past decade, but the country still lags behind Europe and China in sustainable energy. Renewable-energy capacity in the United States has more than tripled since 2008, according to a  report  published this month on US sustainable energy by the Business Council for Sustainable Energy (BCSE), an industry group. Energy capacity from sustainable energy sources such as wind, solar, biomass and geothermal reached a record 141 gigawatts (GW) in the country at the end of 2016 (see 'Sunny outlook'). Hydropower, the most prevalent renewable in the United States, added another 103 GW, which has remained roughly stable over the past decade.  New wind and solar capacity account for the bulk of the increase. The combined capacity for these two energy sources has increased almost fivefold since 2008, from 26 to 123 GW. Wind accounted for 83 GW. But US wind capacity still lags way behind that of the European Union and China, which both had more than 140 GW installed by 2015. The increasing use of solar photovoltaics and cells drove most of the growth in US low-carbon energy in recent years \u2014 the result of favourable tax policies and sharply falling installation costs, according to the BCSE analysis, which was conducted by Bloomberg New Energy Finance. In terms of growth in the solar photovoltaics sector, the United States is surpassed only by China and Japan.  \n             Keeping momentum \n           \u201cThe energy market is shifting, and it\u2019s shifting quickly,\u201d says Lisa Jacobson, president of the BCSE, based in Washington DC. But local, state and federal governments all have a part to play if the United States is going to increase the pace of clean-energy deployment in the coming decades, Jacobson says. \u201cWe still need policy leadership.\u201d Renewable energy, including hydropower, met 15% of US electricity demand last year, up from just 8% a decade ago. By comparison, renewables fulfilled 24% of  global demand . Over the same period, the share of energy from coal fell from almost 50% to 30% in the United States. And thanks to the increasing decarbonization of the power sector and improved energy efficiency generally, US greenhouse-gas emissions plunged to a 25-year low in 2016. Additional reporting by Jeff Tollefson. \n                   Europe leads growing market in offshore wind power 2016-Aug-22 \n                 \n                   Energy policy: Push renewables to spur carbon pricing 2015-Sep-02 \n                 \n                   Economics: Support low-carbon investment 2015-Mar-04 \n                 \n                   Economics: Manufacture renewables to build energy security 2014-Sep-10 \n                 \n                   Business Council for Sustainable Energy \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21482", "url": "https://www.nature.com/articles/nature.2017.21482", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Publisher restores access as negotiations for a nationwide licence continue. A stand-off in which dozens of German universities declined to pay for access to journals from publishing giant Elsevier has been partially resolved. For more than 40 days,  thousands of scientists were cut off from Elsevier journals.  But the Dutch publisher said on 13 February that it had chosen to restore their access even though underlying negotiations for a nationwide German licence have not yet been settled. \u201cThe continuing access for the affected institutions will be in place while good-faith discussions about a nationwide contract carry on. This reflects our support for German research and our expectation that an agreement can be reached,\u201d the publisher said in a  statement . Asked whether or not it was charging for the access, Elsevier said that it is customary in these situations for institutions to retain access to content after a contracted period is concluded and as long as renewal discussions are ongoing. Around 60 universities and research institutions decided not to renew their expiring subscriptions to Elsevier\u2019s content at the end of 2016. They anticipated that a new consortium, called DEAL, would negotiate a nationwide licence with the publisher. But discussions between DEAL and Elsevier broke down last December after disagreements about costs and about whether, under the new agreement, all German-authored articles could be made open access. The universities that had cancelled their individual contracts decided that it still wasn\u2019t worth making new access arrangements. From the start of 2017, their academics were cut off from new Elsevier articles, and in some cases to archived issues. \n             Irritating situation \n           The loss of access to Elsevier content didn\u2019t overly disturb academic routines, researchers say, because they found other ways to get papers they needed, or because Elsevier journals happened not to be of prime importance in their fields. To help scientists cope with the situation, librarians organized speedy inter-library loans. \u201cMost senior scientists are closely networked with colleagues in other countries. Students and young scientists who aren\u2019t have been hit harder,\u201d says Hans-Ulrich Humpf, a food chemist at the University of M\u00fcnster. Humpf asked colleagues in the United States to e-mail him a couple of papers while he had no access. Robin Korte, a PhD student also at the University of M\u00fcnster, was finalizing a list of references for his thesis on allergens in processed foodstuffs when his university lost access to Elsevier journals. Being blocked from journals highly relevant in his field \u2014 such as the\u00a0 Journal of Allergy and Clinical Immunology \u00a0and the\u00a0 Journal of Proteomics \u00a0\u2014 prompted him to cite other sources instead. \u201cI managed to cope somehow,\u201d he says. \u201cBut it was an irritating situation, for sure.\u201d Despite the disruption, many German scientists say they welcome the DEAL consortium\u2019s firm stance in negotiations with Elsevier. Licensing negotiations between the consortium and other publishers, including Wiley and  Nature \u2019s publisher, Springer Nature, are expected to begin later this year. Nature \u2019s news team (which is editorially independent of its publisher) has asked the DEAL consortium for comment. \n                   Scientists in Germany, Peru and Taiwan to lose access to Elsevier journals 2016-Dec-23 \n                 \n                   Dutch lead European push to flip journals to open access 2016-Jan-06 \n                 \n                   Open access: The true cost of science publishing 2013-Mar-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21440", "url": "https://www.nature.com/articles/nature.2017.21440", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Initiative's first grants will fund a medley of wild ideas from top San Francisco Bay Area biologists, engineers and programmers. The biomedical research initiative created by Facebook co-founder Mark Zuckerberg and his wife, physician Priscilla Chan, has awarded its first grants to scientists, on topics ranging from the genomics of obscure microbes to a memory-retrieval device. Forty-seven investigators will receive up to US$1.5 million each in the next five years from the Chan Zuckerberg Biohub, a partnership between  the couple\u2019s Chan Zuckerberg Initiative  and three universities: Stanford, the University of California, Berkeley, and the University of California, San Francisco. Together, the biohub grants announced on 8 February total more than $50 million. \u201cWe told researchers, give us your riskiest ideas,\u201d says biohub co-leader Stephen Quake, a bioengineer at Stanford. More than 750 investigators from the three schools answered the call to submit proposals that elucidate fundamental biological processes and lead to disease-related technologies. Quake says he and other grant reviewers favoured researchers who have impressive track records and bold ideas that lack preliminary evidence. \u201cThere is a creative anarchy in the atmosphere here in the Silicon Valley that we want to harvest,\u201d Quake says. Jure Leskovec, a computer scientist at Stanford and chief scientist at the image-sharing company, Pinterest, won a grant even though his work has focused on analysing social networks rather than biological systems. Leskovec successfully argued that his approach to data could help biologists to understand the complicated interactions of genes and proteins exposed to drugs or disease. \u201cI don\u2019t think I\u2019d get funding to pursue biological research through traditional funding sources because the grant reviewers would be sceptical,\u201d he says. \u201cThey\u2019d say, oh, he\u2019s not one of us.\u201d Other winners express the same sentiment, whether they are engineers who yearn to lead biology projects or biologists wanting to follow a hunch. The US National Institutes of Health (NIH) wants to see a lot of preliminary data, Quake explains: \u201cWe want to fund people so that they are more likely to get the NIH grant later.\u201d \n               The long view \n             Sceptics have questioned whether the couple\u2019s money might be better spent by public institutions such as the NIH and the World Health Organization. But Quake says that the biohub instead seeks to complement those agencies: \u201cWe are trying to take on things that are above their threshold of risk.\u201d Indeed, neither the biohub nor its parent initiative could replace government funding even if it wanted to. The initiative\u2019s $3-billion commitment to science that aims to cure, manage or prevent all diseases pales in comparison with the roughly $30 billion that the NIH spends annually on medical research. The biohub\u2019s leaders hope to accelerate the rate at which its grantees\u2019 discoveries prove useful by requiring investigators to meet several times each year. One participating scientist, geomicrobiologist Jill Banfield of Berkeley, looks forward to the gatherings. She\u2019ll be probing enigmatic bacteria and archaea for genes and proteins that manipulate the genomes of other species, and that might be harnessed for new technologies. In the mid-2000s, Banfield helped draw attention to repetitive genetic sequences called CRISPR within bacteria that she had found in a defunct iron mine in California. Thanks to further work by biochemists, CRISPR\u2013Cas9 has become the hottest tool in gene editing. \u201cEverything I do is basic discovery, but to go on to the next step requires new techniques and methodology that I\u2019m not in a position to do alone,\u201d she says. The biohub investigators must post their manuscripts on open-access preprint servers, such as the arXiv, as soon as they submit the paper to a peer-reviewed journal. But researchers are permitted to file for patents, which would be owned jointly by the biohub and the scientists\u2019 home institution. Marc Kastner, president of the Science Philanthropy Alliance, an organization in Palo Alto, California,  has advised Chan and Zuckerberg, among others . He applauds the biohub for selecting researchers who want to pursue non-traditional projects in this first round of funding. \u201cIf you\u2019re going to take a century-long view on curing disease,\u201d he says, \u201cyou need to emphasize basic research because you can\u2019t tell where breakthroughs come from.\u201d \n                     Big biology projects warm up to preprints 2016-Nov-30 \n                   \n                     Science group seeks to guide Silicon Valley philanthropists 2016-Oct-13 \n                   \n                     Facebook couple commits $3 billion to cure disease 2016-Sep-21 \n                   \n                     Chan Zuckerberg Initiative \n                   \n                     Chan Zuckerberg Biohub \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21503", "url": "https://www.nature.com/articles/nature.2017.21503", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "This mostly submerged world should be recognized alongside Africa, Australia and others, argue some researchers. Beneath the waves in the southwest Pacific Ocean lies a mostly hidden realm \u2014 dubbed Zealandia \u2014 that deserves to be called a continent, geologists say. Geophysical data suggest that a region spanning 5 million square kilometres, which includes New Zealand and New Caledonia, is a single, intact piece of continental crust and is geologically separate from Australia, a team of scientists from New Zealand, Australia and New Caledonia argue in the March/April issue of  GSA Today 1 . (see 'Hidden crust') \u201cIf you could pull the plug on the world\u2019s oceans, then Zealandia would probably long ago have been recognized as a continent,\u201d says team leader Nick Mortimer, a geologist at GNS Science in Dunedin, New Zealand. However, there is no international body in charge of designating official continents, and so the researchers must hope that enough of their colleagues agree to recognize the landmass. Otherwise, their proposal could remain more of a theoretical wish than a radical reshaping of what every child has to learn in geography class. \u201cThe results are pushing us to rethink how broadly we can or should apply the established definition of geological continental landmasses,\u201d says Patricia Durance, a mineral geologist at the GNS Science office in Lower Hutt, New Zealand. \n             Not a mash-up \n           Mortimer and his colleagues have been making the case for Zealandia for more than a decade, in talks, popular articles and books; the latest paper is their most technical synthesis yet. In it, they report that Zealandia began to peel away from the supercontinent of Gondwana starting about 100 million years ago. The rift gave Zealandia its independence, but it also pulled and thinned the crust, causing the area to sink, and dooming most of it to a watery existence. Today, only about 6% of it remains above water, as New Zealand and New Caledonia. Satellite  maps made using Earth\u2019s gravitational field  clearly show that Zealandia is a coherent geographical feature stretching from near Australia\u2019s northeastern coast well past the islands of New Zealand, Mortimer says. Sea-floor samples reveal that Zealandia consists of light continental crust and not the dark volcanic rocks that make up nearby underwater plateaus. The area seems to be structurally intact, rather than a mash-up of different continental-crust fragments. There is no widely accepted definition of a continent, and geographers and geologists differ on the question. (Geographically, Europe and Asia are considered separate continents, whereas geologists consider them the single landmass of Eurasia.) \u201cOne of the main benefits of this article is that it draws attention to the arbitrary and inconsistent use of such a fundamental term as continent,\u201d says Brendan Murphy, a geologist at St. Francis Xavier University in Antigonish, Canada. Zealandia will face an uphill battle in garnering the same popular name recognition as Eurasia, Africa, Antarctica, Australia and North and South America. \u201cClaiming that Zealandia is a continent is a bit like stamp collecting,\u201d says Peter Cawood, a geologist at Monash University in Melbourne, Australia. \u201cSo what?\u201d Whatever it is called, Mortimer says, studies of Zealandia should help biogeographers to better understand how New Zealand\u2019s endemic plants and animals arose \u2014 and give geologists a boost in learning how continental crust can be reshaped. \n                   Behind New Zealand\u2019s wild plan to purge all pests 2017-Jan-11 \n                 \n                   \u2018Zombie volcano\u2019 slowly grows beneath New Zealand 2016-Jun-03 \n                 \n                   Gravity map uncovers sea-floor surprises 2014-Oct-02 \n                 \n                   Long-lost continent found under the Indian Ocean 2013-Feb-24 \n                 \n                   China outlines deep-sea ambitions 2010-Jul-06 \n                 Reprints and Permissions"},
{"file_id": "542282a", "url": "https://www.nature.com/articles/542282a", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "International team seeks better picture of wind as it moves over rugged terrain. Machines have invaded a windswept rural valley in eastern Portugal. Squat white containers stare at the hillsides, sweeping lasers across the eucalyptus-studded slopes, and towers bristling with scientific instruments soar 100 metres into the air. Their international team of minders will spend the next five months measuring nearly everything it can about the wind that blows through the site. An unprecedented arsenal of meteorological equipment will study speed, direction and other characteristics for the world\u2019s most detailed wind-mapping project. The aim is to illuminate fundamental properties of wind flow over complex terrain, to help researchers improve atmospheric computer models and enable engineers to decide where to put wind turbines to get the most energy from them. The results of the project, called Perdig\u00e3o, should also improve models of how air pollution sinks into valleys and help drones and aircraft to navigate gusty mountain terrain. \u201cThis will be utterly transformative in both understanding the physics of the atmosphere and also how to optimally use wind energy,\u201d says Sara Pryor, an atmospheric scientist at Cornell University in Ithaca, New York, who works on the project. \u201cIt\u2019s brilliant.\u201d By testing wind-flow models against the detailed data from Perdig\u00e3o, researchers will be able to apply their findings in other locations. \u201cLessons learned will translate into improved atmospheric models for the entire wind-energy community,\u201d says Sonia Wharton, a meteorologist at the Lawrence Livermore National Laboratory in Livermore, California. Europe gets 11% of its total energy from wind. But just a 10% shift in wind speed can change the amount of energy produced by up to 30%, says Jakob Mann, a wind-energy researcher at the Technical University of Denmark near Copenhagen. And losses are greatest in hilly or forested regions. Mann leads the \u20ac14-million (US$14.9-million) New European Wind Atlas project, a collection of wind-mapping studies and experiments of which the project in Portugal is the largest. A pilot experiment by the Perdig\u00e3o team in 2015 found turbulence downwind of one ridge that affected wind patterns on the next \u2014 the sort of detail that can improve models of atmospheric flow, says Jos\u00e9 Laginha Palma, a wind-energy specialist at the University of Porto in Portugal and head of the project. Such models have typically relied on measure\u00adments from a simpler field experiment based on and around a hill in Askervein, UK, in the 1980s. \u201cWe\u2019re going to update and replace data going back 30\u00a0years,\u201d says Palma. Portugal has a well-developed wind industry, and the Perdig\u00e3o ridges already host one turbine. Winds at the site generally sweep across and down two steep ridges at around 8\u2009metres per second \u2014 but they can blow at up to 40\u2009metres per second. One recent burst blew the door off a temporary office trailer on one of the ridges. Knowing where such gusts occur can help turbine engineers take advantage of the steady winds while avoiding damage by the biggest gusts, says Rebecca Barthelmie, a wind engineer at Cornell who is working at the site. Much of the scientific equipment is already up and running, and researchers will install the rest throughout February. The set-up includes 54 masts outfitted with instruments to measure wind speed, direction, temperature, humidity and other factors, both along and perpendicular to the ridges, 20 times per second. And 22\u00a0instruments will study small-scale wind flow in three dimensions using the laser-based technique lidar. Many studies have looked at wind patterns on the scale of 1\u2009kilometre, but the Perdig\u00e3o experiment is the first to push large-scale wind mapping down to resolutions of 100\u2013500 metres, says Harindra Fernando, a fluid-dynamics engineer at the University of Notre Dame in Indiana. He is co-leader of the US researchers working at Perdig\u00e3o, who are funded with $3.4 million from the National Science Foundation. \u201cWhat we are trying to do is portable to anywhere in the world,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     Glider aims to break world record \u2014 and boost climate science 2016-Aug-09 \n                   \n                     Germany\u2019s renewable revolution awaits energy forecast 2016-Jul-13 \n                   \n                     Renewables: Share data on wind energy 2016-Jan-04 \n                   \n                     New European Wind Atlas \n                   \n                     Perdig\u00e3o experiment \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21510", "url": "https://www.nature.com/articles/nature.2017.21510", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "From legal challenges to ongoing experimentation, the story of who owns the rights to CRISPR\u2013Cas9 gene editing is still being written. The US Patent and Trademark Office (USPTO) issued a key verdict this week in the battle over the intellectual property rights to the  potentially lucrative gene-editing technique CRISPR\u2013Cas9 . It ruled that the Broad Institute of Harvard and MIT in Cambridge  could keep its patents on using CRISPR\u2013Cas9  in eukaryotic cells. That was a blow to the University of California, Berkeley, which had filed its own patents and  had hoped to have the Broad\u2019s thrown out .\u00a0 The fight goes back to 2012, when  Jennifer Doudna  at Berkeley,  Emmanuelle Charpentier , then at the University of Vienna, and their colleagues outlined how CRISPR\u2013Cas9 could be used to precisely cut isolated DNA 1 . In 2013, Feng Zhang at the Broad and his colleagues \u2014 and other teams \u2014 showed 2  how it could be adapted to edit DNA in eukaryotic cells such as plants, livestock\u00a0and humans. Berkeley filed for a patent earlier, but the USPTO granted the Broad\u2019s patents first \u2014 and this week upheld them. There are high stakes involved in the ruling. The holder of key patents could make millions of dollars from CRISPR\u2013Cas9\u2019s applications in industry: already, the technique has  speeded up genetic research,  and scientists are using it to develop disease-resistant livestock and treatments for human diseases. But the fight for patent rights to CRISPR technology is by no means over. Here are four reasons why. \n             1. Berkeley can appeal the ruling \n           Berkeley has two months to appeal the USPTO\u2019s ruling \u2014 and may well do so. A key question is how confident Berkeley feels that its own patents, once granted, would cover the most lucrative applications of gene editing in eukaryotic cells, such as generating new crops or human therapies. The Broad\u2019s victory centred on a key difference: that its patents specified how CRISPR could be adapted for use in eukaryotic cells and Berkeley\u2019s didn\u2019t. This is why the USPTO ruled that the Broad\u2019s patents would not interfere with the granting of Berkeley\u2019s, and so should be allowed to stand. Berkeley\u2019s team was quick to argue, in the wake of the decision, that its patent \u2014 if granted in its current state \u2014 would cover the use of CRISPR\u2013Cas9 in any cell. That, the team says, would mean someone wanting to sell a product made using CRISPR\u2013Cas9 in eukaryotic cells would need to license patents from both Berkeley and the Broad. Yet the details of the USPTO\u2019s ruling could weaken Berkeley\u2019s chances of enforcing its patents in eukaryotic cells, patent scholars say. For example, much of the USPTO\u2019s 50-page decision argues that the use of CRISPR\u2013Cas9 in eukaryotic cells \u2014 described in the Broad patent \u2014 required additional invention beyond that described in the Berkeley patent application. So Berkeley may feel that it must still appeal. And its intellectual property is already licensed to several companies who intend to deploy CRISPR\u2013Cas9 in eukaryotic cells. Those companies will probably prefer not to have to pay for a license from the Broad as well. \n             2. European patents are still up for grabs \n           Both teams have filed similar patents in Europe and are still battling for patent rights there. And the decision in Europe may not necessarily follow the same path as the USPTO, notes Catherine Coombes, a patent lawyer at the intellectual-property specialists HGF in York, UK. On the basis of European case law, the European Patent Office could choose to assess whether the discovery of the general gene-editing system described in the Berkeley patent prompted \u201csufficient motivation\u201d to try to make the leap to eukaryotic cells. If European judges find this to be the case, they could rule that the Berkeley patent covers eukaryotic applications of CRISPR\u2013Cas9. That could give Berkeley an edge that it lacked in the United States. \u201cThe fact that six groups got CRISPR\u2013Cas9 to work in a eukaryotic environment within weeks of one another shows that in the field there was clear motivation to try,\u201d says Coombes. Even so, there is likely to be no quick resolution to the European patent battle either: Coombes estimates that it could drag out for another five years or more. \n             3. Other parties are also claiming patent rights on CRISPR\u2013Cas9 \n           Attention has focused on the Berkeley\u2013Broad battle because their patents are fairly broad and are seen as being crucial to most commercial applications of CRISPR\u2013Cas9. But there are 763 patent families (groups of related patents) that claim Cas9, according to the consulting firm IPStudies near Lausanne, Switzerland. Of those, some claim patent rights to certain aspects of CRISPR\u2013Cas9 gene editing. Over time, holders of those patents may try to assert those rights. That may not happen until companies that use CRISPR\u2013Cas9 start to make money from their products. At that point, someone who owns a related patent may sue for infringement and ask for royalties. When the time comes, look for plenty of patent holders to come calling, says Jacob Sherkow, an intellectual property scholar at New York Law School in New York City. \u201cEverybody and their third cousin twice removed is going to be claiming they have some inventorship interest in the Broad\u2019s patent,\u201d he says. \u201cThe Broad is going to be fighting those battles for years.\u201d \n             4. CRISPR technology is moving beyond what the patents cover \n           Researchers in academia and industry have been pushing CRISPR gene editing beyond the scope of the Broad and Berkeley patents. Both patent families cover the use of CRISPR\u2013Cas9, which relies on the Cas9 enzyme to cut DNA. But there are alternatives to Cas9 that provide other functions, and a way to sidestep the Berkeley\u2013Broad patent fight. One attractive alternative is Cpf1,  an enzyme that may be simpler to use and more accurate than Cas9 in some cases . The Broad has already filed patents on applications of Cpf1 in gene editing, and has licensed them to biotech company Editas Medicine in Cambridge, Massachusetts (which also has licenses for some Broad patents on CRISPR\u2013Cas9). In all, there are already 28 patent families that claim Cpf1, according to IPStudies, and not all of them are from the Broad. Reports of other enzymes are trickling in. In December, researchers at Berkeley said that they had found two new Cas9 alternatives,  CasX and CasY 3 . And some researchers may already be trying to patent unpublished alternatives \u2014 US patent applications typically do not become public until 18 months after they are filed. Sherkow likens the situation to the early days of PCR (the polymerase chain reaction), a technique used to amplify segments of DNA that quickly became a vital tool in molecular biology. Laboratories initially used just one enzyme, Taq1 polymerase, to carry out the protocol. \u201cNow if you go through the catalogue, there\u2019s almost an Amazon warehouse of polymerases that you can use depending on the particular reaction that you want to do,\u201d he says. People are tethering the commercialization aspect of CRISPR to this particular patent fight, Sherkow says. \u201cThat\u2019s missing some of the broader picture.\u201d \n                   Broad Institute wins bitter battle over CRISPR patents 2017-Feb-15 \n                 \n                   CRISPR heavyweights battle in US patent court 2016-Dec-06 \n                 \n                   Titanic clash over CRISPR patents turns ugly 2016-Sep-21 \n                 \n                   How the US CRISPR patent probe will play out 2016-Mar-07 \n                 \n                   Special: CRISPR \n                 \n                   USPTO CRISPR patent interference documents \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21505", "url": "https://www.nature.com/articles/nature.2017.21505", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Global research funds for these illnesses are at their lowest levels for a decade, when cash for West Africa epidemic is excluded. Global funding for research on neglected diseases \u2014 which include tuberculosis, HIV/AIDS and  malaria  \u2014 is at its lowest level since 2007, according to the annual  G-FINDER investment report  by Policy Cures Research, a health-policy analysis firm in Sydney, Australia. But that total \u2014 just over US$3 billion for 2015, the latest year for which figures are available \u2014 does not include a rapid burst of funding for research into Ebola to tackle  the outbreak in West Africa . Investments in Ebola and other African viral haemorrhagic fevers shot up to $631 million in 2015 \u2014 more than was spent on any other neglected disease except  HIV/AIDS  (see 'Two sides of the same coin'). Almost two-thirds of funds invested in Ebola was spent on developing  preventive vaccines , and more than one-third of funding came from industry. That is an unusually high proportion, notes Nick Chapman, executive director of Policy Cures Research. The firm decided to count the Ebola investments separately from the bulk of neglected-disease funding, because of their distorting effect on the underlying figures. \u201cAt the same time that we\u2019re seeing this huge explosion in Ebola funding, governments are letting funding slide for neglected diseases,\u201d Chapman says.  \n             Public funding falls \n           The G-FINDER analysis, or Global Funding of Innovation for Neglected Diseases, tracks public, private and philanthropic investment into illnesses that disproportionately affect people in developing countries, and that don't have enough of a commercial market to attract much private research and development (R&D). The steady drop in cash for diseases other than Ebola, the report finds, is caused almost entirely by a fall in public funds from high-income countries, such as the United States. These countries accounted for 97% of the $1.9 billion in public funds for R&D in 2015. Much of the US money was delivered through grants from the country\u2019s National Institutes of Health, meaning that neglected disease R&D is vulnerable to funding changes at the agency. Philanthropic funding also fell slightly. It comes from two main donors \u2014 the  Wellcome Trust in London  and the  Bill & Melinda Gates Foundation  in Seattle, Washington, which together accounted for $610 million out of $645 million in public funds in 2015. The Wellcome Trust cut its investment by $27 million \u2014 or 22% \u2014 from 2014 to 2015; its funding for neglected diseases has fallen by 33% since 2012. Additional reporting by Richard van Noorden and Nisha Gaind. \n                   Ebola investment boosts neglected-disease research 2015-Dec-07 \n                 \n                   The HIV epidemic can be stopped 2015-Jul-07 \n                 \n                   WHO plans for neglected diseases are wrong 2014-Feb-19 \n                 \n                   Policy Cures Research: G-FINDER report \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21462", "url": "https://www.nature.com/articles/nature.2017.21462", "year": 2017, "authors": [{"name": "Philip Ball"}], "parsed_as_year": "2006_or_before", "body": "Unstable molecule couldn\u2019t be made through conventional synthesis, so IBM researchers carried out molecular surgery using a microscope tip. Researchers at IBM have created an elusive molecule by knocking around atoms using a needle-like microscope tip. The flat, triangular fragment of a mesh of carbon atoms, called triangulene 1 , is too unstable to be made by conventional chemical synthesis, and could find use in electronics. This isn't the first time that atomic manipulation has been used to create unstable molecules that couldn\u2019t be made conventionally \u2014 but this one is especially desirable. \u201cTriangulene is the first molecule that we\u2019ve made that chemists have tried hard, and failed, to make already,\u201d says Leo Gross, who led the IBM team at the firm\u2019s laboratories in Zurich, Switzerland. The creation of triangulene demonstrates a new type of chemical synthesis, says Philip Moriarty, a nanoscientist who specializes in molecular manipulation at the University of Nottingham, UK. In conventional synthesis, chemists react molecules together to build up larger structures. Here, by contrast, atoms on individual molecules were physically manipulated using a microscope. But making molecules one at a time will be useful only in particular situations. And the method is unlikely to work for those with complicated shapes or structures that make it hard to identify or target individual atoms. \n               Unstable triangle \n             Triangulene is similar to a fragment of  graphene , the atom-thick material in which carbon atoms are joined in a hexagonal mesh. The new molecule is made up of six hexagons of carbon joined along their edges to form a triangle, with hydrogen atoms around the sides (see \u2018Radical triangle\u2019). Two of the outer carbon atoms contain unpaired electrons that can\u2019t pair up to make a stable bond. Such a molecule is highly unstable because the unpaired electrons tend to react with anything around them. \u201cAs soon as you synthesize it, it will oxidize,\u201d says Niko Pavli\u010dek, a member of the IBM team. So far, the closest conventional synthesis has come to making molecules of this sort involves buffering the reactive edges with bulky hydrocarbon appendages 2 . The IBM team turned to a  scanning probe microscope , which has a needle-sharp tip that \u2018feels\u2019 a material\u2019s shape. The technique is usually used to image molecules, by measuring attractive forces between the tip and sample, or the electric currents that pass between them. The IBM team has demonstrated 3  that, if the tip has a small molecule such as carbon monoxide attached to it,  force microscopy  can provide images of such high resolution that they resemble the ball-and-stick diagrams of chemistry textbooks.\u00a0 Gross\u2019s team has already shown how the microscope can be used to direct the course of chemical reactions and make unstable 'intermediate' molecules 4 . To produce triangulene, the team began with a precursor molecule called dihydrotriangulene, which lacks the reactive unpaired electrons. The precursors were synthesized by chemists at the University of Warwick in Coventry, UK. The researchers deposited these molecules on a surface \u2014 salt, solid xenon and copper are all suitable \u2014 and inspected them under the microscope. They then used two successive voltage pulses from the tip, carefully positioned above the molecules, to blast off two hydrogen atoms and create the unpaired electrons. The work is published in  Nature Nanotechnology 1 . The team then imaged the products with the microscope, first picking up a carbon monoxide molecule to acquire the high resolution. The images had the shape and symmetry predicted for triangulene. Under the high-vacuum, low-temperature conditions of the experiments, the molecules remained stable for as long as the researchers looked. \n               Quantum applications \n             \u201cTo my knowledge, this is the first synthesis of unsubstituted triangulene,\u201d says chemist Takeji Takui of Osaka City University in Japan, who has previously synthesized triangulene-type molecules 2 . Moriarty calls the work elegant, but is surprised that triangulene remained stable on a copper surface, where he might have expected it to react with the metal. In one set of experiments, says Pavli\u010dek, the molecule was still sitting on the copper four days after the team made it. The researchers also probed triangulene\u2019s magnetic properties. They found that, as they had expected, the two unpaired electrons have aligned spins \u2014 the quantum-mechanical property that gives electrons a magnetic orientation. This property could make triangulene useful in electronics, they say. Takui agrees, and foresees applications in quantum computing, quantum information processing and a field known as spintronics, in which devices manipulate electron spins to encode and process information. Making molecules one at a time might not seem very promising, but Gross points out that current  quantum computers , such as the  Quantum Experience developed at IBM , use only a handful of quantum bits, or qubits, each of which could correspond to a single molecule. Even if you need to make 100 such molecules \u201cby hand\u201d, he says, \u201cit would be worth going through that manual labour\u201d. And although it\u2019s not clear how easily the approach could be applied to molecules that aren\u2019t flat, Gross says that such atom manipulation can be performed for 3D molecules to some extent. Even with triangulene and related graphene-like fragments, \u201cthere\u2019s a lot of exciting science still to be done\u201d, says Moriarty. The IBM team \u201ccontinues to set a high bar for the rest of us\u201d, he adds. \n                     Two techniques unite to provide molecular detail 2013-Jun-05 \n                   \n                     Feeling the shapes of molecules 2010-Aug-01 \n                   \n                     Living cells get nanosurgery 2004-Dec-13 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21466", "url": "https://www.nature.com/articles/nature.2017.21466", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Coalition of scientists and research agencies argue for a one-stop shop server. Life scientists keen to share their findings online before peer review are spoilt for choice. Whereas physicists gravitate to one repository \u2014 the \u2018preprint\u2019 server\u00a0 arXiv  \u2014 life sciences has a fast-growing roster of venues for preprints. There\u2019s the biology-focused bioRxiv, and a biology section on arXiv too. But other sites have sprouted up in the past year, or soon will do, and these too provide opportunities for life sciences: ChemRxiv for chemistry, psyArXiv for psychology; even AgriXiv for agricultural sciences and paleorXiv for palaeontology. Now, a coalition of biomedical funders and scientists is throwing its weight behind a \u2018one-stop shop\u2019 for all life-sciences preprints \u2014 a move that its backers argue should clarify any confusion and make it easier to mine the preprint literature for insights. On 13 February, ASAPbio, a  grassroots group of biologists that advocates for preprints ,  issued a funding call  to build a central preprint site; the US National Institutes of Health (NIH), the Wellcome Trust and several other leading funders  announced their support  for the concept.\u00a0 \u201cThe landscape could become fragmented very quickly,\u201d says Robert Kiley, head of digital services at the London-based Wellcome Trust. \u201cWe want to find a way of ensuring that, although this content is distributed far and wide, there\u2019s a central place that brings it all together\u201d. The details of the service are inchoate: its scope will depend on specific scientific fields and their funders, says Jessica Polka, the director of ASAPbio. But as well as aggregating content from other biology-focused preprint sites, ASAPbio wants the site to mesh with arXiv and with ChemRxiv, which the American Chemical Society in Washington DC  plans to launch soon .\u00a0 \n               All your preprints here \n             Proponents hope that a central site will lure biologists to embrace the practice as wholeheartedly as physical scientists have. Physics manuscripts routinely appear at arXiv.org months before publication in peer-reviewed journals, as researchers race to release their findings online before their rivals. And preprints are now accepted currency in determining priority for a discovery, as well as in winning grants and jobs. ArXiv handles more than 100,000 manuscripts each year in physics, mathematics and computer science.\u00a0(The largest life-sciences preprint server, bioRxiv, posted around 5,000 manuscripts in 2016.) \u201cOne of the lessons of arXiv is that users prefer \u2018one-stop shopping\u2019,\u201d says Paul Ginsparg, a theoretical physicist at Cornell University in Ithaca, New York, who founded the site in 1991. He could see a preprint aggregation site for life sciences working just as well, so long as disparate sites can agree on uniform technical standards. A central preprint service could also help scientists to use automated software to mine the literature for insights, says Ron Vale, a cell biologist at the University of California, San Francisco, and a founder of ASAPbio. At the moment, researchers who want to mine peer-reviewed papers face myriad hurdles, from publisher copyrights to disparate websites that make bulk-downloading difficult. \u201cWe\u2019re trying to think of preprints as data,\u201d says Vale. It would be both technically and legally straightforward for computers to crawl the collection of preprints on the central site, where they would appear under an open-access licence. Polka would not say how much ASAPbio expects the site to cost, but arXiv funding totals about US$925,000 a year, paid for by a global collective of more than 200 research institutions and funders; a large donation has come from the Simons Foundation, a private organization based in New York City. Ginsparg says expenses for the life-sciences site should be around $5 a manuscript, once it is publishing tens of thousands of manuscripts each year. Funders who support the site have not yet committed to paying for it, but Kiley expects that funders will do so once details are hashed out. Other funders that have come out in support of the central service include the UK Medical Research Council, the Howard Hughes Medical Institute (HHMI), the Canadian Institutes of Health Research and the European Research Council. \u201cThat\u2019s going to send a strong message to the science community that this kind of communication is encouraged,\u201d says Vale. Last month, the HHMI announced that it would consider preprints in deciding whether or not to renew the prestigious five-year grants it gives to investigators. \n               Cultural challenge \n             Jason Hoyt, chief executive of the journal  PeerJ  (which also operates a preprint service), says he supports a central preprint site and that his company might bid to help create it. But such a site will succeed only if it can induce a large proportion of life scientists to view preprints as the dominant currency for career progression, he says. \u201cThe challenge is to overturn the thinking in biology.\u201d ASAPbio and the funders supporting a central preprint service emphasize that it\u2019s no replacement for peer-reviewed journals. They note that the vast majority (over 80% in some fields) of arXiv posts wind up in journals.\u00a0\u201cWe really see this as a complement to the journal system, rather than anything that could be threatening,\u201d says Polka, who adds that a central service will not attempt to organize peer review. That would be a missed opportunity, says Rebecca Lawrence, managing director of London-based  F1000Research , which posts papers before they are peer reviewed at the journal (but does not consider these preprints). She would like to see peer review occur through a central preprint service, thereby reducing the influence that traditional journals have on scientists\u2019 careers. \u201cIt\u2019s a great shift in the right direction,\u201d Lawrence says, \u201cbut I think we need to go a lot further.\u201d Ginsparg ultimately envisions a \"federated repository\" that spans scientific disciplines and aggregates preprints from arXiv and other fields, including the life sciences. \u201cTwenty-five years ago, I thought we\u2019d be much closer to that point by now, but I still think it\u2019s inevitable,\u201d he says. \n                     When a preprint becomes the final paper 2017-Jan-20 \n                   \n                     Big biology projects warm up to preprints 2016-Nov-30 \n                   \n                     Chemists to get their own preprint server 2016-Aug-11 \n                   \n                     ArXiv preprint server plans multimillion-dollar overhaul 2016-Jun-29 \n                   \n                     Biologists urged to hug a preprint 2016-Feb-16 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21487", "url": "https://www.nature.com/articles/nature.2017.21487", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Maximum-security biolab is part of plan to build network of BSL-4 facilities across China. Wuhan, China A laboratory in Wuhan is on the cusp of being cleared to work with the world\u2019s most dangerous pathogens. The move is part of a plan to build between five and seven biosafety level-4 (BSL-4) labs across the Chinese mainland by 2025, and has generated much excitement, as well as some concerns. Some scientists outside China worry about pathogens escaping, and the addition of a biological dimension to geopolitical tensions between China and other nations. But Chinese microbiologists are celebrating their entrance to the elite cadre empowered to wrestle with the world\u2019s greatest biological threats. \u201cIt will offer more opportunities for Chinese researchers, and our contribution on the BSL\u20114-level pathogens will benefit the world,\u201d says George Gao, director of the Chinese Academy of Sciences Key Laboratory of Pathogenic Microbiology and Immunology in Beijing. There are already two BSL-4 labs in Taiwan, but the National Bio-safety Laboratory, Wuhan, would be the first on the Chinese mainland. The lab was certified as meeting the standards and criteria of BSL-4 by the China National Accreditation Service for Conformity Assessment (CNAS) in January. The CNAS examined the lab\u2019s infrastructure, equipment and management, says a CNAS representative, paving the way for the Ministry of Health to give its approval. A representative from the ministry says it will move slowly and cautiously; if the assessment goes smoothly, it could approve the laboratory by the end of June. BSL-4 is the highest level of biocontainment: its criteria include filtering air and treating water and waste before they leave the laboratory, and stipulating that researchers change clothes and shower before and after using lab facilities. Such labs are often controversial. The first BSL-4 lab in Japan was built in 1981, but operated with lower-risk pathogens until 2015, when  safety concerns were finally overcome . The expansion of BSL-4-lab networks in the  United States  and  Europe  over the past 15\u00a0years \u2014 with more than a dozen now in operation or under construction in each region \u2014 also met with resistance, including questions about the need for so many facilities. The Wuhan lab cost 300 million yuan (US$44 million), and to allay safety concerns it was built far above the flood plain and with the capacity to withstand a magnitude-7 earthquake, although the area has no history of strong earthquakes. It will focus on the control of emerging diseases, store purified viruses and act as a World Health Organization \u2018reference laboratory\u2019 linked to similar labs around the world. \u201cIt will be a key node in the global biosafety-lab network,\u201d says lab director Yuan Zhiming. The Chinese Academy of Sciences approved the construction of a BSL-4 laboratory in 2003, and the epidemic of SARS (severe acute respiratory syndrome) around the same time lent the project momentum. The lab was designed and constructed with French assistance as part of a 2004 cooperative agreement on the prevention and control of emerging infectious diseases. But the complexity of the project, China\u2019s lack of experience, difficulty in maintaining funding and long government approval procedures meant that construction wasn\u2019t finished until the end of 2014. The lab\u2019s first project will be to study the BSL-3 pathogen that causes Crimean\u2013Congo haemorrhagic fever: a deadly tick-borne virus that affects livestock across the world, including in northwest China, and that can jump to people. Future plans include studying the pathogen that causes SARS, which also doesn\u2019t require a BSL-4 lab, before moving on to Ebola and the West African Lassa virus, which do. Some one million Chinese people work in Africa; the country needs to be ready for any eventuality, says Yuan. \u201cViruses don\u2019t know borders.\u201d Gao travelled to Sierra Leone during the recent Ebola outbreak, allowing his team to report the speed with which the virus mutated into new strains 1 . The Wuhan lab will give his group a chance to study how such viruses cause disease, and to develop treatments based on antibodies and small molecules, he says. The opportunities for international collaboration, meanwhile, will aid the genetic analysis and epidemiology of emergent diseases. \u201cThe world is facing more new emerging viruses, and we need more contribution from China,\u201d says Gao. In particular, the emergence of zoonotic viruses \u2014 those that jump to humans from animals, such as SARS or Ebola \u2014 is a concern, says Bruno Lina, director of the VirPath virology lab in Lyon, France. Many staff from the Wuhan lab have been training at a BSL-4 lab in Lyon, which some scientists find reassuring. And the facility has already carried out a test-run using a low-risk virus. But worries surround the Chinese lab, too. The SARS virus has escaped from high-level containment facilities in Beijing multiple times, notes Richard Ebright, a molecular biologist at Rutgers University in Piscataway, New Jersey. Tim Trevan, founder of CHROME Biosafety and Biosecurity Consulting in Damascus, Maryland, says that an open culture is important to keeping BSL-4 labs safe, and he questions how easy this will be in China, where society emphasizes hierarchy. \u201cDiversity of viewpoint, flat structures where everyone feels free to speak up and openness of information are important,\u201d he says. Yuan says that he has worked to address this issue with staff. \u201cWe tell them the most important thing is that they report what they have or haven\u2019t done,\u201d he says. And the lab\u2019s inter\u00adnational collaborations will increase openness. \u201cTransparency is the basis of the lab,\u201d he adds. The plan to expand into a network heightens such concerns. One BSL-4 lab in Harbin is already awaiting accreditation; the next two are expected to be in Beijing and Kunming, the latter focused on using monkey models to study disease. Lina says that China\u2019s size justifies this scale, and that the opportunity to combine BSL-4 research with an abundance of research monkeys \u2014  Chinese researchers face less red tape than those in the West  when it comes to research on primates \u2014 could be powerful. \u201cIf you want to test vaccines or antivirals, you need a non-human primate model,\u201d says Lina. But Ebright is not convinced of the need for more than one BSL-4 lab in mainland China. He suspects that the expansion there is a reaction to the networks in the United States and Europe, which he says are also unwarranted. He adds that governments will assume that such excess capacity is for the potential development of bioweapons. \u201cThese facilities are inherently dual use,\u201d he says. The prospect of ramping up opportunities to inject monkeys with pathogens also worries, rather than excites, him: \u201cThey can run, they can scratch, they can bite.\u201d Trevan says China\u2019s investment in a BSL-4 lab may, above all, be a way to prove to the world that the nation is competitive. \u201cIt is a big status symbol in biology,\u201d he says, \u201cwhether it\u2019s a need or not.\u201d \n                 Tweet \n                 Follow @NatureNews \n               Editors\u2019 note, March 2020  We are aware that this story is being used as the basis for unverified theories that the novel coronavirus causing COVID-19 was engineered. There is no evidence that this is true; scientists believe that an animal is the most likely source of the coronavirus. \n                     Ebola spurs creation of Japan's first maximum-security biolab 2015-Aug-13 \n                   \n                     European biosafety labs set to grow 2009-Nov-11 \n                   \n                     Booming biosafety labs probed 2009-Sep-30 \n                   \n                     Nature  special: Ebola epidemic \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21519", "url": "https://www.nature.com/articles/nature.2017.21519", "year": 2017, "authors": [{"name": "Barbara Casassus"}, {"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Paris consortium hopes to lure UK institutions with promise of access to European research funds after Brexit. A consortium of academic institutes near Paris is hoping to lure British universities to create research campuses in France, dangling as bait the possibility of access to European Union research funds after Brexit. Some UK institutions aren\u2019t ruling out the idea. But a rush to create outposts in France seems unlikely for the moment, one UK policy expert thinks \u2014 largely because it\u2019s still too unclear what British institutes will lose from Brexit, and what they would gain by moving campuses to Europe. British newspapers splashed headlines on the plan this week, which was floated by the 'University Paris Seine\u2019 consortium, a cluster of 15 academic institutions at Cergy-Pointoise, about 40 kilometres north-west of Paris. It has earmarked \u20ac200 million (US$210 million) for a planned expansion by 2020, including three new facilities. On 14 February it  press-released  a direct overture to UK universities to join the cluster \u201cat a time when Brexit brings uncertainty over the academic relations between British higher education institutions and their European partners\u201d. Universities have five months to send in preliminary ideas. Simple geographical proximity could help French and British scientists work more effectively if Brexit makes existing research ties harder to maintain, says Jean-Michel Blanquer, dean of the ESSEC Business School, which is part of the consortium. But the thought that Brexit might leave UK scientists unable to apply for funds in European research programmes is the main point of the appeal. The idea is that a UK institution's overseas campus would be registered under French law, potentially making it eligible for EU funds \u2014 although their use might be restricted to the staff on the French campus and not include those back in Britain. \u201cThe fact that our UK partners would be registered in France could make it easier to obtain EU funds for our joint projects after Brexit,\u201d Blanquer says. He and Fran\u00e7ois Germinet, president of the University of Cergy-Pontoise (another of the 15 institutions in the Paris Seine consortium), have been to the United Kingdom to discuss the idea informally with institutions including Oxford and Warwick universities. \u201cWe wanted to test the waters and make sure that our idea was not considered absurd,\u201d says Germinet. \u201cMy contacts didn\u2019t say they would definitely come to Paris, but they said our idea was very, very good and corresponded exactly to their reflection on how to position themselves rapidly for a post-Brexit Europe,\u201d he adds. \n             No European rush yet \n           After the media attention, the University of Oxford quickly poured cold water on the idea. \u201cWe have received constructive & helpful proposals from EU colleagues since the Brexit vote. We are not, however, pursuing a campus overseas,\u201d a spokesperson wrote on Twitter.\u00a0 The University of Warwick released a statement saying only that it was \u201cinterested to see\u201d how the Paris consortium plans evolve \u201cand how they might also involve partner universities from across Europe\u201d. Nick Hillman, director of the Oxford-based think tank the Higher Education Policy Institute, says it\u2019s very unlikely that UK universities will rush to build European campuses. At the moment there is huge uncertainty over the possibility of accessing European research funding after Brexit, coupled with domestic confusion around proposed sweeping policy changes to UK higher education. \u201cNobody really knows what Brexit means yet. It would be very odd to get a decision at a time of uncertainty to invest what could be tens of millions abroad,\u201d he says. For instance, it is not clear whether simply having a foreign campus would allow a UK institution access to EU research funds. \u201c The other question is: if you were going to do it, would you do it in France?\u201d Hillman says. At French universities, staff are civil servants and courses have to be signed off by the government \u2014 which Hillman thinks would not sit well with the independence traditionally enjoyed by UK universities. Still, Blanquer says that since last week\u2019s call for proposals the consortium has received e-mails from four other UK universities expressing an interest in the idea and asking for more information. He declined to identify them. \n                   Delay in hiring science advisers intensifies Brexit worries 2017-Feb-20 \n                 \n                   Brexit vote drives UK academics to think about leaving 2017-Jan-09 \n                 \n                   Scientists should not resign themselves to Brexit 2017-Jan-04 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21512", "url": "https://www.nature.com/articles/nature.2017.21512", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "The Earth-sized astronomical bounty circles a dim star that flew under the radar of exoplanet researchers. Seven alien, Earth-sized worlds bask in the cool, red light of their parent star. The planetary menagerie exists around a star overlooked by other exoplanet hunters, although it is just 12 parsecs (39 light years) from Earth. Astronomers have found other seven-planet systems before, but this is the first to have so many Earth-sized worlds. All of them orbit at the right distance to possibly have liquid water somewhere on their surfaces. \u201cTo have this system of seven is really incredible,\u201d says Elisa Quintana, an astrophysicist at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland. \u201cYou can imagine how many nearby stars might harbour lots and lots of planets.\u201d Some of the planets were announced last year, but the authors debuted five newfound ones in a paper published on 22 February in  Nature 1 . Because the system is so close to Earth, astronomers can study the planets\u2019 atmospheres relatively easily. That could reveal an astonishing diversity of worlds, ranging in composition from rocky to icy. \u201cThis system is going to be one of the best laboratories we have for understanding the evolution of small planets,\u201d says Zachory Berta-Thompson, an astronomer at the University of Colorado Boulder. It\u2019s also vindication for astronomers who hunt for planets  around the cool, dim stars known as M dwarfs . These are the most common type of star in the Milky Way, but many exoplanet searches have focused instead on bigger and brighter stars that more closely resemble the Sun. Even NASA\u2019s Kepler space telescope, which found most of the more than 4,700 planetary candidates known so far,  turned to M dwarfs only recently . \u201cThese small stars had been completely overlooked,\u201d says Micha\u00ebl Gillon, an astronomer at the University of Li\u00e8ge in Belgium. \n             Magnificent seven \n           Gillon leads the TRAPPIST collaboration, which hunts for planets using two 60-centimetre telescopes: one in Chile and one in Morocco. They look for the faint dimming of a star\u2019s light that occurs when a planet moves across its face. The team initially reported three planets around the star, known as TRAPPIST-1, last May 2 . The team had caught only two glimpses of one of those planets, so they followed up on the faint signals with other telescopes. That process included 20 consecutive days when NASA\u2019s Spitzer Space Telescope stared at the star. The resulting data revealed that what the scientists thought was a single planet was actually four that orbit their star roughly every 4, 6, 9 and 12 days. Those four joined the two innermost planets, which whirl around the star once every 1.5 days and 2.4 days. The team also caught a hint of a seventh, more distant planet. Gillon says that the six inner planets probably formed farther away from their star and then migrated inward. Now, they are so close to each other that their gravitational fields interact, nudging one another in ways that enabled the team to estimate each planet's mass. They range from around 0.4 to 1.4 times the mass of the Earth. \n             Closing in \n           The arrangement of so many Earth-sized planets so close together will be a bonanza for researchers who are working to compare how worlds evolve. Venus and Earth started out in similar conditions, but ended up in two highly different states; uninhabitable Venus is now choked under a dense blanket of clouds. The TRAPPIST-1 system probably has a similar variety of worlds. \u201cIf one of these planets hosts life and the adjacent one doesn't, why not?\u201d asks Sarah Ballard, an astronomer at the Massachusetts Institute of Technology (MIT) in Cambridge. \u201cThis is a Rosetta stone with seven different languages \u2014 seven different planets that can provide us with completely different perspectives on planet formation,\u201d adds team member Julien de Wit, a data scientist at MIT. Although at least some fraction of each planet could harbor liquid water, it doesn't necessarily follow that they are habitable. TRAPPIST-1 emits about the same amount of X-ray and ultraviolet radiation as the Sun does, which could chew away at any protective atmospheres the planets might have 3 . And the worlds are likely locked into orbits where the same hemisphere always faces the star, rendering them permanently half-lit and half-dark. That would make it much more challenging for life to thrive. Other researchers are already using the Hubble Space Telescope to hunt for atmospheres on the TRAPPIST-1 planets. Kepler is also observing the system and will gather data that can better pin down the planetary masses, says Courtney Dressing, an astronomer at the California Institute of Technology in Pasadena. And the TRAPPIST team is building four new 1-metre-diameter telescopes in Chile to continue the work. \u201cFor all the worlds that we see in science fiction, these are even more extraordinary,\u201d says Hannah Wakeford, an exoplanet scientist at Goddard. \n                   Kepler finds scores of planets around cool dwarf stars 2016-Oct-21 \n                 \n                   Wind may deflate search for habitable planets 2014-Jun-02 \n                 \n                   Earth-sized exoplanet spotted in star\u2019s habitable zone 2014-Apr-17 \n                 \n                   Astronomers revisit dwarf stars\u2019 promise 2013-Oct-29 \n                 \n                   TRAPPIST \n                 \n                   The TRAPPIST-1 system \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21535", "url": "https://www.nature.com/articles/nature.2017.21535", "year": 2017, "authors": [{"name": "Nisha Gaind"}], "parsed_as_year": "2006_or_before", "body": "By 2030, nation\u2019s girls can expect to live to 91, says statistical analysis. South Korea is likely to become the first country where life expectancy will exceed 90 years, according to a study in  The Lancet 1 . Researchers led by public-health researcher Majid Ezzati at Imperial College London have projected how life expectancy will change in 35 developed countries by 2030, using data from the World Health Organization and a suite of 21 statistical models they developed. Life expectancy is expected to increase in all 35 countries, in keeping with steady progress in recent decades, the team found. But it is South Korean women who will be living longest by 2030: there is a nearly 60% chance that their life expectancy at birth will exceed 90 years by that time, the team calculates. Girls born in the country that year can expect to live, on average, to nearly 91, and boys to 84, the highest in the world for both sexes (see 'Ageing populations'). The nation's rapid improvement in life expectancy \u2014 the country was ranked twenty-ninth for women in 1985 \u2014 is probably down to overall improvements in economic status and child nutrition, the study notes, among other factors. South Koreans also have relatively equal access to health care, lower blood pressure than people in Western countries and low rates of smoking among women. But gains in longevity around the world will put pressure on health-care systems and pensions and could push up retirement ages, the authors suggest. One surprise of the study is the poor performance of the United States, the authors say. Life expectancy there already lags behind that of other developed nations, and is predicted to be among the lowest of these countries by 2030. It will lengthen by only\u00a0a couple of years, to 80 for men (similar to the Czech Republic) and 83 for women (similar to Mexico). Deepening inequalities in society and a lack of universal health care, as well as high child mortality and murder rates, are among the key culprits. Reprints and Permissions"},
{"file_id": "nature.2017.21474", "url": "https://www.nature.com/articles/nature.2017.21474", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Modified human embryos should be allowed if researchers meet strict criteria, says long-awaited National Academies report. Scientists should be permitted to modify human embryos destined for implantation in the womb to eliminate devastating genetic diseases such as sickle-cell anaemia or cystic fibrosis \u2014 once gene-editing techniques advance sufficiently for use in people and proper restrictions are in place. That\u2019s the conclusion of a 14 February  report  from the US National Academies of Science, Engineering, and Medicine.\u00a0 The 261-page document follows a 2015 National Academies summit that brought together scientists, ethicists, legal experts and patient groups from around the world. Meeting organizers wanted to  survey concerns about human germline editing : genetic modifications to embryos, sperm or egg cells that can be passed on to offspring. Given the raft of scientific, ethical and legal questions surrounding the issue, the  organizers concluded  at the time that scientists shouldn\u2019t yet perform germline editing on embryos intended for establishing a pregnancy. But they decided that altering human embryos in the lab for the sake of basic research was acceptable. The latest report builds on the earlier consensus and outlines strict limits under which scientists could proceed in the future. It recommends restricting the technique to severe medical conditions for which no other treatment exists. It also calls for international cooperation, strict regulatory and oversight framework, public input into decisions and long-term follow-ups of  children who have edited genomes . The report adds that for now, genome editing should not be used for human enhancement, such as improving a person\u2019s intelligence or giving them super-strength. \n             Managing the inevitable \n           Scientific advances are making genetically modified babies more of a possibility, says Alta Charo, a bioethicist at the University of Wisconsin\u2013Madison and co-chair of the report. Over the past year, she says, researchers have made progress in understanding and preventing the ways in which genome-editing techniques such as CRISPR cause unintended mutations \u2014 a necessary step before using such methods in human embryos. \u201cUp until now, we\u2019ve been talking only hypothetically and most people assumed we simply wouldn\u2019t ever do this,\u201d Charo says. \u201cWe are not saying that you have to or you should, but we are saying that if you can meet these criteria it is permissible.\u201d In part, the National Academies\u2019 recommendations are trying to pre-empt the inevitable. \u201cWe are very much aware that medical tourism is a fact of global life now,\u201d Charo says. Once human genome editing has proved to be effective, clinicians working in countries with few regulations and potentially unsafe conditions may begin modifying embryos and implanting them in patients. \u201cWe certainly don't want to see the same thing\u201d in the United States, Charo says, \u201cand a prohibition might exacerbate the problem.\u201d \n             The green light \n           For those who oppose any human germline editing, the NASEM report is a step back. \u201cIt's disappointing that the National Academies would take such a duplicitous position,\u201d says David Prentice, vice-president and research director of the anti-abortion, non-profit Charlotte Lozier Institute in Washington DC. \u201cIf there are ethical reasons not to allow most germline editing, those same reasons apply to any germline editing.\u201d George Church, a geneticist at Harvard University in Cambridge, Massachusetts, agrees that it may be difficult to draw the line between medical use and enhancement. For instance, researchers have shown that a gene called  GRIN2B  is one of many linked to autism spectrum disorder 1 . But mutations that increase the amount of GRIN2B protein produced in the body have also been connected to higher cognitive abilities 2 . Modifying the gene to prevent autism could end up enhancing recipients compared to the general population, Church says. But the geneticist thinks the recommendations are sensible. And he says that they follow the normal path for drug approval, in which a therapy is tested and perfected in compelling medical cases before being used for non-medical reasons. Church is glad that the academies and numerous other organizations are tackling the issue now. \u201cThe time to get everybody worked up about it is right now, before safety and efficacy are even proven,\u201d he says. \u201cAs soon as they\u2019re proven, it\u2019s very hard to deny it to people.\u201d \n                   Should you edit your children\u2019s genes? 2016-Feb-23 \n                 \n                   Gene-editing summit supports some research in human embryos 2015-Dec-03 \n                 \n                   Human-genome editing summit to sample global attitudes 2015-Nov-30 \n                 \n                   Genome editing: 7 facts about a revolutionary technology 2015-Nov-30 \n                 \n                   National Academies Consensus Study: Human Genome Editing: Science, Ethics, and Governance \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21485", "url": "https://www.nature.com/articles/nature.2017.21485", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "DNA of 500-year-old bacteria is first direct evidence of an epidemic \u2014 one of humanity's deadliest \u2014 that occurred after Spanish conquest. One of the worst epidemics in human history, a sixteenth-century pestilence that devastated Mexico\u2019s native population, may have been caused by a deadly form of salmonella from Europe, a pair of studies suggest. In one study, researchers say they have recovered DNA of the stomach bacterium from burials in Mexico linked to a 1540s epidemic that killed up to 80% of the country's native inhabitants. The team reports its findings in a preprint posted on the bioRxiv server on 8 February 1 . This is potentially the first genetic evidence of the pathogen that caused the massive decline in native populations after European colonization, says Hannes Schroeder, an ancient-DNA researcher at the Natural History Museum of Denmark in Copenhagen who was not involved in the work. \u201cIt\u2019s a super-cool study.\u201d \n               Dead bodies and ditches \n             In 1519, when forces led by Spanish conquistador Hernando Cort\u00e9s arrived in Mexico, the native population was estimated at about 25 million. A century later, after a Spanish victory and a series of epidemics, numbers had plunged to around 1 million. The largest of these disease outbreaks were known as  cocoliztli  (from the word for \u2018pestilence\u2019 in Nahuatl, the Aztec language). Two major  cocoliztli , beginning in 1545 and 1576, killed an estimated 7 million to 18 million people living in Mexico\u2019s highland regions. \u201cIn the cities and large towns, big ditches were dug, and from morning to sunset the priests did nothing else but carry the dead bodies and throw them into the ditches,\u201d noted a Franciscan historian who witnessed the 1576 outbreak. There has been little consensus on the cause of  cocoliztli  \u2014 although measles, smallpox and typhus have all been mooted. In 2002, researchers at the National Autonomous University of Mexico (UNAM) in Mexico City proposed that a viral haemorrhagic fever, exacerbated by a catastrophic drought, was behind the carnage 2 . They compared the magnitude of the 1545 outbreak to that of the Black Death in fourteenth-century Europe.\u00a0 \n               Bacterial genomics \n             In an attempt to settle the question, a team led by evolutionary geneticist Johannes Krause at the Max Planck Institute for the Science of Human History in Jena, Germany, extracted and sequenced DNA from the teeth of 29 people buried in the Oaxacan highlands of southern Mexico. All but five were linked to a  cocoliztli  that researchers think ran from 1545 to 1550. Ancient bacterial DNA recovered from several of the people matched that of  Salmonella , based on comparisons with a database of more than 2,700 modern bacterial genomes. Further sequencing of short, damaged DNA fragments from the remains allowed the team to reconstruct two genomes of a  Salmonella enterica  strain known as Paratyphi C. Today, this bacterium causes enteric fever, a typhus-like illness, that occurs mostly in developing countries. If left untreated, it kills 10\u201315% of infected people. It\u2019s perfectly reasonable that the bacterium could have caused this epidemic, says Schroeder. \u201cThey make a really good case.\u201d But Mar\u00eda \u00c1vila-Arcos, an evolutionary geneticist at UNAM, isn't convinced. She notes that some people suggest that a virus caused the  cocoliztli , and that wouldn't have been picked up by the team\u2019s method. \n               The question of origin \n             Krause and his colleagues\u2019 proposal is helped by another study posted on bioRxiv last week, which raises the possibility that  Salmonella  Paratyphi C arrived in Mexico from Europe 3 . A team led by Mark Achtman, a microbiologist at the University of Warwick in Coventry, UK, collected and sequenced the genome of the bacterial strain from the remains of a young woman buried around 1200 in a cemetery in Trondheim, Norway. It is the earliest evidence for the now-rare  Salmonella  strain, and proof that it was circulating in Europe, according to the study. (Both teams declined to comment on their research because their papers have been submitted to a peer-reviewed journal.) \u201cReally, what we\u2019d like to do is look at both strains together,\u201d says Hendrik Poinar, an evolutionary biologist at McMaster University in Hamilton, Canada. And if more ancient genomes can be collected from Europe and the Americas, it should be possible to find out more conclusively whether deadly pathogens such as  Salmonella  arrived in the New World from Europe. The existence of  Salmonella  Paratyphi C in Norway 300 years before it appeared in Mexico doesn\u2019t prove that Europeans spread enteric fever to native Mexicans, says Schroeder, but that hypothesis is reasonable. A small percentage of people infected with  Salmonella  Paratyphi C carry the bacterium without falling ill, so apparently healthy Spaniards could have infected Mexicans who lacked natural resistance. Paratyphi C is transmitted through faecal material, and a collapse of social order during the Spanish conquest might have led to the poor sanitary conditions that are ripe for  Salmonella  spread, Krause and his team note in the paper. Krause\u2019s study offers a blueprint for identifying the pathogens behind ancient outbreaks, says Schroeder. His own team plans to look for ancient pathogens in Caribbean burial sites that seem to be linked to catastrophic outbreaks, and that were established after the Europeans arrived. \u201cThe idea that some of them might have been caused by  Salmonella  is now a distinct possibility,\u201d he says. \n                     European diseases left their mark on First Nations' DNA 2016-Nov-15 \n                   \n                     Famous ancient iceman had familiar stomach infection 2016-Jan-07 \n                   \n                     Seals brought TB to Americas 2014-Aug-20 \n                   \n                     Ancient cholera mysteriously disappeared 2014-Jan-09 \n                   \n                     Plague genome: The Black Death decoded 2011-Oct-26 \n                   \n                     Plague genome: The Black Death decoded 2011-Oct-25 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21425", "url": "https://www.nature.com/articles/nature.2017.21425", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Distantly related plants acquired their ability to eat meat through similar genetic changes. Any insect unlucky enough to land on the mouth-like leaves of an Australian pitcher plant will meet a grisly end. The plant's prey is drawn into a vessel-like \u2018pitcher\u2019 organ where a specialized cocktail of enzymes digests the victim. Now, by studying the pitcher plant's genome \u2014 and comparing its insect-eating fluids to those of other carnivorous plants \u2014 researchers have found that meat-eating plants the world over have hit on the same deadly molecular recipe, even though they are separated by millions of years of evolution. \u201cWe\u2019re really looking at a classic case of convergent evolution,\u201d says Victor Albert, a plant-genome scientist at the University of Buffalo, New York, who co-led the study 1 , published in  Nature Ecology and Evolution  on 6 February. Carnivorous plants occur across the flowering-plant family tree. The Australian pitcher plant ( Cephalotus follicularis ) \u2014 native to a sliver of coastline in Southwest Australia \u2014 is closer kin to the starfruit ( Averrhoa carambola ) than to other species of pitcher plants found in the Americas and southeast Asia. This suggests that  carnivory has evolved repeatedly  in plants, probably to cope with the nutrient-scarce soils in which they grow, Albert says. \u201cWhat they\u2019re trying to do is capture nitrogen and phosphorus from their prey.\u201d \n             Deadly recipe \n           Australian pitcher plants produce deadly \u2018pitcher\u2019 leaves \u2014 which resemble a toothy grin \u2014 as well as flat leaves. After sequencing the species\u2019 genome, Albert\u2019s team identified genes that are activated differently between the pitcher-like leaves and the plant's other, non-carnivorous, leaves. These included genes involved in making starches and sugars that may help to produce the nectar that lures insects to their deaths, as well as genes encoding waxy substances that may make it hard to escape from the pitcher. To determine how pitchers eat their prey, the researchers sampled the digestive cocktail from  Cephalotus  and several other unrelated carnivorous plants and identified a total of 35 proteins, using mass spectrometry. Many of the proteins are related to those that other flowering plants use to  fend off pathogens 2 , 3 , 4 , 5 . For instance, plants typically produce enzymes that break down a polymer called chitin as a defence against fungi, which make their cell walls out of the chemical. But Albert suspects that Australian pitchers and other carnivorous plants have repurposed the enzyme to digest insect exoskeletons, which are also made of chitin. In the new analysis, Albert and his colleagues also found that in distantly related carnivorous plants, including species of pitcher plants, the genes deployed to make the digestive-fluid proteins have a common evolutionary origin. What\u2019s more, some of these genes have independently evolved to change the shape of the enzymes they encode in similar ways in the different species. The researchers don't have proof yet, but they think that the mutations might help to stabilize the enzymes when they are present together in digestive fluid. While researchers already appreciated the importance of convergent evolution for carnivorous plants, says Aaron Ellison, an ecologist at Harvard Forest in Petersham, Massachusetts, the new study is important because it demonstrates how this convergence can occur down to the molecular level, he says. Gaining the ability to eat an insect is of little use if a plant cannot first entrap one, and here evolution has come up with more diverse solutions, Albert notes. Venus fly-traps ensnare their prey, whereas bladderworts immobilize their victims using tiny suction cups. In his 1875 book  Insectivorous Plants , Charles Darwin included detailed drawings of the tentacles that sundews use to pin insects to their leaves. \"It's no wonder Darwin wrote an entire book on carnivorous plants,\u201d Albert says. \n                   Hungry plant traps worms underground 2012-Jan-09 \n                 \n                   Little lab of horrors 2008-Jan-31 \n                 \n                   Plant has taste for termites 2002-Jan-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21401", "url": "https://www.nature.com/articles/nature.2017.21401", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Physicists harness starlight to support the case for entanglement. A version of an iconic experiment to confirm quantum theory has for the first time used the light of distant stars to bolster the case for a phenomenon that Albert Einstein referred to as \u201cspooky action at a distance\u201d. Einstein disliked the notion that objects can share a mysterious connection across any distance of space, and scientists have spent the past 50 years trying to make sure that their results showing this quantum effect could not have been caused by more intuitive explanations. Quantum physics suggests that two so-called entangled particles can maintain a special connection \u2014 even at a large distance \u2014 such that if one is measured, that instantly tells an experimenter what measuring the other particle will show. This happens despite the fact neither particle has definite properties until it is measured. That unsettled some physicists, including Einstein, who favoured an alternative explanation: that quantum theory is incomplete, and that the outcomes instead depend on some predetermined, but hidden, variables. The latest effort to explore the phenomenon, to be published 1  in  Physical Review Letters  on 7 February, uses light emitted by stars around 600 years ago to select which measurements to make in a quantum experiment known as a Bell test. In doing so, they narrow down the point in history when, if they exist, hidden variables could have influenced the experiment. \u201cIt\u2019s a beautiful experiment,\u201d says Krister Shalm, a quantum physicist at the US National Institute of Standards and Technology (NIST) in Gaithersburg, Maryland. Although few expected it to disprove quantum mechanics, such experiments \u201ckeep pushing alternative theories to be more and more contrived and ridiculous\u201d, he says. Similar techniques could, in the future, help to protect against hackers who try to crack quantum-cryptography systems, he adds. \n             Closing loopholes \n           Physicists at the University of Vienna, along with colleagues in China, Germany and the United States, developed a new version of the Bell test \u2014 a protocol devised by the physicist John Bell in the 1960s to distinguish between two possible explanations for the seemingly strange behaviour of the quantum world. The test involves performing independent measurements on separated pairs of entangled quantum particles. Bell showed that, statistically, correlations between the results, once above a certain threshold limit, could not be explained by particles having hidden properties. Instead the coordinated outcomes seem to be the result of measurements on one particle mysteriously fixing the properties of the other. Although Bell tests have supported quantum theory many times, they include assumptions that leave wiggle room for non-quantum explanations, and physicists have been trying to close these \u2018loopholes\u2019 ever since. In 2015, they sealed a major victory when three separate teams, including Shalm\u2019s,  succeeded in simultaneously closing two major possible loopholes , by showing that entanglement could not be an illusion created by any speed-of-light communication between particles, or an artefact of only detecting certain photons 2 , 3 , 4 . \n             Freedom of choice \n           But they left open another loophole \u2014 one that is more subtle, and impossible to fully close, says Andrew Friedman, an astronomer at the Massachusetts Institute of Technology in Cambridge, and a co-author on the latest paper. Bell tests also assume that experimenters have free choice over which measurements they perform on each of the pair of photons. But some unknown effect could be influencing both the particles and what tests are performed (either by affecting choice of measurement directly, or more plausibly, by restricting the options that are available), to produce correlations that give the illusion of entanglement. To narrow this freedom-of-choice loophole, researchers have previously put 144 kilometres between the source of entangled particles and the random-number generator that they use to pick experimental settings 5 . The distance between them means that if any unknown process influenced both set-ups, it would have to have done so at a point in time before the experiment. But this only rules out any influences in the microseconds before: the latest paper sought to push this time back dramatically, by using light from two distant stars to determine the experimental settings for each photon. \u201cWe outsource the choice to the Universe itself,\u201d says Friedman. The team, led by physicist Anton Zeilinger at the University of Vienna, picked which properties of the entangled photons to observe depending on whether its two telescopes detected incoming light as blue or red. The colour is decided when the light is emitted, and does not change during travel. This means that if some unknown effect, rather than quantum entanglement, explains the correlation, it would have to have been set in motion at least around 600 years ago, because the closest star is 575 light-years (176 parsecs) away, says Friedman, who hopes to eventually push back this limit to billions of years ago by  doing the experiment with\u00a0 light from more distant quasars.  Their results found a level of correlation that supports \u2018action at a distance\u2019 1 . \n             Protection against hackers \n           Technically, the experiment is impressive, say Ronald Hanson, a quantum physicist at the Delft University of Technology in the Netherlands. But, unlike the loopholes closed in 2015, this one can never be fully closed; confining it to further in the past is only possible by making new assumptions \u2014 in this case, for example, by assuming that no one messed with the photons immediately before they hit the telescopes, he says. Others argue that although, fundamentally, the loophole is never closable, such experiments are valuable because new theories necessarily become more improbable and contrived, or eventually, end up assuming that everything in the Universe was determined at the time of the Big Bang \u2014 a philosophical view that most physicists reject. Reworking experiments to reduce and make better assumptions is therefore worthwhile, says Shalm. Such experiments also have practical value, argues Friedman, because if quantum mechanics turns out to be explained by a different underlying theory, that discovery could impact the security of technologies that rely on quantum theory, such as quantum encryption. And trying to close such loopholes is useful because minimizing the assumptions in an experiment serves to also beef up protection against hackers who might otherwise exploit them, says Shalm, whose team at the NIST is exploring whether Bell tests could be used in quantum cryptography. Harnessing cosmic phenomena is not the only way physicists are ensuring the independence of their measurement settings. In November, teams from around the world took part in  the Big Bell Test , which tapped 100,000 game-playing volunteers worldwide to create random sequences of 0s and 1s, which physicists used to fix their measurement settings. Preliminary analysis indicates that in this case, most \u2014 and possibly even all \u2014 of the experiments yet again supported quantum mechanics, says Morgan Mitchell at the Institute of Photonic Sciences (ICFO) in Barcelona, Spain, which coordinated the event. \u201cSorry, Einstein,\u201d he says. Reprints and Permissions"},
{"file_id": "nature.2017.21389", "url": "https://www.nature.com/articles/nature.2017.21389", "year": 2017, "authors": [{"name": "Lauren Morello"}, {"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Order barring citizens of seven countries from entering the United States has left many confused and afraid. Kaveh Daneshvar was thrilled when he was invited to speak at a molecular biology meeting next month in Banff, Canada. Daneshvar, a molecular geneticist, is finishing a postdoc at Harvard Medical School and Massachusetts General Hospital in Boston, and is preparing to go on the job market. He hoped that the conference talk would give him much-needed exposure to leaders in his field. But that now seems impossible: if Daneshvar, an Iranian citizen, leaves the country, he may not be able to return. On 27 January, US President Donald Trump signed a sweeping executive order that blocks refugees from entering the United States for 120 days and stops Syrian refugees indefinitely. It also bans citizens of seven majority-Muslim countries \u201ccompromised by terrorism\u201d \u2014 Iran, Iraq, Libya, Somalia, Sudan, Syria and Yemen \u2014 from entering the United States for 90 days. The US government has issued conflicting statements on whether the provisions apply to people such as Daneshvar who hold visas that would otherwise permit them to live, work or study in the United States \u2014 including those with the permanent resident visas known as green cards. Nature  spoke to more than 20 researchers affected by the new policy, who described their feelings of fear, shock and determination. Some asked to remain anonymous for fear of retaliation by the US government. \u201cI am really appreciative of what the US has given me and allowed me to achieve here, but at the same time this is really shocking,\u201d says Ali Shourideh, an economist at Carnegie Mellon University in Pittsburgh, Pennsylvania. \u201cI've always been under the assumption this is a free country, that once you immigrated they won't try to kick you out or make life hard for you.\u201d Shourideh, an Iranian citizen with a green card, has travelled to Iran several times recently to visit his mother, who has cancer. Now, if he leaves the United States, he may not be able to return. \u201cYou have to make a choice: do I want to see my mom or do I want to keep my job?\u201d he says. \u201cThis is something that for sure will hurt us personally, but also the US, I think, because all these high-skilled-type professionals would not want to be here anymore.\u201d \n               Legal challenge \n             On 28 January, the American Civil Liberties Union and other groups filed a lawsuit against the US government to overturn the order on behalf of two people with valid visas who were detained at US airports. Later that day, the group won a preliminary victory when a federal judge ruled that the government could not deport those detainees. But the ruling does not affect those who were not in transit when the ban took effect. Scientists have already begun to organize against the immigration policy. More than 12,000 researchers \u2014 including 40 Nobel prizewinners and 6 Fields medallists \u2014  have signed a petition denouncing Trump\u2019s actions . The American Association for the Advancement of Science and the Association of American Universities have put out statements urging the Trump administration to re-evaluate the ban. And universities have scrambled to understand how the US policy will affect their professors, postdocs, students and other employees from the seven banned countries. Many institutions are advising these people to stay in the United States until the situation becomes clearer. But that is little comfort to an Iranian engineering student at Wayne State University in Detroit, Michigan. The man has just bought a house with his wife, who is expecting their first child \u2014 a girl \u2014 next week. The couple were expecting their parents to come from Iran to visit the baby, but those plans are on hold. So are the green cards that the pair had expected to receive in April. Now they are contemplating whether to start anew in Australia, where they hold permanent residency cards that will expire in May. \u201cIf you leave, you can get your life back, your parents back, your family back \u2014 but you will lose anything you did here,\u201d the engineering student says. \u201cWe worked hard for this.\u201d \n               Waiting game \n             The sudden nature of the ban has thrown many researchers\u2019 professional lives into disarray. Luca Freschi, an Italian microbial geneticist at Laval University in Quebec, Canada, had planned to move to Harvard Medical School in March. But the US immigration ban has disrupted those plans, because his Iranian wife Maryam will not be able to come with him. She has encouraged Freschi to go without her. \u201cIt\u2019s crazy for us because we got the visa two days before the executive order was signed,\u201d he says. Another couple, both scientists, are stuck in France while they wait to learn whether the woman, an Iranian, will be able to travel to the United States. They are each set to start jobs at a US university in March. And the ban is already disrupting some international collaborations. Samira Samimi, an Iranian studying glaciology at the University of Calgary in Canada, was supposed to go to Greenland in April on a NASA-funded expedition to study snow melt. The team will depart from a US Air National Guard base in Schenectady, New York, aboard a LC-130 cargo plane to Kangerlussuaq, Greenland. But Samimi won\u2019t be able to cross the border to meet her colleagues in New York. And even if she purchased a commercial ticket to Greenland, she might not be allowed to fly on the cargo plane that will take the US team to its remote field sites. If Samimi can\u2019t get to Greenland to continue the research she started there last year, it could slow her progress towards a PhD. \u201cI thought I would be free in Canada,\u201d she says. \u201cI wouldn\u2019t have to fight for my rights anymore.\u201d Samimi\u2019s colleagues are exploring all options to get her on the ice. \u201cThis really upsets me,\u201d says Mike MacFerrin, a glaciologist at the University of Colorado Boulder who is helping to organize the expedition. \u201cNone of this is right.\u201d He adds: \u201cThere is no way this helps us or our science.\u201d \n               Seeking freedom \n             Some of those affected by the immigration shift suffered persecution in their home countries. Samimi, the glaciologist, was detained by Iranian police for the first time when she was 9, because she wore a T-shirt advertising the US rock band Bon Jovi. Later, she was held and questioned because she dyed her hair unacceptable colours and wore nail polish. Ubadah Sabbagh, a doctoral student in neuroscience at Virginia Tech in Blacksburg, is a Syrian citizen who moved to the United States seven years ago, aged 16, to attend university. Because he ignored an order to serve in the Syrian army, he cannot return home or renew his passport. Now he is worried about conditions in the United States. \u201cThis is not going to be a footnote in American history,\u201d Sabbagh says. \u201cWe could slip into a very dark place very quickly if people just decide to be indifferent.\u201d Then there is Amir Haji-Akbari, a computational statistical physicist from Iran, who won a plum assistant professor job at Yale University in New Haven, Connecticut, in 2016. The position offered welcome security after his years as a postdoc, and he began planning to apply for citizenship so that he could bring his elderly parents over from Iran. His wife, who is studying quantitative and computational biology at Princeton University in New Jersey, had invited her mother from Iran to watch her PhD defence in April. Now all of that seems impossible, says Haji-Akbari, who, as an ethnic Azeri and Sunni Muslim, faced discrimination in Iran. \u201cI have always found the tolerance and religious freedom better here,\u201d he says. \u201cWhy am I considered a threat? What have I done to you? I have been a second-class citizen in my own country, and now here you are treating me like garbage.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Trump agenda threatens US legacy of science diplomacy 2017-Jan-27 \n                   \n                     Geneticist launches bid for US Senate 2017-Jan-27 \n                   \n                     Scientists join massive protest against Trump 2017-Jan-22 \n                   \n                     Immigrant and minority scientists shaken by Trump win 2016-Nov-22 \n                   \n                     Trump\u2019s immigration stance stokes fears for science 2016-Apr-05 \n                   \n                     Nature  special: Tracking the Trump White House \n                   \n                     Academics' petition against the US immigration ban \n                   \n                     American Civil Liberties Union lawsuit \n                   \n                     Trump executive order on immigration \n                   Reprints and Permissions"},
{"file_id": "542018a", "url": "https://www.nature.com/articles/542018a", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "A movement to privatize Earth-observing satellites is gaining ground. A controversial push to expand the US government\u2019s use of commercial Earth-observing satellites is about to kick into high gear. Early next month, aerospace start-up Spire Global of Glasgow, UK, will send a mini-satellite into space aboard an Indian government rocket. This \u2018cubesat\u2019 will join 16\u00a0others that are beaming a new type of atmospheric data back to Earth \u2014 and some scientists worry that such efforts are siphoning funding away from efforts to push forward the science of weather forecasting. Spire will begin providing observations to the US government on 30\u00a0April. The probes track delays in radio signals from Global Positioning System (GPS) satellites as they pass through the atmosphere \u2014  a technique known as radio occultation . Researchers can use the data to create precise temperature profiles of the atmosphere to feed into weather-forecasting models \u2014 and eventually, perhaps, climate models. Spire and its competitor GeoOptics of Pasadena, California, are participating in a pilot project announced in September by the US National Oceanic and Atmospheric Administration (NOAA), which is under pressure from the US Congress to determine whether it can cut costs by using commercial weather data. But scientists  worry that such efforts are hampering the development of radio occultation . For years, they have sought federal funding for a project to advance the technique, but Spire and its competitors say they can offer high-quality data for a fraction of the price. \u201cWe are going to provide a lot more observations for less money, and that is how weather forecasts get better,\u201d says Alexander MacDonald, a former NOAA meteorologist who now leads Spire\u2019s modelling programme. Scientists at the University Corporation for Atmospheric Research (UCAR) in Boulder, Colorado, are poised to begin their own radio-occultation mission in September, when SpaceX of Hawthorne, California, will launch six small satellites into orbit over the tropics. This is the first phase of the Constellation Observing System for Meteorology, Ionosphere, and Climate-2 (COSMIC-2), which is funded by the US and Taiwanese governments. The US$420-million project seeks to provide the same measurements that the commercial sector is promising, although with much greater precision. But its second phase \u2014 the launch of polar-orbiting satellites to ensure global data coverage \u2014 has not been funded. \u201cI\u2019m supportive of getting more private companies to provide satellite information,\u201d says Bill Kuo, who directs COSMIC-2 at UCAR. \u201cBut so far we have not seen that the private sector can provide this data with the same level of quality and accuracy.\u201d Radio occultation has been used to study weather since 1995, when scientists at UCAR and NASA\u2019s Jet Propulsion Laboratory (JPL) in Pasadena launched a proof-of-concept mission. The first COSMIC satellites followed in 2006. Two are still feeding data into forecasting systems at NOAA and other meteorological agencies, as are a handful of other satellites. Kuo says that the increased sensitivity of COSMIC-2 will allow higher-quality measurements that extend through the moisture-rich lower atmosphere to Earth\u2019s surface. The goal is to determine how much those advanced data will improve forecasts, he says, but without the second set of satellites there will be coverage gaps at high latitudes. Weather forecasters around the world feed about 40\u00a0million environmental measurements into their models each day. Just 2,100 come from radio occultation, but those data have an oversized impact on overall accuracy, says Sean Healy, a senior scientist at the European Centre for Medium-Range Weather Forecasts in Reading, UK. Ideally, COSMIC-2 would provide global coverage, he says, but forecasters will take what they can get \u2014 including commercial data. GeoOptics expects to launch its first satellite later this year. Another firm, PlanetiQ of Boulder, will launch its first two spacecraft next year. Thanks to falling prices for microelectronics and space launches, these firms argue that the future of radio occultation \u2014 and potentially other types of Earth observation \u2014 rests with the commercial sector. \u201cWe can now put up a constellation of 12\u00a0satellites for $15 million,\u201d says Thomas Yunck, a former engineer at the JPL and founder of Geo-Optics. Yunck says that the data would become almost free if the various forecasting centres around the world shared the cost of operations. A looming question, however, is who will pay for the data. NOAA makes data from its weather satellites available at no cost, and agency officials have said that a World Meteorological Organization resolution would require them to do the same with commercial data that they receive. So far, the agency has offered Spire and GeoOptics contracts worth $370,000 and $695,000, respectively, for the delivery of initial data. The companies say that if NOAA were to purchase their data and give them away for free, it would have to pay enough to cover the firms\u2019 costs and ensure a profit. Or the companies could market the data independently to forecasting centres globally. Either way, they say, all researchers would have free access to the data. \u201cI don\u2019t consider this insurmountable,\u201d MacDonald says. \u201cIt\u2019s going to be in the interest of the governments and the private sector to work out a way to get it paid for.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @jefftollef \n               \n                     Private weather data should not replace basic research 2017-Feb-01 \n                   \n                     Satellite system tracks glaciers' flow in real time 2016-Dec-16 \n                   \n                     Warning to forest destroyers: this scientist will catch you 2016-Oct-04 \n                   \n                     Next generation of carbon-monitoring satellites faces daunting hurdles 2016-May-25 \n                   \n                     Satellites: Make Earth observations open access 2014-Sep-02 \n                   \n                     Microsatellites aim to fill weather-data gap 2012-Nov-28 \n                   \n                     Climate researchers warn of data crisis 2011-Oct-28 \n                   \n                     Earth Monitoring: Not enough eyes on the prize 2007-Dec-05 \n                   Reprints and Permissions"},
{"file_id": "542016a", "url": "https://www.nature.com/articles/542016a", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Neural networks produce pictures to train image-recognition programs and scientific software. Volcanoes, monasteries, birds, thistles: the varied images in Jeff Clune\u2019s  research paper  could be his holiday snaps. In fact, the pictures are synthetic. They are generated by  deep-learning neural networks : layers of computational units that mimic how neurons are connected in the brain. In recent years, neural networks have made huge strides in learning to recognize and interpret information in pictures, videos and speech. But now, computer scientists such as Clune are turning those artificial-intelligence (AI) systems on their heads to create \u2018generative\u2019 networks that churn out their own realistic-seeming information. \u201cI have reached a point in my life where I\u2019m kind of having reality vertigo,\u201d says Clune, who works at the University of Wyoming in Laramie. Generative systems also give an insight into how neural networks interpret the world, says Kyle Cranmer, a particle physicist and computer scientist at New York University. Although it\u2019s not clear how virtual neurons store and interpret information, the plausibility of the data they generate suggests that they have some handle on the real world. AI researchers are excited about using generative networks to train image-recognition software. More widely, Cranmer says, AIs that generate scientific data might help astronomers and other researchers to prune noise from large data sets, and so better understand patterns within them. \n               AI duel \n             In computer science, there\u2019s a particular buzz around a technique that sets a generative network in competition with an image-recognition network, to help both to improve their performance. These \u2018generative adversarial nets\u2019, or GANs, are \u201cthe coolest idea in deep learning in the last 20 years\u201d, said Yann LeCun \u2014 head of Facebook\u2019s AI team in New York City \u2014 in a talk at Carnegie Mellon University in Pittsburgh, Pennsylvania, last November. Typically, a neural network learns to discriminate between training images tagged by people, with descriptions such as \u2018Victorian house\u2019 or \u2018golden retriever\u2019. The training process tells the AI how to tweak connections between its virtual neurons, so that it can eventually tag images by itself \u2014 including new photos that were not part of the original training set. In a GAN, two neural networks train together with minimal outside help. One network, the generator, produces fake images; the other, the discriminator, tries to tell those fake images from real ones. After that, the discriminator checks which images were real and which were fake, so that it can get better at distinguishing between them. The generator never sees the real images \u2014 instead, the discriminator tells it how to tweak its output to make its pictures more like the real thing. \u201cYou can think of the discriminator as a teacher that tells the generator how to improve,\u201d says Ian Goodfellow, a computer scientist at the non-profit organization Open-AI in San Francisco, California. Or, to put it another way, the discriminator is like a banker who helps a counterfeiter learn how to forge money, he adds. Goodfellow came up with the idea of GANs in 2014, while he was a student of machine-learning pioneer Yoshua Bengio at the University of Montreal in Canada. A game-theory analysis, he says, shows that, in principle, the generator will eventually become so good that the discriminator can no longer tell the difference between real and fake. AI image-recognition systems can learn much more efficiently using GANs than can conventional deep-learning systems, says Goodfellow: they can become proficient on the basis of hundreds of training images, whereas current state-of-the-art image recognition typically requires tens of thousands. He says that might help in applications such as medical diagnostics, where large sets of patient data exist but are mostly off limits owing to privacy concerns. AI researchers have invented a variety of approaches to generating images. One, called a variational autoencoder (VAE), seems to be able to produce slightly less realistic but more diverse images than GANs, says computer scientist Max Welling at the University of Amsterdam. And other teams have developed further variants, some combining GANs and VAEs. Clune, Bengio and others collaborated on combined networks to generate the photo-realistic images in their latest paper, which was posted on the arXiv preprint server last November ( A.\u00a0Nguyenetal.Preprintathttps://arxiv.org/abs/1612.00005;2016 ). \n               Artificial data \n             Generative AIs look promising for basic science, too, says Welling, who is helping to develop software for the Square Kilometre Array (SKA), a radio-astronomy observatory to be built in South Africa and Australia. The SKA will produce such vast amounts of data that its images will need to be compressed into low-noise but patchy data. Generative AI models will help to reconstruct and fill in blank parts of those data, producing the images of the sky that astronomers will examine. A team led by Rachel Mandelbaum, an astrophysicist at Carnegie Mellon University, has been experimenting with both GANs and VAEs to simulate images of galaxies that look deformed because of gravitational lensing \u2014 when the gravity of objects in the foreground distorts space-time and warps light rays. Researchers are planning to survey huge numbers of galaxies to map gravitational lensing across the Universe\u2019s history. This could show how the distribution of the Universe\u2019s matter has changed over time, providing clues to the nature of the dark energy that is thought to have driven cosmic expansion. But to do this, astronomers need software that can reliably separate gravitational lensing from other effects. Synthetic images will improve the programs\u2019 accuracy, Mandelbaum says. Many scientists hope that the latest AI neural nets will help them to discover patterns in huge, complex sets of data \u2014 but some are  wary of trusting the interpretation of such \u2018black box\u2019 systems , whose inner workings are mysterious. Even if virtual neurons seem to give correct answers, they might have a mistaken understanding of the world. But adding a generative element to a neural net could help, Cranmer says. \u201cIf it can generate data that look just as real, then it\u2019s much more convincing that, whatever the black box is, it has actually learned the physics.\u201d Clune worries about generative algorithms, too. For all their potential benefits, he\u2019s concerned about the social implications of having machines that will one day be able to produce fake but real-looking pictures or video \u2014 perhaps, say, of Donald Trump receiving bribes from Vladimir Putin. \u201cI think that, increasingly, this is going to be an interesting challenge in society,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @dcastelvecchi \n               \n                     Tech giants open virtual worlds to bevy of AI programs 2016-Dec-14 \n                   \n                     Program good ethics into artificial intelligence 2016-Oct-19 \n                   \n                     Can we open the black box of AI? 2016-Oct-05 \n                   \n                     Anticipating artificial intelligence 2016-Apr-26 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21428", "url": "https://www.nature.com/articles/nature.2017.21428", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "The US Department of Agriculture will no longer make lab inspection results and violations publicly available, citing privacy concerns. \n             Update: On 6 February, the Humane Society of the United States (HSUS) took the first steps toward legal action against the USDA. In 2009, HSUS and the USDA reached a legal agreement that the agency post certain information, such as annual reports, about animal use in labs on its website, or make that information accessible to the public. In a letter sent to the Department of Justice,  \n             lawyers representing HSUS threatened to reopen the case \n              if the USDA did not restore the data immediately. \n           The US Department of Agriculture (USDA) agency  charged with ensuring the humane treatment of large research animals , such as primates and goats, has quietly scrubbed all inspection reports and enforcement records from its website. The move has drawn criticism from animal-welfare and transparency activists who say the public has the right to know how their tax dollars are being used. The USDA\u2019s Animal and Plant Health Inspection Service\u00a0(APHIS), which also oversees animals in circuses, zoos and those sold commercially as pets, says that making the data publicly available posed a threat to individuals\u2019 privacy. USDA spokesperson Tanya Espinosa would not specify what personal information the agency wanted to protect, but said that it would be impossible to redact it from all the tens of thousands of inspection reports, complaints and enforcement action documents that used to be public. The decision is a result of the USDA\u2019s \u201ccommitment to being transparent, remaining responsive to our stakeholders\u2019 informational needs, and maintaining the privacy rights of individuals\u201d, according to a statement on the agency\u2019s website. The records will still be available in redacted form through freedom-of-information requests. \u201dIf the same records are frequently requested via the Freedom of Information Act (FOIA) process, APHIS may post the appropriately redacted versions to its website,\u201d the statement concludes. But some critics met the privacy argument with scepticism. The USDA routinely redacted the names of individuals from the public reports anyway, says Justin Goodman, vice-president of the non-profit White Coat Waste Project in Washington DC, which opposes animal research. \u201cClaiming \u2018privacy\u2019 is a smokescreen to unjustifiably evade critical transparency about government operations.\u201d \n             Watching the watchers \n           The disappearance of information caught animal-welfare groups by surprise. \u201cI'm just flabbergasted,\u201d says Eric Kleiman, a research consultant at\u00a0the Animal Welfare Institute, an advocacy group in Washington DC. \u201cThis is not only the opposite of transparency, it takes us back to the Stone Age.\u201d But Matthew Bailey, president of the non-profit Foundation for Biomedical Research in Washington DC, says the move has some merit, because animal-rights activists sometimes target scientists who use animals. \u201cI would certainly agree that protection of personal information is of utmost importance, given the rich history of targeting individuals involved in animal research,\u201d he says. But Bailey acknowledges that it will now be difficult for organizations such as his to analyse trends in animal use in research. Espinosa declined to answer questions about what triggered the decision, or whether input from business interests, such as the circus industry, or the resignation of agency head Michael Scuse on 20 January were factors. She would not comment on whether the White House had a role in the move, but added that the USDA has \u201cbeen reviewing and updating the information that is released to the public for the last year\u201d. \n             Murky future \n           Inspection reports that were previously available on the APHIS site were crucial in helping animal-welfare groups spot potential abuses in facilities that use animals, Kleiman says. They include instances such as when  2,471 rabbits and 3,202 goats disappeared  from facilities owned by the antibody provider Santa Cruz Biotechnology in 2016. The company, headquartered in Dallas, Texas, was under investigation by the USDA for  alleged animal abuse  at the time. The APHIS website also allowed the public to track when institutions were allowed to perform experiments that could cause pain, such as infecting monkeys with Ebola virus. Getting such information through FOIA requests can take years, Klein says. And knowing what information to request will be difficult, as the USDA will no longer post complaints that it or outside groups file against an institution. These complaints often trigger USDA investigations.  Congressman Ken Calvert (Republican, California), who has backed numerous bills related to animal welfare and research, says that he did not know that the USDA would be removing the data, but would look into it. The USDA\u2019s move stands in stark contrast to a bill that Calvert introduced on 2 February, which would require research-funding agencies to more closely track and report the number of animals that scientists use, in order to minimize redundancy and unnecessary animal testing. It would also require researchers to report the number of mice, rats and birds used in experiments. Currently, the USDA only regulates the use and welfare of larger animals such as rabbits and monkeys. \n                   US government issues historic $3.5-million fine over animal welfare 2016-May-20 \n                 \n                   Thousands of goats and rabbits vanish from major biotech lab 2016-Feb-19 \n                 \n                   US primate centre faces scrutiny 2012-Mar-27 \n                 \n                   Animal rights: Chimpanzee research on trial 2011-Jun-15 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21460", "url": "https://www.nature.com/articles/nature.2017.21460", "year": 2017, "authors": [{"name": "Barbara Casassus"}], "parsed_as_year": "2006_or_before", "body": "Would-be rival to MIT lacks strategy and governance, report says. France\u2019s government auditor has taken a sharp swipe at efforts to develop a science super-campus near Paris that, by 2020, was supposed to rival the world's top campus universities, such as the US Massachusetts Institute of Technology (MIT). More than \u20ac5.3 billion (US$5.7 billion) in public spending has been earmarked for the Paris-Saclay science cluster, the Court of Auditors estimates in an  annual report  published on 8 February \u2014 but the original vision of creating a large integrated research university there is \u201cat a standstill\u201d. The Saclay plateau, about 30 kilometres south-west of Paris, has for decades been home to a high concentration of private and public research labs. In 2010 \u2014 by which time some 25,000 people worked there, including thousands of scientists \u2014 former French president Nicolas Sarkozy declared that it should  transform into something grander : an MIT  \u00e0 la fran\u00e7aise  that would shine in international university rankings. The idea was to meld together what Sarkozy called a badly coordinated \u201cmosaic of institutions\u201d into a cohesive whole by concentrating and restructuring the site\u2019s research around interdisciplinary themes, and also to relocate several elite higher-education institutes, or \u2018grandes \u00e9coles\u2019, to Saclay. Tens of thousands more students and researchers have since moved to the campus, which is now collectively known as the University of Paris-Saclay. But a lack of an overall strategy and governance means that Paris-Saclay risks remaining a mere geographical grouping of higher-education and research establishments without any \u201creal coherence and international visibility,\u201d the auditor\u2019s report says. There is a \u201creal risk that despite the huge investment of public funds, the initial ambition will be watered down,\u201d it adds.\u00a0 It\u2019s not the first time that the Saclay idea has attracted criticism. A French Senate report published in May 2016 said that institutions\u2019 attempts to maintain their own identity had destroyed the collective project, and called the situation \u201cblocked\u201d. And last April, the French government said it would give the Paris-Saclay cluster 18 months to sort out its difficulties \u2014 or else it would cut off stimulus funds granted under an \u2018excellence initiative\u2019 scheme that aims to reward the best research campuses in France. \n             Cluster or university? \n           The president of the University of Paris-Saclay, Gilles Bloch, says that the auditor\u2019s conclusion is \u201ctotally false\u201d. Since the government\u2019s edict last year, he says, an ad hoc committee of the heads of seven establishments on the campus representing all the partners \u2014 except two \u2014 has met weekly to draw up proposals for a new structure that would strengthen links in research, teaching and human resources. The two absentees are grandes \u00e9coles that specialize in engineering, and include the prestigious \u00c9cole Polytechnique. They were not invited to the table because they do not want closer links with their partners, Bloch says. Polytechnique president Jacques Biot explains his institution\u2019s position in the auditor\u2019s report. Picking up on the idea that Paris-Saclay should be more like California\u2019s Silicon Valley than like MIT, he notes that the valley has no real governance, and needs none. The original idea for Saclay was a science and technology cluster, not an integrated university, Biot maintains. Although it has been hard to persuade the grandes \u00e9coles to join forces, the government\u2019s funding has, at least, brought new dynamism to science at Saclay, says Philippe Vernier, director of the Paris-Saclay Institute of Neuroscience, with new projects, new buildings and a stronger presence for biology alongside physics, mathematics and engineering. Some of those involved in the project say that Saclay might end up splitting into two clusters, one for the engineering grandes \u00e9coles and the other for science universities. But Bloch says he hopes the grandes \u00e9coles will return to the fold once a plan takes shape, ideally before a jury reconsiders this December whether Paris-Saclay deserves its \u2018excellence initiative\u2019 label and funding.\u00a0 \u201cRival clusters make no sense. It is important for all establishments to join forces to create a modern university,\u201d he says. \n                   France\u2019s research minister lays out his priorities 2016-May-06 \n                 \n                   Paris plans science in the suburbs 2010-Oct-20 \n                 \n                   French research wins huge cash boost 2009-Dec-15 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21443", "url": "https://www.nature.com/articles/nature.2017.21443", "year": 2017, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Two countries vie to invest more of their economy into research than anyone else. Israel has just nudged ahead of South Korea as the world\u2019s most research-intensive economy, according to figures released on 7 February by the Paris-based Organisation for Economic Co-operation and Development (OECD). Last year, the OECD reported that  South Korea was opening up a clear lead  \u2014 but its latest data, which reveal 2015 investments and make revisions to earlier years, suggest that the two countries are still neck and neck. In 2015, Israel invested 4.25% of its gross domestic product (GDP) in research and development (R&D), marginally more than South Korea, which dipped to 4.23%. In both countries, industry accounts for much R&D spending. When it comes to the intensity given to \u201cbasic\u201d research \u2014 which the OECD defines as work undertaken primarily to acquire new knowledge without any particular application in view \u2014 South Korea holds a clear lead, with 0.73% of its economy invested in the practice, a larger proportion than anywhere else in the world. (Israel, with 0.39% investment in 2014, is ninth on this measure.) China continues to divert more of its economic growth into research: by 2015 it had invested 2.07% of its GDP, and has a plan to reach 2.5% by 2020. In OECD nations (which include Japan, the United States and Germany), the balance between government- and industry-financed R&D is slowly shifting. The fraction of R&D funded by domestic governments has been falling steadily since 2010, the OECD shows, dropping from 31% to 27% over 5 years. Industry-financed investment, which had dipped during the global financial crisis beginning in 2008, is back up to around 61% \u2014 aided by rising tax incentives for business R&D. Separately, cross-border research funding \u2014 not accounted for in the government and industry financing figures \u2014 is also on the rise. \n                   Why South Korea is the world\u2019s biggest investor in research 2016-Jun-01 \n                 \n                   South Korea stretches lead in research investment 2016-Feb-08 \n                 \n                   China tops Europe in R&D intensity 2014-Jan-08 \n                 \n                   OECD science and technology indicators \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21332", "url": "https://www.nature.com/articles/nature.2017.21332", "year": 2017, "authors": [{"name": "Inga Vesper"}], "parsed_as_year": "2006_or_before", "body": "A proposed Hawaiian bill aims to stop the sale of lotions containing certain UV-filters, but their effects on coral are disputed. Legislators in Hawaii are trying to ban the sale of sunscreens that contain two UV-filtering chemicals, after studies suggested that they harm coral reefs. On 20 January, Hawaii state senator Will Espero introduced a bill which would ban sunscreens containing oxybenzone and octinoxate in Hawaii (except under medical prescription) to the state Congress. Espero argues that a ban is important to preserve the state\u2019s tourism industry, because Hawaii relies heavily on tourists attracted by its coral reefs. The bill is already attracting attention from other regions with economies reliant on reefs, including Palau and the British Virgin Islands, Espero says. But manufacturers argue that more evidence is needed to warrant a ban. A bar in the state of Hawaii would be the strongest political measure yet taken against the chemicals \u2013 although some manufacturers already sell \u201creef-friendly\u201d sunscreens without them, produced in response to scientific and consumer concerns. \u201cSince there are eco-friendly sunscreens on the market now, a total ban hurts no one,\u201d Espero argues.\u00a0 In November 2015, a group of European Parliament members proposed a motion to ban oxybenzone in cosmetic products throughout the European Union, but that legislation has stalled. \n             Sunscreen research \n           Espero\u2019s bill draws largely upon research done by US scientists led by Craig Downs, executive director of the Haereticus Environmental Laboratory in Clifford, Virginia. In 2016, his team reported that oxybenzone and octinoxate could stunt the growth of baby corals, and that oxybenzone was toxic to seven coral species in lab tests 1 . A 2008 study from a different group had found that  oxybenzone is likely to cause coral bleaching  both in the lab and in the wild in several tropical regions 2 . Other studies have suggested that oxybenzone also acts as an endocrine disruptor among marine creatures such as shrimps and clams 3 . In ongoing follow-up work \u2013 which has not yet been published \u2013 Downs\u2019 team detected oxybenzone contamination of up to 4,000 parts per trillion (ppt) in the waters off the most popular beaches of the Hawaiian island of Maui. An oxybenzone concentration of around 400 ppt over several days is enough to induce coral bleaching in warm waters, they say. The team suggests that when people snorkel or swim, sunscreen washes off their skin and out into the reefs. \u201cIn many geographic locations, oxybenzone and sunscreen pollution poses a serious environmental hazard,\u201d says Downs. But other reef scientists are more circumspect about the role of sun-screen chemicals in coral-reef destruction. Many factors damage coral reefs, says J\u00f6rg Wiedenmann, head of the Coral Reef Laboratory at the University of Southampton, UK, but he agrees that sunscreen pollution might be detrimental in areas with lots of tourists. \u201cBanning sunscreen will not solve other problems: for example, temperature anomalies, overfishing, coral predators and the big issue of coastal runoffs that pollute and destroy reefs,\" he says. \u201cBut if you have places with a high load of tourists going in, it is not unreasonable to stay cautious and say, \u2018Yes, there may be additive effects.\u201d \n             Disputed effects \n           But sunscreen manufacturers such as L\u2019Or\u00e9al disagree that a ban is needed. \u201cRegulatory decisions have to be made on sound scientific evidence and multiple studies,\u201d says Marc Leonard, head of L\u2019Or\u00e9al\u2019s Research & Innovation, Environmental Research department in Aulnay-sous-Bois, France. \u201cThey have to be completed by different teams to provide a significant bundle of evidence. We are very far from it in this case.\u201d Despite this, says Leonard, L\u2019Or\u00e9al are working on making sunscreen products without oxybenzone, in anticipation of a possible ban. L\u2019Or\u00e9al has not itself reported any tests on the effects of oxybenzone or octinoxate on coral reefs. In June 2016, the manufacturer presented work done with researchers at the Scientific Centre of Monaco, on a different UV filter chemical in its sunscreen, called avobenzone. The scientists reported an adverse effect on corals at the high concentrations of 5 milligrams per litre (5 parts per million) \u2013 but that has little relevance to normal levels of exposure. The Consumer Healthcare Products Association, a national trade association for manufacturers based in Washington DC, says that it will oppose a ban until there is more evidence. \u201cWe sympathize with the desire to preserve Hawaii\u2019s coral reef, but there is no scientific evidence that under naturally occurring conditions, sunscreen ingredients are contributing to coral-reef declines,\u201d says a spokeswoman for the group. Downs says that his team has seen a clear effect in Maui \u2013 and that he feels there is already enough evidence to justify a ban there. Some Hawaiian politicians have tried to push for more funding to support research into the issue. But a bill to the US Congress, asking for funds for the University of Hawaii to further investigate the effect of sunscreens on reefs, stalled in February last year. \u00a0\u201cWe have advocates and science on our side,\u201d Espero says. \u201cFishermen, boat owners, sailors, ocean-sports enthusiasts, ocean-tour operators and environmentalists rely on the ocean for recreation and jobs. Opponents will be out there, but supporters as well.\u201d \n                   Bright spots among the world\u2019s coral reefs 2016-Jun-15 \n                 \n                   Reef grief 2011-Sep-28 \n                 \n                   Sunscreen wipes out corals 2008-Jan-29 \n                 \n                   Haereticus Environmental Laboratory \n                 \n                   Senator Will Espero \n                 \n                   Draft bill \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21463", "url": "https://www.nature.com/articles/nature.2017.21463", "year": 2017, "authors": [{"name": "Lesley Evans Ogden"}], "parsed_as_year": "2006_or_before", "body": "Sustainable fishing of some species for products including fins is feasible, and can avoid cruel practices, study finds. An article from    Scientific American . Sharks and their relatives face an  existential crisis  unprecedented in their 420 million years on the planet. A global trade in products from these animals fuels the capture of tens of millions of individuals a year. Strong demand combined with poor fishery regulation and high levels of incidental catch have resulted in many populations being overfished, with some now facing extinction. Many activists argue a total ban on shark fishing is the only solution to slow or halt the decline. But a  2016 study 1  found the majority of shark researchers surveyed believe sustainable shark fisheries are possible and preferable to widespread bans. Many reported they knew of real-world examples of sustainable shark fisheries. But a global roundup of empirical data exploring which species are being fished sustainably was lacking. New research, appearing in the February 6 issue of  Current Biology 2 , is filling that gap, and the findings bolster the idea that around the world, some sharks are being fished sustainably. Nicholas Dulvy, a marine conservation biologist at Simon Fraser University in British Columbia, and shark ecologist Colin Simpfendorfer of James Cook University in Australia recently examined global stock assessments of 65 shark populations of 47 species. They found 39 of the populations, representing 33 different species, are fished sustainably\u2014that is, they are harvested at levels that allow them to remain stable in size and not edge toward extinction. Although these 33 species account for only a small fraction of the world\u2019s sharks, rays and their kin the chimeras (collectively referred to as sharks), which  in total number more than 1,000 , they are proof of concept that sustainable shark fishing is possible. Cross-referencing stock assessments sourced from the scientific literature, government agencies, known experts and internet searches with other data sets including United Nations Food and Agriculture Organization catch statistics and International Union for Conservation of Nature (IUCN) threat categories, along with trade records, Dulvy and Simpfendorfer calculated the take of biologically sustainable sharks comprised 7 to 9 percent of global totals. But there are two components to sustainable fishing: the biological capability of the fish to withstand harvesting and the careful management of that harvesting by humans. The researchers found only 4 percent of global trade in sharks was directly sustainably managed. Dulvy, who co-chairs the IUCN Shark Specialist Group, says the science \u201ccomes straight out of population modeling theory,\u201d and the idea of maximum sustainable yields. To set limits on what can be harvested sustainably, researchers need to know the proportion of old versus young fish in a population as well as the speed with which individuals can reproduce\u2014factors that affect the entire population\u2019s ability to grow, decline or remain stable in numbers. Many shark species are so poorly studied that scientists do not yet know these basic parameters. But, theoretically, any species whose biology is well understood can be managed sustainably. As expected, Dulvy and Simpfendorfer determined some species that reproduce very slowly, including deep-water gulper sharks and cownose rays, cannot sustain fishing pressure. These creatures produce a maximum of one pup per year, on average, so they must be protected to maintain their numbers. But the researchers found something that may come as a surprise to conservation advocates: other relatively low-productivity species could be sustainably fished. One example is the Pacific spiny dogfish ( Squalus suckleyi ), a type of small shark. In 2011 a fishing industry group in British Columbia obtained Marine Stewardship Council (MSC) certification for this species, a process that validates for consumers the product was fished sustainably. It was the first such certification in the world awarded for a shark, explains Michael Renwick, executive director of the British Columbia Dogfish Hook and Line Industry Association who spearheaded this certification process. The Pacific spiny dogfish can live 70 years and does not reach sexual maturity until age 40. Females gestate their babies for two years, and may take a year off from breeding after pups are born. This shark thus has one of the longest reproductive cycles of any animal. \u201cYou look at that and you go, \u2018how on Earth can [harvesting] that be sustainable?\u2019\u201d Dulvy says. But it is possible because people have invested in figuring out its productivity, in population monitoring and in good management with carefully calculated quotas. Dogfish, a group of species from the Squalidae family of sharks, have not always been managed sustainably. They are the fishes of choice in the traditional British dish, fish and chips. When Europe overfished its own stocks, dogfish fishing shifted overseas to the northeastern coast of the U.S., where it again took its toll. There, overharvesting of Atlantic spiny dogfish ( Squalus acanthias ) throughout the 1990s led officials to significantly restrict that fishery, explains Michael Pentony at the National Oceanic and Atmospheric Administration\u2019s Greater Atlantic Regional Fisheries\u2019 Gloucester, Mass., office. Now that Atlantic dogfish stocks have recovered and the U.S. dogfish industry has obtained MSC certification, British Columbia\u2019s industry has, for multiple reasons, declined, and its industry group has deemed renewal of its MSC status too expensive to pursue. Perhaps the most controversial finding from the new study is that shark fins, too, can be harvested sustainably.  Shark fin is a delicacy in some Asian cultures . But the traditional way of harvesting the fins\u2014in which the fins are hacked off of the live animal, which is then tossed back into the sea to suffocate or die from bleeding\u2014has prompted public outcry. The uproar over this practice, called \u201cfinning,\u201d has been a major driver for shark conservation. Against that backdrop, sustainable shark fin is an \u201cunthinkable notion for many,\u201d Dulvy and Simpfendorfer acknowledge. But their study suggests it is indeed possible. In fact, they found nearly 9 percent of fins on the market originate from sharks whose populations are being fished sustainably. Obtaining shark fins need not involve finning at all, however. \u201cThere are absolutely ways to get fins into the fin trade without finning,\u201d says David Shiffman of the University of Miami, who led the 2016 study that surveyed shark scientists\u2019 attitudes toward shark fishing. He notes great strides in legislation that have reduced the number of sharks finned at sea in at least 17 countries. Indeed, by definition, exploiting a resource sustainably requires whole animal use, Simpfendorfer explains. In the case of MSC-certified Atlantic dogfish, the heads become lobster and crab bait; back meat becomes British fish and chips; belly flaps are a German delicacy; liver supplies nutraceuticals; fins and tails headline east Asian soup; and leftovers become agricultural fertilizer, says Massachusetts-based attorney John Whiteside, Jr., who helped east coast U.S. dogfish fisheries achieve MSC status. But for sustainable shark fishing to work, its products have to be labeled and traceable back to a well-managed source\u2014a requirement that very few of the sustainably harvested fins currently on the market now meet. Traceability depends on careful management of product \u201cchain of custody\u201d with specific information carried through from capture vessel to retailer. Ideally the products have a closed chain of custody, meaning no uncertified products come in from the sidelines, explains Glenn Sant, Fisheries Trade Programme Leader at TRAFFIC International, the wildlife trade monitoring group co-founded by World Wildlife Fund and the IUCN, who was not part of the study. \u201cIndustries have been doing this for a long time,\u201d he observes, with bar codes making traceability of products easy and cheap. Traceability challenges are not technological. They lie in gaining sufficient transparency to discern whether the fishery had adequate management within the product\u2019s country of origin. Currently, unless a product is MSC-certified or has permits from the Convention on International Trade in Endangered Species (CITES) attached, its traceability \u201cneeds great improvement,\u201d Sant says. Determining how to harvest some sharks sustainably while protecting others that cannot be harvested at all will require further work. Dulvy and Simpfendorfer suggest developed countries must support developing ones in improving traceability and negotiating international treaties for fisheries and trade. Bycatch remains a problem, too. Tuna fisheries, for example, often hook pricey species like blue sharks and shortfin makos and then sell them, rather than releasing them. Meanwhile bycatch sharks that are not economically valuable and thus released back to the sea may not fare well either. New satellite tagging research by Steven Campana, a shark biologist\u00a0at the University of Iceland who was not affiliated with the research, says a quarter of those live-released sharks may die from the stresses of capture and handling. Another concern: legal shark fishing could hide illegal trade. But \u201cillegal unsustainable shark fishing is happening regardless,\u201d Shiffman notes. In his view it is better to have at least some sustainable, scientifically well-managed products in the marketplace. Without them, he says, \u201cwhatever fills the gap that we leave is going to be worse.\u201d \n                   Cuba forges links with United States to save sharks 2015-Oct-21 \n                 \n                   South African scientists trial humane shark deterrents 2015-Sep-11 \n                 \n                   Fisheries: Eyes on the ocean 2015-Mar-17 \n                 \n                   Australian shark-cull plan draws scientists' ire 2013-Dec-13 \n                 \n                   Shark species more diverse than thought 2012-Jun-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21445", "url": "https://www.nature.com/articles/nature.2017.21445", "year": 2017, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "New analyses cut down the estimated number of planets unattached to a star by half. Most planets live their lives tethered to the star that created them. But some renegade worlds wander across the Milky Way without a host. Two new analyses suggest that Jupiter-sized rogue planets are a lot less common than scientists thought. The Galaxy is likely home to around 100 billion of these planets, one study shows, instead of the 200 billion proposed in 2011. Two teams of researchers presented their findings on 2 February at a conference in Pasadena, California: one based on a recent statistical analysis and the other on observations of more than 2,600 microlensing events. These occur when a planet passes between Earth and a distant star at just the right angle to \u2014 temporarily \u2014 act like a cosmic magnifying glass. It can briefly brighten the light from the star and provide researchers with information about the size of the \u2018lens\u2019, or planet, which might not reflect any light. This technique is currently the only way to spot these giant rogues. Previous  estimates of the number of free-floating planets  stemmed from a 2011 analysis of ten microlensing events suggestive of renegade worlds 1 . The authors hypothesized that there could be as many as two rogue worlds for every main-sequence star \u2014 one of the most common categories, which includes the Sun. The 2011 finding flew in the face of how many astronomers thought rogue planets formed. In a  binary system  where each star hosts its own planets, the gravitational force of one of the stars could disrupt the orbit of a planet and fling it out of the system. There could be similar effects in a crowded cluster of stars, where one star could eject its neighbour\u2019s outer planet. These and other scenarios could produce some free-floating planets, but probably not hundreds of billions of them, says Sarah Dodson-Robinson, an astronomer at the University of Delaware in Newark. The reduced estimates have reassured astronomers that their ideas of rogue planet formation aren\u2019t so far off the mark. \n             A rogue\u2019s dispute \n           Many of the suspected \u2018rogue planets\u2019 from the 2011 analysis do actually orbit a star, says Christian Clanton, an astronomer at NASA Ames Research Center in Moffett Field, California, who was one of the conference presenters. His statistical analysis 2  showed that they probably circle their star at a distance of 1.5 billion kilometres or more \u2014 farther than  Saturn  is from the Sun. There are perhaps only half as many genuinely rogue worlds as the 2011 analysis estimates, says Clanton, although the planets could still number in the billions. The 2011 paper looked at data from the Microlensing Observations in Astrophysics project, which uses a telescope in New Zealand. The authors examined 474 detections of giant planets more massive than Jupiter, of which 10 seemed to be observations of planets that weren't bound to stars. The team's statistical analysis suggested that the Galaxy is home to roughly 200 billion free-floating worlds. Some researchers took issue with that interpretation because it was based on so few sightings of potential rogue planets, says Jennifer Yee, an astrophysicist at the Harvard-Smithsonian Center for Astrophysics in Cambridge, Massachusetts. But the field had to wait for more data from better-situated telescopes to narrow down the true number. Those observations came from the Optical Gravitational Lensing Experiment (OGLE), which uses a telescope in northern Chile \u2014 a site with better weather and atmospheric conditions for astronomy than New Zealand. When Przemek Mr\u00f3z, an astronomer at Warsaw University Observatory in Poland, and his colleagues analyzed the data, they didn't find evidence for a large population of rogue planets. Mr\u00f3z \u2014 whose team is in the process of publishing its findings \u2014 points out that flaring stars, or stars whose brightness fluctuates could mimic the microlensing effects of a renegade world.\u00a0 Astronomers are looking forward to even better estimates when NASA\u2019s Wide Field Infrared Survey Telescope (WFIRST) launches in the mid-2020s. Once WFIRST settles into position, it will collect much more sensitive microlensing observations of planets. It will even be able to detect worlds that are smaller than Mars. The truth about rogue planets is out there, and WFIRST will help astronomers to find it. \n                   Dwarf planet stretches Solar System's edge 2014-Mar-26 \n                 \n                   First possible exomoon spotted 2013-Dec-23 \n                 \n                   So many lonely planets with no star to guide them 2011-May-18 \n                 \n                   Optical Gravitational Lensing Experiment \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21367", "url": "https://www.nature.com/articles/nature.2017.21367", "year": 2017, "authors": [{"name": "Rachel Cernansky"}], "parsed_as_year": "2006_or_before", "body": "The government\u2019s cancelled National Children\u2019s Study has a successor that may sidestep earlier challenges. Frederica Perera has stocked a dozen freezers with an unusual biological bounty over the past two decades. Inside are vials of umbilical-cord blood, urine and placentas from more than 700 pregnant women and their children from the Washington Heights, Harlem and South Bronx neighbourhoods of New York City. This biobank has proved invaluable in her efforts to understand how urban environments influence children\u2019s health from birth through childhood. Now, Perera\u2019s team is gearing up for another challenge: developing a tool that can test her bank of umbilical-cord blood samples for common pollutants and use the results to predict later impacts on neurodevelopment and obesity. The scientists are also joining a major US government programme that seeks to understand how environmental, behavioural and social factors affect children\u2019s health. Known as the Environmental Influences on Child Health Outcomes (ECHO) programme, the effort will support dozens of longitudinal cohort studies across the United States. Researchers working on the project will meet on 15\u201316 February in Arlington, Virginia, to make decisions key to its success: how to collaborate, and how to combine and compare the individual data sets. The ECHO project emerged from  the ashes of the controversial National Children\u2019s Study  (NCS), a programme run by the US National Institutes of Health (NIH) that aimed to track 100,000 children from before birth to age 21. The NIH cancelled that study in 2014, after spending more than a decade and US$1.2\u00a0billion trying to get it off the ground. ECHO organizers say that their project will be different. By using cohorts that are already under way, they hope to side-step  some of the problems that plagued the NCS , which had trouble recruiting participants, defining its hypotheses and sticking to its budget. Marrying up existing cohort studies will enable the scientists to study large numbers of children more cheaply than  if they created one large cohort from scratch . Doing so will also let them examine rarer health outcomes and differences between subpopulations. But the approach brings its own problems. \u201cThe purpose of the national meeting is to try to combine the cohorts,\u201d says Douglas Ruden, director of epigenomics at Wayne State University\u2019s Institute of Environmental Health Sciences in Detroit, Michigan, and a member of the ECHO steering committee who is helping to lead a participating cohort. \u201cThey all have different goals and study designs, and somehow they have to merge them into one cohort \u2014 and that\u2019s the hard part.\u201d That will be a major challenge, agrees David Savitz, vice-president for research at Brown University in Providence, Rhode Island, who led an NCS pilot site. But Savitz is confident that ECHO will succeed because of smarter planning, better leadership and the quality of the cohort studies selected. He says that the programme director, Matthew Gillman of the NIH, is a respected scientist who has experience coordinating multiple projects. \n               Growing evidence \n             In September 2016, the NIH awarded $157\u00a0million to ECHO to support work on four main topics: obesity; airway conditions; neuro\u00addevelopmental disorders (including autism); and prenatal and postnatal outcomes, such as premature birth and birth defects. Ruden\u2019s study has tracked about 1,000 mother\u2013infant pairs for seven years. He has shown that exposure to lead during pregnancy might be associated with  epigenetic changes  in a woman\u2019s grandchildren \u2014 specifically, shifting patterns of methyl groups attached to DNA, which can affect gene expression 1 . Under ECHO, Ruden will double the size of his cohort and look for similar impacts from prenatal exposure to other metals and organic pollutants. With their $1.5-million ECHO grant, Perera and her team are working to identify a biomarker in umbilical cord blood that would reveal whether a child was exposed in the womb to pollutants called polycyclic aromatic hydrocarbons. This group of more than 100 chemicals, particularly common in urban environments, can be traced to sources such as vehicle exhaust, cigarette smoke and coal-burning; many of them are thought to cause cancer. If the scientists can locate a potential biomarker, they could use samples and information from other ECHO cohorts to help test and validate it \u2014 and to look for links with alterations in children\u2019s development or health. In the long term, scientists hope that ECHO will inform another component of the initiative: a network of clinical trials in medically underserved and rural areas to test treatments based on cohort findings. The trials are still being selected, Gillman says, but could evaluate things such as behavioural interventions to prevent obesity in rural areas. Some project leaders are nervous about ECHO\u2019s future \u2014 and about funding for the health sciences generally \u2014 under the administration of US President Donald Trump, but Gillman says that both Republicans and Democrats in Congress have supported the project. \u201cWe see a bright future for ECHO, no matter the change in administration,\u201d he says. \u201cOur mission is to enhance the health of children for generations to come.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Massive UK baby study cancelled 2015-Oct-27 \n                   \n                     Wanted: 80,000 British babies for massive study 2015-Feb-24 \n                   \n                     NIH ends longitudinal children\u2019s study 2014-Dec-12 \n                   \n                     US child study hits buffers 2014-Jun-17 \n                   \n                     Child-study turmoil leaves bitter taste 2012-May-16 \n                   \n                     Growing pains for children's study 2012-Feb-22 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21424", "url": "https://www.nature.com/articles/nature.2017.21424", "year": 2017, "authors": [{"name": "Shaoni Bhattacharya"}], "parsed_as_year": "2006_or_before", "body": "Researchers caution that stem rust may have returned to world\u2019s largest wheat-producing region. An infection that struck wheat crops in Sicily last year is a new and unusually devastating strain of fungus, researchers say \u2014 and its spores may spread to infect this year\u2019s harvests in Europe, the world\u2019s largest wheat-producing region. \u201cWe have to be careful of shouting wolf too loudly. But this could be the largest outbreak that we have had in Europe for many, many years,\u201d says Chris Gilligan, an epidemiologist at the University of Cambridge, UK, who leads a team that has modelled the probable spread of the fungus\u2019s spores. In alerts released on 2 February, researchers  revealed the existence of TTTTF , a kind of stem rust \u2014 named for the characteristic brownish stain it lays down as it destroys wheat leaves and stems. The alarm was raised by researchers at the Global Rust Reference Center (GRRC), which is part of Aarhus University in Denmark, and the International Maize and Wheat Improvement Center (CIMMYT), headquartered in Texcoco, Mexico. Last year, the stem rust destroyed tens of thousands of hectares of crops in Sicily. What\u2019s particularly troubling, the researchers say, is that GRRC tests suggest the pathogen can infect dozens of laboratory-grown strains of wheat, including hardy varieties that are usually highly resistant to disease. The team is now studying whether commercial crops are just as susceptible. Adding further concern, the centres say that  two new strains  of another wheat disease, yellow rust, have been spotted over large areas for the first time \u2014 one in Europe and North Africa, and the other in East Africa and Central Asia. The potential effects of the yellow-rust fungi aren\u2019t yet clear, but the pathogens seem to be closely related to virulent strains that have previously caused epidemics in North America and Afghanistan. The Food and Agriculture Organization of the United Nations (FAO) in Rome issued  similar alerts  about the three diseases on 3 February. Severe wheat damage in Europe could affect food prices, inflation and the region\u2019s economic stability, says James Brown, a plant pathologist at the John Innes Centre in Norwich, UK. But researchers hope that by putting out alerts before European wheat crops have started to grow this year, they will give farmers enough warning to monitor fields and apply fungicides, halting the disease\u2019s spread. Plant breeders can also start to ramp up efforts to produce resistant varieties. \u201cTimely action is crucial,\u201d says Fazil Dusunceli, a plant pathologist at the FAO. \n               Return of stem rust \n             In the mid-twentieth century, devastation caused by stem rust spurred efforts to breed wheat strains that could resist the fungi. That research \u2014 led by agronomist  Norman Borlaug  \u2014 famously led to the Green Revolution in agriculture,  increasing crop yields around the world . But stem rust returned in the late 1990s and 2000s, with a variety called Ug99 that  spread through Africa  and parts of the Middle East. It ruined harvests and caused international concern because, says Dusunceli, more than 90% of wheat crops were susceptible to it. So far, however, it hasn\u2019t hit large wheat-producing regions such as Europe, China and North America. Researchers are developing resistant crops. Stem rust epidemics haven't been seen in Europe since the 1950s, says Mogens Hovm\u00f8ller, who leads the GRRC\u2019s testing team. \u201cIt\u2019s not a challenge plant breeders have faced for many years,\u201d agrees Brown. But the outbreak that hit Sicily in 2016 suggests that the disease has now returned. Unusually, even the hardy durum wheat, used to make pasta, is susceptible to it, says Hovm\u00f8ller. But it\u2019s too early to say whether the new infection could be as devastating as Ug99. Models based on wind and weather patterns, conducted by Gilligan's team at Cambridge University together with CIMMYT and the UK's Met Office in Exeter, suggest that stem-rust spores released during the Sicilian outbreak may well have been deposited throughout the Mediterranean region. That doesn\u2019t mean the infection will spread \u2014 the spores may not have survived the winter, for example \u2014 but it is worrying enough for researchers to raise the alarm.  The yellow-rust strains are also a concern, says Hovm\u00f8ller. For Europe, perhaps the most alarming is one provisionally called Pst(new), which was spotted in Sicily, Morocco, Italy and northern Europe in 2016. The fungus is related to a virulent strain that hit North America in the 2000s, but it is not clear how aggressive it is. \n               Early-warning system \n             Researchers are accustomed to finding one or two new wheat-rust strains each year in Europe; these must be guarded against but are not usually dangerously virulent. But since 2010, the region has experienced a greater influx of wheat pathogens, says Hovm\u00f8ller. He doesn\u2019t know why, but speculates that it could be down to warmer autumns and milder winters attributable to climate change, combined with changes in farming practices, such as sowing wheat earlier in the season. Increases in international travel \u2014 potentially spreading spores on clothing \u2014 could also be a factor, speculates Brown. Hovm\u00f8ller and others will in the next few weeks ask the European Research Council for funds to establish an early-warning system. That will help partners including breeders, scientists and agrochemical companies in Europe to share diagnostic facilities and information about potential outbreaks. Dusunceli thinks that such a network might have helped to mitigate the Sicily outbreak, which in turn would have meant that fewer spores could spread to other parts of the continent. \u201cI wouldn\u2019t question the necessity for an early-warning system,\u201d he says. \n                     Syrian seed bank gets new home away from war 2016-Oct-05 \n                   \n                     Devastating wheat fungus appears in Asia for first time 2016-Apr-27 \n                   \n                     Wheat lag 2014-Mar-26 \n                   \n                     Science in Africa: The wheat stalker 2011-Jun-29 \n                   \n                     Wheat fungus threatens global crops 2009-Mar-17 \n                   Reprints and Permissions"},
{"file_id": "542148a", "url": "https://www.nature.com/articles/542148a", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Industry and public-health experts concerned about ramifications of Nagoya Protocol. International rules to ensure that developing countries benefit when foreign companies make use of their biological resources could delay the supply of seasonal influenza vaccines or render those vaccines less effective, warn vaccine manufacturers and researchers. The  Nagoya Protocol  dictates that any company using \u2018genetic resources\u2019 from a participating nation must negotiate an agreement to ensure that any profits or benefits are shared. That could include making payments or sharing research results or intellectual property. The treaty covers samples from plants, animals and, crucially, the viruses used to create vaccines. The treaty came fully into force in October 2015. But there are concerns that the need to negotiate agreements may hamper companies\u2019 ability to manufacture the best vaccines in time for the next flu season. The executive board of the World Health Organization (WHO) discussed the public-health impact of the treaty, including how it affects vaccines, at a meeting on 27 January. Pharmaceutical companies have raised concerns with the WHO and with governments. International experts meet twice a year \u2014 in time for both Northern and Southern Hemisphere winters \u2014 to determine which viral strains should be included in the vaccines for the coming flu seasons. The process is conducted by the WHO\u2019s Global Influenza Surveillance and Response System (GISRS), which collects and analyses the latest viral samples from around the world. When the advice changes, \u201cit\u2019s a race against time\u201d to incorporate the new strains into the vaccines, says John McCauley, director of the Crick Worldwide Influenza Centre in London, which is part of the GISRS. \u201cIt\u2019s really, really time-pressured.\u201d Of the four virus strains in the current flu vaccine (2016\u201317), three pre-date the convention and one is from the United States, which has not ratified the treaty. But at some point, the recommendations could change to include samples that fall under the treaty. Currently, 95 parties are bound by the Nagoya Protocol, including the European Union, China, India and Indonesia, and some countries, such as Brazil, have their own legislation that has a similar effect. The GISRS panel is due to meet in New York at the end of the month to determine recommendations for the Northern Hemisphere winter in 2017\u201318. At present, companies have approximately six months to implement any recommended changes before the flu season starts (see \u2018Race to make flu vaccine\u2019). But the need to reach benefit-sharing agreements could introduce delays \u201cconservatively estimated to be a minimum of three months\u201d, says London-based AstraZeneca, which manufactures flu vaccines. This could mean that vaccines would not reach patients until influenza is already circulating. Such a delay \u201cwould place public health at significant risk\u201d, the company says. \u201cWe would be concerned if Nagoya Protocol-related obligations caused delays or other problems in seasonal flu vaccines being made available for vaccination,\u201d adds a spokesperson from GlaxoSmithKline in Brentford, UK. Another possibility is that companies could simply avoid certain strains if the legality of their use is uncertain, says Stephen Inglis, who until last year headed the UK National Institute for Biological Standards and Control near London. This could mean that the resulting vaccine is a poor match for circulating strains. Although Inglis thinks that the Nagoya Protocol \u201cis based on a very noble principle\u201d, he questions whether it should include pathogens. But Edward Hammond, who worked on the creation of a WHO sharing system for zoonotic flu samples known as the Pandemic Influenza Preparedness (PIP) Framework on behalf of the Third World Network, says that it is right that pathogens be included in the treaty\u00a0\u2014\u00a0and that companies share the benefits of products made from them. Hammond, an independent research consultant in Austin, Texas, says that it should take only a few years to come up with a system for seasonal flu that does not require individual agreements but does include benefits-sharing \u2014 in the meantime, there will be just a \u201chandful\u201d of strains that come from treaty-bound nations. One solution along these lines would be to turn the WHO\u2013GISRS system into a formal international agreement that incorporates benefit sharing and is therefore recognized by the Nagoya Protocol: then, samples could be shared without making separate agreements. A similar option is being pursued for the PIP Framework in response to Nagoya. But McCauley notes that the system for seasonal influenza involves many more samples. \u201cThe necessary extra work under the PIP Framework,\u201d he says, \u201cwould be very likely to reduce the number of viruses that are shared for seasonal influenza.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @DPCressey \n               \n                     Biopiracy ban stirs red-tape fears 2014-Sep-30 \n                   \n                     When Google got flu wrong 2013-Feb-13 \n                   \n                     Moving towards a universal flu vaccine 2012-Mar-30 \n                   \n                     GISRS \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21377", "url": "https://www.nature.com/articles/nature.2017.21377", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Studies reveal drug's crystal structure and how it affects people's perceptions of meaning. The acid tests of 1960s San Francisco have morphed into something quite different in today\u2019s Silicon Valley.  Mind-altering trips  have given way to subtle productivity boosts purportedly caused by tiny amounts of LSD or other psychedelic drugs. Fans claim that this \u2018microdosing\u2019 boosts creativity and concentration, but sceptics doubt that ingesting or inhaling one-tenth of the normal dose could have an effect. Science could soon help to settle the matter. Researchers have finally mapped the 3D structure of LSD in its active state \u2014 and the details, published today in  Cell 1 , indicate the key to the chemical\u2019s potency 1 . Another team reports today in  Current Biology 2  that it has pinpointed the molecular go-between that creates the perception of deep meaning experienced during acid trips \u2014 a feeling that the writer Aldous Huxley once described as \u201csolidarity with the Universe\u201d. \u201cThis is what we dreamed of doing when I was a graduate student in the seventies,\u201d says Gavril Pasternak, a pharmacologist at Memorial Sloan Kettering Cancer Center in New York City who has spent decades studying the receptor proteins in the brain that mediate the activity of opioids and psychedelic drugs. \u201cWork like this expands our understanding of how these receptors work.\u201d \n             A long, strange trip \n           In 1972, researchers revealed LSD\u2019s shape by mapping the arrangement of atoms in its crystallized form 3 . But in the decades since, they\u2019ve struggled to reveal the crystal structure of a receptor grasping a molecule of LSD or another psychedelic drug. This active configuration is key to understanding how drugs work, because their action depends on how they cling to molecules in the body. Now, the team behind the Cell study has shown how LSD binds to the protein 5-HT2B, a receptor for the neurotransmitter serotonin,  which helps regulate activities such as appetite and mood . \u201cThis is the first picture of a psychedelic drug in action,\u201d says lead author Bryan Roth, a pharmacologist at the University of North Carolina at Chapel Hill. Roth was surprised to discover that the receptor includes a lid-shaped structure that hovers over the LSD molecule, and that the drug apparently triggers the lid to close, trapping the molecule inside the receptor. \u201cImagine a person crawling into a manhole and a cover sliding over them so they can\u2019t get out,\u201d he says. The lid seems to explain why LSD\u2019s effects can last for more than 20 hours, depending on the amount taken. It also supports the idea that microdosing can have an effect, even when people take doses that are less than one-tenth of the normal amount. \u201cThe fact that LSD gets trapped provides an explanation for why extremely small amounts of the drug can still be potent,\u201d Roth says. \u201cBefore this, what I heard from Silicon Valley was purely anecdotal.\u201d His study did not reveal how microdosing affects people in the short or long term. But another group \u2014 led by Katrin Preller, a psychopharmacologist at the University Hospital for Psychiatry Zurich in Switzerland \u2014 examined the root of certain acid experiences in a study of 22 healthy university students. Preller was interested in the biological basis of one aspect of tripping that involves the assignment of \u2018meaning\u2019, which is based on personal relevance. \u201cIf you have a spider phobia, then the sight of a spider is meaningful,\u201d Preller says. \u201cBut if you don\u2019t have a phobia it doesn\u2019t trigger much within you.\u201d \n             The sound of music \n           Preller\u2019s team asked study participants to list songs that were personally meaningful to them. Then each person was randomly given LSD, a placebo or LSD with ketanserin, a drug that stops LSD from binding to a serotonin receptor similar to 5-HT2B. Importantly, ketanserin does not prevent LSD from connecting to other proteins, such as dopamine receptors or adrenoreceptors. Soon after the dose, the participants heard clips from their chosen tunes, similar songs and free jazz, which almost none of them had previously considered meaningful. They rated each clip in terms of whether the song felt meaningful, pleasant and connected with them. Free jazz elicited substantial emotions only in those who had taken LSD without ketanserin. Likewise, only the students in the LSD group reported strong feelings of unity, bliss and disembodiment, and of seeing sounds or hearing colours, after taking their treatments. Because the ketanserin negated those perceptions, Preller\u2019s team concluded that the serotonin receptor controls the perception of meaning under the influence of LSD, and perhaps beyond. Preller hopes that the finding will trigger research on drugs to treat symptoms of schizophrenia that stem from a dysfunctional assignment of meaning \u2014 such as the paranoia that occurs when an individual interprets an irrelevant object or person as dangerous. And knowing the crystal structure of LSD could aid researchers who are trying to design drugs that mimic some psychedelic compounds\u2019 ability to alleviate depression, but spare them paranoia and debilitating hallucinations. \u201c We desperately need new drugs in psychiatry,\u201d Preller says, \u201cso all of this work is important.\u201d \n                   Magic-mushroom drug lifts depression in first human trial 2016-May-17 \n                 \n                   Brain scans reveal how LSD affects consciousness 2016-Apr-11 \n                 \n                   No link found between psychedelics and psychosis 2015-Mar-04 \n                 \n                   Gavril Pasternak's website \n                 \n                   Bryan Roth's website \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21429", "url": "https://www.nature.com/articles/nature.2017.21429", "year": 2017, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "Archaeologists worry that a museum exhibition will encourage exploitation of priceless historical sites. A museum show of sumptuous treasures from a ninth-century shipwreck is being denounced by researchers, who say that commercial salvage of the artefacts irreversibly damaged the wreck\u2019s scientific value. On 6 February, the Advisory Council on Underwater Archaeology sent a letter of opposition to the Asia Society, the non-profit group that is mounting the show of Chinese Tang-dynasty porcelains, gold vessels and other objects from the wreck at its New York City museum. Critics fear that the exhibition, slated to open on 7 March, will encourage exploitation of wrecks by for-profit firms. Museums that show salvaged treasures don\u2019t intend to promote treasure-hunting, \u201cbut that\u2019s the effect it has\u201d, says Marco Meniketti, an archaeologist at San Jos\u00e9 State University in California who leads the advisory council. Artefacts from the Belitung wreck, named after the Indonesian island close to the ship\u2019s final resting spot, were scheduled to go on display at the Smithsonian Institution's Sackler Gallery in Washington DC in 2012. The institution cancelled the exhibition in December 2011 after vocal opposition from Smithsonian scientists and others. But the problems presented by exhibiting the spoils of commercial salvage remain, says maritime archaeologist Filipe Castro at Texas A&M University in College Station. That type of excavation \u201csilences  all the questions that a vessel like that could answer \u201d, he says, reeling off a list of data that should have been collected at the Belitung site. In a statement, the Asia Society said that \u201cAmerican audiences should have an opportunity to see this material because of its significance\u201d. In recognition of \u201cthe sensitivities\u201d around the exhibition, the society is co-sponsoring a public symposium about the ethics of archaeology and commercial salvage. And the head of Seabed Explorations, the company that salvaged the wreck, defended his team\u2019s work. \u201cWithout Seabed Explorations there wouldn\u2019t be any data existing at all about the Belitung shipwreck,\u201d says Tilman Walterfang. \n               Rocky shoals \n             With 17,000 islands and a location central to maritime trade, Indonesia is rich in shipwrecks. But it is less endowed with resources to protect and study them. After fishermen found the Belitung wreck nearly 20 years ago, looters began to circle the site. Seabed Explorations of Nelson, New Zealand, received a contract to excavate the wreck after the Indonesian government granted a cargo-recovery license. Seabed staff discovered a spectacular hoard on a Middle Eastern ship bound for an empire that included present-day Iran and Iraq. The wreck confirms that sea-based commerce between China and West Asia was thriving more than a millennium ago. Workers recovered some 60,000 artefacts during field seasons in 1998 and 1999. In 2005, a subsidiary corporation set up by the government of Singapore purchased the cargo for US$32 million. The artefacts now belong to Singapore\u2019s Asian Civilisations Museum. Archaeologists tracking the Belitung objects point to a 2001 convention of the United Nations Educational, Scientific and Cultural Organization (UNESCO), which states that \u201c underwater cultural heritage  shall not be traded, sold, bought or bartered as commercial goods\u201d. Such commerce results in the destruction of archaeological sites, says Diane Gifford-Gonzalez, an archaeologist at the University of California, Santa Cruz, and president of the Society for American Archaeology, which opposes the New York show. (Indonesia, Singapore and the United States are not parties to the UNESCO convention, which calls for sanctions against violators.) Researchers also say that when salvage companies control a site, they have an incentive to focus on eye-catching treasures instead of  scientifically valuable items such as potsherds , which can be easily overlooked. The New York show is \u201ccreating a precedent for continued destruction of sites\u201d, says maritime archaeologist Jeremy Green at the Western Australian Museum in Fremantle, near Perth. \n               Hasty haul \n             Officials from Seabed acknowledge that a good portion of the artefacts were salvaged without precise documentation, but they say that the Indonesian government\u2019s demands and the threat of looting required them to do the first round of fieldwork in haste. Moreover, Walterfang says, political instability made it difficult to recruit archaeologists to work on the first round of excavation. During the second round, however, the locations of objects were precisely recorded, says Michael Flecker, who oversaw the second field season for Seabed and is now a maritime archaeologist at the ISEAS Yusof Ishak Institute of Singapore. That fieldwork quickly led to a paper about the ship in a peer-reviewed journal 1 . But removing so many objects from the wreck without full knowledge of their original positions means that much of the ship\u2019s scientific potential will never be realized, says maritime archaeologist Elizabeth Greene of Brock University in St Catharines, Canada. \u201cThe project is described as one of the most important archaeological revelations of the twentieth century. It\u2019s not,\u201d she says. \u201cIt\u2019s perhaps one of the most important sabotaged treasures of the twentieth century.\u201d When the Smithsonian cancelled its show in 2011, museum officials said that they would pursue further excavation of the Belitung site. But Flecker says that when he saw the wreck in 2013, \u201cthe entire hull had been ripped apart\u201d by looters. Even if the Smithsonian had been given permission to excavate, \u201cthere would have been nothing left to record\u201d. \n                     Human skeleton found on famed Antikythera shipwreck 2016-Sep-19 \n                   \n                     Shipwreck points to 18th-century race to colonize New Zealand 2014-Jan-06 \n                   \n                     Underwater archaeology: Hunt for the ancient mariner 2012-Jan-25 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21423", "url": "https://www.nature.com/articles/nature.2017.21423", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Blueprint outlines ambitious scheme to solve uncrackable problems using existing technology. Physicists have sketched a blueprint for a quantum computer built using existing technology that would be powerful enough to crack important and currently unsolvable problems, such as factoring enormous numbers. Such a machine would need to be larger than a football pitch and would cost at least \u00a3100 million (US$126 million) to make, its designers say. \u201cYes it will be big, yes it will be expensive \u2014 but it absolutely can be built right now,\u201d says quantum physicist Winfried Hensinger of the University of Sussex in Brighton, UK, who leads the team that published the blueprint in  \n                   Science Advances \n                 1  on 1 February. The idea is not the first proposal to build a practical quantum computer, and it would involve tough engineering challenges, says Andrea Morello, a quantum physicist at the University of New South Wales in Sydney, Australia. But it is remarkable for its ambition and approach, he says. \u201cI do think this is a landmark paper, and it will be very influential in the community for many years ahead.\u201d \u201cWhile this proposal is incredibly challenging, I wish more in the quantum community would think big like this,\u201d agrees Christopher Monroe, a physicist at the University of Maryland in College Park. \n               Quantum architecture \n             Quantum computers promise to exploit the remarkable properties of quantum particles to  carry out certain calculations exponentially faster than their classical counterparts . Teams around the world are  competing to build them on the scale required for them to be useful , but most designs so far have targeted a few dozen quantum bits, or qubits. Many thousands are probably needed to do useful calculations, such as finding the prime factors of large numbers, a crucial problem in encryption. Hensinger\u2019s team suggests using ions trapped by magnetic fields to create its qubits \u2014 an approach that physicists have been working on for more than 20 years. Most of the components necessary to build a trapped-ion quantum computer have already been demonstrated, Monroe says. \u201cOur community needs a systems-engineering push to simply build it.\u201d In Hensinger\u2019s blueprint, thousands of hand-sized square modules could be yoked together to produce \u2014 in theory \u2014 a quantum computer of any size. Key to the design is how to overcome practical problems, such as the need to dissipate heat produced by the machine. \u201cSuch high-level issues are rarely considered by people in the field of quantum computing, either because they think it\u2019s goofy to think that big, or because in their own physical system, it is nearly impossible to fathom such a high-level view,\u201d Monroe says. In each module, around 2,500 trapped-ion qubits would be suspended in magnetic fields, protected from interference that would affect their delicate quantum states. To perform operations, ions interact with their neighbours by shuttling around an x-shaped grid, like Pac-Man characters. \n               Speed and scale \n             Rather than using individual lasers to control each trapped ion \u2014 which would require a huge engineering effort to build at scale \u2014 the team proposes to control the qubits using a field of microwave radiation through the entire computer. To tune individual qubits in and out of interaction with the wider field, they need only apply a local voltage. The scientists\u2019 scheme suggests using liquid nitrogen to keep the system cool. The ions themselves would hop from chip to chip to transmit information between the modules \u2014 a technique that produces inter-chip connection speeds 100,000 times those of systems that use light waves and optical fibres, says Hensinger. The individual modules would be replaceable, built on silicon bases that could be manufactured using techniques available in the conventional electronics industry, he adds. To find the prime factors of a 2,048-bit (or 617-digit-long) number \u2014 something no classical computer can do today \u2014 the computer would need 2 billion qubit ions. They would take around 110 days to crack the problem, Hensinger says.  This would allow researchers to crack today\u2019s best encryption systems . In theory, only 4,096 qubits are required for this calculation, but 2 billion ions would be needed because of the error rates associated with the modest quality of current trapped-ion-qubit technology. But reducing the rate at which qubits make errors could drastically reduce the computer\u2019s dimensions, perhaps bringing it down to the size of a large room, says Hensinger. Huge technical challenges still stand in the way of any team aspiring to build the quantum computer \u2014 such as how to make the required strong magnetic-field gradients and engineer in the precise control needed to manipulate qubits. But Hensinger and his colleagues are now constructing a prototype based on their design, in an effort to demonstrate that their plans really could work. \u201cBuilding that thing will be an extraordinary engineering challenge, but one that\u2019s worth pursuing,\u201d says Morello.\n Reprints and Permissions"},
{"file_id": "542146a", "url": "https://www.nature.com/articles/542146a", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "It missed the historic discovery, but the Virgo lab in Italy is now primed to extend LIGO\u2019s reach and precision. The car journey along the gravitational-wave detector\u2019s right arm lasts a good 10\u00a0minutes, an eternity compared with the 10\u00a0microseconds it takes for the laser light needed to detect these ripples in space-time to make the same trip. This tunnel isn\u2019t in Hanford, Washington, or Livingston, Louisiana, the locations of the twin labs that form the Laser Interfero\u00admeter Gravitational-Wave Observatory (LIGO), which made history a year ago when its team announced the first direct detection of gravitational waves. This is LIGO\u2019s lesser-known cousin Virgo, a gravitational-wave lab that uses similar equipment and lies in the bucolic Tuscan flatlands near Pisa in Italy. Virgo began hunting gravitational waves in 2007. LIGO came online in 2002 and made its first discovery \u2014 of waves produced by the  merger of two black holes  \u2014 in September\u00a02015, leading to the  announcement on 11\u00a0February\u00a02016 . Virgo was being upgraded and missed the event, a source of quiet disappointment. \u201cLet\u2019s be honest, it will be the Americans who will get the Nobel,\u201d says Luciano Maiani, a particle physicist at the Sapienza University of Rome. Maiani headed Italian funding agency the INFN in the 1990s, when it gave Virgo the go-ahead along with the CNRS, France\u2019s basic-research agency. Now, the 5-year, \u20ac23-million (US$24\u00a0million) \u2018Advanced Virgo\u2019 overhaul is almost finished: the upgraded lab will be inaugurated on 20\u00a0February, although it will be several more weeks before it starts doing science. Together, the twin LIGO machines and Virgo will make more-detailed and more-confident detections than LIGO alone. \u201cWe\u2019re happy to have an instrument that\u2019s starting to come back to life,\u201d says physicist Bas Swinkels, who is co \u00ad ordinating the Virgo tune-up. LIGO\u2019s September find, combined with one it made on 25\u00a0December\u00a02015, suggest that gravitational-wave detections will occur regularly. This validates the whole enterprise and  opens up the field of gravitational-wave astronomy  that Virgo helped to pioneer. \u201cAfter the announcement, we felt vindicated,\u201d says Giovanni Losurdo, who has worked at Virgo since the early 1990s and led the overhaul project. \u201cAll the work we did for nearly 30\u00a0years in near-obscurity suddenly gained a meaning.\u201d The LIGO and Virgo teams have an agreement to pool their data; the LIGO discovery papers included Virgo researchers. Named after the Virgo cluster of galaxies whose stellar explosions it aims to detect, Virgo was built by a Franco-Italian collaboration. The Netherlands, Hungary and Poland later joined up. The Virgo interferometer runs laser light back and forth inside two metal vacuum tubes each 3\u00a0kilometres long, which are housed inside elevated tunnels. Like LIGO, this set-up detects a space-time ripple by constantly comparing the lengths of its two arms for discrepancies of less than one part in 10 21 . But the interfero\u00admeters are shorter than LIGO\u2019s 4-kilometre-long instruments, making Virgo less sensitive. And during the latest rebuild, a significant snafu occurred that will temporarily reduce its sensitivity further. To increase stability and reduce noise, Losurdo\u2019s team had replaced the four silica mirrors that keep the laser bouncing inside the two arms with new mirrors that weigh twice as much as their predecessors, and hung them from hair-thin, fused-silica fibres. But the fibres soon disintegrated, and the team switched back to the steel wires used in the previous decade, which are less effective at keeping out unwanted vibrations. A task force concluded that stray microscopic particles were to blame and that an upgrade to the systems keeping the mirrors under high vacuum should fix the problem, says Swinkels. But for now, the lab plans to forge ahead with the steel wires and replace them later with the silica fibres. In its first run, Virgo should reach more than one-quarter the current sensitivity of LIGO, Swinkels says. Once the silica fibres are installed and other improvements are made, that could rise to one-half, meaning Virgo could scan a cosmic region eight times larger than with steel wires. Even though Virgo has less reach than LIGO, having a third machine will help in several ways. Interferometers are not equally sensitive in all directions, and have blind spots. If the waves come from a direction for which LIGO is relatively ineffective, Virgo could add key information about the event that created them, says Virgo spokesman Fulvio Ricci, a physicist at the Sapienza University of Rome. With a third machine, LIGO can also detect more events, adds theoretical physicist B.\u00a0S.\u00a0Sathyaprakash, a senior LIGO researcher at Pennsylvania State University in University Park. Gravitational-wave signals are picked out from background noise, and a small blip in only one interferometer is almost certainly just that; simultaneous blips in two interferometers may still be a fluke.But blips in three machines at once significantly raise the odds that an actual ripple went by. Because signals from more-distant sources are fainter, Sathyaprakash estimates that Virgo might extend LIGO\u2019s reach by up to 12%, which would mean monitoring 40% more of the volume of the Universe. Perhaps the biggest advantage of a third interferometer is that it helps to narrow down the possible origin of the waves. For the event that underpinned LIGO\u2019s discovery, the collaboration could say only that it came from a slice of sky centred near the celestial south pole. By triangulating the precise timing of future signals from all three interferometers, researchers will be able to narrow the region down by at least a factor of five. This is important for astronomers who plan to look for visible light or other radiation coming from the same gravitational-wave source. Receiving both types of signal from the same event could help to elucidate phenomena such as supernova explosions. And searching a narrower region could reduce a week\u2019s worth of observation to one night, Sathyaprakash says. That precision should improve further when the Kamioka Gravitational Wave Detector, or KAGRA, near Hida City in Japan, joins the gravitational-wave family in 2018. KAGRA\u2019s arms are 3\u00a0kilometres long, like Virgo\u2019s, but two key features aimed at reducing noise will diffentiate it from LIGO and Virgo: it is the first major interferometer to be built underground, and its mirrors will be kept some 20\u2009degrees above absolute zero, not at room temperature. Several years later, another family member should light up:  LIGO-India , a replica of the twin LIGO machines. The Indian government has selected a site in Maharashtra state, but construction has yet to begin, says LIGO-India spokesman Tarun Souradeep, a cosmologist at the Inter-University Centre for Astronomy and Astrophysics in Pune. For now, all eyes are on Virgo. \u201cWe feel the pressure from LIGO, from the funding agencies and from the whole world to get this online,\u201d Swinkels says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @dcastelvecchi \n               \n                     LIGO detects whispers of another black-hole merger 2016-Jun-15 \n                   \n                     The black-hole collision that reshaped physics 2016-Mar-23 \n                   \n                     Gravitational waves: How LIGO forged the path to victory 2016-Feb-16 \n                   \n                     Nature  special: Gravitational waves \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21330", "url": "https://www.nature.com/articles/nature.2017.21330", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "US agency releases finalized \u2018Common Rule\u2019, which governs human-subjects research. In a blow to patient-privacy advocates, the US government has abandoned a plan that would have required scientists to obtain the consent of people who donate biological samples before using the material in subsequent studies. The US Department of Health and Human Services (HHS) had proposed the change in 2015, as part of an overhaul of the \u2018Common Rule\u2019, a set of regulations that govern clinical trials and patient consent in research. But the provision was not included in  the final version of the rule  released on 18 January. Most of the changes to the 26-year-old Common Rule are intended to lessen the regulatory burden on researchers. They eliminate requirements that researchers obtain individual approval from ethics boards at every institution where a study will be performed, for instance. This allows individual government agencies to decide whether a study needs multiple approvals or not. The HHS first released its  proposed revisions to the Common Rule in September 2015 . That version would have required researchers to obtain consent from patients before using biological samples such as blood and tissue in studies, even if those specimens could not be identified. The US National Academies of Sciences, Engineering and Medicine  blasted that requirement and others  in a June 2016 report, arguing that the changes would impose an undue burden on researchers. The academies said that the government's plan was \u201cmarred by omissions and a lack of clarity\u201d, and recommended that it be withdrawn. \n               Mixed feelings \n             The final version of the Common Rule shows that the government listened to scientists\u2019 fears about increased research burdens, says Ellen Clayton, a bioethicist and lawyer at Vanderbilt University in Nashville, Tennessee. \u201cI went into my chair\u2019s office and did a happy dance, I\u2019m thrilled.\u201d The updated Common Rule does still require that patients be informed if the research might include whole-genome sequencing, which could make the specimens they donate identifiable. Clayton cautions that the idea of \u2018identifiability\u2019 may change in the future as genomic analysis and electronic security technologies evolve, and the law may need to evolve as well. But the decision to drop the consent requirement is a disappointment to Twila Brase, president and co-founder of the Citizens' Council for Health Freedom in St Paul, Minnesota. The group has campaigned to have blood spots used in infant disease screenings classified as human subjects, and require consent for their use in research. Under US law, Congress has 60 days to retract the updates to the Common Rule, and Brase says that her group will ask it to do so and reinstate the consent requirement. The new version of the Common Rule does require that researchers include a description of the study, along with the risks and benefits, on the consent forms used by patients. It also stipulates that some federally funded trials must post patient consent forms online. However, the requirements do not extend to trials that do not receive federal funds. The agency decided that extending the rule to non-federally funded trials would be an unnecessary burden, says Jerry Menikoff, director of the HHS Office for Human Research Protections. Most institutions that receive federal money apply the Common Rule to all of their trials regardless of who funds them, he says. That decision is a disappointment, says Michael Carome, director of health research at the consumer-advocacy group Public Citizen in Washington DC. \u201cWe think human subjects deserve protection whether or not they're in a federally funded trial.\u201d \n                     Science academies blast US government\u2019s planned research-ethics reforms 2016-Jun-29 \n                   \n                     US agencies plan research-ethics overhaul 2015-Sep-03 \n                   \n                     US agency updates rules on sharing genomic data 2014-Sep-01 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21342", "url": "https://www.nature.com/articles/nature.2017.21342", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Open-science advocate says journals should be clearer to peer-reviewers about terms and conditions. Are peer-reviewers free to openly share the content of their reviews if journal editors haven\u2019t explicitly told them not to? Jon Tennant, a scientist-turned-outreach specialist, thinks so. Tennant had reviewed a research paper submitted to the journal  Palaeogeography, Palaeoclimatology, Palaeoecology . He recommended that the authors\u2019 new approach to studying fossil seabird fauna should be published. The journal\u2019s editors agreed and published the paper. Tennant, who now works as communications director at ScienceOpen, an online platform that promotes open-access research, wanted to receive credit for his unpaid peer-review work. With permission from the authors of the paper, he decided to openly post the text of his review on Publons, a  platform for sharing reviews . But his post was turned down. Publons told him that the journal\u2019s publisher, Elsevier, requires reviewers to obtain permission from journal editors before posting a review. That was not part of the deal \u2014 at least, not explicitly \u2014 Tennant argues. \u201cI didn\u2019t sign a confidentiality agreement, and I was not aware that I had implicitly agreed to the journal\u2019s policies,\u201d he says. Since he retains the copyright for his review, he argues that he is free to publish its text if he has not made any other pre-agreement with the journal. \n               Implicit standards \n             Elsevier does have peer-review guidelines on its website, notes Thomas Algeo, a geochemist at the University of Cincinnati in Ohio and co-editor-in-chief of  Palaeogeography, Palaeoclimatology, Palaeoecology.  According to the guidelines, reviewers \u201cmust not share information about the review with anyone without permission from the editors and authors\u201d. Those policies are in line with  general guidelines  adopted by the Committee on Publication Ethics, an independent organization that sets standards for scientific publication. Peer-reviewers should \u201crespect the confidentiality of peer review and not reveal any details of a manuscript or its review, during or after the peer-review process, beyond those that are released by the journal\u201d, the guidelines say. \u201cThese are general community standards for peer review, of which all experienced science professionals should be aware,\u201d says Algeo. But Tennant says he was never explicitly pointed to Elsevier\u2019s guidelines. He says that before he raised his objections, he had  added a note to his personal website , saying that he charges \u00a310,000 (US$12,500) for peer reviews. Does this mean, he asks, that because he didn't point journal editors to this condition, he could claim money? The question is a rhetorical jab, Tennant says: he\u2019s not trying to get cash. But he says that some journals are failing to explicitly communicate their terms and conditions for reviewers. Another co-editor for the journal, palaeoclimatologist Paul Hesse at Macquarie University in Sydney, Australia, agrees that the journal itself is not specific about such policies in its invitation letters, which typically request that reviewers \u201cgive this review invitation the same consideration that you would want one of your own manuscripts to receive\u201d. \n               Push for open review \n             Charles Oppenheim, a consultant in Aberdeen, UK, who specializes in copyright issues and scholarly publishing, thinks Tennant has a point. \u201cReviewers should not need to dig around for terms and conditions,\u201d he says. Scholarly publishers, he adds, shouldn\u2019t assume confidentiality; they should make it explicitly clear upfront if their policy is to restrict dissemination of reviews. \u201cIf they don\u2019t, they are heading for difficulties as the idea of open peer review is becoming more common.\u201d Tennant has raised the issue before. In 2015, he debated his rights to share a peer review that he\u2019d conducted for a paper in the  Journal of Morphology , published by Wiley. He eventually agreed not to post it online. But after that debate, Wiley revisited its policies, says its editorial director Allyn Molina. \u201cWe thought Jon raised some important questions regarding the accessibility of our peer-review guidelines,\u201d she says, adding that the publisher has now made its policy clearer in correspondence to reviewers. (At Wiley, she says, peer review is confidential unless a particular journal has a policy of open review.) The  growing popularity of open peer review  is prompting journals to rethink both their policies and the way in which they communicate these to reviewers, says Andrew Preston, the London-based co-founder and chief executive of Publons. Many journals are making clear on Publons what they do \u2014 and don\u2019t \u2014 allow in terms of sharing reviews, he says. The site is also in discussion with companies, including  Nature \u2019s publisher Springer Nature, to figure out other ways of sharing credit for peer-reviewing in cases in which open review isn\u2019t allowed. ( Nature \u2019s news team is editorially independent of the journal  Nature .) \u201cWe\u2019re caught in the middle of people who want very different things,\u201d Preston says. \u201cAnd while the community will need to find middle ground, it\u2019s good that some people are pushing at the edges.\u201d \n                     Open peer review finds more takers 2016-Nov-10 \n                   \n                     Peer review: Close inspection 2016-May-11 \n                   \n                     Review rewards 2014-Oct-15 \n                   \n                     The scientists who get credit for peer review 2014-Oct-09 \n                   \n                     Publishing: Credit where credit is due 2014-Apr-16 \n                   \n                     Publons \n                   \n                     COPE - ethical guidelines for peer reviewers [PDF] \n                   Reprints and Permissions"},
{"file_id": "541447b", "url": "https://www.nature.com/articles/541447b", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Scepticism surrounds the ultimate potential of D-wave machines, but researchers are already finding uses for them. The company that makes the world\u2019s only commercially available quantum computers\u00a0has released its biggest machine yet \u2014 and researchers are paying close attention. Named 2000Q after the number of quantum bits, or qubits, within its processor, the machine, made by D-Wave of Burnaby, Canada, has almost twice as many qubits as its predecessor. Many researchers remain sceptical about the long-term potential of such machines, whose approach differs from that of other nascent quantum computers. But others are already booking time on D-Wave\u2019s computers to explore challenges from machine learning to cybersecurity. Moreover, improvements to 2000Q, the company\u2019s fourth-generation machine, are largely a result of researchers\u2019 feedback. \u201cWe\u2019re providing guidance as a community of scientists,\u201d says Davide Venturelli, a physicist at the NASA Ames Research Center. Venturelli manages a scheme run by the non-profit Universities Space Research Association (USRA) in Washington DC that lets external researchers access a joint NASA\u2013Google D-Wave machine. D-Wave is also working on a fifth model, which it hopes will answer critics by providing even greater capacity and connectivity and a closer fit to scientists\u2019 needs. Likely to launch within two years, the machine will again double the number of qubits, to around 4,000. Crucially, it will also provide more-complex connections between qubits, allowing it to tackle more-complicated problems. \u201cChanging the underlying connectivity is going to be a game-changer,\u201d says Mark Novotny, a physicist at Charles University in Prague, who is exploring a D-Wave machine\u2019s applications to cybersecurity. \u201cI\u2019m basically drooling hoping for it. It\u2019s very exciting.\u201d D-Wave machines have attracted scepticism as well as excitement since they went on sale six years ago. So far, researchers have proved that, for a problem crafted to suit the machine\u2019s abilities, the quantum computer can offer a huge increase in processing speed over a classical version of an algorithm ( V. S. Denchev  et al. Phys. Rev. X    6, 031015; 2016 ). But the computers do not beat every classical algorithm, and no one has found a problem for which they outperform all classical rivals. D-wave\u2019s qubits are much easier to build than the equivalent in more traditional quantum computers, but their quantum states are also more fragile, and their manipulation less precise. So although scientists now agree that D-wave devices do use quantum phenomena in their calculations, some doubt that they can ever be used to solve real-world problems exponentially faster than classical computers \u2014 however many qubits are clubbed together, and whatever their configuration. The uncertainty hasn\u2019t stopped the number of users growing: last September, around 100 scientists attended D-Wave\u2019s first users\u2019 conference in Santa Fe, New Mexico. Existing D-Wave computers are located in the United States, but researchers globally can access them remotely, including through schemes such as the USRA\u2019s. The machines are attracting new kinds of researcher, says Venturelli, who uses one of them to try to find the best way for rovers to autonomously schedule operations and manage time. \u201cUniversities with nothing to do with quantum physics are now trying their algorithms,\u201d he says. Unlike other quantum computers , D-Wave is suitable only for solving certain tasks, known as optimization problems. To find optimal solutions, researchers first put qubits, made of superconducting loops, into their lowest energy state, in which each is in a quantum superposition of both \u2018on\u2019 and \u2018off\u2019. Magnetic fields that represent the problem then gently nudge this state towards a new one\u00a0\u2014\u00a0a process known as quantum annealing. The state evolves while maintaining its low energy such that when it eventually \u2018collapses\u2019, it should leave qubits in the best configuration for solving that problem. Because the system sifts every possible answer at once, in theory it could be a faster way to resolve problems that, when solved classically, get exponentially harder with each added variable. But posing research questions in a form that the machine can handle often means using several qubits to represent a single variable, limiting the size of the problems it can handle. \u201cQuantum computing is a new tool,\u201d says Novotny. \u201cSo, part of what we\u2019re doing is just trying to figure out how we can use it.\u201d He works on machine-learning algorithms known as Boltzmann machines, used to study patterns in online traffic and identify cyberattacks. So far, for small examples, his group has been able to show that D-Wave\u2019s machines can be more efficient than their classical counterparts, detecting likely attacks more quickly, he says. D-Wave\u2019s latest iteration includes an upgrade that Novotny has been clamouring for. The feature gives more control when different groups of qubits go through the annealing process. In at least one case, D-Wave has shown that this can speed up certain calculations 1,000-fold. For Novotny, the feature is crucial because it will allow his team to \u201csample\u201d qubits during the process, which opens the door to D-Wave exploring a different type of machine-learning algorithm that could learn to recognize much more complex patterns of cyberattacks. But researchers want greater connectivity. Currently, each qubit in the processor can \u2018talk\u2019 to only six others, says Scott Pakin, a computer scientist and D-Wave scientific and technical lead at the Los Alamos National Laboratory in New Mexico, which has had a D-Wave computer since August. \u201cThe richer the connections, the easier and faster it is to get problems onto the D-Wave. So that\u2019s top of my wish list.\u201d D-Wave is redesigning its fifth processor to increase connectivity significantly, says \u00adJeremy Hilton, the company\u2019s senior vice-president responsible for technology. And because this upgrade involves a hardware overhaul, it will have an additional benefit: allowing the firm to expand beyond the 10,000-qubit limit imposed by the current processor\u2019s design in future machines, he adds. D-wave machines are a long way from showing the exponential speed increase over classical computers that their advocates hope to see. But in a paper posted on 17 January and not yet peer-reviewed, a D-Wave team claimed the 2000Q could find solutions up to 2,600 times faster than any known classical algorithm ( J.Kingetal.PreprintatarXivhttps://arxiv.org/abs/1701.04579;2017 ). Now the onus will be on sceptics to try to find a faster classical algorithm. \u201cAll I know is that, in the now two or three previous cases where we were in this same situation, it did turn out that a different classical solver eliminated the claimed gap,\u201d says Scott Aaronson, a computer scientist at the University of Texas at Austin. Hilton thinks that, this year, D-Wave will  demonstrate a computation  that would be impossible for even the most powerful classical supercomputer, a goal that competitors call \u201cquantum supremacy\u201d. \u201cWe\u2019ve achieved some results,\u201d he says, \u201cand are working with outside collaborators to review those and see if they hold up.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Quantum computers ready to leap out of the lab in 2017 2017-Jan-03 \n                   \n                     Inside Microsoft\u2019s quest for a topological quantum computer 2016-Oct-21 \n                   \n                     Quantum computer makes first high-energy physics simulation 2016-Jun-22 \n                   \n                     Google moves closer to a universal quantum computer 2016-Jun-08 \n                   \n                     Silicon quantum computers take shape in Australia 2016-May-24 \n                   \n                     Google and NASA snap up quantum computer 2013-May-16 \n                   Reprints and Permissions"},
{"file_id": "541445a", "url": "https://www.nature.com/articles/541445a", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Old-school areas of plant biology are getting tech upgrades that herald more detailed, faster data collection. As a postdoc, plant biologist Christopher Topp was not satisfied with the usual way of studying root development: growing plants on agar dishes and placing them on flatbed scanners to measure root lengths and angles. Instead, he would periodically stuff his car with plants in pots dripping with water and drive more than 600 kilometres from North Carolina to Georgia to image his specimens in 3D, using an X-ray machine in a physics\u00a0lab. Five years later, the idea of using detailed imaging to study plant form and function has caught on. The use of drones and robots is also on the rise as researchers pursue the \u2018quantified plant\u2019 \u2014 one in which each trait has been carefully and precisely measured from nearly every angle, from the length of its root hairs to the volatile chemicals it emits under duress. Such traits are known as an organism\u2019s phenotype, and researchers are looking for faster and more comprehensive ways of characterizing it. From 10 to 14 February, scientists will gather in Tucson, Arizona, to compare their methods. Some will describe drones that buzz over research plots armed with hi-tech cameras; others will discuss robots that lumber through fields bearing equipment to log each plant\u2019s growth. The hope is that such efforts will speed up plant breeding and basic research, uncovering new aspects of plant physiology that can determine whether a plant will thrive in the field. \u201cPhenotype is infinite,\u201d says Topp, who now works at the Donald Danforth Plant Science Center in St\u00a0Louis, Missouri. \u201cThe best we can do is capture an aspect of it \u2014 and we want to capture the most comprehensive aspect we can.\u201d The plummeting cost of DNA sequencing has made it  much easier to find genes , but working out what they do remains a challenge, says plant biologist Ulrich Schurr of the J\u00fclich Research Centre in Germany. \u201cIt is very easy now to sequence a lot of stuff,\u201d he says. \u201cBut what was not developed with the same kind of speed was the analysis of the structure and function of plants.\u201d Plant breeders are also looking beyond  the traits they used to focus on \u2014 such as yield and plant height \u2014 for faster ways to improve crops. \u201cThose traits are useful but not enough,\u201d says Gustavo Lobos, an ecophysiologist at the University of Talca in Chile. \u201cTo cope with what is happening with climate change and food security, some breeders want to be more efficient.\u201d Researchers aiming to boost drought tolerance, for example, might look at detailed features of a plant\u2019s root system, or at the arrangement of its leaves. \n               A need for speed \n             The needs of these researchers have bred an expanding crop of phenotyping facilities and projects. In 2015, the US Department of Energy announced a US$34-million project to generate the robotics, sensors and methods needed to characterize sorghum, a biofuel crop. Last year, the European Union launched a project to create a pan-European network of phenotyping facilities. And academic networks have sprung up around the globe as plant researchers attempt to standardize approaches and data analyses. Large-scale phenotyping has long been used in industry, but was too expensive for academic researchers, says Fiona Goggin, who studies plant\u2013insect interactions at the University of Arkansas in Fayetteville. Now, the falling prices of cameras and drones, as well as the rise of the \u2018maker\u2019 movement that focuses on homemade apparatus, are enticing more academics to enter the field, she says. At Washington State University in Pullman, biological engineer Sindhuja Sankaran\u2019s lab is preparing to deploy drones carrying lidar, the laser equivalent of radar. The system will scan agricultural fields to gather data on plant height and the density of leaves and branches. Sankaran also uses sensors to measure the volatile chemicals that plants give off, particularly when they are under attack from insects or disease. She hopes eventually to mount the sensors on robots. Sankaran\u2019s mechanical minions return from their field season with hundreds of gigabytes of raw data, and analysing the results keeps her team glued to computers for the better part of a year, she says. Many researchers do not realize the effort and computing savvy it takes to pick through piles of such data, says Edgar Spalding, a plant biologist at the University of Wisconsin\u2013Madison. \u201cThe pheno\u00adtyping community has rushed off to collect data and the computing is an afterthought.\u201d Standardizing the technology is another barrier, says Nathan Springer, a geneticist at the University of Minnesota in St Paul. The lack of equipment everyone can use means that some researchers have to rely on slower data-collection methods. Springer has been working with 45\u00a0research groups to characterize 1,000\u00a0varieties of maize (corn) grown in 20\u00a0different environments across the United States and Canada. The project has relied heavily on hand measurements rather than on drones and robots, he says. Topp now has his own machine to collect computed tomography (CT) images, but processing samples is still a little slow for his liking. He speaks with reverence of a facility at the University of Nottingham, UK, that speeds up its scans by using robots to feed the plants through the CT machine. But he\u2019s pleased that he no longer has to haul his soggy cargo across three states to take measurements. \u201cIt\u2019s just endless, the number of possibilities.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @heidiledford \n               \n                     Plant-genome hackers seek better ways to produce customized crops 2016-Nov-02 \n                   \n                     Plant biology: Growth industry 2010-Dec-15 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21378", "url": "https://www.nature.com/articles/nature.2017.21378", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Chimaeras could pave the way for growing human organs in other animals. Scientists have published the first peer-reviewed account of creating pig\u2013human hybrid fetuses, a step toward growing animals with  organs that are suitable for transplantation into humans . The team that made these chimaeras also reports the creation of mouse\u2013rat and human\u2013cow hybrids on 26 January in  Cell 1 . Such modified animals could provide researchers with new models for testing drugs and understanding early human development. To create chimaeras, scientists generally inject pluripotent stem cells \u2014 which can become any type of organ \u2014 from one species into the early embryo of a second species. In theory, the foreign cells should differentiate and spread throughout the body, but in practice,  producing viable hybrid embryos has proven difficult . To get around this, a team led by developmental biologist Juan Carlos Izpisua Belmonte of the Salk Institute for Biological Studies in La Jolla, California, used  CRISPR gene-editing technology  to create mouse embryos without the genes that cause organs to form. The scientists then injected rat stem cells into the mouse embryos and implanted the embryos into a mouse\u2019s uterus. Because the rat cells still contained genes for organ formation, the resulting chimaeras had organs that were composed largely of rat cells. The animals lived for up to two years, the normal lifespan of a mouse. \n             Mix and match \n           Next, the researchers attempted to hybridize two distantly related species: humans and pigs. The team injected more than 1,400 pig embryos with one of three types of human induced pluripotent stem cell \u2014 normal cells, cells that were primed to develop into tissue or \"intermediate\" cells that were neither normal nor fully primed. All of the human cells had been modified to produce a green fluorescent protein so that they could be identified within the newly created chimaeras. The scientists allowed the pig\u2013human chimaeras to develop for three to four weeks before destroying them, according to ethics regulations. Chimaeras injected with the intermediate stem cells grew to contain the largest proportion of human cells, suggesting that previous attempts to create chimaeras may have used stem cells at the wrong stage of development. Even then, only about 1 in 100,000 of the cells in the pig\u2013human chimaeras were human \u2014 at best, says study co-author Jun Wu, a biologist at the Salk Institute. \u201cI think it\u2019s a very important, very exciting paper,\u201d says Jacob Hanna, a developmental biologist at the Weizmann Institute of Science in Rehovot, Israel. Now, he says, researchers will want to see whether the human cells in the chimaeras have normal DNA structure and gene expression. But Hiromitsu Nakauchi, a stem-cell researcher at Stanford University in California, says that the low number of human cells in the pig\u2013human chimaeras means that the hybrids are still a long way from serving any useful purpose, such as organ donors. \u201cIt\u2019s a good try, but the result seems like more a negative result,\u201d he says. \n             Transplant hopes \n           Nakauchi\u2019s group is using similar methods to create human\u2013sheep chimaeras, in part because he suspects that sheep embryos may be better able to take up human cells than pig embryos can. But Wu, says that pigs will probably be the best organ donors, because their large litter sizes would allow quicker production of organs. Pig organs are also close to the same size as human ones. Researchers are pursuing a number of strategies to make pigs into human-organ donors, such as  using CRISPR to disable pig proteins  that could cause an immune response in primates. The advantage of chimaeras, Izpisua Belmonte says, is that researchers could one day use a patient\u2019s own cells to create a pig chimaera with a human organ that has been grown for that individual. \n                   US agency to lift ban on funding human\u2013animal hybrids 2016-Aug-05 \n                 \n                   Scientists stumble across unknown stem-cell type 2015-May-06 \n                 \n                   Hybrid embryos fail to live up to stem-cell hopes 2009-Feb-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21343", "url": "https://www.nature.com/articles/nature.2017.21343", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "What Novozymes might do with the NgAgo protein, claimed by some to be a powerful gene editor, is still unclear. A major enzyme manufacturer has signed an agreement with a Chinese university to explore uses for a protein claimed to be a  powerful alternative  to the  popular genome-editing tool CRISPR\u2013Cas9 .\u00a0 Several scientists have failed to reproduce the results of the paper that first made the claim and doubt that the protein, NgAgo, works as a gene editor. It is not clear whether the company \u2014 Novozymes of Bagsv\u00e6rd, Denmark \u2014 plans to use NgAgo for gene editing. \u201cWe have tested the technology and seen indications that it might be useful, but it is very early in its development and still needs a lot of work before we can determine if it is relevant for us,\u201d said company spokesperson Dongyi Chen. The company said that it had made an undisclosed upfront payment to the Hebei University of Science and Technology in Shijiazhuang to use NgAgo. It also says that the university will receive royalties if Novozymes uses the technology in developing a commercial product. \n               DNA snipper \n             In May, a group led by Hebei biologist Han Chunyu reported 1  that NgAgo could be used to locate and snip specific bits of DNA in laboratory-grown human cells, permanently disabling genes. The  paper claimed  that NgAgo might be more efficient and versatile than the now-ubiquitous CRISPR\u2013Cas9 gene-editing technique. But NgAgo soon  attracted controversy . Initial complaints on social media that the research could not be replicated were followed by a  series of peer-reviewed publications demonstrating the same . Some researchers used human cells as Han did, while others tried zebrafish or mouse cells. Some of those researchers reported that NgAgo could disrupt genes, and suggested that this was because it interrupts the process by which the genes are turned into proteins \u2014\u2018silencing\u2019 the genes rather than permanently altering the DNA. Both methods prevent a gene from being expressed, but whereas gene editing is permanent, silencing is not. In November 2016,  Nature Biotechnology  published one of the papers 2  in which a group of researchers  reported that they could not reproduce Han\u2019s initial results , and the journal released an  'expression of concern ' about the Han team\u2019s original paper. The journal also said that it would make an announcement about that paper by the end of January. Han has  steadfastly stood by his results , arguing that cell contamination may explain the failures by others. \n               New data \n             On 19 January, the journal postponed a conclusive announcement, saying in a statement that\u00a0 \u201c new data related to the reproducibility of the NgAgo system have become available to the journal, which we need to explore before any further action could be taken\u201d. ( Nature Biotechnology \u00a0is published by\u00a0 Nature \u2019s publisher, Springer Nature;\u00a0 Nature \u2019s news team is editorially independent of the publisher\u2019s research editorial teams.) On the same day, Han\u2019s university  announced a cooperation agreement  between\u00a0Novozymes and the university's Center for Gene Editing Technology. Novozymes then confirmed that it had entered a collaboration with the university \"to explore if NgAgo can be a tool in the microbial systems we work with for enzyme production\u201d.\u00a0 The company did not respond to the question of whether it had succeeded in using NgAgo to do genome editing. NgAgo has \u201cshown potential\u201d in a fungus gene-expression system produced by Novozymes, says the university's press release, which Novozymes confirmed. Han\u00a0says that Novozymes has\u00a0\u201cevidence that real genetic modification has occurred\u201d. Gaetan Burgio,\u00a0a geneticist at the Australian National University in Canberra\u00a0and  one of the first scientists to publish a critique of Han\u2019s claims ,\u00a0suspects that Novozymes\u2019 interest in NgAgo may not be as a gene editor. He notes that the company has an RNA-interference technology used to silence gene expression. \u201cMy speculation here is they might have found a more powerful way to silence the genome,\u201d he says. \n               Gene silencer \n             The scope of the contract between Novozymes and Hebei University of Science and Technology isn\u2019t clear. Han says that Novozymes licensed NgAgo \u201cfor genetic manipulation\u201d, which could include\u00a0both genome editing and gene-silencing functions. But he says he needs to consult with his lawyer before discussing more details of the patent.\u00a0 Jin-Soo Kim, a geneticist at Seoul National University, says he recently filed a patent claiming the gene-silencing function of NgAgo. Kim co-authored the critique of Han\u2019s paper in  Nature Biotechnology  and has since co-written a report 3  suggesting that NgAgo could be used as a gene silencer. The deal between Novozymes and the university seems to represent a fresh vote of confidence in Han\u2019s technology as well as in the university's gene-editing centre, which was launched last summer at a cost of 224 million yuan (US$32 million) and has been criticized given the problems surrounding NgAgo. But among the scientific community, there seems to be little change to the dwindling enthusiasm for NgAgo gene editing. \u201cThis changes nothing,\u201d says Wei Wensheng, a\u00a0molecular biologist at Peking University in Beijing. \u201cHan claimed that NgAgo would work in a mammalian system for efficient genome editing. Prove it!\u201d \n                     Updated: NgAgo gene-editing controversy escalates in peer-reviewed papers 2016-Nov-23 \n                   \n                     Beyond CRISPR: A guide to the many other ways to edit a genome 2016-Aug-08 \n                   \n                     Replications, ridicule and a recluse: the controversy over NgAgo gene-editing intensifies 2016-Aug-08 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21339", "url": "https://www.nature.com/articles/nature.2017.21339", "year": 2017, "authors": [{"name": "Lauren Morello"}, {"name": "Sara Reardon"}, {"name": "Jeff Tollefson"}, {"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "The US president reiterated his promise to roll back climate regulations on his first day in office. US President Donald Trump took office on 20 January, pledging to \u201cunlock the mysteries of space, to free the Earth from the miseries of disease, and to harness the energies, industries and technologies of tomorrow\u201d. His early actions included publishing an energy plan that reiterates  his campaign promise to repeal federal climate-change regulations , and freezing new or pending regulations on any topic until they can be reviewed by Trump administration officials. Among the policies that could be affected is  the 'Common Rule' on human-subjects research ; a revised version of the rule was finalized on 18 January, but has not yet taken effect. Also ensnared is the Fish and Wildlife Service's plan to put the rusty patched bumblebee ( Bombus affinis ) on the endangered species list, and several energy-efficiency regulations from the Department of Energy. Trump\u2019s inaugural speech, delivered from a platform overlooking Washington DC\u2019s monument-filled National Mall, described a country in decline. The president\u2019s pledge to reverse \u201cAmerican carnage\u201d took a markedly different tone from the hopeful address of Barack Obama in 2009, when Obama delighted many scientists  by pledging to \u201crestore science to its rightful place\u201d . \"The switch of focus to national borders, local concerns and short-term problems should give scientists cause for concern,\" says Jack Stilgoe, a science-policy expert at University College London, who is on sabbatical at the University of Colorado Boulder. \"If 'America first' translates into techno-nationalism, then the world and its science will be worse off.\" Others are still in wait-and-see mode. \u201cIn the science community there have been alarm bells, reports that the president has already launched a war on science,\u201d says Tobin Smith, vice-president for policy at the Association for American Universities in Washington DC. \u201cI think it\u2019s way too premature to draw that conclusion.\u201d That  did not stop scientists from joining protesters at massive rallies  in Washington DC and other cities around the world to protest against Trump\u2019s policies. Many said that they are concerned by Trump\u2019s questioning of the science underlying climate change, and by his remarks suggesting a link between vaccination and autism. \n               Fossil fuels first \n             Minutes after Trump took the oath of office, the White House website displayed  the new president's 'America First' energy plan . \u201cFor too long, we\u2019ve been held back by burdensome regulations on our energy industry,\u201d the document says. \u201cPresident Trump is committed to eliminating harmful and unnecessary policies such as the Climate Action Plan and the Waters of the U.S. rule.\u201d The  Climate Action Plan  is the collective name for  regulations to reduce greenhouse-gas emissions and fight climate change  that were put in place by the administration of the previous president, Barack Obama. The Trump energy plan pledges to \u201crefocus the EPA on its essential mission of protecting our air and water\u201d. The EPA, or Environmental Protection Agency, regulates heat-trapping emissions from power plants, vehicles and other sources. It has been the key actor in Obama's climate plan. Trump's strategy emphasizes fossil fuels, calling for greater development of US shale, oil and natural-gas reserves, and says the administration is \u201ccommitted to clean coal technology\u201d. But it does not mention renewable energy sources.\u00a0 \u201cOmitting renewable energy from the plan is churlish,\u201d says Robert Socolow, a climate scientist at Princeton University in New Jersey. \u201cIt reads like score-settling.\u201d Socolow adds that he was surprised that the plan also omits any mention of nuclear energy. The focus on fossil fuels carries enormous risks for Trump, says Sam Adams, US director for the World Resources Institute, an environmental think tank in Washington DC. The president has promised to create jobs, but ignoring clean energy \u2014 one of the fastest-growing sectors in the US economy \u2014 could drive jobs overseas, Adams says, while worsening global warming. \"There lies, somewhere ahead in the path that they have taken, a political trip wire,\" Adams says. \"The political accountability will rest with them, for failing to act.\" \n               Taking Trump's temperature \n             For biomedical researchers, it is still unclear what the Trump administration will bring, despite the president's inaugural pledge to fight disease. \u201cI could see a world in which it was equally likely we could wake up tomorrow and find that the president has proposed that the NIH budget be doubled or that the president has proposed that the NIH be eliminated,\u201d says Benjamin Corb, director of public affairs at the American Society for Biochemistry and Molecular Biology in Rockville, Maryland. \u201cIt\u2019s really unknown right now and I think that\u2019s a challenge we\u2019re trying to deal with.\u201d Still, Corb sees reasons to be hopeful \u2014 including the Trump team's decision, announced on 19 January,  to retain National Institutes of Health director Francis Collins , at least temporarily. Collins was nominated to the job by former president Barack Obama and took office in 2009. Still, Trump has said nothing serious about the agency or biomedical research in general. \u201cWe\u2019re watching all our crystal balls, but they appear to be foggy,\u201d Corb says. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     NIH director Francis Collins staying on \u2014 for now 2017-Jan-19 \n                   \n                     Perry promises to protect \u2018all of the science\u2019 at the US energy department 2017-Jan-19 \n                   \n                     Trump\u2019s vaccine-commission idea is biased and dangerous 2017-Jan-17 \n                   \n                     Surprising contenders emerge for Trump\u2019s NIH chief 2017-Jan-13 \n                   \n                     Is Donald Trump pushing more scientists towards political activism? 2016-Dec-13 \n                   \n                     Does it matter if Donald Trump has a science adviser? 2016-Dec-08 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21380", "url": "https://www.nature.com/articles/nature.2017.21380", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Unusual study of NASA\u2019s Scott and Mark Kelly finds gene-expression shifts during nearly a year in space. Preliminary results are in from  NASA\u2019s unprecedented twin study  \u2014 a detailed probe of the genetic differences between astronaut Scott Kelly, who spent nearly a consecutive year in space, and his identical twin Mark. Measurements taken before, during and after Scott Kelly\u2019s mission reveal changes in gene expression, DNA methylation and other biological markers that are likely to be attributable to his time in orbit. From the lengths of the twins\u2019 chromosomes to the microbiomes in their guts, \u201calmost everyone is reporting that we see differences\u201d, says Christopher Mason, a geneticist at Weill Cornell Medicine in New York City. He and other project scientists reported the early results on 26 January in Galveston, Texas, at  a meeting of scientists working in NASA\u2019s Human Research Program . \u201cThe data are so fresh that some of them are still coming off the sequencing machines,\u201d Mason says. The challenge now is to untangle how many of the observed changes are specific to the physical demands of spaceflight \u2014 and how many might be simply due to natural variations. And because the Kelly twins are just two people, the results may not be generalizable to others. Still, the work is some of the most detailed molecular profiling ever done, involving some of the most physically demanding environments. \u201cThe greatest importance of the study is to show that we can do it,\u201d says team member Andrew Feinberg, a geneticist at Johns Hopkins University School of Medicine in Baltimore, Maryland. \u201cI don\u2019t think people realized it would be so easy to  do genomics on astronauts in space .\u201d Scott Kelly spent 340 days in space in 2015\u201316, giving him a lifetime total of 520 days. Mark Kelly, also an astronaut, had previously flown in space for a total of 54 days over four space-shuttle missions between 2001 and 2011. \n             Space case \n           Because the two men have almost identical genomes and similar life experiences, NASA arranged to have blood and other biological samples taken from them to try and observe biological changes brought about by long-duration spaceflight. Studies of the twins' telomeres, the caps on the ends of their chromosomes, showed that during spaceflight Scott's telomeres grew to be longer than his brother's. \u201cThat is exactly the opposite of what we thought,\u201d says Susan Bailey, a radiation biologist at Colorado State University in Fort Collins. A second lab has studied the same samples and confirmed this puzzling increase in telomere length, she says. Once Scott returned to the ground, the length of his telomeres returned to his pre-flight levels relatively quickly. The scientists are working to figure out what this means, and are running a separate study of telomere length in ten unrelated astronauts that, when completed in 2018, may shed more light on how spaceflight affects telomeres. DNA methylation \u2014 the reversible addition of a chemical marker to DNA that can affect gene expression \u2014 decreased in Scott during flight and increased in Mark over the same period, Feinberg says. Levels for both men returned close to preflight levels after Scott came back to Earth. What this means isn\u2019t yet clear, Feinberg says. Mason\u2019s team also reported changes in gene-expression signatures between the twins. Such changes happen in earthbound people all the time, associated with environmental shifts such as changes in diet and sleep habits. But the changes in Scott seemed to be larger than normal \u2014 perhaps due to the stress of eating freeze-dried food and trying to sleep while floating in space. \n             Data splashdown? \n           Personalized medicine could play into NASA\u2019s plans for how to keep astronauts healthy during long-duration spaceflight, such as any future trips to Mars. For instance, the agency might want to use genetic tests to screen astronaut candidates for cancer susceptibility, says a 6 January report from the US National Academies of Science, Engineering and Medicine. Actually publishing the results of the twin study will take some time, and the full data may never come out. Because of the detailed nature and sheer amount of the genetic information involved in the studies, the Kelly twins will review all information before it is published, to avoid revealing sensitive data they may wish to keep private. \u201cWe\u2019re working with a small number of highly identifiable people here,\u201d John Charles, head of NASA\u2019s Human Research Program, told the meeting. \n                   Zero-gravity genomics passes first test 2015-Oct-13 \n                 \n                   Astronaut twins study raises questions about genetic privacy 2015-Mar-26 \n                 \n                   Space-station science ramps up 2014-Jun-10 \n                 \n                   NASA twins study \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21329", "url": "https://www.nature.com/articles/nature.2017.21329", "year": 2017, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Massive effort plans to stockpile vaccines against future outbreaks. SARS, Zika, Ebola \u2013 when some of the world\u2019s most terrifying disease outbreaks occur, health workers often find themselves powerless. A billion-dollar initiative launched on 18 January aims to change that situation by pre-emptively developing and stockpiling vaccines to combat potential epidemic threats. \u201cI'm thrilled. This is only the formal launch, and to have near $500 million \u2014 and likely more \u2014 to get started is great,\u201d says Jeremy Farrar, director of biomedical charity the Wellcome Trust in London, one of the new project\u2019s backers. The Coalition for Epidemic Preparedness Innovations (CEPI) launched on 18 January at the World Economic Forum in Davos, Switzerland, with an initial US$460 million of backing from Norway, Germany, Japan, the Wellcome Trust and the Bill & Melinda Gates Foundation. The organization expects to raise the full $1 billion that it needs for the next 5 years by the end of 2017, says John-Arne R\u00f8ttingen, CEPI's interim chief executive. It is by far the largest vaccine development initiative ever against viruses that are potential epidemic threats. The first targets for CEPI are vaccines against the Nipah virus and those that cause Middle East respiratory syndrome (MERS) and Lassa fever, which might be next to cause outbreaks similar in scale to SARS, Ebola or Zika. Vaccine researchers welcome the initiative. \u201cI\u2019m delighted to see the launch of CEPI \u2014 it's very much needed,\u201d says vaccine researcher Adrian Hill, director of the Jenner Institute in Oxford, UK. CEPI is well placed to help: \u201cThis group is distinctive in being a large, very inclusive effort spanning academia, public-health agencies, large and small companies and a range of philanthropic and government funders,\u201d says Hill. \n               Stocking the pipelines \n             The Ebola epidemic that began in December 2013 in West Africa shows the need to develop vaccines pre-emptively, says Farrar. No vaccine against Ebola was available when the outbreak started, but researchers were able to develop a safe and effective vaccine against the Zaire strain responsible in record time \u2014 just a year and a half. Making a vaccine from scratch usually takes years, or even decades. They were able to move fast because US and Canadian researchers had already developed experimental Ebola vaccines. Researchers fighting Ebola lost valuable time, however, because the experimental vaccines, which had sat on the shelf for years, had been tested for safety in animals, but not humans. \u201cWe had to spend what was 9\u201312 months getting safety data for those vaccines, and that was 9\u201312 months where ultimately many people lost their lives,\u201d says Farrar. By contrast, CEPI's planned work on MERS, Nipah and Lassa vaccines will take experimental vaccine candidates \u2014 two for each disease \u2014 through testing in humans to establish that they are safe and produce an immune response that is likely to be protective. It would then create sufficient stockpiles of promising candidates to rapidly test for efficacy, and possible use, in the event of an outbreak. For the three diseases initially targeted, CEPI aims to have stockpiles by 2021. \n               Market failure \n             CEPI intends to support research at every stage, from basic lab work to vaccine discovery and clinical trials. It also made its first call for research proposals on 18 January, and teams have until 8 March to submit preliminary proposals for grants. \u201cFor too long, we have separated out the academic work from the next step of taking it into all that is actually required to make a vaccine,\u201d says Farrar. There is also no market for vaccines against 'potential' epidemic threats, he notes, which explains why there is no commercial incentive to take research leads out of the lab and into clinical development. CEPI aims to change this state of affairs by bringing together sustained long-term funding from governments and philanthropies to encourage collaboration with biotechnology companies and large vaccine makers.Industry involvement will be crucial, says Farrar. Pharmaceutical companies GlaxoSmithKline (GSK), Johnson & Johnson, Sanofi, Pfizer, Takeda and several other companies have said that they will support CEPI, but details about their involvement are still under negotiation. CEPI is particularly keen for the United States to join, but discussions will take time given the change in administration, adds R\u00f8ttingen. \u201cIrrespective of the government, it was a bad time to engage the United States on that.\" \n                     How to turn competitors into collaborators 2017-Jan-18 \n                   \n                     Viral complacency 2016-Apr-05 \n                   \n                     The race is on to develop Zika vaccine 2016-Mar-28 \n                   \n                     How Ebola-vaccine success could reshape clinical-trial policy 2015-Aug-04 \n                   \n                     Coalition for Epidemic Preparedness Innovations (CEPI) \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21388", "url": "https://www.nature.com/articles/nature.2017.21388", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "The United Kingdom\u2019s role in major fusion projects remains in limbo. Scientists are shocked and angry at the UK government\u2019s sudden confirmation on 26 January that it wants to pull out of the European Atomic Energy Community, or Euratom, as part of its arrangements for Brexit. Depending on whether and how the United Kingdom negotiates a way back in to the organization, the move could endanger British participation in the world\u2019s largest fusion experiment,  the International Thermonuclear Experimental Reactor (ITER ) in southern France. It could also curtail operations at the Joint European Torus (JET), a nuclear-fusion facility in Culham, UK. The facility is a half-sized version of ITER and acts as a test bed for it; it currently receives around \u20ac56 million ($60 million) annually from Euratom. \u201cIt is simply bonkers to leave Euratom,\u201d says Steven Cowley, a theoretical physicist at the University of Oxford who until last year was director of the Culham Centre for Fusion Energy, which hosts JET. \u201cThis has happened without discussion or analysis. It\u2019s left us in shock. Not the behaviour of a transparent government,\u201d tweeted Scientists4EU, a UK lobby group originally set up to campaign against the UK\u2019s exit from the European Union. The Culham Centre\u2019s current chief executive, Ian Chapman, told  Nature  that \u2014 after meeting with government officials \u2014 he is sure that the United Kingdom has no intention of drawing back from nuclear research and development or civil nuclear programmes. \u201cThere\u2019s no indication that this means we\u2019re stopping our nuclear programme, far from it,\u201d says Chapman, who is also chief executive of the UK Atomic Energy Authority. The United Kingdom will have to change how it participates in these programmes, however. \u201cThere\u2019s still a commitment from the government to think about how we can put in place arrangements to continue running JET, and to continue participating in the ITER programme,\u201d Chapman says. \u201cThe nuclear industry remains of key strategic importance to the UK and our withdrawal from the Euratom Treaty in no way diminishes our nuclear ambitions\u201d, a spokesperson from the Department for Business, Energy and Industrial Strategy says. \n             Quiet announcement \n           Euratom predates the formation of the EU. But the two are legally entangled, and experts had predicted that Brexit would probably mean that the United Kingdom would also leave Euratom. For months, it was unclear whether the UK government wanted to leave Euratom, or how a transition away from the agency would occur. ( Nature  received no response to questions on the issue). But on 26 January, confirmation that it intended to leave Euratom appeared in notes appended to a short parliamentary bill. That legislation is meant to allow the UK prime minister to trigger Article 50, the formal notification of the United Kingdom\u2019s withdrawal from the EU.  Alexandrine K\u00e1ntor, a senior electrical designer at the Culham Centre for Fusion Energy, said on Twitter that it was the first she\u2019d heard of it. \u201cAlways nice to know you might lose your job via the newspapers, cause the gov\u2019 didn't think it necessary to tell your CEO,\u201d she wrote. \n             Hazy consequences \n           The consequences of pulling out of Euratom are uncertain, as are many of the implications of Brexit. Besides the uncertainty facing JET and ITER, some reports suggest that it could increase the costs of regulating existing nuclear facilities and delay the building of new power stations while the United Kingdom makes new arrangements. The United Kingdom could become a Euratom \u2018third country\u2019, like the United States \u2014 which has a cooperation agreement that allows it to participate in some programmes. That status would not automatically make the United Kingdom a member of ITER, however. And although Euratom is technically able to fund projects in third countries, it would be unlikely to continue funding JET. The UK government has not said whether it would then pick up the bill for the facility. Alternatively, the United Kingdom could become an \u2018associate country\u2019 \u2014 like Switzerland, which gained this status in 2014 and participates in ITER. Under this arrangement, Euratom would be more likely to continue funding JET. JET\u2019s contract runs out in 2018 and negotiations over an extension to 2020 are ongoing. If the facility\u2019s funding is cut in 2019, when the United Kingdom is currently scheduled to leave the EU, that could delay or prevent a fusion experiment at JET using the heavy hydrogen isotopes deuterium and tritium. This trial is intended as a dress rehearsal, to indicate whether ITER\u2019s magnetic-confinement technology will perform as hoped when it runs with this mix some time in the 2030s. The UK Nuclear Industry Association has called on the government to agree to transitional arrangements, which would see the United Kingdom remain part of Euratom until it had time to renegotiate international agreements that are currently all managed through the organisation. The complex process of leaving Euratom should be done in a careful and deliberate manner, Chapman says, even if it takes longer than the two years prescribed for Brexit in Article 50. But the UK \u2018Brexit ministry\u2019 \u2014 the Department for Exiting the European Union \u2014 says that the two-year time limit applies to leaving Euratom as well.\u00a0 \n                   Brexit offers rare chance to make Britain greener 2017-Jan-11 \n                 \n                   UK scientists in limbo after Brexit shock 2016-Jun-28 \n                 \n                   US advised to stick with troubled fusion reactor ITER 2016-May-26 \n                 \n                   Nuclear physics: Pull together for fusion 2015-Jun-09 \n                 \n                   Nature special: Brexit and science \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21375", "url": "https://www.nature.com/articles/nature.2017.21375", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Measure of humanity's risk of annihilation now sits at 2.5 minutes to midnight, the highest level of alert since 1953. The  Bulletin of the Atomic Scientists  has moved the hands of  its symbolic Doomsday Clock  30 seconds closer to midnight \u2014 signalling the greatest threat of apocalypse since 1953. Back then, Russia and the United States had detonated hydrogen bombs in tests within nine months of each other, intensifying the nuclear arms race and escalating the cold war. Now, governments\u2019 \u201ccavalier and reckless\u201d talk about nuclear weapons and a growing disregard for scientific expertise have pushed the clock hands to 2.5 minutes to midnight, the  Bulletin  said. The group\u2019s executive director and several prominent scientists announced the update at a press conference in Washington DC on 26 January. \u201cClimate change should not be a partisan issue,\u201d said  Bulletin  board member David Titley, former chief oceanographer for the US Navy and a meteorologist at Pennsylvania State University in University Park. \u201cThe well established physics of the Earth\u2019s carbon cycle is neither liberal nor conservative in character.\u201d Titley called on new  US President Donald Trump  to state \u201cunequivocally\u201d that  climate change  is real and caused by humans. \u201cThere are no \u2018alternative facts\u2019 here,\u201d Titley said, referencing the language used by several Trump spokespeople earlier in the week. The  Bulletin\u2019 s board of directors is especially concerned about language that Trump and Russian President Vladimir Putin have used to talk about climate change, nuclear weapons and the  idea of facts . \u201cThis is the first time the words and stated policies of one or two people placed in high positions have so impacted our perception of the existential threats we believe the world faces,\u201d said Lawrence Krauss, a  Bulletin  board member and a cosmologist at Arizona State University in Tempe. If Trump and Putin can choose to act together instead of behaving like \u201cpetulant children\u201d, said Krauss, such threats could be neutralized. \n             Tick, tick, tick ... \n           The Doomsday Clock\u2019s hands have historically moved in full-minute increments, but the latest update saw them move forward by 30 seconds. That decision reflects a feeling among the  Bulletin  board members that \u201cwords matter\u201d, said the group's executive director, Rachel Bronson.Michael Oppenheimer, a geoscientist and international climate-policy specialist at Princeton University in New Jersey, agrees with that decision. \u201cWe don\u2019t know yet if [Trump's] words foreshadow a significant change in policy,\u201d Oppenheimer said. \u201cBut based on what we do know, there\u2019s a serious risk that things could go very badly on the climate front.\u201d If Trump follows through on his pledge to withdraw the United States from the Paris climate agreement, that would slow the world\u2019s progress towards cutting greenhouse-gas emissions, Oppenheimer adds. The  Bulletin of the Atomic Scientists  created the Doomsday Clock in 1947, in response to the 1945 detonation of nuclear bombs at Hiroshima and Nagasaki in Japan. At first, the clock\u2019s hands sat at seven minutes to midnight. In the 70 years since then, the clock has never strayed further from destruction than 17 minutes to midnight, its position when the cold war ended in 1991. The current setting is not the closest that the clock has come to midnight, but Krauss said that the challenges facing the world today \u2014 such as fake news that threatens to undermine democracy and  cybersecurity  breaches \u2014 are unprecedented. \u201cThe future of the clock, and our future, is in your hands,\u201d he said. \n                   Trump nominee backs Paris climate agreement and questions Iran nuclear deal 2017-Jan-11 \n                 \n                   Seven days: 23\u201329 January 2015 2015-Jan-28 \n                 \n                   Five minutes from disaster 2012-Feb-02 \n                 \n                   Doomsday draws two minutes closer 2007-Jan-17 \n                 \n                   Threat of Atomic Warfare 1954-Feb-06 \n                 \n                   Blogpost: One minute safer than yesterday \n                 \n                   Doomsday Clock timeline \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21382", "url": "https://www.nature.com/articles/nature.2017.21382", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Concerns mount that the new US president will sideline science\u2019s role in international relations. A  newly minted leader with no experience  governing at home or establishing policy abroad now oversees the United States\u2019 vast diplomatic enterprise. US President Donald Trump has a deep bench of scientific and technical expertise to tap across multiple government agencies \u2014 but it is not clear that he will use it. Science diplomats are watching warily to see whether the volatile new president will draw on the best available evidence when setting foreign policy. So far, his isolationist tendencies are winning: Trump is reportedly considering whether to pull the United States back from international organizations such as the United Nations. And he is drafting plans to ban immigration from a number of countries across the Middle East. \u201cEverybody\u2019s worried that we won\u2019t be in the room any more as a voice of reason advocating for evidence-based decision-making, for bringing the best and brightest to the table no matter where they come from or who they are,\u201d says Frances Col\u00f3n, who until last week was the deputy science adviser at the US Department of State. For decades, scientists have had a key role in informing US foreign policy, primarily through the state department. The American Association for the Advancement of Science (AAAS) began sending scientists to the department on yearlong placements in 1980, just before Ronald Reagan was elected. The department got its first permanent science adviser in 2000, late in Bill Clinton\u2019s presidency, a position that strengthened under George W. Bush when scientific exchanges were established with nations such as Iraq. \u201cWe need scientists and engineers not just because of their technical expertise but because of their analytical nature, their ability to sift through a lot of different types of information and evidence and weigh them in a rational way,\u201d says Tom Wang, director of the AAAS Center for Science Diplomacy in Washington DC. \n             Scientist to scientist \n           The state department\u2019s current science adviser, geochemist Vaughan Turekian, is expected to stay on under the new secretary of state,  presumed to be Trump\u2019s nominee Rex Tillerson . As the nation\u2019s top diplomat, Tillerson would be the US lead on international issues such as nuclear non-proliferation, disaster response, climate change and the oceans. Tillerson is a member of the US National Academy of Engineering, elected during his tenure as head of the oil company ExxonMobil, where he also grappled with global issues such as public health. \u201cHe knows the importance of science,\u201d says Peter Hotez, a tropical-disease expert at the Baylor College of Medicine in Houston, Texas, who has met Tillerson. Science can be a starting point for traditionally estranged nations to open a dialogue, says William Colglazier, a physicist who was science adviser to the secretary of state from 2011 to 2014. \u201cEven if other countries don\u2019t like our government, they still admire and want to interact with our universities, our research institutions and our high-tech companies.\u201d For instance, years before Fidel Castro died,  the Cuban government began working with the AAAS on scientific exchanges  to study Caribbean-focused topics such as hurricane prediction and the spread of tropical diseases. The future of that programme is now in question, because Trump has suggested that he would reverse Barack Obama\u2019s loosening of US relations with Cuba. \u201cI firmly believe in the power of science diplomacy,\u201d says Jane Lubchenco, a marine biologist at Oregon State University in Corvallis who served as head of the National Oceanic and Atmospheric Administration and later as a \u2018science envoy\u2019 for the state department. \u201cIt has huge potential for sharing knowledge, for bringing goodwill, for resulting in tangible outcomes that can benefit people\u2019s lives and the opportunity to help build scientific capacity.\u201d \n             Global view \n           Lubchenco points to the envoy programme,  which Obama created in 2009 as part of his early outreach to Muslim-majority countries . Eighteen top scientists have participated since then, in projects ranging from bolstering women in engineering in Nepal to establishing a vaccine production centre in Saudi Arabia. In her time as envoy, Lubchenco helped to set up working groups involving Chinese and US fisheries experts, as well as a programme headed by scientists in several African countries to track ocean acidification in the poorly monitored southwestern Indian Ocean. US science diplomacy also happens outside of the state department. Physicist and former energy secretary Ernest Moniz was instrumental in negotiating  the 2015 nuclear deal with Iran . The US Agency for International Development supports many research projects such as water management across the Middle East. Even former NASA administrator Charles Bolden travelled to Cairo in 2010, in a trip that backfired politically when critics charged that the space agency should be focused more on exploration than on improving international relations. Trump has said that he supports high-tech businesses and investments that would keep the United States a global leader. But if he withdraws the country from the worldwide stage, other nations may soon surpass it in scientific and technical innovation, says Col\u00f3n. And isolationist stances like Trump's will further slow action on pressing international issues such as climate change, says Robert Patman, an expert in international relations at the University of Otago in Dunedin, New Zealand. \u201cIt remains to be seen whether science diplomacy can realize its full potential to make the world a better place,\u201d he says.  \n                   Can Cuban science go global? 2016-Sep-28 \n                 \n                   Policy: The art of science advice to government 2014-Mar-12 \n                 \n                   International opportunities: The science of diplomacy 2011-Feb-16 \n                 \n                   The scientific diplomat 2010-Jan-20 \n                 \n                   Warning for diplomats over misuse of science 2009-Jun-03 \n                 \n                   Nature special: Tracking the Trump White House \n                 \n                   AAAS Center for Science Diplomacy \n                 \n                   US Department of State science adviser \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21386", "url": "https://www.nature.com/articles/nature.2017.21386", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "The sharpest science shots from December and January, selected by  Nature \u2019s photo team. After spending December producing our  pictures of the year ,  Nature\u2019 s images of the month returns with a bumper round up of the best images and videos from the past two months. \n             Dippy departure \n           \n             Aerial arctic \n           \n             Shifting sheds \n           \n             Starfish swirls \n           This video of water movements around an eight-week-old starfish larva won William Gilpin of Stanford University, California, and his colleagues first place in the Nikon Small World in Motion Photomicrography Competition, announced in December. Also in December, Gilpin and his colleagues reported in\u00a0 a paper in\u00a0 Nature Physics 1  how these observations can offer insight into these animals\u2019 lives and explain how starfish balance swimming and feeding. \n             Ant code \n           \n             Touchdown! \n           \n             Cold snap \n           \n             Ultraviolet flowers \n           \n             Blooming marvellous \n           Artist John Edmark  creates 3D-printed sculptures , which create strange animations when spun. This work is based on the \u2018golden ratio\u2019, a mathematical pattern seen in many natural systems, such as plant branching and some shell spirals. \n                   2016 in pictures: The best science images of the year 2016-Dec-16 \n                 \n                   An expensive dodo, an even more expensive telescope, and a \u2018fog rainbow\u2019 2016-Dec-01 \n                 \n                   Martian clouds form, a frozen ship heads home and an orangutan goes climbing 2016-Oct-28 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21400", "url": "https://www.nature.com/articles/nature.2017.21400", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "John Holdren worries that immigration restrictions could harm researchers\u2019 ability to collaborate across borders. Former White House science adviser John Holdren has condemned US President Donald Trump\u2019s decision to temporarily ban all refugees and citizens of seven majority-Muslim countries from entering the United States. Holdren,  who served nearly eight years under President Barack Obama , told  Nature  on 30 January that the ban is \u201cperverse\u201d, \u201can abomination, and a terrible, terrible idea\u201d. The executive order enacted on 27 January will not increase the country\u2019s security, he adds, and may damage it by sending an offensive message to Muslims, who make up almost one-quarter of the world\u2019s population. \u201cIf the ban is maintained, it will damage a wide array of collaborations in science and technology around the world,\u201d says Holdren, who led the White House Office of Science and Technology Policy from 2009 until earlier this month. \u201cA more prosperous world is a more stable world, and it\u2019s clear that innovations in science and technology drive economic growth.\u201d The ban has inspired shock, fear and confusion among researchers  in the United States and around the world. It prevents refugees from entering the country for 120 days, and bars those from Syria indefinitely. Citizens from Iran, Iraq, Libya, Somalia, Sudan, Syria and Yemen are banned for 90 days. \n             Uncertainty \n           The US government has offered conflicting interpretations about how the policy applies to people from the seven countries who hold visas allowing them to live, work or study in the United States. The White House now says that people with the permanent-resident visas called green cards will be evaluated on a case-by-case basis if they seek to enter the country. However, many researchers told  Nature  that airlines have erred on the side of caution, and have decided not to allow anyone with passports from these countries to board connecting flights to the United States because of uncertainty about the changing rules. Trump defended the ban in a statement issued on 29 January. \u201cThis is not about religion \u2014 this is about terror and keeping our country safe,\u201d he said. But Holdren says that Trump\u2019s immigration stance could begin to undermine  the international science ties that Obama sought to build during his eight years in office  \u2014 and, in doing so, could make the world less safe. Such relationships also aid the United States, he argues, by helping other nations to improve their ability to respond to global emergencies such as pandemics. \u201cOur scientific collaborations with China mean we get notice on influenza outbreaks immediately so that we can develop vaccines to target the right strain of the virus months ahead of time,\u201d Holdren says. Holdren is also shaken by reports that government science agencies have instructed their employees not to talk to Congress or to the press. In at least some cases, those orders have reportedly come from high-ranking civil servants at the science agencies, rather than from the White House itself. \u201cDuring a transition, there is a tendency to want to get the new teams up to speed before they communicate to the press, but what has happened so far is beyond what is normal for transitions,\u201d Holdren says. \u201cI suspect that the combination of swiftness and comprehensiveness of the Trump team\u2019s restrictions may well be unprecedented.\u201d \n                   Meet the scientists affected by Trump\u2019s immigration ban 2017-Jan-29 \n                 \n                   Trump agenda threatens US legacy of science diplomacy 2017-Jan-27 \n                 \n                   Scientists must fight for the facts 2017-Jan-24 \n                 \n                   Obama\u2019s top scientist talks shrinking budgets, Donald Trump, and his biggest regret 2016-Jul-06 \n                 \n                   Nature  special: Tracking the Trump White House \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21420", "url": "https://www.nature.com/articles/nature.2017.21420", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "The ensuing damage to scientific collaborations puts the United States at risk, researchers say. Diseases don\u2019t respect borders, laws or walls. And efforts to combat them rely on networks of scientists to detect outbreaks early, understand how the diseases operate and then intervene. Researchers say that President Donald Trump\u2019s travel ban challenges that process,  putting the United States at risk . The policy, enacted on 27 January,  bars refugees from entering the country for 120 days, except those from Syria, who are banned indefinitely. Citizens of Iran, Iraq, Libya, Somalia, Sudan, Syria and Yemen are banned for 90 days. On 1 February, the White House said that the order did not apply to people from those countries who hold US permanent-resident visas, or green cards. Still, \u201cthe ban could hamper our ability to learn about the epidemiology of neglected diseases emerging out of conflict zones\u201d, says infectious disease expert Peter Hotez at Baylor College of Medicine in Houston, Texas. For example, leishmaniasis is spreading in occupied areas of Syria and Iraq, and schistosomiasis is spreading in Yemen. \u201cScientific communities across the world need collaborators in these countries who can combat epidemics before they arrive in the US,\u201d Hotez says. The ban has already disrupted work on a vaccine for  leishmaniasis , says Farrokh Modabber, an Iranian infectious-disease scientist with collaborators at the US National Institutes of Health and the Pasteur Institute of Iran, among others. They've already discussed whether to cancel an upcoming meeting due to travel concerns, but Modabber is also worried about how the US immigration stance could affect their work in the long term. US-led teams have been developing tropical disease vaccines and drugs over the past decade, he says, but testing them could be difficult or impossible without the involvement of scientists in those countries where the diseases are endemic. Sudanese scientists on the frontlines of tropical disease are stunned as well. In Sudan\u2019s capital Khartoum, Ahmed Fahal, directs the Mycetoma Research Centre \u2014 the world\u2019s only research centre devoted to a potentially lethal condition caused by flesh-eating fungi and bacteria. Although mycetoma afflicts impoverished people in at least 23 countries, vanishingly little is known about the malady and there\u2019s no reliable cure. Last May, the World Health Organization added mycetoma to their list of tropical diseases that require attention. Soon after, Fahal was invited to speak at this year\u2019s American Society of Microbiology conference in New Orleans, Louisiana, in June. He had planned to talk with scientists from the US Centers for Disease Control and Prevention about monitoring mycetoma, and to find collaborators from universities in the United States, India and Nigeria. Now, Fahal fears he must cancel his plans. \u201cIt\u2019s a big blow,\u201d he says. \n             A murky future \n           The US policy has also hampered scientists fighting river blindness. The disease is caused by the parasite Onchocerca volvulus, which is spread by blackflies, and often leads to irreversible blindness. About 37 million people are infected across Africa, Latin America and Yemen. Last November, a Sudanese and American team reported the elimination of river blindness in northern Sudan, the first time this had been done in Africa. The work was supported by former president Jimmy Carter\u2019s foundation, the Carter Center in Atlanta, Georgia. The centre holds an annual meeting in late February with its donors and scientists to plan the coming year. But Isam Zarroug, who directs Sudan\u2019s river-blindness programme, can no longer attend due to the ban. He worries that missing that opportunity to make crucial contacts could jeopardize his team\u2019s efforts to fight the disease in conflict-laden regions of the country at its border with Ethiopia and South Sudan. His colleague, Tarig Higazi, a scientist at Ohio University in Athens, says he\u2019ll probably cancel his field season this summer in Sudan. Although he\u2019s now a US citizen, he worries that erratic changes in the immigration policy might separate him from his family in Ohio. That\u2019s what has happened to Arash Alaei, a HIV researcher at the University at Albany in New York, whose colleague and brother has been stranded in Iran owing to the ban. In addition, Alaei says his projects involving HIV in Iraq and medical training in Syria are now in danger. And he worries that the travel ban could extend to countries such as Pakistan, Afghanistan and Turkey, where he and his colleagues focus on intravenous drug use, HIV and hepatitis C. \u201cI invite scholars to come here to the US, where they can safely talk,\u201d he says. Alaei knows first-hand how important ties with the global scientific community are. When he and his brother were jailed in 2008 for running Iran\u2019s first HIV harm-reduction programme, researchers and AIDS activists successfully rallied for his release. \u201cThe most important message I heard in my solitary cell in Iran was that there were people speaking out about us and it meant we were not forgotten,\u201d he says. \n             It takes a village \n           Public health is just one beneficiary of cross-border partnerships. Some policy analysts say scientific collaboration improves national security. If countries can respond to crises ranging from Ebola outbreaks to nuclear spills on their own, Americans are at less risk, says Hotez.  Apolitical science partnerships make for good diplomacy , he adds. Approval of the United States has declined from 25% in 2009 to 15% in 2012 in Muslim-majority countries, according to the Pew Research Center, a non-profit organization in Washington DC. But respect for US science has remained high in these countries. \u201cThe premise of the US executive order is that it is needed to keep the US safe,\u201d says Mohamed Hassan, director of The World Academy of Science in Trieste, Italy. \u201cBut nobody from Sudan has ever committed a terrorist action against the US. Some people have suggested that the order gives terrorists leverage for recruiting new members, and I worry they could be right.\u201d Building rapport also encourages scientists from other countries to be open with those in the United States  about mysterious outbreaks on their soil , despite the potential harm this could cause to their economy, says Hotez. He worries that the isolating effect of the ban could spread to Muslim-majority countries not yet listed. Thomas Bollyky, a senior fellow at the Council on Foreign Relations, a think tank in Washington DC, agrees. \u201cThere\u2019s no evidence to suggest this measure would have stopped the terrorism we\u2019ve seen,\u201d he says. \u201cSo, if you\u2019re a scientist from a Muslim country not included in the ban, you\u2019d be rightly concerned that your country may be added too.\u201d Hotez notes that it was collaboration \u2014 not isolation \u2014 that ended  the latest Ebola outbreak . \u201cThe only way to prevent emerging diseases from coming to the US is to stop them in their tracks in the countries where they arise,\u201d he says. \u201cWe didn\u2019t stop Ebola by making a nurse freeze her ass off outside of a New Jersey airport, we stopped Ebola by having our top scientists go there and work with scientists in those countries.\u201d \n                   Obama science adviser: Trump immigration ban \u2018an abomination\u2019 2017-Jan-30 \n                 \n                   Meet the scientists affected by Trump\u2019s immigration ban 2017-Jan-29 \n                 \n                   Trump agenda threatens US legacy of science diplomacy 2017-Jan-27 \n                 Reprints and Permissions"},
{"file_id": "542015a", "url": "https://www.nature.com/articles/542015a", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Until this obstacle is overcome, the technology is unlikely to succeed in the wild. In the small city of Terni in central Italy, researchers are putting the final touches on what could be the world\u2019s most sophisticated mosquito cages. The enclosures, each occupying 150 cubic metres, simulate the muggy habitats in which Africa\u2019s  Anopheles gambiae  mosquitoes thrive. By studying the insects under more-natural conditions, scientists hope to better understand how to eradicate them \u2014 and malaria \u2014 using an emerging genetic-engineering technology called gene drives. The technique can quickly disseminate genetic modifications in wild populations through an organism\u2019s offspring,  prompting some activists to call for it to be shelved . Yet gene drives might not be as effective as activists think. Recent research has identified a major hurdle to using them to eliminate diseases and vanquish invasive pests: evolution. Organisms altered by gene drives, including mosquitoes, have shown promise in  proof-of-concept   laboratory experiments . But wild populations will almost certainly develop resistance to the modifications. Researchers have begun identifying how this occurs so that they can address the problem. Gene drives thwart the rules of inheritance in sexually reproducing organisms. Normally, offspring have a 50:50 chance of inheriting a gene from their parents. Gene drives alter those odds, preferentially passing on one version to an organism\u2019s offspring until, in theory, an entire population bears that gene. Such \u2018selfish\u2019 genetic elements occur naturally in mice, beetles and many other organisms, and researchers have had modest success with hijacking them to battle pests. But interest in gene drives has surged with the  advent of CRISPR\u2013Cas9 gene editing , which can be used to copy a mutation from one chromosome into another. In late 2015,  researchers reported a CRISPR gene drive  that caused an infertility mutation in female mosquitoes to be passed on to all their offspring 1 . Lab experiments showed that the mutation increased in frequency as expected over several generations, but resistance to the gene drive also emerged, preventing some mosquitoes from inheriting the modified genome. This is hardly surprising, says Philipp Messer, a population geneticist at Cornell University in Ithaca, New York. Just as antibiotics enable the rise of drug-resistant bacteria, population-suppressing gene drives create the ideal conditions for resistant organisms to flourish. One source of this resistance is the CRISPR system itself, which uses an enzyme to cut a specific DNA sequence and insert whatever genetic code a researcher wants. Occasionally, however, cells sew the incision back together after adding or deleting random DNA letters. This can result in a sequence that the CRISPR gene-drive system no longer recognizes, halting the spread of the modified code. The researchers building the mosquito cage in Italy, part of a multimillion-dollar project called Target Malaria, found this form of resistance in some mosquitoes. And Messer\u2019s team reported in December that these mutants are likely to flourish 2 . Natural genetic variation is another route to resistance. CRISPR-based gene drives work by recognizing short genetic sequences, and individuals with differences at these sites would be immune to the drive. A recent study 3  analysed the genomes of 765 wild  Anopheles mosquitoes from across Africa. The team found extreme genetic diversity, which would limit the list of potential gene-drive targets, the researchers say. \u201cThese things are not going to get too far in terms of eradicating a population,\u201d says Michael Wade, an evolutionary geneticist at Indiana University Bloomington. Gene drives could result in the genetic isolation \u2014 in which populations do not mate with each other \u2014 of groups that manage to avoid inheriting the modified genetic code, he and his colleagues found 4 . And gene variants that decrease a population\u2019s propensity to mingle with other populations \u2014 such as those that limit flight capacity in insects \u2014 would suddenly prove beneficial and could spread. Resistance to gene drives is unavoidable, so researchers are hoping that they can blunt the effects long enough to spread a desired mutation throughout a population. Some have floated the idea of creating gene drives that target multiple genes, or several sites within the same gene, diminishing the speed with which resistance would develop. By surveying a species\u2019 natural genetic diversity, researchers could target genes common to all individuals. The Target Malaria team has developed a second generation of gene-drive mosquitoes, hoping to slow the development of resistance, says Andrea Crisanti, a molecular parasitologist at Imperial College London. The researchers plan to test them in their new Italian facility later this year to get a sense of how the mosquitoes might fare in the wild. But molecular biologist Tony Nolan, also at Imperial, expects evolution to throw up some surprises. He says that his greatest worry about gene drives is that they simply won\u2019t work. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @ewencallaway \n               \n                     \u2018Gene drive\u2019 moratorium shot down at UN biodiversity meeting 2016-Dec-21 \n                   \n                     Fast-spreading genetic mutations pose ecological risk 2016-Jun-08 \n                   \n                     Gene editing can drive science to openness 2016-Jun-08 \n                   \n                     Mosquitoes engineered to pass down genes that would wipe out their species 2015-Dec-07 \n                   \n                     'Gene drive' mosquitoes engineered to fight malaria 2015-Nov-23 \n                   \n                     Safety upgrade found for gene-editing technique 2015-Nov-16 \n                   \n                     Gene drive overdrive 2015-Oct-08 \n                   \n                     Caution urged over editing DNA in wildlife (intentionally or not) 2015-Aug-04 \n                   \n                     Target Malaria \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21373", "url": "https://www.nature.com/articles/nature.2017.21373", "year": 2017, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Centre evaluates how public-health spending can improve mortality rates and disease burden, but many countries still do not record how people die. The world\u2019s premier centre for health metrics \u2014 the science of measuring and analysing global health problems, and how they relate to healthcare and biomedical research funding \u2014 will receive a US$279-million cash injection from the Bill & Melinda Gates Foundation. The University of Washington\u2019s Institute for Health Metrics and Evaluation (IHME) in Seattle, also home town to the Gates Foundation, announced the funding boost on 25 January. The cash will go towards expanding the institute\u2019s work over the next decade and consolidating its primacy in the field. It is considered by far the biggest and most influential research centre for health metrics, and its work informs the funding and policy decisions of many national governments and local, regional and global organizations, including the World Bank and the US National Institutes of Health. The University of Washington created the IHME in 2007 using  a $105-million grant from the Gates Foundation and $20 million of its own money . The institute has since grown from just 3 people to more than 300 \u2014 an eclectic army of epidemiologists, statisticians, computer scientists, economists and mappers. \n               Global Burden of Disease study \n             Health economist Christopher Murray, who has headed the IHME from the outset, helped to pioneer the field of health metrics in the 1990s when he was struck by the utter lack of data on who was dying or falling ill, of what and where in the world. \u201cIf you are not measuring health well, then you don't know if the extraordinary $6\u20137 trillion spent annually on health care, is working, or if we are spending it in the right ways,\u201d says Murray. The IHME coordinates in particular the Global Burden of Disease (GBD) study, a massive undertaking to estimate the causes of death and illness worldwide, and which many countries have used to inform funding and policy priorities. The first edition of the IHME's GBD, published as a  series of papers  in 2012, involved 488 researchers in 50 countries, who collaborated to present data from 1990\u20132010 analysing 291 diseases and injuries and 67 risk factors. The data covered 20 age groups in 187 countries, and took up a complete special triple issue of  The Lancet.  The latest edition, published in  The    Lancet  last October, involved 1,870 specialists in 127 countries, and expands and updates the data to 2015. Alan Lopez, who helped to launch the health metrics field with Murray in the 1990s and is an epidemiologist now at the University of Melbourne in Australia, is thrilled by the funding boost. \u201cWe were just two young guys believing in what we were doing,\" he says. \"To see now the fact that someone as powerful and as influential as Bill Gates and the Gates Foundation believing in this enough to invest such a large amount of money for decades makes me delighted, and delighted for Chris, and for global-health epidemiology,\u201d he says. \n               Unrecorded deaths \n             \u201cIHME is doing clever stuff \u2014 I admire their science,\u201d says Peter Byass, a global-health scientist at Ume\u00e5 University in Sweden. But he cautions that the IHME is focused on intensive analysis and modelling of existing data, whereas many of the available data are poor. \u201cThere\u2019s a dearth of data in poorer countries \u2014 Africa is a huge hole, and so is quite a bit of Asia,\u201d he says. Of the roughly 60 million estimated deaths worldwide each year, around two-thirds go unrecorded. And for those that are documented, around two-thirds of death certificates fail to state the cause of death, or get it wrong. There has been longstanding tension between researchers, who, although in agreement that sophisticated and refined estimates are valuable and badly needed, also feel that funders need to put more money into collecting better data in the first place. Lopez is heading up part of a $100-million \u2018Data for Health\u2019 initiative funded by Bloomberg Philanthropies, headquartered in New York City, to do just that. \u201cIt a fair comment,\u201d he says. Murray says that it is a false dichotomy: \u201cIt\u2019s not an \u2018either, or\u2019 \u2014 we need both.\u201d Investments in strengthening country health information are hugely expensive, and they take 10\u201320 years before they result in major improvements in coverage and quality, he adds: \u201cThe world needs to make local, national, regional and global decisions before this happens.\u201d \n               Future health patterns \n             Lopez agrees, noting that IHME draws on research and survey data to fill in data gaps. \u201cWithout IHME, we would be in complete ignorance about disease burden or causes of death, say, in Mali. IHME are saying, \u2018Well all right, given everything we know about Mali, every scrap of crappy data about Mali, how can we piece together something that is plausible?\u2019\u201d \"It can\u2019t \u2014 won't \u2014 be right, because there is very little data, but it [a picture of the burden of disease] is not implausible. And not implausible is of great value to public health in countries compared to complete ignorance.\u201d For the IHME, the Gates\u2019 cash will sustain the institute\u2019s core infrastructure, including costly computing facilities and salaries, says Murray. It will also launch an area of research focused on trying to forecast the trajectory of future health patterns, down to the local level, under various scenarios. In addition, the institute intends to expand its tracking of how much is spent on what, and where, on health. Despite the trillions poured into health care, he says, \u201cthere\u2019s remarkably poor information on where the money goes\u201d. \"But ultimately, what we are we are trying to do is to build up a multidisciplinary field \u2014 a science of health metrics,\u201d says Murray. \n                     Three minutes with Hans Rosling will change your mind about the world 2016-Dec-14 \n                   \n                     Four steps to precision public health 2016-Dec-05 \n                   \n                     Vital statistics 2013-Feb-19 \n                   \n                     Global survey reveals impact of disability 2012-Dec-18 \n                   \n                     A burden weighed 2012-Dec-18 \n                   \n                     Straight talk with...Christopher Murray 2009-Oct-01 \n                   \n                     Institute for Health Metrics and Evaluation \n                   \n                     Bill and Melinda Gates Foundation \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21473", "url": "https://www.nature.com/articles/nature.2017.21473", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "The simplicity of the stains' repeating patterns is key to why we see so many images in them. It\u2019s easy to see familiar shapes in seemingly random patterns. Witness how many people see faces in clouds, for example \u2014 or in the 'poured' paintings of American artist Jackson Pollock, which he famously composed by dripping paint over the canvas. But Pollock disliked the idea that viewers of his paintings were distracted by such figures, which he called \u201cextra cargo\u201d. In fact, during his career, he is thought to have intuitively increased the complexity of his works to prevent the phenomenon. Now, researchers may have revealed the basis of Pollock\u2019s intuition \u2014 using the mathematics of fractal geometry. They have found that images with relatively low 'fractal complexity' generate a greater number of perceived forms. As this visual complexity increases, the number of perceived images decreases. The finding is published in  PLoS ONE 1 . \n             Repeating patterns \n           A fractal is a repeating pattern that is apparent at every magnification. Examples in nature can be seen in snowflakes, cauliflowers and tree branches. Fractal complexity is measured according to its  D  value, which reflects the amount of fine structure in an image.  D  runs from 1.0 \u2014 a smooth line with no fractals \u2014 to 2.0 for a completely filled-in block in which no lines, and so no fractals, are visible. Richard Taylor, a physicist and arts scholar at the University of Oregon in Eugene, was interested in why certain random patterns induce image perceptions. To find out, his team turned to the work of another radical figure from the past: the Swiss Freudian psychiatrist Hermann Rorschach. Rorschach created ten symmetrical ink blots in 1921 for psychological tests. He asked patients to name each of the familiar objects that they saw in the stains. He interpreted their perceptions \u2014 whether they were flowers or guns, for example \u2014 to help him diagnose their psychological problems. Although the idea that ink blots can reveal the mysteries of the human unconscious has long since fallen out of favour, Taylor wanted to know what it was about their jagged-edged shapes that triggered image perceptions, and whether this might be related to fractals.\u00a0 So he and his colleagues analysed the fractal characteristics of Rorschach blots using edge-detection computer algorithms. \n             Less complexity, more images \n           For simplicity, the team worked only with Rorschach\u2019s five black blots, and not his multicoloured ones, because the researchers found that different tints had their own fractal characteristics. The  D  values of the black blots ranged from 1.1 to 1.3 \u2014 relatively low complexity. The scientists also hunted down two large historical data sets in which all of the images perceived in Rorschach\u2019s blots, known as percepts, had been recorded, and extracted the total number of perceived shapes each blot could trigger. One data set, which had information from 1,050 people, recorded a total of 300 percepts for one of the blots. Both data sets showed that, as  D  increased, the number of percepts decreased. \u201cOur results came as a bit of a\u00a0surprise,\u201d says Taylor. He had also anticipated finding that the blots had a mid-range fractal complexity that is commonly found in nature (around 1.3\u20131.5), and which the human visual system has adapted to. Taylor had previously found that the brains of people viewing fractals in this range show signs of stress reduction 2 . Concerned that other characteristics of Rorschach\u2019s handmade blots, such as variations in symmetry, orientation or shading, might have contributed to the result, the scientists repeated the experiment with 24 computer-generated blots that differed only in fractal complexity. These had  D  values fixed between 1.05 and 1.95. The researchers recruited 23 university students, showed them each blot for ten seconds and told them to note all the images that they saw. Again, the team found that the number of percepts decreased with greater fractal complexity. They also found that images with a  D  of 1.1 generated the most percepts. \n             Fractal \u2018sweet spot\u2019 \n           \u201cThe results are rather counter-intuitive,\u201d says psychologist Alex Forsythe of the University of Liverpool, UK, who studies how fractal patterns in artworks reflect the artist\u2019s neurological state. \u201cIt makes me think that I should pay more attention to low fractal complexity in our studies.\u201d Taylor says that the work could be useful for studying the human visual system, and for designing improved camouflage materials. And as for Pollock, Taylor says that he had been fascinated for the past 20 years by the \u201cheated debate\u201d among scholars about perceived images in the artist\u2019s poured paintings. \u201cOver the decade from 1943, Pollock\u2019s works evolved from simple low- D  to complex high- D  fractal patterns,\u201d says Taylor. The latest work suggests that artists such as Pollock have unconsciously picked up the ball on the fractal phenomenon, he adds \u2014 long before the mathematics were developed. \u201cNow I have put this private puzzle to rest,\u201d Taylor says. \n                   Fractals and art: In the hands of a master 2006-Feb-08 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21419", "url": "https://www.nature.com/articles/nature.2017.21419", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Drug patents and environmental regulations feature in upcoming court cases as Trump nominates a justice. On 31 January, US President Donald Trump nominated Neil Gorsuch to the Supreme Court. Gorsuch, a conservative federal appeals court judge, would fill the vacancy left by the death of conservative justice Antonin Scalia in February 2016. Since then, the court has been split evenly between conservative and liberal justices; if Gorsuch is confirmed by the US Senate, the court's ideological centre would shift towards the conservative. Nature  looks at the science-related cases that are already on the court's agenda this year, and others that are likely to advance to the highest court in the land. \n             Biological drugs \n           The court will hear a pair of patent cases dealing with biological drugs. Because these living products are impossible to copy exactly, companies seeking to make cheaper generic versions called biosimilars must prove that their manufacturing process is as safe and effective as that of the original product. Only then will the US Food and Drug Administration (FDA) allow a biosimilar onto the market. The Supreme Court will decide whether such manufacturing processes themselves are trade secrets. In 2014, Sandoz, the generics arm of Swiss pharmaceutical giant Novartis, patented a generic version of  the biological cancer drug filgrastim . Amgen, the company in Thousand Oaks, California, that makes filgrastim, then sued Sandoz, alleging that it infringed Amgen\u2019s patents and failed to comply with legal requirements to disclose its manufacturing process to Amgen. Sandoz later countersued, challenging a federal requirement that a biosimilar maker wait six months after approval before marketing its therapy. Because the FDA has already evaluated each company\u2019s manufacturing process for safety and efficacy, the court\u2019s ruling will have no bearing on patient care, says Arti Rai, a legal expert at Duke University in Durham, North Carolina. But the ruling could have a massive effect on the biologics market. \n             Patents for natural products \n           The court may also revisit when patents can be awarded for products made by naturally occurring processes. In 2012, the Supreme Court ruled that Prometheus Laboratories in San Diego, California, could not patent a kit that measured chemicals in a patient\u2019s blood to determine whether a drug is working. And in 2013, it ruled that Myriad Genetics of Salt Lake City, Utah,  could not patent a gene linked to breast cancer . The decisions shocked the biotechnology industry, because they implied that a wide array of products could not be patented, and companies are now hoping that the Supreme Court will provide clarity by taking another case. Although in 2016 the court declined to hear a lawsuit over whether companies  could patent prenatal tests that measure fetal DNA in maternal blood samples , Rai says that most experts in the field expect that it will accept a similar case soon. \n             Water-pollution limits \n           The court agreed in January to hear a case that will determine which lower court should be the first to hear a lawsuit brought by developers challenging federal water-pollution regulations. The case could also decide whether the Clean Water Act applies to small tributaries and watersheds that contain as much as 60% of the fresh water in the United States. The law was originally intended to protect lakes and other navigable waterways from pollution, but the administration of former president Barack Obama expanded it to cover more waters. \u201cIt\u2019s a big-time rule,\u201d says Patrick Parenteau, an environmental lawyer at the Vermont Law School in South Royalton. \u201cIf you shrink the scope of the Clean Water Act, you're going to do incredible damage to water across the country.\u201d The court\u2019s ruling could affect nine lawsuits that are pending around the country in federal district courts. Among them is a case filed by Oklahoma attorney general Scott Pruitt \u2014 Trump\u2019s pick to lead the US Environmental Protection Agency (EPA), which enforces the Clean Water Act. \n             Endangered species \n           Another case that could reach the court is a challenge to the Endangered Species Act that is now pending in Utah, Parenteau says. Property owners filed the suit to protest government restrictions on harassing or killing the endangered Utah prairie dog, even on private lands. In 2014, a federal judge ruled that the Endangered Species Act cannot be used to protect the prairie dog. When the US Congress enacted the species law, it relied on a provision in the US Constitution that allows the government to regulate interstate commerce. Because the prairie dog appears to exist only in Utah, the interstate commerce provision \u2014 and thus, the endangered species law \u2014 does not apply, the federal judge said. The US Fish and Wildlife Service, which administers the endangered-species law, has appealed against the ruling, but that court\u2019s decision has been pending for a year. Parenteau says that the appeals' court's long deliberation time suggests that it may uphold the Utah judge's ruling. If the case ultimately reaches the Supreme Court, it could affect whether the federal government can protect other species that are only found in one state. \n             Climate-change rules \n           The most closely watched environmental case that might appear before the court deals with the Clean Power Plan, Obama\u2019s 2015 policy to  regulate greenhouse-gas emissions produced by power plants . Twenty-seven states have sued the EPA over the rule, saying that the agency\u2019s authority to regulate air quality does not extend to greenhouse-gas emissions. (Trump\u2019s EPA pick Pruitt filed suit on Oklahoma\u2019s behalf.) In February 2016, the Supreme Court  forbade the EPA from enforcing the policy  until the suit had been decided. A federal court in Washington DC heard the case in September 2016, and a ruling is expected any day. Jonathan Adler, a legal expert at Case Western Reserve University in Cleveland, Ohio, says that the court is widely expected to side with the EPA, in which case the states would almost certainly appeal to the Supreme Court. Trump has promised to repeal the Clean Power Plan, and his administration is not expected to defend the regulations in court. But the president cannot reverse the regulations himself without providing a valid, non-political reason, Adler says, citing a 1983 Supreme Court ruling. Formulating such a reason could take Trump\u2019s EPA a great deal of time, and it may not finish before the Supreme Court rules on the pending case. Either way, Adler says, the legal fight over the Clean Power Plan is likely to extend for years, and the plan is unlikely to survive in its current form. \n                   The ultimate experiment: How Trump will handle science 2016-Nov-11 \n                 \n                   Obama\u2019s science legacy: climate (policy) hots up 2016-Aug-23 \n                 \n                   US Supreme Court puts Obama climate regulations on hold 2016-Feb-10 \n                 \n                   First biosimilar drug set to enter US market 2015-Jan-13 \n                 \n                   Biotech reels over patent ruling 2014-Jul-08 \n                 \n                   Conservation: The Endangered Species Act at 40 2013-Dec-18 \n                 \n                   Mixed reviews for US Clean Water Act 2012-Nov-14 \n                 \n                   Supreme Court ruling is good, bad and ugly 2011-Jun-21 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21379", "url": "https://www.nature.com/articles/nature.2017.21379", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Many researchers are sceptical of a paper claiming to have compressed hydrogen to a metallic state. Two physicists say that they have crushed hydrogen under such immense pressures that the gas became a shiny metal \u2014 a feat that  physicists have been trying to accomplish for more than 80 years . But other researchers have serious doubts about the claim, the latest in a field with a long history of failed attempts. Ranga Dias and Isaac Silvera, both physicists at Harvard University in Cambridge, Massachusetts, first posted a report of their results on the arXiv preprint server last October 1 , which attracted immediate criticism. A peer-reviewed version of the report was published on 26 January in  Science 2 , but sceptics say that it includes little new information. Five experts told  Nature \u2019s news team that they do not yet believe the claim, and need more evidence. \u201cI don\u2019t think the paper is convincing at all,\u201d says Paul Loubeyre, a physicist at France\u2019s Atomic Energy Commission in Bruy\u00e8res-le-Ch\u00e2tel. Silvera and Dias say that they wanted to publish their first observation before making further tests on their fragile material. \n               Metallic dream \n             Producing metallic hydrogen in the laboratory has been a dream of high-pressure researchers ever since 1935, when theorists first predicted its existence 3 . When squeezed with enough pressure inside an anvil, hydrogen should be able to conduct electricity, the hallmark of a metallic state. And theorists say that the material could have other exotic properties, such as being a superconductor \u2014 able to conduct electricity without resistance \u2014 even at room temperature. By making metallic hydrogen, physicists might also be able to explore planetary science at their lab bench: gas-giant planets such as Jupiter are theorized to have metallic hydrogen in their cores, which would perhaps explain how they can sustain a magnetic field. In recent years, physicists have crushed tiny samples of hydrogen between diamond anvils at pressures exceeding those in the centre of Earth. The experiments are delicate and fraught with potential for error. Researchers have seen the material change from transparent to dark as it is compressed, which suggests that as electrons are crowded together, they are able to absorb photons of visible light. But no one has proven the existence of metallic, shiny hydrogen, which would reflect light. In 2011, a report 4  by physicists at the Max Planck Institute for Chemistry in Mainz, Germany, was  controversial . Mikhail Eremets, who leads that group, says his team has not yet provided conclusive evidence. Dias and Silvera say that they were able to squeeze their hydrogen gas at greater pressures than anyone else has managed. To do so, they used an anvil that can fit inside a cryostat, enabling them to cool their hydrogen sample to just above absolute zero. They also say they have found a better way to polish the tips of their diamonds, to remove irregularities that could break the gems. They then turned a screw to crank up the pressure to 495 billion pascals (495 GPa), or almost 5 million times higher than atmospheric pressure at sea level. \u201cThen, suddenly, it becomes a lustry, reflective sample, which you can only believe is a metal,\u201d Silvera says. Seen through a microscope, the sample appeared shiny, and it reflected light in the way metallic hydrogen should do, he says. \n               Redo the measurement \n             Other researchers aren't convinced. It\u2019s far from clear that the shiny material the researchers see is actually hydrogen, says geophysicist Alexander Goncharov of the Carnegie Institution for Science in Washington DC. Goncharov has criticized the Silvera lab\u2019s methods before. He suggests that the shiny material may be alumina (aluminium oxide), which coats the tips of the diamonds in the anvil, and may behave differently under pressure. Loubeyre and others think that Silvera and Dias are overestimating the pressure that they reached, by relying on an imprecise calibration between turns of the screw and pressure inside the anvil. Eugene Gregoryanz, a physicist at the University of Edinburgh, UK, adds that part of the problem is that the researchers took only a single detailed measurement of their sample at the highest pressure \u2014 making it hard to see how pressure shifted during the experiment. \u201cIf they want to be convincing, they have to redo the measurement, really measuring the evolution of pressure,\u201d says Loubeyre. \u201cThen they have to show that, in this pressure range, the alumina is not becoming metallic.\u201d But Silvera says that he just wanted to get the news out there before making confirmation tests, which, he says, could break their precious specimen. \u201cWe wanted to publish this breakthrough event on this sample,\u201d he says. To preserve the material, he and Dias have kept it in the cryostat; the lab has only two cryostats, and the other is in use for other experiments, he says. \u201cNow that the paper has been accepted, we\u2019re going to do further experiments.\u201d Despite the scepticism, press-release materials issued by  Science  and by Harvard University confidently proclaim that metallic hydrogen has been made. \u201cThis is the holy grail of high-pressure physics,\u201d Silvera says in Harvard\u2019s press release. \u201cIt's the first-ever sample of metallic hydrogen on Earth.\u201d Additional reporting by Lee Billings. \n                     Superconductivity record sparks wave of follow-up physics 2015-Aug-17 \n                   \n                     Metallic hydrogen: Hard pressed 2012-Jun-13 \n                   \n                     Great balls of metal 2000-Jun-20 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21486", "url": "https://www.nature.com/articles/nature.2017.21486", "year": 2017, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "The provisional agreement may set a precedent for other funders and journal publishers. If research funders demand open-access publishing, will subscription journals acquiesce? An  announcement today \u00a0by the publisher of\u00a0 Science  suggests they will \u2014 as long as that funder is as influential as the Bill & Melinda Gates Foundation. The global health charity, based in Seattle, Washington, has partnered with the American Association for the Advancement of Science (AAAS) in a year-long agreement to \u201cexpand access to high-quality scientific publishing\u201d. This means that Gates-funded research can be published on open-access (OA) terms in\u00a0 Science\u00a0 and\u00a0 four other AAAS journals. \u201cThis is the first time the AAAS is offering open-access publishing for  Science  and the subscription-based sister journals,\u201d says Meagan Phelan, a spokesperson for the AAAS in Washington DC. However, the AAAS-Gates agreement is provisional, says Dick Wilder, associate general counsel with the Gates Foundation\u2019s Global Health Program, and will be reviewed later this year to see if it continues for 2018. \u201cWe hope and they hope that this is something that will continue indefinitely,\u201d he adds. Scholars  were previously not allowed to publish Gates-funded research  in some AAAS journals because they didn\u2019t accommodate Gates\u2019 strict OA policy. The same OA clash exists at other influential subscription journals, including  Nature . ( Nature\u2019s\u00a0 news team is editorially independent of the journal \u00a0Nature ). Gates' policy stipulates that researchers must make their resulting papers and data open immediately upon publication, and under a licence that allows unrestricted reuse for commercial purposes. Open-access advocates applauded the move. \u201cGood for\u00a0 Science \u00a0for agreeing to accommodate the Gates policy, and good for Gates in refusing to accommodate the previous terms and conditions of\u00a0 Science ,\" says Peter Suber, director of the Harvard Open Access Project and the Harvard Office for Scholarly Communication in Cambridge, Massachusetts. \n             A temporary arrangement \n           The Gates Foundation usually pays journals\u2019 publishing fees for individual studies in order to assure OA content. But as part of this new agreement, the Foundation will pay AAAS a lump sum of US$100,000 for the year, says Wilder. The Foundation estimates that it will publish between 10 and 15 studies in AAAS journals this year, and says that it will work with AAAS to develop a report looking at the sustainability of OA publishing in journals such as\u00a0 Science , which make money largely from library subscriptions. Suber says that the agreement may reassure other funders that they can try to adopt strong OA policies without locking their grantees out of major journals. \u201cThe Gates Foundation is showing that other foundations should not worry about journal embargo and licensing terms in the first place, or if they do worry, they should act even without waiting for the worry to lift,\u201d he says. \n             Future partners? \n           The Wellcome Trust in London, UK, is one funder that has  pushed for open-access policies . But if the publisher does not offer OA, the organization allows a six-month embargo period before papers must be made open to the public. \u201cWe welcome AAAS\u2019s efforts to ensure Gates grantees\u2019 publications are openly available, and look forward to exploring similar opportunities for Wellcome-funded research,\u201d says Robert Kiley, who leads the charity\u2019s open-access efforts.\u00a0 The AAAS-Gates partnership is the only such arrangement AAAS is considering for now, says Phelan. But \u201cAAAS will consider additional partnerships at the end of 2017\u201d. Science \u00a0is not the only journal looking to accommodate Gates\u2019 policy in some way, Wilder says. The foundation is in ongoing discussions with the other journals, and more announcements may come soon, he adds. Spokespeople for the  Proceedings of the National Academy of Sciences  and the  New England Journal of Medicine  say their respective journals are still discussing the matter.  Nature \u2019s news team is waiting on comment from other publishers that do not currently comply with Gates\u2019 OA policy. \n                   German scientists regain access to Elsevier journals 2017-Feb-14 \n                 \n                   Gates Foundation research can\u2019t be published in top journals 2017-Jan-13 \n                 \n                   Wellcome Trust launches open-access publishing venture 2016-Jul-06 \n                 \n                   Open access: The true cost of science publishing 2013-Mar-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21370", "url": "https://www.nature.com/articles/nature.2017.21370", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "A new algorithm succeeds by asking members of large groups how they think others will respond. Ask a group of people to guess a stranger\u2019s weight, the thinking goes, and the average answer should be close to correct. This idea, termed  the wisdom of crowds , is that in a large group errors of judgement should cancel each other out. But there are situations in which this classic theory falls apart. If you ask a group of people whether Philadelphia is the capital of Pennsylvania, most will incorrectly answer yes. That\u2019s because they know one set of facts: Philadelphia is a large city in Pennsylvania, and capital cities are large. But another, smaller group will give the correct answer: Harrisburg. A new algorithm could help pull the correct answer out of a crowd, even when the most popular answer is wrong, a team led by Dra\u017een Prelec, a social scientist at the Massachusetts Institute of Technology in Cambridge, reports on 25 January in  Nature 1 . The team asked study participants to answer a given set of questions. Then the researchers asked those respondents to guess how other people would answer. The algorithm then looked for answers that were \u2018surprisingly popular\u2019, or more popular than most respondents thought they would be. In most cases, the answers that exceeded expectations were the correct ones. \u201cIn society, I think there is an assumption that the average opinion is generally right, and that\u2019s been supported by past statistical arguments on crowd wisdom,\u201d says Prelec, \u201cBut that\u2019s not the way evidence works. There are specialists with special knowledge, like doctors. This lets us identify that knowledge.\u201d \n             What's it worth? \n           Prelec and his colleagues asked groups of 20\u201351 participants a variety of questions. Sometimes, they were simple geographical ones, such as naming capital cities. They asked people to estimate the value of art, and asked dermatologists to identify skin lesions. Prelec says that most of the time, the algorithm was 21\u201336% more effective at identifying the correct answer than other methods,  such as relying on the most popular answer  or ranking answers by confidence. It was better at answering yes or no questions such as the Philadelphia one than it was at estimating the value of art. \u201cThis is a very clever technique, and a very simple way of polling people,\u201d says Mark Steyvers, a cognitive scientist at the University of California, Irvine. Steyvers notes that in real life, people ask each other about their backgrounds and skills to determine the validity of their information. But for anonymous polling situations, he says, Prelec\u2019s method can be a good way to identify views informed by specialized knowledge. And Prelec and Steyvers both caution that this algorithm won\u2019t solve all of life\u2019s hard problems. It only works on factual topics: people will have to figure out the answers to political and philosophical questions the old-fashioned way. Reprints and Permissions"},
{"file_id": "nature.2017.21327", "url": "https://www.nature.com/articles/nature.2017.21327", "year": 2017, "authors": [{"name": "Lauren Morello"}], "parsed_as_year": "2006_or_before", "body": "From stem-cell law to national monuments, the president-elect has myriad opportunities to transform the research landscape. Barack Obama used his presidential powers to make changes that affect science. Once Donald Trump is inaugurated as president on 20 January, he will be able to do the same. These charts illustrate the government that Trump inherits as it relates to science and research, and explore how the new president might seek to take things in a different direction. \n             Appointing leaders and freezing new hires \n           As does every new president, Trump gets to fill out the ranks of federal science agencies with political appointees, from the agency chiefs who require Senate confirmation to lower-level bureaucrats. These jobs range from two spots at the US Geological Survey \u2014 the director and an assistant \u2014 to 358 positions at the Department of Energy. Trump has already nominated a handful of people to fill these slots, including  former Governor of Texas Rick Perry, who has questioned the science underlying climate change, as energy secretary . The much-larger ranks of non-political \u2018career\u2019 employees, meanwhile, could shrink under Trump, who has pledged to freeze federal hiring within his first 100 days in office. Staffing levels at science agencies \u2014 which stayed relatively flat under Obama,  despite his enthusiasm for research  \u2014 could eventually dwindle by attrition. \n             Balancing basic and applied science \n           Funding science involves a delicate balance. Science in the Obama years  tilted the needle towards applied research  \u2014 from the launch of  the ambitious Precision Medicine Initiative \u00a0to sequence the genomes of one million people, to the\u00a0creation of a string of institutes to foster robotics and other innovative manufacturing technologies in partnership with private industry. It is not clear which flavour of research Trump will favour, in part because  he has said little publicly about science before or after the election . In September, Trump wrote that \u201cscientific advances do require long term investment\u201d, in response to questions from the advocacy group ScienceDebate.org. But the president-elect's pick to lead the White House Office of Management and Budget, Representative Mick Mulvaney (Republican, South Carolina), has pushed for sharp cuts in government spending in recent years.\u00a0 \n             Undoing Obama's conservation triumphs \n           More than any other president, Obama has used the Antiquities Act \u2014 a law that dates back to 1906 \u2014 to protect public lands from development. He has declared 29 new national monuments, such as the Bears Ears buttes in Utah, and enlarged 5 others, preserving a total of around 553 million acres of land and water. Some Republican politicians have suggested that Trump should remove protections from some or all of these areas, but most legal scholars say that only an act of Congress can reverse a monument designation. That might not stop the Trump administration from trying. The president-elect's nominee to lead the Interior Department, Representative Ryan Zinke (Republican, Montana), told a Senate committee on 17 January that Trump could \u201camend\u201d, if not fully rescind, the monuments that Obama created. \n             Reversing stem cell and climate change policies? \n           Faced with an often-hostile Congress,  Obama enacted many of his signature policies by executive order  \u2014 from  reversing restrictions on research with human embryonic stem cells  to helping communities prepare for climate change. That strategy now seems poised to backfire: Trump has vowed to reverse \u201cevery unconstitutional executive action, memorandum and order issued by President Obama\u201d beginning on his first day in office, 20 January. \n                   US Earth scientists plan for uncertain future under Trump 2016-Dec-20 \n                 \n                   The ultimate experiment: How Trump will handle science 2016-Nov-11 \n                 \n                   Obama\u2019s science legacy: uneven progress on scientific integrity 2016-Aug-23 \n                 \n                   Obama\u2019s science legacy: betting big on biomedical science 2016-Aug-22 \n                 \n                   Obama\u2019s science legacy: a space race stalls 2016-Aug-22 \n                 \n                   US science: The Obama experiment 2012-Sep-26 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21295", "url": "https://www.nature.com/articles/nature.2017.21295", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "A reproducibility guru, a former defence-research official and a controversial entrepreneur rumoured to be on list, along with current NIH leader and a congressman. Could US president-elect Donald Trump be close to choosing a leader for the National Institutes of Health (NIH)? Current NIH chief Francis Collins and Representative Andy Harris (Republican, Maryland), both front-runners for the job, met separately with Trump on 11 January, as did billionaire surgeon Patrick Soon-Shiong on 10 January. Several people familiar with the Collins and Harris meetings described them as job interviews. Other rumoured candidates include Geoffrey Ling, a retired Army neurosurgeon and  former director of biotechnology at the Defense Advanced Research Projects Agency  (DARPA), who says that he met with Trump's transition team recently, and John Ioannidis, an epidemiologist at Stanford University in California  who has pushed for reproducibility in biomedical science . Although Ioannidis says that he has not been approached by Trump\u2019s staff, sources close to the transition team say that the scientist has been floated for the NIH position. \u201cIf they call, my first priority would be to make sure there are no strings attached in promoting any anti-science ideas,\u201d Ioannidis says, such as linking vaccines to autism. But Collins \u2014 who has led the NIH since August 2009 \u2014 has already said that he would continue on if Trump asked. That would make Collins, the longest-tenured member of President Barack Obama\u2019s science \u2018dream team\u2019, the first NIH director since the 1970s to be chosen by two presidents. Known for his skill at communicating with lawmakers, Collins has the backing of four senior Republican members of Congress, who signed a 2 December letter urging Trump to keep him on. But extending a single director\u2019s tenure for so long may not be in the agency\u2019s best interest, says Ezekiel Emanuel, a bioethicist at the University of Pennsylvania in Philadelphia. \u201cIn general, I think more than eight years has not been a good idea,\u201d he says. \u201cThere\u2019s a cycle, and eight years is hard to have new ideas and new energy.\u201d Others worry that Trump could go too far in the opposite direction, and pick an NIH chief without a significant science track record or experience in managing large research projects. With both Harris and Soon-Shiong, \u201dmy concern would be that this is a person who hasn't really been tested\u201d, says Keith Yamamoto, a biologist at the University of California, San Francisco.\u00a0 \n             Culture clash? \n           Harris, an anaesthesiologist, has taken a strong interest in the NIH during his three terms in the House of Representatives. He helped to write the 21st Century Cures Act, a law enacted last year to reform research and development at the NIH and the Food and Drug Administration, and pushed the NIH to develop a five-year strategic plan. And Harris has taken a special interest in early-career scientists, proposing legislation that would force the NIH to set aside more money for young researchers and to lower the age at which investigators receive their first grant. Many lobbyists and science advocates contacted by  Nature  refused to comment on the record about Harris. Some expressed worry that his policy positions \u2014 including staunch opposition to research with human embryonic stem cells \u2014 would be at odds with the NIH\u2019s culture. \u201c He would be much more entrepreneurial in outlook and attitude\u201d than Collins, says one long-time NIH-watcher, who works in science policy. \u201cIf it's Harris, I think there would be a mass exodus of senior leaders.\u201d Still, Harris may benefit from having served in the House with Representative Tom Price (Republican, Georgia),  whom Trump has nominated to lead the Department of Health and Human Services , which oversees the NIH. \n             Business interests \n           And his interest in early-career scientists could give him an edge with key Trump advisers, including Silicon Valley billionaire Peter Thiel, who met with Trump on 11 January, and former House speaker Newt Gingrich. Both are said to be particularly interested in improving conditions for young researchers. Another candidate who could appeal to Thiel is Ling. As the first director of DARPA\u2019s biotechnology office, Ling oversaw the kind of \u2018high-risk, high-reward\u2019 projects that the NIH does not often fund \u2014 and Thiel has said that science needs more bold, entrepreneurial ventures. Ling says that he met with the Trump transition team as recently as the week of 9 January, although he would not comment on whether he met with Trump himself. \u201cThey're really spending a lot of time trying to decide what direction they want to go,\u201d he says. If selected as director, Ling says that he would seek to increase NIH\u2019s engagement with the private sector, particularly with start-up companies. Doing so could help the NIH navigate difficulties posed by its relatively flat funding and increase opportunities for young scientists.\u00a0 \u201cNIH wants to grow,\u201d he says. The start-up world \u201cis a robust environment right now, it\u2019s out there,\u201d Ling says, \u201cbut with a little bit of help from NIH, I think it could really explode and that\u2019s a good thing\u201d. \n             Dark horse \n           If Trump is looking for an outsider candidate, that could boost the chances of Soon-Shiong, a billionaire surgeon who runs a network of health companies called NantWorks. Soon-Shiong was among the scientists who advised v ice-president Joe Biden\u2019s Cancer Moonshot initiative . He also runs his own, separate programme called Cancer MoonShot 2020, a collaboration between several pharmaceutical companies that are developing immunotherapies. Sources who have spoken with the transition team say that Soon-Shiong is also under consideration for other government positions, including  presidential science adviser . (Another rumoured candidate for science adviser, former NIH director Elias Zerhouni, told Bloomberg News on 9 January that he did not want to leave his current post at drug giant Sanofi.) \n                   Does it matter if Donald Trump has a science adviser? 2016-Dec-08 \n                 \n                   Trump's pick for US health secretary has pushed to cut science spending 2016-Nov-29 \n                 \n                   The ultimate experiment: How Trump will handle science 2016-Nov-11 \n                 \n                   Donald Trump's US election win stuns scientists 2016-Nov-09 \n                 \n                   Scientists worry as cancer moonshots multiply 2016-Apr-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21300", "url": "https://www.nature.com/articles/nature.2017.21300", "year": 2017, "authors": [{"name": "Jane  Qiu"}], "parsed_as_year": "2006_or_before", "body": "Two species of distantly related panda may have adapted to a bamboo-centric diet in similar genetic ways. Giant pandas and the distantly related red pandas may have independently evolved an extra \u2018digit\u2019 \u2014 a false thumb \u2014 through changes to the same genes. The two species share a common ancestor that lived more than 40 million years ago. Giant pandas ( Ailuropoda melanoleuca ) are distant relatives of other bears, whereas red pandas ( Ailurus fulgens ) are more closely related to ferrets. Both species subsist on a diet composed almost entirely of bamboo, with the help of a false digit. The pandas\u2019 \u2018thumbs\u2019 \u2014 which are actually abnormally enlarged wrist bones \u2014 allow both species to grip and handle bamboo with remarkable dexterity. But \u201cexactly how such evolutionarily distant animals evolved such a similar lifestyle and body form has long been a mystery,\u201d says Steve Phelps, a geneticist at the University of Texas at Austin. In a new study, Wei Fuwen and Hu Yibo, conservation geneticists at the Chinese Academy of Sciences\u2019 Institute of Zoology in Beijing, and their colleagues, produced the first genome sequence of the red panda and compared it with  the giant panda genome . This comparison turned up a list of 70 genes that showed signs of evolutionary change in both species. Two of the genes,  DYNC2H1  and  PCNT , are important for limb development, and mutations in these genes can cause bone and muscle abnormalities, including extra digits, in mice and humans. Both pandas also share single amino-acid changes in the proteins encoded by  DYNC2H1 \u00a0and\u00a0 PCNT\u00a0 that are not found in 60 other mammal species. The researchers propose that these changes could have contributed to the pandas\u2019 false thumbs. Seven other genes on the list \u2014 including those involved in absorbing vitamins and amino acids that the body cannot produce \u2014 may have helped both pandas subsist on nutrient-poor bamboo, says Wei. The team\u2019s findings were published on 16 January in  Proceedings of the National Academy of Sciences USA. 1 Andrew Foote, an evolutionary biologist at Bangor University, UK, says that the team has come up with a \u201cvery strong\u201d list of candidates to explain the pandas\u2019 shared adaptations to a unique lifestyle. But he notes that the study was designed to identify only those genetic changes shared by both species \u2014 and not those unique to one panda or the other that also contribute to their similarities. David Stern, a geneticist at the Janelia Research Campus of the Howard Hughes Medical Institute in Ashburn, Virginia, stresses that additional experiments \u2014 in transgenic mice, for instance \u2014 will be needed to prove that mutations in genes including  DYNC2H1  and\u00a0 PCNT \u00a0contributed to adaptations such as the pandas\u2019 thumbs. But he notes that the study fits in with a growing body of literature that suggests that organisms that face the same challenges often adapt in genetically similar ways. Evolution, Stern says, \u201cis actually much more predictable than anybody predicted.\u201d \n                   Panda guts not suited to digesting bamboo 2015-May-19 \n                 \n                   Experts question China's panda survey 2015-Feb-28 \n                 \n                   Genome reveals panda's carnivorous side 2009-Dec-11 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21293", "url": "https://www.nature.com/articles/nature.2017.21293", "year": 2017, "authors": [{"name": "Charles Q. Choi"}], "parsed_as_year": "2006_or_before", "body": "Until now, prions were only seen in the cells of eukaryotic organisms such as plants and animals. Prions, the infectious agents best known for causing degenerative brain disorders such as \u2018mad cow\u2019 disease, may have been spotted in bacteria. A section of a protein in  Clostridium botulinum , the microbe that causes botulism, can behave like a prion when it is inserted into yeast and  Escherichia coli  bacteria, researchers report in the 13 January issue of  Science 1 . Prions are formed by proteins that can fold in a number of structurally distinct ways. A prion version of a protein can perpetuate itself in an infectious manner by converting normal forms of that protein into the prion version. Scientists first discovered prions in the 1980s as the agents behind  fatal brain disorders known as transmissible spongiform encephalopathies . Since then, researchers have found the misfolded proteins in mammals, insects, worms,  plants  and fungi 2 , and learned that not all prions harm their hosts. But until now, prions were only seen in the cells of eukaryotic organisms, a group that includes animals, plants and fungi. \n             Needle in a haystack \n           In the latest study, researchers analysed roughly 60,000 bacterial genomes using software trained to recognize prion-forming proteins in yeast. They focused on a section of the bacterial protein Rho. In many bacteria, such as  C. botulinum  and  E. coli , Rho is a global regulator of gene expression, meaning that it can control the activity of many genes. When the potentially prion-forming section of Rho taken from  C. botulinum  was inserted into  E. coli , clumps of malformed proteins that are characteristic of most prions formed. Moreover, when the protein snippet was inserted into yeast, it could replace the functions of a known prion-forming yeast protein. The researchers also found that although the normal version of Rho suppressed gene activity in  E. coli , many genes were active when the protein was in its prion form. This suggests that prions might allow bacteria to adapt to certain kinds of environmental stresses, says Ann Hochschild, a bacterial geneticist at Harvard Medical School in Boston, Massachusetts, and a co-author of the study. For instance, the scientists found that  E. coli  modified with the prion version of Rho were better able to adapt to exposure to ethanol than could bacteria with normal Rho. These findings suggest that prions predate the evolutionary split between eukaryotes and bacteria about 2.3 billion years ago. \u201cPrions are likely to be much more widespread in nature than previously assumed,\u201d Hochschild says. \u201cWe believe other prion-forming proteins will be uncovered in bacteria.\u201d \n             Quick-change artist \n           Because prions are heritable, the findings suggest that these proteins could allow bacteria to inherit traits without the need for a genetic mutation. That could come in handy \u201cwhen bacteria might need quick responses to their environment, such as dealing with antibiotics\u201d, says Peter Chien, a bacterial biochemist at the University of Massachusetts Amherst. The next step for researchers is to confirm that Rho can act like a prion in its natural host, Chien says. But that could be difficult, because  C. botulinum  is less tractable to genetic experiments than conventional lab organisms such as  E. coli , Chien adds. Developing the capability to experiment with prions in bacteria could help to reveal more about the behaviour of human prions, which may be linked to diseases such as Alzheimer\u2019s and Parkinson\u2019s, says Jeffrey Roberts, a molecular biologist at Cornell University in Ithaca, New York. \n                   Plant protein behaves like a prion 2016-Apr-25 \n                 \n                   Deadly animal prion disease appears in Europe 2016-Apr-18 \n                 \n                   Genetic mutation blocks prion disease 2015-Jun-10 \n                 \n                   Computer scientist makes prion advance 2014-Oct-02 \n                 Reprints and Permissions"},
{"file_id": "541272a", "url": "https://www.nature.com/articles/541272a", "year": 2017, "authors": [{"name": "Mi\u0107o Tatalovi\u0107"}, {"name": "Nenad Jari\u0107 Dauenhauer"}], "parsed_as_year": "2006_or_before", "body": "Pavo Bari\u0161i\u0107 says he won't step down after a parliamentary ethics committee found he copied another scholar's work. In a plagiarism scandal in Croatia, the country\u2019s highest-level research ethics committee is clashing with its science minister \u2014 who says he won't step down after the committee found he had copied another scholar\u2019s work. Scientists say the case raises questions about academic integrity at the top of a research system that is already riven with misconduct allegations. Pavo Bari\u0161i\u0107, a philosopher at the University of Split, became Croatia\u2019s science minister in October 2016. Soon after that, Croatian media began reporting allegations that Bari\u0161i\u0107 had reproduced text without attributing other scholars in a review article that first appeared in 2008 in a local journal,  Synthesis Philosophica . The charges were old \u2014 they had been raised by four other philosophers in 2011 \u2014 but Croatia\u2019s parliament-appointed Committee for Ethics in Science and Higher Education (CESHE) said it would investigate. On 9 January, the committee's report was leaked to the local press. The CESHE, which has not yet formally published the report, concluded that a footnote in Bari\u0161i\u0107's article used text copied from a blogpost by an American international-affairs specialist, Stephen Schlesinger, at the Century Foundation in New York City. Bari\u0161i\u0107's article had other problems too \u2014 such as his description of ideas from the deceased US political scientist Samuel Huntington without attribution \u2014 but the committee didn't agree on whether that constituted plagiarism. In the months beforehand, Bari\u0161i\u0107 maintained that he had done nothing wrong \u2014 even as academics in Croatia and abroad called for his resignation. The minister pointed out that in 2011, an ethics committee at the University of Split had dismissed the allegations as ill-founded. In December 2016, the then-head of the CESHE, Vlatko Silobr\u010di\u0107, resigned, alleging government pressure to drop the case. By then, Bari\u0161i\u0107 had changed his stance. He told journalists that he had taken text from Schlesinger without attribution, and had apologised to him. But the minister said that the fault was merely a \u201ctypographic error\u201d \u2014 so there was no need for him to resign. After the allegations had first surfaced in 2011, later translations and a later republication of the article in a book did attribute Schlesinger, he noted. (These later versions also corrected other errors, such as the lack of attribution to Huntington.) On 14 January, Bari\u0161i\u0107\u2019s original article was amended too, although only the Schlesinger footnote was altered. Bari\u0161i\u0107 did not reply to  Nature \u2019s request for comment. The ethics committee has no power to impose sanctions, but calls for Bari\u0161i\u0107\u2019s resignation have intensified. Sa\u0161a Zelenika, an engineer at the University of Rijeka who was Croatia's assistant science minister in 2012\u201314, says that Bari\u0161i\u0107 has repeatedly misled the public about the matter. \u201cThe minister should definitely resign,\" he says. Ivan Diki\u0107, a Croatian-born biochemist at the Goethe University of Frankfurt in Germany, wrote an open letter to Croatia\u2019s Prime Minister Andrej Plenkovi\u0107 on 11 January, saying that Bari\u0161i\u0107\u2019s actions did not show he could responsibly lead the science ministry. And five days later, Diki\u0107 wrote a second lengthy letter, accusing Bari\u0161i\u0107 of further plagiarism in several other places in his 2008 article. \n               Political struggle \n             But Bari\u0161i\u0107 has some support. Other prominent Croatian scientists said in a newspaper article that the case was overblown, given the small amount of plagiarized text. Plenkovi\u0107 said that he would stand by his minister. And on 15 January, another open letter \u2014 signed by 100 or so scientists, including some of Bari\u0161i\u0107's colleagues at the University of Split \u2014 supported Bari\u0161i\u0107, saying that his \u201csmall omission\u201d could not be considered plagiarism.  The case has wider implications than a back-and-forth about plagiarism and the minister\u2019s responsibility, Zelenika says. He sees the reaction to it as emblematic of Croatia\u2019s struggles to crack down on scientific cheating. In 2008, for example, dozens of the country's professors were arrested on charges of selling exam scripts \u2014 many were later found guilty \u2014 while studies have documented widespread plagiarism among Croatian university students 1 . Other politicians have fallen foul of plagiarism allegations, too. In 2014, for example, the dean of Zagreb's police academy found that the parliament\u2019s current vice-president, Milijan Brki\u0107, had plagiarized large parts of his graduate dissertation on policing. Brki\u0107 has not resigned, but has to write another thesis. Some of those lining up on Bari\u0161i\u0107\u2019s side are now seeking to limit the CESHE\u2019s investigational powers. In November 2016, academic heads at the University of Zagreb initiated a case in Croatia\u2019s constitutional court to review whether the CESHE should retain its statutory authority to pronounce on university ethics disputes. If the case removes CESHE's authority, then Croatia will have diluted an important institution that seeks to uphold its scientific integrity, Zelenika says. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Croatian science faces crisis 2012-Feb-28 \n                   \n                     Croatian scientists call for openness over funding 2006-Jan-04 \n                   \n                     Croatian minister rejects \u2018meddling\u2019 claim 2005-Jan-19 \n                   \n                     Croats protest that science minister is \u2018meddling\u2019 in MedILS 2004-Dec-01 \n                   \n                     Murky dealings abound in Balkan academia \n                   Reprints and Permissions"},
{"file_id": "541271a", "url": "https://www.nature.com/articles/541271a", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Probe could give early warnings of catastrophic solar storms heading for Earth. Excitement is building over European plans to launch a new space-weather satellite that would drastically improve forecasts of how solar storms will affect Earth. The European Space Agency (ESA) hopes to send the probe to a gravitationally stable point in space known as Lagrange point\u00a05 (L5) by around 2023, where it would provide a unique, side-on view of streams of charged particles heading towards Earth. The strongest of such eruptions, known as coronal mass ejections (CMEs), can knock out navigation and communications satellites, interfere with aeroplane navigation systems and disrupt power grids. Currently, probes can only look at incoming space weather head-on. The side-on view would allow scientists to measure the speed of the bursts with greater accuracy. And by observing the Sun\u2019s surface as it rotates towards Earth, the probe would give a preview of sunspots, some of which produce CMEs, before they directly face Earth (see \u2018Parking space-weather probes\u2019). \u201cAn L5 mission would give something the others don\u2019t have,\u201d says Hermann Opgenoorth, a space-plasma physicist at the Swedish Institute of Space Physics in Uppsala. \u201cWe\u2019re excited that it\u2019s finally going ahead.\u201d European ministers agreed to fund the first design phase of the \u20ac450-million (US$478-million) mission with between \u20ac20\u00a0million and \u20ac30\u00a0million at a meeting in Lucerne, Switzerland, last month. The space-weather mission would be ESA\u2019s first aimed at forecasting, rather than pure science. ESA officials will ask for the rest of the funding at the next ministerial meeting in 2019. Technically, ESA has yet to decide whether the satellite will go to L5 or to another gravitationally stable point, known as L1, between Earth and the Sun. Andreas Ottenbacher at the European Space Operations Centre in Darmstadt, Germany, who is a member of ESA\u2019s Space Situational Awareness Programme, says that sending a new mission to L1 is essential, but the United States looks likely to do that in the early 2020s, leaving Europe free to explore the L5 mission. L1 is well populated with probes, but some are ageing, such as the 20-year-old joint ESA\u2013NASA Solar and Heliospheric Observatory (SOHO). And others, such as the US Deep Space Climate Observatory (DSCOVR), lack a coronagraph \u2014 an instrument needed to detect the onset of a CME, the most dangerous form of space weather. Data from NASA\u2019s twin STEREO satellites, one of which passed through L5 during its orbit of the Sun between 2008 and 2010, suggest that a permanent craft there should cut the uncertainty in CME impact time from 10\u00a0hours to less than 6\u00a0hours, says Mike Hapgood, a space-weather physicist at the Rutherford Appleton Laboratory in Didcot, UK, who chairs the UK Space Environment Impact Experts group. The profile view would also allow scientists to see whether separate CMEs interact to build up into a much greater shockwave. Moreover, the L5 point would give a preview of the surface of the rotating Sun soon to be facing Earth\u00a0\u2014\u00a0with benefits for forecasting and solar physics. Currently, forecasts from L1 can raise the alarm only once a ball of plasma has gone hurtling into space. With plasma speeds as high as 3,000\u00a0kilometres per second, this means just 15\u201317 hours\u2019 warning\u00a0\u2014\u00a0well short of the 2\u20133 days that power-grid operators say they need to prepare for disruption, says Juha-Pekka Luntama, who heads ESA\u2019s space-weather team at the European Space Operations Centre. From its shifted position around Earth\u2019s orbit, an L5 craft would see the Sun\u2019s rotating surface four to five days before one at L1 would. Although scientists can\u2019t yet predict with great certainty when sunspots will erupt, just seeing the approach of active zones could allow them to raise an early warning that a dangerous space-weather event is more likely, says Luntama. \u201cIt\u2019s a little like a tornado warning in the US\u00a0\u2014\u00a0you can\u2019t tell exactly when it\u2019s going to happen or where, but you can give a warning that there\u2019s an increased probability of dangerous conditions,\u201d Luntamasays. Combined with L1 data, an L5 craft would allow scientists to track sunspots for longer, which should help them to eventually work out what makes the features erupt and when, adds Opgenoorth. An extreme space-weather event has not hit Earth since 1859, when a CME caused telegraph equipment to catch fire. There was a comparable event in 2012, but it happened on the opposite side of the Sun so did not affect Earth. The impact of an equivalent event, given today\u2019s infrastructure, would be enormous, adds Luntama. \u201cWe have been lucky that we have not been hit by a really big event,\u201d he says. \u201cWe will be hit eventually, the question is, \u2018when?\u2019\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Cosmic rays may threaten space-weather satellite 2016-Oct-28 \n                   \n                     US sharpens surveillance of crippling solar storms 2016-Sep-20 \n                   \n                     Al Gore\u2019s dream spacecraft gears up for launch 2015-Jan-14 \n                   \n                     Solar eruptions combine to cause super storms 2014-Mar-18 \n                   \n                     UK bolsters defences against crippling solar storms 2013-Dec-26 \n                   \n                     ESA: Space Situational Awareness \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21313", "url": "https://www.nature.com/articles/nature.2017.21313", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "A virus that infects bacteria listens to messages from its relatives when deciding how to attack its hosts. Viruses sense chemical signals left behind by their forebears so they can decide whether to kill or just to infect their hosts. The discovery \u2014 in viruses that attack  Bacillus  bacteria \u2014 marks the first time that any type of viral communication system has ever been found. But researchers say that many other viruses could communicate with each other\u00a0through their own molecular languages \u2014 perhaps even viruses that are responsible for human diseases. If that is the case, scientists might have found a new way to disrupt viral attacks. The secret viral code was spotted by a team led by Rotem Sorek, a microbial geneticist at the Weizmann Institute of Science in Rehovot, Israel. Their findings are published in  Nature  on 18 January 1 . \u201cThis is going to be one of those transformative papers,\u201d says microbiologist Martha Clokie, who studies viruses that infect bacteria (known as bacteriophages, or phages) at the University of Leicester, UK. \n             Infection signals \n           Sorek\u2019s team was looking for evidence that a bacterium called  Bacillus subtilis  might alert other bacteria to phages. The researchers knew that bacteria speak to their brethren through secreting and sensing an array of chemicals. This phenomenon, called quorum sensing, allows the bacteria to adjust behaviours according to the numbers of other bacteria around. For instance, bacteria use quorum sensing to decide whether to divide or when to launch an infection.\u00a0 Instead, the team found, to its surprise, that a viral invader of  Bacillus  bacteria \u2014 a phage called phi3T \u2014 makes a chemical that influences the behaviour of other viruses.\u00a0 Some phages can infect cells in two different ways. Usually, they hijack host cells and multiply until the hosts burst and die. Sometimes, however, phages insert their own genetic material into a host\u2019s genome,\u00a0then lie dormant until a trigger causes them to reawaken and multiply later. The newly discovered viral communication system alters the way phi3T infects. The team first injected phi3T into a flask of  Bacillus subtilis  bacteria, and found that the virus tended to kill the bacteria. Then they filtered the contents of this flask to remove bacteria and viruses \u2014 but keeping small proteins \u2014 and fed this \u2018conditioned medium\u2019 to a fresh culture of bacteria and phages. That changed what the phage did: it was now more likely to slip its genome into the bacteria, rather than kill it. The team named the mysterious molecule that they suspected was involved \u2018arbitrium\u2019 (after the Latin word for decision) and set out to identify it. \n             'Annoyingly good' \n           After a two-and-a-half year search, Sorek and graduate student Zohar Erez discovered that arbitrium was a short viral protein that seeps out of infected bacteria after death. When levels of arbitrium build up \u2014 after a large number of cells have died \u2014 phages stop killing off the remaining bacteria and retreat to lie dormant in bacterial genomes instead. Sorek, Erez and their colleagues identified two further phi3T proteins that measure levels of arbitrium and then influence the nature of subsequent infections. \u201cIt does make a lot of sense,\u201d says Peter Fineran, a microbial geneticist at the University of Otago in Dunedin, New Zealand. \u201cIf the phage is running out of hosts, it would try and limit its destruction, and sit quiet and wait for the host to re-establish growth.\u201d The new work is \u201cannoyingly good\u201d, says Clokie. \u201cI\u2019ve thought about doing those experiments to see if there\u2019s something in the media.\u201d She also expects other phage biologists will discover other communication systems. Sorek\u2019s team found more than 100 different arbitrium-like systems, most of them in the genomes of other  Bacillus  viruses. \u201cPhages broadcast in different frequencies. They speak in different languages and they can hear only the language that they speak,\u201d he adds. He even wonders whether viruses that infect more complex organisms, such as people, could talk to one another. HIV and herpes viruses can cause both active and latent infections, he notes. \u201cIf you had a molecule that could drive viruses into complete latency, it would be a good drug.\u201d Read the related News & Views article: ' Phages make group decision ' Reprints and Permissions"},
{"file_id": "nature.2017.21319", "url": "https://www.nature.com/articles/nature.2017.21319", "year": 2017, "authors": [{"name": "Jeff Tollefson"}, {"name": "Alexandra Witze"}, {"name": "Amy Maxmen"}, {"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "President-elect's picks to lead environment and health agencies testify before Congress. On 18 January, four of US president-elect Donald Trump's picks for key government positions had confirmation hearings in the US Senate. Lawmakers had a chance to question the nominees, who must be confirmed by the Senate before they can take office.  Nature  covered the proceedings as they happen. \n             UN: Cholera in Haiti \n           Senator Edward Markey (Democrat, Massachusetts) says that UN peacekeepers from Nepal introduced cholera to Haiti in 2010, causing around 8,000 deaths thus far. And yet, he says, the UN has not committed to cleaning up the sanitation system in the country so that cholera outbreaks will not re-emerge every time there\u2019s a hurricane. \u201cCountries need to take action against violators who harm the people they are supposed to protect,\u201d responds Haley. \u201cThose countries need to be held accountable.\u201d \n             UN: Iran nuclear deal \n           Senator Tim Kaine (Democrat, Virginia) asked Haley whether she might unilaterally back out of the Iran nuclear deal. The deal,  signed by six countries July 2015 , eased sanctions on Iran that had negative unintended consequences for scientists in that country at large. Haley said that for now, she\u2019d like to check to ensure that Iran is in compliance with the agreement \u2014 and if it is not, to act on those violations. She includes a note of disapproval for the deal, however. \u201cWe gave a state sponsor of terrorism a pass,\u201d she says, \u201cAnd we gave them billions of dollars to do it.\u201d \n             EPA: 'Some' human contribution to climate change \n           Shortly before the Pruitt hearing adjourned for a brief recess, Senator Bernie Sanders \u2014 the Vermont Democrat who lost the 2016 Democratic presidential nomination to Hillary Clinton \u2014 argued that Pruitt\u2019s nomination is \u201cdesigned to protect the fossil fuel industry, not the environment\u201d. When Sanders asked Pruitt about his views on global warming, Pruitt said he believes humans are contributing to global warming \u201cin some manner\u201d.Sanders then asked the nominee whether he believes that humans must reduce emissions in order to address global warming. \u201cMy personal opinion is immaterial,\u201d Pruitt said, noting that the EPA administrator\u2019s job is to enforce environmental laws. Pressed again, Pruitt said that the \u201cEPA has a very important role in regulating the emissions of CO2\u201d. \n             HHS: Mission creep at the FDA? \n           Roberts, who chairs the Senate\u2019s agriculture committee, asked Price what he would do about what he sees as mission creep by the US Food and Drug Administration. \u201cI\u2019m concerned that the [Obama] administration did not prioritize FDA\u2019s mission to protect the nation\u2019s food supply,\u201d Roberts said, instead focusing on regulating nutrition. Roberts authored a 2016 bill that would have banned states from requiring the labelling of genetically modified organisms. \u201cIf I'm confirmed, I would work specifically with the FDA commissioner to make sure we are relying on science, that science is driving the decisions we\u2019re making and that transparency makes it available,\u201d Price said. \n             EPA: States' rights \n           One theme that Republican senators have returned to again and again during today's hearing for Pruitt is the role of the states in implementing federal environmental laws \u2014 and the general feeling that EPA has been too aggressive in its enforcement. Senator Dan Sullivan (Republican, Alaska) noted that 32 states \u2014 most with Republican majorities, in the US interior \u2014 have challenged a federal rule intended to expand protections under the Clean Water Act. \u201cThe states are not mere vessels of the federal government,\u201d Pruitt said in response. Environmental laws passed by Congress establish a specific role for states, he added. \u201cThat needs to be respected.\u201d \n             HHS: NIH funding, and more on climate science \n           Senator Susan Collins (Republican, Maine), asked Price whether he would support funding increases for the US National Institutes of Health (NIH). Price says that he does support that. \u201cNIH is a treasure for our country and the kinds of things we should be doing to find cures,\u201d he says. \u201cOne of the core avenues to make those is through NIH.\u201d Senator Sheldon Whitehouse (Democrat, Rhode Island), challenged Price on a 2010 comment that there were \u201cmany recent revelations of errors and obfuscation in the allegedly \"settled science' of global warming\u201d. \u201cIt appears to every science organization in the country \u2014 all the legitimate major ones and to every American university \u2014 that this actually is pretty darn settled science, and the only people who oppose it have vast financial interests,\u201d Whitehouse said. \u201cIn making these statements you have taken the side of special interests. If we can't trust you on the science as settled as climate science, how can we trust you on public health issues where there are financial interests on the other side?\u201d Price dodged the science question. \u201cThe climate is obviously changing, continuously changing. The question from the science standpoint is what impact does human behaviour have on that and how to mitigate it. That needs study.\u201d \n             UN: Questions about US financial support \n           Several senators have mentioned worries that president-elect Trump will cut US funding for the United Nations. \u201cHe has allowed the perception that the United States will no longer take a leadership role,\u201d said Senator Tom Udall (Democrat, New Mexico). \u201cThat he would cut off funding and end our participation in important aspects of the UN. US leadership is paramount. If we left, it will be filled by countries that might not fill our interest like Russia and china.\u201d Udall said that he is pleased by Haley's remarks today about maintaining a strong relationship with the UN.\u00a0 Senator Christopher Murphy (Democrat, Connecticut) also addressed the funding issue. \u201cThe risk of pulling funding because the US doesn't get its way is catastrophic,\u201d he says, noting the UN's role in vaccinating children and providing maternal healthcare.\u00a0 Haley shot down the notion of cutting US financial support. \u201cI have never suggested we should pull funding,\u201d she said. \u201cI do not think we need to pull money from the UN, I do not believe in slash and burn.\u201d Rather, she said, if she did not like a particular UN action she would discuss the matter with Trump before moving forward. As for Trump\u2019s threats suggesting that he might defund or step away from the UN, she said, \u201cI know he has made comments about the UN but those are not things I would believe in.\u201d \n             UN: US role in Paris climate pact \n           Senator Tom Udall (Democrat, New Mexico) asked Haley if she agrees that the United States must remain a part of  the Paris climate agreement . Haley said that the \u201cclimate change will always be on the table for me\u201d. Haley continued: \u201cWhen we look at that Paris agreement, we should do what is right, but not at the peril of our industries.\u201d \n             EPA: Climate-change hoax? \n           Senator Ed Markey (Democrat, Massachusetts) quoted  president-elect Donald Trump calling global warming a \u201choax\u201d perpetrated by China , then asked Pruitt if he agrees. \u201cI do not,\u201d Pruitt said. Markey then asked Pruitt if Trump is wrong, but Pruitt dodged the question. \u201cI do not believe that climate change is a hoax,\u201d he said. In the past, Pruitt has been decidedly less definitive about his position on the both the science and the mainstream scientific consensus. \u201cScientists continue to disagree about the degree and extent of global warming and its connection to the actions of mankind,\u201d Pruitt wrote last May in a guest editorial in the  National Review , co-authored with Alabama attorney general Luther Strange. \u201cThat debate should be encouraged.\u201d Pruitt's hearing comes on the same day that the World Meteorological Organization, NASA and NOAA have each announced that 2016 was the hottest year since record-keeping began in the 1880s. (The previous record-holder was 2015.) \n             NOAA: Balancing budgets, plus more on scientific integrity \n           Senator Brian Schatz (Democrat, Hawaii) asked Ross how he would balance various financial demands within NOAA, such as the competing needs of maintaining coastal research vessels against building in the much more expensive satellite programme. \u201cAs someone who has operated vessels I\u2019m well aware that old vessels are quite inefficient to operate,\u201d Ross said. He noted it would be up to appropriators to decide how much money to allocate to NOAA overall, but pledged to find ways to deal with \u201cthese very pressing capital expenditure needs\u201d. Schatz also followed up on the question about scientific integrity at NOAA, asking the nominee whether he would support the agency\u2019s 2011 scientific integrity policy. \u201cAs I\u2019ve said, I believe that science is science and scientists should perform science,\u201d Ross said. \u201cI haven\u2019t studied the intricate details, frankly, of that document, so I can\u2019t make a formal commitment to it. But as to the general concepts of scientists doing the science, I\u2019m totally in support of that.\u201d \n             HHS: Unclogging the drug pipeline \n           Senator Pat Roberts (Republican, Kansas) asked Price what he would do to improve the pipeline for innovative therapies developed in the United States. Price mentioned the Orphan Drug Act, a 1983 law intended to create more therapies for rare, neglected diseases by offering companies incentives such as market exclusivity, tax credits, and lowered liability in clinical trials. The law, Price says, \u201cmade the US the leader for rare disease\u201d, and suggested that innovation could be further increased by following this model. The number of orphan drug approvals  has indeed skyrocketed in recent years , in part because of incentives but also because blockbuster drugs for common diseases (such as heart disease) are becoming more difficult to find. The rise of precision medicine and easier genome sequencing has also made it easier to identify the cause of a patient\u2019s particular rare condition and develop a drug for it. But the cost of these drugs has also skyrocketed. And some drug approvals, such as a recent decision  to greenlight a drug called eteplirsen to treat Duchenne muscular dystrophy , have proven controversial. Eteplirsen, made by Sarepta Therapeutics in Cambridge, Massachusetts, was approved using data from a 12-patient trial that demonstrated small increases in levels of a key protein rather than changes in symptoms or disease progression. \n             EPA: Energy ties questioned \n           The Pruitt hearing has now settled into a predictable pattern. Democrats use the bulk of their allotted time to attack Pruitt, leaving him little opportunity to respond. Republican senators then step in and offer a bit of their time so that Pruitt can address the Democrats\u2019 accusations. Republicans \u2014 who thus far have been supportive of Pruitt \u2014 then switch to a more gentle line of questioning. Moments ago, this pattern played out with regard to a letter that Pruitt sent to the EPA in 2011 challenging the agency\u2019s estimates of methane emissions from natural-gas wells. As first reported by the  New York Times  last year, that letter was a near-verbatim copy of a letter provided by Devon Energy, an oil and gas company based in Oklahoma. Democrats accused Pruitt of using his office to advance Devon Energy\u2019s interests, but Pruitt hardly had time to defend himself. After Republicans stepped in, Pruitt maintained that he was representing the interests of an industry that is important to Oklahoma \u2014 and thus its people. \u201cThe letter that was sent to EPA was not sent on behalf of any one company,\u201d Pruitt said. \u201cIt was the position of the state.\u201d \n             UN: Maternal health and birth control \n           Senator Jeanne Shaheen (Democrat, New Hampshire) told Haley that 60% of maternal deaths take place in humanitarian settings, such as those affected by conflict. Many of those deaths could be prevented by expanding access to birth control, among other efforts, the senator said \u2014 noting the key role that the UN Population Fund plays in improving reproductive healthcare. \u201cI will support any efforts to help educate, plan and let them know what contraceptives are in place,\u201d Haley said. \u201cI am strongly pro life so anything we can do to prevent abortions I support.\" (Shaheen's figures may be slightly out of date: physician and epidemiologist Hans Rosling has concluded that  no more than 17% of maternal deaths  take place in settings of conflict, displacement and natural disaster.) \n             UN: Philippines killings and HIV \n           Senator Ben Cardin (Democrat, Maryland) asked Haley how she would respond to the decision by Philippines president Rodrigo Duterte to sanction the murder of suspected drug abusers \u2014 a measure that he\u2019s said can combat the country's HIV crisis. Haley said that if she is confirmed as US ambassador to the UN, she would speak up against the killings: \u201cWe have always been the moral compass of the world and we need to speak up on that.\u201d \n             EPA: Conflict of interest? \n           Democrats also pressed Pruitt on his role in an organization called the Rule of Law Defense Fund, which they said receives funding from the energy industry and advocates against climate regulations. Pruitt said he is an officer of the organization and has attended fundraisers, but he denied accusations that this represents a conflict of interest. \n             EPA: Mercury emissions rule \n           Democrats launched an early attack on Pruitt, focusing on the lawsuits that he participated in as Oklahoma attorney general challenging the EPA\u2019s efforts to curb mercury emissions from power plants. A Democratic senator cited statements by Pruitt that seemed to downplay the danger of mercury pollution, but Pruitt said those lawsuits were intended to challenge the regulatory process \u2014 particularly the agency\u2019s estimates of the costs and benefits of the rules. \u201cI believe that mercury should be regulated,\u201d Pruitt said. \u201cThere was no argument that we made that mercury was not a hazardous pollutant.\u201d \n             NOAA: Scientific integrity \n           Nelson asked whether Ross would support  NOAA\u2019s scientific integrity policy , which lays out how agency scientists can clearly communicate scientific results without political interference. \u201cI support the dissemination of valid information to the public,\u201d Ross said. \u201cI have great respect for the scientific quality of NOAA.\u201d Nelson countered by asking whether Ross would consider data on sea level rise to be valid scientific data. \u201cIt\u2019s very hard for me to parse which part of data is what,\u201d Ross responded. He noted that NOAA would shortly release a big report updating its latest climate findings. \u201cIt will be very, very interesting to see what their updated findings are on that topic [sea level rise] as well as other topics,\u201d Ross said. \u201cI\u2019m sure they are mindful of the facts.\u201d \n             EPA: A regulator's role \n           In his opening statement, Scott Pruitt \u2014 Trump's pick to lead the US Environmental Protection Agency, and Oklahoma's attorney-general \u2014 said that he would listen to state regulators, the public and Congress as he enforces federal environmental laws and regulations. He said he rejects the narrative that to be pro-energy is to be anti-environment, and vice versa. He promised predictability: \u201cRegulators are supposed to make things regular.\u201d And although Pruitt has  questioned the science underlying climate change in the past , he took a softer position today. \u201cScience tells us the climate is changing,\u201d and that humans are contributing to that phenomenon, Pruitt said. But the ability to measure that change and what to do about it \u201care subject to continued debate and dialogue\u201d. \n             NOAA: Climate change hits home \n           Wilbur Ross, a billionaire businessman from Florida, is Trump\u2019s nominee to lead the Department of Commerce. The department, which oversees issues such as trade policy, also includes the National Oceanic and Atmospheric Administration (NOAA). Senator Bill Nelson (Democrat, Florida) opened the confirmation hearing by citing data from NOAA and NASA satellites on rising sea levels in Florida. He called on Ross, as a resident of the state, to accept the scientific consensus on climate change. Ross noted that he and his wife live on the water and as such, \u201cweather sensitivity comes to you naturally\u201d. He referred to  the recent launch of the GOES-R satellite , the first of a next generation of weather satellites from NOAA, as closing a gap in forecasting abilities between the US and Europe and Japan. \u201cAs far as I can tell the new sensing devices will bring us up to equal, and probably ahead of, the others,\u201d he said. Ross also said that he had been getting up to speed on the importance of the nation\u2019s fisheries, which are overseen by NOAA. \u201cI don\u2019t think I understood how an intricate an industry that is,\u201d he said. \u201cGiven the enormity of our coastlines and our freshwater, I would like to try to figure out how we can become much more self-sufficient in fishing and perhaps even a net exporter,\u201d he said. \n             And we're off ... \n           The nominees under consideration today include: Reprints and Permissions"},
{"file_id": "nature.2017.21328", "url": "https://www.nature.com/articles/nature.2017.21328", "year": 2017, "authors": [{"name": "Andrew Silver"}], "parsed_as_year": "2006_or_before", "body": "Librarian Jeffrey Beall won\u2019t say why he has unpublished his widely read blog. A widely read website that lists \"potential, possible or probable predatory scholarly open-access publishers\" was wiped clean of all its content on 15 January \u2014 but its creator, Jeffrey Beall, won\u2019t say why. \u201cMy blog is now unpublished,\u201d said Beall, an academic librarian at the University of Colorado, Denver (UCD). He added that he couldn\u2019t give reasons and declined to comment further. A spokeswoman for UCD said that Beall made a \u201cpersonal decision\u201d to close down his blog, and that Beall is still employed on the university\u2019s faculty. In a statement, the university added that Beall would no longer maintain or publish his research on open-access journals and predatory publishers. Beall\u2019s profile page on his employer\u2019s website has also been emptied, as has a Facebook page that he used to publicise his list. Since 2010, Beall has  single-handedly listed thousands of open-access journals that he says exploit or deceive authors  by charging fees to publish papers without providing expected publishing services such as peer review, archiving and editing. \u201cThe list\u2019s importance is tremendous,\u201d says Rick Anderson, an associate dean in the library at the University of Utah in Salt Lake City. \u201cThere really are predators out there running scholarly-communication scams, and Beall has been the only person willing to call them out.\u201d Anderson says he fears the list was taken down because of legal threats. \n             Criticisms \n           Beall\u2019s \u2018blacklist\u2019 has been controversial. Some publishers, such as OMICS Group, based in Hyderabad, India, have threatened to sue him. (Last year, the US Federal Trade Commission itself  sued OMICS  for deceiving researchers and hiding publication fees.) There have been several past legal threats, says the UCD spokeswoman, but none has escalated into actual lawsuits. Others have complained of a lack of transparency in Beall\u2019s judgements, and that it is hard to get off the list once on it. In 2015, Beall controversially added the publisher Frontiers to his list \u2014 a decision that  divided researchers . (The Holtzbrinck Group, in Stuttgart, Germany, is a part owner both of Frontiers and of  Nature \u2019s parent company, Springer Nature). A scholarly-services firm, Cabell\u2019s International in Beaumont, Texas, is creating its own blacklist of journals, which it says is launching this spring. It had hired Beall as a consultant, and its list will include some of the journals on Beall's list if they satisfy the firm's own criteria, a spokeswoman for Cabell\u2019s says. It had not been made aware of any changes regarding Beall being a consultant, the spokeswoman adds, and the organization is \"not sure what is going to happen going forward\u201d. Lacey Earle, vice-president of business development at Cabell\u2019s,  tweeted  that Beall was \u201cforced to shut down blog due to threats & politics\u201d. She did not respond to a request to discuss this with  Nature  and the spokeswoman declined to comment further.\u00a0 Beall\u2019s list hasn\u2019t quite vanished, however. Since its disappearance, cached copies have been shared widely on social media. \n                   Open-access index delists thousands of journals 2016-May-09 \n                 \n                   Backlash after Frontiers journals added to list of questionable publishers 2015-Oct-23 \n                 \n                   Rate that journal 2015-Mar-30 \n                 \n                   Open-access website gets tough 2014-Aug-06 \n                 \n                   Investigating journals: The dark side of publishing 2013-Mar-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21334", "url": "https://www.nature.com/articles/nature.2017.21334", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Trump\u2019s nominee for energy secretary says that he will base decisions on \u2018sound science\u2019. Former Texas governor Rick Perry says that he will defend scientists at the US Department of Energy if he is confirmed as the agency\u2019s next leader. Perry, president-elect Donald Trump\u2019s pick for energy secretary, also says that he would base decisions on \u201csound science\u201d. And he disavowed a questionnaire from the Trump transition team that  sought the names of agency employees who had worked on climate policy . \u201cI am going to protect all of the science, whether it\u2019s related to the climate or other aspects of what we\u2019re going to be doing,\u201d Perry told a Senate committee on 19 January, during a hearing on his nomination. \u201cI am going to  protect the men and women of the scientific community  from anyone that would attack them, no matter what their reason may be, at the Department of Energy.\u201d Perry also said that he regrets  calling for the abolition of the agency in 2012 , when he was vying for the Republican presidential nomination. He told lawmakers that he is \u201cexcited and passionate\u201d about advancing the core missions of the department, from maintaining and modernizing the nuclear-weapons stockpile to advancing modern energy technologies. \n             In the hot seat \n           Democrats on the Senate committee pressed Perry about past statements in which he questioned mainstream climate science. The nominee told them that he thinks global warming is happening. \u201cI believe some of it is naturally occurring, but some of it is caused by manmade activity,\u201d Perry said. \u201cThe question is how we address it in a thoughtful way that doesn\u2019t compromise economic growth.\u201d That did not entirely satisfy Democrats, including Senator Maria Cantwell of Washington state. \u201cI guarantee you today that we are compromising economic growth because of our overdependence on fossil fuels,\u201d she told Perry. Cantwell said that the science under way at the energy department will be critical to understanding the impacts of rising greenhouse-gas levels in the atmosphere \u2014 from the melting of Arctic sea-ice to ocean acidification \u2014 and to maintaining US leadership in clean-energy technologies. Perry cited his own record as governor of Texas from 2000 to 2015, when the state led the nation in the expansion of wind energy, thanks to his support for oil and gas development. He said that, as energy secretary, he would advocate for all forms of energy, including renewable sources. \n             Reaction \n           Perry also seemed to acknowledge concerns from researchers who say he has no experience with basic science or nuclear weapons, both of which are at the core of the department\u2019s mission. \u201cMy desire is to lead this agency in a thoughtful manner, surrounding myself with expertise on the core functions of this department,\u201d he said. He promised to \u201cprotect and modernize\u201d the nation\u2019s nuclear-weapons arsenal. Aside from waffling a bit on questions about the wisdom of nuclear-weapons testing and whether climate change represents a global crisis, Perry generally said the right things, says Michael Lubell, a physicist at the City College of New York. The most important of these, Lubell says, were Perry\u2019s backtracking on his proposal to abolish the energy department and his disavowal of the Trump transition team\u2019s questionnaire. But Lubell added that, given the nominee\u2019s lack of experience, much will depend on whom Perry surrounds himself with and how much freedom Trump gives him to make decisions on budget and policy decisions. \u201cHe may be constrained by the White House,\u201d Lubell says. \u201cIt\u2019s too early to tell.\u201d \u200b \n                   Trump nominees talk science: As it happened 2017-Jan-18 \n                 \n                   Trump's pick for energy secretary once sought to eliminate DOE 2016-Dec-13 \n                 \n                   What Trump\u2019s pick for secretary of state could mean for climate policy 2016-Dec-13 \n                 \n                   Trump\u2019s pick for environment agency chief sued government over climate rules 2016-Dec-07 \n                 Reprints and Permissions"},
{"file_id": "541269a", "url": "https://www.nature.com/articles/541269a", "year": 2017, "authors": [{"name": "Monya Baker"}, {"name": "Elie Dolgin"}], "parsed_as_year": "2006_or_before", "body": "An open-science effort to replicate dozens of cancer-biology studies is off to a confusing start. Erkki Ruoslahti was on track to launch a drug trial in people with cancer this year, but his plan may now be in \u00adjeopardy. A high-profile project designed to gauge the reproducibility of findings from dozens of influential papers on cancer biology publishes results for its first five papers this week, including one by Ruoslahti. And scientists who tried to replicate his findings say that they can\u2019t get his drug to work. For the other four papers, the replication results are less clear. Ruoslahti, a cancer biologist at the Sanford Burnham Prebys Medical Discovery Institute in La Jolla, California, disputes the verdict on his research. After all, at least ten laboratories in the United States, Europe, China, South Korea and Japan have validated the 2010 paper 1  in which he first reported the value of the drug, a peptide designed to penetrate tumours and enhance the cancer-killing power of other chemotherapy agents. \u201cHave three generations of postdocs in my lab fooled themselves, and all these other people done the same? I have a hard time believing that,\u201d he says. Reporter Kerri Smith finds out about efforts to repeat high-profile cancer research. A single failure to replicate results does not prove that initial findings were wrong\u00a0\u2014\u00a0and shouldn\u2019t put a stain on individual papers, says\u00a0Tim Errington, the manager of the reproducibility project, who works at the Center for Open Science in Charlottesville, Virginia. Investigators should take results as information, not condemnation, says Errington. \u201cIf we just see someone else\u2019s evidence as \u00admaking it hard for the person who did the original research, there is something wrong with our culture.\u201d But Ruoslahti worries that the failure to reproduce his results will weaken his ability to raise money for DrugCendR, a company in La Jolla that he founded to develop his therapy. \u201cI\u2019m sure it will,\u201d he says. \u201cI just don\u2019t know how badly.\u201d \n               Repeated attempts \n             The Reproducibility Project: Cancer Biology  launched in 2013  as an ambitious effort to scrutinize key findings in 50 cancer papers published in  Nature ,  Science ,  Cell  and other high-impact journals. It aims to determine what fraction of influential cancer biology studies are probably sound\u00a0\u2014\u00a0a pressing question for the field. In 2012, researchers at the biotechnology firm Amgen in Thousand Oaks, California, announced that they had  failed to replicate 47 of 53 landmark cancer papers 2 . That was widely reported, but Amgen has not identified the studies involved. The reproducibility project, by contrast,  makes all its findings open \u00a0\u2014\u00a0hence Ruoslahti\u2019s discomfort. Two years in, the project downsized to 29 papers, citing budget constraints among other factors: the Laura and John Arnold Foundation in Houston, Texas, which funds\u00a0the \u00adproject, has committed close to US$2\u00a0million for it. Full results should appear by the end of the year. But seven of the replication studies are now complete, and  eLife  is publishing  five fully\u00a0analysed efforts on 19 January. These five paint a muddy picture (see \u2018Muddy waters\u2019). Although the attempt to replicate Ruoslahti\u2019s results failed 3 , two of the other attempts 4 , 5  \u201csubstantially reproduced\u201d research findings\u00a0\u2014 although not all experiments met thresholds of statistical significance, says Sean Morrison, a senior editor at  eLife . The remaining two 6 , 7  yielded \u201cuninterpretable results\u201d, he says: because of problems with these efforts, no clear comparison can be made with the original work. \n               Muddy waters \n               \u201cFor people keeping score at home, right now it\u2019s kind of two out of three that appear to have been reproduced,\u201d says Morrison, who studies cancer and stem cells at the University of Texas Southwestern Medical Center in Dallas. Nature  spoke to corresponding authors for all of the original reports. Some praised the reproducibility project, but others worried that the project might unfairly discredit their work. \u201cCareers are on the line here if this comes out the wrong way,\u201d says Atul Butte, a computational biologist at the University of California, San Francisco, whose own paper was mostly substantiated by the replication team. The reason for the two \u201cuninterpretable\u201d results, Morrison says, is that things went wrong with tests to measure the growth of tumours in the replication attempts. When this happened, the replication researchers\u00a0\u2014\u00a0who were either at contract research labs or at core facilities in academic institutions\u00a0\u2014\u00a0were not allowed to deviate from the peer-reviewed protocols that they had agreed at the start of their experiments (in consultation with the original authors). So they simply reported the problem. Doing anything else\u00a0\u2014\u00a0such as changing the experimental conditions or restarting the work\u00a0\u2014\u00a0would have introduced bias, says Errington. Such conflicts mean that the replication efforts are not very informative, says Levi Garraway, a cancer biologist at the Dana-Farber Cancer Institute in Boston, Massachusetts. \u201cYou can\u2019t distinguish between a trivial reason for a result versus a profound result,\u201d he says. In his study, which identified mutations that accelerate cancer formation, cells that did not carry the mutations grew much faster in the replication effort 7  \u2014\u00a0perhaps because of changes in cell culture. This meant that the replication couldn\u2019t be compared to the original. \n               Devil\u2019s in the details \n             Perhaps the clearest finding from the project is that many papers include too few details about their methods, says Errington. Replication teams spent many hours working with the original authors to chase down protocols and reagents, in many cases because they had been developed by students and postdocs who were no longer with the lab. Even so, the final reports include long lists of reasons why the replication studies might have turned out differently\u00a0\u2014\u00a0from laboratory temperatures to tiny variations in how a drug was delivered. If the project helps to bring such confusing details to the surface, it will have performed a great service, Errington says. Others think that the main value of the project is to encourage scepticism. \u201cCommonly, investigators take published results at face value and move on without reproducing the critical experiments themselves,\u201d says Glenn Begley, an author of the 2012 Amgen report. That\u2019s not the case for Albrecht Piiper, a liver-cancer researcher at the University Hospital Frankfurt in Germany. Piiper has replicated Ruoslahti\u2019s work in his own lab 8 . Despite the latest result, he says, he has \u201cno doubt\u201d about the validity of Ruoslahti\u2019s paper. See Editorial:  Replication studies offer much more than technical details \n                 Tweet \n                 Follow @NatureNews \n               \n                     Replication studies offer much more than technical details 2017-Jan-18 \n                   \n                     Go forth and replicate! 2016-Aug-24 \n                   \n                     1,500 scientists lift the lid on reproducibility 2016-May-25 \n                   \n                     Cancer reproducibility project scales back ambitions 2015-Dec-02 \n                   \n                     Sluggish data sharing hampers reproducibility effort 2015-Jun-03 \n                   \n                     Parasite test shows where validation studies can go wrong 2014-Dec-17 \n                   \n                     Independent labs to verify high-profile papers 2012-Aug-14 \n                   \n                     Nature blog post: Initiative gets $1.3 million to verify findings of 50 high-profile cancer papers \n                   \n                     'Reproducibility Project: Cancer Biology' at the Open Science Framework \n                   \n                     'Reproducibility Project: Cancer Biology' at eLife. \n                   Reprints and Permissions"},
{"file_id": "541267a", "url": "https://www.nature.com/articles/541267a", "year": 2017, "authors": [{"name": "Sanjay Kumar"}], "parsed_as_year": "2006_or_before", "body": "Scientists accused of deceiving the public about benefits of transgenic mustard. India\u2019s long-standing push to approve genetically modified (GM) food crops has been controversially delayed, after an environmental campaigner launched a lawsuit that accuses scientists of deceiving the public about the benefits of transgenic mustard. The claims are untrue, says Deepak Pental, a plant geneticist at the University of Delhi who has led research into the crop. \u201cThese attacks are only calculated to bring a bad name to Indian science,\u201d he says. Other researchers are wary of pronouncing on the merits of the case, which is set for its next hearing in February. But the dispute has halted the approval of India\u2019s first GM food crop, which had seemed imminent. No one is sure when the case will be settled, and a lack of transparency from the regulator that oversees GM-crop approvals adds further complications. Approval of the first transgenic food crop would be a significant moment for India\u2019s agricultural biotechnology industry, potentially paving the way for dozens of GM plants, says Trilochan Mohapatra, director-general of the Indian Council of Agricultural Research in New Delhi. The country currently permits only one GM crop, a variety of cotton that has transgenes to ward off certain insects. In India \u2014 as in many nations \u2014 GM crops are a controversial technology. Researchers say the crops will help to feed the country\u2019s growing population. But campaigners worry about safety and that multi\u00adnational agrotechnology firms could take control of the country\u2019s food supply. In 2010, nationwide protests saw the govern\u00adment  bar commercial planting  of what was once set to be India\u2019s first GM food crop: an insect-resistant aubergine (brinjal). It then gave states the power to veto GM-crop trials, effectively barring field tests. After Prime Minister Narendra Modi came to power in 2014,  some field trials resumed . And the GM mustard ( Brassica juncea ) seemed poised for approval by September 2016, when India\u2019s environment ministry released a review that found no safety concerns. Pental says that the crop raises yields of mustard seed by 25\u201330%, allowing more mustard oil to be produced, which could reduce India\u2019s dependence on other, imported food oils. But on 7\u00a0October, India\u2019s Supreme Court agreed to hear a case brought by Aruna Rodrigues, an anti-GM campaigner who wants a moratorium on the crop\u2019s approval until it undergoes an independent evaluation. While reiterating general concerns over GM crops, Rodrigues says that both Pental and India\u2019s regulatory authorities have exaggerated the benefits of transgenic mustard, and that non-GM mustard could be just as high-yielding. Tests overseen by the environment ministry\u2019s Genetic Engineering Appraisal Committee (GEAC) didn\u2019t pit the new crop against its best possible competitors, she says. She accuses Pental and the authorities of deliberate deception. Pental dismisses these criticisms. The trials were designed to test health and safety, he says, not to stringently compare yields against all competitors. It\u2019s possible, he says, that non-GM varieties might produce higher yields than his first GM generation \u2014 but this hasn\u2019t been tested. Ultimately, farmers will decide on the basis of how the crop performs, he says. The value of transgenic mustard, he adds, is that the introduced genes make it possible to cross-breed the seeds with a wide range of varieties, and to introduce other useful traits, such as resistance to blight or stem rot. Pental also rejects Rodrigues\u2019s complaints of deliberate deception; particular accusations about fudged data, for example, relate to a simple mistake in data reporting, he says. Rodrigues is also worried about a herbicide-tolerant trait bred into the crops \u2014 the trait aids the production of hybrid seeds, but Rodrigues says it could lead farmers to spray more herbicides in the field. Pental says that India\u2019s agriculture ministry would have to give permission for farmers to spray herbicides, although other scientists note that in practice, the government will find it hard to stop unlicensed spraying. And Rodrigues adds that DNA from transgenic mustard might contaminate nearby plants. Pental says that contamination is not a problem: \u201cEven if transgenes go into another variety, what catastrophe is expected?\u201d But other scientists are more cautious. \u201cYou cannot ignore the issue of contamination. It will have to be assessed very carefully,\u201d says Imran Siddiqi, a biologist at the Centre for Cellular and Molecular Biology in Hyderabad. Citing legal sensitivities and lack of familiarity with the case, researchers say they don\u2019t know whether the GEAC and Pental\u2019s team will defeat Rodrigues\u2019s suit. But the legal wrangling is irritating and depressing for biotech researchers, says Govindarajan Padmanaban, a biochemist and scientific adviser to India\u2019s Biotechnology Industry Research Assistance Council, a government body that promotes industry\u2013academia partnerships. Rodrigues\u2019s case has also given a fresh airing to grievances over India\u2019s GM-regulation system. In 2004, a former GEAC member called Suman Sahai lodged a Supreme Court case seeking a regulatory system with more transparency and a higher level of technical competence than she said the GEAC possessed. Sahai runs Gene Campaign, an advocacy organization based in New Delhi, which focuses on conserving India\u2019s agrobiodiversity; she says that India needs a new independent body dedicated to biosafety testing. The Supreme Court is still considering her case, together with a decade-old lawsuit \u2014 filed by Rodrigues \u2014 seeking a national moratorium on GM crops. The mustard case typifies the GEAC\u2019s lack of transparency, say critics including Rodrigues. They note that the agency didn\u2019t share its full biosafety assessment of the GM mustard publicly online \u2014 contrary to the orders of the government\u2019s Central Information Commission, which enforces rights to information. Instead, the GEAC allowed only a limited inspection of its assessment, at its office in Delhi. Agency chair Amita Prasad says that the GEAC had to protect confidential information. For his part, Pental says he has no objection to the details being released, but that it\u2019s up to the GEAC. No one knows when the Supreme Court will decide on Rodrigues\u2019s complaints, says Kabir Dixit, a lawyer in Delhi \u2014 but India\u2019s government has already agreed that it needs the court\u2019s permission before it can approve the mustard\u2019s commercial release. Even if that happens, the crop may still face blocks by state governments. In some states, anti-GM farming organizations have already laid down ultimatums. Rakesh Tikait, a spokesperson for Bhartiya Kisan Union, a leading farmer\u2019s organization in north India, says his group is not going to let GM mustard be planted. \u201cIf any shopkeeper is found selling GM mustard seed, all the seeds of his shop will be taken out and burnt and the shop\u2019s shutters welded,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n               \n                     India eases stance on GM crop trials 2015-May-12 \n                   \n                     India stalls on GM crops 2014-Aug-05 \n                   \n                     Case studies: A hard look at GM crops 2013-May-01 \n                   \n                     Plagiarism plagues India's genetically modified crops 2010-Sep-29 \n                   \n                     India's transgenic aubergine in a stew 2010-Feb-10 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21290", "url": "https://www.nature.com/articles/nature.2017.21290", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Revised scientific-integrity policy gives researchers more leeway to speak to the press and publish their findings. The US Department of Energy (DOE) has released new guidelines to protect researchers from political interference \u2014 a move that  many say is long overdue . \u201cDOE officials should not and will not ask scientists to tailor their work to any particular conclusion,\u201d said energy secretary Ernest Moniz, who announced the guidelines on 11 January. The plan allows scientists to publicly state their opinions on science and policy, as long as they make clear that they are not speaking for the government. It requires researchers to notify their supervisors if they speak to the media or publish their findings, but does not require them to seek approval for such activities. \u201cIt makes it absolutely clear that notification is the only thing required,\u201d says Wendy Wagner, a law professor at the University of Texas at Austin. \u201cThe tenor of the entire policy seems to be full bore about giving scientists and technical people the complete freedom to speak about their research and how it intersects with policy.\u201d The plan \u2014 which applies to DOE employees, contractors and grant recipients \u2014 also calls for the department to appoint an independent ombudsperson to handle complaints. That is a major shift from the DOE\u2019s previous scientific-integrity policy, issued in 2012. That policy applied only to DOE employees, and required them to coordinate with their supervisors before talking to the media and to receive approval before publishing their findings in peer-reviewed journals. \n               Climate of fear \n             \u201cThe old policy was extremely vague, bare bones and had no structure for implementation,\u201d says Michael Halpern, deputy director of the Center for Science and Democracy at the Union of Concerned Scientists in Cambridge, Massachusetts. \u201cWhen rights are not explicit, scientists that share personal opinions can be retaliated against.\u201d The revised guidelines come amid concerns that president-elect Donald Trump\u2019s administration will seek to limit federal support for science, including climate-change research. In December, Trump\u2019s team asked the DOE for the names of employees who have worked on climate-change issues; the department refused and  Trump staffers later disavowed the request . Moniz says the new policy is not a response to that incident or to Trump\u2019s election, and has been in the works for a while. But Wagner thinks that the timing is significant. \u201cThe DOE might feel that if they don\u2019t get this policy out now, it won\u2019t be implemented,\u201d she says. But implementing the full plan is likely to fall to the administration of Trump, who takes office on 20 January.\u00a0 His pick for energy secretary  \u2014 former Texas governor Rick Perry \u2014 could soon be confirmed by the Senate. \u201cThe Senate really needs to get details from Governor Perry, when they go through the confirmation process, about the specific implementation plans he has to ensure that this becomes a reality,\u201d Halpern says. \n                     US Earth scientists plan for uncertain future under Trump 2016-Dec-20 \n                   \n                     Trump's pick for energy secretary once sought to eliminate DOE 2016-Dec-13 \n                   \n                     Obama\u2019s science legacy: uneven progress on scientific integrity 2016-Aug-23 \n                   \n                     Integrity policy unveiled at last 2010-Dec-20 \n                   \n                     Science & politics: Speaking out about science 2010-Oct-13 \n                   \n                     DOE scientific integrity policy: 2016 version \n                   \n                     DOE scientific integrity policy: 2012 version \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21299", "url": "https://www.nature.com/articles/nature.2017.21299", "year": 2017, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Publications such as  Nature  and  Science  have policies that clash with the global health charity's open-access mandate. One of the world\u2019s most influential global health charities says that the research it funds cannot currently be published in several leading journals, because the journals do not comply with its open-access policy. Scientists who do research funded by the Bill & Melinda Gates Foundation are not \u2014 for the moment \u2014 allowed to publish papers about that work\u00a0in journals that include  Nature ,\u00a0 Science , the\u00a0 New England Journal of Medicine (NEJM)  and\u00a0the\u00a0 Proceedings of the National Academy of Sciences (PNAS) . The bar is a result of the Gates Foundation\u2019s  policy in support of open access and open data , which was first\u00a0 announced in 2014 \u00a0but came into force at the beginning of 2017. \u201cPersonally, I applaud the Gates Foundation for taking this stance,\u201d says Simon Hay, a Gates-funded researcher who is director of geospatial science at the Institute for Health Metrics and Evaluation in Seattle, Washington. \u201cThe overwhelming majority of my colleagues in global health and fellow Gates grantees with whom I have chatted are highly supportive of these developments,\u201d he says. \n               Open-access clash \n             The foundation, which is headquartered in Seattle, Washington, stipulates that the researchers whom it funds must make open their resulting papers and underlying data sets immediately upon publication. And papers must be published under a licence that allows unrestricted reuse \u2014 including for commercial purposes. But some journals do not offer this kind of open-access (OA) publishing. Many of them allow papers to be made free to read after an embargo period, usually of around six months, and let authors upload accepted manuscripts online. But neither policy meets the Gates Foundation\u2019s requirements. And so, for papers submitted from the start of 2017, a few top journals are currently off limits to Gates-funded academics.  \u201cWe are having ongoing and fruitful discussions with these publishers,\u201d says Dick Wilder, associate general counsel with the Gates Foundation\u2019s Global Health Program. Wilder adds that the Gates Foundation does not plan to allow exceptions to its policy. \n               No compromise \n             The clash will affect only a few hundred research papers. The foundation typically sees around 2,000\u20142,500 papers published each year from its funding, says Wilder, of which 92% are published in journals that comply with its OA policy. Still, the discussions could result in influential journals making special arrangements with the Gates Foundation to permit OA publishing. If that happens, it would be the first time that journals such as\u00a0 Nature \u00a0and\u00a0 Science\u00a0 have allowed a group of scientists an open-access publishing route based on their funding source. \u201cI predict that the Gates Foundation won't compromise. The journals ought to compromise, and in due time, I predict that they will,\u201d says Peter Suber, director of the Harvard Open Access Project and the Harvard Office for Scholarly Communication in Cambridge, Massachusetts.  Suber recalls that in 2008, many journals were unwilling to accommodate a US National Institutes of Health (NIH) policy, which, at the time, mandated that papers be made freely available no later than 12 months after publication. \u201cEssentially, the NIH forced publishers to choose between accommodating the new policy and refusing to publish the large volume of high-quality research by NIH-funded authors,\u201d he says. In the end, publishers accommodated the policy, Suber notes. He expects that the Gates policy will draw the same concessions from publishers. Another private medical funder, the Wellcome Trust in London, UK, also mandates OA publishing. But its policy permits a six-month embargo on making published papers open, if the journal publisher does not offer open access. When asked whether Wellcome would change its policy if journals were to accommodate the Gates Foundation requirements, its head of digital services, Robert Kiley, said: \u201cWe\u2019ll be watching this development closely.\u201d \n               Journals' view \n             A spokesperson for\u00a0 Nature \u2019s publisher, Springer Nature, said that most Springer Nature journals do comply with the Gates Foundation policies. ( Nature \u2019s\u00a0news team is editorially independent of the journal\u00a0 Nature. ) But a \u201csmall number\u201d, including\u00a0 Nature\u00a0 and some Nature-branded research titles, do not. \u201cAt the moment we believe the subscription model is still the best way to provide sustainable and widespread access to journals with low acceptance rates such as  Nature \u00a0and the\u00a0Nature-branded research and reviews titles,\u201d the spokesperson added, pointing out that authors can share links that allow anyone to read their papers for free through an online reader, albeit not to download them. The American Association for the Advancement of Science, which publishes the\u00a0Science\u00a0family of journals, said that it is \u201cpresently in discussions with the Gates Foundation on this matter\u201d, while the  NEJM  said that \"the policy of the Gates Foundation is under active discussion at this time\".\u00a0 Diane Sullenberger, the executive editor of  PNAS , said: \u201cWe don\u2019t currently have any plans to change our PNAS author license, but we regularly evaluate our policy in light of developments in the scientific community.\u201d \n                     Scientists in Germany, Peru and Taiwan to lose access to Elsevier journals 2016-Dec-23 \n                   \n                     Funders punish open-access dodgers 2014-Apr-09 \n                   \n                     Gates Foundation announces world's strongest policy on open access research \n                   Reprints and Permissions"},
{"file_id": "nature.2015.19081", "url": "https://www.nature.com/articles/nature.2015.19081", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "President-elect Donald Trump\u2019s team has asked Collins to remain in his job for an unknown period. On the eve of his inauguration, president-elect Donald Trump has decided to retain Francis Collins as director of the US National Institutes of Health (NIH) \u2014 at least temporarily. Collins has been \u201cheld over by the Trump administration\u201d, NIH spokesperson Renate Myles said in a 19 January statement. It is not clear whether Trump will formally reappoint Collins, or whether Collins will stay in his job only until Trump appoints a permanent director. The president-elect is set to take office on 20 January. Myles directed further questions about Collins\u2019s status to the Trump transition team. \u201cWe truly do not have any additional details,\u201d she said. The transition team did not respond to a request for comment. Collins,  a geneticist who took office in August 2009 , is the longest-serving member of US President Barack Obama\u2019s science \u2018dream team\u2019. Like other Obama appointees, he submitted a pro forma resignation letter to the president, offering to leave his job on 20 January. But in recent weeks, Collins  has emerged as a candidate to lead the NIH  in Trump\u2019s administration, and he met the president-elect on 11 January. Others rumoured to be under consideration for the post include Representative Andy Harris (Republican, Maryland), biotech billionaire Patrick Soon-Shiong and Geoffrey Ling, former biotech director of the Defense Advanced Research Projects Agency. Despite the uncertainty over how long Collins will stay at the NIH, \u201cI think everyone in the research community will be thrilled\u201d, says Tony Mazzaschi, senior director for policy and research at the Association of Schools and Programs of Public Health in Washington DC. Because Collins was confirmed by the Senate during his first appointment, he would not need to be reconfirmed if Trump decides to retain him long-term. \u201cIt brings some stability to NIH during a stressful budget time,\u201d Mazzaschi says, referring to the fact that the government is operating a stopgap spending bill that runs out in April. \n                   Surprising contenders emerge for Trump\u2019s NIH chief 2017-Jan-13 \n                 \n                   Obama\u2019s science legacy: betting big on biomedical science 2016-Aug-22 \n                 \n                   NIH chief keeps hopes afloat 2014-Aug-15 \n                 \n                   NIH revamp rushes ahead 2011-Mar-01 \n                 \n                   Francis Collins: One year at the helm 2010-Aug-11 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21331", "url": "https://www.nature.com/articles/nature.2017.21331", "year": 2017, "authors": [{"name": "Amy  Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Last-minute proposal from Obama administration addresses CRISPR and other cutting-edge technologies. Researchers transforming animals with the latest genome-engineering tools may be disappointed by draft rules released by the US Food and Drug Administration (FDA) on 18 January \u2014 two days before US President Barack Obama leaves office. It is not clear how the administration of incoming president Donald Trump will carry the proposals forward, however. The most controversial of three proposed regulations declares that all animals whose genomes have been intentionally altered will be examined for safety and efficacy in a process similar to that for new drugs. Many researchers had hoped that the FDA would be less stringent about evaluating organisms whose genomes have been edited with precise tools \u2014 such as CRISPR and a separate technique called TALENs \u2014 than it is for animals that have been given DNA from different species or created using less-sophisticated means. Alison van Eenennaam, an animal geneticist at the University of California, Davis, calls the draft FDA proposals \u201cinsane\u201d. \u201cThe trigger for their regulation is whether the animal was intended to be made, and what does intention have to do with risk?\u201d she says. \u201cThe risk has to do with the attributes of the product.\u201d \n             Swimming upstream? \n           Some scientists, including van Eenennaam, are afraid that the proposed rules would prompt businesses, universities and non-profit organizations to abandon development of genetically engineered animals. They see a cautionary tale in the genetically engineered salmon created by AquaBounty Technologies in the early 1990s. The company \u2014 based in Maynard, Massachusetts \u2014 spent  US$60 million on developing the fish , an Atlantic salmon ( Salmo salar ) with genes from Chinook salmon ( Oncorhynchus tshawytscha ) that allow it to grow rapidly. But the firm had to wait 20 years for the FDA to review more than 50 studies demonstrating that the salmon posed no unusual risks before  the agency approved the fish in November 2015 . Even then, the salmon cannot be sold until  the FDA decides whether it must be labelled as genetically modified . AquaBounty\u2019s story terrifies Scott Fahrenkrug, chief scientific officer at gene-editing company Recombinetics in St Paul, Minnesota. The firm has produced hornless dairy cattle by inserting a gene from naturally hornless beef cattle into a breed of the same species that is used in milk production. The animals could help to reduce the practice of surgical \u2018dehorning\u2019, a controversial practice that has raised animal-welfare concerns. On 21 December, Recombinetics told the FDA that it intended to market food from its cows without FDA approval, and with a label reading \u2018generally recognized as safe\u2019. The company\u2019s decision was bolstered by the US Department of Agriculture\u2019s announcement in April 2016 that it would  forgo regulation of a mushroom that has been genetically modified to resist browning . The agency said that the fungus, which was created using the CRISPR\u2013Cas9 method, did not require approval because it did not contain genes from other species. Recombinetics\u2019 cattle were also created without foreign genes, using TALENs. \n             Enter Trump \n           Fahrenkrug was taken aback by the FDA\u2019s new proposal, and says that the agency has \u201cgone off the rails\u201d. \u201cThey\u2019re suggesting that an already existing allele we have been eating for thousands of years now needs to be evaluated for risk because we\u2019ve intentionally put it into this cow\u2019s genome,\u201d he says. The company plans to protest against the agency\u2019s plan to the incoming administration of president-elect Donald Trump, which will oversee finalization of any new regulations. The draft regulations will be open for public comment until 19 April, and the FDA may modify its approach according to the feedback it receives. Others welcomed the Obama administration\u2019s last-minute overture. \u201cThe public is leery of genetic engineering of animals, in particular,\u201d says Jennifer Kuzma, a social scientist at North Carolina State University in Raleigh. \u201cWith gene editing we do see off-target effects, so it is wise on the part of the FDA to include all of these organisms in the near term while they build up data.\u201d But having had her own transgenic projects frozen in the past owing to arguably baseless fears from the public and regulators, van Eenennaam disagrees. \u201cBecause of measures like this, almost everything in genetic engineering will have to be done by huge multinational companies,\u201d she says. \u201cIf the scientific community doesn\u2019t stand up and say this is crazy, we\u2019ve done a disservice to innovation.\u201d \n                   Gene-edited CRISPR mushroom escapes US regulation 2016-Apr-14 \n                 \n                   CRISPR: gene editing is just the beginning 2016-Mar-07 \n                 \n                   CRISPR tweak may help gene-edited crops bypass biosafety regulation 2015-Oct-19 \n                 \n                   CRISPR, the disruptor 2015-Jun-03 \n                 \n                   Seeds of change 2015-Apr-08 \n                 \n                   US regulation misses some GM crops 2013-Aug-20 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21336", "url": "https://www.nature.com/articles/nature.2017.21336", "year": 2017, "authors": [{"name": "Alexandra Witze"}, {"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Climate sceptic William Happer and ardent critic of academia David Gelernter have met with the president. US President Donald Trump has met with two rumoured front-runners for the role of White House science adviser. Trump met with David Gelernter \u2014 a computer scientist at Yale University in New Haven, Connecticut, and a critic of liberal academia \u2014 on 16 January. And on 13 January, Trump met with William Happer, a physicist at Princeton University in New Jersey who rejects the notion that carbon dioxide emissions from human activities will cause dangerous levels of global warming. Several media reports have identified the two men as contenders for the science-adviser job. Gelernter told  Nature  in an e-mail that his meeting with Trump was \u201cwide-ranging & informal\u201d, adding that the president is \u201cnot just sharp; he's thoughtful\u201d. Happer says that he did not discuss the science-adviser post with the president, but did speak to him about science and technology. Still, the meetings have sparked speculation that Trump could soon pick a science adviser who would also lead the White House Office of Science and Technology Policy. Most of the previous presidential science advisers have been physicists \u2014 including Barack Obama\u2019s choice, John Holdren. \u201cThe science adviser must cover a huge range of issues, and in order to do that you have to have a very broad set of contacts across the disciplines,\u201d says Andrew Rosenberg, director of the Center for Science and Democracy at the Union of Concerned Scientists in Cambridge, Massachusetts. \u201cIf you have someone who is a bit of an iconoclast, it seems unlikely that they would have that ability.\u201d \n             Science under the lens \n           Gelernter is a pioneer in the field of parallel processing, in which multiple processors run simultaneously to speed up calculations. In the early 1980s, he helped to develop a parallel-programming system he named Linda, after a star of pornographic films. It became the basis for many subsequent programming systems. He told  Nature  that the Trump team has not offered him a job, but added that the next science adviser will face a daunting challenge: not only educating the public about science, but capturing the public imagination. \u201cThe gap between the public & the sciences has grown so gigantic, it's dangerous,\u201d he said. \u201cPeople rely every day, sometimes every hour, on computers & the net \u2014 often without knowing even vaguely how they work. The 'educated public' no longer has the vaguest idea what physics is doing. Which means, in turn, that science & tech will increasingly be the work of an elite priesthood that does exactly what it likes.\u201d He added: \u201cScience has never been less articulate, less interested in communicating its own excitement and wonder and fascination.\u201d In his own work, Gelernter has looked to the frontiers of technology. His 1991 book  Mirror Worlds  (Oxford University Press) imagines computing of the future, and a company he founded in New Haven as Mirror Worlds Technologies later sued Apple for reported patent infringement. In the mid-1990s, Gelernter helped to develop a concept known as lifestreams, meant to sort a person\u2019s information into a time-ordered stream something akin to a Twitter or Facebook feed today. Being a public face of the future of technology proved dangerous. In 1993, Gelernter was seriously hurt when a package sent by Unabomber Ted Kaczynski exploded in his office. Gelernter has criticized the field of artificial intelligence as underperforming, and modern academia as a broken system. His 2012 book  America-Lite: How Imperial Academia Dismantled Our Culture (And Ushered in the Obamacrats)  (Encounter Books) excoriates liberalism on campus. In it, he also writes that Obama was \u201coblivious to the gathering scientific doubts\u201d about climate change. In October, Gelernter appeared on the Fox News television channel in support of Trump. The computer scientist has also stirred controversy by proposing to limit the use of review panels when funding scientific research, says Michael Lubell, a physicist at the City College of New York. Gelernter has suggested replacing such panels with online tools where researchers could post ideas and managers could choose which ones to fund. \u201cI don\u2019t criticize him for not being well intentioned \u2014 he believes that this approach will lead to more robust research and development,\u201d Lubell says. \u201cIt\u2019s just that he is very much outside the mainstream.\u201d \n             Warm thoughts \n           Happer, an emeritus professor at Princeton, is no stranger to government: he directed energy research at the US Department of Energy from 1991 to 1993 and is a long-time member of JASON, a US defence advisory group. He is also a well-known critic of mainstream climate science and as such, a frequent target of environmental activists. In 2015, the environmental group Greenpeace UK announced that it had caught Happer in a sting operation. Greenpeace officials, posing as representatives of an unnamed Middle Eastern oil company, offered Happer money to write a report on the benefits of increasing atmospheric levels of CO 2  \u2014 while keeping the funding source a secret. Happer agreed, and maintains that he did nothing wrong. He says that he told the \u2018oil company\u2019 officials that any payments should be sent to the CO 2  Coalition, a US non-profit organization that promotes \u201cthe important contribution made by carbon dioxide to our lives and the economy\u201d. \u201cMy views are that the whole climate hysteria is greatly overblown,\u201d Happer told  Nature . \u201cI really do believe more CO 2  will be good for the world.\u201d That contradicts decades of climate-change research that has linked rising greenhouse-gas levels in the atmosphere to everything from shifting ecosystems to rising seas. Although his views on climate change are outside the mainstream, colleagues say that Happer is a solid physicist who has excelled at previous posts. \u201cPeople are complex. That\u2019s the only way to understand it,\u201d says Lyman Page, who chairs the physics department at Princeton. \u201cHe cares deeply about the country, and he is a very principled person.\u201d  \n                   NIH director Francis Collins staying on \u2014 for now 2017-Jan-19 \n                 \n                   Trump nominees talk science: As it happened 2017-Jan-18 \n                 \n                   Trump\u2019s vaccine-commission idea is biased and dangerous 2017-Jan-17 \n                 \n                   Trump nominee backs Paris climate agreement and questions Iran nuclear deal 2017-Jan-11 \n                 \n                   US Earth scientists plan for uncertain future under Trump 2016-Dec-20 \n                 \n                   Does it matter if Donald Trump has a science adviser? 2016-Dec-08 \n                 \n                   The scientists who support Donald Trump 2016-Oct-18 \n                 \n                   Obama\u2019s top scientist talks shrinking budgets, Donald Trump, and his biggest regret 2016-Jul-06 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21344", "url": "https://www.nature.com/articles/nature.2017.21344", "year": 2017, "authors": [{"name": "Jane J. Lee"}], "parsed_as_year": "2006_or_before", "body": "Comments about the new US president and the importance of science flowed under the #USofScience and #SciTrump hashtags. Nature  rounds up a sample of the reactions from researchers and science advocates on social media as Donald Trump became the 45th US president. Trump has questioned the validity of climate science and linked autism to childhood vaccinations, stirring up worries over how his administration will approach science and research in the United States. \n             Many highlighted the value of diversity in science. \n           \n             Others were concerned about the future of science education. \n           \n             Some worried about funding for certain scientific fields. \n           \n             And others celebrated science and all its accomplishments. \n           \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Trump\u2019s next move? Scientists struggle with foggy future 2017-Jan-20 \n                 \n                   Trump nominees talk science: As it happened 2017-Jan-18 \n                 \n                   The ultimate experiment: How Trump will handle science 2016-Nov-11 \n                 \n                   How scientists reacted to the US election results 2016-Nov-09 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21345", "url": "https://www.nature.com/articles/nature.2017.21345", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Researchers at Women's March in Washington DC defend their work as US president takes office. Washington DC The women in white lab coats didn\u2019t expect to be treated like celebrities. The group of scientists, dozens strong, came to Washington DC on 21 January to join the Women\u2019s March, a massive protest against  the brand-new US President, Donald Trump . But as they navigated the dense crowd near the National Air and Space Museum, the researchers were greeted by shouts of \u201cWe love science!\u201d Eager strangers asked the scientists to pose for photographs with the signs they carried, which bore slogans such as \u201cStand up 4 Science\u201d and \u201cScience does not discriminate.\u201d The march drew hundreds of thousands of people to the US capital. It was organized to protest against Trump\u2019s comments about women and reproductive health, but for many researchers at the event, the president\u2019s positions on scientific issues are equally worrisome. Trump, who took office on 20 January,  has questioned the science underlying climate change  and  suggested a link between childhood vaccinations and autism . \u201cHaving this man be elected, and the people he\u2019s placed so far [in government], is unbelievable,\u201d said Erin DiMaggio, a geoscientist at Pennsylvania State University in University Park. \u201cThey're not supporting evidence-based anything.\u201d Celia Chen, an ecotoxicologist at Dartmouth College in Hanover, New Hampshire, came to the march with her daughter Jane, a graduate student in epidemiology at the University of North Carolina in Chapel Hill. Neither had been politically active, but after Trump\u2019s election \u201cwe were feeling very depressed and said we had to come\u201d, Celia Chen said. The mother\u2013daughter pair marched with a group called 500 Women Scientists, which formed in November 2016  to organize an open letter defending science, diversity and equality for women  that now has more than 13,500 signatures. Members of the group, which is trying to build networks between women scientists in different countries, participated in Women\u2019s March events all over the world on 21 January.\u00a0 The group says that it had 150\u2013200 scientists at the Washington DC march; another organization, the Association for Women in Science, had at least 30 people marching. The day of activism reached as far south as McMurdo Station in Antarctica. About 95 of the 800 people stationed at the US research base attended the march to Hut Point, where British explorer Sir Robert Scott and his team camped in the early 1900s. The marchers did not have signs, because nearly all poster supplies at McMurdo are US government property. \n             Speaking up \n           The Washington DC march drew a number of US government employees. Several told  Nature  that they were worried for their jobs under the Trump administration, and requested anonymity to avoid violating their agencies\u2019 policies about talking to the press. Jennifer Kirk, a biostatistician who is about to start a job in the US Food and Drug Administration\u2019s vaccine division, attended the march to protest the unequal treatment of women, particularly women of colour. She is also concerned about  Trump\u2019s views on vaccination . \u201cVaccines are one of our greatest medical triumphs,\u201d Kirk said. Others at the march were concerned about how the president\u2019s immigration stance could affect international science collaborations and foreign researchers\u2019 ability to study and work in the United States. Trump has  pledged to build a wall along the US border with Mexico  and to institute \u201cextreme vetting\u201d of people who want to come to the United States. That has made some immigrant and minority scientists nervous , says Lindy Elkins-Tanton, a planetary scientist at Arizona State University in Tempe. \u201cTo make the best progress, we need to hear all voices,\u201d she said. \u201cYou have to feel safe to speak up.\u201d Whatever the future brings, the scientists\u2019 warm reception at the Washington DC march encouraged Kim Cobb, a climate scientist at the Georgia Institute of Technology in Atlanta. \u201cAs I heard the cheers and the echoes across the hundreds of thousands of people there today,\u201d she said, \u201cwhat I felt was the presence of an army of people who have my back\u201d. \n                   Trump\u2019s next move? Scientists struggle with foggy future 2017-Jan-20 \n                 \n                   Trump\u2019s vaccine-commission idea is biased and dangerous 2017-Jan-17 \n                 \n                   US Earth scientists plan for uncertain future under Trump 2016-Dec-20 \n                 \n                   Is Donald Trump pushing more scientists towards political activism? 2016-Dec-13 \n                 \n                   Immigrant and minority scientists shaken by Trump win 2016-Nov-22 \n                 \n                   The scientists who support Donald Trump 2016-Oct-18 \n                 \n                   Trump\u2019s border-wall pledge threatens delicate desert ecosystems 2016-Aug-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21579", "url": "https://www.nature.com/articles/nature.2017.21579", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Researchers are cutting short travel, ending collaborations and rethinking their US ties. Hani Goodarzi is sticking close to home these days. The cancer biologist at the University of California, San Francisco, cancelled a talk at the University of Calgary in late January and has put international travel on hold indefinitely. That\u2019s because Goodarzi, an Iranian citizen who holds a US green card, is afraid that if he leaves the United States he might not be let back in. He is not alone. Many foreign-born scientists say they are reconsidering plans to work or study in the United States, even though federal courts have indefinitely blocked US President Donald Trump\u2019s travel ban. The policy, which Trump signed on 27 January,  sought to deny entry to citizens of seven Muslim-majority nations  for 90 days \u2014 including those with valid US visas. Some researchers worry that the Trump administration will find a way to reinstate the policy, and perhaps even expand its reach. The government is reportedly preparing a reworked ban that would exclude current visa-holders, and Trump has also made brief mention of instituting a \u201cmerit-based\u201d immigration system. The  lingering uncertainty over US immigration rules  is prompting some scientists to curtail crucial research trips and may dissuade other researchers, students and entrepreneurs from considering the US as a destination. \u201cThere is  this spread of psychology of fear ,\u201d says Mustafa al\u2019Absi, a behavioural scientist at the University of Minnesota in Duluth. \u201cThis is where the burden is: what\u2019s going on in the air more than the facts.\u201d \n               Broken link \n             The Trump ban affected citizens of Iran, Iraq, Libya, Somalia, Sudan, Syria and Yemen \u2014 including those who had already secured permission to visit or live in the United States. In the first days after the policy took effect, numerous reports surfaced of students and faculty from US universities who were trapped overseas or detained in airports. Even though the ban has been blocked pending legal challenges, many institutions are still playing it safe. \u201cAll foreign nationals should carefully assess whether it is worth the risk to travel outside the country,\u201d officials from the international office of Harvard University in Cambridge, Massachusetts, said in a 28 January letter to students and faculty \u2014 advice that is still in place for people from the seven countries. Researchers from other universities told  Nature  that they had received similar guidance. Goodarzi says that he won\u2019t leave the country unless it is an emergency, even though the White House moved to exempt green-card holders from the ban before the courts intervened. \u201cI don\u2019t think I can risk it at this time,\u201d he says. That will prevent him from attending international meetings that could help to establish his scientific reputation as he builds a new lab. Similarly, al\u2019Absi and his colleagues at the University of Minnesota have ended a collaboration with researchers in Yemen to study the mental-health effects of khat, a recreational drug commonly taken in parts of Africa and the Middle East. The US group had scaled back the project a few years ago, in response to political upheaval in Yemen, but the prospect of working there at all seems impossible now given the direction that US immigration policy has taken, al\u2019Absi says. An Iranian\u2013American astronomer, who did not want to be named because he has international travel coming up, says that the vetting process to enter the US is already very strict. He went through multiple interviews and fingerprinting to get his green card and later, his US citizenship. \"It's not like giving out candies,\" he says. \n               Global experiment \n             It\u2019s not clear whether the current uncertainty over immigration will dissuade foreign students from enrolling in US universities. More than 216,000 international students used temporary visas to enrol in science or engineering graduate programmes at US institutions in 2015, according to the US National Science Foundation. About 35,000 were working as postdocs in those fields. \u201cThe worry we have is a snowball chilling effect,\u201d says Benjamin Corb, director of public affairs at the American Society for Biochemistry and Molecular Biology in Rockville, Maryland. Prospective students from places that were not included in Trump\u2019s ban may still wonder if their country could be affected in the future, and avoid the United States, he adds. New York University, which has more international students than any other US institution, has not seen a decrease in interest from foreigners, says Thomas Sirinides, associate director of international student services. But applications to graduate programmes are not due until August, and the situation could change by then, he says. \u201cIf [international students] don\u2019t feel confident they can finish a degree, they don\u2019t want to come here to start a degree,\u201d Sirinides adds. In Malaysia, a Muslim-majority country that was not included in the Trump ban, \u201cthere\u2019s confusion mixed with a little worry,\u201d says James Coffman, executive director of the Malaysian\u2013American Commission on Educational Exchange in Kuala Lumpur. The political climate in the United States is one reason that Coffman expects fewer Malaysians to apply to American universities this year. \n               Shifting centre \n             Half a world away, in California\u2019s Silicon Valley, investors and entrepreneurs are trying to understand how Trump\u2019s immigration policies will affect the thriving start-up scene \u2014 which draws heavily on foreign science and engineering talent. \u201cIf it\u2019s not friendly to stay here after you build your start-up, then why bother coming?\u201d says Arvind Gupta, founder of IndieBio, a biotech accelerator programme in San Francisco, California. Investors could also be put off if obtaining visas for start-up founders becomes harder or more expensive, he adds. Such fears have prompted Gupta to consider opening IndieBio\u2019s first office outside the United States. Some science groups are trying to come up with their own creative solutions to immigration problems. When the American Physical Society\u2019s international-affairs committee meets in May, its members will discuss how the society can blunt the effects of the travel ban. Potential actions could include redoubling efforts to help foreign researchers obtain US visas, or setting up virtual mentorships and collaborations for young scientists outside the country, says Maria Spiropulu, a physicist at California Institute of Technology in Pasadena and a member of the committee. Still, Spiropulu is optimistic about the future. \u201cWe will remember this as a turbulent time,\u201d she says. \u201cI cannot believe that this world will persist.\u201d  Alexandra Witze and Amy Maxmen contributed reporting. \n                     Hunted, haunted, stateless and scared: the stories of refugee scientists 2017-Mar-01 \n                   \n                     Academics must protest against Trump\u2019s travel ban \u2014 but they should do so productively 2017-Feb-07 \n                   \n                     Meet the scientists affected by Trump\u2019s immigration ban 2017-Jan-29 \n                   \n                     Trump agenda threatens US legacy of science diplomacy 2017-Jan-27 \n                   \n                     Immigrant and minority scientists shaken by Trump win 2016-Nov-22 \n                   \n                     Trump\u2019s immigration stance stokes fears for science 2016-Apr-05 \n                   \n                     Nature  special: Tracking the Trump White House \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21511", "url": "https://www.nature.com/articles/nature.2017.21511", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Policy experts want scientists at the table when government decides on environmental protection and membership of international collaborations. Two government departments charged with managing the United Kingdom\u2019s departure from the European Union have not yet appointed chief scientific advisers (CSAs) \u2014 and might not do so. That is starting to concern science-policy experts, who worry that scientists won\u2019t be at the table when government makes key decisions on issues such as environmental protection and membership of international collaborations. The United Kingdom has for years embraced the CSA model, in which highly qualified researchers are appointed to senior advisory roles and then embedded in government departments. But neither the  Department for Exiting the European Union (DExEU)  nor the Department for International Trade (DIT), both of which were created in the wake of the United Kingdom\u2019s decision to leave the EU, has yet appointed, or committed to appointing, a CSA.\u00a0 Last October, government ministers told a hearing of the House of Commons science select committee that DExEU was recruiting for a CSA, but this statement was later withdrawn. Then, in a  letter sent to the committee on 3 February , DExEU minister Robin Walker said that the department is still considering whether it needs a CSA. The letter came in response to questions from the select committee, whose chairman, Stephen Metcalfe, is concerned about a lack of scientific advice in DExEU. \u201cI can\u2019t really understand why there is such resistance to appointing a CSA,\u201d says Metcalfe. Metcalfe has also raised concerns about the broader CSA system. On 9 February, his committee sent a letter to the  government\u2019s CSA Mark Walport , who leads the network of departmental CSAs and is supported by the Government Office for Science. The letter notes the absence of CSAs in at least six departments, including DExEU and the DIT; apparent impending absence in a seventh and confusion over the role in an eighth (see \u2018Scientfic advice\u2019). It also expresses concern about the time taken to replace some CSAs. \n               Scientific advice \n               \n               Waning emphasis? \n             The number of departments without a CSA does seem to have increased in recent years, although it has fluctuated. According to government websites, it was just three in 2011, dipped to two in 2012, but also reached the current high of six in 2015 before falling again last year. Science-policy experts are paying close attention. \u201cWhen you\u2019ve got a lot of jobs lying vacant, when you\u2019ve got really quite a lot of departments saying they don\u2019t have a CSA and don\u2019t have plans to have one, that really does start to raise questions about whether or not the government has reduced the emphasis it places on scientific advice,\u201d says Graeme Reid, a science-policy researcher at University College London. \u201cThere does seem to have been an erosion of the role of the departmental CSAs,\u201d adds Naomi Weir, deputy director of the Campaign for Science and Engineering in London. The letter from Metcalfe\u2019s committee calls on the government CSA \u2014 either Walport, who  recently accepted a major new role overseeing UK funding , or his replacement \u2014 to bring the system back to full strength. The Office for Science says that it will reply to Metcalfe\u2019s criticisms soon, and that the UK system for scientific advice is \u201cinternationally recognized\u201d and \u201cnot just strong in its breadth across government but also in its depth\u201d.\u00a0 But Reid and Mike Galsworthy, programme director of the group Scientists for EU, which was set up to campaign against Brexit, say that the lack of a CSA at the DExEU might already have compromised how the government handled one scientific issue. \n               Fusion fears \n             At the end of January, the government sent shockwaves through the physics community when it announced that  the United Kingdom would leave the European Atomic Energy Community (Euratom) at the same time as its departure from the EU . This could jeopardize UK participation in the world\u2019s largest fusion experiment,\u00a0 the International Thermonuclear Experimental Reactor (ITER ) in southern France, and curtail operations at the Joint European Torus (JET), a nuclear-fusion facility in Culham, UK, that acts as a test bed for ITER. But the announcement was made in brief notes published alongside a parliamentary bill on Brexit. \u201cThe Euratom fiasco is a clear case of where some science person in the core Brexit team could have averted the sudden crisis of confidence from the science community,\u201d says Galsworthy. \u201cThis is the problem with not having a CSA on the inside who instantly gets how every action will ramify through the science community.\u201d Reid is particularly concerned about the lack so far of a CSA at the DIT, which will be responsible for negotiating international trade deals that the United Kingdom will have to forge with other nations after it leaves the EU. Although the public might associate these deals with tariffs, the deals also can determine the patents given to different drug types, levels of environmental protection or how genetically modified organisms are regulated. \u201cAll the substance of a trade agreement is underpinned by scientific detail,\u201d says Reid. \u201cThat\u2019s why it\u2019s so important the Department for International Trade has a chief scientific adviser.\u201d DExEU declined to elaborate on whether and when it plans to appoint a CSA, beyond the 3 February letter. And the DIT has said only that it is working with Walport and his office to \u201cprovide advice on the specification for any such role\u201d. \n                     The most powerful man in UK science on his new role 2017-Feb-08 \n                   \n                     The head of Britain\u2019s powerful new funding body deserves a chance 2017-Feb-08 \n                   \n                     Brexit vote drives UK academics to think about leaving 2017-Jan-09 \n                   \n                     Scientists should not resign themselves to Brexit 2017-Jan-04 \n                   \n                     Brexit and science \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21599", "url": "https://www.nature.com/articles/nature.2017.21599", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Physicists demonstrate the first single-atom magnetic storage. Chop a magnet in two, and it becomes two smaller magnets. Slice again to make four.\u00a0But the smaller magnets get, the more unstable they become; their magnetic fields tend to flip polarity from one moment to the next. Now, however, physicists have managed to create a stable magnet from a single atom. The team, who published their work in\u00a0 Nature \u00a0on 8 March 1 , used their single-atom magnets to make an atomic hard drive. The rewritable device, made from 2 such magnets, is able to store just 2 bits of data, but scaled-up systems could increase hard-drive storage density\u00a0by 1,000 times, says Fabian Natterer, a physicist at the Swiss Federal Institute of Technology (EPFL) in Lausanne, and author of the paper. \u201cIt\u2019s a landmark achievement,\u201d says Sander Otte, a physicist at Delft University of Technology in the Netherlands. \u201cFinally, magnetic stability has been demonstrated undeniably in a single atom.\u201d Inside a regular hard drive is a disk split up into magnetized areas \u2014 each like a tiny bar magnet \u2014\u00a0the fields of which can point either up or down. Each direction represents a 1 or 0 \u2014 a unit of data known as a bit. The smaller the magnetized areas, the more densely data can be stored. But the magnetized regions must be stable, so that \u20181\u2019s and \u20180\u2019s inside the hard disk do not unintentionally switch Current commercial bits comprise around 1 million atoms. But in experiments physicists have radically shrunk the number of atoms needed to store 1 bit\u00a0\u2014 moving from 12 atoms in 2012 2 \u00a0to now just one. Natterer and his team used atoms of holmium, a rare-earth metal, sitting on a sheet of magnesium oxide, at a temperature below 5 kelvin. Holmium is particularly suitable for single-atom storage because it has many unpaired electrons that create a strong magnetic field, and they sit in an orbit close to the atom's centre where they are shielded from the environment. This gives holmium both a large and stable field, says Natterer. But the shielding has a drawback: it makes the holmium notoriously difficult to interact with. And until now, many physicists doubted whether it was possible to reliably determine\u00a0the atom\u2019s state. \n             Bits of data \n           To write the data onto a single holmium atom, the team used a pulse of electric current from the magnetized tip of scanning tunnelling microscope, which could flip the orientation of the atom's field between a 0 or 1. In tests the magnets proved stable, each retaining their data for several hours, with the team never seeing one flip unintentionally. They used the same microscope to read out the bit \u2014 with different flows of current revealing the atom\u2019s magnetic state. To further prove that the tip could reliably read the bit, the team \u2014 which included researchers from the technology company IBM\u00a0\u2014 devised a second, indirect, read-out method. They used a neighbouring iron atom as a magnetic sensor, tuning it so that its\u00a0electronic properties depended on the orientation of the two holmium atomic magnets in the 2-bit system. The method also allows the team to read out multiple bits at the same time, says Otte, making it more practical and less invasive than the microscope technique.\u00a0 Using individual atoms as magnetic bits would radically increase the density of data storage, and Natterer says that his EPFL colleagues are working on ways to make large arrays of single-atom magnets. But the 2-bit system is still far from practical applications and well behind\u00a0 another kind of single-atom storage , which encodes data in atoms\u2019 positions, rather than in their magnetization, and has already built a 1-kilobyte (8,192-bit) rewritable data storage device. One advantage of the magnetic system, however, is that it could be compatible with\u00a0 spintronics , says Otte. This emerging technology uses magnetic states not just to store data, but to move information around a computer in place of electric current, and would make for much more energy-efficient systems. In the near term, physicists are more excited about studying the single-atom magnets. Natterer, for example, plans to observe three mini-magnets that are oriented so their fields are in competition with each other \u2014 so they continually flip. \u201cYou can now play around with these single-atom magnets, using them like Legos, to build up magnetic structures from scratch,\u201d he says. Read the related News & Views article:  'Single-atom data storage' \n                   Nanoscience: Single-atom data storage 2017-Mar-08 \n                 \n                   How DNA could store all the world\u2019s data 2016-Aug-31 \n                 \n                   Atom wranglers create rewritable memory 2016-Jul-18 \n                 \n                   The chips are down for Moore\u2019s law 2016-Feb-09 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21585", "url": "https://www.nature.com/articles/nature.2017.21585", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Company plans a bigger, better system aimed at creating a market for the still-immature technology. Hoping that if you build it, they will come, IBM plans to roll out the world\u2019s first commercial \u2018universal\u2019 quantum-computing service some time this year, the company announced on 6 March. Named IBM Q, the system will be accessible over the Internet for a fee. It will not outperform conventional computers, at least not yet. But the company says that the system will be crucial in developing a market for future  quantum machines that can handle complex calculations  currently out of reach of classical computers. The cloud service is the latest salvo in the  heated battle to build a useful quantum computer . The project builds on know-how developed around IBM\u2019s existing cloud computing service: Quantum Experience, which anyone can access for free. That system went online in May 2016 and recently received an upgraded user interface. \u201cHaving it up for ten months has taught us a lot,\u201d says physicist Jerry Chow, who leads the quantum-computing laboratory at IBM\u2019s research centre in Yorktown Heights, New York. It has provided a way for researchers around the world to practise building quantum algorithms without access to their own quantum computer. IBM\u2019s overall strategy is to build \u201ca community and an ecosystem\u201d around its technology, Chow says. The company is being tight-lipped about when exactly IBM Q will come online, saying only that it will happen this year. It is also not disclosing how powerful the system will be, or how much it will cost to access. The company says that it has already lined up its first clients, although it would not identify them, saying only that several commercial partners will test and develop their own applications for the machine. \n               Quantum competition \n             Quantum computers harness the counter-intuitive properties of subatomic physics, in which bits of information \u2014 called quantum bits, or qubits \u2014 can assume multiple states simultaneously, rather than simply representing a 0 or 1, as bits do in classical computing. Starting in the 1990s, theoretical physicists, including some at IBM, have developed qubit-based algorithms that in theory could perform certain tasks exponentially faster than classical computers can. But in practice, getting enough qubits to work together to run any such algorithm \u2014 in what is known as a  universal quantum computer  \u2014 has proved extremely challenging. Two technologies have emerged as front-runners for handling qubits. One traps individual ions in a vacuum using electric and magnetic fields; the other incorporates qubits into microscopic superconducting circuits kept at a few degrees above absolute zero. IBM has bet heavily on the latter approach. In recent years,  Google has also entered the fray , establishing a superconducting-qubit lab in Santa Barbara, California. Google, IBM and a handful of other companies and academic labs have announced aggressive road maps for building machines that can outperform classical computers. But these machines would need to run on roughly 50 qubits each. The current record is about 20\u00a0qubits, barely enough for simple computations. \n               Practical matters \n             So when IBM rolled out Quantum Experience \u2014 which runs on five superconducting qubits \u2014 some did not see the point. \u201cA lot of folks looked at it as a publicity stunt,\u201d says physicist Christopher Monroe, who runs an ion-trap laboratory at the University of Maryland in College Park. \u201cBut I think it\u2019s a really big deal.\u201d Even though it is not a state-of-the-art machine, IBM had to overcome a number of challenges to get Quantum Experience online and make it usable for researchers who are not necessarily physicists and have never worked on a quantum computer before. That included creating a system that functions without the constant attention of the physicists who built it. \u201cPutting the machine on the cloud is an obvious thing to do,\u201d Monroe says. \u201cBut it takes a lot of work in getting a system to that level.\u201d Having access to a system such as Quantum Experience or IBM Q also means that researchers around the world could start working on the unique challenges of quantum programming. This is very different from conventional coding, and requires programmers to understand and adapt to the limitations of physical qubits. In principle, a five-qubit machine is easy to simulate using a classical computer \u2014 even a laptop, Monroe says. But real qubits are not so simple. \u201cThe real challenge is whether you can make your algorithm work on real hardware that has imperfections,\u201d says Isaac Chuang, a physicist at the Massachusetts Institute of Technology in Cambridge. Chow says that IBM Q will have more qubits than Quantum Experience, but the company has not yet settled on a specific number. \n               Era of the quantum cloud \n             Quantum Experience has so far attracted about 40,000 users from more than 100 countries. Chuang, for example, used it in an online, graduate-level class on quantum computing that he taught late last year, so that students could practise programming an actual quantum computer. The system\u2019s users have performed 275,000 experiments and produced about 15 research papers. Among them is one in which a team led by Monroe and his collaborators compared the performance of IBM\u2019s superconducting machine with that of a five-qubit ion-trap machine at Monroe\u2019s lab 1 . The company's quantum cloud service was faster, but Monroe's machine was more precise. Monroe has co-founded a start-up called IonQ that expects to roll out a cloud-based, trapped-ion quantum service, but he won\u2019t speculate on when. Google is planning to do the same with its own superconducting-qubit machines, but only after it has made a working 50-qubit computer, says John Martinis, who heads the company\u2019s quantum-computing laboratory in Santa Barbara. Meanwhile, D-Wave, a company based in Burnaby, Canada, has had a quantum-computing service on the cloud since 2010. \u201cThe core of our strategy is really gearing towards the cloud access model,\u201d says Jeremy Hilton, senior vice president of systems. But D-Wave's machines are not \u2018universal\u2019 computers, and can only run a limited range of quantum algorithms. Nevertheless,  several research groups have used it for their projects . \n                     Commercialize quantum technologies in five years 2017-Mar-03 \n                   \n                     D-Wave upgrade: How scientists are using the world\u2019s most controversial quantum computer 2017-Jan-24 \n                   \n                     Quantum computers ready to leap out of the lab in 2017 2017-Jan-03 \n                   \n                     IBM Quantum Experience \n                   \n                     Research papers based on Quantum Experience \n                   Reprints and Permissions"},
{"file_id": "541010a", "url": "https://www.nature.com/articles/541010a", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Tool to divide water masses into precise categories can help in conservation planning. Oceanographers are carving up the world\u2019s seas like the last of the holiday turkey. A new 3D map sorts global water masses \u2014 from deep, frigid circumpolar waters to the oxygen-starved Black Sea \u2014 into 37\u00a0categories. The map groups together marine regions of similar temperature, salinity, oxygen and nutrient levels. It has been available for only a few months, and researchers are still working through how they might use it. But its international team of developers hopes that the map will help conservationists, government officials and others to better understand the biogeography of the oceans and make decisions about which areas to preserve. It could also serve as a data-rich baseline for analysing future ocean changes. Many existing systems also attempt to classify variations in the ocean, such as lists of large marine ecosystems or the Longhurst biogeographical provinces that are defined by the rate at which ocean life consumes carbon. But these are often limited to surface or coastal ecosystems. The latest effort, known as the ecological marine units (EMUs), is the most detailed attempt yet to cover the global ocean in three dimensions. \u201cWhat\u2019s often missing is all that\u2019s between the surface of the ocean and the ocean bottom,\u201d says Dawn Wright, chief scientist of Esri, a geographic information-systems company in Redlands, California, that helped to develop the 3D map. \u201cThat\u2019s what our project will hopefully bring to the table.\u201d Esri launched a web portal for the EMU data in September, and has been presenting the concept at conferences since then. Wright described it on 16\u00a0December in San Francisco, California, at a meeting of the American Geophysical Union. EMUs can help to reveal why marine animals live where they do. In the eastern tropical Pacific Ocean the mapping shows a complex interplay between oxygen-rich and oxygen-poor waters. The boundary of the low-oxygen zone shifts towards the surface in some spots and dips deeper in others. That variation affects the locations of economically important tuna fisheries, says Patrick Halpin, a marine ecologist at Duke University in Durham, North Carolina. \u201cIt\u2019s an interesting thing to look at in three dimensions, fairly unique and gratifying.\u201d Such data could guide the United Nations\u2019 effort to designate a series of ecologically or biologically significant marine areas to focus future conservation efforts, Halpin notes. Looking at the distribution of EMUs could help officials to pinpoint the boundaries of those areas, or to make sure they are designating enough waters to capture all the biogeographic diversity. And the South African National Biodiversity Institute is interested in using EMUs to update data on open-ocean and deep-sea habitats for the country\u2019s next national biodiversity assessment, due in 2019, says Heather Terrapon, a spatial analysis coordinator at the institute in Cape Town. Nations that do not have the money to gather their own data sets could use the free EMU data and visualizations to manage their marine resources, says Peter Harris, a marine geologist at the environmental information-management centre GRID-Arendal in Arendal, Norway. The creation of the EMUs is the second step in a project that started with similar mapping on land. The intergovernmental Group on Earth Observations asked Roger Sayre, an ecologist at the US Geological Survey in Reston, Virginia, to lead a team to categorize terrestrial eco\u00adsystems. The researchers, including some at Esri, combined information on geology and vegetation to generate nearly 4,000 \u2018ecological land units\u2019. One example might be warm, wet plains, on metamorphic rock, with mostly deciduous forest. Next, the team moved their focus from land to the oceans. \u201cIt\u2019s like total world domination in ecosystem mapping,\u201d says Sayre, who heads the EMU project with Wright. They began with 52\u00a0million data points in the World Ocean Atlas maintained by the US National Oceanic and Atmospheric Administration. These include information on chemical and physical parameters gathered every 27\u00a0kilometres to create a 3D grid. The team added other data such as the shape of the sea floor and used statistical techniques to group the results into categories. The resulting EMUs include the deep, very cold, low-oxygen waters that encompass roughly one-quarter of the world\u2019s oceans. Others are much smaller, such as the upper waters of the Red Sea, or the dilute estuaries of several Northern Hemisphere rivers. For now, the EMU maps rely on data averaged over five decades. Looking at conditions over shorter periods of time, such as seasons, would provide more helpful detail, says Frank Muller-Karger, a biological oceano\u00adgrapher at the University of South Florida in St Petersburg who has been comparing EMUs with weekly maps of coastal changes made using satellite imagery. And to monitor change over decades, the EMU team would need to recalculate its maps every five years or more. The EMU developers say that future iterations of the system could tackle such issues. For now, they are hoping to expand on the land and marine units by creating new categories for coastal and freshwater ecosystems. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     World\u2019s largest marine reserve hailed as diplomatic breakthrough 2016-Oct-28 \n                   \n                     Policy: Marine biodiversity needs more than protection 2016-Jul-13 \n                   \n                     Conservation: The seas cannot be saved on a budget of breadcrumbs 2016-Jun-01 \n                   \n                     Massive network of robotic ocean probes gets smart upgrade 2016-Mar-22 \n                   \n                     Gravity map uncovers sea-floor surprises 2014-Oct-02 \n                   \n                     Ocean conservation: Uncertain sanctuary 2011-Dec-07 \n                   \n                     Esri site on ecological marine units \n                   \n                     Ecological marine unit explorer \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21256", "url": "https://www.nature.com/articles/nature.2017.21256", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "The agency's next leader will have an opportunity to reshape its approach to regulation. US president-elect Donald Trump wants to speed up drug approvals and broadly reduce government regulations. What that means for the US Food and Drug Administration (FDA) is not yet clear \u2014 but if Trump\u2019s choices for other posts are any guide, he will look for an FDA commissioner to shake up the status quo. The next FDA chief could shift the agency\u2019s stance on everything from medical testing to clinics that claim to provide stem-cell therapies. But it's not clear how far the Trump administration will deviate from past practices and from guidelines proposed \u2014 but not finalized \u2014 during President Barack Obama's administration. Until Trump announces his pick and that person is confirmed by the US Senate, the drug industry will struggle to map out its future, says David Fox, a partner at the law firm Hogan Lovells in Washington DC. \u201cPeople in this industry need to plan substantially in advance, and as regulations and structure are removed, it starts to make planning much, much more difficult,\u201d he says. Here,  Nature  looks at what the next administration could push forward \u2014 or sweep away. \n               1. Swifter drug approvals \n             The FDA has struggled to balance pressure for speedy drug approvals with its desire for convincing clinical data. That situation came to a head in September 2016 when the agency approved the drug eteplirsen to treat Duchenne muscular dystrophy. Patient advocates cheered the new drug, made by Sarepta Therapeutics in Cambridge, Massachusetts \u2014 one of only a few treatments for the devastating genetic disease. But some FDA reviewers were dismayed that the agency acted on the basis of a clinical trial that included only 12 children, and which demonstrated small increases in levels of a key protein rather than changes in symptoms or disease progression. The decision has left the industry and patient advocates guessing at what standards the FDA will apply to future decisions on drugs to treat rare diseases. \u201cThe new commissioner is going to face the aftermath of the Sarepta approval,\u201d says Fox. \u201cIt\u2019s a very big issue: his or her role is to help the agency manage the patient voice and maintain a certain standard for drugs marketed in the United States.\u201d By law, the FDA must require \u201csubstantial evidence\u201d of efficacy and safety before it approves a drug, but that term is subject to interpretation, says Fox . And the agency could soon come under tremendous pressure to lower that bar. One person thought to be under consideration to head the agency is investor Jim O\u2019Neill of Mithril Capital Management in San Francisco, California. O\u2019Neill has said that the FDA should approve drugs based on safety alone, allowing the patient to take the gamble of whether the drug will work. That is such a radical divergence from past practices that it is hard to believe someone with O\u2019Neill\u2019s views would be confirmed by the US Senate, says Douglas Sipp, who studies stem-cell policy at the RIKEN Center for Developmental Biology in Kobe, Japan. \u201cBut nobody knows what Trump is going to do from hour to hour,\u201d he adds. \u201cIt\u2019s difficult to write it off completely.\u201d \n               2. Stem-cell 'clinics' \n             In 2014 and 2015, the FDA issued a series of proposals to regulate a wide swathe of clinics that claim to perform unproven stem-cell therapies. There are about 570 of these in the United States, according to one study 1 , and their numbers are growing. The proposals have been met with condemnation from the stem-cell clinics and from patient advocates who want access to the therapies without having to wait for them to be proven effective. But many scientists, particularly those who work on stem cells, have called on the FDA to  crack down on untested cell therapies . They cite concerns for patient safety and fears that such treatments will damage the reputation of all stem-cell therapies. The FDA\u2019s proposals have not yet been finalized. \n               3. Food from gene-edited animals \n             Gene editing \u2014 a technique that  allows researchers to make targeted changes to genomes  \u2014 has swept through academic and industry labs, and poses challenges for regulators who must adapt old regulations to new technology. The US Department of Agriculture has already determined that several gene-edited crops  do not fall under its regulatory purview . All eyes are on the FDA, which regulates genetically engineered animals, to see how it will handle  the menagerie of gene-edited livestock to come . In July 2015, Obama\u2019s Office of Science and Technology Policy ordered the agencies that regulate genetically modified foods  to determine which of their regulations need updating , but it remains unclear whether and how the FDA will regulate gene-edited animals. \n               4. Medical tests developed in laboratories \n             On 31 July 2014, the FDA notified Congress of its plans to expand regulation of some medical diagnostics. The proposal would encompass tests that are developed in laboratories rather than sold as a kit, in an effort to cope with  the growing complexity and importance of such tests  for patient diagnosis and treatment, particularly in cancer. Industry and academic labs say the plan would stifle innovation in a field that is  crucial for the advancement of precision medicine . Others, including Francis Collins, head of the US National Institutes of Health, have argued that the lack of regulation has created  a wild west of unreliable tests  that could harm patients. The FDA has not finalized its plans, making it easier for the next commissioner to influence itheir ultimate form. Scott Gottlieb, a physician, investor and fellow at the American Enterprise Institute think tank in Washington DC, is rumoured to be under consideration for the job, and has said that the current proposals could stifle medical innovation. But Gottlieb has also acknowledged that some tests \u2014 particularly highly complex ones involving multiple variables \u2014 may require some oversight. \n               5. Off-label drug promotion \n             The agency released draft guidance in 2014 to clarify how far companies can go in advertising approved drugs for unapproved 'off-label' uses \u2014 another issue that  pits industry interests against consumer activists . Given Trump\u2019s aversion to regulations, some fear for the fate of these proposals, which have not been finalized. \u201cIf companies are allowed to promote drugs and medical devices for uses not approved by the agency, that would really undermine important public-health protections,\u201d says Michael Carome, director of health research at the consumer advocacy group Public Citizen in Washington DC. \u201cThat\u2019s a very important issue that, depending on who leads the agency, could dramatically affect drug and medical-device safety.\u201d \n                     Gene-editing surges as US rethinks regulations 2016-Apr-12 \n                   \n                     Welcome to the CRISPR zoo 2016-Mar-09 \n                   \n                     US regulators try to tame 'wild west' of DNA testing 2015-Feb-20 \n                   \n                     Home-brew tests need regulation 2014-Aug-05 \n                   \n                     US regulation misses some GM crops 2013-Aug-20 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21261", "url": "https://www.nature.com/articles/nature.2017.21261", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Analysis reveals the gas clouds that the far-flung spacecraft will encounter. Grapevine, Texas As they sail into interstellar space, NASA\u2019s twin Voyager probes are entering a mysteriously complex realm. The spacecraft aren\u2019t in completely uncharted territory though. Information from the Hubble Space Telescope is illuminating what may lay in front of the probes, revealing rich clouds of hydrogen along their path. The work is a rare marriage of two of the most famous space missions \u2014 and an unprecedented glimpse at the realm between the stars. \u201cIf the Voyager spacecraft are the Google Street View car going around your neighbourhood taking pictures on the street, then Hubble is providing the overview, the road map for the Voyagers on their trip through interstellar space,\u201d says Julia Zachary, an undergraduate student at Wesleyan University in Middletown, Connecticut. She and her colleagues reported their findings on 6 January at a meeting of the American Astronomical Society in Grapevine, Texas. \n             Uncharted territory \n           Both Voyagers  launched in 1977 , on missions to visit Saturn, Jupiter, Uranus and Neptune.  Voyager 1 entered interstellar space in 2012  and is more than 20 billion kilometres from Earth. Voyager 2 is still just barely within the Solar System and is around 17 billion kilometres away. Each is traveling on a different angle away from the plane of the Solar System, and Hubble peered into space along their lines of sight. The telescope gathered information on the light coming from distant stars, far beyond where the spacecraft currently lie. By analysing chemical signatures in that light, picked up from the intervening material, Zachary\u2019s team could tease out details about the nature of the interstellar environment between Hubble and the stars. The clouds, made mostly of hydrogen, also contain small amounts of heavier elements such as carbon. Both Voyagers currently lie within the local interstellar medium, a bubble of material that encompasses the Solar System. The Hubble data suggest that Voyager 2 will exit it in a couple of thousand years and then enter another cloud beyond that one. It\u2019s unclear when Voyager 1 will break through the bubble. \n             Road map for the future \n           Astronomers have used instruments such as Hubble to obtain indirect measurements of the material in interstellar space. But the Voyager probes are giving them a direct taste of this mysterious environment, sending back data on the electron density of their surroundings. \u201cAs an astronomer, I\u2019m not used to having measurements from the place I\u2019m observing,\u201d says Seth Redfield, an astronomer at Wesleyan and a member of the team. Voyager\u2019s direct, and Hubble\u2019s indirect, measurements of interstellar space will be important for planning true interstellar missions such as  the future Breakthrough Starshot , Zachary says. Brandon Lawton, an astronomer at the Space Telescope Science Institute in Baltimore, Maryland, who was not involved in the work, notes that Hubble helped with the study of the region around Pluto \u2014  searching for potentially hazardous moons  \u2014 before NASA\u2019s New Horizons spacecraft flew past in July 2015. Similarly, the Voyager work \u201chelps map the lay of the land\u201d, he says, as the probes soar outward into the unknown. \n                   Voyager 1 has reached interstellar space 2013-Sep-12 \n                 \n                   Voyager: Outward bound 2013-May-22 \n                 \n                   Voyager\u2019s long goodbye 2012-Sep-05 \n                 \n                   Voyager mission page \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21234", "url": "https://www.nature.com/articles/nature.2016.21234", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Agency plans to launch a mission to visit the Trojan asteroids in 2021, and one to the metallic asteroid Psyche in 2023. NASA will send two spacecraft to explore asteroids in the hopes of revealing new information about the Solar System\u2019s origins. Psyche will journey to what could be the metallic heart of a failed planet and Lucy will investigate the Trojan asteroids near Jupiter. The missions, announced on 4 January, are part of NASA\u2019s Discovery Program for planetary exploration. They were  shortlisted by NASA in September 2015  and have survived a final cut that eliminated two proposed missions to Venus \u2014 which has not seen a US planetary mission since Magellan launched in 1989. \u201c What can I say? It\u2019s deeply disappointing,\u201d says Robert Grimm, a planetary scientist at the Southwest Research Institute in Boulder, Colorado, and chairman of a group that analyses Venus issues for NASA. \u201cWe want to make sure NASA continues to support high-level Venus activities.\u201d Scheduled to launch in October 2021 and arrive at its first major target in 2027, Lucy will explore six of Jupiter\u2019s Trojan asteroids, which are trapped in orbits ahead of and behind the giant planet. Named after the famous hominid fossil, the spacecraft will investigate the origins of the giant planets by looking at the fragments left over from their formation. \u201cThese small bodies really are the fossils of planet formation,\u201d said Lucy principal investigator Hal Levison of the Southwest Research Institute, at a media teleconference. Psyche is slated to launch in October 2023 and should reach its 210-kilometre-wide target in 2030. It will explore what could be the exposed core of an early, now-vanished planet. \u201cWe have visited icy world and rocky worlds and worlds made of gas, but we have never visited a metal world,\u201d said Lindy Elkins-Tanton, head of the Psyche project at Arizona State University in Tempe, at the press briefing. \u201c Lucy and Psyche will take us to unique worlds that humankind has never explored before,\u201d says Thomas Zurbuchen, NASA\u2019s associate administrator for space science. The agency will also provide another year of funding to develop a space telescope called NEOCam, which plans to hunt for near-Earth asteroids. \n             Open for exploration \n           The Discovery Program is open to projects that study any target in the Solar System other than Earth or the Sun \u2014 at a cost of US$450 million or less. Earlier Discovery missions included the planet-hunting Kepler telescope and the Genesis mission that returned samples of the solar wind. Discovery\u2019s most recent addition was the Mars geophysical lander known as InSight. It was meant to launch in 2016, but a vacuum leak in its main instrument, a French-built seismometer, delayed it. NASA has reworked the seismometer and now plans to launch InSight in May 2018. But the delay added $154 million to the mission\u2019s original price tag,  raising questions about how NASA would absorb the costs  while still developing new spacecraft. Jim Green, head of NASA's planetary sciences division in Washington DC, says that the agency staggered Lucy and Psyche's launch dates so that both remain affordable along with InSight. Not all is lost for researchers wanting to explore Earth\u2019s twin. Venus is one of six proposed targets for New Frontiers, a class of NASA planetary missions that can cost up to $850 million. The other five, prescribed by a survey of US planetary science released in 2013, are a probe to Saturn, one to its ocean moons Titan and/or Enceladus, another visit to the Trojan asteroids and sample returns from a comet\u2019s surface and the moon\u2019s South Pole-Aitken basin. Ideas for New Frontiers missions are due on 28 April. \n                   NASA Mars woes could delay other planetary missions 2016-Mar-11 \n                 \n                   NASA narrows its list of planetary targets 2015-Sep-30 \n                 \n                   Five Solar System sights NASA should visit 2015-Mar-16 \n                 Reprints and Permissions"},
{"file_id": "541009a", "url": "https://www.nature.com/articles/541009a", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Google, Microsoft and a host of labs and start-ups are racing to turn scientific curiosities into working machines. Quantum computing has long seemed like one of those technologies that are 20\u00a0years away, and always will be. But 2017 could be the year that the field sheds its research-only image. Computing giants Google and Microsoft recently hired a host of leading lights, and have set challenging goals for this year. Their ambition reflects a broader transition taking place at start-ups and academic research labs alike: to move from pure science towards engineering. \u201cPeople are really building things,\u201d says Christopher Monroe, a physicist at the University of Maryland in College Park who co-founded the start-up IonQ in 2015. \u201cI\u2019ve never seen anything like that. It\u2019s no longer just research.\u201d Google started working on a form of  quantum computing that harnesses superconductivity  in 2014. It hopes this year, or shortly after, to perform a computation that is beyond even the most powerful \u2018classical\u2019 supercomputers\u00a0\u2014\u00a0an elusive milestone known as quantum supremacy. Its rival, Microsoft, is betting on an intriguing but unproven concept,  topological quantum computing , and hopes to perform a first demonstration of the technology. The quantum-computing start-up scene is also heating up. Monroe plans to begin hiring in earnest this year. Physicist Robert Schoelkopf at Yale University in New Haven, Connecticut, who co-founded the start-up Quantum Circuits, and former IBM applied physicist Chad Rigetti, who set up Rigetti in Berkeley, California, say they expect to reach crucial technical milestones soon. Academic labs are at a similar point. \u201cWe have demonstrated all the components and all the functions we need,\u201d says Schoelkopf, who continues to run a group racing to build a quantum computer at Yale. Although plenty of physics experiments still need to be done to get components to work together, the main challenges are now in engineering, he and other researchers say. The quantum computer with the most qubits\u00a0so far \u2014\u00a020\u00a0\u2014\u00a0is being tested in an academic lab led by Rainer Blatt at the University of Innsbruck in Austria. Whereas classical computers encode information as bits that can be in one of two states, 0 or 1,  the \u2018qubits\u2019 that comprise quantum computers  can be in \u2018superpositions\u2019 of both at once. This, together with qubits\u2019 ability to share a quantum state called entanglement, should enable the computers to essentially perform many calculations at once. And the number of such calculations should, in principle, double for each additional qubit, leading to an exponential speed-up. This rapidity should allow quantum computers to perform certain tasks, such as searching large databases or factoring large numbers, which would be unfeasible for slower, classical computers. The machines could also be transformational as a research tool, performing quantum simulations that would enable chemists to understand reactions in unprecedented detail, or physicists to design materials that superconduct at room temperature. There are many competing proposals for how to build qubits. But there are two front runners, confirmed in their ability to store information for increasingly long times\u00a0\u2014\u00a0despite the vulnerability of quantum states to external disturbance\u00a0\u2014\u00a0and to perform quantum-logic operations. One approach, which Schoelkopf helped to pioneer and which Google, IBM, Rigetti and Quantum Circuits have adopted, involves encoding quantum states as oscillating currents in superconducting loops. The other, pursued by IonQ and several major academic labs, is to encode qubits in single ions held by electric and magnetic fields in vacuum traps. John Martinis, who worked at the University of California, Santa Barbara, until Google hired him and his research group in 2014, says that the maturity of superconducting tech\u00adnologyprompted his team to set the bold goal of quantum supremacy. The team plans to achieve this using a \u2018chaotic\u2019 quantum algorithm that produces what looks like a random output ( S.\u00a0Boixoetal.Preprintathttps://arxiv.org/abs/1608.00263;2016 ). If the algorithm is run on a quantum computer made of relatively few qubits, a classical machine can predict its output. But once the quantum machine gets close to about 50 qubits, even the largest classical supercomputers will fail to keep pace, the team predicts. The results of the calculation will not have any uses, but they will demonstrate that there are tasks at which quantum computers are unbeatable\u00a0\u2014\u00a0an important psychological threshold that will attract the attention of potential customers, Martinis says. \u201cWe think it will be a seminal experiment.\u201d But Schoelkopf does not see quantum supremacy as \u201ca very interesting or useful goal\u201d, in part because it dodges the challenge of error correction: the ability of the system to recover its information following slight disturbances to the qubits, which becomes more difficult as the number of qubits increases. Instead, Quantum Circuits is focused on making fully error-corrected machines from the start. This requires building in more qubits, but the machines could also run more-sophisticated quantum algorithms. Monroe hopes to reach quantum supremacy soon, but that is not IonQ\u2019s main goal. The start-up aims to build machines that have 32 or even 64 qubits, and the ion-trap technology will enable their designs to be more flexible and scalable than superconducting circuits, he says. Microsoft, meanwhile, is betting on the technology that has the most to prove. Topological quantum computing depends on excitations of matter that encode infor\u00admation by tangling around each other like braids. Information stored in these qubits would be much more resistant to outside disturbance than are other technologies and would, in particular, make error correction easier. No one has yet managed to create the state of matter needed for such excitations, let alone a topological qubit. But Microsoft has hired four leaders in the field, including Leo Kouwenhoven of the University of Delft in the Netherlands, who has created what seems to be the right type of excitation. \u201cI tell my students that 2017 is the year of braiding,\u201d says Kouwenhoven, who will now build a Microsoft lab on the Delft campus. Other researchers are more cautious. \u201cI am not making any press releases about the future,\u201d says Blatt. David Wineland, a physicist at the National Institute of Standards and Technology in Boulder, Colorado, who leads a lab working on ion traps, is also unwilling to make specific predictions. \u201cI\u2019m optimistic in the long term,\u201d he says, \u201cbut what \u2018long term\u2019 means, I don\u2019t know.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @dcastelvecchi \n               \n                     Inside Microsoft\u2019s quest for a topological quantum computer 2016-Oct-21 \n                   \n                     Quantum computer makes first high-energy physics simulation 2016-Jun-22 \n                   \n                     Google moves closer to a universal quantum computer 2016-Jun-08 \n                   \n                     AI talent grab sparks excitement and concern 2016-Apr-26 \n                   \n                     Physics: Quantum computer quest 2014-Dec-03 \n                   \n                     Topological insulators: Star material 2010-Jul-14 \n                   \n                     IBM Research Quantum Experience \n                   \n                     Rigetti \n                   \n                     Quantum Circuits \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21255", "url": "https://www.nature.com/articles/nature.2017.21255", "year": 2017, "authors": [{"name": "Jane Qiu"}], "parsed_as_year": "2006_or_before", "body": "Genetic and archaeological evidence points to pre-agricultural residents of the 'roof of the world'. Intrepid hunter-gatherers may have lived permanently in the cold, harsh environment of the oxygen-starved Tibetan Plateau at least 7,400 years ago \u2014 nearly 4,000 years earlier than researchers had thought. The claim, made by archaeologists who have re-examined ancient hand- and footprints at a site in central Tibet, could shed light on how and why humans moved to live at high altitudes. And it fits with genetic studies suggesting that Tibetan people began to acquire physiological adaptations to help them cope with reduced atmospheric oxygen levels around the same time. But some researchers say the evidence is too scanty to confirm such early year-round habitation on the plateau. With an average elevation of 4.5 kilometres, the air on the Tibetan Plateau has around half the oxygen present at sea level.\u00a0\u201cIt\u2019s the ultimate test for human survival and adaptation in extreme environments,\u201d says Mark Aldenderfer, an archaeologist at the University of California in Merced, and a co-author of the new study,  published on 5 January in  Science 1 .  Scientists thought that people began to live there year-round \u2014 both in summer and in bitter winter \u2014 only about 3,600 years ago, when  barley crops that can tolerate frost and cold temperatures were introduced , and farmers moved upland en masse 2 . But Aldenderfer and colleagues argue that hunter-gatherers lived on the plateau long before agriculture took hold. Their evidence comes from a site called Chusang, northwest of Lhasa, a remote, high-altitude region more than 4 kilometres above sea level. Rocks that were once soft mud near a hot spring there retain impressions of human hand- and footprints, from at least six individuals, including some children 3 . Prehistoric stone tools have been found nearby, and pollen buried in the imprints suggest lush grasslands where wild animals could thrive \u2014 food for anyone who made the trek, says Aldenderfer. Using three dating methods, the researchers, led by Aldenderfer and Michael Meyer, a geologist at the University of Innsbruck in Austria, found that sediments around the prints are between 7,400 and 12,700 years old. (An earlier study had put the sediments at 20,000 years old 3 , but it used a technique that tends to overestimate age, Meyer says.) The site probably wasn\u2019t visited only in summer, Aldenderfer says. Chusang is a long way from any habitable lowland spots in all directions. To visit and then return to a lower base camp would take at least a month over often impassable mountains; a more-plausible route would involve a round-trip time over two months, his team\u2019s modelling study suggests. The travel distances involved are far longer than those undertaken by modern nomadic groups, Aldenderfer says, which suggests that those who left the prints lived in the area year-round. \n             Genetic adaptations \n           The findings seem to fit genetic studies. Researchers completed sequencing the Tibetan genome last year, showing that the modern Tibetan gene pool was largely shaped between 15,000 and 9,000 years ago 4 . Based on that evidence, thousands of people may have migrated to the plateau during that time, argues Shuhua Xu, a population geneticist at the Chinese Academy of Sciences\u2019 Shanghai Institutes for Biological Sciences who led the study. Other studies have also suggested that Tibetans began to acquire genetic mutations that protected them from low blood oxygen levels between 12,800 and 8,000 years ago 5 , 6 , 7 . \u201cHumans really had to have a permanent presence and, more crucially, reproduce on the plateau to obtain the necessary mutations,\u201d says Xu. Around 8,000\u20137,000 years ago, the Tibetan Plateau went through a warm, wet period, says Guanghui Dong, an archaeologist at Lanzhou University in China who co-led a 2014 study that examined how farmers spread to the plateau later on 2 . It\u2019s possible that this expanded its resources, attracting humans to move upwards. Meanwhile, increasing competition for lowland resources could have pushed hunter-gatherers into marginal, harsh environments. \u201cIt\u2019s good to finally see that Chusang has some robust age estimates,\u201d says Jeffrey Brantingham, an anthropologist at the University of California, Los Angeles, who studies the peopling of the plateau. The new study is exciting, but it doesn't prove year-round occupation, he says. \u201cI'd say the jury is still out.\u201d Signs of post-holes where tents might have been put up, or inferences of mid-winter occupation from preserved animal remains, would be more direct evidence, he says. \u201cEven if humans lived on the plateau permanently that early, it would have been a marginal existence involving only a small number of people,\u201d adds Dong. \u201cA large population could not have survived on the plateau year-round without agriculture,\u201d he says. \n                   How China is rewriting the book on human origins 2016-Jul-12 \n                 \n                   Barley fuelled farmers' spread onto Tibetan plateau 2014-Nov-20 \n                 \n                   Origins of Arctic fox traced back to Tibet 2014-Jun-11 \n                 \n                   High life prompts genetic shift 2004-Feb-17 \n                 Reprints and Permissions"},
{"file_id": "541014a", "url": "https://www.nature.com/articles/541014a", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Expect researchers to glimpse an event horizon, continue striving for quantum supremacy and brace themselves for a political hangover. \n               Rough seas for climate \n             If the United States pulls back on its climate commitments as president-elect Donald Trump has promised, China, the world\u2019s biggest emitter of greenhouse gases, could take the lead on climate-change mitigation. The country\u2019s  national cap-and-trade system  to limit greenhouse-gas emissions should launch later this year. Global emissions have plateaued over the past three years, and some scientists hope that the levels may even fall this year, aided by a stagnant economy and a surge in green technology. And data from  robotic probes in the Southern Ocean  should reveal how much carbon dioxide the formidable sea around Antarctica is really sucking up. \n               Political hangover \n             Last year\u2019s elections brought political shocks, but 2017 will reveal the consequences. After  Trump\u2019s inauguration on 20\u00a0January , researchers should have a better idea of whether his administration will really gut NASA\u2019s climate and Earth-science programmes or revoke permission to carry out research with human embryonic stem cells. In March, the United Kingdom starts formal negotiations on the  country\u2019s exit from the European Union , with potentially huge impacts on research. And beginning in April, scientists will watch to see whether the West\u2019s enthusiasm for populist nationalism continues as, first France, then Germany, elect new leaders. \n               Return to sender \n             China\u2019s  Chang\u2019e-5 mission to the Moon  will return the first lunar samples to Earth since the 1970s. If the mission is successful, the 2\u00a0kilograms of rock and soil collected should further studies of the Moon\u2019s formation and evolution. Then, in September, NASA\u2019s 20-year-old Cassini probe will go out in a blaze of glory. The spacecraft will dive past Saturn\u2019s inner rings, sending back what researchers hope will be a trove of data before breaking apart in the planet\u2019s atmosphere. \n               The world within \n             Expect more studies on how the human microbiome \u2014 the collection of viruses, bacteria and other microbes in the body, together with their genes \u2014  affects health . Researchers are examining the microbiome\u2019s effects on brain development and cancer. And results could also arrive from phase two of the US Human Micro-biome Project, which focuses on the human microbiota\u2019s link to premature births and the onset of inflammatory bowel disease and type\u00a02 diabetes. \n               Genetic competition \n             A US court is likely to rule on the CRISPR\u2013Cas9 patent dispute between the University of California, Berkeley, and the Broad Institute in Cambridge, Massachusetts. The institute that can claim the invention of the gene-editing technique could collect billions of dollars in patent licences. NgAgo, a rival gene-editing system that has been difficult to replicate,  could sink or swim on the basis of follow-up studies . And in the United Kingdom, clinics can now apply for licences to use a controversial assisted-reproduction technique that mixes DNA from three people. The pro-cedure aims to prevent children from inheriting diseases passed down through their mother\u2019s mitochondria, the cell\u2019s energy-producing structures. \n               Quantum supremacy \n             Physicists hope that 2017 will be the year in which quantum computers perform calculations that would be impossible on even the best classical computers. Google, D-wave and a handful of others are among those racing for quantum supremacy. But they are not the only ones aiming for greater computational heights. Microsoft is working on an ambitious alternative technique known as  topological quantum computing , which encodes information in the movement of particle-like objects in materials, and may be much more robust than rival methods. The company could see its first successful computation later this year. \n               Illuminating the dark \n             Scientists will make their first attempt to photograph the event horizon of a black hole in April, when nine radio telescopes around the world collaborate as a single, planet-sized observatory. The Event Horizon Telescope will spy on the supermassive black hole at the Milky Way\u2019s centre. If the attempt is successful, the images should help to test general relativity and  illuminate black-hole behaviour . Meanwhile, teams at the Laser Interferometer Gravitational-Wave Observatory (LIGO) and Virgo, a European observatory near Pisa, Italy, will perform their first advanced run together, which could enable researchers to pinpoint the origin of gravitational waves to particular galaxies. \n               Wonder materials \n             Cheap, thin solar cells are set to move out of the lab  as commercialization begins in earnest later this year. The efficiency of perovskite-based solar cells has skyrocketed since 2009. But researchers are only now making strides in overcoming major drawbacks in the material, including instability and toxicity, while pushing forward with ways to produce the cells at low cost. Materials science will also get a boost as the \u20ac1.2-billion (US$1.2-billion)  European X-ray free-electron laser  at DESY in Hamburg, Germany, becomes operational. The instrument will allow researchers to study split-second chemical reactions and biological and physical processes in atomic detail. \n               Big blue \n             The  world\u2019s largest marine reserve  goes into effect in December, when portions of Antarctica\u2019s Ross Sea become exempt from commercial fishing and mineral exploitation. Elsewhere in the Antarctic, a large iceberg could calve off the Larsen C Ice Shelf, shrinking the mass of ice and snow to its smallest size since its discovery in 1893. In warmer climes, studies looking at the  extensive coral bleaching events  of the past few years should reveal clues to why corals in some areas have survived relatively unscathed. \n               T cells fight back \n             A first-of-its-kind, complex cancer immunotherapy called CAR-T looks ready to hit the market. Drug firms Kite Pharma and Novartis are racing to get approval for the therapy, which involves genetically engineering T\u00a0cells from a patient\u2019s immune system and using them to fight their cancer. Despite toxicity issues that led to patient deaths in some companies\u2019 studies, the therapy could be approved this year as a last-ditch approach for treating people with leukaemias and lymphomas. \n               Planet Nine \n             Studies of the outer Solar System are likely to help constrain  the location of Planet Nine , a hypothetical behemoth that may orbit the Sun roughly every 20,000 years. There was little evidence for its existence until a 2016 study found behaviour in some Kuiper-belt objects\u00a0\u2014 icy bodies in an area far beyond Pluto\u2019s orbit\u00a0\u2014 that suggested it was there. And there will be a new hunter for planets outside the Solar System when NASA launches the Transiting Exoplanet Survey Satellite (TESS) in December. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Nature  special: Science and the US election \n                   \n                     Nature  special: Brexit and science \n                   \n                     Nature  special: Human microbiota \n                   \n                     Nature  special: Gravitational waves \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21217", "url": "https://www.nature.com/articles/nature.2016.21217", "year": 2017, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "US government proposes introducing wolves to Isle Royale as population dwindles. The world\u2019s longest-running study of predators and prey is on the endangered list \u2014 but it could soon get a reprieve from the US government. Scientists have been charting the changing fortunes of wolves and moose on Isle Royale in Lake Superior for nearly 60 years, but a sharp decline in the wolf population \u2014 now reduced to just two closely related animals \u2014 has threatened to end the project. Now, after years of debate, the US agency that manages the island in Michigan has proposed introducing up to 30 wolves from the mainland. If the National Park Service carries through with the plan introduced on 16 December, it would create a new population of wolves. But  the 'genetic rescue' long advocated by scientists  hoping to save the island's inbred wolfpack now appears out of reach. Isle Royale\u2019s remaining wolf pair has little chance of producing healthy pups, because the male is the father of the female and they have the same mother. The animals\u2019 only known offspring was visibly deformed and died young. \u201cUnless something is done, you are going to lose wolves from Isle Royale,\u201d says Matthew Gompper, a carnivore expert at the University of Missouri in Columbia who helped the park service solicit expert input for its plan. \u201cEcologically they are just a relict on the island. Moose are skyrocketing and we are seeing changes to the plant community.\u201d The park service\u2019s plan \u2014 which is open for public comment until 15 March \u2014 analyses several different scenarios for the next 20 years, from letting Isle Royale\u2019s wolves die out to adding wolves whenever the population gets too inbred. The agency favours \u2018Alternative B\u2019, which would add 20\u201330 wolves within 5 years, and then leave the island alone for another 15. But shoring up the wolf population may not be enough to prevent Isle Royale\u2019s ballooning moose population from reshaping the island\u2019s ecosystem. Moose are eating balsam fir so heavily that it could largely disappear, along with aspen, birch and mountain ash trees \u2014 turning a closed-canopy forest into an open spruce savannah. John Vucetich, a population biologist who is one of the study\u2019s two principal investigators, worries that relocating a large number of wolves to the island within the next five years won\u2019t save the balsam fir. \u201cWhen the moose population has been growing at 22% per year like it has for the past 4\u00a0years, that is not something you stop on a dime,\u201d says Vucetich, who is based at Michigan Technological University in Houghton. \u201cThat is a freight train.\u201d It will take about five years after wolves return to determine whether the new predators can save the balsam fir, he adds. \n               Wild cycle \n             Results from the Isle Royale study,  which began in 1958 , have underscored the importance of unpredictable events to predator\u2013prey population trends. Instead of neatly oscillating boom and bust cycles as wolves overeat moose, then starve and allow their prey to repopulate, the island\u2019s moose and wolf populations have spiked and crashed in response to external factors. These include a virus transmitted from domestic dogs, explosions in the population of moose ticks and a single wolf crossing the frozen lake from the mainland and bringing his genes with him. On some level, the introduction of new wolves by humans would be just the latest of these contingent events, says Vucetich, who favours such \u2018re-wolfing\u2019. But others oppose the plan as inappropriate for Isle Royale, a national park where 99% of the land is designated as wilderness \u2014 which requires the federal government to preserve its wild character. \"This is a slippery slope,\u201d says Kevin Proescholdt, conservation director of Wilderness Watch in Minneapolis, Minnesota. He predicts that adding wolves to Isle Royale will open the door to further manipulation, because many of the same factors that led the current wolf population to dwindle \u2014 including disease and climate variability \u2014 could do the same to a reinforced population. Those who support adding wolves to the island admit that the population may eventually need to be topped up again, especially because climate change has reduced how often Lake Superior freezes solid. That is the only condition under which wolves can reach the island on their own. But Rolf Peterson, the study\u2019s other principal investigator, notes that early proponents of the US national wilderness-protection system supported adding wolves to Isle Royale in the 1940s to control the moose population. That was before the wolves first crossed the frozen lake and introduced themselves to the island. In 1944, conservationist Aldo Leopold made such a recommendation in a letter to the acting director of the park service \u2014 and foresaw the study that was to begin 14 years later. \u201cIsle Royale must present a wonderful opportunity for long-time records on the interaction of moose and browse,\u201d Leopold wrote, \u201cand if wolves are added, on the interaction of all three. I hope the Park Service will not overlook this opportunity.\u201d \n                     Wolf decline threatens iconic island study 2015-Apr-17 \n                   \n                     Iconic island study on its last legs 2014-Feb-11 \n                   \n                     Lone wolves 2014-Feb-11 \n                   \n                     Grey wolves left out in the cold 2013-Sep-11 \n                   \n                     Environmental impact statement on Isle Royale project \n                   \n                     Project page: Wolves and Moose of Isle Royale \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21259", "url": "https://www.nature.com/articles/nature.2017.21259", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Many researchers also object to proposed higher-education reforms, says survey. A survey of more than 1,000 UK-based university staff suggests that the country\u2019s  vote to leave the European Union  could drive an academic exodus. Forty-two per cent of lecturers and professors surveyed say they are more likely to consider leaving the UK higher-education sector as a result of the referendum outcome. The proportion was even greater (76%) among the non-UK EU citizens in the survey, commissioned by the University and College Union, which represents tens of thousands of academics and is based in London. Many individual foreign researchers have said they feel less welcome in Britain after the Brexit vote, or that they now see better opportunities abroad. But the latest poll is one of the clearest indications of the widespread nature of this feeling in UK academia. The survey also reveals huge opposition to the UK government\u2019s controversial plans to reform higher education (HE) and research. More than half of academics think that the proposal  to merge the nine UK research funding agencies  into one body \u2014 currently being debated in Parliament \u2014 will have a negative impact. Just 9% think it would be a positive move. Even greater proportions think that there will be negative impacts from other changes, such as plans to make it easier for new universities to be set up. \u201cThe level of concern amongst staff about the bill\u2019s plans must be cause for alarm,\u201d said Sally Hunt, the union\u2019s general secretary, in a statement. \u201cThe government must focus its full attention on dealing with the impacts of Brexit and shelve the divisive HE bill.\u201d \n                   Brexit by the numbers: the fear of brain drain 2016-Dec-12 \n                 \n                   Brexit government\u2019s anti-immigration stance spooks UK scientists 2016-Oct-06 \n                 \n                   E-mails show how UK physicists were dumped over Brexit 2016-Aug-05 \n                 \n                   Lessons from Brexit 2016-Jul-25 \n                 \n                   Nature  special: Brexit and science \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21273", "url": "https://www.nature.com/articles/nature.2017.21273", "year": 2017, "authors": [{"name": "Devin Powell"}], "parsed_as_year": "2006_or_before", "body": "Hand-powered device can process blood samples and separate out parasites such as those that cause malaria. Growing up in India, Manu Prakash entertained himself with a bottle cap that spun around on two strings that he tugged with his fingers. As a physical biologist at Stanford University in California, he is now transforming that simple toy, called a whirligig, into a cheap tool to help diagnose diseases such as malaria and conditions like anaemia. Prakash started this project, the results of which are published on 10 January in  Nature Biomedical Engineering 1 , after a research trip to Uganda in 2013. While visiting health-care clinics, he noticed that most lacked a working centrifuge \u2014 or the  electricity to power one  \u2014 and could not separate blood samples to perform  basic disease diagnostics . \u201cOne clinic used its broken centrifuge as a doorstop,\u201d says Prakash, a 2016 MacArthur \u2018genius grant\u2019 winner who has also invented a foldable paper microscope 2 . \u201cWhen we got back from Africa we asked ourselves, \u2018Can we do centrifugation with no electricity, using only human power?\u2019\u201d Other researchers have come up with low-tech,  inexpensive  centrifuges that used salad spinners 3  and egg beaters 4 , but these devices could manage only around 1,200 rotations per minute (r.p.m.) and took too long to process samples, says Prakash. Hoping to do better, his team went on a shopping spree to a toy store, collecting spinning gizmos and filming them with a high-speed camera. Yo-yos spun too slowly (and required training to use). But whirligigs were both easy to operate and reached speeds of 10,000 r.p.m., comparable to a commercial centrifuge. Delighted by the whirligig\u2019s performance, the researchers began exploring the mathematics underlying it in the hope of making improvements. Video footage revealed that the toy\u2019s strings not only twist around each other as they wind and unwind, but also form coils similar to structures found in DNA. Solving the equations that describe the forces behind that coiling revealed the specs for an ideal whirligig \u2014 from the size of its disc to the thickness of its strings \u2014 capable of spinning a million times per minute. Human hands cannot spin the toy fast enough to hit that theoretical limit. But a new design made in the lab achieved 125,000 r.p.m. \u2014 submitted to Guinness World Records last year as the fastest device to rotate under human power. \n             Hiding in plain sight \n           \u201cWhat makes this really special is that it takes something simple and reveals something superbly useful hiding just under our noses,\u201d says Tadashi Tokieda, an applied mathematician at the University of Cambridge, UK. After optimizing the whirligig, Prakash and his team then mounted plastic tubes for holding blood samples onto their paper device. Their final prototype, dubbed the paperfuge, can reach 20,000 r.p.m., separating plasma from blood in 1.5 minutes, and malaria parasites in 15 minutes. Whether health-care workers will be willing to spend that much time powering the paperfuge \u2014 either in a health-care facility or out in the field \u2014 remains to be seen. Prakash has partnered with the health-care nonprofit PIVOT in Boston, Massachusetts, for a clinical trial in Madagascar, which will assess not only how easy the device is to use, but also its durability and reliability compared to commercial centrifuges. \u201cWe don\u2019t know yet if the paperfuge will work,\u201d says Matt Bonds, PIVOT cofounder and an economist at Harvard University in Cambridge, Massachusetts. \u201cIt would take a lot of evidence to convince people to abandon modern centrifuges, but having paperfuges available as an alternative could open up a world of new possibilities.\u201d \n                   Deep-sea microbes, simple medical diagnostic tools and complex computing win 2016 MacArthur \u2018genius grants\u2019 2016-Sep-22 \n                 \n                   \u2018Open-hardware\u2019 pioneers push for low-cost lab kit 2016-Mar-08 \n                 \n                   Microscopic marvels: Microscope for the masses 2009-Jun-03 \n                 \n                   Blood tests using sticky tape and paper 2008-Dec-08 \n                 \n                   How to make graphene in a kitchen blender \n                 \n                   Foldable instruments \n                 \n                   Pivot \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21223", "url": "https://www.nature.com/articles/nature.2016.21223", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}, {"name": "Emiliano Rodr\u00edguez Mega"}], "parsed_as_year": "2006_or_before", "body": "Libraries pursue alternative delivery routes after licence negotiations break down. \n               9 January: Since this story was published, Elsevier has granted a one-month access extension \u2014 until the end of January \u2014 to those Taiwanese universities that had cancelled their online subscriptions. Negotiations between the Taiwanese consortium of university libraries, CONCERT, and Elsevier have resumed. \n             Thousands of scientists in Germany, Peru and Taiwan are preparing for a new year without online access to journals from the Dutch publishing giant Elsevier. Contract negotiations in both Germany and Taiwan broke down in December, while Peru\u2019s government has cut off funding for a licence. \u201cIt\u2019s very unpleasant,\u201d says Horst Hippler, spokesperson for the DEAL consortium of state-funded universities and research organizations, which is overseeing negotiations in Germany. \u201cBut we just cannot accept what Elsevier has proposed so far.\u201d Universities regularly complain about the rising costs of academic journals, and sometimes threaten to cancel their subscriptions. But negotiators usually strike a deal to avoid cutting researchers off. Last year, for example, a consortium of 14 universities in the Netherlands threatened to boycott Elsevier if it could not agree that articles by Dutch authors would be made open access. In the end, it  thrashed out a compromise : 30% of its Dutch papers will be open access by 2018. And this month, a Finnish consortium that could not agree on terms with major publishers including Elsevier settled for  a one-year extension deal  while talks continue. That hasn\u2019t happened in Germany or Taiwan. In Germany, the DEAL consortium was supposed to broker its first nationwide licence agreement for the beginning of 2017. It wants all German-authored articles to be made open access. But Hippler says that Elsevier\u2019s proposed contract cost too much, and didn\u2019t include an open-access clause. Negotiations ended in December without agreement; Hippler says they are likely to resume in January. Asked for comment, an Elsevier spokesperson pointed to a  2 December statement  that said the publisher had \u201cmade suggestions for a path to open access publishing in Germany\u201d, and that it looked forward to resuming talks in 2017. Elsevier declined to comment further on details of the negotiations. \n               Closed access \n             Before the DEAL collective formed, German institutions had negotiated their own contracts with Elsevier individually. Hundreds of universities are still on multi-year individual contracts, so are not yet affected. But for more than 60 institutions, access licences ran out at the end of 2016. In October, assuming that a nationwide deal would be struck, they decided not to automatically renew. Now, academics in those institutions are set to lose access: in some cases only to articles published from the start of 2017 onwards, but in others, to archived issues too. At the University of G\u00f6ttingen, for example, researchers will not have access to archived content in economics journals. The affected institutions could choose to renew their individual licences, but seem content to ride out the lack of access while DEAL negotiations continue. Elsevier and the DEAL consortium, says Hippler, are still far apart with regards to pricing and the OA business model. \u201cTaxpayers have a right to read what they are paying for,\u201d he says. \u201cPublishers must understand that the route to open-access publishing at an affordable price is irreversible.\u201d In Taiwan, meanwhile, more than 75% of universities, including the country\u2019s top 11 institutions, have joined a collective boycott against Elsevier, says Yan-Jyi Huang, library director at the National Taiwan University of Science and Technology (NTUST, also known as Taiwan Tech). On 7 December, the Taiwanese consortium, CONCERT, which represents more than 140 institutions, announced it  would not renew its contract  with Elsevier because fees were too high. Elsevier switched to dealing with universities individually. But the NTUST and many others \u2014 including Taiwan\u2019s leading research institute, Academia Sinica \u2014 have each decided to uphold the boycott, from 1 January 2017. \u201cIn the spirit of camaraderie with the other schools, the Taiwan Tech library has decided to join the collective boycott against Elsevier with other top universities in Taiwan,\u201d an  NTUST statement  says. \n               Alternative access routes \n             The problem is not as dramatic as it might seem because it is now easy to access many newly published papers in a free-to-read format outside of commercial publishers\u2019 websites, says Ralf Schimmer, a librarian at the Max Planck Society in Munich, Germany (whose Elsevier licence has not yet expired). \u201cThere are many perfectly legal ways to obtain scientific papers from open-access platforms, neighbouring institutes or directly from the authors,\u201d he says. The affected universities in Germany are offering scientists access through inter-library loans \u2014 which is also the approach being taken in Taiwan, says Huang. The NTUST, for example, has applied to join an international \u2018rapid inter-library loan\u2019 service hosted by Colorado State University Libraries, which already has members in Taiwan, Singapore, and Australia, as well as across the United States. In Peru, researchers are also set to lose online access to Elsevier\u2019s Science Direct and Scopus platforms from 2017 because of a lack of government funding. But some scientists there say that it\u2019s not a problem, because they can get the papers they need illegally from  the Sci-Hub website . \u201cI\u2019m not worried. Downloading papers is rather easy now with Sci-Hub,\u201d says one plant biologist who doesn't want to be named. Exactly why Peru\u2019s government isn\u2019t providing the funds to its National Council for Science, Technology and Technological Innovation (CONCYTEC) for access to Elsevier\u2019s products is not clear. CONCYTEC announced the problem on 14 December, but declined to comment on why funding was cut off. \u201cThe cancellation is a simple result of a lack of government funding,\u201d an Elsevier spokesperson adds. Josmel Pacheco-Mendoza, a bibliometrics researcher at the San Ignacio de Loyola University in Lima, suspects that it may be a combination of government funding shortfalls and high subscription costs: the government spent nearly $10 million for a three-year licence, he says. Peru had until recently been eligible for free or low-cost access to major science journals under an initiative called HINARI, set up by the World Health Organization. But because of its economic growth, the country lost that route in 2012. At that time \u2014 before CONCYTEC stepped in with a national licence starting in 2014 \u2014 researchers \u201chad to start begging for papers\u201d through social media groups or from colleagues in foreign universities, the plant biologist says. Now everyone uses Sci-Hub, he adds. \u201cI\u2019m 30 years old, and I would say that around 95% of my generation uses it.\u201d But other Peruvian scientists say they\u2019re reluctant to use Sci-Hub, and that it cannot be a permanent solution to their lack of access. \u201cI hope the government realizes that databases are important,\u201d says Dionicia Gamboa, a molecular parasitologist from Cayetano Heredia University in Lima. Losing access, she says, is a step backwards. Additional reporting by Richard Van Noorden \n                     Pirate research-paper sites play hide-and-seek with publishers 2015-Dec-04 \n                   \n                     Half of 2011 papers now free to read 2013-Aug-20 \n                   \n                     Open access: The true cost of science publishing 2013-Mar-27 \n                   \n                     Researchers opt to limit uses of open-access publications 2013-Feb-06 \n                   \n                     Nature  special: The future of publishing \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21253", "url": "https://www.nature.com/articles/nature.2017.21253", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Updated version of DeepMind's AlphaGo program behind mystery online competitor. A mystery player causing a stir in the world of the complex strategy game Go has been revealed as an updated version of AlphaGo, the artificial-intelligence (AI) program created by Google's London-based AI firm, DeepMind. Known only by the name \u2018Master(P)\u2019, since late December the anonymous player has beaten the world\u2019s best at Go in a string of online games, including defeating current world number one, 19-year-old Ke Jie. Go is regarded as the most complex board game ever invented, and is famously difficult for computers to crack. But last year, AlphaGo showcased the strength of AI software when it  stunned the Go world , first by defeating a professional human player, Fan Hui, and then going on to  beat one of the Go world's top players, Lee Sedol . Fellow players had a hunch that Master(P) was probably also an AI program. It came out of nowhere to win dozens of consecutive quick-fire games across two separate online platforms. And on 4 January, Google DeepMind chief executive Demis Hassabis  revealed on Twitter  that Master(P) is a new prototype version of AlphaGo. The \"unofficial\" games were designed to test the prototype, he said: \"We're excited by the results and also by what we and the Go community can learn from some of the innovative and successful moves played by the new version of AlphaGo.\" \n               http://www.nature.com/news/google-ai-algorithm-masters-ancient-game-of-go-1.19234 \n             \n               Victory prize \n             Playing on the online servers Tygem and FoxGo, Master(P) played more than 50 games, winning in all \u2014 except perhaps for one game, which, according to some reports, was deemed a tie only because the network connection of the opponent, the Go professional Chen Yaoye, timed out. \u201cIt\u2019s extremely impressive whoever/whatever it is,\u201d said British Go player Jon Diamond ahead of the announcement. After losing to Master(P), Chinese professional Gu Li offered a reward of 100,000 yuan (US$14,400) to any human who could beat the mysterious player. Although AlphaGo was rumoured to be behind the bot, many observers also suspected that another team had created an AI that could master the game, something both Chinese and South Korean scientists have said they are attempting to do. Hassabis said that the new version of AlphaGo would play official, full-length games later this year. How strong it will be in more high-profile tournaments remains unclear, because the rules of such matches differ from those played in online forums. Online games are usually played at a faster pace, which favours the computer over humans, says R\u00e9mi Coulom, a freelance developer of Go programs based in Lille, France. \"But still, I expect a strong correlation with performance in serious slow tournament games,\u201d he adds. AlphaGo has only played around a dozen public games, so Google DeepMind's decision to trial its latest version in the open will allow Go players to study more of its moves. \u201cI personally think it's fantastic that there are all these games for people to look at and study. There are lots of moves that are really new and surprising,\u201d says Niall Cardin, a UK-based Go player. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Google's AI reasons its way around the London Underground 2016-Oct-13 \n                   \n                     Can we open the black box of AI? 2016-Oct-05 \n                   \n                     South Korea trumpets $860-million AI fund after AlphaGo 'shock' 2016-Mar-18 \n                   \n                     Google AI algorithm masters ancient game of Go 2016-Jan-27 \n                   \n                     Nature special: The Go Files \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21274", "url": "https://www.nature.com/articles/nature.2017.21274", "year": 2017, "authors": [{"name": "Carrie Arnold"}], "parsed_as_year": "2006_or_before", "body": "This group of viruses is hundreds of millions of years older than previously thought. Retroviruses probably evolved roughly half a billion years ago, making this  medically  and economically important group of viruses five times older than scientists previously thought. The finding, which is based on an  analysis published on 10 January in  Nature Communications 1 , indicates that retroviruses moved with their vertebrate hosts from the ocean to dry land. Using new mathematical techniques to calculate the age of an ancient line of retroviruses called  foamy viruses , which infect species ranging from lemurs to fish, the researchers worked out that retroviruses first evolved between 460 million and 550 million years ago. \u201cThese viruses are as old as vertebrates themselves, older than any other viruses we know about,\u201d says study co-author Aris Katzourakis, a palaeovirologist at the University of Oxford, UK. Until now, scientists didn\u2019t have the tools to calculate the age of viruses as ancient as this, because the natural accumulation of mutations in the viral genes clouded the micro-organisms\u2019 early history. \u201cYou can see rapid evolution in retroviruses over short time frames, but this is new evidence that they\u2019ve been around for hundreds of millions of years,\u201d says Michael Worobey, an evolutionary virologist at the University of Arizona in Tucson. \u201cWe\u2019re up against the limits of our ability to determine their age.\u201d \n             Back in time \n           Many viruses insert copies of their genome into their host\u2019s DNA, and retroviruses are particularly adept at doing this. If hosts pass on the viral genome to their offspring, the virus has effectively become a part of the animal\u2019s genetic code and can be passed down through time. Scientists have sequenced an increasing number of animal genomes, discovering ever more of these kinds of retrovirus. About 8% of the  human genome consists of retroviral elements , although random mutations have rendered many of them inert. Katzourakis had previously established that retroviruses have been  infecting mammals  for at least 100 million years 2 , and a study published in 2012 hinted that they could be even older 3 . To settle this question, he turned to foamy viruses. Named for their ability to make infected cultured cells look as if they were soaking in a bubble bath, foamy viruses infect animals from very different lineages. This makes these viruses ideal for studying the ancient history of retroviruses, because their history could be investigated in multiple groups of animals through the traces of their genes in their hosts\u2019 genomes. Normally, scientists construct an evolutionary tree by using mutation rates to calculate when two organisms last shared a common ancestor. More mutations mean a longer time since two species diverged. But Katzourakis hit a wall when he tried this for foamy-virus sequences from 36 reptile and amphibian lineages, whose ancestors were probably the first animals infected by retroviruses. \n             Tracking mutations \n           When scientists studied viral evolution over longer time spans, they noticed that the mathematical formulae they had been using to calculate mutation rates made virus evolution look as if it had slowed down. In reality, the viruses evolve at roughly the same rate over any time period. So Katzourakis created a mathematical formula that helped him to account for this apparent difference in evolutionary rates of viral genes in deep time. This analysis allowed Katzourakis and his co-author, Pakorn Aiewsakun, a palaeovirologist at the University of Oxford, to extend the age of retroviruses back to when animals emerged from the ocean onto land. Michael Emerman, a retrovirologist at the Fred Hutchinson Cancer Research Center in Seattle, Washington, says that understanding the retroviruses locked in animal genomes is essential for understanding not only the evolution of viruses but also that of vertebrates. Comparing the various viruses in the genomes of different species can tell researchers more about when new species emerged. \u201cIt\u2019s a really nice paper that uses the fact that almost every animal has a retrovirus, and their evolution occurred with these viruses,\u201d he says. \u201cYou can\u2019t consider the evolution of a species without the evolution of their pathogens.\u201d \n                   The scientist who put the nail in XMRV's coffin 2012-Sep-18 \n                 \n                   Animal genomes riddled with the 'skeletons' of ancient viruses \n                 \n                   Ancient human virus resurrected \n                 Reprints and Permissions"},
{"file_id": "541145a", "url": "https://www.nature.com/articles/541145a", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Environmental scientists plan to push for policy changes but are nervous about losing current protections. Britain\u2019s environment faces significant risks from Brexit, with protections for wildlife and millions of euros in funding for environmental programmes now facing an uncertain future. But the pending departure of the United Kingdom from the European Union will free lawmakers to craft UK-specific legislation\u00a0\u2014\u00a0and some environmental researchers spot a rare chance to use their expertise to shape future policy. \u201cThe decision to leave the European Union presents substantial risks, but also significant opportunities,\u201d says Sue Hartley, an ecologist at the University of York, UK, and president of the British Ecological Society. She gave evidence to a parliamentary inquiry into the impact of Brexit on the environment, which was led by Member of Parliament Mary Creagh and released its conclusions on 4\u00a0January. The process of leaving the EU is due to start by the end of March 2017, and must be completed within two years. To avoid a sudden change in how things work, the UK government says it will introduce a \u2018great repeal bill\u2019 that will largely convert EU laws into UK ones. But it will then be able to modify or strike out EU laws, something that currently requires unwieldy negotiations with the rest of the EU. Some environmental campaigners are worried about what this will mean for the EU legislation that currently safeguards UK birds and habitats. \u201cThe evidence has shown that these directives are effective,\u201d says Martin Harper, conservation director of the Royal Society for the Protection of Birds. Creagh\u2019s committee has called for an act to safeguard existing protections for UK wildlife ahead of the implementation of the great repeal bill. But environmental researchers, many of whom have spent years pushing for reforms to huge EU programmes only to be frustrated by the slow pace of change, also spy an opportunity\u00a0\u2014\u00a0in particular when it comes to one of the most contentious pieces of EU legislation, the Common Agricultural Policy, or CAP. In the United Kingdom, most CAP funding is spent on direct payments to farmers to support their income. This amounts to around \u00a31.8 billion (US$2.2\u00a0billion) annually. A smaller proportion\u00a0\u2014\u00a0\u00a3400 million\u00a0\u2014\u00a0goes to programmes that benefit the environment, such as paying for buffer strips between fields to promote wildlife habitat or to reduce damage from fertilizers. But scientists argue that more of the CAP money should go towards environmental protection. Reforms in 2013 were meant to make CAP greener, such as a rule requiring farmers to grow at least three crops to maintain biodiversity, but this did not assuage all concerns. \u201cIt\u2019s pretty hard to make the Common Agricultural Policy worse than it currently is,\u201d says Dieter Helm, an economist at the University of Oxford. In September, Helm wrote a  report exploring ways in which a post-Brexit United Kingdom might replace CAP . His preferred option is a radical overhaul that would eliminate automatic subsidies to farmers. Instead, the government could target investment at rural programmes that provide proven benefits, such as reducing pollution or increasing biodiversity, he suggests. These could involve payments to farmers who modify their farms to provide such green benefits. Richard Brazier, who studies the environmental impact of land use and agriculture at the University of Exeter and was a witness in the parliamentary inquiry, also spots an opportunity to reform CAP. His specialism is landscape restoration, in which farmed land is altered to provide better \u2018ecosystem services\u2019 alongside food production. One example is  reintroducing beavers to benefit flood management . A UK-specific agriculture policy could aim to rewild between 1% and 10% of farmed land, he suggests. He recommends that any new policy removes existing barriers to rewilding, such as CAP rules that effectively penalize farmers for transforming woodland or ponds into wildlife habitat that does not produce crops. The parliamentary report also mentions the possibility that rewilding, and the removal of these disincentives, could feature more prominently in UK-only laws. But there are risks associated with losing CAP.  The government has guaranteed to fund existing CAP payments until 2020 , but on 4 January, environment minister Andrea Leadsom  pledged to \u201cdesign a domestic successor to CAP\u201d  while scrapping various pieces of EU legislation\u00a0\u2014\u00a0including the three-crop rule\u00a0\u2014\u00a0and \u201ccutting the red tape that comes out of Brussels\u201d. Even researchers who have criticized CAP in the past fear that modifications could undermine its environmental benefits. Lynn Dicks, an applied ecologist at the University of East Anglia in Norwich, co-authored a highly cited critique of the 2013 reforms ( G.\u00a0Pe\u2019er  et\u00a0al. Science    344, 1090\u20131092; 2014 ), but in 2013 she also reported that many schemes designed to protect wildlife produced consistent benefits ( L.\u2009V. Dicks  et\u00a0al. Conserv. Lett.    7, 119\u2013125; 2014 ). \u201cI think we\u2019ve been quite innovative actually, within the CAP,\u201d she says. \u201cIt\u2019s terrifying to me that we might lose all of it.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @DPCressey \n               \n                     Scientists should not resign themselves to Brexit 2017-Jan-04 \n                   \n                     Brexit watch: Scientists grapple with the fallout 2016-Jul-08 \n                   \n                     Nature  Special: Brexit and science \n                   \n                     Parliamentary report \n                   \n                     Dieter Helm \n                   Reprints and Permissions"},
{"file_id": "541144a", "url": "https://www.nature.com/articles/541144a", "year": 2017, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Spice extract dupes assays and leads some drug hunters astray. Inside the golden-yellow spice turmeric lurks a chemical deceiver: curcumin, a molecule that is widely touted as having medicinal activity, but which also gives false signals in drug screening tests. For years, chemists have urged caution about curcumin and other compounds that can mislead naive drug hunters.\u00a0 Now, in an attempt to stem a continuing flow of muddled research, scientists have published the most comprehensive critical review yet of curcumin\u00a0\u2014\u00a0concluding that there\u2019s no evidence it has any specific therapeutic benefits, despite thousands of research papers and more than 120 clinical trials. The scientists hope that their report will prevent further wasted research and alert the unwary to the possibility that chemicals may often show up as \u2018hits\u2019 in drug screens, but be unlikely to yield a drug. \u201cCurcumin is a cautionary tale,\u201d says Michael Walters, a medicinal chemist at the University of Minnesota in Minneapolis, and lead author of the review ( K.\u00a0M.\u00a0Nelsonet\u00a0al.J.\u00a0Med.Chem.http://dx.doi.org/10.1021/acs.jmedchem.6b00975;2017 ), published on 11\u00a0January. Commonly used drug screens detect whether a chemical latches on to a binding site of a protein implicated in disease\u00a0\u2014\u00a0a hint that it may be the starting point for a drug. But some molecules, such as curcumin,  seem to show such specific activity when there is none . The molecules may fluoresce naturally, foiling attempts to use fluorescence as a signal of protein binding. They may disrupt cell membranes, duping assays that try to spot drugs targeting specific cell-membrane proteins. And they may surreptitiously degrade into other compounds that have different properties, or contain impurities that have their own biological activity. Chemists call these irritants PAINS (pan-assay interference compounds)\u00a0\u2014\u00a0and curcumin is one of the worst. \u201cCurcumin is a poster child for these promiscuous molecules that come up often in screens,\u201d says James Inglese, who directs assay development and screening technology at the National Center for Advancing Translational Sciences in Bethesda, Maryland. \u201cA lot of people doing this kind of work aren\u2019t technically aware of all the issues that this thing can cause.\u201d \u201cMuch effort and funding has been wasted on curcumin research,\u201d says Gunda Georg, co-editor-in-chief of the  Journal of Medicinal Chemistry , which published the review. Even so, she says, her journal sees a regular stream of curcumin manuscripts. Curcumin has been proposed to treat such disorders as erectile dysfunction, hirsutism, baldness, cancer and Alzheimer\u2019s disease, says Guido Pauli, a natural-product researcher at the University of Illinois at Chicago and a co-author of the review. But it\u2019s never yielded a proven treatment.\u00a0 Pauli thinks part of the problem is that researchers don\u2019t always know what molecule they are studying. Turmeric extracts contain dozens of compounds besides curcumin, which is itself used as a shorthand for three closely related molecules. In some cases, researchers may observe promising biological effects but ascribe activity to the wrong molecule.\u00a0 Misinterpretations feed on themselves, Walters says. Curcumin gets reported as having an effect even if the assay was flawed. \u201cPeople accept what is in the literature as being correct and then build a hypothesis, even though it doesn\u2019t hold up.\u201d And scientists don\u2019t seem to check the literature to see whether compounds have been flagged as problematic. At least 15\u00a0articles on curcumin have been retracted since 2009 and dozens more corrected. Many researchers are still optimistic about curcumin. \u201cThere is evidence that the biological activity of curcumoids is real,\u201d says Julie Ryan, a radiation oncologist at the University of Rochester Medical Center in New York. She says\u00a0that it interacts with many different proteins and so works differently from many drugs. Ryan has tested curcumin in clinical trials for dermatitis on more than 600 people. Although she found no significant effect, she says there were trends that warrant further study. She thinks that chemically modified forms of curcumin might prove more effective at reaching tissues. But the review shows that getting real answers will be tough, says Bill Zuercher, a chemical biologist at the University of North Carolina at Chapel Hill. \u201cIt may very well be the case that curcumin or turmeric extracts do have beneficial effects, but getting to the bottom of that is complex and might be impossible,\u201d he says. Walters isn\u2019t confident that his report will stop poorly conducted research. \u201cThe people who should be reading this probably won\u2019t,\u201d he says. See Correspondence \u2014  Drug screening: Don't discount all curcumin trial data \n                 Tweet \n                 Follow @NatureNews \n               \n                     Drug screening: Don't discount all curcumin trial data 2017-Mar-01 \n                   \n                     Scientists unite to warn against flawed chemical reagents 2015-Jul-21 \n                   \n                     Chemistry: Chemical con artists foil drug discovery 2014-Sep-24 \n                   \n                     Traditional drug-discovery model ripe for reform 2011-Mar-02 \n                   Reprints and Permissions"},
{"file_id": "541143a", "url": "https://www.nature.com/articles/541143a", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "US National Science Foundation looks to slash funding for Puerto Rico\u2019s Arecibo Observatory. Grapevine, Texas It is the radio telescope that hunts killer asteroids, probes distant cosmic blasts and decades ago sent Earth\u2019s most powerful message to the stars. Yet the storied Arecibo Observatory, an enormous aluminium dish nestled in a Puerto Rican sinkhole, might soon find itself out of the science game. The US National Science Foundation (NSF), which owns the observatory, wants to offload the facility to free up money for newer ones. In the coming weeks, it will ask for ideas about how Arecibo might be managed if the NSF reduces its current US$8.2-million annual contribution. By May, the agency plans to release a final environmental-impact statement, a federally mandated analysis of the effects of various scenarios \u2014 from continuing to run Arecibo to mothballing or even demolishing its iconic dish. Soon after that, the NSF will decide which path to take. Arecibo advocates are not going to let the telescope die without a fight. On 4\u00a0January, they pressed their case at a meeting of the American Astronomical Society in Grapevine, Texas \u2014 arguing that Arecibo is putting out some of the best science it has ever done, and that the NSF is moving too quickly to divest itself of an astronomical treasure. \u201cArecibo definitely has a future,\u201d says Francisco Cordova, the observatory\u2019s director. \u201cThough it will be a different future.\u201d Arecibo is playing a key part in illuminating the mystery of fast radio bursts, which are emerging as a completely new class of celestial phenomenon. And at the astronomy meeting, observatory scientists revealed a previously unknown contributor to the Universe\u2019s cosmic microwave background glow \u2014 cold electrons \u2014 plus a pair of pulsars that has surprisingly erratic radio emissions. \u201cIt is still a state-of-the-art observatory,\u201d says Nicholas White, senior vice-president for science at the Universities Space Research Association in Columbia, Maryland, which helps to manage Arecibo for the NSF. NSF officials agree. But they say they need money for new projects such as the Large Synoptic Survey Telescope, which is under construction in Chile (see \u2018On the block\u2019). A 2012 review of the NSF\u2019s astronomy portfolio recommended cutting support for some of its smaller and older facilities. Although Arecibo was not among them, the report recommended that the NSF evaluate the facility\u2019s status later in the decade. \n               On the block \n               Some of the observatories targeted in the review have found potential partners: New Mexico State University in Las Cruces is leading an effort to take over the Dunn Solar Telescope in Sunspot, New Mexico. Others remain in limbo, including the 100-metre radio telescope in Green Bank, West, where university partners have offered limited help. In October, the NSF released a draft environmental impact statement for Arecibo that outlines how various management options would affect everything from endangered plants to local tourism. The NSF would prefer to find collaborators to shoulder most of the cost of operating the observatory for science purposes. But the draft statement includes the possibility of shuttering the facility, and even details which explosive would be needed to dismantle the 305-metre-wide dish. NSF officials included this bleak option to satisfy federal rules that require them to describe the environmental impact of all possible outcomes. \u201cWe specifically leaned towards making things look a bit more drastic,\u201d says James Ulvestad, head of the NSF\u2019s astronomy division. Gravitational-wave astronomers are among those who are unhappy about the idea of Arecibo going offline. The international NANOGrav consortium uses about 850\u00a0hours of Arecibo time each year to discern how ripples in space-time affect radio pulsars. Between Arecibo and Green Bank, the team is just now reaching the sensitivity at which it should be able to detect gravitational waves. \u201cWe\u2019re so close,\u201d says Xavier Siemens, an astrophysicist at the University of Wisconsin\u2013Milwaukee. \u201cLosing Arecibo would mean losing US leadership in the field.\u201d Arecibo also has a unique role in stimulating public interest in science, says Edgard Rivera-Valent\u00edn, a planetary radar specialist at the observatory. Like many Puerto Ricans, he first visited Arecibo as a child, on a family trip. \u201cIt just blew me away,\u201d he says. \u201cI knew pretty much then that I wanted to do astronomy.\u201d The NSF pays for roughly two-thirds of Arecibo\u2019s $12-million annual budget. Half of that comes from its astronomy division and half from its atmospheric and geospace sciences division, which uses Arecibo to study Earth\u2019s ionosphere. The remainder comes from NASA, which tracks near-Earth asteroids from Arecibo and would probably keep doing so if other collaborators stepped in to make up for NSF cutbacks. Arecibo\u2019s current operating contract ends in March 2018. After that, new approaches to make ends meet could include charging scientists hourly rates to use the observatory, instead of having them apply for time through federal agencies. \u201cThis is where the rubber hits the road,\u201d says White. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     Arecibo Observatory hit with discrimination lawsuit 2016-Oct-13 \n                   \n                     Arecibo Observatory director quits after funding row 2015-Nov-09 \n                   \n                     US struggles to offload telescopes 2014-Jan-28 \n                   \n                     US telescopes face up to agency cuts 2012-Aug-21 \n                   \n                     Arecibo Observatory \n                   \n                     NSF environmental review of Arecibo \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21275", "url": "https://www.nature.com/articles/nature.2017.21275", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Long-hypothesized brain cells give bats their distance and angle to a location. Bats have brain cells that keep track of their angle and distance to a target, researchers have discovered. The neurons, called \u2018vector cells\u2019, are a key piece of the mammalian\u2019s brain complex navigation system \u2014 and something that neuroscientists have been seeking for years. Our brain\u2019s navigation system has many types of cells, but a lot of them seem designed  to keep track of where we are . Researchers know of \u2018place\u2019 cells, for example, which fire when animals are in a particular location, and \u2018head direction\u2019 cells that fire in response to changes in the direction the head is facing. Bats also have a kind of  neuronal compass  that enables them to orient themselves as they fly. The vector cells, by contrast, keep spatial track of where we are going. They are in the brain\u2019s hippocampus, which is also where \u2018place\u2019 and \u2018head-direction\u2019 cells were discovered. That\u2019s a surprise, considering how well this area has been studied by researchers, says Nachum Ulanovsky, who led the team at the Weizmann Institute of Science in Rehovot, Israel, that discovered the new cells. His team published their findings in  Science  on 12 January 1 . \n             360-degree approach \n           Finding the cells \"was one of those very rare discovery moments in a researcher\u2019s life,\u201d says Ulanovsky. \u201cMy heart raced, I started jumping around.\u201d The trick to finding them was a simple matter of experimental design, he says. Most navigation research has been carried out in rats, which tend to slink close to walls. No-one had monitored animals' brains while they navigated to a goal in the centre of a room. But Ulanovsky\u2019s team developed techniques for studying the system in Egyptian fruit bats (Rousettus aegyptiacus), whose heads are large enough to carry the experimental equipment as the animals fly towards a centrally located perch. The team screwed tiny wireless devices into the skulls of three bats to track their flight paths and collect data from electrodes implanted inside their hippocampi. They released the bats into a large flight room with a perch bearing bananas, the fruit bat\u2019s favourite meal, at its centre. Freed from smaller cages, the bats would exuberantly loop-the-loop before heading towards the food. Having the goal in the centre of the room, so that approach paths covered 360 degrees, turned out to be the essential element in pinpointing the vector cells. It meant that the team could verify that the same neurons were firing whatever the direction of approach. \n             Hidden goal \n           In one experiment, the researchers were able to monitor 309 neurons in the three bats. Around one-third of these neurons were simple place cells, firing when the bats flew over a particular spot. But 58 were tuned to the angular direction of the destination. A majority of these vector cells fired at their highest rates when the bat was heading directly to the goal. The neurons remained tuned to goal direction throughout the bats\u2019 long and convoluted flights. Forty-nine neurons responded to distance to goal, and most fired at their highest rates when the bat was within two metres. Twenty-four cells were tuned to both angle and distance. In the wild, a favourite fruit tree would usually be hidden behind other trees or over a hill, and so the bat \u2014 and its vector cells \u2014 would need to remember where that target was, says Ulanovsky. To mimic this scenario, the team hid the fruit stand against a wall and fixed a plastic curtain floor-to ceiling in front of it. The curtain was opaque to vision and echolocation and did not let odours through. The bats were able to fly around it. But on one side of it, they could no longer see the bananas, Still, when the bats were on this side, the vector cells maintained their tuning to the remembered goal. \u201cThis suggests that the vector cells are indeed memory-based rather than sensory-based,\u201d says Ulanovsky. \n             A window into Alzheimer\u2019s? \n           The new find \u201cmakes us rethink how the navigation system works as a whole,\u201d says Edvard Moser, who is founding director of the Kavli Institute for Systems Neuroscience in Trondheim, Norway. Moser  shared the 2014 Nobel Prize in Physiology or Medicine  for key discoveries in brain navigation. Moser says researchers will now hope to find the same cells in rats. The discovery raises a slew of questions about how navigation circuitry works as a whole. The brain might also have other ways to compute goal trajectories without having specialized cells for it, he says. \u201cThis is a fascinating finding,\u201d adds cognitive neuroscientist Howard Eichenbaum of Boston University, Massachusetts. In 1987, Eichenbaum identified cells in rat brains that seem to fire when rats approach a target 2 . In his view, the connection with the hippocampus suggests that navigation may just be \"a really complicated memory task.\u201d Perhaps, researchers think, this is why people with Alzheimer\u2019s disease lose their way easily \u2014 along with losing their memories. \n                   Technology: Use or lose our navigation skills 2016-Mar-30 \n                 \n                   \u2018Speedometer\u2019 neurons discovered in rat brains 2015-Jul-15 \n                 \n                   'Bat-nav' system enables three-dimensional manoeuvres 2014-Dec-04 \n                 \n                   Laboratory of Nachum Ulanovsky \n                 \n                   Moser group \n                 \n                   Laboratory of Cognitive Neurobiology, Boston University \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21292", "url": "https://www.nature.com/articles/nature.2017.21292", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Stimulating certain areas of the animals\u2019 brains can trigger predatory behaviours including biting and grabbing. Researchers have found a switch that seems to turn on a mouse\u2019s predatory instincts. When certain parts of the rodents\u2019 brains were stimulated with light, mice displayed a complex array of hunting activities. Predatory behaviours  such as grabbing and biting are familiar to fans of nature documentaries, but the brain circuits involved remain a mystery. Previous research found that the central amygdala, an almond-shaped area of the brain  involved in producing emotions including fear , was activated when rats hunt 1 . Researchers wanted to know whether the amygdala itself controls hunting behaviours, and a study published on 12 January in  Cell 2  suggests that it does. To activate the central amygdala in mice, Ivan de Araujo, a neurobiologist at Yale University in New Haven, Connecticut, and his colleagues used a technique called  optogenetics . First, they infected the mice with a virus that made the neurons in their brains sensitive to blue light. Then, the researchers used a tiny optic fibre to shine a blue laser on the amygdala. This prompted the animals to tense their jaw and neck muscles. The behaviour didn\u2019t occur when the researchers stimulated other parts of the brain. When the laser was on, the mice hunted just about everything placed in their paths, from edible treats such as crickets to non-food items like bottle caps. The researchers observed the same activity when they triggered the amygdala with chemogenetics, a similar technique that stimulates neurons with molecules rather than light. The hunting and feeding behaviours even happened when there was nothing to hunt. When mice in empty cages had their amygdalas activated, they stopped whatever they were doing, positioned their front legs as if they were holding food and moved their mouths as if they were chewing. \n             Friend vs. food \n           But this doesn\u2019t mean that researchers have found the neural circuit for ravenous, murderous mice, says de Araujo. \u201cThe first thing we thought was, maybe this was just generalized aggression. Or maybe we just made the mice very hungry.\u201d So the team tested that. Although the light-stimulated mice hunted more than the ones left alone, both groups ate the same amount. And the laser-activated mice could still tell the difference between friend and food: \u201cWhen they were with another mouse, they might have become more curious, but we didn\u2019t observe any attacks,\u201d says de Araujo. This left him fairly certain that the experiments were triggering predation, not hunger or aggression. This is significant because predation is a very complex behaviour, says Kay Tye, a neuroscientist at the Massachusetts Institute of Technology in Cambridge. \u201cIt\u2019s not just physiological, it\u2019s hunting, biting, releasing and eating. Those are motor sequences that require a lot of information, so it\u2019s remarkable you can get this behaviour with that sort of gross manipulation.\u201d \n             Opening the door \n           Scientists once thought that the central amygdala\u2019s role in behaviour was limited to fear. But research has now shown that this area of the brain is implicated in a number of complex behaviours such as grooming 3 . Tye thinks that predation is one more example of the many things it can trigger. Because the central amygdala is involved in so many different behaviours, she says, future research needs to tease out the precise neuronal circuits involved in hunting. \u201cThe central amygdala has been linked to escape and flight \u2014 this is completely different from that.\u201d A hunting animal is seeking something out for a reward, she explains, whereas a creature in escape or flight mode is actively avoiding something. Tye wants to know how much overlap there is between the circuits that control the two behaviours. She thinks that the amygdala might be acting as a \u2018gate\u2019, holding back a variety of programmes that are constantly running in the background of the brain. If that\u2019s the case, de Araujo and his colleagues may have discovered the door for hunting behaviours. \n                   Laser used to control mouse's brain \u2014 and speed up milkshake consumption 2016-Nov-17 \n                 \n                   Light-controlled genes and neurons poised for clinical trials 2016-May-19 \n                 \n                   Brain-manipulation studies may produce spurious links to behaviour 2015-Dec-09 \n                 \n                   Rethinking predators: Legend of the wolf 2014-Mar-07 \n                 \n                   Researchers scare 'fearless' patients 2013-Feb-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21291", "url": "https://www.nature.com/articles/nature.2017.21291", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "But Rex Tillerson, Trump\u2019s pick for secretary of state, tells senators that efforts to predict climate change are \u2018very limited\u2019. Rex Tillerson, US president-elect Donald Trump\u2019s nominee for the post of secretary of state, says that the United States should remain part of  the 2015 Paris climate agreement . \u201cIt\u2019s important that the US maintain its seat at the table,\u201d Tillerson told the Senate Committee on Foreign Relations during his confirmation hearing on 11 January. The threat of global warming is real and \u201crequires a global response\u201d, he added. \u201cNo one country is going to solve this on its own.\u201d As the top US diplomat, Tillerson \u2014 who was chief executive of oil giant ExxonMobil until his nomination \u2014 would lead international climate negotiations for the Trump administration. He declined to discuss how his own positions conflict with those of Trump,  who has questioned climate science  and promised to pull the United States out of the Paris agreement. Tillerson told senators that a carbon tax is the wisest way to reduce the greenhouse-gas emissions that drive global warming. But he stressed that the state department does not oversee domestic climate policy. Tillerson baulked at questions about ExxonMobil\u2019s financial support of scientists and groups that deny climate science and oppose climate regulations, saying he could no longer speak on behalf of the company. When a Democratic senator asked whether Tillerson lacked the knowledge to respond or was just refusing to, Tillerson said \u201ca little of both\u201d. \n             In the hot seat \n           When asked whether greenhouse-gas emissions from human activities cause climate change, Tillerson said that \u201cthe increase in greenhouse-gas concentrations in the atmosphere [is] having effect\u201d. But, he added, \u201cour ability to predict that effect is very limited\u201d. Tillerson\u2019s comments are encouraging, but insufficient, says David Waskow, who directs the International Climate Initiative at the World Resources Institute, an environmental think tank in Washington DC. \u201cBoth Trump and Tillerson have wavered on climate science in the past,\u201d he said. \u201cTheir actions over the coming weeks and months will surface whether or not they are committed to sound science, and policies founded on sound science.\u201d Tillerson\u2019s comments came during an initial session that lasted more than six hours. The hearing often centred on the US relationship with a resurgent Russia, which US intelligence agencies say worked to interfere with the US election on behalf of Trump. The  international agreement to limit Iran\u2019s nuclear programme  came up only briefly. Tillerson stopped short of criticizing the deal \u2014 which Trump has done \u2014 but said that he would conduct a full review of the pact. \u201cThe current agreement does freeze their ability to progress,\u201d Tillerson said of Iran, \u201cbut it does not ultimately deny them the ability to have a nuclear weapon.\u201d\u00a0 That is not enough, he told senators. \u201cWhat comes at the end of this agreement must be a mechanism that does in fact deny Iran the ability to develop a nuclear weapon.\u201d \n                   US Earth scientists plan for uncertain future under Trump 2016-Dec-20 \n                 \n                   Trump's pick for energy secretary once sought to eliminate DOE 2016-Dec-13 \n                 \n                   What Trump\u2019s pick for secretary of state could mean for climate policy 2016-Dec-13 \n                 \n                   Trump\u2019s pick for environment agency chief sued government over climate rules 2016-Dec-07 \n                 \n                   Iranian researchers welcome nuclear deal 2015-Jul-15 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21242", "url": "https://www.nature.com/articles/nature.2017.21242", "year": 2017, "authors": [{"name": "Valeria Rom\u00e1n"}], "parsed_as_year": "2006_or_before", "body": "Young scientists angry at budget cuts say they have been denied permanent jobs. Hundreds of young researchers occupied Argentina\u2019s science ministry in Buenos Aires last month, angry at budget cuts that they say have denied them permanent jobs at the country\u2019s National Scientific and Technical Research Council (CONICET). The occupation was the most extreme action yet by Argentinian scientists after  months of protests at last year\u2019s budget , the first under President Mauricio Macri. And the occupation seems to have paid off, in part: many of those involved have been offered extensions to their fellowships. In the week from 19 December, around 200 people slept overnight in the ministry building, and more than 1,000 joined rallies outside. Then, on 23 December, ministry officials agreed to a compromise that dispersed the crowds. There would be no extra permanent research positions, but hundreds of scientists on temporary CONICET fellowships have been offered at least a year\u2019s extension to their contract. \u201cOur protest worked. It was a historic event. It prevented hundreds of young scientists from being left without wages,\u201d says psychologist Mar\u00eda Julia Hermida, who took part in the protests. Hermida is on a CONICET-funded fellowship at the privately run Center for Medical Education and Clinical Research in Buenos Aires; she had hoped for a permanent CONICET job, but is making do with the fellowship extension. \n             Temporary fix \n           Still, the deal hasn\u2019t solved researchers\u2019 problems, scientists say. \u201cThe agreement was just a palliative solution,\u201d says Andr\u00e9s Cernadas, a geneticist at the University of Buenos Aires school of agronomy. On 29 December, some 200 scientists met at C\u00f3rdoba National Observatory to discuss how to continue their campaign for new permanent jobs and a higher science budget. CONICET, a research institute that employs some 9,600 research staff, had hoped to expand its staff by 10% each year until 2019, following a national innovation plan that was announced in 2013. And the agency seemed to be on track to meet that goal. When Macri became president in December 2015, he pledged to boost Argentina\u2019s science spending further. Accordingly, some 1,500 scientists applied last year for new CONICET jobs (to start in 2017), and 874 of them received positive evaluations \u2014 a recommendation that would normally lead to a salaried position. But Argentina\u2019s science budget, passed on 30 November, gave CONICET only a 6% pay rise, once inflation is taken into account \u2014 meaning that the council could hire only around half of its recommended applicants. Groups of young researchers and trade-union representatives marched on CONICET\u2019s building in protest, and then decided to occupy the science ministry, next door. \u201cI know the peaceful occupation of the ministry is an extreme measure, but we did not have any other option,\u201d says Julieta Haidar, a political scientist at the University of Buenos Aires, and one of those who slept in the ministry overnight. The occupation didn\u2019t disrupt the work of ministry employees, she says. People who lived in nearby apartments brought the occupiers pizza and drinks. The protest was also supported by senior Argentinian scientists, some of whom turned up mid-week to deliver speeches. \n             Mixed results \n           The compromise deal means that about 400 researchers (including Haidar and Hermida) have had their CONICET fellowships extended to the end of 2017 or, in some cases, to March 2018 \u2014 and around 100 have been given new fellowships. Some scientists will work at other Argentinian institutes or universities, albeit on CONICET\u2019s payroll. Funding for the positions will be reassigned from CONICET\u2019s existing budget,  Argentina\u2019s science minister, Lino Bara\u00f1ao , told  Nature , although he did not make clear which areas would be cut. Bara\u00f1ao also said that increasing CONICET\u2019s staff by 10% each year no longer looks realistic. The occupation shows the depth of feeling in the science community against budgetary restrictions put in place under Macri, says Rolando Gonz\u00e1lez-Jos\u00e9, an evolutionary biologist who directs the Patagonian Institute of Social Sciences in Puerto Madryn. He is part of a group of concerned scientists, called Science and Technology Argentina, who in October coordinated a petition against Macri\u2019s first budget, which had proposed deeper cuts for science. \u201cIt is clear that in Argentina and other Latin American nations, technological innovation is now not seen as the key to economic development,\u201d he says. \n                   Argentina president's first budget angers scientists 2016-Nov-17 \n                 \n                   A tale of two governments: the politician behind Argentina's science growth 2016-Aug-16 \n                 \n                   What Argentina\u2019s financial woes mean for science 2014-Aug-21 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21656", "url": "https://www.nature.com/articles/nature.2017.21656", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Treatment reduces the risk of heart attack and stroke, but might not live up to outsized expectations. For years, medical researchers have hoped that a burgeoning class of cholesterol drugs targeting a protein called PCSK9 could be the  next generation of blockbuster treatments . Now, a large clinical trial has demonstrated that this approach can lower the risk of heart disease. But it\u2019s still unclear whether these drugs \u2014 which attempt to mimic a beneficial genetic mutation \u2014 will be the breakthrough that scientists and pharmaceutical companies had imagined. The results, published in the  New England Journal of Medicine 1  and presented at the American College of Cardiology conference in Washington DC on 17 March, show that a drug called evolocumab (Repatha) reduced the risk of cardiovascular death, heart attack and stroke by about 20% in patients who were already taking other cholesterol-controlling drugs called statins. This reduction in risk is roughly the same magnitude as patients might see from taking statins alone. On another measure that also included hospitalizations for conditions that cause reduced blood flow to the heart, evolocumab reduced the risk by 15%. The US Food and Drug Administration (FDA) approved evolocumab in 2015 for use in some patients with high cholesterol, based on data showing that the drug could lower levels of \u2018bad\u2019 low-density lipoprotein (LDL) cholesterol circulating in the blood by approximately 60% 2 . But researchers didn\u2019t have evidence then that the drug could also protect against heart attacks or strokes. \u201c It is an exceptionally important study,\u201d says Harlan Krumholz, a cardiologist at Yale University in New Haven, Connecticut. \u201cThe promise of these drugs has been very clear. Whether they would deliver on that promise was suspected, but not known.\u201d The new results \u2014 from a trial with more than 27,500 participants \u2014 vindicate the concept that inhibiting PCSK9 can control cholesterol and heart-disease risk. The question now is whether physicians and health-care payers will consider that benefit great enough to warrant the annual price tag of roughly US$14,000. \n             Rough road \n           The PCSK9 protein helps to control the amount of bad cholesterol in the blood by regulating the number of LDL receptor proteins on cell surfaces, which take LDL out of circulation. People with naturally occurring mutations in the  PCSK9  gene have unusually low levels of bad cholesterol \u2014 and up to an  88% lower risk of developing heart disease . Turning that information into a successful treatment, however, has been a challenge. Several drugs that target PCSK9 are either in development or have been approved, but evolocumab is the first to report results from such a large trial. Pfizer, based in New York City, abandoned a PCSK9-blocking drug called bococizumab last year after running into problems during patient trials. Bococizumab, like evolocumab, is an antibody that binds to the PCSK9 protein. But participants who received bococizumab tended to form an immune response against the drug, which interfered with the treatments 3 . And the FDA approved evolocumab, made by Amgen in Thousand Oaks, California, only for certain patients, such as those with a hereditary condition that causes extremely high levels of LDL. \n             Worth any price? \n           Now that the data on evolocumab are in, some health-care payers such as insurance companies and government programmes might be more willing to shoulder the treatment\u2019s steep cost. But any new cholesterol drug faces stiff competition from cheaper statins, which have been used to control LDL levels for decades. Some analysts say that demonstrating a statistically significant heart-health benefit would not be enough to ensure the PCSK9 drug\u2019s status as the next big thing. \u201cThe more important hurdle is the one that payers have imposed restricting access to these medicines,\u201d wrote analysts at the investment bank Leerink Partners in New York City, in a report released 15 March. To cross that threshold, Leerink\u2019s analysts estimated that evolocumab would need to reduce cardiovascular risks by 25% or more. Overall, the risk reduction was less than what might have been expected based on how much evolocumab reduces the amount of LDL cholesterol in the body, says Krumholz. But the evidence of a benefit is strong enough that he will discuss the drug as an option with his patients, he adds. \n                   Geneticists tap human knockouts 2014-Oct-28 \n                 \n                   Genetics: A gene of rare effect 2013-Apr-09 \n                 \n                   Cholesterol limits lose their lustre 2013-Feb-26 \n                 \n                   US National Institutes of Health Genetics Home Reference: PCSK9 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21660", "url": "https://www.nature.com/articles/nature.2017.21660", "year": 2017, "authors": [{"name": "Michele Catanzaro"}], "parsed_as_year": "2006_or_before", "body": "Academics call for the release of Ahmadreza Djalali, who has been imprisoned without trial since last April. An Iranian researcher jailed in Tehran for the last 11 months is in declining health after spending more than two months on hunger strike. This month, researchers around the world made urgent appeals for his release.\u00a0 Ahmadreza Djalali, a researcher in disaster medicine and a resident of Sweden, was arrested on an academic visit to Tehran in April 2016. On 11 March he was brought to a prison hospital after he refused to eat in protest at being threatened with the death sentence and at being denied his choice of lawyer. Djalali, who still awaits trial, has experienced kidney and heart pain and for a week in late February refused to take liquids, says his wife, Vida Merhannia. He has lost 30% of his body weight since he entered prison. Djalali, 45, works on improving hospitals\u2019 emergency responses to armed terrorism and radiological, chemical and biological threats. He has affiliations with Sweden\u2019s Karolinska Institute in Stockholm and Italy\u2019s University of Eastern Piedmont in Novara. But on 25 April 2016 he was arrested and accused of \u201ccollaboration with a hostile government\u201d. According to his wife, he was kept in solitary confinement for three months, and forced to sign a confession. Djalali began a first hunger strike in late December in protest against what he has told his wife is a false accusation. In late January, a judge on Iran\u2019s revolutionary court threatened him with a death sentence. He stopped his strike on 15 February, but resumed it three days later after the judge ordered him to change his lawyer or choose a court-appointed one. His trial has not yet been scheduled. \n             Petition organized \n           On 9 March, Djalali\u2019s colleagues, together with the Committee of Concerned Scientists in New York and human-rights groups such as Amnesty International and Scholars at Risk,  wrote to the Iranian authorities  to ask that Djalali be given due legal process and released, unless charged with a \u201crecognizable criminal offence\u201d. Djalali\u2019s case has drawn particular attention in Italy, in part because of his Eastern Piedmont connections. Parliamentarians there have protested to the Iranian ambassador, and Elena Cattaneo, a senator and stem-cell researchers at the University of Milan, said she would refuse to attend a July conference on stems cells in Iran in protest.\u00a0 It\u2019s unclear why the Iranian government has arrested Djalali, says his colleague Luca Ragazzoni, a health researcher at the University of Eastern Piedmont, who worked with him from 2012 to 2015. In a separate case, physicist Omid Kokabee \u2014  released from a Tehran jail in August 2016 after five years imprisonment  \u2014 believes he himself was punished for refusing to help a covert nuclear-weapons programme. But Ragazzoni says that disaster health research is less controversial. \u201cThe data we work with are not sensitive, and we publish all our results: I don\u2019t see what else a government should be interested in,\u201d he says. He thinks the group\u2019s international collaborations may have raised suspicion. \n             Imprisoned scentists \n           The US\u2013Iran nuclear deal in 2015 had sparked hopes of greater academic freedom in Iran. But since that agreement, other researchers besides Djalali have been imprisoned or sentenced. They include Homa Hoodfar, a Canadian\u2013Iranian social anthropologist who was arrested in March 2016 and charged with \u201cdabbling in feminism and security matters\u201d, before being released on \u201chumanitarian grounds\u201d 112 days later; and retired Iranian polymer scientist Mohammad Hossein Rafiee-Fanood, who was sentenced to six years in prison in May 2015 for political activism, and was released on medical furlough last year. Hamid Babaei, an Iranian mathematics student who was studying for a PhD in finance at the University of Li\u00e8ge in Belgium when he was arrested in August 2013, remains in prison on a six-year sentence for \u201cspying and contact with enemy states\u201d. He says that he was imprisoned for refusing to be an informant in Belgium for Iran\u2019s intelligence ministry. \"Iranian scientists enjoy access to world institutions and the worldwide web of scientific information. But they do not enjoy freedom of political dissent. The nuclear deal has not changed this situation by an inch,\" says Eugene Chudnovsky, a physicist at the City University of New York who is co-chair of the Committee of Concerned Scientists. \n                   Iran releases physicist after five years in jail 2016-Aug-29 \n                 \n                   Iranian researchers welcome nuclear deal 2015-Jul-15 \n                 \n                   Iran needs to present a united front on science 2014-Apr-23 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21685", "url": "https://www.nature.com/articles/nature.2017.21685", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Editors are more likely to select reviewers of the same gender. In many scientific fields, women publish fewer papers than men, are less likely to be listed as first authors 1  and are less likely to receive\u00a0 glowing letters of recommendation \u00a0from their advisers 2 . These disparities have\u00a0 decreased over time, but they persist . Now, a study finds that some journal editors might be inadvertently taking gender into account when selecting reviewers for papers. They found that, on average, male editors were much more likely to pick male reviewers, whereas female editors were more likely to pick other women. This bias was stronger for men, the researchers report in a study 3  published on 21 March in  eLife . Previous papers have looked at gender bias in peer review, but most of them have focused on one field. But this latest study analysed 142 journals in the Frontiers family of publications across science, health, engineering and social sciences. \u201cThe quality of scientific work is not determined by gender,\u201d says Markus Helmer, a computational neuroscientist, and the lead study author, who performed most of the work while at the Max Planck Institute in G\u00f6ttingen, Germany. \u201cSo if gender is impacting which reviewers are chosen, that means journals are not getting the highest-quality reviewers.\u201d Jennifer Glass, a sociologist at the University of Texas, Austin says this is similar to what happens on corporate boards. By limiting board members \u2014 or journal reviewers \u2014 to one gender, these groups can overlook some of the top candidates. Helmer, now at Yale University in New Haven, Connecticut, was surprised to see that gender bias in peer review existed across the fields of science that he and his colleagues surveyed. \n             Gender gap \n           Because Frontiers journals make public the identities of their editors and reviewers, Helmer\u2019s team was able to look at more than 9,000 editors and 43,000 reviewers of studies published between 2007 and 2015. They found the overall pattern among journal editors after controlling for the number of men and women who have published in each field. And they were also able to see the gender bias of individual reviewers. Helmer and his colleagues found that bias was widespread across male editors, but for women, the overall effect seemed to be driven by just a few female editors. When researchers removed those outliers from the data set, female editors\u2019 preference for female reviewers disappeared. Marcia McNutt, president of the US National Academy of Sciences and former editor-in-chief of\u00a0 Science , thinks that the data are solid, and she is happy to see this disparity documented. But she also thinks that there is a major gap in the study\u2019s design: the data set shows only the numbers of men and women who actually reviewed papers, not how many were asked to perform a review. A previous study of geophysical journals found that women between 20 and 80 years of age decline the invitation to review papers more often than men 4 . Dana Britton, a sociologist at Rutgers University in New Brunswick, New Jersey, also notes this hole. \u201cThey leave out any consideration of people\u2019s willingness to respond to review requests,\u201d she says. \u201cSo, it could be that the initial pool of choices is more diverse than the ultimate pool of reviewers.\u201d \n             The people you know \n           Helmer and his colleagues suggest that the editors\u2019 preferences for reviewers of their own gender could be due to differences in the way that men and women construct their social networks, or humans\u2019 supposed innate tendency to associate with people with similar qualities. They also suggest that some female editors might be attempting to make their field more egalitarian by deliberately picking female reviewers. McNutt thinks that such bias might have less to do with human nature and more to do with social networks. \u201cI have my network of go-to scientists, and most of them are women,\u201d she says. \u201cWomen scientists also tend to mentor women students, and that expands their network.\u201d Britton agrees, saying that men in the US and Europe tend to be full professors. \"These men are more likely to know each other, and to consider each other experts in their field,\u201d she explains. So biases in peer review could be the result of existing disparities in academia. \n                   Patchy progress on fixing global gender disparities in science 2017-Mar-08 \n                 \n                   Women postdocs less likely than men to get a glowing reference 2016-Oct-03 \n                 \n                   Gender bias found in Earth-science society journals 2016-Sep-29 \n                 \n                   In business as in science, prejudice holds women back 2014-Mar-10 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21235", "url": "https://www.nature.com/articles/nature.2016.21235", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Repeating bursts come from a faint, distant dwarf galaxy. Astronomers have pinpointed the location of an enigmatic celestial object that spits out brief, but powerful, blasts of radio waves. Surprisingly, the source of these intermittent signals lies not in a bright galaxy but in a small, dim one, some 2.5 billion light-years from Earth. The discovery begins to lift the curtain on the mystery of fast radio bursts,  which have puzzled astronomers since they first described the signals in 2007 1 .  \u201c This detection has really broken open the gates of a new realm of science and discovery,\u201d says Sarah Burke-Spolaor, an astronomer at the National Radio Astronomy Observatory in Socorro, New Mexico, and West Virginia University in Morgantown. She spoke in Grapevine, Texas, at a meeting of the American Astronomical Society. Fast radio bursts appear to come from beyond the Milky Way and crop up seemingly at random across the sky. Although they last just milliseconds, the radio blasts can emit as much power as 500 million Suns. The bursts were first spotted by the Parkes radio telescope in New South Wales, Australia, and fewer than 20 have been found so far. Most were discovered in wide-field searches that cannot pinpoint exactly where they come from \u2014  which makes it harder for astronomers  to winnow down possible explanations for what causes them. \n             A puny host \n           The latest work, published on 4 January in  Nature 2 , is the sharpest look yet at the home of a fast radio burst known as FRB 121102. Located in the constellation Auriga, the intermittent signal was first detected on 2 November 2012. Since then, it has flared up several times, making it the only fast radio burst known to repeat 3 . A team led by Shami Chatterjee, an astronomer at Cornell University in Ithaca, New York, began with the 305-metre-wide Arecibo radio telescope in Puerto Rico. Its sensitivity allowed the scientists to detect multiple bursts from FRB 121102. The team then used two sets of radio telescopes \u2014 the Karl G. Jansky Very Large Array in New Mexico, and the European VLBI Network across Europe \u2014 to narrow down the location of FRB 121102 even further 4 . The bursts originate from a dwarf galaxy that emits faint radiation in both radio and visual wavelengths. Follow-up observations with the Gemini North telescope, on Mauna Kea, Hawaii, showed that it is less than one-tenth the size and has less than one-thousandth the mass of the Milky Way 5 . \u201dThe host galaxy is puny,\u201d says team member Shriharsh Tendulkar, an astronomer at McGill University in Montreal, Canada. \u201cThat's weird.\u201d With fewer stars than many galaxies, dwarf galaxies would seem to have less of a chance of hosting whatever creates fast radio bursts. That would include neutron stars, one of the leading candidates for the source of fast radio bursts. But much more work is needed to pin down the physical mechanism of what causes these mysterious bursts, says Chatterjee. For now, FRB 121102 is just one example. That need could be filled later this year when a  new radio telescope comes online in British Columbia , Canada, dedicated to hunting fast radio bursts. See the related News & Views article, ' Radio burst caught red-handed '. \n                   Long-sought signal deepens mystery of fast radio bursts 2016-Nov-17 \n                 \n                   Why ultra-powerful radio bursts are the most perplexing mystery in astronomy 2016-Jun-28 \n                 \n                   Fresh confusion over origins of enigmatic radio-wave blasts 2016-Mar-02 \n                 \n                   Mysterious radio burst pinpointed in distant galaxy 2016-Feb-24 \n                 \n                   Fast radio burst catalogue, from Swinburne University of Technology \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21254", "url": "https://www.nature.com/articles/nature.2017.21254", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "House Republicans conclude that tissue from aborted fetuses is of limited value for research and seek to reduce funding. The US government should restrict or eliminate support for research that uses human fetal tissue obtained from abortions because it is of little use to medicine, a special panel of the US House of Representatives said on 3 January. The panel said that the US National Institutes of Health (NIH) should develop a system to determine whether fetal tissue is \u201cthe most appropriate model\u201d for projects seeking government funding. It also urged Congress to commission studies on the feasibility of using tissue from stillborn and preterm infants instead. If that proves viable, the group said, the government should stop funding experiments with tissue from aborted fetuses \u2014 even though dozens of universities and scientific societies  say such research is vital  to  the development of therapies . The recommendations  released by the panel\u2019s Republican majority  come after an extensive probe of the practice of distributing human fetal tissue for research. Scientists reacted strongly to the report. \u201cFetal-tissue research is scientifically important and it should continue to be pursued,\u201d says Larry Goldstein, a neuroscientist at the University of California, San Diego. \u201cThis report is wrong and wrongheaded. It\u2019s driven by ideology, not science.\u201d The House Energy and Commerce Committee created the special panel in 2015, after undercover videos surfaced showing abortion providers and companies that distribute fetal tissue discussing how they gather the tissue, and collect payments for it. The videos caused an outcry \u2014 particularly among Republicans opposed to abortion \u2014 and prompted a series of congressional hearings and investigations. In the aftermath, scientists who work with human fetal tissue  worried that they would be targeted  by anti-abortion groups, and that research with the tissue could be restricted. In  a March 2016 statement signed by 62 institutions and scientific organizations , the Association of American Medical Colleges argued that such research is vital for the development of therapies to treat Parkinson\u2019s disease and Ebola, and has been crucial in the development of many vaccines. Democrats on the investigative panel produced a report in December  largely echoing these sentiments . But the Republican majority determined that such statements were \u201cmisleading and false\u201d. \u201cThe alarmist claims that restrictions on human fetal tissue research would somehow delay or prevent the development of cures are entirely unfounded,\u201d the Republicans wrote. \n             Significant figures \n           They also argued that human fetal tissue is not as important in the development of vaccines as proponents of the research have made it out to be. \"This to me is very, very worrisome,\" says Alta Charo, who studies law and ethics at the University of Wisconsin\u2013Madison. \"They are not only reimagining history but reimagining a future in which all the materials we currently think we need, we don\u2019t actually need.\" Much of the House Republicans\u2019 argument is predicated on the relative rarity of such research: their investigators found that only 329 NIH grants awarded between 2010 and 2014 involved fetal-tissue research, about 0.2% of NIH grants during that time. Few clinical trials use fetal tissue, and the investigators concluded that published research using fetal tissue garners few citations. But this ignores how science works, counters Goldstein. \u201cSomething that\u2019s scientifically important is not necessarily pursued by a lot of people,\u201d he says. \u201cIt\u2019s not a popularity contest.\u201d Fetal tissue is often an integral part of an experimental protocol without being the focus of the experiment itself, he adds, and that may not be apparent in a grant application. A paucity of publications may also reflect the scarcity of fetal tissue. \u201cOf course there are not many publications, because there\u2019s not much of a supply of material \u2014 and that\u2019s fine,\u201d he says. \u201cIt\u2019s used carefully.\u201d \n             Limited supplies \n           Difficulty acquiring such tissue is one reason that physiologist Alan Fine shifted his research programme at Dalhousie University in Halifax, Canada, away from using fetal-tissue transplants to treat neurological diseases. He thinks that such research should continue, but says its benefits are sometimes exaggerated. \u201cThe idea that fetal tissue represents an essential and gold-standard research material for work in many fields \u2014 those claims are a bit of a stretch,\u201d says Fine. \u201cBut people do need to be mindful there may be cases where it is uniquely valuable to work with primary human fetal tissue.\u201d David Prentice, vice-president and research director of the anti-abortion, non-profit Charlotte Lozier Institute in Washington DC, says that such claims are clouded by researchers\u2019 self-interest. \u201cLike anybody, scientists don\u2019t like to be told they can\u2019t do certain things,\u201d he says. \u201cI would say there are probably better and newer alternatives to any type of fresh fetal tissue.\u201d It is unclear how president-elect Donald Trump will view the matter, but Prentice is optimistic that the investigation\u2019s recommendations will be influential in the newly elected Congress. \"They will have a Republican majority in both the House and the Senate,\u201d he says. \u201cI think there is still some will to move ahead with some of these recommendations.\u201d \n                   Zika highlights role of controversial fetal-tissue research 2016-Mar-30 \n                 \n                   Fetal tissue research under threat 2015-Dec-07 \n                 \n                   The truth about fetal tissue research 2015-Dec-07 \n                 \n                   Medical research: Cell division 2013-Jun-26 \n                 \n                   House panel Republicans\u2019 report \n                 \n                   House panel Democrats\u2019 report \n                 Reprints and Permissions"},
{"file_id": "541141a", "url": "https://www.nature.com/articles/541141a", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "iCarbonX believes its cutting-edge partners and generous funding give it the upper hand. Shenzhen One of China\u2019s most intriguing biotechnology companies has fleshed out an earlier quixotic promise to use artificial intelligence (AI) to revolutionize health care. The Shenzhen firm iCarbonX has formed an ambitious alliance with seven technology companies from around the world that specialize in gathering different types of health-care data, said the company\u2019s founder, Jun Wang, on 5\u00a0January at the Digital Life Summit, which was hosted by iCarbonX. The alliance will use algorithms to analyse reams of genomic, physiological and behavioural data and provide customized health and medical advice directly to consumers through an app. The announcement was a long-anticipated debut for iCarbonX, which Wang founded in October 2015 shortly after he  left his leadership position  at China\u2019s genomics powerhouse, BGI, also in Shenzhen. The firm has now raised more than US$600\u00a0million in investment \u2014 this contrasts with the tens of millions that most of  its rivals are thought to have invested  (although several big players, such as Google, have not disclosed exact figures). Initial funding of some $200\u00a0million came mostly from Shenzhen-based Tencent, which owns the social-media application WeChat. At the summit, Wang said that roughly another $400\u00a0million had been invested in the alliance members, but he declined to name the source. Wang also demonstrated the smartphone app, called Meum after the Latin for \u2018my\u2019, that customers would use to enter data and receive advice. As well as Google, IBM and various smaller companies, such as Arivale of Seattle, Washington, are working on similar technology. But Wang says that the iCarbonX alliance will be able to collect data more cheaply and quickly. The tools offered by alliance partners are cutting edge and the set-up will allow different types of data to be integrated seamlessly; moreover, China\u2019s large population is already used to sharing information through WeChat and other social media, Wang notes. \u201cNo one will be able to collect at the same scale that I am doing,\u201d he says. Wang is confident that he can get samples and data from one million people in five years, which in turn will lead to a more informed AI. His plans are driven by frustration with genomics. The largest genomic studies offer only subtle hints about an individual\u2019s susceptibility to disease \u2014 such as pinpointing a gene that makes an individual only one or two per cent more likely to develop heart disease. So, in addition to mining its customer\u2019s genomes, the iCarbonX alliance will scour biological molecules from various tissues to provide a more accurate and actionable picture of someone\u2019s health. Wang chose alliance members for their promise in mining such signals. SomaLogic of Boulder, Colorado, for example, has a chip that can measure some 4,200\u00a0proteins simultaneously. In June, researchers using a commercially available precursor that reads 1,130\u00a0proteins were able to predict which subset of heart-attack patients would have a recurrence by measuring the activity of nine blood proteins ( P. Ganz  et al. J. Am. Med. Assoc.    315,  2532\u20132541; 2016 ). Another alliance member, HealthTell of San Ramon, California, makes a chip that uses microarrays of some 330,000\u00a0protein fragments to fish antibodies from a blood sample to answer questions about disease progress, allergies and vaccine effectiveness ( J.\u00a0B.\u00a0Legutki  et al. Nature Commun.   5,  4785; 2014 ). And another, PatientsLikeMe of Cambridge, Massachusetts, asks its 500,000 or so users to upload to a website less-clear-cut data about pain levels, sleep and fatigue. These are combined with medical data, behaviour patterns and the users\u2019 experiences of diseases and drugs to find patterns that predict such \u2018immeasurables\u2019. The end result will be an unwieldy set of data from various sources, which is why Wang and a team at iCarbonX are developing algorithms to understand how these variables correlate with healthy or diseased states. The Meum app enables users to enter their meals and activity levels, as well as any physiological or vital-sign data, and gives advice on what to eat, when to sleep and how active they should be. Views are mixed about how well the venture will work. The alliance will provide iCarbonX with a collection of high-quality indicators that should reduce noise in the data and allow patterns to emerge, says Bernard Munos, a senior fellow at FasterCures, a drug-development advocacy organization in Washington DC. \u201cThis is very important given the number of variables they will be dealing with.\u201d But he worries about the chaotic behaviour of some of the systems. Alliance member General Automation Lab Technologies of San Francisco, California, will provide personalized assessments of how microbes living on someone\u2019s body may affect their health. But the microbiome is poorly understood and in a constant state of flux, says Munos. \u201cThere is a lot of randomness in biology at the individual level that will be hard to capture, let alone model. I wish them well, but, at the moment, I am guarded as to their chance of success.\u201d Others have faith in Wang. \u201cThere\u2019s no bullshit. He sucks you in with a vision of what can be, and then he makes it happen,\u201d says Larry Gold, founder and chairman of alliance member SomaLogic. Wang is keenly aware that the success of the venture will depend on its users\u2019 readiness to submit data and heed the advice the app gives. He said during one of his many toasts during the summit: \u201cMeum might tell me not to drink, but I don\u2019t have to listen.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     China\u2019s bid to be a DNA superpower 2016-Jun-22 \n                   \n                     China embraces precision medicine on a massive scale 2016-Jan-06 \n                   \n                     Exclusive: Genomics pioneer Jun Wang on his new AI venture 2015-Jul-28 \n                   \n                     Visionary leader of China\u2019s genomics powerhouse steps down 2015-Jul-24 \n                   \n                     iCarbonX \n                   \n                     Digital Life Summit \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21659", "url": "https://www.nature.com/articles/nature.2017.21659", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Landing on Jupiter's moon in search of alien life won't be easy. Sometime in the early 2030s, NASA hopes to attempt a landing on Jupiter\u2019s moon Europa. A four-legged spacecraft would descend towards the icy surface, ready to hunt for signs of alien life in a buried ocean. But Europa could be a treacherous place to land. Its surface may be unexpectedly hard \u2014 or so porous that the probe might sink into it. And giant crevasses threaten to swallow any visitor. With an extremely thin atmosphere, low gravity, and bone-chilling temperatures of just 100 kelvin (\u2013176 \u00b0C), Europa poses formidable challenges to spacecraft engineers. \u201cWe really just don\u2019t know enough,\u201d says Cynthia Phillips, a planetary scientist at the Jet Propulsion Laboratory (JPL) in Pasadena, California. She and others are discussing ideas for a Europa lander this week at the Lunar and Planetary Science Conference in The Woodlands, Texas. Prompted by the US Congress's enthusiasm for visiting icy worlds, NASA is working on  a pair of spacecraft concepts for exploring Europa,  to launch in the 2020s. The first, an ongoing project named Clipper, would fly to the Jupiter system and loop past Europa multiple times, photographing it and creating a new high-resolution map of the world. The second spacecraft \u2014 not yet formally approved, and left out of  President Donald Trump's recent budget proposal for NASA  \u2014\u00a0would follow perhaps several years later and land on the moon. \n             Safe landing \n           One challenge is finding a suitable landing site. Europa\u2019s surface is riven by crevasses,  possibly with geyser-like plumes of water occasionally spurting up through the cracks . One of the top candidates for a landing site is an area called Thera Macula, where iceberg-like blocks jostle against one another in what is evocatively known as \u201cchaos terrain\u201d. Arriving there could be like trying to touch down on a glacier in Greenland spawning ice chunks, says Catherine Walker, a planetary scientist at JPL. \u201cI don\u2019t know if you really want to land on that,\u201d she says. But scientists want to get as close as possible to areas where water could be squirting up from beneath Europa\u2019s icy shell \u2014\u00a0possibly carrying extraterrestrial microbes. Chaos terrains like Thera Macula may lie above shallow liquid water 1 , making them the best chance of finding direct connections between the buried ocean and the surface. \u201cIf we\u2019re right about those areas, maybe things weren\u2019t alive recently but the record of organisms could be more intact,\u201d says Britney Schmidt, a planetary scientist at the Georgia Institute of Technology in Atlanta. If there are at least 100 cells of extraterrestrial organisms in every millilitre of Europan ice, the lander\u2019s instruments could detect them, according to  a NASA report released last month . That\u2019s comparable to the number of microbes in the ice overlying Antarctica\u2019s buried Lake Vostok. \u201cFor the first time in the history of humanity, we have the tools and capability to go and do this great experiment of seeing whether or not biology works beyond Earth,\u201d says Kevin Hand, an astrobiologist at JPL. He co-chaired the new report, which is being discussed this week at the Texas meeting. But so little is known about the surface properties of Europa that planning a lander is like planning the first Moon landings, Phillips says. \n             Cold effect \n           Temperatures are so cold that ice grains on Europa behave very differently from on Earth. Phillips and her colleagues, led by Jamie Molaro at JPL, have been studying how Europan ice grains might 'sinter' or merge together, becoming more dense. Theoretical modelling and lab experiments, intended to grow tiny chunks of Europa-like ice, show how the ice grains begin to stick together over time. That process will affect how the lander's footpads interact with the surface, Phillips says. The lander has to survive intact enough to burrow 10 centimetres into the ice, collecting five samples in 20 days and then analyzing them for signs of life. Current mission designs call for a four-legged lander with a flat belly, able to land on rough ice with unknown properties. It would be the first touchdown in the outer Solar System since 2005, when  the European Space Agency\u2019s Huygens probe parachuted onto Saturn\u2019s moon Titan . \u201cWhen Huygens was built, we had no idea if Titan had a liquid or a solid surface,\u201d Phillips notes. \u201cThat was a crazy engineering challenge.\u201d Europa engineers are facing much the same thing today. \n                   Europa's peek-a-boo plumes confirmed 2016-Sep-26 \n                 \n                   Plate tectonics found on Europa 2014-Sep-07 \n                 \n                   Hubble spots water spurting from Europa 2013-Dec-12 \n                 \n                   Europa Clipper \n                 \n                   Science report on lander concept \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21681", "url": "https://www.nature.com/articles/nature.2017.21681", "year": 2017, "authors": [{"name": "Sid Perkins"}], "parsed_as_year": "2006_or_before", "body": "'Textbook-changing' analysis of dinosaur bones upends long-accepted relationships among major groups. The longstanding division of dinosaurs into 'bird-hipped' species including  Stegosaurus  and their 'lizard-hipped' counterparts such as  Brachiosaurus and   Tyrannosaurus rex  may no longer be valid, a study published on 22 March\u00a0in  Nature  contends 1 . Among the other proposed changes to the dinosaur family tree, the long-necked herbivorous  and often gargantuan sauropods  such as  Brachiosaurus  are no longer as closely related to bipedal, meat-eating theropods such as  T. rex  as they were under previous schemes. \u201cThis is a textbook changer \u2014 if it continues to pan out,\u201d says Thomas Holtz, a vertebrate palaeontologist at the University of Maryland in College Park. \u201cIt\u2019s only one analysis, but it\u2019s a thorough one.\u201d The new study assesses kinship among 74 dinosaur species that span the family tree, on the basis of similarities or differences in more than 450 anatomical features, says Matthew Baron, a vertebrate palaeontologist at the University of Cambridge, UK, who led the study. \n             Dinosaur regrouping \n           Most of the species considered in the analysis lived within the first 100 million years of dinosaurs' reign. The oldest known dinosaur fossil dates from about 243 million years ago, and the last dinosaurs \u2014 along with myriad other creatures \u2014  died en masse around 66 million years ago , leaving the birds as their only descendants, after an asteroid slammed\u00a0into the sea just north of what is now Mexico\u2019s Yucat\u00e1n Peninsula. Baron and his colleagues\u2019 most notable revision grafts the theropod lizard-hipped lineage onto the branch containing all of the bird-hipped (ornithiscian) dinosaurs, such as  Stegosaurus  and  Triceratops . The team\u2019s analysis indicates that members of both major groups share 21 anatomical traits, ranging from a distinctive ridge on their upper jaw to the fusion of particular bones in their feet. For this newly amalgamated branch of the family tree, the team resurrected a group name that was first proposed in the 1870s but later fell out of favour \u2014 the Ornithoscelida, which loosely translated from Greek means 'bird-limbed'. Besides upending decades of accepted wisdom about the relations among various dinosaur lineages, the new study hints that the first dinosaurs might have appeared around 247 million years ago, slightly earlier than previously suspected. They may also have originated in what is now North America, rather than in Gondwana \u2014 the southern portion of the supercontinent Pangaea \u2014 which was presumed to have been the dinosaur cradle. \n             Provocative reassessment \n           In  an accompanying News & Views article 2 , Kevin Padian, a vertebrate palaeontologist at the University of California, Berkeley, calls the team\u2019s findings an \u201coriginal and provocative reassessment of dinosaur origins and relationships\u201d. And because Baron and his colleagues used well-accepted methods, he notes, the results can\u2019t simply be dismissed as a different opinion or as mere speculation. \u201cThis will send people back to the drawing board,\u201d he added in an interview. Hans-Dieter Sues, a vertebrate palaeontologist at the Smithsonian Institution\u2019s National Museum of Natural History in Washington DC, says the study should stoke discussion. \u201cBut I caution against totally reorganizing the dinosaur family tree just yet,\" he says. For one thing, palaeontologists\u2019 analyses of relations among species are keenly sensitive to which species are considered, as well as which and how many anatomical features are included, he says. The discovery of new dinosaur species or more complete specimens of those already known might also drive future analyses back toward more currently accepted arrangements of dinosaur lineages, Sues says. In recent years,  South America has yielded a flurry of new dinosaur discoveries . And, he says, North American rocks laid down during the dinosaurs\u2019 earliest days have yet to be explored as thoroughly as South American rocks of the same age. \u201cFor many regions of the world, there\u2019s so much we don\u2019t know about the fossil record,\u201d he notes. \n                   Horse-sized dinosaur sheds light on T. rex\u2019s origins 2016-Mar-14 \n                 \n                   First dinosaurs arose in an evolutionary eye-blink 2015-Dec-07 \n                 \n                   Beloved Brontosaurus makes a comeback 2015-Apr-07 \n                 \n                   Palaeontology: The truth about T. rex 2013-Oct-23 \n                 \n                   China's dinosaur hunter: The ground breaker 2012-Sep-05 \n                 \n                   Dinosaurs: Rise of the titans 2011-Jul-13 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21803", "url": "https://www.nature.com/articles/nature.2017.21803", "year": 2017, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "Birds were spiritual emblems in pueblos of the southwestern United States and northern Mexico. To ancient peoples of the American Southwest, a macaw\u2019s brilliant feathers weren\u2019t just adornments. They were status symbols and spiritual emblems \u2014 so precious, in fact, that macaws were kept in captivity and deliberately plucked of their plumage, new evidence suggests. Macaw skeletons from three prehistoric pueblos in New Mexico bear signs of feather harvesting, according to analysis presented on 31 March at a meeting of the Society for American Archaeology in Vancouver, Canada. But the skeletons also hint that the macaws\u2019 handlers went to great lengths to care for their demanding charges. \u201cPeople were doing their utmost to keep them alive,\u201d says Randee Fladeboe, an archaeologist at the University of Florida in Gainesville who analysed the macaw bones. Archaeologists studying the ancient Native Americans called the Puebloans and nearby groups have found macaw bones and feathers dating from  ad  300 to  ad  1450 at sites ranging from Utah in the American Southwest to Chihuahua in Mexico. It is likely that many of these birds were imported; there is scanty evidence of macaw breeding, except at one Mexican site, and many macaws are tropical. The highly prized scarlet macaw ( Ara macao ), for example, lives at least 500 kilometres to the southeast. Fladeboe examined the wing bones of 17 scarlet and military macaws ( Ara militaris ) from three pueblos. Fifteen of the birds had small bumps marring the upper surfaces of their wing bones. A macaw\u2019s flight feathers are rooted in the bone, so pulling them out can cause bleeding and infection, Fladeboe says. Multiple infections, or a combination of infection and malnutrition, lead to bumps like those on the skeletons. Macaws do sometimes yank out their own feathers, but the ancient bones show traces of multiple feather loss along their entire lengths and on both right and left wings. To Fladeboe, it seems unlikely that 15 of the 17 macaws she studied would strip themselves so methodically. \n             Tough old birds \n           One macaw had suffered two broken wings, and its beak bore signs of attacks from other macaws. Its bones also show irregularities from either malnutrition or illness. This macaw probably would not have survived without hand-feeding and protection, Fladeboe says. Fladeboe makes a \u201cgood preliminary case\u201d that the birds were plucked by humans, says zooarchaeologist Erin Keenan Early at Texas State University in San Marcos, who thinks the evidence that the birds were well cared for is also credible. Fladeboe plans to do computerized tomography scanning of the bones to confirm her early results. Macaws that were stressed by captivity and feather removal may have engaged in \u201cself-destructive and otherwise aggressive behavior, making them quite difficult to care for\u201d, says zooarchaeologist Meredith Wismer of the University of Iowa in Iowa City. Fladeboe thinks that the birds\u2019 caretakers probably learned to soothe the macaws; happy macaws have more attractive feathers. \u2028 Few sites had more macaws than  Chaco Canyon, a cluster of settlements in New Mexico . Chaco\u2019s Pueblo Bonito even had what seems to be an aviary, complete with a layer of guano 25 centimetres thick. A radiocarbon analysis demonstrated that macaws were living there in the late 1000s and early 1100s, even as the pueblo was heading towards collapse. Earlier research had shown that birds were imported to the pueblo when it was flourishing 1 . But seemingly the pueblo\u2019s access to macaws \u201ccontinued throughout the rise and decline of Chaco\u201d, illustrating the birds\u2019 importance, says archaeologist Adam Watson of the American Museum of Natural History in New York City, who presented the new dates at the meeting on 30 March. Macaw keepers at places such as Chaco Canyon clearly had to go to great lengths to procure the water and food the birds needed, Fladeboe says. To ancient Southwestern peoples, the macaws served a role befitting their powers as ambassadors to the underworld and bringers of rain. The macaws\u2019 caretakers \u201cdid obviously care for the birds\u201d, she says. \u201cTo say that they only cared about them [for] their feather output would be to do them a disservice.\u201d \n                   The greatest vanishing act in prehistoric America 2015-Nov-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21715", "url": "https://www.nature.com/articles/nature.2017.21715", "year": 2017, "authors": [{"name": "Olga  Dobrovidova"}], "parsed_as_year": "2006_or_before", "body": "Beleaguered institution cancels presidential election two days before vote, and appoints acting chief. Academics at Russia\u2019s premier science body have been left shocked and confused after an election that was supposed to determine the new president of the Russian Academy of Sciences (RAS) was cancelled at the last minute. The three candidates\u00a0\u2014 including incumbent president Vladimir Fortov \u2014 pulled out on 20 March, just two days before the election was scheduled to happen. Three days later, the Russian government appointed academy vice-president Valery Kozlov, who had not planned to stand in the election, as acting leader. The reasons for the candidates\u2019 withdrawal remain mysterious. But the events are just the latest upheaval at an organization still grappling to come to terms with reforms that began four years ago. \u201cNo one asking to postpone the election actually said anything specific,\u201d says Askold Ivantchik, a historian at the RAS Institute of World History in Moscow and the New York University Institute for the Study of the Ancient World. \u201cFortov mentioned some procedural complaints \u2014 of which we know nothing. His opponents said nothing at all. Their withdrawals were, frankly, unseemly as they gave no arguments.\u201d The RAS, established in 1724, is the umbrella body for Russia\u2019s largest network of research institutions. It manages basic research and acts as an authority on science policy. But its past few years have been tumultuous \u2014 with a  surprise reform  announced by the government in 2013. The reform \u2014 aimed at modernizing the academy \u2014 began months after Fortov had been elected for his first term. It caused outrage among some scientists because it transferred budget and administrative controls to a new government agency, largely stripping the RAS of its powers. \n               \u2018Archaic\u2019 procedures \n             Fortov\u2019s term as president was due to end on 27 March, and last week\u2019s cancelled election would have been the first since the reforms. The RAS has been electing its presidents since 1917. On the first morning of a pre-election conference, the two challengers, biologist Alexander Makarov and physicist Vladislav Panchenko, announced to a room of shocked scientists and journalists that they were dropping out of the race. They gave no reason why. Fortov, the election favourite endorsed by the academy\u2019s governing council, withdrew immediately afterwards, saying that he could not run unopposed. Some clues to what happened emerged from interviews that Makarov and Panchenko gave to the government-run newspaper  Rossiyskaya Gazeta  the day before they withdrew. Makarov called election procedures at the academy \"archaic\" and \"nonsensical\". Panchenko mentioned that he and several unnamed RAS members had sent a letter to the governing council asking it to make the election procedure \u2014 which \"leaves room for manipulation\" \u2014 more transparent. The letter was not made public, and neither Makarov nor Panchenko responded to  Nature \u2019s requests for comment. Four years after the reforms began, many of the academy\u2019s scientists are still fuming. In his election campaign, Fortov himself described the government overhaul as \u201cthe most radical and risky for science\u201d in the academy\u2019s history, and accused the government of further encroaching on the RAS\u2019s autonomy. \n               Symbolic message \n             Rumours are rife in Russia\u2019s scientific community. Valery Rubakov, a theoretical physicist at the RAS Institute for Nuclear Research in Moscow, called the developments \u201cextraordinary\u201d. He told  Nature  that \u201cwithout pressure \u2018from above\u2019, this turn of events would not have been possible\u201d. Rubakov and at least two other members of the academy, physicists Vladimir Zakharov and Gennady Mesyats, suggested that Fortov had had a meeting at the Kremlin on Friday 17 March. When asked about this allegation at the meeting, Fortov neither confirmed nor denied it. Mesyats, speaking at the election conference, called the events culminating in the election\u2019s cancellation a \"special operation\" against RAS. Kozlov, a prominent mathematician, oversaw a mid-2000s internal push to reform the RAS that had limited results. He is expected to serve as acting president until a presidential election takes place \u2014 which, under the academy\u2019s charter, should be no later than 28 September. Experts agree that turmoil in the academy, which is revered as a historic institution but has held little sway since the reforms, seems unlikely to affect scientists on the ground beyond sending a symbolic message. \u201cThis was yet another demonstration of a profound level of disrespect for the scientific community,\u201d says Mikhail Gelfand, deputy director of the RAS Institute for Information Transmission Problems in Moscow. \u201cThe people doing science in Russia were told, once again, that no one asked for their opinion.\" Olga Dobrovidova is employed by TASS, a state-owned news agency in Russia. \n                     Russian science at the crossroads 2016-Nov-01 \n                   \n                     Russia: A faltering recovery 2016-Aug-31 \n                   \n                     Academy 'reform' is stifling Russian science 2014-Jul-02 \n                   \n                     Vote seals fate of Russian Academy of Sciences 2013-Sep-19 \n                   Reprints and Permissions"},
{"file_id": "543597a", "url": "https://www.nature.com/articles/543597a", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Physicists try to rebuild the laws of heat and energy for processes at a quantum scale. The young field of quantum thermodynamics, which tries to reconcile quantum theory with the 200-year-old science of heat and entropy, is booming. It\u2019s also causing some heated disputes. Many physicists hope that rebuilding thermodynamics from the laws of quantum mechanics will help to settle long-debated conundrums. There are practical implications, too. The field could help to resolve whether the concepts of heat and efficiency apply to tiny electronic components and even atom-sized machines. But despite proliferating approaches\u00a0\u2014 many of which were presented at the Fifth Quantum Thermodynamics Conference this month in Oxford, UK\u00a0\u2014\u00a0the field is as contentious as ever. The crux of the issue is whether the fundamental laws that govern heat and energy on large scales also dictate the behaviour of nanoscale systems\u00a0\u2014\u00a0or whether new laws are needed. Interest is growing: this year, more than 100\u00a0scientists attended the quantum thermodynamics conference, says co-organizer Vlatko Vedral, a physicist at the University of Oxford. That is double the attendance in previous years. Such meetings bring together researchers from subfields that use different technical languages, says co-organizer Felix Binder, a theoretician at Nanyang Technological University in Singapore. \u201cThere are a lot of barriers being broken between different approaches.\u201d But a few physicists, such as Peter H\u00e4nggi of the University of Augsburg, Germany, caution that some of the work is misguided. \u201cThe field is growing rapidly, but also a lot of nonsense is written (and talked) about,\u201d he says. Physicists have argued over the meaning of the three laws of thermodynamics since they were written in the nineteenth and early twentieth centuries. The laws say that energy cannot be created or destroyed; that the amount of disorder, or entropy, in an isolated system can never decrease; and that it is impossible to cool an object to absolute zero. But thermo-dynamics is paradoxical. The second law, which also puts limits on how efficiently heat can be converted into work\u00a0\u2014\u00a0as happens in a steam engine\u00a0\u2014\u00a0is particularly controversial. The law says that the production of disorder is irreversible. But some physicists argue that at the microscopic level, this seems to conflict with the laws of mechanics\u00a0\u2014\u00a0be they those of Newton or of quantum physics. Mechanical laws, say these researchers, prescribe that all processes can be reversed. Researchers have come up with different approaches to solving this conundrum, but none has satisfied everyone. \u201cThis has always been a bit of a dirty business,\u201d says Christian Gogolin, a physicist at the Institute of Photonic Sciences in Castelldefels, Spain. Gogolin\u2019s work involves taking statistical mechanics, in which quantities such as temperature or heat are averaged properties of systems made of many particles, and developing a quantum version of it. Some physicists maintain that this statistical-mechanics approach suggests that quantities such as entropy or heat depend on the information an observer possesses. In particular, an all-seeing, \u2018godlike\u2019 being could know the positions and motions of each particle and calculate their evolution, and this level of order would be in the eye of the beholder. This approach has been revived in recent years, as many physicists have come to regard information as something quantifiable, and with physical significance. Statistical mechanics is even murkier in systems made of relatively few particles and governed by quantum laws. For example, if the tendency towards disorder is a purely statistical phenomenon, it might in principle not apply to a single molecule. Yet in the past decade, theorists have suggested that quantum systems tend to reach and maintain a state of equilibrium\u00a0\u2014\u00a0or maximum disorder\u00a0\u2014\u00a0even when they have just a handful of components. Experiments confirmed this with small numbers of atoms trapped by laser light in a vacuum 1 . And in a 2011 theory paper in  Nature , Vedral and his collaborators showed that quantum correlations\u00a0\u2014\u00a0the ability of particles to share an \u2018entangled\u2019 quantum state when far apart\u00a0\u2014\u00a0can be harnessed to produce mechanical work 2 . More recently, physicists have made progress with the third law. In a paper published on 14 March in  Nature Communications 3 , Lluis Masanes and Jonathan Oppenheim at University College London showed that the laws of quantum mechanics limit how fast heat can be extracted from an object, and that reaching absolute zero would take an infinite amount of time. Their work seems to confirm that the third law emerges from quantum mechanics. A more radical proposal, by Oxford theoretical physicists Chiara Marletto and David Deutsch, suggests a set of principles that all physics theories have to satisfy, a sort of a \u2018theory of everything\u2019 from which laws such as quantum mechanics should follow. And in a 2016 preprint 4 , Marletto sketched out how this set of meta-laws leads to a redefiniton of thermodynamic concepts in terms of rules that physical transformations have to obey. Whatever the outcome of these debates, they may have implications for future technologies. Physicists have made \u2018quantum heat engines\u2019\u00a0\u2014 that can turn heat into work at the quantum level 5 . Applications such as quantum computing are moving from the theoretical to the real world, so understanding thermodynamics on a tiny scale could be crucial. \u201cYou need to design algorithms that are not just faster,\u201d says Renato Renner at the Swiss Federal Institute of Technology Zurich, and a co-author of the 2011  Nature  paper, \u201cbut also thermodynamically optimized.\u201d \n                     Quantum gas goes below absolute zero 2013-Jan-03 \n                   \n                     Demonic device converts information to energy 2010-Nov-14 \n                   \n                     Nature Physics Insight: Non-equilibrium physics \n                   \n                     A Meta-Law to Rule Them All: Physicists Devise a \u201cTheory of Everything\u201d \n                   \n                     Oxford conference \u201cQTD5\u201d \n                   Reprints and Permissions"},
{"file_id": "543602a", "url": "https://www.nature.com/articles/543602a", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Gut bacteria and altered metabolic pathways are suspects in mysterious disease. Before his 33-year-old son became bedridden with chronic fatigue syndrome, biochemist Ronald Davis created technologies to analyse genes and proteins faster, better and more cheaply. Now he aims his inventions at a different target: the elusive inner workings of his son\u2019s malady. In his office at the Stanford Genome Technology Center in Palo Alto, California, Davis holds a nanofabricated cube the size of a gaming die. It contains 2,500\u00a0electrodes that measure electrical resistance to evaluate the properties of human cells. When Davis exposed immune cells from six people with chronic fatigue syndrome to a stressor\u00a0\u2014 a splash of common salt\u00a0\u2014 the cube revealed that they couldn\u2019t recover as well as cells from healthy people could. Now his team is fabricating 100\u00a0more devices to repeat the experiment, and testing a cheaper alternative\u00a0\u2014 a paper-thin nanoparticle circuit that costs less than a penny to make on an inkjet printer. Davis\u2019s findings, although preliminary, are helping to propel research on chronic fatigue syndrome, also called myalgic encephalomyelitis (ME/CFS), into the scientific mainstream. Physicians used to dismiss the disease as psychosomatic, but studies now suggest that it involves problems in the chemical reactions, or pathways, within cells. \u201cWe now have a great deal of evidence to support that this is not only real, but a complex set of disorders,\u201d says Ian Lipkin, an epidemiologist at Columbia University in New York City. \u201cWe are gathering clues that will lead to controlled clinical trials.\u201d A report released in February 2015 by the US Institute of Medicine (IOM) has helped to drive the shift. After reviewing more than 9,000\u00a0studies, an expert panel  concluded that chronic fatigue syndrome was an under-studied physiological illness . \u201cThey essentially said, \u2018Shame on you for not investigating this,\u2019\u201d says Zaher Nahle, vice-president of scientific programmes at the Solve ME/CFS Initiative, a non-profit group in Los Angeles, California. The US National Institutes of Health (NIH) responded by doubling its planned spending on research into the condition, from around US$6\u00a0million in 2016 to $12 million in 2017. This month, Avindra Nath, a neurologist at the NIH\u2019s National Institute of Neurological Disorders and Stroke in Bethesda, Maryland, enrolled the first patients in a study to compare blood, spinal fluid, saliva and faecal samples from people with chronic fatigue to those without it. The scientists will analyse gut bacteria and proteins involved in metabolism and immune responses, among other things. \u201cI call this a hypothesis-generating study,\u201d Nath says. \u201cResearchers are thinking deeply about how to build the field.\u201d \n               From tests to treatments \n             Elucidating the mechanisms behind the syndrome could lead to new treatments\u00a0\u2014 and the first diagnostic tests. The US Centers for Disease Control and Prevention estimate that 1\u00a0million people in the United States have the illness, but the IOM report concluded that the number could be as high as 2.5\u00a0million. Physicians use a broad list of criteria to diagnose patients, including whether a person has experienced cognitive impairment and more than six months of profound fatigue \u2014 and whether other conditions have been ruled out. \u201cMy son can\u2019t read. He can\u2019t listen to music. He can\u2019t talk. He can\u2019t write,\u201d Davis says. \u201cBut when the doctor does a battery of tests on him, they all come out normal.\u201d Having a test that could signal if something was wrong in such cases would be a big help, he adds. Lipkin has identified a distinct set of intestinal bacteria in 21 people with chronic fatigue syndrome who also had irritable bowel syndrome\u00a0\u2014 conditions that often occur together. His study, accepted for publication in the journal  Microbiome, also links both diseases to changes in body processes influenced by gut microbes, such as the production of vitamin B6 (D. Nagy-Szakal  et al. Microbiome ; in the press). And a study by another team, published in December 2016, finds problems with the function of an enzyme that is crucial for the process by which cells create energy ( \u00d8.\u00a0Fluge  et al. JCI Insight    1,  e89376; 2016 ). Rather than seeing the thicket of metabolic, microbial and immunological data as adding to the confusion surrounding chronic fatigue, researchers are studying how the body\u2019s systems affect each other. The current consensus is that a variety of initial triggers might converge to alter similar metabolic pathways, which ultimately leads to life-changing fatigue. Davis says that such metabolic disruptions could impair cells\u2019 ability to generate energy in response to stress, explaining the findings from his nanofabricated cube. First, however, he wants to ensure that his results are consistent, by comparing more data from people with chronic fatigue and those with and without other diseases. \u201cThis is not an academic exercise,\u201d he says. \u201cMy son is in bad, bad shape.\u201d \n                     US panel redefines chronic fatigue syndrome 2015-Feb-11 \n                   \n                     The scientist who put the nail in XMRV's coffin 2012-Sep-18 \n                   \n                     Chronic fatigue syndrome: life after XMRV 2011-Jun-03 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21700", "url": "https://www.nature.com/articles/nature.2017.21700", "year": 2017, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Global health charity is latest funder to start its own publishing \u2018channel\u2019 \u2014 and the European Commission is considering its own service. One of the world's wealthiest charities, the Bill & Melinda Gates Foundation in Seattle, Washington, is set to launch its own open-access publishing venture later this year. The initiative,  Gates Open Research , was announced on 23 March\u00a0and will be modelled on  a service begun last year  by the London-based biomedical charity, the Wellcome Trust. Like that effort, the Gates Foundation\u2019s platform is intended to accelerate the publication of articles and data from research funded by the charity. Along similar lines, the European Commission (EC) is considering its own open-access publishing platform for outputs from its \u20ac80-billion (US$86-billion) Horizon 2020 research programme. At an 'open science' conference in Berlin on 21 March, an EC representative suggested the service might launch this year, says Sabina Leonelli, a philosopher at the University of Exeter, UK, who attended the meeting. An EC spokesperson said that the Commission was looking at Wellcome Trust and Gates Foundation models, and had asked a panel called the Open Science Policy Platform (of which Leonelli is a member) to provide an opinion on the idea. \n               Welcome to the team \n             The Gates Foundation has, similarly to the Wellcome Trust, contracted management of its publishing service to  F1000Research , an open-access platform that rapidly publishes papers and data sets after an initial sanity check by its in-house editors. Papers are peer-reviewed after publication, and the reviews and the names of their authors are published alongside. The foundation will have no editorial oversight of Gates Open Research, says spokesperson Bryan Callahan. It will also fully cover all article-processing charges (APCs) \u2014 US$150 for articles of up to 1,000 words, $500 for those ranging 1,000\u20132,500 words and $1,000 for those exceeding 2,500 words. Callahan says the platform should prove useful to Gates-funded researchers in developing countries. It should also help grantees avoid predatory publishers. Wellcome Open Research published its first papers in November 2016. According to Robert Kiley, Wellcome\u2019s head of digital services, the platform currently hosts 53 articles, at an average cost of \u00a3791 (US$990) per paper for the 50 invoiced so far. That contrasts with an average of \u00a32,044 for the 3,552 articles that the Charity Open Access Fund (a coalition of six UK charities, of which Wellcome Trust is the largest) supported to make open access between October 2015 and September 2016. Over this period, the coalition spent \u00a36.6 million on APCs \u2014 up 32% from the previous financial year. For researchers, a benefit of the Wellcome Open channel is that papers appear quickly, typically being posted around one week after submission, and passing peer review after a median of 27 days. (Not all article pass peer review: those that are rejected remain on the site but are not indexed in abstract databases such as PubMed). The Gates foundation \u2014 whose funding generates around 2,000\u20132,500\u00a0research articles per year \u2014 has  one of the most stringent open-access policies  of any research funder. Researchers must make their papers and data open access immediately upon publication, and allow their unrestricted reuse. \u201cWe believe that published research resulting from our funding should be promptly and broadly disseminated,\u201d says Callahan. \u201cOur research saves lives.\u201d \n                     Science journals permit open-access publishing for Gates Foundation scholars 2017-Feb-14 \n                   \n                     Gates Foundation research can\u2019t be published in top journals 2017-Jan-13 \n                   \n                     Wellcome Trust launches open-access publishing venture 2016-Jul-06 \n                   \n                     Does it take too long to publish research? 2016-Feb-10 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21825", "url": "https://www.nature.com/articles/nature.2017.21825", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Brain drain from entering member states led to less-integrated research in countries of origin. When the European Union expanded in the 2000s, it had a negative impact on scientific collaborations between researchers in new member countries and elsewhere, a study has found. Membership in the EU gives countries access to the bloc\u2019s huge science-funding schemes and to the  European Research Area  (ERA), which strives for a border-free, well-funded, pan-European system of science. But according to a paper published on 12 April in  Science Advances 1 , countries that joined in two waves of expansion \u2014 ten new members in 2004 and two more in 2007, all but three of them part of the former Soviet bloc \u2014 would have had more cross-border collaboration between scientists if they had not joined. The findings \u201cchallenge central tenets underlying ERA integration policies,\u201d write the authors. \n             Collaboration cuts \n           In the paper, Alexander Petersen, a computational social scientist at the University of California, Merced, and his co-authors assess the collaboration rates of countries based on publication involving authors from more than one nation. They found a much slower increase in Eastern European rates of collaboration per publication in the decade after 2004 than in previous ones (see Inter-EU brain drain). They also modelled what the cross-border publication rate might have been, had those 12 countries not joined the EU. According to the team\u2019s results, nations that joined in 2004 \u2014 such as Poland and Lithuania \u2014 saw 9% fewer cross-border publications than they might have expected given their scientific and economic metrics, such as spending on research and development. When countries join the EU, their citizens generally also gain the automatic right to work in any other EU member state, which raises the risk of a \u2018brain drain\u2019. Petersen says that promising young academics who work in their home states often establish cross-border collaborations. But if those same researchers move west, their countries of origin lose not only their human capital, but also their bridges with the rest of the world. \u201cAnd this process naturally explains what we found in our paper \u2014 Eastern European countries would have been more integrated within science had they never integrated within the EU,\u201d he says. Petersen thinks that the ERA is \u201cgreat for multiple reasons\u201d, including that it brings together countries with different innovation systems. He also says that the EU is doing a good job of dealing with the problems identified in this paper, for instance through programmes that pair Eastern-European institutions with Western ones. The latest paper shows, however, that Eastern European countries should invest in collaboration with Western countries, but should also implement \u2018home-return\u2019 conditions to make sure scientists come back at some point, he says. \n             Brexit pressure \n           The research comes at a crucial time for scientific collaboration in the EU, given that one of its major players \u2014 the United Kingdom \u2014 is about to leave the bloc. Several groups, including the League of European Research Universities (LERU) and the European University Association,  called last month for  \u201cnew momentum\u201d to be given to the ERA, by setting more ambitious goals and expanding beyond Europe. \u201cOf course there has been brain drain,\u201d says Kurt Deketelaere, secretary-general of LERU and a professor of law at the University of Leuven in Belgium. But it did not have to happen, he says. Deketelaere faults the new member states for not strengthening their own research systems in line with the ERA aims. \u201cIf they had done that, they would have experienced brain circulation, much less brain drain and have a much better-performing research system,\u201d he says. Commenting on the paper, a European Commission spokesperson said in a statement, \u201cIn recent years, transnational cooperation between member states has grown by 7.8% \u2014 an encouraging sign that ERA is working. But it is now up to member states in particular to further improve the implementation of ERA.\u201d The commission will assist with this by helping lower-performing countries improve their scientific efforts, the spokesperson added. \n                   Research gets increasingly international 2016-Jan-19 \n                 \n                   Interdisciplinarity: How to catalyse collaboration 2015-Sep-16 \n                 \n                   Collaboration: Strength in diversity 2014-Sep-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21816", "url": "https://www.nature.com/articles/nature.2017.21816", "year": 2017, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Highly anticipated independent review also calls for better oversight and coordination of government research spending. The Canadian government should increase its support for fundamental science by more than a third, from Can$3.5 billion per year to Can$4.8 billion, according to a long-awaited independent review of the country\u2019s research priorities and funding. \u201cMajor reinvestments are urgently required,\u201d members of the panel, known as the Fundamental Science Review, said in a report released on 10 April. It also recommends the creation of several new bodies to coordinate and oversee government-funded research. That advice might prove hard to swallow. Although Canada\u2019s three major granting agencies and a research-support fund received a record-breaking Can$95-million boost in 2016,  their funding stayed flat in the 2017 budget  that the government released last month. The science review recommends increases for those three agencies, as well as a handful of other programmes, that would amount to Can$325 million per year for four years. \"The economy is growing. The population is growing. I can\u2019t imagine a better set of circumstances for the government to follow where it has been promising,\" says David Naylor, the chair of the science review and former president of the University of Toronto. The left-leaning Liberal government  launched the analysis in June 2016 to evaluate how basic science is organized and supported in Canada \u2014 the first such broad external review since the 1970s. The document describes Canada\u2019s \u201csobering\u201d international standing in science funding. Basic researchers have faced a 35% drop in available funds per capita since 2013, the analysis concludes, making it hard for the country to compete \u201ceven with smaller peers such as Australia and Switzerland\u201d. And many government programmes aren\u2019t keeping pace with inflation. The Canada Research Chair initiative is designed to attract top-flight international scholars to the country's universities, but the value of its individual awards has stagnated at Can$200,000 since 2000 \u2014 and in that time, the percentage of international recruits has fallen significantly. Canada's spending on research and development, as a percentage of GDP, has declined over the same period while the United States and Japan have increased the portion of their GDP that goes to science. \n             Wish list \n           \u201c We have had a war on science  in this country,\u201d says Kennedy Stewart, who tracks science issues for the New Democratic Party, the left-wing opposition to Prime Minister Justin Trudeau\u2019s middle-left Liberals. \u201cWe have had lots of rhetoric from this government about reinstating science. Now it has to put its money where its mouth is.\u201d But it is not clear whether the government can fulfil the panel\u2019s recommendations before the next federal election in 2019, Stewart adds. The review panel calls for an independent national council on research and innovation to advise the prime minister and watch over government science funding. It would replace the controversial Science, Technology and Innovation Council, which provides confidential reports to government and has no independent authority. The science review also recommends starting a board to forge a coherent strategy between the three major funding agencies for natural, health and social sciences \u2014 for example, to ensure that younger researchers get their fair share of grants. The new board would also oversee the Canada Foundation for Innovation, which supports science infrastructure and which the science review recommends giving a steady annual budget. The review also proposes a standing committee to sort out funding for major science projects, including international efforts such as the Thirty Meter Telescope. \u201cI was a little disappointed they didn\u2019t call for more consolidation; we have a proliferation of programmes,\u201d says James Woodgett, a biomedical researcher and director of research at the Lunenfeld-Tanenbaum Research Institute in Toronto. \u201cBut a big theme here is integration.\u201d Woodgett is helping to coordinate a meeting of 250 researchers in late May to discuss the report\u2019s findings and help translate it into action. \u201cThey\u2019ve really handed the baton over \u2014 to government and to us,\u201d he says. \n                   Canada budget falls flat with scientists 2017-Mar-23 \n                 \n                   Help wanted: Canada begins search for chief science adviser 2016-Dec-05 \n                 \n                   Scientific challenges loom for Canada\u2019s popular prime minister 2016-Oct-25 \n                 \n                   Nine years of censorship 2016-May-03 \n                 \n                   Canada\u2019s top scientist faces tough challenge 2015-Dec-22 \n                 \n                   Fundamental Science Review \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21815", "url": "https://www.nature.com/articles/nature.2017.21815", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "A better understanding of this pedestrian problem could lead to improved surgeons\u2019 knots and fibres. Oliver O\u2019Reilly was teaching his daughter to  tie her shoes  when he realized something: he had no idea why shoelaces suddenly come undone. When he went looking for an answer, it was apparent that no one else knew either. So O\u2019Reilly, a mechanical engineer at the University of California, Berkeley, roped in two of his colleagues to help work it out. In a paper published on 11 April in  Proceedings of the Royal Society A , they show that a combination of forces act on shoelace knots to cause a sudden, runaway failure 1 . The scientists expected that the knots would come undone slowly. But their slow-motion footage \u2014 focused on the shoelaces of a runner on a treadmill \u2014 showed that the knots rapidly failed within one or two strides. To figure out why, O\u2019Reilly and his colleagues used an accelerometer on the tongue of a shoe to measure the forces acting on a knot. They found that when walking, the combined impact and acceleration on a shoelace totals a whopping 7 gs \u2014 about as much as an Apollo spacecraft on reentry to Earth\u2019s atmosphere. Further experiments demonstrated that simply stomping up and down wasn\u2019t enough for a knot to fail; neither was swinging it back and forth. It took the interlaced effects of the two forces to undo the knot: the repeated impacts loosened it while the changes of direction pulled on the laces. \n               Watch where you step \n             This interest in why knots come untied is more than purely academic, says Khalid Jawed, a mechanical engineer at Carnegie Mellon University in Pittsburgh, Pennsylvania. Shoelace knots are the simplest type of knot, called the trefoil, he says. Most of the commonly used knots are usually just a combination of trefoils. \u201cIf we understand how simple knots work and fail, we can understand more complex knots,\u201d he says. This could help to create better surgeon\u2019s knots and stronger fibres \u2014 and even unravel the reasons why deep-sea optic cables become tangled and break. It could also improve how computer animators mimic the movement of hair because it moves and twists in a similar way to strings and knots. O\u2019Reilly encourages people to make their own observations the next time they walk or run. They could tie one shoe with a granny knot and the other with a sturdier reef or square knot and see how their laces fare. But tread carefully: you don\u2019t want to trip. \n                     Laces high 2002-Dec-05 \n                   \n                     Maths helps magicians knot 2001-Sep-11 \n                   \n                     Genes get knotted 1999-Jun-03 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21885", "url": "https://www.nature.com/articles/nature.2017.21885", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Genetic map showing how dog breeds are related provides a wealth of information about their origins. A new family tree of dogs containing more than 160 breeds reveals the hidden history of man\u2019s best friend, and even shows how studying canine genomes might  help with research into human disease . In a study published on 25 April in  Cell Reports , scientists examined the genomes of 1,346 dogs to create one of the most diverse maps produced so far tracing the relationship between breeds 1 . The map shows the types of dog that people crossed to create modern breeds and reveals that canines bred to perform similar functions, such as working and herding dogs, don't necessarily share the same origins. The analysis even hints at an ancient type of dog that could have come over to the Americas with people thousands of years before Christopher Columbus arrived in the New World. The new work could come as a surprise to owners and breeders who are familiar with how dogs are grouped into categories. \u201cYou would think that all working dogs or all herding dogs are related, but that isn\u2019t the case,\u201d says Heidi Parker, a biologist at the US National Institutes of Health (NIH) in Bethesda, Maryland, and a study author. When geneticists tried to map out herding-dog lineages in the past, they couldn\u2019t do so accurately. Parker and Elaine Ostrander, also a biologist at the NIH and a study author, say that this was because herding dogs emerged through selective breeding at multiple times and in many different places. \u201cIn retrospect, that makes sense,\u201d says Ostrander. \u201cWhat qualities you\u2019d want in a dog that herds bison are different from mountain goats, which are different from sheep, and so on.\u201d \n             Coming to America \n           Most of the breeds in the study arose from dog groups that originated in Europe and Asia. But domestic dogs came to the Americas thousands of years ago, when people crossed the Bering land bridge linking Alaska and Siberia. These New World dogs later disappeared when European and Asian dogs arrived in the Americas. Researchers have looked for the genetic legacy of these ancient canines in the DNA of modern American breeds, but have found little evidence until now. The way that two South American breeds, the Peruvian hairless dog and the xoloitzcuintli, clustered together on the family tree suggested to Ostrander and Parker that those animals could share genes not found in any of the other breeds in their analysis. Parker thinks that those genes could have come from dogs that were present in the Americas before Columbus\u2019s arrival. \u201cI think our view of the formation of modern dog breeds has historically been one-dimensional,\u201d says Bob Wayne, an evolutionary biologist at the University of California, Los Angeles. \u201cWe didn\u2019t consider that the process has a deep historical legacy.\u201d That extends to what was probably the first period of  domestication for canines  in hunter-gatherer times. Ostrander and Parker think that dog breeds underwent two major periods of diversification. Thousands of years ago, dogs were selected for their skills, whereas a few hundred years ago, the animals were bred for physical traits. \u201cYou would never be able to find something like this with cows or cats,\u201d says Wayne, \u201cWe haven\u2019t done this kind of intense deliberate breeding with anything but dogs.\u201d Although the latest study can help researchers to better understand the history of the domestic dog, there are several practical reasons for creating a database such as that produced by Ostrander, Parker and their colleagues. One reason is that it can help in diagnosing illnesses in domestic dogs. Another is that it can aid the study of human diseases. Dogs and people can suffer from similar conditions, such as epilepsy. In humans, there might be hundreds of genes that can influence that illness. However, because dog breeds are relatively genetically isolated, each breed might carry only one or two of the genes involved in epilepsy, says Ostrander. \u201cBy studying dogs, we can we look at each [gene] individually. It\u2019s much more efficient.\u201d \n                   Canine clues: Dog genomes explored in effort to bring human cancer to heel 2015-Dec-08 \n                 \n                   Dog's dinner was key to domestication 2013-Jan-23 \n                 \n                   Genetics: Pet project 2010-Aug-25 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21884", "url": "https://www.nature.com/articles/nature.2017.21884", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Rising ocean temperatures drive more intense and longer lasting toxic outbreaks. Researchers have long suggested that climate change could mean more damage from algal blooms \u2014 runaway growths of algae that can strangle marine ecosystems and devastate coastal economies. Now, a study has unpicked how warming ocean temperatures have already driven an intensification of blooms around North America \u2014 the first time this link has been established at an ocean scale 1 .  Harmful algal blooms can occur when changes in water conditions lead to a huge growth in the number of a particular species of algae. The blooms can produce toxins, become so large that they kill marine life, and even turn water a different colour.  Research has established that one factor that helps blooms to spread is a sudden increase in nutrients such as nitrogen and phosphorus \u2014 often from agricultural fertilizers \u2014 and it has also linked warming temperatures to individual events. But the broader influence of climate change on these outbreaks is less well quantified. \n             Blooms abound \n           Christopher Gobler, who studies coastal ecosystems at Stony Brook University in Southampton, New York, and his colleagues looked at the relationship between blooms in the North Atlantic and North Pacific oceans and temperature changes in the region to investigate whether the events there were linked to were linked to ocean warming. Previous research has studied the influence of climate change on algal blooms in individual coastal systems, says Gobler, but this is the first to assess ocean-basin-wide trends. The researchers looked at two species of algae:  Alexandrium fundyense  and  Dinophysis acuminata . (These species produce toxins that can cause illnesses \u2014 sometimes fatal \u2014 in humans who eat shellfish contaminated with them). They used detailed data on sea-surface temperatures to model trends in the growth rates of the algae species and the periods when blooms occurred from the early 1980s into the twenty-first century. At dozens of sites, their model suggests that new blooms could occur where they hadn't happened before. The researchers found higher potential growth rates and longer bloom seasons for both species in many parts of the Atlantic coast and along Alaska. In some places, they found the bloom season to now be more than a month longer than it was in 1982. The team used its model to retrospectively predict what harmful blooms might have occurred in the time period and found good agreement with actual events. \u201cWhat\u2019s different about this study is they\u2019re going beyond just saying 'Look, warmer is bad' and trying to do a rigorous quantitative analysis,\u201d says Anna Michalak, who studies climate change and water quality at the Carnegie Institution for Science in Stanford, California. Gobler points out that that the ocean does not warm uniformly, with some regions warming faster than average and some cooling. This means blooms will appear in new regions, and may actually reduce in some places they currently occur. Factors other than temperature are still clearly important, he says. \n             Many factors \n           Michalak points out that for events such as major droughts and floods, researchers can now often estimate how much more likely such events will be as a result of climate change. But there is  less research on the relationship between water quality and climate change . \u201cWe don\u2019t have that science on the water quality side,\u201d she says, adding that this paper is one step in that direction. Michalak\u2019s team has previously studied a massive 2011 bloom in Lake Erie 2  \u2014 one of the largest ever on the Great Lake. They pinned the event on a combination of weather conditions and agriculture putting huge nutrient loads in the lake. That interplay of different factors is one reason why not everyone is yet prepared to say that climate change will necessarily lead to more harmful algal blooms. Mark Wells, who studies harmful algal blooms at the University of Maine in Orono, points out that that rising temperatures alone may not always cause more harmful algal blooms. In 2010 in the Gulf of Maine, he says, there were very high water temperatures, and many blooms were expected. But in fact, water temperatures were so high that the layers of sea water became stratified and prevented mixing and the transfer of nutrients, so in the end there were fewer blooms than expected. Still, he says, the latest study \u201cprovides a lot of new evidence\u201d and represents a believable trend. Reprints and Permissions"},
{"file_id": "nature.2017.22000", "url": "https://www.nature.com/articles/nature.2017.22000", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Two research teams cook up recipe to make long-sought cells in mice and people. After 20 years of trying, scientists have transformed mature cells into primordial blood cells that regenerate themselves and the components of blood. The work, described today in  Nature 1 , 2 , offers hope to people with leukaemia and other blood disorders who need bone-marrow transplants but can\u2019t find a compatible donor. If the findings translate into the clinic, these patients could receive lab-grown versions of their own healthy cells. One team, led by stem-cell biologist George Daley of Boston Children\u2019s Hospital in Massachusetts, created human cells that act like blood stem cells, although they are not identical to those found in nature 1 . A second team, led by stem-cell biologist Shahin Rafii of Weill Cornell Medical College in New York City, turned mature cells from mice into fully fledged blood stem cells 2 . \u201cFor many years, people have figured out  parts of this recipe , but they\u2019ve never quite gotten there,\u201d says Mick Bhatia, a stem-cell researcher at McMaster University in Hamilton, Canada, who was not involved with either study. \u201cThis is the first time researchers have checked all the boxes and made blood stem cells.\u201d Daley\u2019s team chose skin cells and other cells taken from adults as their starting material. Using a standard method, they reprogrammed the cells into  induced pluripotent stem (iPS) cells, which are capable of producing many  other cell types . Until now, however, iPS cells have not been morphed into cells that create blood. The next step was the novel one: Daley and his colleagues inserted seven transcription factors \u2014 genes that control other genes \u2014 into the genomes of the iPS cells. Then they injected these modified human cells into mice to develop. Twelve weeks later, the iPS cells had transformed into progenitor cells capable of making the range of cells found in human blood, including immune cells. The progenitor cells are \u201ctantalizingly close\u201d to naturally occurring \u2018haemopoetic\u2019 blood stem cells, says Daley. Bhatia agrees. \u201cIt\u2019s pretty convincing that George has figured out how to cook up human haemopoetic stem cells,\u201d he says. \u201cThat is the holy grail.\u201d \n             Bloody good \n           By contrast, Rafii\u2019s team generated true blood stem cells from mice without the intermediate step of creating iPS cells. The researchers began by extracting cells from the lining of blood vessels in mature mice. They then inserted four transcription factors into the genomes of these cells, and kept them in Petri dishes designed to mimic the environment inside human blood vessels. There, the cells morphed into blood stem cells and multiplied. When the researchers injected these stem cells into mice that had been treated with radiation to kill most of their blood and immune cells, the animals recovered. The stem cells regenerated the blood, including immune cells, and the mice went on to live a full life \u2014 more than 1.5 years in the lab. Because he bypassed the iPS-cell stage, Rafii compares his approach to a direct aeroplane flight, and Daley\u2019s procedure to a flight that takes a detour to the Moon before reaching its final destination. Using the most efficient method to generate stem cells matters, he adds, because every time a gene is added to a batch of cells, a large portion of the batch fails to incorporate it and must be thrown out. There is also a risk that some cells will mutate after they are modified in the lab, and could form tumours if they are implanted into people. But Daley and other researchers are confident that the method he used can be made more efficient, and less likely to spur tumour growth and other abnormalities in modified cells. One possibility is to temporarily alter gene expression in iPS cells, rather than permanently insert genes that encode transcription factors, says Jeanne Loring, a stem-cell researcher at the Scripps Research Institute in La Jolla, California. She notes that iPS cells can be generated from skin and other tissue that is easy to access, whereas Rafii\u2019s method begins with cells that line blood vessels, which are more difficult to gather and to keep alive in the lab. Time will determine which approach succeeds. But the latest advances have buoyed the spirits of researchers who have been frustrated by their inability to generate blood stem cells from iPS cells. \u201cA lot of people have become jaded, saying that these cells don\u2019t exist in nature and you can\u2019t just push them into becoming anything else,\u201d Bhatia says. \u201cI hoped the critics were wrong, and now I know they were.\u201d Read the related News & Views article: ' Education for stem cells ' \n                   Machine learning predicts the look of stem cells 2017-Apr-05 \n                 \n                   Japanese man is first to receive 'reprogrammed' stem cells from another person 2017-Mar-28 \n                 \n                   How iPS cells changed the world 2016-Jun-15 \n                 \n                   Stem cells: The black box of reprogramming 2014-Dec-10 \n                 \n                   Skin cells converted to heart muscle cells 2010-Aug-05 \n                 \n                   George Daley \n                 \n                   Shahin Rafii \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22001", "url": "https://www.nature.com/articles/nature.2017.22001", "year": 2017, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "Breaking from the general northward movement of many trees, flowering species take an unexpected turn. Ecologists have long predicted that climate change will send plants and animals uphill and towards the poles in search of familiar temperatures. Such movements have increasingly been documented around the world. But a study now shows that some tree species in the eastern United States are going their own way and moving west, not north, as the climate changes. Songlin Fei, a forest ecologist at Purdue University in West Lafayette, Indiana, and his colleagues tracked the shifting distributions of 86 types of tree (species and genus level) using data collected by the US Forest Service\u2019s Forest Inventory and Analysis programme during two periods: between 1980 and 1995 and in 2015 for most states. They found more species heading west than north, probably partly because of changing precipitation patterns, the team reported on 17 May in  Science Advances 1 . \u201cThat was a huge surprise for us,\u201d says Fei. This study indicates that changes in moisture availability owing to climate change probably exert stronger pressures on tree distributions in the near-term than temperature changes, he says. The team measured shifts in the centres of abundance for the 86 types of tree and found that over the past 30 years or so, 34% showed statistically significant poleward shifts at an average rate of 11 kilometres per decade. Forty-seven per cent made statistically significant westward shifts at an even faster rate \u2014 15.4 kilometres per decade. Hardly any types of tree moved south or east. \n             A new direction \n           A closer look at the data revealed that most of the trees that shifted west were angiosperms, or flowering trees. Northbound trees were usually gymnosperms, which are mostly conifers in North America. Increased precipitation in the central United States could be one explanation for the angiosperms\u2019 westward movement, say the study's authors. The increase in moisture is still subtle enough that only the more drought-tolerant and faster-growing flowering trees, with their more-efficient and robust vascular systems, can take advantage for now. In addition, nearly all of the wind-pollinated trees, which includes most of the gymnosperms and some of the angiosperms, shifted north. This suggests that these trees find it easier to change their distribution than those that depend on range-limited animal pollinators. Teasing out the true explanations for these shifts is complicated by the fact that the eastern United States hosts a complex and dynamic forest inhabited by people. Many researchers say that this forest is still in the process of growing back from large-scale clearing before the 1920s 2 . The changing distribution of tree type could be in part owing to regrowth and the natural succession of species through an area, combined with  human management  such as the suppression of fires. \n             Uncertain future \n           Tree physiologist Leander Love-Anderegg at the University of Washington in Seattle says that the study did well to acknowledge these potentially confounding variables. \u201cThey point out that in the eastern US it is a really tricky question to pull out climate-related changes in forests, from forests getting older and the effects of fire suppression,\u201d he says. Whether the mechanisms are perfectly understood or not, knowing movement trends helps forest managers, Love-Anderegg says. \u201cWe live in an era of very rapid ecological change. In order to avoid some of the more drastic and negative consequences of that change \u2014 like massive forest fires and massive beetle outbreaks \u2014 we all have an interest in trying to predict change before it occurs.\u201d What is certain is that the forests of today will look different 10, 20 or 30 years from now. \u201cIf you think of these species as members of a family, the question is, will some families break apart, or will they travel together?\u201d says Fei. \u201cWe might be talking about these families breaking apart.\u201d \n                   Forests not equal when it comes to climate 2016-Feb-04 \n                 \n                   The hunt for the world\u2019s missing carbon 2015-Jun-30 \n                 \n                   Carbon sequestration: Managing forests in uncertain times 2014-Feb-12 \n                 \n                   Citizen scientists' climate-impact survey wraps up 2011-Dec-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.21955", "url": "https://www.nature.com/articles/nature.2017.21955", "year": 2017, "authors": [{"name": "Erin Ross"}], "parsed_as_year": "2006_or_before", "body": "Certain insects, and perhaps some vertebrates, lack permanent microbial residents in their intestines. Many animals,  including humans , can\u2019t live healthy lives without the microbes in their guts. These intestinal residents break down food and help to fight off disease-causing microorganisms. But the latest research suggests that some species, including caterpillars, can do just fine without them. It\u2019s possible, say scientists who have studied these symbiotic bacteria, fungi and other microbes, that gut microbiomes might be less ubiquitous than previously assumed. Tobin Hammer, an evolutionary ecologist at the University of Colorado, Boulder, investigated the intestinal microbes of 124 species of wild, leaf-eating caterpillars from the Americas by sequencing a gene commonly used to identify microorganisms. In a preprint posted to the bioRxiv server, Hammer and his team report that they found no sign of what he calls \u201cresident\u201d microbes \u2014 a group of organisms that have co-evolved with their hosts 1 . The paper is the latest in a small but growing list of studies that have failed to find gut microbiomes in various animal and insect species. Researchers have had some trouble getting such papers published, probably because it's hard to prove a negative, says Hammer. Conventional wisdom holds that herbivores, such as cows,  need gut microbes to break down the fibres in plant cell walls . Because all of the caterpillars that Hammer studied ate leaves, he thought they would harbour a diverse and complex microbiome. \u201cBut it\u2019s important to remember: caterpillars are not mini cows,\u201d says Hammer. When scientists look at faecal matter from large herbivores, they find a lot more microbe DNA than plant DNA. But with caterpillars, the opposite seems true. The few bacteria and viruses Hammer found appeared to come from the insect\u2019s food and environment. The ecologist also tested whether any gut microbes in the caterpillars helped the insects to survive in some way. He hatched 72 tobacco hornworms ( Manduca sexta ), a common North American moth, and dosed the caterpillars with varying levels of antibiotics intended to wipe out any microbes the insects contained. But the treatments had no impact on the hornworms' health or survival. \n             Huge implications \n           Past studies have also indicated that caterpillars don\u2019t have microbiomes, says Melissa Whitaker, an ecologist who studies the relationships between caterpillars and bacteria at Harvard University in Cambridge, Massachusetts. But those studies looked only at a handful of species; Hammer\u2019s study looked at more than 100. Previous research also lacked experimental data on whether the microbes present in caterpillars were beneficial. Taken together, Whitaker thinks that the implications of Hammer's work are huge. \u201cThey\u2019re one of the largest groups of herbivores,\u201d Whitaker says. A project at University College London, UK, estimates that there are about 180,000 known caterpillar species. \u201cIf they\u2019re not relying on the bacteria in their guts to help with their diet, what are they relying on?\u201d says Whitaker. \u201cIt\u2019s got to be something entirely different. It\u2019s fascinating.\u201d Whitaker thinks that results like Hammer\u2019s might be more common than they seem in the literature. \u201cI think there\u2019s some selection bias,\u201d she says. Researchers might be reluctant to submit their negative results, and journals may be equally reluctant to publish them. It\u2019s a familiar story \u2014 when Whitaker first started looking at caterpillar gut bacteria, she was convinced there was something wrong with her data or her methods. Eventually, however, it became clear that there were no intestinal symbionts to find 2 . \n             The exceptions \n           Other scientists have had similar experiences. Jon Sanders, a postdoc at the University of California, San Diego, investigates the co-evolution of microbes and their hosts. In a study of Peruvian ants, Sanders found that some ground-dwelling species seemed to lack an intestinal microbiome entirely. His paper spent a year and a half in review before it was rejected. Sanders eventually posted it to bioRxiv 3 , and it\u2019s now in review at the journal  Integrative and Comparative Biology . Entomologist Matan Shelomi, affiliated with the Max Planck Institute for Chemical Ecology in Jena, Germany, spent years studying the gut microbiomes of herbivorous stick insects (Phasmatodea). He discovered that there were no microbes in the insects\u2019 guts 4 . Later, he found evidence that the Phasmatodea could break down pectin 5  \u2014 another fibre found in plant cell walls \u2014 using genes stolen from bacteria early on in the insects' evolutionary history. Shelomi eventually published his findings 6 , but \u201cit took a lot of work and arguing during the peer-review process\u201d, he says. It's possible that some vertebrates lack gut microbiomes, too. \u201cAnecdotally, I\u2019ve heard from researchers having similar problems in birds and fish,\u201d says Hammer. His study included data from several vertebrate species as controls. Some, such as goats, do harbour a gut microbiome. But when Hammer looked for gut microbes in faeces from geese and bats, he found none. There is still only a handful of published studies pointing to microbe-free guts. But now that people are looking, Whitaker, Hammer, Shelomi and Sanders all think that there will be other, similar findings in the future. \u201cAs a discipline we\u2019re  really ready to claim that everything is related to the microbiome  and every organism has one,\u201d says Whitaker. \u201cIt only takes one exception before all of that goes out the window.\u201d \n                   White House goes big on microbiome research 2016-May-13 \n                 \n                   The tantalizing links between gut microbes and the brain 2015-Oct-14 \n                 \n                   Panda guts not suited to digesting bamboo 2015-May-19 \n                 \n                   Microbiology: Microbiome science needs a healthy dose of scepticism 2014-Aug-20 \n                 Reprints and Permissions"},
{"file_id": "545395a", "url": "https://www.nature.com/articles/545395a", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Alarms raised over suspected efforts to collect massive numbers of genetic samples from citizens. Police in the northwestern region of Xinjiang, China, have been collecting DNA samples from citizens and are now ramping up their capacity to analyse that genetic cache, according to evidence compiled by activists and details gathered by  Nature . The advocacy group Human Rights Watch reported last month that Xinjiang authorities intend to accelerate efforts to gather blood samples from the region\u2019s large population of Muslim Uighur people. China\u2019s government has cracked down on Xinjiang\u2019s separatist movement in recent years, so the prospect of a DNA database there has stoked fears that authorities could use it as a political weapon. \u201cOur concern is that there is widespread collection of DNA without legal protection and without telling people,\u201d says Maya Wang, a researcher for Human Rights Watch in Hong Kong and the author of the report. In its report, the organization said that Xinjiang\u2019s police had ordered 12 DNA sequencers.  Nature  has confirmed the order and learned, from documents and interviews with those involved in the transaction, that the police have purchased enough machines to process up to 2,000 DNA samples per day. The police department hung up when  Nature  rang to ask about the reason for the purchase. That capacity goes well beyond what would be needed for routine forensics, says Sumio Sugano, a genomics researcher at the University of Tokyo. \u201cIt\u2019s definitely the kind of capacity that can be used to build a database,\u201d says a source familiar with the equipping of forensics laboratories in China, who did not want to be identified. \u201cThey are building a laboratory,\u201d he suggested after being shown the full purchase order for the sequencing equipment. According to a sales officer at a firm involved in the procurement, Xinjiang police have purchased eight sequencers produced by Thermo Fisher Scientific in Waltham, Massachusetts. The machines can be used to look at short stretches of DNA that tend to vary between individuals and are typically used in forensic DNA fingerprinting to match samples collected from a crime scene with individuals listed in a database (or even their close relatives). The police also purchased four domestically produced sequencers made for the same purpose. Nature  has learned that Xinjiang officials have also bought a \u2018next generation\u2019 DNA sequencer, which could be used to determine ancestry, eye colour and other physical characteristics from genetic samples. The report also gives details of a nationwide database that began in the early 2000s and has accrued 44 million entries from 40 million individuals, including 1.5 million from samples, such as cigarette butts, found at crime scenes. China\u2019s police have said that the database is for solving crimes. But Human Rights Watch says it has found evidence of \u201ccampaigns to amass biometrics from ordinary citizens\u201d. Many countries use DNA fingerprinting to solve crimes, reunite kidnapped children with their parents and identify bodies, and some researchers say that the boost in Xinjiang\u2019s DNA-analysis capacity does not, by itself, stand out. \u201cExpansion of police surveillance is expected by any civilized nation,\u201d says Sara Katsanis, who researches the applications of genetic testing at Duke University in Durham, North Carolina. Still, Katsanis and others worry about how DNA is being collected in China and especially in Xinjiang. Last year, Human Rights Watch reported that citizens in Xinjiang were required to give a blood sample to get a passport. And in March, Chinese state media detailed the conclusion of a 4-month programme during which 17.5 million people \u2014 who were predominantly Uighurs \u2014 were given health checks, including blood tests. Last week, reports emerged that many of the people who underwent these examinations had been forced to do so. Megan Allyse, a biomedical-ethics researcher at Mayo Clinic in Rochester, Minnesota, says that DNA profiling is especially fraught in China, because there seems to be no clear framework governing how the samples can be collected, transferred or stored, or when they are allowed to be used in court, and other matters. She hopes that countries can work together to use the data justly. \u201cWe need broad, international consensus on the appropriate use of DNA in national-security collections,\u201d she says. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Forensics: Germany considers wider use of DNA evidence in criminal cases 2017-Mar-27 \n                   \n                     Forensic DNA evidence is not infallible 2015-Oct-28 \n                   \n                     Mugshots built from DNA data 2014-Mar-20 \n                   \n                     Science in court: DNA's identity crisis 2010-Mar-17 \n                   \n                     Human Rights Watch report \n                   Reprints and Permissions"},
{"file_id": "545393a", "url": "https://www.nature.com/articles/545393a", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Canadian foundation says its field research could boost fisheries in Chile, but researchers doubt its motives. Marine scientists are raising the alarm about a proposal to drop tonnes of iron into the Pacific Ocean to stimulate the growth of phytoplankton, the base of the food web. The non-profit group behind\u00a0the plan says that it wants to revive Chilean fisheries. It also has ties to a controversial 2012 project in Canada that was accused of violating an international moratorium on commercial ocean fertilization. The Oceaneos Marine Research Foundation of Vancouver, Canada, says that it is seeking permits from the Chilean government to release up to 10 tonnes of iron particles 130\u00a0kilometres off the coast of Coquimbo as early as 2018. But Chilean scientists are worried because the organization grew out of a for-profit company, Oceaneos Environmental Solutions of Vancouver, that has sought to patent iron-fertilization technologies. Some researchers suspect that the foundation is ultimately seeking to profit from an unproven and potentially harmful activity. \u201cThey claim that by producing more phytoplankton, they could help the recovery of the fisheries,\u201d says Osvaldo Ulloa, director of the Millennium Institute of Oceanography in Concepci\u00f3n, Chile. \u201cWe don\u2019t see any evidence to support that claim.\u201d Tensions flared in April, when researchers at the institute went public with their concerns in response to Chilean media reports on the project. The government has since requested input from the Chilean Academy of Science, and the institute is organizing a forum on the project and related research on 25 May, at a marine-sciences meeting in Valpara\u00edso, Chile. The Oceaneos foundation, which declined an invitation, has accused the scientists of improperly classifying its work as geoengineering, rather than ocean restoration. Oceaneos president Michael Riedijk says that his team wants to work with Chilean scientists and will make all the data from its experiment public. The foundation plans to hold its own forum later, but if scientists aren\u2019t willing to engage, he says, \u201cwe\u2019ll just move on without them\u201d. Researchers worldwide have conducted 13\u00a0major iron-fertilization experiments in the open ocean since 1990. All have sought to test whether  stimulating phytoplankton growth  can increase the amount of carbon dioxide that the organisms pull out of the atmosphere and deposit in the deep ocean when they die. Determining how much carbon is sequestered during such experiments has proved difficult, however, and scientists have raised concerns about potential adverse effects, such as toxic algal blooms. In 2008, the United Nations Convention on Biological Diversity  put in place a moratorium on all ocean-fertilization projects  apart from small ones in coastal waters. Five years later, the London Convention on ocean pollution adopted rules for evaluating such studies. Because Oceaneos\u2019s planned experiment would take place in Chilean waters, it is allowed under those rules. Riedijk says that the foundation will voluntarily follow international protocols for such studies; it is unclear whether that will allay fears that the group is promoting an unproven technology, rather than conducting basic research. Philip Boyd, a marine ecologist at the University of Tasmania in Hobart, Australia, wants to see the foundation publish research based on lab experiments before heading out into the field. \u201cIf they are a not-for-profit scientific venture that wants to partner with academics, then surely transparency is their best foot forward,\u201d he says. Oceaneos\u2019s links to a 2012 iron-fertilization project off the coast of British Columbia, Canada, have made some researchers wary. In that project, US entrepreneur Russ George convinced a Haida Nation village to pursue iron fertilization to boost salmon populations, with the potential to sell carbon credits based on the amount of CO 2  that would be sequestered in the ocean. News of the plan broke after project organizers had dumped around 100\u00a0tonnes of iron sulfate into the open ocean. In the years since, scientists have seen no evidence that the experiment worked. Riedijk says he was intrigued when he read about the Haida experiment in 2013, and contacted one of its organizers, Jason McNamee. McNamee later served as chief operating officer of Oceaneos Environmental Solutions\u00a0\u2014 which Riedijk co-founded \u2014 before leaving the company last year. Despite the Haida project\u2019s problems, Riedijk says that ocean fertilization merits further research: \u201cIf this actually does work, it does have global implications.\u201d Oceaneos Environ-mental Solutions has developed an iron compound that can be consumed efficiently by phytoplankton, he adds, but he declined to release details. Riedijk also says that the foundation is working on a method to trace the movement of iron up the food chain and into fish populations. In the meantime, scientists say that it will be difficult to get solid data from the Oceaneos foundation\u2019s planned experiment. The geology off the Chilean coast, and the patterns of currents there, create a mosaic of low- and high-iron waters. Anchovies, horse mackerel and other fish move freely between these areas. And adding iron could shift the location and timing of phytoplankton blooms to favour fast-growing species, says Adrian Marchetti, a biological oceanographer at the University of North Carolina at Chapel Hill. One of those, the diatom  Pseudo-nitzschia , produces domoic acid, a neurotoxin that can kill mammals and birds. Oceaneos\u2019s experiment will probably increase plankton growth in low-iron waters, Marchetti says, \u201cbut it\u2019s not to say that that is actually good for the higher levels of the food chain\u201d. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @jefftollef \n               \n                     Emissions reduction: Scrutinize CO2 removal methods 2016-Feb-10 \n                   \n                     Climate geoengineering schemes come under fire 2015-Feb-10 \n                   \n                     Climate tinkerers thrash out a plan 2014-Dec-02 \n                   \n                     Ocean-fertilization project off Canada sparks furore 2012-Oct-23 \n                   \n                     Dumping iron at sea does sink carbon 2012-Jul-18 \n                   \n                     Ocean fertilization experiment suspended 2009-Jan-14 \n                   \n                     UN decision puts brakes on ocean fertilization 2008-Jun-03 \n                   \n                     Oceanos Marine Research Foundation \n                   \n                     UN Joint Group of Experts on the Scientific Aspects of Marine Environmental Protection \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22114", "url": "https://www.nature.com/articles/nature.2017.22114", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Remains from Morocco dated to 315,000 years ago push back our species' origins by 100,000 years \u2014 and suggest we didn't evolve only in East Africa. Researchers say that they have found the oldest  Homo sapiens  remains on record in an improbable place: Morocco. At an archaeological site near the Atlantic coast, finds of skull, face and jaw bones identified as being from early members of our species have been dated to about 315,000 years ago. That indicates  H. sapiens  appeared more than 100,000 years earlier than thought: most researchers have placed the origins of our species in East Africa about 200,000 years ago. The finds, which are published on 7 June in  Nature 1 , 2 , do not mean that  H. sapiens  originated in North Africa. Instead, they suggest that the species' earliest members evolved all across the continent, scientists say. \u201cUntil now, the common wisdom was that our species emerged probably rather quickly somewhere in a \u2018Garden of Eden\u2019 that was located most likely in sub-Saharan Africa,\u201d says Jean-Jacques Hublin, an author of the study and a director at the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany. Now, \u201cI would say the Garden of Eden in Africa is probably Africa \u2014 and it\u2019s a big, big garden.\u201d Hublin was one of the leaders of the decade-long excavation at the Moroccan site, called Jebel Irhoud. \n             Jaws and tools \n           Hublin first became familiar with Jebel Irhoud in the early 1980s, when he was shown a puzzling specimen of a lower jawbone of a child from the site. Miners had discovered a nearly complete human skull there in 1961; later excavations had also found a braincase, as well as sophisticated stone tools and other signs of human presence. The bones \u201clooked far too primitive to be anything understandable, so people came up with some weird ideas\u201d, Hublin says. Researchers guessed they were 40,000 years old and proposed that Neanderthals had lived in North Africa. More recently, researchers have suggested that the Jebel Irhoud humans were an \u2018archaic\u2019 species that survived in North Africa until  H. sapiens  from south of the Sahara replaced them.  East Africa is where most scientists place our species\u2019 origins : two of the oldest known  H. sapiens  fossils \u2014 196,000 and 160,000-year-old skulls 3 , 4  \u2014 come from Ethiopia, and  DNA studies of present-day populations around the globe  point to an African origin some 200,000 years ago 5 . \n             Decade-long dig \n           Hublin first visited Jebel Irhoud in the 1990s, only to find the site buried. He didn\u2019t have the time or money to excavate it until 2004, after he had joined the Max Planck Society. His team rented a tractor and bulldozer to remove some 200 cubic metres of rock that blocked access. Their initial goal was to re-date the site using newer methods, but in the late 2000s, the team uncovered more than 20 new human bones relating to at least five individuals, including a remarkably complete jaw, skull fragments and stone tools. A team led by archaeological scientist Daniel Richter and archaeologist Shannon McPherron, also at the Max Planck Institute for Evolutionary Anthropology, dated the site and all the human remains found there to between 280,000 and 350,000 years old using two different methods. The re-dating and the tranche of new human bones convince Hublin that early  H. sapiens  once lived at Jebel Irhoud. \u201cIt\u2019s a face you could cross in the street today,\u201d he says. The teeth \u2014 although big compared with those of today's humans \u2014 are a better match to  H. sapiens  than they are to Neanderthals or other archaic humans. And the Jebel Irhoud skulls, elongated compared with those of later  H. sapiens , suggest that these individuals' brains were organized differently. This offers clues about the evolution of the  H. sapiens  lineage into today\u2019s anatomically modern humans. Hublin suggests that anatomically modern humans may have acquired their characteristic faces before changes to the shape of their brains occurred. Moreover, the mix of features seen in the Jebel Irhoud remains and other  H. sapiens -like fossils from elsewhere in Africa point to a diverse genesis for our species, and raises doubt about an exclusively East African origin. \u201cWhat we think is before 300,000 years ago, there was a dispersal of our species \u2014 or at least the most primitive version of our species \u2014 throughout Africa,\u201d Hublin says. Around this time,  the Sahara was green and filled with lakes and rivers . Animals that roamed the East African savanna, including gazelles, wildebeest and lions, also lived near Jebel Irhoud, suggesting that these environments were once linked. \n             Genomic evidence \n           An earlier origin for  H. sapiens  is further supported by an ancient-DNA study posted to the bioRxiv preprint server on 5 June 6 . Researchers led by Mattias Jakobsson at Uppsala University in Sweden sequenced the genome of a boy who lived in South Africa around 2,000 years ago \u2014  only the second ancient genome from sub-Saharan Africa to be sequenced . They determined that his ancestors on the  H. sapiens  lineage split from those of some other present-day African populations more than 260,000 years ago. Hublin says his team tried and failed to obtain DNA from the Jebel Irhoud bones. A genomic analysis could have clearly established whether the remains lie on the lineage that leads to modern humans. Palaeontologist Jeffrey Schwartz, at the University of Pittsburgh, Pennsylvania, says the new finds are important \u2014 but he is not convinced that they should be considered  H. sapiens . Too many different-looking fossils have been lumped together under the species, he thinks, complicating efforts to interpret new fossils and to come up with scenarios on how, when and where our species emerged. \u201c Homo sapiens , despite being so well known, was a species without a past until now,\u201d says Mar\u00eda Mart\u00ednon-Torres, a palaeoanthropologist at University College London, noting the scarcity of fossils linked to human origins in Africa. But the lack of features that, she says, define our species \u2014 such as a prominent chin and forehead \u2014 convince her that the Jebel Irhoud remains should not be considered  H. sapiens . \n             Forefront of evolution \n           Chris Stringer, a palaeoanthropologist at the Natural History Museum in London, who co-authored  a News & Views article accompanying the studies , says he was baffled by the Jebel Irhoud remains when he first saw them in the early 1970s. He knew that they weren\u2019t Neanderthals, but they seemed too young and primitive-looking to be  H. sapiens . But with the older dates and the new bones, Stringer agrees that the Jebel Irhoud bones stand firmly on the  H. sapiens  lineage. \u201cThey shift Morocco from a supposed backwater in the evolution of our species to a prominent position,\u201d he adds. For Hublin, who was born in nearby Algeria and fled at the age of eight when its war of independence began, returning to North Africa to a site that has captivated him for decades was an emotional experience. \u201cI feel like I have a personal relationship with this site,\u201d he says. \u201cI cannot say we closed a chapter, but we came to such an amazing conclusion after this very long journey. It blows my mind.\u201d Read the related News & Views article: ' On the origin of our species ' \n                   How China is rewriting the book on human origins 2016-Jul-12 \n                 \n                   Oldest ancient-human DNA details dawn of Neanderthals 2016-Mar-14 \n                 \n                   Teeth from China reveal early human trek out of Africa 2015-Oct-14 \n                 \n                   'Pit of bones' catches Neanderthal evolution in the act 2014-Jun-19 \n                 \n                   Studies slow the human DNA clock 2012-Sep-18 \n                 \n                   Ethiopia is top choice for cradle of Homo sapiens 2005-Feb-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22231", "url": "https://www.nature.com/articles/nature.2017.22231", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Roman recipe lasted 2,000 years thanks to strengthening reactions with seawater. Ancient Romans built concrete sea walls that have withstood pounding ocean waves for more than 2,000 years. Now, an international team has discovered a clue to the concrete\u2019s longevity: a rare mineral produced during chemical reactions between the concrete and seawater that strengthen the material. Structural engineers might be able to use these insights to make stronger,  more-sustainable concrete , says team leader Marie Jackson, a geologist at the University of Utah in Salt Lake City. She and her colleagues report their findings on 3 July in  American Mineralogist 1 . Modern concrete uses a paste of Portland cement and water to hold together small rocks. It degrades within decades, especially in harsh marine environments. Instead of Portland cement, the Roman concrete used a mix of volcanic ash and lime to bind rock fragments. The Roman philosopher Pliny the Elder, described underwater concrete structures that become \u201ca single stone mass, impregnable to the waves and every day stronger.\u201d This piqued Jackson\u2019s interest. \u201cFor me the question was, how does this material become a rock?\u201d she says. In earlier work, Jackson and colleagues reported some of the unusual chemistry of Roman concrete, such as the presence of a rare mineral known as aluminium tobermorite 2 . For the new study, the scientists took samples of Roman harbour concrete to the Advanced Light Source, an X-ray synchrotron at Lawrence Berkeley National Laboratory in Berkeley, California, and mapped out the location of minerals in the samples. The researchers found a silicate mineral called phillipsite, which is common in volcanic rocks, with crystals of aluminium tobermorite growing from it. Tobermorite seems to have grown from the phillipsite when seawater, which is packed with calcium and silica, washed through the concrete, turning it more alkaline.\u00a0. \u201cIt's a very rare occurrence in the Earth,\u201d Jackson says, such crystallization has only been seen in places such as the Surtsey volcano in Iceland. As tobermorite grows, it may strengthen the concrete because its long, plate-like crystals allow the material to flex rather than shatter as it bends. \n             Applying ancient knowledge \n           Modern concrete-makers could learn from the ancient Romans\u2019 knowledge, says Nele De Belie, a materials engineer at  Ghent University in Belgium. She and her colleagues have used materials such as fly ash, produced during the burning of coal, to give concrete \u2018self-healing\u2019 properties, whereby the material closes up cracks after they form 3 . Fly ash is similar to the volcanic ash that Romans used in their mix. Jackson has been working to recreate the Romans\u2019 concrete recipe in the lab. \u201cI\u2019m not saying this would be the concrete that would be used in everyday infrastucture,\u201d she says. \u201cBut for materials like sea walls, we could formulate mixtures with lime and volcanic ash materials in the way that the Romans did.\u201d The Romans may have got their ideas from studying how ash from volcanic eruptions crystallized into durable rock, Jackson says. Jackson is a consultant for a cement company in Nevada that is using volcanic ash from the western United States to formulate such concretes. The process releases much less carbon dioxide, a greenhouse gas, than the usual methods for making modern concrete. \n                   Q&A: Concrete conservator 2014-Mar-05 \n                 \n                   Green cement: Concrete solutions 2013-Feb-20 \n                 \n                   Marie Jackson \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22018", "url": "https://www.nature.com/articles/nature.2017.22018", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Geneticists harness two mutations \u2014 each cherished by breeders, but detrimental when combined \u2014 to improve on 10,000 years of tomato domestication. From their giant fruits to compact plant size, today\u2019s tomatoes have been sculpted by thousands of years of breeding. But mutations linked to prized traits \u2014 including one that made them easier to harvest \u2014 yield an undesirable plant when combined, geneticists have found 1 . It is a rare example of a gene harnessed during domestication that later hampered crop improvement efforts, says geneticist Zachary Lippman of Cold Spring Harbor Laboratory in New York. After identifying the mutations, he and his colleagues used CRISPR gene editing to engineer more productive plants \u2014 a strategy that plant breeders are eager to adopt. \u201cIt\u2019s pretty exciting,\u201d says Rod Wing, a plant geneticist at the University of Arizona in Tucson. \u201cThe approach can be applied to crop improvement, not just in tomato, but in all crops.\u201d \n               Rotten tomatoes \n             Lippman knows his way around a tomato farm. As a teenager, he spent his summers picking the fruit by hand \u2014 a chore he hated. \u201cRotten tomatoes. The smell lasts all day long,\u201d he says. \u201cI would always pray for rain on tomato-harvest day.\u201d But years later, his interest in the genetics that control a plant\u2019s shape led him back to tomato fields, to untangle the genetic changes that breeders had unknowingly made. In the 1950s, researchers found a new trait in a wild tomato relative growing in the Gal\u00e1pagos Islands: it lacked the swollen part of the stem called the joint. Joints are weak regions of the stem that allow fruit to drop off the plant. Wild plants benefit from dropping fruit because it helps seed dispersal. But with the advent of mechanical tomato pickers, farmers wanted their fruit to stay on the plant. Breeders rushed to incorporate the \u2018jointless\u2019 trait into their tomatoes. This new trait came with a downside. When it was crossed into existing tomato breeds, the resulting plants had flower-bearing branches that produced many extra branches and looked like a broom, terminating in a host of flowers. The flowers were a drain on plant resources, diminishing the number of fruits it produced. Breeders selected for other genetic variants that overrode this defect. But decades later, Lippman's team went looking for the genes behind this phenomenon. \n               Two rights that make a wrong \n             They had previously screened a collection of 4,193 varieties of tomato, looking for those with unusual branching patterns 2 . From that collection, they tracked down variants of two genes that, together, caused extreme branching similar to what plant breeders had seen. One of the two genes, the team reports in a paper published online in  Cell  on 18 May, is responsible for the jointless trait 1 . The other gene favours the formation of a large green cap of leaf-like structures on top of the fruit \u2014 a trait that was selected for thousands of years ago, in the early days of tomato domestication. The benefits of this trait are unclear, Lippman says, but it may have helped to support heavier fruits. With these genes uncovered, his team used CRISPR\u2013Cas9 editing to eliminate their activity, as well as that of a third gene that also affects flower number, in various combinations. This generated a range of plant architectures, from long, spindly flower-bearing branches to bushy, cauliflower-like bunches of flowers \u2014 including some with improved yields. The findings should help to quell lingering doubts among plant breeders that negative interactions between desirable genetic traits are a force to be reckoned with, says Andrew Paterson, a plant breeder at the University of Georgia in Athens. The idea has been controversial, he says, because the effects have been difficult to detect statistically. Lippman\u2019s team is now working with plant breeders to use gene editing to develop tomatoes with branches and flowers optimized for the size of the fruit. Plants with larger fruit, for example, may have better yields if they have fewer flowering branches than those with smaller fruit. \u201cWe really are tapping into basic knowledge and applying it to agriculture,\u201d he says. \u201cAnd ironically, it happens to be in the crop that I least liked harvesting on the farm.\u201d \n                     Geneticists enlist engineered virus and CRISPR to battle citrus disease 2017-May-16 \n                   \n                     Dog family tree reveals hidden history of canine diversity 2017-Apr-25 \n                   \n                     CRISPR, microbes and more are joining the war against crop killers 2017-Mar-14 \n                   \n                     Ale genomics: how humans tamed beer yeast 2016-Sep-08 \n                   \n                     When chickens go wild 2016-Jan-20 \n                   \n                     Fiendish wheat genome reveals grain's history 2014-Jul-17 \n                   \n                     SolCAP Tomato Phenotype Data \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22290", "url": "https://www.nature.com/articles/nature.2017.22290", "year": 2017, "authors": [{"name": "Laura Castells"}], "parsed_as_year": "2006_or_before", "body": "Insects' structural secrets offer model for designing swarm robots. To cross streams or secure themselves against water currents, fire ants join forces to form rafts or build towers. Researchers have now worked out how the ants sustain tall structures without crushing their friends: they constantly circulate around the tower, behaving like a fluid. Fire ants ( Solenopsis invicta ) have sticky pads on their feet that help them to assemble collectively into shapes. Researchers had already  worked out the secrets of fire ants\u2019 raft-building techniques : the ants adhere to each other with their feet and orient themselves to create pockets of air, distributing their weight to form a buoyant structure. So a team co-led by Craig Tovey, a modelling mathematician at the Georgia Institute of Technology in Atlanta, sought to find out how the insects sculpt themselves into towers. In a laboratory, the team used high-speed cameras to record how the insects assemble around a slippery Teflon rod, and tagged half the colony with a radioactive tracer to see how the insects moved inside the tower structure. The ants use trial and error to form a tower, continuously rebuilding weaker parts that collapse until the structure is sound. Each individual insect can support up to three other ants, the researchers found. And when an ant is overloaded, it lets go of its neighbours and sinks down the column until it emerges outside the base of the tower. The result is a dynamic, bell-shaped structure that moves similarly to a fluid, and in which each ant carries an equal load. \u201cThe ants are circulating like a water fountain, in reverse,\u201d says Tovey. The work is published in  Royal Society Open Science 1 . \n             Dynamic structure \n           Scientists knew that the tower structures were dynamic, but the videos mark the first recording of the phenomenon, says Guy Theraulaz, an animal-behaviour researcher at the Research Centre on Animal Cognition in Toulouse, France. The team was also able to predict the shape and growth rate of the towers using mathematical models. They already knew that when fire ants form rafts, the feat depends on the behaviour of individual ants rather than on colony members following a central command. This individual behaviour can be described by three basic rules that can be fed into an mathematical model of the structure. The researchers were surprised to find out that when the ants build towers, they obey the same rules. The two shapes are different: the raft is static and tower dynamic, says Tovey. \u201cYet both structures follow the same decentralized rules.\u201d The findings could help robotics researchers who are trying to work out how to program swarms of minuscule robots to achieve a greater goal. \u201cUnderstanding how ants can build this variety of sound 3D structures following a very set of simple rules can help to figure out how program tiny multipurpose robots,\u201d says Tovey. \u201cThe next step is to figure out how they build bridges.\u201d \n                   Researchers create 1,000-robot swarm 2014-Aug-14 \n                 \n                   Termite-inspired robots build castles 2014-Feb-13 \n                 \n                   Ants team up to stay dry 2011-Apr-26 \n                 \n                   Ants avoid traffic jams 2004-Mar-04 \n                 Reprints and Permissions"},
{"file_id": "547145a", "url": "https://www.nature.com/articles/547145a", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Pared-back staff struggles to continue cybersecurity, climate-change and science-education efforts without direction from the Trump administration. US President Donald Trump has pledged to shrink the federal government, and he seems to be starting with science. Nearly six months after taking office,  Trump has not chosen a science adviser , and the White House\u2019s Office of Science and Technology Policy (OSTP) has dwindled from around 130\u00a0staff members under former president Barack Obama to 35. The vacancies have diminished the White House\u2019s ability to coordinate science policy and spending between agencies, and have left government-wide programmes on topics such as cybersecurity, regulation of genetically modified organisms and science education without clear direction. And the problem is expected to worsen, with the continuing exodus of the OSTP\u2019s non-political (or \u2018career\u2019) staff; four senior people left on 30 June alone. Many are frustrated that the White House is not calling on scientific expertise when making decisions.\u00a0 OSTP insiders fear that it may be difficult for the next science adviser \u2014 who normally directs the office \u2014 to restore it to its role of scientific coordinator. \u201cAnyone who is nominated, if they are confirmed, is going to have to play catch-up,\u201d says a former OSTP staff member, who is still a government employee and not authorized to speak to the press. \u201cAnd I don\u2019t know if they\u2019re ever really going to have a seat at the table.\u201d\u00a0 Trump has waited longer than most recent presidents to choose a science adviser. Obama and Bill Clinton each named theirs the month after they were elected, whereas George W.\u00a0Bush announced his pick in June 2001, about six months after taking office. A White House official says that  Trump is considering three or four candidates , but declined to say when a decision might be announced. For now, it is unclear who is running the OSTP. Long-time staff member Ted Wackler has been acting director since  Obama\u2019s science adviser, John Holdren , left in January. But a mid-level Trump appointee \u2014 deputy chief technology director Michael Kratsios \u2014 represents the office at meetings of the president\u2019s senior staff, the anonymous White House official says. That slot is normally occupied by the president\u2019s science adviser.\u00a0 Kratsios, former chief of staff to venture capitalist and Trump donor Peter Thiel, has helped to hire eight people to work on technology issues in three of the OSTP\u2019s five Obama-era divisions: environment and energy, national security and the office of the chief technology officer. But two divisions \u2014 science, and technology and innovation \u2014 are now completely unstaffed, according to several former employees. \u201cIt begs the question: if science and technology is in your name and you do not have a science or technology division, what are you doing?\u201d one former staffer says. The White House says that there are 12\u00a0people \u201cworking on science\u201d across the OSTP. \u201cThe scientists, policy experts and advisers at OSTP are constantly working together across the entire office,\u201d according to a statement provided to  Nature . \u201cWhat might have worked structurally under the Obama administration, with five separate divisions, actually looks pretty siloed today.\u201d Despite these changes, some of  Obama\u2019s big signature science programmes, such as the BRAIN Initiative  (Brain Research through Advancing Innovative Neurotechnologies), have matured enough for the agencies involved to continue them without White House support. \u201cMost of us tried to get everything done so [our programmes] could be on autopilot for six months or so,\u201d says Tamara Dickinson, who left her job as principal assistant deputy director of the office\u2019s environment and energy division in January. But the end of that period is approaching, and without a science adviser, OSTP career staff cannot establish new working groups, call meetings or approve budgets. As a result, says a former staffer, it is unclear which agency will handle science-education initiatives. And because  Trump\u2019s positions on the environment and climate change  clash with those of his predecessor, OSTP employees who work on these issues are at a standstill until they get clear direction from above. \u201cEveryone\u2019s sort of afraid to step too far out in front of knowing what the new leadership is going to want,\u201d Dickinson says. Meanwhile, individual agencies are doing what they can to keep projects on track. Jackie Richter-Menge, a polar researcher with the US Army Corps of Engineers\u2019 Cold Regions Research and Engineering Laboratory in Hanover, New Hampshire, says that the 16\u00a0agencies that coordinate the US Arctic research programmes have been working harder on issues such as data collection, scientific infrastructure and international cooperation since Trump took office. \u201cWe know the leadership\u2019s not there at the top of the pyramid,\u201d she says. \u201cWe know we need to keep things going.\u201d \n                     How Trump\u2019s science cuts could hurt states that voted for him 2017-May-17 \n                   \n                     Trump officials act to tilt federal science boards toward industry 2017-May-16 \n                   \n                     Trump agenda threatens US legacy of science diplomacy 2017-Jan-27 \n                   \n                     Rumours swirl about Trump's science adviser pick 2017-Jan-20 \n                   \n                     Does it matter if Donald Trump has a science adviser? 2016-Dec-08 \n                   \n                     Obama\u2019s top scientist talks shrinking budgets, Donald Trump, and his biggest regret 2016-Jul-06 \n                   \n                     Nature  special: Tracking the Trump White House \n                   \n                     White House Office of Science and Technology Policy \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22272", "url": "https://www.nature.com/articles/nature.2017.22272", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Clutch of DNA analyses show that ancient humans moved around on the continent far more than has been appreciated. Ignored for too long by researchers, ancient humans who lived in Africa thousands of years ago are finally having their genomes studied. Two projects released results this week on the genomes of around 20 individuals, which together reveal that the history of our species on the continent is much more complex than previously thought. Africa\u2019s neglect until now by ancient-DNA researchers was largely a result of the  continent\u2019s scorching climate . Because heat speeds the deterioration of DNA, scientists have focused on sequencing remains from cooler European sites and Siberian permafrost. The first success in Africa came in 2015, when researchers  sequenced the genome of a 4,500-year-old man from Ethiopia  who was preserved in a relatively chilly mountainous cave.\u00a0 But advances in removing contamination, and the discovery that a tiny\u00a0inner ear bone is chock full of\u00a0ancient DNA, have convinced\u00a0researchers that the technology is finally ready to grapple with\u00a0Africa\u2019s past. Stephan Schiffels, a population geneticist at the Max Planck Institute for the Science of Human History in Jena, Germany, says gaps in the knowledge of sub-Saharan African history are \u201cembarrassing\u201d \u2014 especially in light of how much researchers know about ancient peoples in Eurasia. This makes it all the more important to use DNA to uncover Africa's hidden history of human migration, he says. That is what a team led by Pontus Skoglund and David Reich, population geneticists at Harvard Medical School in Boston, Massachusetts, has now done. In a talk on 3 July at the Society for Molecular Biology\u2019s annual meeting in Austin, Texas, Skoglund said that his team had examined the genomes of 15 ancient individuals who lived as long as 6,000 years ago in eastern and southern Africa. He described a detailed analysis of 11 of them. \n               Highly mobile \n             The results showed that ancient humans moved around on the continent much more than was appreciated. The genome of a 3,000-year-old individual from Tanzania bore the ancestry not only of ancient East African hunter-gatherers but of early farmers from the Middle East. That supports  past studies that documented a \u2018back to Africa\u2019 migration several thousand years ago : these migrants were closely related to early farmers from the Levant region in the Middle East. The Tanzanian fossil was found at an archaeological site linked to animal herding, or pastoralism, and some of its genetic signatures have also been found in present-day pastoralists in southern Africa, Skoglund said. This suggests that East Africans took herding to southern Africa. The unpublished study from Skoglund\u2019s team revealed additional movement. The genome of a 2,000-year-old individual from southern Africa was related to those of contemporary southern African hunter-gatherers known as the San. It was also related to ancient genomes that the team had sequenced from hunter-gatherers whose remains were found in Malawi and Tanzania \u2014 but not to the DNA of the current inhabitants of East Africa. The reason for this, Skoglund suggested, is a well-documented migration of Bantu-speaking groups from western Africa, who brought agriculture and a distinct language to eastern and southern Africa 1,000\u20132,000 years ago. These migrants seem to have completely replaced local hunter-gatherers. An individual who lived on Tanzania\u2019s Zanzibar peninsula 750 years ago, after the migration, shared no ancestry with earlier hunter-gatherers from southern or East Africa. A separate team, led by Mattias Jakobsson at Uppsala University in Sweden, found evidence for the same migrations in the genome of a boy who lived 2,000 years ago near Ballito Bay in South Africa, and in the DNA of 6 other ancient southern Africans. Their study 1  was posted to the bioRxiv preprint server last month. Proof of migrations such as the Bantu expansion have been found at archaeological sites, as well as in the DNA of contemporary Africans, says Schiffels. But it is gratifying to have direct evidence of these movements, he notes. \n               Early days \n             Ancient African genomes also have the potential to illuminate much earlier events. Jakobsson\u2019s team used the Ballito Bay boy\u2019s genome to infer that  Homo sapiens  emerged at least 260,000 years ago \u2014 much earlier than previous genetic studies have suggested. Skoglund\u2019s team, meanwhile, used the ancient genomes it had sequenced to help uncover a possible \u2018ghost population\u2019. This, the team suggested, had diverged from the founding population of  H. sapiens  before any other African group, and later it contributed to the genetic make-up of some present-day West Africans. Iain\u00a0Mathieson, a population geneticist at the University of Pennsylvania in Philadelphia,\u00a0hopes that ancient African DNA can explain our species\u2019 migration out of Africa, some 50,000\u2013100,000 years ago, by painting a genetic picture of the continents\u2019 inhabitants around this time. This might require DNA much older than a few thousand years \u2014 and obtaining this could require another major technical advance. Analysis of bones thought to be about 300,000 years old from Morocco,  attributed to the earliest-known  H. sapiens , has so far yielded no usable DNA. \u201cIt\u2019s early days,\u201d for ancient African genomics, says Mathieson. \u201cIt really is.\u201d \n                     Oldest Homo sapiens fossil claim rewrites our species' history 2017-Jun-07 \n                   \n                     Farming invented twice in Middle East, genomes study reveals 2016-Jun-20 \n                   \n                     Ancient DNA from hot climes yields its secrets 2015-Oct-13 \n                   \n                     First ancient African genome reveals vast Eurasian migration 2015-Oct-08 \n                   \n                     African genes tracked back 2013-Aug-27 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22117", "url": "https://www.nature.com/articles/nature.2017.22117", "year": 2017, "authors": [{"name": "Lauren Morello"}], "parsed_as_year": "2006_or_before", "body": "Geneticist has led the biomedical research agency since 2009. US President Donald Trump has chosen Francis Collins to lead the National Institutes of Health (NIH) on a permanent basis, the White House announced on 6 June. Collins,  who has led the agency since August 2009 , is a holdover from the administration of president Barack Obama \u2014 and is now the first NIH director since the 1970s to be chosen by two presidents. In January,  Trump asked Collins to stay at the NIH temporarily  while the White House evaluated candidates to lead the agency.  Rumoured contenders  included Representative Andy Harris (Republican, Maryland), an anaesthesiologist; retired Army neurosurgeon Geoffrey Ling, the former director of biotechnology at the Defense Advanced Research Projects Agency; and billionaire surgeon Patrick Soon-Shiong, who runs a network of health companies called NantWorks. Before taking over the top job at the NIH, Collins was perhaps best known for his leadership of the Human Genome Project, which in 2000 published the first \u2018rough draft\u2019 of the genome. As NIH director,  Collins has launched several large research projects , including the Brain Research Through Advancing Innovative Neurotechnologies (BRAIN) initiative to map the human brain; the Precision Medicine Initiative, which includes an ambitious study of health records and genomic information from one million people in the United States; and the Cancer Moonshot, a US$1-billion proposal to double the pace of cancer research in five years. Trump has put forth several proposals to reshape how the biomedical-research agency functions \u2014  including a plan to cut the NIH budget by 18% in 2018, to US$26 billion . Much of the savings would come from changing the system that the NIH uses to reimburse grantees\u2019 institutions for expenses such as administration and facilities maintenance, which are collectively known as \u201cindirect costs\u201d. It is not clear whether Congress will go along with this plan; in early May, lawmakers approved a 2017 budget that  increased the NIH\u2019s funding by $2 billion  over the 2016 level, to about $34 billion. \n                   NIH to limit the amount of grant money a scientist can receive 2017-May-03 \n                 \n                   NIH director Francis Collins staying on \u2014 for now 2017-Jan-19 \n                 \n                   Surprising contenders emerge for Trump\u2019s NIH chief 2017-Jan-13 \n                 \n                   Obama\u2019s science legacy: betting big on biomedical science 2016-Aug-22 \n                 \n                   Back to the thesis 2016-Jul-06 \n                 \n                   Francis Collins named as NIH chief 2009-Jul-09 \n                 \n                   Nature  special: Tracking the Trump White House \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22236", "url": "https://www.nature.com/articles/nature.2017.22236", "year": 2017, "authors": [], "parsed_as_year": "2006_or_before", "body": "June\u2019s sharpest science shots, selected by  Nature \u2019s photo team. \n             Taxonomic titan \n           \n             Disco rover \n           \n             Cassini\u2019s swansong continues \n           \n             Not-Saturn \n           \n             Helpful\u00a0 \n             Hyalinobatrachium \n           \n             Secure seeds \n           \n             Coral crystals \n           \n             Aftermath \n           \n             Super shock \n           \n                   Horatio\u2019s head, arty ants and an ephemeral lake 2017-May-30 \n                 \n                   Golden neurons, river piracy and bright nights 2017-Apr-28 \n                 \n                   Space ravioli, nuclear explosions and a synthetic sun 2017-Mar-31 \n                 Reprints and Permissions"},
{"file_id": "547148a", "url": "https://www.nature.com/articles/547148a", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Physicists find ways to make LIGO and other gravitational-wave detectors even more sensitive. Gravitational-wave observatories have some of the most sensitive detectors on the planet, which allows them to spot the faint ripples in space-time that pass through Earth from  the collisions of massive black holes billions of light years away . But their ability to catch more subtle signals is constrained by fundamental quantum limits. Now physicists are devising tricks to get around this problem. The goal is to peer farther into the Universe and to spot the effects of collisions between less massive objects, such as neutron stars. The US-based Advanced Laser Interferometer Gravitational-Wave Observatory (LIGO) is already planning to use photonics techniques to \u2018squeeze\u2019 light. That should increase LIGO\u2019s sensitivity by 50%. Quantum physicists from outside the gravitational-wave community are pitching in with new ideas, too. In  Nature  this week, they describe a technique that could, in theory, double the sensitivity of detectors ( C.\u00a0B.\u00a0M\u00f8ller et al. Nature 547, 191\u2013195; 2017 ). \u201cWe\u2019ve been eagerly looking for applications where quantum limits have already been reached,\u201d says physicist Eugene Polzik at the Niels Bohr Institute in Copenhagen, who led the latest work.\u00a0 \n               LIGO\u2019s quantum limits \n             Each of LIGO\u2019s detectors, based in Hanford, Washington, and Livingston, Louisiana, consists of two 4-kilometre-long tunnels perpendicular to one another, with mirrors at both ends. A beam of laser light is split and bounced back and forth along each tunnel. A gravitational wave stretches one arm and squeezes the other. Because light then travels a different distance down each arm, the two beams are out of sync when they are recombined. Using this method, LIGO can spot shifts as small as 10 \u201319  metres\u00a0\u2014 about one ten-thousandth the width of a proton.\u00a0 Engineers shield LIGO from the rumble of distant trucks and compensate for tiny temperature fluctuations. But the quantum nature of laser light creates fundamental uncertainties in measurement. It\u2019s impossible to know exactly how many photons are in the laser beams that reach LIGO\u2019s detectors, creating noise in the distance measurement. Photons also impart a kick of momentum to LIGO\u2019s mirrors as they hit them. As photon numbers fluctuate, they shift the mirrors by an unknowable amount, adding further uncertainty. Polzik and his team get round the latter limit by giving photons an opposite kick to compensate. In their set-up, laser light passes through a cloud of caesium atoms before it hits its target\u00a0\u2014\u00a0which is a membrane, rather than a mirror. The researchers artificially inverted the atomic spins of the caesium atoms, so that a passing photon\u2019s kick flips the atomic spins to a lower, rather than a higher, energy state. By taking measurements of the membrane\u2019s position from the point of view of this atomic cloud, the effects of both kicks can be cancelled out\u00a0\u2014\u00a0in principle entirely. In practice, the technique allowed the team to cut uncertainty by 34%. The method is exciting, says Nergis Mavalvala, a physicist at the Massachusetts Institute of Technology in Cambridge and member of the LIGO collaboration. \u201cEven though exactly how it would work in a gravitational-wave detector is technically quite unexplored, the first calculations look promising,\u201d she says. Polzik\u2019s team is now working with the University of Moscow and the Russian Quantum Center in Skolkovo near Moscow to develop the idea further. The team is also discussing its method with gravitational-wave researchers at LIGO and at the Max Planck Institute for Gravitational Physics in Hanover, Germany, which operates a smaller gravitational-wave detector, called GEO600. Adapting the technique could take five to ten years, but it has the potential to double the sensitivity of the detectors, says Polzik, which would mean covering an eight times larger volume of the Universe. \u201cNow that begins to sound serious,\u201d he says. \n               Squeezed light \n             Physicists at LIGO are independently planning to use a technique called  squeezed light to suppress quantum noise . This is already used at GEO600 and was trialled in an earlier phase of LIGO. It is impossible to simultaneously reduce uncertainty about two complementary properties of photons\u00a0\u2014\u00a0such as position and momentum. But it is possible to \u2018squeeze\u2019 light to reduce uncertainty in one of these dimensions, at the expense of an increase in the other.\u00a0 The precision with which LIGO can detect high-frequency gravitational waves is limited by fuzziness in the number of photons that hit LIGO\u2019s detectors \u2014 and researchers can squeeze just that dimension. For detecting low-frequency waves, however, it is fluctuations in momentum that limit precise measurement. To simultaneously reduce the noise for both effects requires light to be differently squeezed for different frequencies of wave. In about five years, LIGO aims to begin using a device called a filter cavity to do this, which should improve sensitivity across LIGO\u2019s entire detection band. Others hope additional quantum tricks will remove the need for extra equipment. Yiqiu Ma at the California Institute of Technology in Pasadena and his colleagues have theorized a way of squeezing light for all frequencies by entangling two beams\u00a0\u2014\u00a0meaning that their properties are intrinsically linked, so that measuring the uncertainty in one predicts the uncertainty in the other. The quest to push the limits of quantum measurement can yield benefits beyond gravitational-wave detectors, says Polzik. \u201cThese kinds of studies are critical to exploring the very boundaries of quantum mechanics.\u201d \n                     LIGO spots gravitational waves for third time 2017-Jun-01 \n                   \n                     LIGO\u2019s underdog cousin ready to enhance gravitational-wave hunt 2017-Feb-08 \n                   \n                     The black-hole collision that reshaped physics 2016-Mar-23 \n                   \n                     Sensor turns faintest radio waves into laser signals 2014-Mar-05 \n                   \n                     Squeezed light mutes quantum noise 2013-Aug-07 \n                   \n                     Physics: Quantum all the way 2008-Apr-30 \n                   \n                     Nature  Special: Gravitational waves \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22345", "url": "https://www.nature.com/articles/nature.2017.22345", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "National security community examines the risks and benefits of technology to quickly spread genetic modifications. The JASONs, a\u00a0 group of\u00a0elite\u00a0scientists that\u00a0advises\u00a0the US government on national security , has weighed in on\u00a0issues ranging from cyber security\u00a0\u200bto\u00a0renewing America\u2019s\u00a0nuclear arsenal. But at a meeting in June, the secretive group\u00a0took stock of a new threat:\u00a0gene drives, a genetic-engineering\u00a0technology\u00a0that can swiftly spread modifications through entire populations and\u00a0could  help vanquish malaria-spreading mosquitoes . That meeting forms part of a broader US national security effort this year to grapple with the possible risks and benefits of a technology that could  drive species extinct and alter whole ecosystems . On 19 July, the US Defense Advanced Research Projects Agency (DARPA) announced US$65 million in funding to scientists studying gene-editing technologies; most of the money will be for work on gene drives. And a US intelligence counterpart to DARPA is planning to fund research into detecting organisms containing gene drives and other modifications. \u201cEvery powerful technology is a national security issue,\u201d says Kevin Esvelt, an evolutionary engineer at the Massachusetts Institute of Technology in Cambridge, who won DARPA funding to limit the spread of gene drives. Esvelt says he also attended last month\u2019s JASON meeting in San Diego, California, where he outlined how would-be bioterrorists might weaponize gene drives. But he is far more concerned about the potential for accidental release of gene-drive organisms by scientists, he says. \u201cBio-error is what I\u2019m worried about.\u201d So, too, is the US military, according to Renee Wegrzyn, the DARPA programme officer leading its \u2018Safe Genes\u2019 initiative, which supports research on restraining gene drives. The technology has been developed in recent years in fruit flies, mosquitoes and other organisms, using CRISPR gene editing. A UK-based team  hopes to begin field tests of gene drives in  Anopheles gambiae  mosquitoes , the main carrier of malaria in Africa, as soon as 2024. \u201cI\u2019ve been very excited to watch the advances, but I\u2019ve noted with increasing concern that the advances are outpacing biosecurity,\u201d Wegrzyn says. The JASONs' gene-drive discussion involved around 20 scientists, according to Philipp Messer, a population geneticist at Cornell University in Ithaca, New York, who attended the meeting. (As a German citizen, he was identified as a foreign national and accompanied by an escort.) \u201cI\u2019m not used to that kind of conference,\u201d says Messer, who says he told the group about his lab\u2019s efforts  to study the evolution of resistance to CRISPR gene drives in fruit flies . \u201cWe just had open discussions about this technology and what we think the current state of the field was and what we think the problems are.\u201d Gerald Joyce, a biochemist at the Salk Institute in La Jolla, California, and a JASON member who Messer says co-organized the meeting, declined to comment on the meeting, which is likely to lead to a classified report. \n               Gene drive countermeasures \n             Under the DARPA programme, seven teams won four-year contracts. Esvelt plans to develop CRISPR gene drives in nematode worms \u2014 a fast-reproducing model organism \u2014 that are designed to spread a genetic modification in a local setting and then fizzle out, a concept that other scientists are pursuing. He and the other teams receiving military funding also plan to develop tools to counter rogue gene drives that spread out of control. Such methods include chemicals that block gene-editing or \u2018anti-gene drives\u2019 that can reverse a genetic modification or immunize unaltered wild organisms so they are resistant to a gene drive. These tools could combat a gene drive deployed to do harm, such as those that engineer insects to transmit diseases more effectively or deliver toxins. But such countermeasures are far more likely to be deployed against accidental gene-drive releases from research labs, says Esvelt. Lax or non-existent biosafety guidelines for working on gene-drive organisms increase the odds of a release, he says. Other efforts are afoot to fund work studying the national security implications of gene drives. Next week, the Intelligence Advanced Research Projects Agency (IARPA), which is part of the Office of the US Director of National Intelligence, will hold a meeting about a planned funding programme for detecting genetically modified organisms that are potentially harmful, including ones that contain gene drives. Todd Kuiken, who studies policy relating to synthetic biology at North Carolina State University in Raleigh, is glad to see gene-drive research receive more funding. But he has qualms about the US military\u2019s interest in the field; with Safe Genes, DARPA has become the world\u2019s largest government funder of gene-drive research. Kuiken worries that this could sow suspicions about gene drives in parts of the world that view the US military in a less-than-favourable light, including countries that stand to benefit from the elimination of disease carriers such as mosquitoes. Esvelt shares those concerns but sees military support as the only way, for the time being, to advance gene-drive technology, while making it safer for eventual deployment. Private funders such as the Bill and Melinda Gates Foundation, in Seattle, Washington, and the Tata Trusts, a Mumbai-based charity, have spent tens of millions on gene-drive research, but this funding has been directed to specific projects or institutions; other government funders have not yet made large contributions to the field. \u201cNo one else is offering us large amounts of money,\u201d Esvelt says. The DARPA programme explicitly prevents the release of gene-drive organisms and requires contract winners to work under stringent biosafety conditions and to disclose their planned experiments to the public \u2014 measures that should reduce the risk of any accidental release, Esvelt adds. \u201cIf what you\u2019re worried about is your cowboys running amok and causing trouble, then what you really want to do is employ the cowboys to make sure they stay out of trouble.\u201d \n                     Gene drives thwarted by emergence of resistant organisms 2017-Jan-31 \n                   \n                     Fast-spreading genetic mutations pose ecological risk 2016-Jun-08 \n                   \n                     Gene editing can drive science to openness 2016-Jun-08 \n                   \n                     Mosquitoes engineered to pass down genes that would wipe out their species 2015-Dec-07 \n                   \n                     'Gene drive' mosquitoes engineered to fight malaria 2015-Nov-23 \n                   \n                     Safety upgrade found for gene-editing technique 2015-Nov-16 \n                   \n                     Caution urged over editing DNA in wildlife (intentionally or not) 2015-Aug-04 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22374", "url": "https://www.nature.com/articles/nature.2017.22374", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Scientists hope studying last month\u2019s deadly event will improve modelling of rockslides that could become more frequent with climate change. One of the tallest tsunamis in recorded history \u2014 a 100-metre-high wave that devastated a remote settlement in  Greenland  last month \u2014 was caused, unusually, by a massive landslide, researchers report.\u00a0 Seismologists returning from studying the rare event hope that the data they have collected will improve models of landslide mechanics in glacial areas and provide a better understanding of the associated tsunami risks. They warn that such events could become more frequent as the climate warms. The landslide occurred on the evening of 17 June, in the barren Karrat Fjord on the west coast of Greenland. It caused a sudden surge of seawater that wreaked havoc in the fishing village of Nuugaatsiaq, located on an island within the fjord about 20 kilometres away (see \u2018Greenland tsunami\u2019). The wave washed away eleven houses, and four people are presumed dead. The slide was so large that it generated a seismic signal suggestive of a magnitude-4.1 earthquake, confounding initial efforts to identify its cause, says Trine Dahl-Jensen, a seismologist at the Geological Survey of Denmark and Greenland. But more careful examination indicated no significant tectonic activity just before the landslide. A research team that visited the site earlier this month found that a large volume of rock had plunged \u2014 probably spontaneously \u2014 from one of the steep sides of the fjord into the water 1,000 metres below, and shattered chunks of a glacier. That disturbance pushed water levels up by more than 90 metres along the coastline on the same side as the slide. And although the tsunami dissipated quickly as it crossed the deep, six-kilometre-wide fjord, it still had enough energy to send water 50 metres up the hillside opposite. The team also measured an increase in water levels of about 10 metres on shorelines 30 kilometres away. \u201cLandslide-generated tsunamis are much more locally limited than tsunamis produced by sea quakes, but they can be massively tall and devastating in the vicinity,\u201d says Hermann Fritz, an environmental engineer at the Georgia Institute of Technology in Atlanta who led the research team. \n             On the rocks \n           Fritz and his team hope to produce a 3D reconstruction of the Greenland event. Such information is sorely needed, says Costas Synolakis, a tsunami researcher at the University of Southern California in Los Angeles who was not involved in the Greenland survey. In cold, glacial regions, rocks and ice are held together on steep rock sides, and rising temperatures could make these slopes unstable and these events more common. Synolakis says that his team has documented in detail only two landslides near glaciers. \u201cWe need at least ten such events to be able to have some rudimentary confidence in landslide computational models to study future impacts and establish early warning criteria.\u201d Researchers have noted another potentially imminent\u00a0landslide in the Karrat Fjord, says Fritz, where a slow trickle of rocks could turn into abrupt slide. Residents of three villages in the region have been permanently evacuated to the nearby town of Uummannaq. Fritz adds that the Greenland event is reminiscent of a 1958 tsunami \u2014 the tallest ever recorded 1  \u2014 in Lituya Bay, Alaska. A magnitude-8.3 quake triggered a landslide into a narrow fjord and the bay\u2019s shallow water, causing the water to rise 500 metres above the normal tide level (a measure known as run-up). By comparison, the  2011 quake-triggered tsunami in Japan , which killed more than 16,000 people and caused the  Fukushima nuclear disaster , reached only about 40 metres at its maximum height. And in 2015, a landslide-generated tsunami in the Taan Fjord in Icy Bay, Alaska, caused a 300-metre run-up of water, says Synolakis.\u00a0 \u201cEarlier, we didn\u2019t really believe such extremes were possible,\u201d he says. \u201cBut with global warming and sea level rise, such landslides are going to be far more common.\u201d \n                   Tsunami alerts fail to bridge the \u2018last mile\u2019 2014-Dec-10 \n                 \n                   Tsunami forecasting: The next wave 2012-Mar-07 \n                 \n                   On the trail of destruction 2005-Jan-26 \n                 \n                   International Tsunami Information Center \n                 Reprints and Permissions"},
{"file_id": "547389a", "url": "https://www.nature.com/articles/547389a", "year": 2017, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Transplanted cells offer middle-aged rodents an increased lifespan. Stem cells in the brain could be the key to extending life and slowing ageing. These cells \u2014 which are located in the hypothalamus, a region that produces hormones and other signalling molecules \u2014 can re\u00adinvigorate declining brain function and muscle strength in middle-aged mice, according to a study published on 26 July in  Nature 1 . Shamini Bundell discovers more about the brain\u2019s role in ageing Previous studies have  suggested that the hypothalamus is involved in ageing , but the latest research shows that stem cells in this region can slow the process. That makes sense, because the hypothalamus is involved in many bodily functions, including inflammation and appetite, says Dongsheng Cai, a neuroendocrinologist at Albert Einstein College of Medicine in New York City. In their study, Cai and his colleagues found that stem cells in the hypothalamus disappear as mice grow older. When the researchers injected their mice with viruses that destroy these cells, the animals seemed to grow older faster, experiencing declines in memory, muscle strength, endurance and coordination. They also died sooner than untreated mice of the same age. Next, the team injected stem cells taken from the hypothalami of newborn mice into the brains of middle-aged mice. After four months, these animals had better cognitive and muscular function than untreated mice of the same age. They also lived about 10% longer, on average. The researchers found that these stem cells release molecules called microRNAs, which help to regulate gene expression, into the cerebro\u00adspinal fluid. When the team injected these microRNAs into the brains of middle-aged mice, they found that the molecules slowed cognitive decline and muscle degeneration. \n               Forever young \n             It's an interesting paper, says Leonard Guarente, a molecular biologist at the Massachusetts Institute of Technology in Cambridge, who studies ageing. He adds that it could lead to various ways of developing anti-ageing therapies in people. Stem-cell therapies might enhance the ability of the hypothalamus to act as a master regulator, given that the latest results suggest it controls ageing through signalling peptides such as hormones and microRNAs, Cai says. He says that his team is trying to identify which of the thousands of types of microRNA produced are involved in ageing, and hopes to investigate whether similar mechanisms exist in non-human primates. The findings represent a breakthrough in ageing research, says Shin-ichiro Imai, who studies ageing at Washington University in St Louis, Missouri. The next steps would be to link these stem cells with other physiological mechanisms of ageing, he says. For instance, these cells may have a role in regulating the neurons that release a hormone called GnRH, which is secreted by the hypothalamus and is associated with ageing. Imai would also like to know whether the microRNAs from the cells can pass into the bloodstream, which would carry them throughout the body. Cai suspects that anti-ageing therapies targeting the hypothalamus would need to be administered in middle age, before a person\u2019s muscles and metabolism have degenerated beyond a point that could be reversed. It is unclear by how much such a therapy could extend a human lifespan, but Guarente says that slowing the effects of ageing is the more important goal. \u201cLiving longer isn\u2019t important if you\u2019re not healthy,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Sara_Reardon \n               \n                     Young human blood makes old mice smarter 2017-Apr-19 \n                   \n                     Ageing research: Blood to blood 2015-Jan-21 \n                   \n                     Molecules in the brain trigger ageing 2013-May-01 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22375", "url": "https://www.nature.com/articles/nature.2017.22375", "year": 2017, "authors": [{"name": "Dalmeet Singh Chawla"}], "parsed_as_year": "2006_or_before", "body": "One of scientists\u2019 favourite statistics \u2014 the  P  value \u2014 should face tougher standards, say leading researchers. Science is in the throes of  a reproducibility crisis , and researchers, funders and publishers are increasingly worried that the scholarly literature is littered with unreliable results. Now, a group of 72 prominent researchers is targeting what they say is one cause of the problem: weak statistical standards of evidence for claiming new discoveries. In many disciplines the significance of findings is judged by  P  values. They are used to test (and dismiss) a \u2018null hypothesis\u2019, which generally posits that the effect being tested for doesn\u2019t exist. The smaller the  P  value that is found for a set of results, the less likely it is that the results are purely due to chance. Results are deemed 'statistically significant' when this value is below 0.05. But many scientists worry that the 0.05 threshold  has caused too many false positives to appear in the literature , a problem exacerbated by a practice called  P  hacking, in which researchers gather data without first creating a hypothesis to test, and then look for patterns in the results that can be reported as statistically significant. So, in a provocative manuscript posted on the PsyArXiv preprint server on 22 July 1 , researchers argue that  P -value thresholds should be lowered to 0.005 for the social and biomedical sciences. The final paper is set to be published in  Nature Human Behaviour . \u201cResearchers just don\u2019t realize how weak the evidence is when the  P  value is 0.05,\u201d says Daniel Benjamin, one of the paper\u2019s co-lead authors and an economist at the University of Southern California in Los Angeles. He thinks that claims with  P  values between 0.05 and 0.005 should be treated merely as \u201csuggestive evidence\u201d instead of established knowledge. Other co-authors include two heavyweights in reproducibility: John Ioannidis, who studies scientific robustness at Stanford University in California, and Brian Nosek, executive director of the Center for Open Science in Charlottesville, Virginia. \n               Super-sized samples \n             One problem with reducing  P -value thresholds is that it may increase the odds of a false negative \u2014 stating that effects do not exist when in fact they do \u2014 says Casper Albers, a researcher in psychometrics and statistics at the University of Groningen in the Netherlands. To counter that problem, Benjamin and his colleagues suggest that researchers increase sample sizes by 70%; they say that this would avoid increasing rates of false negatives, while still dramatically reducing rates of false positives. But Albers thinks that in practice, only well-funded scientists would have the means to do this. Shlomo Argamon, a computer scientist at the Illinois Institute of Technology in Chicago, says there is no simple answer to the problem, because \u201cno matter what confidence level you choose, if there are enough different ways to design your experiment, it becomes highly likely that at least one of them will give a statistically significant result just by chance\u201d. More-radical changes such as new methodological standards and research incentives are needed, he says. Lowering  P -value thresholds may also exacerbate the \u201cfile-drawer problem\u201d, in which studies with negative results are left unpublished, says Tom Johnstone, a cognitive neuroscientist at the University of Reading, UK. But Benjamin says all research should be published, regardless of  P \u00a0value. \n               Moving goalposts \n             Other scientific fields have already cracked down on  P  values \u2014 and in 2015,  one psychology journal banned them . Particle physicists, who collect reams of data from atom-smashing experiments, have long demanded a  P  value below 0.0000003 (or 3\u00a0\u00d7\u00a010 \u22127 ) because of concerns that a lower threshold could lead to mistaken claims, notes Valen Johnson, a statistician at Texas A&M University in College Station and a co-lead author of the paper. More than a decade ago, geneticists took similar steps to establish a threshold of 5\u00a0\u00d7\u00a010 \u22128  for genome-wide association studies, which look for differences between people with a disease and those without across hundreds of thousands of DNA-letter variants. Yet other scientists have abandoned  P  values in favour of more-sophisticated statistical tools, such as Bayesian tests, which require researchers to define and test two alternative hypotheses. But not all researchers will have the technical expertise to carry out\u00a0Bayesian tests, says Johnson, who thinks that  P  values can still be useful for gauging whether a hypothesis is supported by evidence. \u201c P  value by itself is not necessarily evil.\u201d \n                     Statisticians issue warning over misuse of P values 2016-Mar-07 \n                   \n                     Reproducibility: A tragedy of errors 2016-Feb-03 \n                   \n                     How scientists fool themselves \u2013 and how they can stop 2015-Oct-07 \n                   \n                     Statistics: P values are just the tip of the iceberg 2015-Apr-28 \n                   \n                     Psychology journal bans P values 2015-Feb-26 \n                   \n                     Scientific method: Statistical errors 2014-Feb-12 \n                   Related external links Reprints and Permissions"},
{"file_id": "548015a", "url": "https://www.nature.com/articles/548015a", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Officials at the US Environmental Protection Agency are consulting global-warming sceptics as they weigh up a technical review. A\u00a0sweeping US government report on the state of climate-change science is nearing the finish line, but researchers who wrote it aren\u2019t ready to relax just yet. Federal scientists have twice reviewed the roughly 600-page document \u2014 which examines everything from shifting weather patterns to rising sea levels \u2014 as have the US National Academies of Sciences, Engineering, and Medicine. Just one hurdle remains, but it may be the highest: final sign-off by top officials in President Donald Trump\u2019s administration,  many of whom are sceptical of climate science . Although there have not yet been any signs of trouble, researchers are keeping a close eye on how the White House and federal agencies handle the science report \u2014 a technical prelude to the fourth National Climate Assessment, a legally mandated analysis of the causes and impacts of global warming that is due in 2018.\u00a0 Many climate scientists are particularly uneasy about the potential for interference by the US Environmental Protection Agency (EPA), one of 13 agencies that must approve the science report before its expected release in November. EPA administrator Scott Pruitt,  who rejects well-established climate science , has raised the possibility of organizing an adversarial \u2018red team\u2013blue team\u2019 review of such research. And he has help from the Heartland Institute, a think tank in Chicago, Illinois, that promotes scepticism about climate change.\u00a0 \u201cWe can\u2019t allow science to be held hostage,\u201d says Donald Wuebbles, a climate scientist at the University of Illinois at Urbana-Champaign and co-chair of the report. \u201cI\u2019m hopeful it won\u2019t get to that, because it would look really bad for the administration to fight this.\u201d It wouldn\u2019t be the first time that a Republican president had sought to stymie the United States\u2019 national climate-assessment process. The administration of George W. Bush came under fire for ignoring the first National Climate Assessment, which was released by then-President Bill Clinton in 2000. After the Bush administration subsequently missed the legal deadline in 2004 to complete a second assessment, environmentalists sued the government in federal court to compel the report\u2019s release \u2014 and won. The message of the latest science report \u2014 that human-caused global warming poses urgent problems for the United States \u2014 isn\u2019t likely to sit well with the White House. The Trump administration has sought to repeal environmental regulations and  cut climate research . Energy secretary Rick Perry has joined Pruitt in  questioning climate science . And Pruitt\u2019s chief of staff, Ryan Jackson, once worked for Senator James Inhofe (Republican, Oklahoma), a prominent climate sceptic.\u00a0 \u201cThis is going to be the first big test in the climate arena,\u201d says Tammy Dickinson, who led the energy and environment division at the White House Office of Science and Technology Policy (OSTP) under president Barack Obama. One major issue, she adds, is that Trump  has yet to fill many positions at the OSTP  \u2014 which has coordinated work on the last three government climate assessments \u2014 or high-level science posts at federal agencies that work on climate change. At the EPA, rank-and-file staff say that they haven\u2019t been told who will sign off on the science report, or how the OSTP will manage the final review process. Agency scientists told  Nature  that climate change has become taboo in their discussions with EPA leadership. The fact that agency leaders have consulted with climate sceptics has only added to the confusion.\u00a0 One EPA official, who asked for anonymity because of career concerns, provided  Nature  with two lists circulating among Pruitt\u2019s team that seem to have been compiled by the Heartland Institute. One list, labelled \u201cclimate scientists\u201d, contains the names of more than 140 people, including many climate sceptics; the second names several dozen climate economists.\u00a0 The Heartland Institute would not comment on the documents, but a spokesman confirmed that Heartland has provided the EPA with names of people for a climate science \u2018red team\u2019. Many agency researchers assume that Pruitt will use the lists to assemble that team, but some fear that it could be used to identify candidates for empty slots on the EPA\u2019s Board of Scientific Counselors, which advises the agency\u2019s research arm. An EPA spokeswoman declined to comment on the lists or the science report.  For the anonymous official, the question now is whether the adversarial approach embodied by the \u2018red team\u2019 idea will drive the Trump administration to delay the science report. \u201cThey are aware of the report,\u201d the official says. \u201cWe don\u2019t know what they are going to do.\u201d Then there is the broader national climate assessment, which will delve into questions that have profound implications for government policy, such as how coastal communities should respond to rising seas. That document is expected to go out to federal agencies this month.\u00a0 Pruitt will have to be careful how he handles both documents, says Kyla Bennett, a former EPA ecologist who now works for the watchdog group Public Employees for Environmental Responsibility in North Easton, Massachusetts. The EPA could ignore the climate report\u2019s findings while implementing policies that affect the oil, gas and coal industries, which Trump has vowed to protect and promote. But if the administration pushes regulations that ignore mainstream climate science, Bennett says, it is likely to face lawsuits from environmental and science groups. \u201cThe EPA is supposed to be using the best science out there,\u201d she says. \u201cThey can\u2019t just suddenly say the Earth is flat, CO 2  is not a pollutant and coal is the best thing for the world.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @jefftollef \n               \n                     Seek climate advice through established routes 2017-Aug-01 \n                   \n                     How scientists reacted to the US leaving the Paris climate agreement 2017-Jun-02 \n                   \n                     Trump pulls United States out of Paris climate agreement 2017-Jun-01 \n                   \n                     Republican scientists negotiate the Trump era 2017-Apr-18 \n                   \n                     How Trump plans to wipe out Obama-era climate rules 2017-Mar-28 \n                   \n                     Trump and Republicans take aim at environmental agency 2017-Mar-10 \n                   Related external links Reprints and Permissions"},
{"file_id": "548014a", "url": "https://www.nature.com/articles/548014a", "year": 2017, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "The country wants to use a focus on research to solve its problems and build diplomatic ties in the Middle East. When the World Science Forum kicks off on the shore of the Dead Sea in November, it will be the latest jewel in the crown for one of Jordan\u2019s biggest champions of science. Princess Sumaya bint El Hassan successfully lured the high-profile biennial conference to the Middle East for the first time \u2014 part of Jordan\u2019s ongoing push to transform itself into a regional research powerhouse. The country hopes to emphasize the power of science to transcend politics and war in the increasingly volatile Middle East.\u00a0 It\u2019s a tall order, but there are signs that these efforts are beginning to pay off for Jordan, which created its first national science fund in 2005. In February, the country cemented plans for a reticular-chemistry foundry, the world\u2019s first. And in May, the Middle East\u2019s first synchrotron, SESAME, opened near Amman with the backing of seven nations and the Palestinian Authority.\u00a0 Jordan\u2019s leaders see science, engineering and technology as an engine of economic growth for their 71-year-old country, which lacks the oil resources of many neighbouring states. The nation\u2019s political stability and central location have aided these ambitions. So has its diplomacy: Jordan is one of the only places in the Middle East where scientists from Israel and Arab countries can meet. \u201cWe are all in the region facing issues with energy, water and the environment,\u201d El Hassan says. \u201cA bird with avian flu does not know whether there is a peace accord between Israel and Jordan, it just flies across the border.\u201d The princess did not set out to be an architect of Jordan\u2019s science ambitions, however. In 1994, her father \u2014 the brother of King Hussein \u2014 asked the then-24-year-old art-school graduate to lead the board of trustees for an information technology college in Amman (now the Princess Sumaya University for Technology). El\u00a0Hassan initially declined the job, but relented on the condition that she would first earn a computer-science diploma from the school.\u00a0 Through that experience, El Hassan says, \u201cI\u00a0came to see science as a tool for human dignity. I began to see myself as a science enabler.\u201d In 2006, she became president of the Royal Scientific Society, an applied-science institution in Amman that also facilitates research collaborations across Jordan.\u00a0 The country has focused its science efforts on areas that could improve daily life for its citizens, such as energy development. \u201cThe country was dependent on oil in Iraq, and then natural gas from Egypt,\u201d says Khaled Toukan, chairman of the Jordan Atomic Energy Commission. \u201cThe problem with these sole sources is that we were subjected to political changes, like the US invasion of Iraq and the overthrow of the Egyptian government.\u201d Now, he says, Jordan is looking to exploit its uranium resources to include nuclear power, and it is exploring the potential of solar and wind energy. The Jordanian government is also looking for ways to cope with one of the lowest levels of water availability in the world \u2014 a problem that has intensified with the recent influx of an estimated 1.3 million Syrian refugees. Some help could come from a partnership that the Royal Scientific Society announced in February with the University of California, Berkeley, to build a reticular-chemistry foundry. Reticular chemistry involves making porous crystals. It was pioneered by Jordanian chemist Omar Yaghi, who heads the Berkeley Global Science Institute and has developed materials that can harvest water from the atmosphere.\u00a0 Still, Jordan faces a long climb to fulfil its scientific ambitions. The country spent just over 0.4% of its gross domestic product (GDP) on research and development in 2011, the latest year for which figures are available. That beats its wealthy neighbour Saudi Arabia (0.07% of GDP), but Jordan lags behind some nearby countries, such as Turkey. And although Jordan nearly doubled its yearly output of scientific publications between 2005 and 2014, from 641 to 1,093, the overall number remains small. To help build research capacity, the government set up the Jordanian Scientific Research Support Fund in 2005. The fund was initially supported by a law that required all companies in Jordan to pay 1% of their profits into the fund. By 2012, when that statute was overturned, the fund had acquired US$85 million. It is now kept afloat by Jordan\u2019s universities, which must spend 3% of their annual budgets on research or contributions to the fund. Between 2008 and 2016, the foundation gave a total of $35\u00a0million to 325 projects, mainly in the medical, pharmaceutical and agricultural sciences.\u00a0 Abeer Al Bawab, a chemist who in March became director of the fund, is thinking deeply about how to monitor its success. \u201cThe oldest university in the country is only 55 years old, and the support fund has just been around for ten years,\u201d she notes. Because Jordan is still building its culture of science, Al Bawab says that metrics such as the rate of scientific publications are not by themselves the best indicators of progress. She hopes to quantify the intersections between academic research, science policy and the private sector.\u00a0 In the meantime, El Hassan hopes that the World Science Forum will help to raise the profile of science in the eyes of the Jordanian public. \u201cA generation of analytical thinkers and risk takers,\u201d she says, \u201cis something I\u2019d like to see.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @amymaxmen \n               Travel for this story was supported by the Pulitzer Center on Crisis Reporting. \n                     First Middle Eastern X-ray factory readies for action 2016-Nov-22 \n                   \n                     Middle East X-ray factory is a source of hope 2016-Nov-22 \n                   \n                     Jordan\u2019s stem-cell law can guide the Middle East 2014-Jun-11 \n                   \n                     Clashing nations back SESAME 2012-Mar-21 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22411", "url": "https://www.nature.com/articles/nature.2017.22411", "year": 2017, "authors": [{"name": "Ben Upton"}], "parsed_as_year": "2006_or_before", "body": "Mice genetically engineered to show autism-like symptoms can affect behaviour of unmodified animals when the two are kept together. Mice that have been genetically modified to develop symptoms of autism spectrum disorder can influence how their unmodified littermates act \u2014 causing them to become less social, researchers have found. The phenomenon could undermine certain experiments that rely on mouse models of autism, and raises questions about the reliability of past results. St\u00e9phane Baudouin, a behavioural neuroscientist at Cardiff University, UK, was developing an experiment to study autism using mice engineered to lack a gene called neurolignin-3. In humans, mutations in this gene are linked to autism; in mice, they are linked to symptoms similar to those seen in people with the disorder, such as repetitive behaviours and social deficits. Baudouin noticed that when the knockout mice were kept with control animals that hadn\u2019t been modified, the controls showed no interest in the smell of the urine of other mice \u2014 usually a robust test of social behaviour. \u201cI was completely surprised by that,\u201d said Baudouin. \u201cI was concerned straight away.\u201d To confirm his suspicion, he and his colleagues observed control mice that had been kept apart from animals lacking neurolignin-3, and saw that the effect disappeared. Turning the neurolignin-3 gene back on in their knockout models also restored typical social behaviour in both the modified mice and the controls that lived with them. Those experiments confirmed that it was the act of keeping both types of mouse together that was causing the change in behaviour. The work is published in  eNeuro 1 . The effect could extend to other mouse models of autism, says Toru Takumi, a molecular neuroscientist who studies the disorder at the RIKEN Brain Science Institute in Tokyo. Takumi says that he might need to re-analyse all his behavioural experiments and take the effect into consideration for future animal-model studies. \n             Wider implications \n           It would not be the first time that researchers questioned the suitability of mice for studying behavioural conditions such as autism. The animals are often accused of being  poor predictors of human conditions , and their behaviours can be unsettled by even subtle changes to their diet and handling. Phenotypes, that is, physical or behavioural traits, may not be replicable in a different social environment, says behavioural neuroscientist Mu Yang of Columbia University Medical Center in New York City. And it\u2019s well known that experiments that succeed in one mouse population  might not even work in other mice . In light of these problems, some autism researchers have turned to more social animals,  such as rats . And last year, researchers in China reported that they had  engineered monkeys  with a mutation that causes a disorder similar to autism in humans \u2014 which the team says is the most realistic animal model of the condition yet. Still, issues with mice\u2019s social environment can be minimized by careful experimental design, says Hannelore Ehrenreich, a molecular neuroscientist at the Max Planck Institute for Experimental Medicine in G\u00f6ttingen, Germany. But she emphasizes that researchers must always be transparent about reporting their animals\u2019 social situation. Too many studies  omit crucial details needed to interpret how animals act , such as their housing conditions and genetic background, she says. \u201cThe behaviour is often not well described.\u201d Baudouin\u2019s team also found that modified mice seemed to become even less social and more anxious when kept with control mice; such symptoms were not exacerbated when they were housed with mice that also lacked neurolignin-3. Co-housing seems to \u201caffect wild-type and knockout animals and can lead to improvement or worsening of some features\u201d, says Ehrenreich. That effect is interesting, she says \u2014 it could recreate the social stress experienced by people with autism. \n                   A mouse\u2019s house may ruin experiments 2016-Feb-12 \n                 \n                   Monkeys genetically modified to show autism symptoms 2016-Jan-25 \n                 \n                   Missing mice: gaps in data plague animal research 2016-Jan-05 \n                 \n                   Misleading mouse studies waste medical resources 2014-Mar-26 \n                 \n                   Diuretic drug prevents autism in mice and rats 2014-Feb-06 \n                 \n                   Bacterium can reverse autism-like behaviour in mice 2013-Dec-05 \n                 \n                   Autism symptoms reversed in mice 2012-Nov-21 \n                 \n                   Rat models on the rise in autism research 2011-Nov-23 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22418", "url": "https://www.nature.com/articles/nature.2017.22418", "year": 2017, "authors": [{"name": "Dalmeet Singh Chawla"}], "parsed_as_year": "2006_or_before", "body": "Large study of open research analysed reader data from Unpaywall tool, which finds freely available versions of articles. Almost half of the scholarly papers that people attempt to access online are now freely and legally available, according to a huge study that tracked 100,000 online requests for journal papers in June. The work, published on 2 August in  \n                 PeerJ Preprints \n               1 , examined reader data from a web-browser extension called  Unpaywall , which trawls the Internet to find free-to-read versions of paywalled papers. The tool, which launched in April, was developed by two authors of the study, Jason Priem and Heather Piwowar, who co-founded the non-profit company Impactstory in Vancouver, Canada. It has been installed by more than 80,000 people worldwide and is used around 50,000 times a day, says Priem. When Unpaywall users land on a journal paper, the tool queries a database called oaDOI \u2014 also developed by the pair \u2014 that contains records of all 67 million journal articles with digital object identifiers (DOIs), an identifier code widely used for academic publications. The widget then signals to the user whether a free-to-read version of the article is available. The study authors analysed server logs of 100,000 papers that Unpaywall users tried to access during one week in June, and found that 47% of accessed studies were legally available to read for free somewhere on the web. Around half the content being accessed was published in the past two years, says Priem. The study, which hasn\u2019t yet been peer-reviewed, is \u201ccareful and extensive\u201d, says Ludo Waltman, deputy director of the Centre for Science and Technology Studies at Leiden University in the Netherlands who edits the  Journal of Informetrics . The study authors say theirs is the first broad analysis of the state of open research since a  2014 report  produced  for the European Commission . But the two analyses employed different methods: the earlier one used automated software to search online for papers drawn at random from the Scopus database. It also scoured social scholarly networks such as Academia.edu and ResearchGate \u2014 which the Unpaywall study does not examine \u2014 and estimated that, at the time, more than half of peer-reviewed research articles published from 2007\u201312 were free to read online. Given the methodological differences, that\u2019s roughly comparable to the finding in the new work, Piwowar says.\u00a0 The latest work also delves into how papers become free to read. More than 20% of scholarly articles searched for through Unpaywall were available directly from journals, with clear licences describing whether the papers were free not just to read, but also to download or redistribute. Another 9% of the studies were still published behind a paywall, but authors later uploaded their paper \u2014 or some version of it, such as a peer-reviewed manuscript \u2014 to an online repository (see \u2018The state of open research\u2019). The most intriguing category of papers were the 15% that were posted on a publisher\u2019s site as free to read, but without any explicit open licence. The authors say this type of open-access \u2014 which they call \u2018bronze\u2019, in contrast to the widely used \u2018gold\u2019 and \u2018green\u2019 definitions \u2014 has been scarcely discussed. \n             Citation complications \n           To measure the prevalence of free-to-read papers in the scholarly literature as a whole, the authors used oaDOI to identify the publication statuses of 100,000 articles chosen randomly from the 67 million journal articles available on the DOI registry Crossref. In this sample, 28% of articles were free-to-read, predicting a total of 19 million such articles in the literature. Of papers published in 2015 \u2014 the most recent year examined \u2014 45% were freely available, which suggests that newer articles are more likely to be open. The study also investigated the claim that open-access articles are more cited than paywalled studies. It analysed another random set of 100,000 papers from the 8 million indexed in the Web of Science database between 2009 and 2015, found that, for a given subject area and publication year, free-to-read articles are cited 18% more than the average. The trend is supported by several  previous   studies 2 , but some have  questioned  whether the effect exists. Waltman says that it\u2019s difficult to know for sure whether these studies are being cited more frequently specifically because they are open. To be certain, he says, one would need to check whether researchers citing the studies have access to paywalled content. Priem says that one limitation of the study is that its samples included only articles with DOIs, which aren\u2019t always used by publishers in the arts and humanities disciplines and in the developing world. Still, \u201cthe percentage of literature that is OA continues to grow quite steadily\u201d, he says. And that could have implications for academic libraries. As tensions  over the costs of institutional subscription packages  grow between universities and publishers, the finding that roughly half of recently published research may be available to read for free could \u201ctip the scales toward cancellation for some institutions\u201d, the study says. To Priem, the future looks open. \u201cIn the next few decades, we\u2019re going to be seeing nearly all the literature available freely.\u201d \n                   Unpaywall finds free versions of paywalled papers 2017-Apr-04 \n                 \n                   Open-access website gets tough 2014-Aug-06 \n                 \n                   Half of 2011 papers now free to read 2013-Aug-20 \n                 \n                   Science publishing: Open access must enable open use 2012-Dec-19 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22484", "url": "https://www.nature.com/articles/nature.2017.22484", "year": 2017, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Panel sought to help businesses and state and local governments prepare for the effects of global warming. US President Donald Trump's administration has disbanded a government advisory committee that was intended to help the country prepare for a changing climate. The US National Oceanic and Atmospheric Administration established the committee in 2015 to help businesses and state and local governments make use of the next national climate assessment. The legally mandated report, due in 2018, will lay out the latest climate-change science and describe how global warming is likely to affect the United States, now and in coming decades. The advisory group's charter expired on 20 August, and Trump administration officials informed members late last week that it would not be renewed. \u201cIt really makes me worried and deeply sad,\u201d says Richard Moss, a climate scientist at the University of Maryland in College Park and co-chair of the committee. \u201cIt\u2019s another thing that is just part of the political football game.\u201d The decision to wind down the advisory committee came as the Trump administration approached a major deadline related to the forthcoming climate assessment. On 18 August, 13 federal agencies were due to deliver their final comments on a federal report on the state of climate science \u2014 a technical prelude to the main climate assessment due out next year. Scientists in academia and at government agencies have raised concerns that climate sceptics in the Trump administration \u2014 particularly at the US Environmental Protection Agency (EPA) \u2014  might try to meddle with the document . But Michael Kuperberg, executive director of the US government's multi-agency Global Change Research Program, said in an e-mailed statement that the climate-science report, which is tentatively scheduled for release in November, \u201cis on track to meet this goal\u201d. \n             Going it alone \n           Richard Wright, a retired engineer who is serving on a climate panel organized by the American Society of Civil Engineers, laments the Trump administration\u2019s decision to disband the climate advisory committee. He says the panel has already become a valuable mechanism to bring together federal scientists and outside professionals who handle tasks such as managing water resources, setting standards for construction and establishing communications networks. \u201cWe found this committee a very effective way of communicating with the climate and weather community,\u201d Wright says. \u201cIt would be a pity not to have it.\u201d Moss says that the committee members hope to push forward with their work outside the federal advisory committee process. \u201cWe believe in the importance of completing this charge, and we will find a way to do it,\u201d he says. The decision to let the advisory committee's charter lapse is not the first time that the Trump administration has dismissed scientific advisers. In May and June,  the EPA came under fire for dismissing dozens of scientists  who were serving on the its Board of Scientific Counselors, which advises the EPA's research arm. And  Trump has not chosen a presidential science adviser  to lead the White House Office of Science and Technology Policy,  where a number of positions remain empty . \n                   US science envoy resigns in protest at Trump policies 2017-Aug-23 \n                 \n                   Fears rise for US climate report as Trump officials take reins 2017-Aug-01 \n                 \n                   Seek climate advice through established routes 2017-Aug-01 \n                 \n                   White House\u2019s dwindling science office leaves major research programmes in limbo 2017-Jul-11 \n                 \n                   Trump officials act to tilt federal science boards toward industry 2017-May-16 \n                 \n                   NOAA website: Advisory Committee for the Sustained National Climate Assessment \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22476", "url": "https://www.nature.com/articles/nature.2017.22476", "year": 2017, "authors": [{"name": "Rachael Lallensack"}], "parsed_as_year": "2006_or_before", "body": "Nightfall sparks blustery snowstorms in the Red Planet\u2019s lower atmosphere. When night falls on Mars, plunging temperatures can lead to snowstorms with whipping winds that could rattle a rover as it tries to land, according to a new study.  The analysis upends researchers\u2019 previous assumptions that Martian snow falls slowly and gently from the sky. Getting a handle on the planet\u2019s weather is important for future exploratory missions. But it could also help to explain how Mars lost a lot of its water, and what might happen to the water that remains. The study, published on 21 August in  Nature Geoscience 1 , moves researchers closer to an answer by providing the first detailed peek into what happens to the water in the Red Planet\u2019s clouds. Scientists combined powerful computer models that enabled them to run global climate measurements, calculate air turbulence and even make localized weather predictions for Mars. If a researcher uses only a global climate model, they can predict where clouds might be, but they won\u2019t have any idea about the dynamics within a cloud, says Aymeric Spiga, a planetary scientist at Pierre and Marie Curie University in Paris and lead study author. \u201cThat\u2019s the reason why these snowstorms were not discovered before,\u201d he says. \u201cIt\u2019s a bit like a Russian doll, with each successively higher-resolution model fitting inside the other,\u201d says Paul Hayne, a planetary scientist at NASA\u2019s Jet Propulsion Laboratory in Pasadena, California, who was not involved with the study. \u201cVery clever.\u201d \n             Falling fast \n           During the day, icy clouds about 10\u201320 kilometres above Mars\u2019s surface absorb sunlight and help to keep the atmosphere warm and stable. But Spiga and his colleagues found that when the sun sets, the temperature inside the clouds cools rapidly, dipping 4 degrees Kelvin per hour. Cold, descending air masses mix with hot air rising from Mars\u2019s surface. By about 2 a.m. local time, powerful columns of rushing wind reach speeds of 10 metres per second. The descending winds bring snow-like ice particles with them. These miniscule particles \u2014 only one-thousandth the size of a raindrop \u2014 take 5\u201310 minutes to freefall 1\u20132 kilometres, which is much faster than the 4 hours that scientists had previously estimated. This means that clouds must be within a kilometre or two of the planet\u2019s surface for snow to accumulate on the ground. The researchers\u2019 simulations not only demonstrated how Mars\u2019 atmosphere transports water closer to the surface, it also revealed some upward release of water vapour in the clouds near the planet\u2019s poles \u2014 where NASA\u2019s Phoenix Lander first spotted falling snow in 2008. The authors note that they can\u2019t conclude whether atmospheric mixing patterns favour sending water higher into Mars\u2019 atmosphere \u2014 where it could potentially be lost to space \u2014 or down towards the surface. \n             Sticking the landing \n           If this relatively low-level atmospheric mixing pushes water higher up into the atmosphere, that could explain how the Red Planet lost a lot of its water, says Mike Chaffin, a planetary scientist at the University of Colorado Boulder who studies Mars\u2019 upper atmosphere. \u201cMore and more, we\u2019re understanding that the Mars atmosphere is connected vertically in ways we didn\u2019t expect,\u201d Chaffin says. Understanding the dynamics of the planet\u2019s atmosphere will help to eliminate surprises for future missions to Mars. Alhough the wind speeds in these snowstorms would be considered moderate on Earth \u2014 they wouldn\u2019t be strong enough to ground a commercial flight \u2014 Mars\u2019s thinner atmosphere would amplify wind turbulence, Spiga says. \u201cAny time NASA sends a new lander or rover to Mars, the landing of these spacecraft is always very risky process,\u201d says Spiga. Every little bit of information on what a rover \u2014 or a crewed mission \u2014 would encounter in the planet\u2019s atmosphere will help to set the craft down on the surface in one piece. \n                   Ancient Mars probably too cold for liquid water 2014-Apr-13 \n                 \n                   Old Mars rover finds signs of ancient water 2014-Jan-23 \n                 \n                   Water seems to flow freely on Mars 2013-Dec-10 \n                 \n                   Mars exploration: Phoenix: a race against time 2008-Dec-10 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22453", "url": "https://www.nature.com/articles/nature.2017.22453", "year": 2017, "authors": [{"name": "Nicky Phillips"}], "parsed_as_year": "2006_or_before", "body": "Scientists say the move will reduce the country\u2019s capacity to predict future ecosystem changes. Every year since 1990, ecologist Glenda Wardle of the University of Sydney has ventured to the same expanse of desert in central Australia to take stock of its flora and fauna. But this year may be the last time Wardle can collect data from the 8,000-square-kilometre site in the Simpson Desert. The consortium that operates her research area and 11 other long-term sites, comprising more than 1,100 individual field plots, will stop funding this network by the end of the year because of budget cuts and shifting priorities, say its leaders. Without this money, which covers a large portion of the operating costs at these sites, 6 of the 12 will probably close, says ecologist David Lindenmayer, who is the science director of the network and is based at the Australian National University in Canberra. This would break time-series data that scientists have collected over decades, he says. \u201cIt\u2019s a foolish decision given the environmental effects that are occurring throughout the world, and especially in Australia,\u201d says Gene Likens, an ecologist at the Cary Institute of Ecosystem Studies in Millbrook, New York. Without the information collected at these long-term sites, he says, it will be impossible to know how to manage these landscapes effectively under climate change. Other researchers, however, concede that tight budgets mean that not all facilities can be funded. As Australia plans to cut its ecosystem-surveillance network, other countries are expanding theirs. The US National Science Foundation, for example, announced in March that it would expand its own network of 25 long-term ecological research (LTER) sites by adding 3 new ones. \u201cTerminating Australia\u2019s LTER network is totally out of step with international trends and national imperatives,\u201d wrote Lindenmayer and 68 authors in a letter published in  Science 1  on 11 August. They say urgent and direct investment by the Australian government is crucial. \n               Budget cuts \n             The cuts in Australia follow years of piecemeal support for ecological research infrastructure. Only five years ago, the government tasked a consortium known as the Terrestrial Ecosystem Research Network (TERN) with bringing together the country\u2019s existing LTER sites. The dozen sites in the resulting Long Term Ecological Research Network (LTERN) cover deserts, rainforest, savannahs and alpine regions and collect data to answer questions specific to each ecosystem. The oldest field locations have been running continuously for 73 years. In June, TERN director Beryl Morris and chair of the advisory board Lyn Beazley sent a letter to LTERN\u2019s executive director, Emma Burns, stating that the network would not be funded beyond 2017. \u201cI was completely blindsided,\u201d says Burns, an ecologist at the Australian National University. Burns says the reason given for cutting LTERN's funding, along with support for a complementary ecosystem-modelling facility known as eMAST, was so that TERN could meet the needs of the government\u2019s planned environmental prediction system while staying within its budget, which is Aus$6 million (US$4.7 million) for 2016\u201317, a decrease of more than 50% since 2010\u201311. The government did not respond to questions from Nature about the future of LTERN. Morris, who is based at the University of Queensland in Brisbane, where TERN is administered, says that TERN is funded as research infrastructure and must now develop an environmental prediction system open to all researchers. To do that, she says, it must collect data on a \u201ccontinental scale that is generalized, not bespoke, so you can predict from it\u201d. But Burns says the local and international scientific communities do not agree that TERN can deliver an environmental prediction system without LTERN. Time-series data and modelling are essential to a prediction system, says Wardle. Michael Mirtl, who chairs the International LTER Network and is based at the Helmholtz Centre for Environmental Research in Leipzig, Germany, says the network\u2019s closure will be a loss for groups in other countries that looked to Australia for guidance on how to integrate an LTER network and other surveillance systems with data processing and modelling systems. \u201cI think many people in Australia making decisions were simply not aware of how excellent the Australian achievement was in the field,\u201d says Mirtl. \n               Experimental design \n             Plans to withdraw funding from LTERN resurrect an ongoing debate in ecology about whether it is better to invest limited resources for environmental forecasting in broad-scale surveillance \u2014 generating lots of data by taking the same measurements in the same way at sites across the landscape \u2014 or in targeted ecological monitoring, which looks for drivers of change in specific ecosystems. Likens says that standardized surveillance and \u201cinstruments are useful\u201d, but he and others, such as Lindenmayer, believe that monitoring should be driven by researchers asking questions that answer problems. In the tropics of northern Queensland, for example, cyclones are the main driver of environmental change, whereas in parts of inland Australia, cattle grazing is the biggest factor. \u201cThat means you can\u2019t just measure the same things in different environments,\u201d says Lindenmayer. Ecologist Ben Sparrow of the University of Adelaide and environmental chemist Mike Liddell of James Cook University in Cairns, both of whom direct other TERN facilities, say TERN doesn\u2019t have the money to keep all its facilities running. Sparrow says that arguing over the merits of broad-scale surveillance and targeted monitoring is not constructive: both systems are necessary for understanding the environment, as is remote sensing using satellites. \u201cThe fundamental point is the lack of resourcing from the government,\u201d says Sparrow. \n                     Ecology\u2019s $434,000,000 test 2016-Jan-19 \n                   \n                     Reprieve for Australian research facilities 2015-Mar-17 \n                   \n                     Australian research facilities under threat 2015-Mar-10 \n                   \n                     Australia\u2019s Terrestrial Ecosystem Research Network \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22565", "url": "https://www.nature.com/articles/nature.2017.22565", "year": 2017, "authors": [{"name": "Bruno Martin"}], "parsed_as_year": "2006_or_before", "body": "Analysis of 215,000 people's DNA suggests variants that shorten life are being selected against. A huge genetic study that sought to pinpoint how the human genome is evolving suggests that natural selection is getting rid of harmful genetic mutations that shorten people\u2019s lives. The work, published in  PLoS Biology 1 , analysed DNA from 215,000 people and is one of the first attempts to probe directly how humans are evolving over one or two generations. To identify which bits of the human genome might be evolving, researchers scoured large US and UK genetic databases for mutations whose prevalence changed across different age groups. For each person, the parents\u2019 age of death was recorded as a measure of longevity, or their own age in some cases. \u201cIf a genetic variant influences survival, its frequency should change with the age of the surviving individuals,\u201d says Hakhamanesh Mostafavi, an evolutionary biologist at Columbia University in New York City who led the study. People who carry a harmful genetic variant die at a higher rate, so the variant becomes rarer in the older portion of the population. Mostafavi and his colleagues tested more than 8 million common mutations, and found two that seemed to become less prevalent with age. A variant of the  APOE  gene, which is strongly linked to Alzheimer\u2019s disease, was rarely found in women over 70. And a mutation in the  CHRNA3  gene associated with heavy smoking in men petered out in the population starting in middle age. People without these mutations have a survival edge and are more likely to live longer, the researchers suggest. This is not, by itself, evidence of evolution at work. In evolutionary terms, having a long life isn\u2019t as important as having a reproductively fruitful one, with many children who survive into adulthood and birth their own offspring. So harmful mutations that exert their effects after reproductive age could be expected to be \u2018neutral\u2019 in the eyes of evolution, and not selected against. But if that were the case, there would be plenty of such mutations still kicking around in the genome, the authors argue. That such a large study found only two strongly suggests that evolution is \u201cweeding\u201d them out, says Mostafavi, and that others have probably already been purged from the population by natural selection. \n             Links to longevity \n           Why these late-acting mutations might lower a person\u2019s genetic fitness \u2014 their ability to reproduce and spread their genes \u2014 remains an open question. The authors suggest that for men, it could be that those who live longer can have more children, but this is unlikely to be the whole story. So scientists are considering two other explanations for why longevity is important. First, parents surviving into old age in good health can care for their children and grandchildren, increasing the later generations\u2019 chances of surviving and reproducing. This is sometimes known as the \u2018grandmother hypothesis\u2019, and may explain why humans tend to live long after menopause. Second, it\u2019s possible that genetic variants that are explicitly bad in old age are also harmful \u2014 but more subtly \u2014 earlier in life. \u201cYou would need extremely large samples to see these small effects,\u201d says Iain Mathieson, a population geneticist at the University of Pennsylvania in Philadelphia, so that\u2019s why it\u2019s not yet possible to tell whether this is the case. The researchers also found that certain groups of genetic mutations, which individually would not have a measurable effect but together accounted for health threats, appeared less often in people who were expected to have long lifespans than in those who weren't. These included predispositions to asthma, high body mass index and high cholesterol. Most surprising, however, was the finding that sets of mutations that delay puberty and childbearing are more prevalent in long-lived people. To see a genetic link to delayed childbearing is intriguing, says Jonathan Pritchard, a geneticist at Stanford University in California. The link between longevity and late fertility has been spotted before, but those studies could not discount the effects of wealth and education, because people with high levels of both tend to have children later in life. The latest genetic evidence makes Pritchard think there is an evolutionary trade-off between fertility and longevity, which had previously been studied only in other animals. \u201cTo actually find this in humans is really pretty cool,\u201d he says. \u201cI think it's a really nice study.\u201d Studying ongoing evolution in humans is notoriously difficult. Scientists who want to observe selection directly would need to measure the frequency of a mutation in one generation, and then again in all that generation\u2019s children and, better still, grandchildren, says Gil McVean, a statistical geneticist at the University of Oxford, UK. \u201cThat would be very hard to do well,\u201d he says. \u201cYou would need vast samples\u201d. \n                   Scientists track last 2,000 years of British evolution 2016-May-17 \n                 \n                   Gene variants linked to success at school prove divisive 2016-May-11 \n                 \n                   Genetic secrets of the healthy elderly unveiled 2016-Apr-21 \n                 \n                   Studies slow the human DNA clock 2012-Sep-18 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22066", "url": "https://www.nature.com/articles/nature.2017.22066", "year": 2017, "authors": [{"name": "Shannon Hall"}], "parsed_as_year": "2006_or_before", "body": "Brightness of exploding stars may vary more than researchers realized. The exploding stars known as type Ia supernovae are so consistently bright that astronomers refer to them as standard candles \u2014 beacons that are used to measure vast cosmological distances. But these cosmic mileposts may not be so uniform. A new study finds evidence that the supernovae can arise by two different processes, adding to lingering suspicions that standard candles aren't so standard after all. The findings, which have been posted on the arXiv preprint server 1  and accepted for publication in the  Astrophysical Journal , could help astronomers to calibrate measurements of the Universe\u2019s expansion. Tracking type Ia supernovae showed that the Universe is expanding at an ever-increasing rate, and helped to prove the existence of dark energy \u2014 advances  that secured the 2011 Nobel Prize in Physics . The fact that  scientists don\u2019t fully understand these cosmological tools  is embarrassing, says the latest study\u2019s lead author, Griffin Hosseinzadeh, an astronomer at the University of California, Santa Barbara. \u201cOne of the greatest discoveries of the century is based on these things and we don\u2019t even know what they are, really.\u201d It's not for lack of trying: astronomers have put forth a range of hypotheses to explain how these stellar explosions arise. Scientists once thought that the supernovae were built uniformly, like fireworks in a cosmic assembly line. That changed in the 1990s, when astronomers noticed that some of the supernovae were dimmer than the others. Astronomers can correct for the difference because the brightest supernovae seem to fade more slowly than their dimmer kin. Still, the fact that each \u2018standard candle\u2019 looks slightly different from the next is cause for concern. \u201cWhen you\u2019re trying to measure the expansion rate of the Universe to 1%, these subtle differences make you worry that maybe\u00a0type Ia supernovae are throwing you off,\u201d says Peter Garnavich, an astronomer at the University of Notre Dame in Indiana. \n               Burning bright \n             At least one thing seems clear, however. Astronomers remain convinced that a white dwarf, an Earth-sized remnant of a Sun-like star,  plays a central part in the formation of each type Ia supernova . But they\u2019re not sure what pushes white dwarves over the edge, because these stars are too stable to explode on their own. That suggests that a companion star \u2014 another white dwarf, a star like the Sun or even a giant star \u2014 helps to set each supernova in motion. If this companion star is large, the idea goes, then the white dwarf would siphon material from it. Eventually, it would accumulate so much extra mass that the pressure would ignite a runaway thermonuclear explosion. But if the companion star is small \u2014 perhaps a second white dwarf \u2014 the two celestial bodies would spiral towards each other and merge together before exploding. Researchers have been searching for evidence of these processes by hunting for newly formed supernovae. That\u2019s because a supernova created in the first scenario would leave evidence behind: material travelling out from the stellar explosion would light up as it hit the slightly smaller, but still intact, companion star. But a supernova formed by the merger of a white dwarf and a small companion would obliterate all traces of the stars involved in its birth. Astronomers had only seen evidence for the second scenario \u2014 until now. Griffin and his team\u2019s paper is the first to report a supernova formed by a white dwarf leaching material from a massive companion star. The results add weight to the idea that type Ia supernovae can form through two different stellar assembly lines. \n               On the hunt \n             The first hint of the discovery came on 10 March, when a supernova appeared on the outskirts of the spiral galaxy NGC 5643, 16.9 million parsecs from Earth (55 million light years). David Sand, an astronomer at the University of Arizona in Tucson and a co-author of the study, found it as he pored over data from the DLT40 supernova search, which scans roughly 500 galaxies every night. Sand quickly took another image to verify that what he had seen was a stellar explosion, not an unknown asteroid. Within a few minutes, he knew it was time to alert the Las Cumbres Observatory \u2014 a network of 18 telescopes around the world that allows astronomers to monitor objects continuously as they move across the sky. Hosseinzadeh, Sand and their colleagues observed the supernova every 5 hours for roughly 6\u00a0days and then once a night for 40 days after \u2014 allowing them to map its changing luminosity. During this period, they saw a temporary jump in brightness caused by material ejected from the supernova striking the companion star. \u201cThis is the best evidence yet for a shock due to a companion star in a normal type Ia supernova,\u201d Garnavich says. But the discovery is just the beginning of unravelling the mystery behind these not-so-standard candles. To better pin down their measurements of the cosmos, astronomers will keep searching for more of these dim young supernovae. \u201cIt\u2019s like having a tool that you know how to use, but you don\u2019t know how it works,\u201d Hosseinzadeh says. \u201cUnderstanding the physics of the tool that you're using seems better than just using it blindly.\u201d \n                     Supernova erupts in nearby galaxy 2014-Jan-22 \n                   \n                     Kepler clue to supernova puzzle 2014-Jan-14 \n                   \n                     Early observations identify star at heart of nearby supernova 2011-Dec-14 \n                   \n                     Brightest supernovae are in a class of their own 2011-Jun-08 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22549", "url": "https://www.nature.com/articles/nature.2017.22549", "year": 2017, "authors": [{"name": "Bruno  Martin"}], "parsed_as_year": "2006_or_before", "body": "Researchers surprised to observe bacterial protein triggering a switch from asexual to sexual behaviour. Researchers have stumbled on a surprising aphrodisiac for a single-celled organism: a protein secreted by a bacterium. They suggest it\u2019s the first time that bacteria have been found to have a hand in controlling the sexual behaviour of eukaryotes \u2014 the domain of life that includes fungi, plants and animals. The organism involved belongs to the choanoflagellates: sperm-like creatures that are among the closest living single-celled relatives of animals. Biologists study them to understand how unicellular organisms evolved to become the earliest multicellular animals. Choanoflagellates usually divide asexually. Until now, scientists had only managed to coax them into mating by withholding their food. A team led by microbiologist\u00a0Nicole King of the University of California, Berkeley, was studying how certain bacterial signals induce asexual division in the choanoflagellate  Salpingoeca rosetta  when they discovered something surprising: adding a marine bacterium called  Vibrio fischeri  to the culture caused  S. rosetta  to swarm into a mating frenzy and reproduce sexually. \u201cIt was completely unexpected,\u201d says Jon Clardy, a biochemist and study co-author at Harvard Medical School in Boston, Massachusetts. \u201cTo be honest, we were using  V. fischeri  as a control, because we knew that it wouldn\u2019t induce multicellularity.\u201d The work was published on 31 August in  Cell 1 . \n             Protein perk up \n           Further experiments revealed that the bacteria secreted a protein \u2014 which the researchers dubbed EroS, after the Greek god of sex \u2014 that caused the swarming behaviour. The choanoflagellates clustered in groups of up to 35 and fused head-on before duplicating and recombining their DNA and then dividing into genetically distinct offspring. \u201cIt\u2019s the first time that I see bacteria inducing mating in a eukaryotic cell,\u201d says Vanessa Sperandio, a microbiologist at the University of Texas Southwestern Medical Center in Dallas. Sperandio points out that bacteria could be influencing the behaviour of multicellular animals more than we know. When a new signalling pathway is discovered, she says, chances are that similar discoveries will follow in other groups of organisms. \u201cIt\u2019s odd to rely on bacteria to induce your mating,\u201d agrees Nick Brown, a cell biologist at the University of Cambridge, UK. He says that in further work, he\u2019d like to know whether and, if so, how choanoflagellates are able to trigger their own sexual behaviour. The researchers now think that the mechanism they observed might be how  S. rosetta  usually reproduces in the wild. It lives in the same coastal habitats as  V. fisheri , and natural concentrations of the bacterial aphrodisiac could cause the choanoflagellates to gather in large numbers, making it more likely that two cells will come together for sexual reproduction. Study author Arielle Woznica of the University of California, Berkeley, suggests that choanoflagellates may have adapted to use  V. fisheri  as an indicator that environmental conditions call for sexual reproduction. \n             Mating mechanics \n           Why bacteria would control sex in choanoflagellates is not yet clear. But the researchers have a few theories as to how the protein induces mating. EroS is an enzyme that cuts up a compound found in  S. rosetta \u2019s extracellular matrix, a collection of structural molecules surrounding the cell. The compound that it targets, called chondroitin sulfate, is made from sugar molecules \u2014 so it\u2019s likely that  V. fisheri  secrete EroS to feed on this molecule, the authors say. Clardy suggests that chewing up the extracellular matrix may physically \u2018soften up\u2019 the cells, so that two choanoflagellates can fuse. King is investigating a different lead: she thinks that chondroitin sulfate may be a signalling molecule that becomes active only when cleaved by EroS. The finding is one of a growing number of examples of \u2018cross-kingdom signalling\u2019 \u2014 a process in which one group of organisms picks up cues from another. It has implications for the richness of chemical ecology that remains to be discovered, says Rosie Alegado, a microbiologist from the University of Hawaii at Manoa. Other microbes thought to be asexual might be convinced to give sex a try \u2014 if they're exposed to the right conditions. \n                   Fungi borrowed bacterial gene again and again 2014-Jul-02 \n                 \n                   Microbiology: Tinker, bacteria, eukaryote, spy 2009-May-13 \n                 \n                   Humans and sponges may share a slimy ancestor 2009-Jan-26 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22838", "url": "https://www.nature.com/articles/nature.2017.22838", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Source may be dust shed by planet\u2019s iconic rings, according to data from NASA's doomed Cassini probe. Provo, Utah NASA's Cassini spacecraft continues to yield surprising discoveries, more than a month after  it burned up on its mission-ending dive into Saturn . New data from the probe suggest that Saturn's majestic rings are showering tiny dust particles into the planet's upper atmosphere, where they form a complicated and unexpected chemical mix. A mass spectrometer aboard Cassini detected the strange chemistry as the probe spent its final five months  looping between Saturn and its rings . \u201cWe really hit the jackpot,\u201d said Mark Perry, a planetary scientist at the Johns Hopkins University Applied Physics Laboratory in Laurel, Maryland. He reported the findings on 17 October at a meeting of the American Astronomical Society\u2019s Division for Planetary Sciences in Provo, Utah. Mission scientists had expected Cassini's mass spectrometer to spot the signature of water molecules as the spacecraft slipped between the planet and its rings. In the 1970s and 1980s, NASA's Pioneer and Voyager missions found fewer charged particles than expected in Saturn\u2019s uppermost atmosphere. On the basis of those data, researchers proposed in 1984 that water molecules coming off the rings \u2014 mostly in the form of ice \u2014 act as catalysts to strip charged particles from the atmosphere 1 . Cassini's final months gave scientists their first opportunity to test this idea directly. \n             Chemical surprise \n           But it wasn't evidence of water that jumped out at Cassini's science team. Data from the mass spectrometer revealed a witch\u2019s brew of chemicals, including methane, a molecule that could be carbon monoxide and more-complex molecules. The concentrations of these chemicals are greatest around Saturn\u2019s equator and at high altitudes, which suggests that the material is shedding off the planet\u2019s rings. The deeper the probe went into the atmosphere, the stranger the measurements became. Cassini\u2019s closest swings past Saturn's surface revealed a panopoly of heavy molecules, Perry told conference attendees. The scientists have not yet pinpointed each type of molecule, but clearly, there is much more than just water around. By analysing the types of material that could be coming off the rings, Perry\u2019s team concluded that the debris must be fragments of tiny dust particles, which measure just 1 to 10 nanometres across but are relatively heavy. When these particles spiralled off the rings and slammed into Cassini\u2019s mass spectrometer, they shattered into smaller pieces. Exactly how those particles make the journey from the rings to the atmosphere remains to be seen. \u201cWe have a lot of work to do to understand how they are getting in there,\u201d Perry said. \u201cNone of the models predict this.\u201d On these final plunges, pulled along by Saturn\u2019s gravity, Cassini was zooming along at more than 30 kilometres per second \u2014 a speed more than four times greater than the mass spectrometer was designed to withstand. \u201cThese are higher speeds than anything it has ever seen,\u201d noted Linda Spilker, a planetary scientist at the Jet Propulsion Laboratory in Pasadena, California, and Cassini\u2019s project scientist. At such enormous speeds, anything that Cassini rammed into would have splintered into bits. \n                   Cassini crashes into Saturn \u2014 but could still deliver big discoveries 2017-Sep-15 \n                 \n                   Cassini\u2019s 13 years of stunning Saturn science \u2014 in pictures 2017-Aug-30 \n                 \n                   Saturn spacecraft begins science swan-song 2017-Apr-12 \n                 \n                   Cassini mission \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22551", "url": "https://www.nature.com/articles/nature.2017.22551", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "James Bridenstine, a member of Congress, has long pushed for the United States to return to the Moon. James Bridenstine, a Republican member of the US Congress from Oklahoma, has been tapped to be the next head of NASA. Bridenstine is a strong supporter of lunar exploration and commercial space flight. If confirmed by the Senate, he will take the reins of an agency that is building a new heavy-lift rocket to fly astronauts to an as-yet-undecided destination. Bridenstine has repeatedly argued that the United States should return to the Moon \u2014 to, among other things, mine water ice to fuel a fleet of satellites with lunar hydrogen and oxygen. \u201cFrom the discovery of water ice on the Moon until this day, the American objective should have been a permanent outpost of rovers and machines at the poles with occasional manned missions for science and maintenance,\u201d Bridenstine told a lunar-exploration group last November. \u201cThis is our Sputnik moment.\u201d Bridenstine has also pushed to accelerate the government\u2019s use of commercial space services. \u201cThe US government understands that in the future, and even today, it will be a customer of routine space services, not a provider of routine space services,\u201d he said in the November speech. NASA currently pays for private companies to fly agency cargo to the International Space Station; US astronauts will fly aboard commercial rockets no earlier than next year. \u201cRepresentative Bridenstine is certainly a \u201cdifferent\u201d choice for NASA administrator, but to me the difference is mainly positive,\u201d says John Logsdon, who specializes in space policy at George Washington University in Washington DC. \u201cHe has been refining his ideas with diverse audiences over the past months, and would bring to the NASA position a clearer and better-defined strategy for moving ahead than did most of his predecessors as they began their tenure.\u201d \n             Space credentials \n           After studying economics, business and psychology at Rice University in Houston, Texas, Bridenstine served as a pilot in the US Navy. He flew combat missions in Iraq and Afghanistan, and in anti-drug operations in Central and South America. He also worked as executive director for an aerospace museum in Tulsa, Oklahoma. Since he was first elected to Congress in 2012, Bridenstine has slowly built up his space-policy credentials, serving on the House of Representatives\u2019 science, space and technology committee and speaking in front of groups such as the US Federal Aviation Administration\u2019s space-transportation conference. In 2016, Bridenstine introduced legislation in the House that would require NASA to make Mars its \u201cmain human spaceflight priority\u201d \u2014 presumably after first establishing a Moon base \u2014 and bolster the already-growing role of commercial space flight. The legislation stalled at the subcommittee level. Bridenstine has expressed scepticism about climate change. In a June 2013 speech on the House floor, he disparaged the role of humans in global warming and criticized then-President Barack Obama for spending more money on climate research than on weather forecasting. Bridenstine has argued to exclude greenhouse gases from federal regulation, and to expand oil and gas exploration on federal lands and offshore. Major challenges facing the next NASA administrator include keeping the development of the Space Launch System heavy-lift rocket and its accompanying Orion crew capsule on track. The first flight of the paired system is meant to be in November 2018 but will probably be delayed, an April report from the US Government Accountability Office found. \u201cWe hope the new administrator embraces NASA\u2019s strong commitment to science and public engagement,\u201d says Heidi Hammel, executive vice-president of the Association of Universities for Research in Astronomy (AURA) in Washington DC. \u201cAURA looks forward to working with the new NASA administrator to ensure that the agency maintains a robust science portfolio.\u201d Bridenstine would replace Charles Bolden, a former astronaut who flew four times aboard the space shuttle. In June, the administration of President Donald Trump  re-established the National Space Council , an on-again, off-again entity meant to coordinate space activities between various government departments, including civilian and military agencies. Vice-President Mike Pence is chair of the council. \n                   United States revives space-policy council after 24-year absence 2017-Jun-07 \n                 \n                   NASA science chief: \u2018I have no worries about the resilience of this country\u2019 2016-Dec-15 \n                 \n                   Obama\u2019s science legacy: a space race stalls 2016-Aug-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22542", "url": "https://www.nature.com/articles/nature.2017.22542", "year": 2017, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "Advance planning has kept some Texas facilities safe during the unprecedented storm. Hurricane Harvey swept ashore on 25 August and dumped record-breaking amounts of rain on Houston, Texas, over the next several days. As the storm begins to dissipate, scientists in its wake are starting to take stock of the personal and professional toll. Many institutions in Houston were relatively well prepared for Harvey, having put precautions in place after suffering major losses when Tropical Storm Allison flooded the city in 2001. Facilities in other parts of the state have not been so lucky, but researchers hit by Harvey \u2014 now downgraded to a tropical depression \u2014 are not being left to fend for themselves. As of 31 August, roughly 200 scientific laboratories across the country have offered computer time, lab space, animal care and spare rooms to researchers displaced by the storm, using the hashtag  #SciHelpTX  on Twitter. When Harvey made landfall as a category 4 hurricane, it hit facilities at the University of Texas at Austin Marine Science Institute in Port Aransas particularly hard, ripping the roof off Brett Baker\u2019s microbial-ecology lab. Baker says that one of his graduate students has already arranged to transfer to a lab at the University of California, Berkeley, and a postdoc is heading to Uppsala University in Sweden. \u201cOur institute is on a barrier island,\u201d Baker says, and it took a direct hit from the storm. Baker spent some time crying, he adds, but is now so busy with logistics that he hasn't fully processed his feelings. \n               Lessons learnt \n             Most of the biomedical-research facilities in Houston, including those at Rice University, MD Anderson Cancer Center and the University of Texas Health Science Center, had installed special doors and floodgates to hold back storm waters after Allison. Those precautions saved equipment and animals, says Anirban Maitra, a pathologist at MD Anderson. \u201cI think they prevented a mega-catastrophe,\u201d he adds. Baylor College of Medicine lost 60,000 breast-cancer specimens in the 2001 storm. But the  lessons that it learnt have paid off , says spokesperson Lori Williams. \u201cWe built a wall around the entire campus,\u201d she says. \u201cWe\u2019ve had no animals lost, no research lost.\u201d The University of Houston (UH), by contrast, does not have special flood infrastructure. So the institution has been dealing with flooded basement labs, and has struggled to keep animals dry and fed. Forty baby rhesus monkeys had their formula milk rationed, says Amr\u00a0Elnashai, vice-president for research and technology transfer at UH. A few had to be weaned a week early. Supplies of liquid nitrogen and helium are also running low, endangering frozen samples if they cannot be restocked soon. \u201cIf the worst is over, then we are fine,\u201d says Elnashai. \u201cIf there is another hit, then we are in deep trouble.\u201d \n               Personal costs \n             Meanwhile, staff at the Johnson Space Center in Houston are camping out at mission control to keep the International Space Station and the James Webb Space Telescope (JWST) programmes going. \u201cI came in for a shift Friday night and I\u2019ve been here ever since,\u201d says flight director Courtenay McMillan. Staff have been sleeping on makeshift beds and air mattresses, and subsisting on provisions provided by co-workers and friends. \u201cWe have not run out of coffee, which is the most important thing,\u201d McMillan adds. The JWST was in the middle of a 100-day test in a thermal vacuum chamber when Harvey struck, but is unharmed. And a Soyuz capsule landing scheduled for this weekend in Kazakhstan \u2014 which the space centre will help to coordinate \u2014 will go ahead with only minor modifications to the plan, says McMillan. Although many institutions have fared relatively well despite the storm\u2019s ferocity, researchers and staff are still dealing with personal losses. Officials estimate that at least 38 people have died as a result of the storm. Maitra says that one administrator on his team has been evacuated to a hotel. \u201cShe had to leave in a hurry with her kids in the middle of the night. They were stuck on the third floor of her complex for three days. It is just heartbreaking.\u201d Louise Prockter, director of the Lunar Planetary Institute in Houston, was travelling when Harvey swept into town. She has been trying to support her staff remotely from Washington DC. \u201cSome of our staff have lost all their property,\u201d she says. \u201cIt is a mess. For some people, normal is a long, long way off.\u201d \n                     US biomedical-research facilities unprepared for attacks and natural disasters 2017-Aug-10 \n                   \n                     Emergency planning: Be prepared 2014-Oct-22 \n                   \n                     Hurricane Sandy: After the deluge 2013-Apr-24 \n                   \n                     Researchers battle storm\u2019s wrath 2012-Nov-06 \n                   \n                     Texan labs batten hatches against Hurricane Rita 2005-Sep-23 \n                   Related external links Reprints and Permissions"},
{"file_id": "nature.2017.22819", "url": "https://www.nature.com/articles/nature.2017.22819", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Therapy that targets disease-causing mutations could become the first of its kind approved for use in the United States. Advisers to the US Food and Drug Administration (FDA) have paved the way for the agency\u2019s first approval of a gene therapy to treat a disease caused by a genetic mutation. On 12 October, a panel of external experts unanimously voted that the benefits of the therapy, which treats a form of hereditary blindness, outweigh its risks. The FDA is not required to follow the guidance of its advisers, but it often does. A final decision on the treatment, called voretigene neparvovec (Luxturna), is expected by 12 January. An approval in the lucrative US drug market would be a validation that gene-therapy researchers have awaited for decades. \u201cIt\u2019s the first of its kind,\u201d says geneticist Mark Kay of Stanford University in California, of the treatment. \u201cThings are beginning to look more promising for gene therapy.\u201d \n               Gene replacement \n             Luxturna is made by Spark Therapeutics of Philadelphia, Pennsylvania, and is designed to treat individuals who have two mutated copies of a gene called  RPE65.  The mutations impair the eye\u2019s ability to respond to light, and ultimately lead to the destruction of photoreceptors in the retina. The treatment consists of a virus loaded with a normal copy of the  RPE65  gene. The virus is injected into the eye, where the gene is expressed and supplies a normal copy of the RPE65 protein. In a randomized controlled trial that enrolled 31 people, Spark showed that, on average, patients who received the treatment improved their ability to navigate a special obstacle course 1 . This improvement was sustained for the full year during which the company gathered data. The control group, however, showed no improvement overall. This was enough to convince the FDA advisory committee that the benefits of the therapy outweigh the risks.  \n               Long road \n             That endorsement is an important vote of confidence for a field that has struggled over the past 20 years. In the early 1990s, gene therapy was red hot, says David Williams, chief scientific officer at Boston Children\u2019s Hospital in Massachusetts. \u201cYou couldn\u2019t keep young people out of the field,\u201d he says. \u201cEveryone wanted in.\u201d Then came the  death of a young patient  enrolled in a gene-therapy clinical trial, and the realization that a gene therapy used to treat children with an immune disorder  could cause leukaemia . Investors backed away from gene therapy, and some academics grew scornful of it. Although European regulators approved one such therapy in 2012, for a condition that causes severe pancreatitis, many doubted that it worked. (The company that makes it has announced that it will not renew its licence to market the drug when it expires on 25 October.) \u201cYou\u2019re too smart to work in this field,\u201d a colleague told Kay. \u201cIt\u2019s a pseudoscience.\u201d But some researchers kept plugging away at the problem, improving the vectors that shuttle genes into human cells. Over time,  new clinical trials began to show promise , and pharmaceutical companies became  more interested in developing treatments for rare genetic diseases . Gradually, investors returned. Now, demand for gene-therapy vectors is so high that suppliers are oversubscribed, and researchers have to wait between 18 months and 2 years to get some of the reagents that they need for clinical studies, says Williams. \n               Measured expectations \n             In the past few years, gene therapies have shown promise in clinical trials for a range of diseases \u2014 including haemophilia, sickle cell disease and an immune disorder called Wiskott\u2013Aldrich syndrome. On 4 October, Williams and his colleagues published results of a gene-therapy trial to treat cerebral adrenoleukodystrophy (ALD), a devastating and sometimes fatal disorder that affects the nervous system and adrenal glands 2 . Disease progression was halted for the roughly 2-year duration of the study in 15 of 17 boys who were treated. The FDA approved its first gene therapy, a treatment in which  immune cells are engineered to combat cancer , on 30 August. Unlike Spark\u2019s therapy, the cancer treatment does not target a specific disease-causing mutation, and is administered to immune cells that are removed from the body, engineered and then reinfused. That is why researchers say that an FDA approval for voretigene neparvovec would be a landmark. \u201cThe general concept of gene therapy is replacing or compensating for a missing gene, and that\u2019s what this does,\u201d says Matthew Porteus, a paediatric haematologist also at Stanford. \u201cPeople are so excited.\u201d But Spark\u2019s treatment also highlights the limitations of this generation of gene therapies. Although the treatment seems to improve vision, it is still unclear how long the virus will continue to express the normal  RPE65  gene \u2014 and thus how long its effects will last. \u201cIt isn\u2019t a cure,\u201d says Kay. Similarly, the cerebral ALD therapy seemed to slow the effects of the disease in the brain, but is not expected to treat symptoms in other parts of the body, which can emerge later in life. \u201cI think we still need to have major improvements in the technology before we\u2019re going to be able to cure these diseases,\u201d says Kay. \u201cBut along the way there may be treatments that help make improvements.\u201d \n                     Engineered cell therapy for cancer gets thumbs up from FDA advisers 2017-Jul-12 \n                   \n                     Promising gene therapies pose million-dollar conundrum 2016-Jun-15 \n                   \n                     Leukaemia success heralds wave of gene-editing therapies 2015-Nov-05 \n                   \n                     Success against blindness encourages gene therapy researchers 2015-Oct-21 \n                   \n                     FDA Cellular, Tissue, and Gene Therapies Advisory Committee meeting materials \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22888", "url": "https://www.nature.com/articles/nature.2017.22888", "year": 2017, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Policies are expected to speed up access to medicines and boost the country\u2019s pharmaceutical industry. China is overhauling its drug-approval system to let companies bring their treatments to market quicker and more easily. On 9 October, the Communist Party of China and the State Council, two of the country\u2019s most authoritative bodies, announced plans to reduce the backlog of medicines awaiting approval by the China Food and Drug Administration (CFDA). Policies will also be introduced to boost the productivity of Chinese drugmakers and spur innovation in health care. Details of the plans are only just starting to emerge, but industry observers expect them to be in place by the end of 2017. One proposal, released for public comment on 20 October, states that companies will be allowed to use data from clinical trials conducted in other countries when applying for drug approval in China. Currently, companies have to perform extra trials in China to test a drug\u2019s efficacy. Under the new guidelines, they will instead need to provide data that show that a drug works in all human populations. The changes will significantly reduce the time Chinese people have to wait for new medicines, and will save multinational companies time and money, says Angela Yan, senior director of science and regulatory affairs at the R&D-based Pharmaceutical Association Committee in Beijing, which represents the interests of foreign companies in China. A vaccine against the human papillomavirus, for example, was approved in China only in 2016, a decade after it was given the green light in the United States. More than 20 years of efforts to reduce delays are now paying off, says Yan. \u201cThis is very positive.\u201d \n             Unblocking the pipeline \n           The shake-up is the latest in a series of measures to accelerate China\u2019s drug-regulation process and make it more rigorous, in line with international standards. In the past two years, the government has dramatically increased the number of application inspectors at the CFDA to reduce the backlog of medicines awaiting approval. It has also  threatened to jail  manufacturers or researchers caught submitting fraudulent applications. And in June, China became a member of the International Council for Harmonisation of Technical Requirements for Pharmaceuticals for Human Use, which requires a nation\u2019s drug-approval agency to adhere to international standards and guidelines. As well as reducing the administrative burden of drug registration, the government is eager to expand its pharmaceutical industry, given that China is the world\u2019s second largest drug market. Between 2001 and 2016, China approved just over 100 new drugs, whereas developed countries approved 433. \n             Far-reaching policies \n           Su Ling, director of the Institute of Drug Regulatory Science at Shenyang Pharmaceutical University and a venture partner for the investment fund Lilly Asia Ventures in Shanghai, says the government will introduce a range of policies that will have broad effects on the industry. \u201cOverall they are in the right direction to become more aligned with international norms and to promote new drug R&D and access,\u201d says Su. \u201cThis is really important.\u201d Another policy, announced by the CFDA on 10 October, will end the restriction that prohibits pharmaceutical companies from starting phase I safety trials for a drug in China until its safety has been proved in another country. The ban was designed to protect Chinese people from exploitation by drug companies during early experiments. Yan says loosening the restriction could plug crucial holes in China\u2019s drug-development pipeline, which has lost capacity to translate research from animals to humans. \u201cNow they can do global phase I trials and learn and improve their capabilities,\u201d she says. \n                   China cracks down on fake data in drug trials 2017-May-11 \n                 \n                   China embraces precision medicine on a massive scale 2016-Jan-06 \n                 \n                   China drugs head fired over article row 2013-Jun-18 \n                 \n                   Executed Chinese drug czar corrupted by system, observers say 2007-Aug-31 \n                 \n                   China's deadly drug problem 2007-Apr-04 \n                 Reprints and Permissions"},
{"file_id": "nature.2017.22892", "url": "https://www.nature.com/articles/nature.2017.22892", "year": 2017, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Gene-editing pioneers prepare for next stage of intellectual-property disputes in the United States and Europe. The long-running battle over US patents for CRISPR\u2013Cas9 gene editing continues. On 25\u00a0October, the Broad Institute of Cambridge, Massachusetts, filed a fresh set of arguments with the US government to defend a key patent. That action helps to set the stage for a second round of oral arguments in the  unusually vitriolic case , which observers expect to take place in early 2018. A decision is anticipated to follow shortly thereafter. In the filing, lawyers for the Broad and its collaborators argued that its opponent, a team that includes the University of California, Berkeley, has failed to provide new evidence that would undermine the legitimacy of the Broad\u2019s patent. The lawyers also used the University of California\u2019s own press releases as a sign that the case should be thrown out. At stake are intellectual-property rights to the use of CRISPR\u2013Cas9 gene-editing tools in eukaryotes, organisms such as plants and animals. This would include applications of the technique to treat human genetic diseases \u2014 an approach that has recently entered  cancer clinical trials in China , and is potentially the most lucrative application of gene editing. Although non-profit research institutes often reach settlements over such patent disputes, both sides in the CRISPR case have invested heavily in a prolonged patent fight, says Kevin Noonan, a partner at the law firm McDonnell Boehnen Hulbert & Berghoff in Chicago, Illinois. \u201cThey really went after each other so vigorously,\u201d he says. \u201cYou want to say, \u2018Hey, let\u2019s take a breath.\u2019\u201d \n             Novelty seeking \n           The fight began when the US patent office granted the Broad a patent covering the use of CRISPR\u2013Cas9 in eukaryotic cells. The California team had filed its patent earlier, but the Broad opted for an expedited review that got its application granted first. The University of California then argued that the Broad\u2019s patent interfered with the granting of its own patent, and  launched an official proceeding  before a board of specialized patent judges. Throughout that proceeding, the University of California team argued that its patent \u2014 which explicitly describes the use of CRISPR\u2013Cas9 gene editing only in non-eukaryotes such as bacteria \u2014 rendered applications in eukaryotic cells \u201cobvious\u201d and therefore unpatentable. The Broad countered that the University of California\u2019s invention needed significant and non-obvious tweaks before it could be used in eukaryotes. In February,  the patent office sided with the Broad . The University of California team soon filed an appeal to the US Court of Appeals for the Federal Circuit, claiming that the patent board had made \u201cfundamental errors of law\u201d that would allow the Broad to unfairly claim rights to the most important and valuable applications of CRISPR\u2013Cas9 gene editing. Despite that argument, Noonan expects the court \u2014 which generally defers to the patent office \u2014 to uphold the patent board\u2019s decision. \u201cFor Berkeley to prevail, the Federal Circuit is going to have to say, \u2018Yeah, the board got it wrong,\u2019\u201d he says. \u201cI think it\u2019s unlikely that they\u2019ll do that.\u201d \n             Counter arguments \n           In the 25 October filing, lawyers for the Broad also pointed to press releases issued by the University of California in the wake of the patent board\u2019s February decision. Those press releases argued that the University of California had come out ahead in the decision, because people who wanted to use CRISPR\u2013Cas9 gene editing in any system \u2014 eukaryotic or not \u2014 would still need to license its patents. If so, the Broad argued, then the University of California was not harmed by the patent board\u2019s decision and therefore lacks legal standing to appeal it. Upholding that previous decision could spell trouble for the University of California, notes Jacob Sherkow, a legal scholar at New York Law School. The university\u2019s patent would go back to the patent office for examination. But in May, the patent office issued another key CRISPR patent to Vilnius University in Lithuania. That application was filed earlier than the University of California\u2019s, so patent law could dictate that it takes precedence. The California patent could be crowded out, Sherkow says: \u201cThis is a dramatic turn.\u201d The CRISPR patent landscape elsewhere  is also uncertain . In Europe, the Broad has been granted ten patents but is in danger of losing as many as eight of them, notes Catherine Coombes, a patent attorney at intellectual-property specialists HGF in York, UK. In April, the European Patent Office issued a preliminary ruling that threw out the Broad\u2019s earliest filing date for its first patent, because the institute had later removed an inventor from the patent application. If that decision \u2014 which will be discussed during oral arguments in mid-January \u2014 becomes final, it will push the Broad\u2019s patent date to a time after the institute\u2019s team published its findings in a scientific article 1 . And that would invalidate the patent application altogether. Overall, there are more than 1,880 families of CRISPR patent, according to IPStudies, a consulting firm near Lausanne, Switzerland. More than 100 new families \u2014 each a group of related intellectual-property claims \u2014 are published each month. With those numbers in mind, people looking to commercialize CRISPR\u2013Cas9 gene editing will probably continue to face a daunting patent landscape, notes Coombes. \u201cThe situation is going to get a lot more complicated before it gets better.\u201d \n                   Why the CRISPR patent verdict isn\u2019t the end of the story 2017-Feb-17 \n                 \n                   Broad Institute wins bitter battle over CRISPR patents 2017-Feb-15 \n                 \n                   CRISPR heavyweights battle in US patent court 2016-Dec-06 \n                 \n                   Titanic clash over CRISPR patents turns ugly 2016-Sep-21 \n                 \n                   How the US CRISPR patent probe will play out 2016-Mar-07 \n                 \n                   Nature  special: CRISPR \n                 Reprints and Permissions"},
{"file_id": "nature.2017.23051", "url": "https://www.nature.com/articles/nature.2017.23051", "year": 2017, "authors": [{"name": "Barbara Casassus"}], "parsed_as_year": "2006_or_before", "body": "WHO data suggest around 10% of medications in poorer countries are fraudulent or substandard. One in ten medicines in developing countries is fake or substandard, data from the World Health Organization (WHO) suggest. Malaria drugs and antibiotics are among the most commonly reported, the agency found. But the problem extends to a variety of medications, including those for cancer, heart disease and HIV, as well as contraceptives and painkillers (see 'Fake drugs').  The latest figures come from a pair of reports 1 , 2  released by the WHO on 28 November \u2014 the agency\u2019s first on fake medicines in about a decade. The findings focus on fraudulent and poor-quality medications in low- and middle-income countries: of 1,500 cases reported to the agency in the past four years,\u00a042% were from Africa, 21% from the Americas and 21% from Europe. Data on the issue had until now been scant, because there was no mechanism to track the problem. The WHO set up a global system to report inferior medicines in 2013, tracking drugs that are deliberately fraudulent, fail to meet quality standards, or which have not been evaluated or authorized for market. These medications are often referred as counterfeit drugs, but the agency stopped using the term in May to shift the focus from intellectual-property issues to public health. The cases captured so far are probably just the tip of the iceberg, the WHO says, because many more go unreported. So far, the agency has trained 550 people in 141 countries to track these drugs. \u201cThe more one looks, the more one finds,\u201d it says. \n             Public-health problem \n           The studies estimate that roughly 10% of medicines in circulation\u00a0in poorer countries \u2014 where technical capacity to enforce quality standards is often limited \u2014 are substandard or falsified. Cases aren\u2019t limited to expensive or well-known medications, and are split about equally between generic and patented drugs. One analysis in the reports estimates that up to 169,000 children could be dying each year from pneumonia because of inferior antibiotics.  Poor-quality medicines not only fail to treat or prevent disease, they also risk worsening antimicrobial resistance, says Mari\u00e2ngela Sim\u00e3o, the WHO\u2019s assistant director-general for Access to Medicines, Vaccines and Pharmaceuticals. People taking substandard antibiotics that don't fully treat an infection could develop resistant infections that spread.  The findings underestimate the scourge of fake drugs, says Marc Gentilini, a member of the French Academy of Medicine who studies the issue. But crucially, he adds, there is not yet a plan in sight to tackle the problem. Reprints and Permissions"},
{"file_id": "nature.2017.22868", "url": "https://www.nature.com/articles/nature.2017.22868", "year": 2017, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Discovery raises questions about how a light 'supercurrent' might behave. Superconductivity \u2014 a phenomenon in which electrons can travel through certain materials with zero resistance \u2014 has revolutionized parts of medicine, travel and science. Now, an intriguing experiment has seen the same behaviour that underlies superconductivity \u2014 but in particles of light. The finding has left physicists wondering how far the comparison might reach. \u201cThis is really exciting work,\u201d says Nick Vamivakas, a quantum physicist at the University of Rochester, New York, who was not involved with the research. \u201cIt\u2019s a beautiful connection between light scattering, condensed-matter physics and quantum optics.\u201d Conventional superconductivity relies on the formation of \u2018Cooper pairs\u2019 of electrons, which stabilize each other\u2019s path and allow electricity to flow without resistance. Its discovery led to the development of powerful superconducting magnets, which are now used in medical scanners, particle accelerators, wind turbines and magnetically levitated trains. Physicists in Brazil have now seen evidence of photons of light forming similar pairs. The process occurs at room temperature when light passes through a range of transparent liquids, including water, although it is very difficult to observe. \u201cNot only is this formation of pairs possible, but it is everywhere,\u201d says Andr\u00e9 Saraiva, a theoretical physicist at the Federal University of Rio de Janeiro (UFRJ) and co-author of a paper that has been  accepted for publication  in  Physical Review Letters. The team has yet to explore how far the parallel with superconductivity goes. As photons already interact less with their environment than electrons do, similar pairs in light are unlikely to lead to such dramatic effects as in electric currents. But the work is already triggering speculation about how light \u2018supercurrents\u2019 might behave, and how they might be used. \n               Pairing up \n             The discovery stems from work led by Ado Jorio at the Federal University of Minas Gerais (UFMG) in Belo Horizonte, Brazil, which investigated how light scatters within materials. When this happens, photons can lose energy to the atoms in the material, which vibrate. If a second photon immediately absorbs this packet of vibrational energy, the two photons become indirectly linked, with one gaining the energy the other lost. When Jorio described his research to the condensed-matter department at UFRJ, it sparked an idea in physicist Belita Koiller. She noticed the similarity between this process (in which vibrations caused by one photon affect another) and the formation of Cooper pairs in superconductivity, when distortions in an atomic lattice, caused by a speeding electron, allow the particle to attract a partner in its wake. In both cases, pairs form as a result of movement in the atoms around them. In superconductors, however, the vibrations are of a fleeting kind allowed by quantum mechanics, known as virtual phonons. Koiller and her team wondered: was this true for light as well? First, the UFRJ team showed mathematically that if photons also interact via virtual phonons, their behaviour would be an exact match for Cooper pairs in superconductors. Then the researchers at UFMG looked for evidence of such pairs by shining pulses of laser light at room temperature through water and seven other transparent liquids. They used detectors to examine the emerging photons, searching for pairs that arrived simultaneously, in which one photon had shifted towards red (losing energy) and the other towards blue (gaining energy). If the arriving pairs were created by virtual phonons, rather than the standard scattering process, the energy shifts of the photons should be too small to come from classically allowed vibrations, so the team applied a filter to let through only this range of energy shifts. They compared the results with the number they saw when both types of energy shifts were allowed. In both cases, they saw the same rate of photon pairs, suggesting that the pairs had to be created by the virtual process. The signal was tiny: of around 10 quadrillion photons pumped through the material per second, they saw 10 pairs, compared with the 1 pair every 10 seconds that they would have expected to see by chance. It's an interesting discovery, says Andrea Ferrari, a physicist at the University of Cambridge, UK, although he cautions that the explanation will need to be validated by other groups. \u201cI would say this is not the end, but certainly the beginning.\u201d \n               Intriguing possibilities \n             The possibility of Cooper-like pairs in light has both quantum optics and condensed matter physicists taking notice, says Saraiva, largely because they want to see how far the analogy with superconductivity can be stretched. In matter, Cooper pairs are behind a wide range of intriguing effects \u2014 but so far the team has no data to hint whether the same would apply with light. \u201cThese are very important questions we\u2019re keen to answer,\u201d says Saraiva. If the team can boost the number of photon pairs, there could also be applications. Harnessing the way the paired photons interact with matter might reveal currently invisible properties of a material. And if the particles can be shown to correlate in ways beyond their timing \u2014 to have their quantum properties intrinsically linked \u2014 room-temperature water could prove a remarkably cheap source of 'entangled' photons, which are essential for quantum cryptography and computing. Physicists are also wondering whether the pairs might form supercurrents, behaving similarly to their electron counterparts: perhaps light would disperse less as it travels through a material, for example, leading to more efficient quantum communication. Might paired photons even make materials more transparent? At this stage, says Saraiva, we just don't know. For now, all this is pure speculation. But mapping concepts from condensed-matter physics onto light research has a pedigree of generating useful technologies, says Vamivakas. Photonic crystals, for example, which are used to tailor how photons flow through materials, grew out of insights about how a crystal lattice influences electrons in mattter, he points out. Vamivakas says that when he first heard of the latest work, he asked his students: \"Hey, why didn\u2019t we think of this?\" The discovery might not have happened at all if it hadn't involved such a simple experimental set-up. Funding for science in Brazil has been  cut by 60% since 2013 , leaving many laboratories unable to sustain their equipment. \u201cWe were fortunate to come across such a profoundly important phenomenon that does not require special equipment to see,\u201d says Saraiva. \u201cWe can\u2019t count on this kind of luck every time.\" \n                     A quantum pioneer unlocks matter\u2019s hidden secrets 2017-Sep-27 \n                   \n                     Quantum meld brings photons together 2013-May-09 \n                   \n                     Physicists spooked by faster-than-light information transfer 2008-Aug-13 \n                   \n                     Let there be light 2001-Feb-22 \n                   Reprints and Permissions"},
{"file_id": "nature.2017.22855", "url": "https://www.nature.com/articles/nature.2017.22855", "year": 2017, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "US-registered Central European University faces another year of uncertainty over whether it can continue to operate in Hungary. The threatened Central European University (CEU) in Budapest has been dealt a blow in its efforts to avert possible closure in Hungary. The country\u2019s parliament voted on 17 October to postpone for a year a decision that would allow the university to keep operating there. At a press conference held by the university shortly after the vote, CEU rector Michael Ignatieff called the delay \u201cunacceptable\u201d and \u201cunnecessary\u201d. In April, the Hungarian government  unexpectedly amended its higher-education law  to require that all foreign-accredited universities there had to operate as higher-education institutes in their countries of origin by 1 January 2018. The change drew protests and was widely believed to be politically motivated. Critics saw it as an attack on billionaire philanthropist George Soros, who founded the university in 1991 and has openly criticized Hungary\u2019s strict refugee policies. The CEU  took steps to comply with the new requirements  and on 3 October sealed an agreement with Bard College in Annandale-on-Hudson, New York, to provide educational activities there. Accredited courses run jointly by the universities would be launched next year, the CEU said. The agreement still needs to be signed by the Hungarian government and ratified by the country\u2019s parliament. But on 16 October the government proposed delaying the implementation of the amendment until 1 January 2019, and the parliament approved the delay the next day.  A government spokesperson told  Nature  that the purpose of the delay was to give other foreign higher-education institutions time to comply with the new requirements, adding that three institutions, including the CEU, are still in negotiation. Zoltan Balogh, Hungary\u2019s minister for human capacity, suggested on 16 October that government sign-off of the CEU\u2019s agreement might have to wait for the new deadline. \u201cWe are being deliberately kept in legal limbo,\u201d said Ignatieff, who fears the uncertainty will make it hard to retain faculty and recruit students. \u201cWe are being slowly strangled in this battle for academic freedom.\u201d \n                     Elite Hungarian university may be saved 2017-Oct-04 \n                   \n                     Arctic drilling, controversial reforms and new views of Saturn 2017-May-03 \n                   \n                     Hungary's protests, coral bleaching and a neutrino anomaly 2017-Apr-12 \n                   Reprints and Permissions"},
{"file_id": "d41586-017-08321-2", "url": "https://www.nature.com/articles/d41586-017-08321-2", "year": 2017, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08235-z", "url": "https://www.nature.com/articles/d41586-017-08235-z", "year": 2017, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08391-2", "url": "https://www.nature.com/articles/d41586-017-08391-2", "year": 2017, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08309-y", "url": "https://www.nature.com/articles/d41586-017-08309-y", "year": 2017, "authors": [{"name": "Jo Marchant"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08368-1", "url": "https://www.nature.com/articles/d41586-017-08368-1", "year": 2017, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08589-4", "url": "https://www.nature.com/articles/d41586-017-08589-4", "year": 2017, "authors": [{"name": "Andy Extance"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-08492-y", "url": "https://www.nature.com/articles/d41586-017-08492-y", "year": 2017, "authors": [{"name": "Nisha Gaind"}], "parsed_as_year": "2006_or_before", "body": ""}
]