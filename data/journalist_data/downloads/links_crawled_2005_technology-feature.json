[
{"file_id": "444963a", "url": "https://www.nature.com/articles/444963a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "\n               Table 1 \n               Reprints and Permissions"},
{"file_id": "438700a", "url": "https://www.nature.com/articles/438700a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "It's easy to focus on the kit and forget the really important part of the system \u2014 the cell. Cells of most interest with respect to ion channels include neurons and heart cells, which cannot be grown for long in culture and do not divide. Many of the cell lines used in ion-channel work are, therefore, stem cells and cell lines engineered to express specific channels. These include human embryonic kidney (HEK293) and Chinese hamster ovary (CHO) lines. bSys of Basel, Switzerland, offers a wide range of screening techniques, but chief executive officer Daniel Konrad believes that one of the company's chief advantages is their skill in selecting and fine-tuning cells. \u201cEach clone of cells is subtly different, and only trialling with many different sources can show which expression system is ideal,\u201d he says. bSys also works hard to find the right suspension protocol. This can make the difference between cells that generate 200 picoamp currents and those that can generate 500\u20131,000 picoamps and can be used in robotic screening systems, says Konrad. A new company moving into the designer-cell niche is Cellular Dynamics International (CDI) of Madison, Wisconsin, founded by noted human embryonic stem-cell researchers James Thomson, Craig January and Timothy Kamp of the University of Wisconsin. CDI will initially focus on developing HEK cell and cardiomyocyte-based screening services to the pharmaceutical and biotechnology industries, and plans to have a drug-screening service running by the first quarter of 2006. On the other side of the Atlantic, in Edinburgh, UK, the European arm of Stem Cell Sciences, founded by Peter Mountford in Melbourne, Australia, is developing neural stem (NS) cell lines from the Universities of Edinburgh and Milan. These cells are thought to be phenotypically similar to the NS cells found  in vivo . Derived from human and animal embryonic stem (ES) cells and from fetal and adult brain tissue, NS cells have great potential in biomedical research because of their homogeneity, their ability to self-renew indefinitely, and their relative ease of manipulation. Stem Cell Sciences is establishing a service for generating specifically mutated NS cells from engineered ES cells and transgenic animals. NS cells are attractive candidates for  in vitro  drug screening and may also be useful for cellular therapy for conditions such as Parkinson's disease and epilepsy. R&D Systems of Minneapolis, Minnesota offer ready-to-use primary cortical stem cells derived from rat embryos and the kits to grow them. The cells are validated for differentiation into astrocytes, neurons and oligodendrocytes. \n               P.M. \n             Reprints and Permissions"},
{"file_id": "438702a", "url": "https://www.nature.com/articles/438702a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Protein kinases are linked to numerous disease states, including cancer, arthritis, diabetes, cardiovascular diseases and neurological disorders. Gleevec from Novartis was the first compound active against a kinase (the Abl kinase) to be approved as a treatment \u2014 for certain gastrointestinal tumours and chronic myeloid leukaemia. The market for kinases is large. \u201cMore than 25% of new drugs being developed today are based on kinase technology,\u201d says Jeff Linton, president of Upstate of Charlottesville, Virginia, which offers one of the largest collections of kinases. A flagship of Upstate's operation is its KinaseProfiler service, run from Dundee in Scotland. This provides quantitative characterization of compounds against an ever-expanding panel of human protein kinases in a direct radiometric assay. The panel currently contains around 230 kinases, almost 50% of the total number of human kinases in the genome. A new focus for Upstate is the addition of naturally occurring mutant kinases as they are identified. Attention is also focusing on the newly emerging Gleevec-resistant mutants of Abl, and mutant forms of other kinases including the epithelial growth factor (EGF) receptor, as these mutations can alter an inhibitor's efficacy. One of these mutations involves a single \u2018gatekeeper\u2019 amino acid. Mutations in this amino acid can prevent therapeutic compounds from binding effectively without affecting the enzyme's activity. \u201cThe search is on for successful inhibitors that are not sensitive to changes at the gatekeeper site,\u201d says Steve Davies, director of Upstate's drug discovery segment. Upstate is helping this search by adding eight different mutant kinases to their portfolio, including ones for Kit, EGFR, Abl, Flt3 and p38/SAPK2a \u2014 and, says Davies, there are more in the pipeline. A highly specific set of anti-kinase antibodies makes up R&D Systems' Proteome Profiler Phospho-MAPK Array. This allows analysis of the phosphorylation status of 19 key signalling proteins, including members of all three major families of mitogen-activated protein kinases \u2014 the extracellular signal-regulated kinases, c-Jun N-terminal kinases, and the p38 kinases. These enzymes play essential roles in numerous signalling pathways that underlie cell function and disease. Signalling pathway analysis products from Beckman Coulter of Fullerton, California, are also devoted to looking at intracellular activated (phosphorylated) kinases. One strength is that these reagents can be used on many different types of specimen including whole blood, and can resolve activated and inactivated kinases in whole blood cells, according to Michel Herbert, marketing manager for Beckman Coulter. \n               P.M. \n             Reprints and Permissions"},
{"file_id": "438699a", "url": "https://www.nature.com/articles/438699a", "year": 2005, "authors": [{"name": "Pete Moore"}], "parsed_as_year": "2006_or_before", "body": "Ion channels, stem cells and cell signalling are the focus of intense interest in both cell biology and drug discovery. Pete Moore takes a look at what's on offer for the researcher. Ion channels act as electrical gatekeepers in cell membranes, and are responsible for the generation and propagation of nerve impulses, muscle contraction, and many other biological processes. With more than 400 ion-channel genes identified in the human genome, interest in detecting and measuring their activity is burgeoning. A high-throughput method of assessing the function of outward-rectifying potassium channels is to monitor the flow of tracer ions through them. In the case of potassium channels, rubidium ions (Rb + ) are used as a tracer because Rb +  has similar characteristics to K +  but is not present in biological systems and so there is no background noise. Trace amounts of Rb +  (as low as 0.05 mg l \u22121 ) can be detected using flame atomic absorption spectroscopy with the Ion Channel Reader (ICR) from Aurora Biomed of Vancouver, British Columbia. The ICR can be used to study voltage- and ligand-gated potassium channels as well as sodium channels and chloride channels. Another way of studying ion-channel activity is to monitor changes in membrane potential. Invitrogen of Carlsbad, California, and PerkinElmer of Boston, Massachusetts, have recently joined forces to offer a combination of Invitrogen's Voltage Sensor Probes ion-channel reagents and PerkinElmer's CellLux Fluorescence Cellular Screening Platform. This assay is based on fluorescence resonance excitation transfer (FRET); it uses a coumarin-phospholipid FRET donor that binds to the exterior of the cell membrane and a negatively charged FRET acceptor. In resting cells the two probes associate with the membrane exterior, resulting in efficient FRET and a red fluorescence signal. When a cell becomes depolarized as ions flow through channels, the FRET acceptor rapidly translocates to the other membrane face. Exciting the donor probe now generates a blue fluorescence signal. \n               Tracking channels \n             Ion-channel localization can affect cell function dramatically, and ChanTest of Cleveland, Ohio, offers antibody-based tests for detecting intracellular ion-channel trafficking. \u201cIn cystic fibrosis, 50% of families have a defect that prevents the CFTR channel protein being transported to the cell surface, and for the hereditary form of the hERG disease, about half of the mutations in the hERG channel protein affect trafficking,\u201d says ChanTest's chief executive officer Arthur \u2018Buzz\u2019 Brown. Blocking the function of the hERG potassium ion channel in cardiac muscle may be a major adverse drug effect as it can cause arrhythmia and sudden cardiac death, and all new drugs must be tested for whether they block this channel. In ChanTest's HERG-Lite assay, human embryonic kidney (HEK) cells express a version of the hERG channel carrying a hemagglutinin epitope. Protein turnover replenishes hERG channels about every 12 hours, so the cells are incubated overnight with the test compounds. The next day an antibody for the epitope is added along with a second antibody that produces a chemiluminescent signal. \u201cIf you don't permeabilize the membrane you can count the number of channels at the cell surface \u2014 it's simple and fast,\u201d says Brown. ChanTest's FAST & Lite service runs the antibody-based test alongside automated patch clamping to assess channel function. Assays for other channels are being developed and ChanTest has been awarded a small-business innovation grant from the National Institutes of Health to automate its system. \n               Patch clamping goes automated \n             Although indicator-based methods are fast and inexpensive, the gold-standard for assessing ion channels is the Nobel prize-winning technique of patch clamping developed by Erwin Neher and Bert Sakmann in the 1970s. The conventional manual method involves a glass micropipette filled with an ionic solution that electrically connects a silver\u2013silver chloride electrode wire to a small patch of cell membrane. A vital part of the procedure is to get an electrical seal of at least 1 gigaohm between the pipette tip and the membrane; without this seal the tiny currents that pass through the channels in the membrane patch cannot be measured. The drawback is that the technique requires considerable expertise, hours are spent poring over a microscope, and recordings can only be taken from one cell at a time. But over the past few years automation has entered this green-fingered science. A major player in the automated patch-clamp market is Molecular Devices of Sunnyvale, California, which merged last year with imaging specialists Axon Instruments. Molecular Devices has two high-throughput automated patch-clamping systems that can collect between 100 and 2,000 patch-clamping data points a day, depending on configuration. Both instruments work by sucking cells down against 1\u20132 \u00b5m diameter pores in the base of multi-well plates. The PatchXpress 7000A uses 16-well, glass SealChip plates made by Aviva Biosciences of San Diego, California. The machine places cells in each well and suction holds one cell that falls on the pore in place with sufficient strength to create an electrical seal of 1 gigaohm. The machine uses suction to disrupt the cell membrane to access the interior of the cell, and currents are measured across the entire cell surface. \u201cYou are, in effect, reversing traditional patch clamping by having the ground electrode measuring from the inside of the cell rather than from the outside,\u201d says Steve Davenport, vice-president of Europe for Molecular Devices. Each well is controlled and monitored individually and cells can be sealed for 30 minutes or more \u2014 during which time test compounds can be added to and flushed from the well. A single run takes around 45 minutes. The PatchXpress platform works well for both voltage-gated and ligand-gated ion channels and yields high-quality data comparable to the conventional manual patch-clamp method. IonWorks Quattro from the same company uses a 384-well Patch Plate, but wells share electronics. \u201cThis makes sense for a screening instrument where you need the highest throughput possible without compromising the pharmacology,\u201d explains Davenport. The system uses a new technology developed by Molecular Devices called Population Patch Clamp (PPC). PPC uses 64 holes versus a single hole in each well of the Patch Plate. This enables the signal from up to 64 cells in each well to be averaged. \u201cThe advantage of PPC over conventional single-hole planar patch-clamp is the reduction in biological variability and substantial increase in the success rate of obtaining a data point from each measurement,\u201d says Davenport. Using IonWorks, scientists can measure up to 2,000 data points per day. This speed doesn't come cheap. Both machines cost up to US$400,000. And although the IonWorks platform works well for voltage-gated channels, where you can adjust the voltage at the same time as recording, it will not work for fast ligand-gated channels, whose currents often last a millisecond or less, as the machine cannot add test compounds and record simultaneously. Contenders aiming to overcome the ligand-gated channel barrier in automated patch clamping also include Sophion Bioscience of Ballerup, Denmark, which uses a microfluidics approach. Its QPatch 16 operates 16 independent patch-clamp sites, each comprising a flat silicon chip with recording electrodes, a patch-clamp hole, pipetting wells and integrated microfluidic glass flow channels for applying solutions. \u201cQPatch 16 also provides a cell preparation facility in which the cells are suspended in culture medium until right before the experiment. This ensures that cells are kept viable and healthy, and enables unattended operation for at least 4 hours,\u201d says Niels Willumsen, a senior executive at Sophion. The integrated microfluidic flow channels of the QPlate allow sequential application of multiple compounds at very low volumes (around 5 \u00b5l) from four to eight pipette tips, and ensure the fast solution exchange (about 50 ms) required to study ligand-gated ion channels. The modular design can be upgraded to a 48-channel system and the machine can give 250\u20131,200 data points per working day. On a smaller scale, Fred Sigworth and Kathryn Klemic at Yale University, New Haven, Connecticut, have developed a planar patch clamp that can be built in the lab. \u201cIn the future, instead of buying an expensive chip, a lab might have a little device that can make an electrode, or an array of little electrodes, by moulding them out of silicon rubber,\u201d says Sigworth. A thin layer of polydimethylsiloxane (PDMS) resin is poured on to a plate containing a 2-\u00b5m diameter hole. Before the PDMS cures, air is blown through the hole, creating a 1-\u00b5m hole in the rubber sheet. After peeling the sheet off the plate, exposure of the surface to plasma oxidation creates a 100-\u00b5m thick glassy surface layer of SiO 2 . \u201cOn the one hand you have a hydrophobic silicone rubber base, then you create this thin layer of glass that the cell rests on \u2014 to a cell it looks a lot like a conventional glass electrode,\u201d says Klemic. In expert hands, the best systems for patch clamping can currently detect a pulse of about 150 elementary charges: equivalent to a flow of 150 sodium ions. \u201cThe grand challenge would be to resolve single elementary charges. Then you could watch a lot of really interesting processes such as the turnover of ions in pumps,\u201d says Sigworth. He is unsure whether this single-ion resolution will ever be possible, but thinks that it may be possible to mould the PDMS sufficiently carefully to reduce the capacitance in the system and substantially increase the resolution. Sigworth is also intrigued by the Port-a-Patch system developed by Nanion Technologies, a spin-off from the Centre for Nanoscience at the University of Munich in Germany. The beauty of Port-a-Patch is its ease of use. \u201cIt's basically a bench-top patch clamp. You pipette in the cells, close the lid and make the recording,\u201d he says. Nanion claims that this turn-key solution only takes half an hour to set up. \u201cWe run one-day training courses, and the system is easily used by people who have no experience in electrophysiology,\u201d says Nanion's chief executive officer Niels Fertig. It is the only automated device that addresses the need for low throughput with high accuracy, Fertig claims. The Port-a-Patch system uses planar borosilicate glass chips (100-\u00b5m thick) in which a conical pore of 1-\u00b5m diameter is micromachined. The pore has the three-dimensional geometry of an inverted pipette tip and cells are simply positioned via suction. It creates a strong electrical seal with the cell and is ideal for whole-cell patch clamping. Single-channel recordings can be performed in a cell-attached configuration. A software-controlled eight-channel microfluidics add-on can deliver sufficiently rapid changeover of solutions to allow the study of ligand-gated channels. A robotic version of the system that will run 16 patches at a time is in prospect. The Flyscreen, an alternative approach for moderate-throughput applications from flyion of T\u00fcbingen, Germany, can perform 100 to 500 independent whole-cell screens per day. The instrument uses glass micropipettes, into which cells are loaded. As the cells settle, a single one falls towards the tip and wedges near the opening. Carefully controlled suction draws the cell into a tight fit and further trains of pressure pulses disrupt the membrane, leaving a patch of cell membrane spanning the pipette's lumen. A plastic jacket moulded around the pipette enables robotic handling. The machine holds up to six pipettes and each channel runs independently, so pipettes can be discarded as soon as the cell fails. \u201cGlass blowing enables us to be flexible in the shape and geometry of the tips,\u201d says inventor Albrecht Lepple-Wienhues, founder and chief executive officer of flyion. This allows tailoring to suit different types of cells, and the new Flip-the-tip Large tips, which have a bowl at the base, enable the machine to monitor ligand-gated channels. \u201cThe bowl at the base gives us enough space to introduce a 130-\u00b5m diameter quartz needle,\u201d says Lepple-Wienhues. In flyion's standard tips, solution exchange takes about 60 seconds, but the new tips allow solutions to be puffed directly on to the cell through the quartz needle and give exchange rates of less than 50 milliseconds, while continuous recording is being carried out from each cell. \n               Patch-clamp economics \n             A report published in September by the Cambridge-based market-research consultancy HTStec makes interesting reading for those involved in the ion-channel industry. According to HTStec, the pharmaceutical and biotech market will spend around $32 million in 2005 on automated patch-clamping machines. \u201cWe predict that sales will peak in 2006 at around 200 units a year,\u201d says HTStec director John Comley. In addition to this, the report estimates that for automated patch-clamping, labs spend around $10 per data point for safety assessment and $3.00 per data point in primary screening. Companies claim they would be more comfortable paying around $6 and $0.60 respectively. HTStec's survey of 66 companies and universities indicated that manual patch clamping was still the preferred option in assay development and safety assays such as hERG compliance, but automated patch clamping was the method of choice for secondary screening, lead optimization and early non-compliant hERG liability testing. The highest possible throughput of some 3,000 data points a day is still far short of the 20,000 data points that respondents said they would like to get from a machine. Many were looking forward to machines that measure ligand-gated channels much more cheaply. As these account for 29% of all ion channels studied, this is a potentially big market. With genomics and proteomics creating a resurgence in cellular and systems research, there is every reason to believe that ion-channel research will become even more important in the coming decade. Sigworth Laboratory \u00a0 HTStec Reprints and Permissions"},
{"file_id": "438699b", "url": "https://www.nature.com/articles/438699b", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Although most patch-clamp technologies seek to maximize the number of cells rushed through the system, Owe Orwar and his colleagues at Cellectricon, a start-up company based in Gothenburg, Sweden, have developed a platform that maximizes the information gained from each cell. The result is a powerful tool for secondary screening in drug discovery. Their Dynaflow technology uses conventional glass pipette patch clamping, in combination with a novel microfluidic device for controlled delivery of drug solutions. Solutions of drugs or drug combinations are placed in up to 48 wells, each of which is connected to a measurement chamber by micrometre-diameter channels. These solutions can be directed through the chamber with high precision. \u201cDynaflow uses the unique properties of fluids when they are running at very low Reynolds numbers. When the fluids come out from a tiny channel in the open volume they behave as if they are still in channels \u2014 they do not mix,\u201d says Orwar. With no turbulence, diffusion would be the only chance of mixing between solution batches, but the timescales used are too short for that to occur. Consequently, Dynaflow can provide step changes in drugs or drug concentrations, with a change every 30 milliseconds if desired. \u201cIt is the most precise technology in the world to titrate receptors,\u201d claims Orwar. \u201cYou can see it as a microfluidic device that generates a barcode of chemicals, and the cell effectively reading the barcode,\u201d he adds. The ability to squeeze so much data out of a single cell enables some users to claim a ten-fold increase in productivity. By using carefully considered combinations of drugs in each well, cells can be taken through physiologically relevant conditions that relate to many different disease states. \u201cIn effect, it gives you the option of passing a chemical waveform over the cell while constantly recording from it,\u201d says Orwar. \n               P.M. \n             Reprints and Permissions"},
{"file_id": "438703a", "url": "https://www.nature.com/articles/438703a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Reprints and Permissions"},
{"file_id": "438701a", "url": "https://www.nature.com/articles/438701a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Human stem cells are valuable commodities: as well as their medical potential, their pristine naivety makes them attractive as gold-standard cell lines for research. Stem-cell banks, where owners deposit their precious products and would-be investigators apply for loans, are now being developed. The most advanced is the UK Stem Cell Bank, based at the National Institute for Biological Standards and Controls in Potters Bar, near London. Initiated in September 2002, and funded by the Medical Research Council and the Biotechnology and Biological Sciences Research Council since January 2003, it has the aim of providing a repository for all types of human stem-cell lines. \u201cAs of October 2005, we have 24 stem-cell lines approved for accession into the bank,\u201d says director Glyn Stacey, but none is yet ready for sending out to end-users. That probably won't be until early 2006. \u201cThe process is complex. It is not like growing an ordinary cell line where you could create and quality control a bank within a few months of receiving the cells,\u201d says Stacey. One time-consuming step is the creation of agreements for depositers and recipients, with each cell type presenting different problems and opportunities. Exploitation will be controlled by the depositer who retains ownership of the cells. Legal issues aside, stem cells are challenging to grow. The main problem is scaling up to provide hundreds of ampoules of cells at identical passage levels and stages of differentiation. \u201cIt could take an entire day for a highly skilled person to dissect and recover cells from just one line,\u201d says Stacey. And cultures have to be characterized and checked for contamination before release. All lines currently in the bank are human embryonic stem (ES) cells. \u201cWe have had some contact with people who think they have adult stem cell lines, but they are being careful about characterization,\u201d says Stacey. A few ampoules of each cell line have been frozen as back-up, whereas the master bank contains 20 or 30 ampoules. The distribution stock may eventually contain around a hundred ampoules of each line. Stacey hopes that early in 2006 the bank's website will start tracking progress of the cell lines that will be available to researchers. A few other initiatives are taking shape. The US National Stem Cell Bank will be located at the WiCell Research Institute, in Madison, Wisconsin, with a $16.1 million, four-year National Institutes of Health grant. It will acquire, store, characterize and distribute human embryonic stem-cell lines, but will be limited to those approved for federal funding. After a year of legal wrangling, a stem-cell bank is taking shape at the University of Granada in Spain, and others are being considered in Australia and South Korea. \n               P.M. \n             Reprints and Permissions"},
{"file_id": "4371198a", "url": "https://www.nature.com/articles/4371198a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Researchers interested in printing their own microarrays in-house now have an array of options \u2014 from contact (pin or split pin) and non-contact printing methods (bubblejet or piezoelectric inkjet) to  in situ  array synthesis. Bio-Rad Laboratories of Hercules, California, launched the BioOdyssey Calligrapher miniarrayer last month, which prints oligos, proteins or cell lysates onto slides, membranes or 96-well plates. This bench-top instrument has an eight-pin print head and prints up to 16 slides at a time. Optional extras include humidity and temperature controls. Telechem International of Sunnyvale, California, has also added humidity controls to its NanoPrint microarrayer. A plate-arraying option is now available on the BioRobotics MicroGrid ii and GeneMachines OmniGrid Accent platforms from Genomics Solutions of Holliston, Massachusetts. This enables DNA and protein microarrays of up to 1,000 features per well to be printed in 96- and 384-well microplates, providing high-throughput, multiplexing capabilities for diagnostic, ELISA and protein\u2013protein interaction applications. Non-contact printers may have got a bad rap in the early days but Arrayjet of Mayfield, UK, hopes to win over researchers with its new Aj120 piezoelectric inkjet printer, which it launched in July. \u201cContact printing can affect the quality of the data you get because it introduces surface-based artefacts into the microarray,\u201d says Duncan Hall, sales and marketing director for Arrayjet. Pin printers can also be very susceptible to atmospheric conditions, he says, particularly when hygroscopic printing buffers are used. \u201cWe carry our sample inside the print head so there isn't any evaporation from the print head.\u201d The Aj120 includes a microplate stacker and lid lifter, which enables walk-away printing of microarrays from up to 48 (96- or 384-well) microtitre plates. With the standard 12-sample connector block, 100 slides (samples and replicates side-by-side) can be printed in 90 seconds, says Hall. Additional replicates can be printed on the fly in no extra time. The Aj120 prints DNA, proteins and intact cells with a 100-\u00b5m spot diameter. PerkinElmer Life and Analytical Sciences of Boston, Massachusetts, also offers contact and piezoelectric non-contact systems. For those with deeper pockets, CombiMatrix sells a CustomArray desktop DNA synthesizer for the  in situ  synthesis of oligonucleotides on microarrays with up to 12,000 features. Synthesis occurs on a blank CombiMatrix semiconductor chip using standard phosphoramidite chemistry methods. \n               D.G. \n             Reprints and Permissions"},
{"file_id": "435993a", "url": "https://www.nature.com/articles/435993a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "One goal of the HapMap project is to help reserachers find SNPs associated with human disease. Josephine Hoh at Yale University's School of Public Health and colleagues at Rockefeller University, New York, and the National Eye Institute in Bethesda, have identified an SNP associated with age-related macular degeneration (AMD), a major cause of blindness in people over 60. The SNP is in the gene for complement factor H, leading to a tyrosine to histidine mutation. The researchers studied 96 patients with AMD and 50 healthy controls, and measured the frequency of over 116,000 SNPs in each group. \u201cFor the initial screen, we used Affymetrix's set of 100K SNP chips,\u201d says team member Robert Klein. \u201cTo identify the putative causal mutation, we used PCR to amplify each exon in a number of samples and then resequenced to find all variants in the exons.\u201d Hoh and her colleagues found that caucasian patients with AMD are at least four times more likely than usual to have this SNP. How the change causes AMD is not yet known, and one of the next directions for her lab \u201cis to figure out the functional mechanism of complement factor H in the pathogenesis of AMD\u201d, says Hoh. There are a few clues. The amino-acid change lies in a part of factor H that interacts with C-reactive protein and heparin, both known to be associated with AMD. And factor H is known to regulate components of the immune system that are found in drusen, fatty deposits that accumulate in the macula with age. In people with AMD, the drusen are larger and more numerous, killing cells needed to nourish adjacent retinal photoreceptors, which eventually results in loss of sight. SNP mapping is also underway in animal models of human disease. Kent Hunter at the National Cancer Institute (NCI) in Bethesda, Maryland, uses SNPs to look for cancer-modifying genes in mice. \u201cUltimately, we hope to identify the particular polymorphic gene or genes that modulate metastatic efficiency,\u201d he says. Maxwell Lee at the NCI is interested in how genetic variation determines gene expression and phenotypes in human cancer and uses SNPs to search for epigenetic markers. \u201cWe need to understand more dynamic aspects of the genome including interactions between SNPs and other downstream targets such as chromatin, DNA methylation and gene expression,\u201d he says. Caitlin Smith Reprints and Permissions"},
{"file_id": "435992a", "url": "https://www.nature.com/articles/435992a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "At the high-throughput end of multiplex SNP genotyping, Illumina of San Diego, California, is currently beta testing the Sentrix Human-1 BeadChip, containing more than 100,000 SNPs, nearly 30,000 of which are located in genes, with another 40,000 within 10 kb of genes. The company is developing BeadChips containing 250,000 and 500,000 SNPs for release next year, which will make it possible to genotype 1 million SNPs on just a pair of chips. Using a different approach to SNP genotyping, the LightTyper Genotyping System from Roche Applied Science of Indianapolis, Indiana, is designed for the heavy-duty end of the market, where thousands of samples may have to be genotyped each day. After PCR amplification of genomic samples in 96- or 384-well plates using a standard thermal cycler, plates are transferred directly to the LightTyper and genotyped within 10 minutes, using the melting points of fluorescently labelled probes hybridized with the SNPs as the detection system. Probe-target complexes with different melting points reflect the presence of different alleles, and show up as allele-specific peaks in the melting curves. Because many samples can be tested simultaneously, \u201cthe LightTyper instrument is mainly used for SNP genotyping, in particular for disease association studies,\u201d says Burkhard Ziebolz of science communications at Roche Diagnostics in Mannheim, Germany. The Luminex xMAP platform for multiplex genotyping is used by several genetic diagnostics service companies, including TmBioscience of Toronto, Ontario, which has developed the first Food and Drug Administration-approved multiplexed test for cystic fibrosis mutations, and Tepnel LifeCodes of Manchester, UK, whose speciality is HLA DNA typing. For less-intensive SNP detection, the READIT SNP genotyping system from Promega of Madison, Wisconsin, can be scaled up or down. It uses the company's READase-mediated destabilization of perfectly matched probe-target complexes coupled with a luciferase reporter assay for the ATP generated. With appropriately designed probes, the system can detect SNPs, insertions, deletions and chromosomal translocation, and can estimate allele frequency and carry out allele-correlation studies. And PerkinElmer of Boston, Massachusetts, have SNP detection kits in their established AcycloPrime range. Caitlin Smith Reprints and Permissions"},
{"file_id": "4371196a", "url": "https://www.nature.com/articles/4371196a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Array-based methods are now being applied in a diagnostic setting and offer the possibility of analysing multiple analytes (and even multiple samples) in a highly parallel and high-throughput manner. In diagnosis, however, the tolerance for error is very low: it is important to get the right answer not just occasionally but all of the time, under stringent conditions and with varying sample quality. Nevertheless, important milestones have been achieved in the past year as array-based diagnostic tests begin to trickle onto the market. Agendia of Amsterdam, The Netherlands, offers MammaPrint, a diagnostic test for assessing the risk of breast cancer progression. The test predicts the future development of metastases on the basis of a 70-gene expression signature discovered by scientists at the Netherlands Cancer Institute and Antoni van Leeuwenhoek Hospital in Amsterdam. Its use should improve the quality of treatment decisions for cancer patients by distinguishing those individuals who would, and who would not, benefit from further treatment. In May, Tm Bioscience of Toronto, Canada, received FDA clearance for its Tag-It cystic fibrosis (CF) kit to be used as an  in vitro  device for diagnostic use. The test, which identifies a group of mutations in the CF transmembrane conductance regulator (CFTR) gene, is based on the bead-based xMAP multiplexing technology developed by Luminex of Austin, Texas. xMAP allows multiplexing of up to 100 assays within a single sample. In addition to human genetic disorders, Tm Bioscience is developing products aimed at pharmacogenetics and infectious diseases. Last year, Affymetrix of Santa Clara, California, received clearance by regulatory authorities in the United States and Europe for the  in vitro  diagnostic use of its GeneChip System 3000Dx. Affymetrix's strategy for developing new array-based diagnostic tests on its GeneChip platform is to work alongside partners from the diagnostics industry, such as Roche Diagnostics of Basel, Switzerland, bioM\u00e9rieux of Marcy l'Etoile, France, and Veridex of Warren, New Jersey. \u201cWe are a technology-driven company,\u201d says Robert Lipshutz, senior vice-president of molecular diagnostics and emerging markets at Affymetrix. \u201cWe did not have a large regulatory or commercial presence in the diagnostics industry.\u201d The first microarray product to be launched through the partnership with Roche is the AmpliChip CYP450 test, which identifies variations in two drug-metabolism genes that can affect the rate at which an individual metabolizes many common drugs. Other companies are taking a different approach. CombiMatrix of Mukilteo, Washington, formed a diagnostic subsidiary, CombiMatrix Molecular Diagnostics, in May, now led by former senior executives from the diagnostics industry. \u201cWe want to capture revenue not just from the chip but from the test itself,\u201d says Michael Tognotti, vice-president of sales and marketing at CombiMatrix. \u201cWe didn't feel that high-density arrays are the way to go for clinical utility,\u201d says Graham Lidgard, senior vice-president of research and development at Nanogen of San Diego, California. The company is targeting the clinical and diagnostic market with its NanoChip electronic microarray system. \u201cIf you want to do one or two targets, then reverse transcription\u2013PCR is really the way to go, but if you want to look at four or five single-nucleotide polymorphisms to 100 targets across a number of patients, our technology is probably best suited to that application,\u201d Lidgard says. The company's NanoChip 400 platform for multiplexed mutation detection, out later this year, features increased automation and will offer a 400-site cartridge for increased throughput; the original version has 100 electrodes, or test sites. An equity investment in Jurilab of Kuopio, Finland, announced in July, gives Nanogen certain rights to develop diagnostic products based on genes and gene markers discovered by Jurilab. The initial focus will be on cardiovascular and metabolic diseases, including adult-onset diabetes. BioArray Solutions of Warren, New Jersey, has developed a novel twist on traditional bead-based systems where beads displaying proteins or DNA capture probes are in suspension and assays are performed \u2018in-tube\u2019. BioArray's BeadChip format provides a bead array in the form of a single pre-assembled layer of colour-coded beads in random configuration on a small silicon chip. The company is initially developing BeadChip assays to screen carriers for CF and Tay\u2013Sachs disease, as well as for transfusion and transplantation medicine. \u201cIt's a very diverse set of applications that we've already developed and deliver on a complete platform,\u201d says Michael Seul, president of BioArray Solutions. \u201cAs a small company, we've chosen to focus on certain areas where we can have a large impact because they have been largely unexplored.\u201d MetriGenix of Toronto, Canada, is developing genomic biomarker panels and genomics instrumentation for the diagnostic market. In the company's Flow-thru chip technology, molecular interactions occur within 3D microchannels rather than on a planar surface. The company's TipChip technology is provided as part of the MGX8 automated system, which can process eight 1\u00d71-cm silicon TipChips in parallel with up to 1,600 biomolecular targets or \u2018spots\u2019 per chip. The system is suitable for RNA, DNA or protein targets. Sample preparation is still a time-consuming process in all platforms. Further automation on the front end would improve robustness and reduce costs. \n               D.G. \n             Reprints and Permissions"},
{"file_id": "437775a", "url": "https://www.nature.com/articles/437775a", "year": 2005, "authors": [{"name": "Lisa Melton"}], "parsed_as_year": "2006_or_before", "body": "Over the past ten years, microscopy has been transformed from slice, stain and fix, to the capacity to view living cells and even whole organisms in real time. Lisa Melton looks at what's on offer. When it was introduced in the late 1980s, confocal laser-scanning microscopy opened up a new high-resolution world to biologists. But researchers are becoming more demanding of their microscopes. They expect not just to see a clearer image, but to monitor dynamic protein networks within cells, map the kinetics of intracellular organelles and track calcium signalling. Microscope developers have responded by producing confocal microscope systems that have dramatically improved scanning speeds, greater resolution and the capacity to see detail in live cells labelled with multiple colours. Researchers traditionally struggled to obtain sharp images from multi-stained specimens, the main obstacle being spectral emission overlap from different fluorescent probes. Nikon's recently launched Digital Eclipse C1 Spectral Imaging confocal system collects high-resolution data from the 400\u2013750 nanometres range with a single pass of the laser. A mathematical process unmixes closely overlapping spectral data to produce clean images with no cross-talk, even for notoriously difficult reds. \u201cWe use chromatic aberration-free objectives, so everything towards either end of the spectra focuses at the same point,\u201d says Chay Keogh, marketing manager for Nikon, UK in Kingston upon Thames. \u201cBy eliminating the need for multiple scans, specimen damage is kept to a minimum.\u201d A rival system from Olympus, the Fluoview FV1000, is a confocal laser-scanning microscope with two independent, synchronized laser scanners in a single instrument. While one laser provides high-resolution confocal images, the second scanner, the SIM scanner, simultaneously stimulates the sample. This makes the FV1000 an ideal choice for live-cell applications such as fluorescence recovery after photobleaching (FRAP), fluorescence loss in photobleaching (FLIP), uncaging, or photoactivation and photoconversion. \u201cIt offers, for the first time, the opportunity to study the kinetics of rapid cellular reactions after laser stimulation, without a time lag, because you don't have to stop imaging when using laser light for stimulation,\u201d points out Martin Tewinkel, business manager at Olympus Life and Material Science Europa in Hamburg, Germany. \u201cSuch studies of rapid cellular responses can provide important insights into how various cellular mechanisms operate.\u201d Another high-speed, high-resolution confocal imaging system is the Nipkow-disk-based Ultraview ERS from PerkinElmer of Boston, Massachusetts, which offers a choice of cameras for different applications: a standard interline CCD detector for the highest resolution with slower processes or bright samples that withstand higher laser intensities, or an electron-multiplying CCD detector for highly dynamic processes, very dim fluorescence, or light-sensitive samples. For researchers who want speed but don't need the high resolution of a confocal microscope, Olympus has designed live-cell imaging systems that can be fitted to Olympus's upright BX or inverted IX series wide-field microscopes \u2014 the relatively inexpensive cell \u2227 M imaging station and the high-end station cell \u2227 R. The cell \u2227 R takes ten multicolour images per second at full resolution and can be used to track cell growth, metabolic transport and signal transduction in real time. \u201cIt's always a trade-off: the quality of the data on the one hand and speed on the other,\u201d explains Christian Seel, head of information transfer management at Olympus BioSystems in Munich. The key to speed is finely synchronized illumination and camera controls. The high-intensity coloured light is switched off the specimen immediately after taking each photo, reducing photo-damage to a minimum, says Seel. Time-lapse series are stored by the imaging software and presented as movies or charts. Developers at Carl Zeiss believe there is no need to sacrifice resolution for ultra-fast cellular dynamics with the confocal imaging system LSM 5 LIVE. \u201cOur main motivation was to develop an instrument dedicated to fast live-cell imaging, with a much higher speed than any other system available today while maintaining a very good confocal resolution,\u201d says Richard Ankerhold, director of advanced development at Carl Zeiss in Jena, Germany. Dynamic interactions can be viewed at different scales \u2014 a group of interacting molecules, a complete cell, a developing organ, or even an entire zebrafish embryo, notes Ankerhold. LSM 5 LIVE operates even on weakly fluorescent specimens and collects up to 120 confocal images per second at a resolution of 512 \u00d7 512 pixels, scanning about 20 times faster than a traditional confocal system. Developmental biologist Mary Dickinson and her group at the California Institute of Technology in Pasadena have capitalized on the instrument's fast-frame recording to image erythroblasts rushing through the heart of an 8-day-old mouse embryo, and to produce a time-lapse series of the beating heart of a zebrafish embryo. This technology is expensive, however, and at present only affordable by large research institutes. Alternative optical approaches to imaging embryos for developmental research are selective plane illumination microscopy and optical projection tomography microscopy (see  \u2018An illuminating breakthrough\u2019  and  \u2018Optical tomography for embryos\u2019 ). With calcium-sensitive dyes such as Fura-2 you can visualize spikes, waves and oscillations of calcium in living cells. An instrument dedicated to imaging intracellular ion kinetics \u2014 and with a price tag within the reach of most research labs \u2014 is the InCyt Imaging system from Intracellular Imaging of Cincinnati, Ohio, co-founded by Eric Gruenstein, director of the Center for Image Analysis at the University of Cincinnati. Starting at US$30,000, it includes a fluorescence microscope, low-light-level CCD camera, filter changer and image-processing computer. \u201cIt's a very cost-effective and feature-rich solution for ion imaging and cell kinetics,\u201d says Tim Fletcher, product specialist at Image Solutions of Preston, the UK distributors for Intracellular Imaging. InCyt has been tailored to image and quantify calcium, but can measure other ions, and works with all commonly used dyes. Designed by cell biologists, the software follows the logical flow of an experiment. Images can be displayed in real time or saved and played back as an animated sequence. \u201cThe InCyt system needs very little training, and researchers pick it up quickly,\u201d says Fletcher. \n               The whole animal \n             For some imaging applications, getting a picture from inside the living body is the goal (see  \u2018Optical biopsies\u2019 ). And for others, a shift from imaging  in vitro  to the whole living animal is desirable. \u201cMany pathways interact on a systems level, that is, the immune system and the endocrine system,\u201d says Pam Contag, co-founder of imaging company Xenogen in Alameda, California. Xenogen puts together non-invasive optical imaging systems with transgenic mice and rats containing the required luciferase-tagged genes. The Xenogen IVIS 200 will image either bioluminescence or fluorescence, and its adjustable field of view makes it versatile enough to image single cells at high resolution or up to five anaesthetized mice at a time. Biophotonic imaging has proved a success with the pharmaceutical industry to test drug candidates and make more educated predictions. \u201cIn drug discovery, the cell is used as the gold standard, but you don't treat single cells, you treat the whole person,\u201d Contag insists. \u201cOur goal is to make animal models to be predictive for what happens in humans.\u201d Lightools of Encinitas, California, concentrates on whole-body imaging of animals carrying fluorescent-tagged genes. \u201cWe can zoom in and out from a couple of centimetres to 10\u201315 centimetres in the field of view,\u201d says John Fox, Lightool's president. The company has recently introduced two novelties that are proving popular. One is a device for simultaneously viewing green and red fluorescent proteins (GFP and RFP) in transgenic animals, with independent controls for each fluorophore. \u201cIt allows you to turn up the RFP excitation and turn down the GFP \u2014 which is usually brighter \u2014 to obtain a more balanced image,\u201d says Fox. The second is the Pan-A-See-Ya panoramic imaging system, which gives a 270\u00b0 view of the animal in one evenly illuminated image. \u201cIt's like being able to see round the corner,\u201d says Fox. A target such as a fluorescent tumour can be viewed from two different angles at the same time with a single camera. The process is even fast enough to allow animals to be imaged without anaesthesia. \n               Breaking the resolution barrier \n             Abbe's law, postulating that optical resolution is impossible below 200 nanometres, went unchallenged for 120 years. Until recently, that is, when physicist Stefan Hell, a director of the Max Planck Institute for Biophysical Chemistry in G\u00f6ttingen, Germany, established a new law that promises greater resolution in fluorescence microscopy. The first commercial application of his new ideas is the 4Pi fluorescence confocal imaging system, created in cooperation with Leica Microsystems in Mannheim, Germany. The Leica TCS 4Pi improves resolution of fluorescent images to 110 nanometres along the  z  axis. Martin Hoppe, marketing manager for Leica Microsystems, says that the system addresses a resolution gap between optical and electron microscopes. \u201cThat's what I see when I offer this system to researchers,\u201d he says. Structures down to 110 nanometres can now be resolved in living cells \u2014 a malaria parasite can now be localized precisely inside a red blood cell, for example. For life-sciences researchers, the advantage of the TCS 4Pi over electron microscopy is that specimens can be kept alive and fluorescent stains can be used. \u201cPeople don't have to redo their staining techniques,\u201d says Hoppe. The remarkable gain in sharpness is due to the use of two opposing lenses with high numerical aperture to illuminate a single focal spot. The two wavefronts of the opposing beams interfere constructively at the focal point, which gives much higher resolution. But at US$1,000,000, the TCS 4Pi doesn't come cheap. \u201cWhat drives up the cost is the combination of precision mechanics, interferometer optics and state-of-the-art electronics. Also, the 4Pi objectives have to be paired, this makes the manufacturing yield very low,\u201d Hoppe points out. \n               A world of colour \n             Quantum dots may be the newest kid on the block (see  \u2018Quantum dots keep on glowing\u2019 ), but since its cloning a decade ago, the green fluorescent protein has become one of the most powerful molecular tools in the cell biology tool-box. Either by itself or as part of a fusion protein, GFP is used to visualize proteins inside living cells in a vast number of applications, from detecting gene expression to tracking cell fate in developing embryos. The range of fluorescent proteins from jellyfish now includes red (RFP), cyan (CFP) and yellow (YFP) relatives of GFP. CFP and YFP, in particular, make a suitable contrasting pair for multicolour imaging for differential gene expression and protein localization. Species other than jellyfish are now being mined to expand the colour palette. The DsRed\u2013Monomer fluorescent protein, an engineered variety of a protein from the sea anemone  Discosoma , was recently launched by BD Biosciences Clontech of Mountain View, California, now part of Shiga-based Japanese life-sciences supply company Takara Bio. \u201cWhat is driving users' interest towards red is a better signal-to-noise ratio, because the background fluorescence from the culture medium is in the green range,\u201d explains Andrew Farmer, director of cellular and molecular biology for Clontech Business Research. The monomeric form of the new protein is an added advantage, particularly for subcellular labelling. \u201cThe DsRed\u2013Monomer is less likely to misbehave than the tetrameric reds, which can sometimes disrupt the function of the fusion protein,\u201d says Farmer. Stony corals have yielded a remarkable collection of new fluorescent proteins. The CoralHue range was originally isolated by Atsushi Miyawaki at the RIKEN Brain Science Institute in Saitama, Japan. Kaede (Japanese for maple leaf), the first of the family, is a brilliant green fluorescent protein that changes colour to a stable red when exposed to a short pulse of ultraviolet or violet light. Miyawaki's team have used Kaede to study hippocampal neuronal connections. Cultured neurons are labelled with green Kaede by gene transfection then, with a focused violet light pulse, a single cell body is illuminated. As the red spots spread rapidly throughout the cell's cytosol, all the nerve-cell processes, including an axon and illuminated dendrites, stand out from the green background, delineating the neuron and its multiple contact sites. A recent addition to the CoralHue family is Kusabira orange, the first monomeric true-orange fluorescent protein. \u201cIts greatest value is in combination with Midoriishi\u2013Cyan for fluorescence resonance excitation transfer analysis,\u201d says Suzan Oberle, product manager for MBL International of Woburn, Massachusetts, which distributes the CoralHue range. The CoralHue pair is brighter and shows better spectral separation of donor and acceptor signals than the widely used CFP and YFP pair. For FRAP and FLIP applications, CoralHue Dronpa green bleaches following excitation at 500 nanometres but completely regains its bright green fluorescence after minimal irradiation at 400 nanometres, without losing signal intensity. The switching can be repeated without losing brightness. Miyawaki's group has used this reversible protein highlighting technique to track proteins shuttling across the nuclear membrane after cell stimulation. Another photo-switchable fluorescent protein is produced by Evrogen, a biotechnology company based in Moscow, Russia. Their cyan-to-green photo-converting protein PS-CFP2, gives a 2,000-fold increase in the green-to-cyan fluorescence ratio, making it the highest-contrast monomeric photoactivatable fluorescent protein so far. The microscope may be 400 years old, but microscopy is refusing to show its age. High-resolution live imaging is giving researchers a whole new look at the biological world. Reprints and Permissions"},
{"file_id": "435991b", "url": "https://www.nature.com/articles/435991b", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Having helped to identify many miRNAs, Christopher Burge and his colleagues at the Massachusetts Institute of Technology are one of many teams now tackling an even bigger job \u2014 to find out which genes are regulated by the known miRNAs, and how they fit into physiological pathways. Finding targets begins computationally, using the TargetScan algorithms developed by Benjamin Lewis working with Burge and with David Bartel at the Whitehead Institute for Biomedical Research in Cambridge, Massachusetts. These algorithms \u201crely on evolutionary conservation of segments complementary to the microRNA \u2018seed\u2019 region in the 3\u2032 untranslated regions of orthologous genes from multiple vertebrate organisms\u201d, says Burge. The seed region, six or seven bases at the 5\u2032 end of the miRNA, is thought to be key to specifying which genes an miRNA will regulate. Targets have been verified in Bartel's lab using a dual luciferase reporter system, which measures the effect of predicted miRNA interaction sites on protein production in cultured human cells. In a computational analysis published earlier this year, Lewis, Burge and Bartel estimated that more than a third of our genes might be regulated by miRNAs. The task will be complicated by the fact that an miRNA may regulate as many as 200 genes, according to a computational study by Nikolaus Rajewsky and his colleagues at New York University and Rockefeller University, using their PicTar algorithm to identify miRNA targets. Other software for miRNA target prediction includes miRANDA from Anton Enright and his colleagues at the Memorial Sloan-Kettering Cancer Center in New York and DIANA-microT from Artemis Hatzigorgeou and Axel Bernal at the University of Pennsylvania, Philadelphia. Frank Slack's team at Yale University uses  in situ  hybridization, northern blots and fluorescent protein fusions to find when and where miRNAs and their targets are expressed. \u201cWe use genetics and RNA interference to reduce the expression of potential targets to see if we suppress the effects of a mutation in the corresponding miRNA, and use reporter gene assays to test if the miRNA-complementary sites function in gene regulation,\u201d he says. \u201cThe classic tools of developmental biology and physiology are needed to correlate miRNA expression and targeting to biological function,\u201d agrees James Carrington at Oregon State University, Corvallis, who is looking at pathways regulated by miRNAs in  Arabidopsis . \u201cmiRNA sensors involving miRNA target sites within gene constructs expressing a fluorescent protein are quite useful in understanding spatial and temporal miRNA expression and activity patterns,\u201d he says. But to address the question of how miRNAs integrate with cellular pathways, \u201cthe more quantitative approaches using the tools of systems biology and computational analysis are the trend in this lab\u201d, he says. Caitlin Smith Reprints and Permissions"},
{"file_id": "4371195a", "url": "https://www.nature.com/articles/4371195a", "year": 2005, "authors": [{"name": "Diane Gershon"}], "parsed_as_year": "2006_or_before", "body": "DNA microarrays are diversifying in new directions, including  in vitro  diagnostics. Diane Gershon takes a look at what's around the corner for microarray applications. It's now ten years or so since Affymetrix of Santa Clara, California, first began selling commercial DNA microarrays. In that time, complete or partial sequences of numerous genomes, including human, have been deposited in the public databases. Coupled with recent improvements in microarray technology, this development is propelling microarrays into areas of application that extend well beyond gene-expression analysis. It is also now generally accepted that new insights will not be gained simply by acquiring more and more gene-expression data, and that it is no longer sufficient to focus on the 25,000 or so protein-coding genes that make up roughly 2% of the human genome. Exploring the role and diversity of non-coding RNAs is equally important. Ten years on, Affymetrix still dominates the high-density DNA microarray market. But new players have entered more recently, hoping to carve out a niche in new and emerging areas such as splice-variant or microRNA analysis (see \u2018It's a small world\u2019). Others are differentiating themselves by leveraging their more flexible methods of array synthesis and offering custom-made microarrays for the human genome and a whole host of model organisms. As a general rule of thumb, there are three key things to look out for when it comes to assessing DNA microarray platforms: feature density per array, flexibility (how easy it is to change the array content and design), and sensitivity. CombiMatrix of Mukilteo, Washington, an operating group of Acacia Research Corporation, concentrates on designing and manufacturing relatively low-density custom microarrays containing up-to-date content. Last month the company began offering its 4\u00d72K customized microarrays for US$99, produced using its semiconductor-based  in situ  oligonucleotide synthesis method. The 4\u00d72K CustomArrays contain four arrays of 2,240 oligonucleotide features per slide with a 44-\u00b5m feature size. CombiMatrix plans to offer its first high-density array early in 2006, which will have 90,000 features and a 25-\u00b5m feature size. \u201cWe're custom, quick, flexible and cost-effective,\u201d says Michael Tognotti, vice-president of sales and marketing at CombiMatrix. There are no minimum order requirements for these arrays, which Tognotti says can be re-used up to three times, further driving down costs for researchers. \n               Tiling technology \n             But companies such as Affymetrix see less of a need for customization now that it can put whole genomes on a chip. \u201cAffymetrix, as a result of continually shrinking the feature size, has made it practical to do experiments where we look across the entire genome without bias,\u201d says John Blume, vice-president of RNA products at Affymetrix. The development of tiling arrays marked a departure from the way DNA microarrays had traditionally been designed. Rather than containing probes just for known or suspected functional regions, tiling arrays can be used to interrogate, or \u2018tile\u2019 across, the genome in an unbiased fashion, by means of probes spaced at regular intervals along the genome. Tiling microarrays can be used for the genome-wide study of gene regulation, specifically to map sites of transcription-factor binding, chromatin modification, DNA methylation and chromosomal origins of replication. This month, Affymetrix will launch a set of seven arrays, each with 6.5 million probes and a 5-\u00b5m feature size, to tile across the entire human genome at 35-base-pair (bp) resolution. Tiling arrays for several model organisms, including  Arabidopsis ,  Drosophila ,  Saccharomyces cerevisiae  and  Schizosaccharomyces pombe , are planned. \u201cAffymetrix will continue to innovate with respect to feature size. We don't think 5 [\u00b5m] is the end,\u201d says Blume. The highest-density arrays from Agilent Technologies of Palo Alto, California, have 44,000 features. The company is about to launch its next-generation ink-jet printing platform for the non-contact  in situ  synthesis of 60-mer oligonucleotide probes on glass slides. With the new instrument, which will not be sold commercially, \u201cwe think that we can get about an order of magnitude higher density in the span of about two years,\u201d says Scott Cole, head of genomics marketing at Agilent. \n               Scanning to size \n             The ever-shrinking feature size on high-density microarrays must also be coupled with improvements in scanning technology. This summer Affymetrix launched the new GeneChip Scanner 3000 7G with a scanning resolution in the sub-micrometre pixelation range, and which can scan features ranging in size from 2.5 to 0.51 \u00b5m. The scanner supports all high-resolution GeneChip products for tiling, all-exon and single-nucleotide polymorphism genotyping research. For those on a budget, TeleChem International offers the 10-\u00b5m resolution SpotLight microarray scanner. Rather than using lasers and photomultiplier tubes, as in most traditional scanners, the SpotLight uses \u2018cool\u2019 excitation technology that is optimized for two-colour detection (Cy3 and Cy5). Optional filter sets are available for fluorescein, rhodamine, allophycocyanin, ethidium bromide, the Alexa dyes and several green fluorescent protein variants. Scanning solutions are also available from established scanner manufacturers including arrayWoRxe from Applied Precision of Issaquah, Washington, GenePix from Molecular Devices of Sunnyvale, California and ProScanArray from Perkin Elmer. CombiMatrix is developing an electrochemical detection (ECD) method to read its semiconductor-based microelectrode arrays, as an alternative to fluorescence. The company hopes to develop a smaller, less expensive detection system that will provide better performance than fluorescence-based systems \u2014 the only method so far to be commercially successful. A prototype is in beta testing and a commercial product is expected next year. CombiMatrix hopes to corner the molecular diagnostics market with a handheld version. Options are also available for researchers who want to print their own microarrays (see \u2018On the hardware front\u2019,  page 1198 ). \n               Comparative genomic hybridization \n             For the best part of a decade, the microarray market has been dominated by gene expression. \u201cBut gene expression is not the most demanding thing you can do with a microarray,\u201d says Emile Nuwaysir, vice-president of business development at NimbleGen of Madison, Wisconsin. Other microarray applications are now coming to the fore \u201cthat even have the potential to eclipse gene expression\u201d, he says. One such area is array-based comparative genomic hybridization (CGH), which can provide a robust and accurate platform for routinely mapping chromosomal imbalances at exon-level resolution. Several companies now offer microarray-based products and services for identifying and characterizing gains and losses of genomic regions that lead to copy-number changes in genes and regulatory regions. Such changes are thought to underlie diseases such as cancer and many congenital disorders. \u201cTo be able to see in the full complexity of the human genome that small change in signal is very demanding, and commercial arrays weren't capable of doing it five years ago,\u201d says Nuwaysir. Unlike some array-based CGH products that use a gene-centric design, NimbleGen's human whole-genome array CGH platform is a single array with 385,000 probes tiled throughout the human genome every 6,000 bp. The company's customized fine-tiling CGH arrays contain the same number of probes as the whole-genome CGH array but tiled at higher resolution in chromosomal regions selected by the researcher. Here the probes can be spaced as densely as every 10 bp. \u201cWe're the only company that combines the benefits of high-density, long oligo arrays and the ability to change the design whenever you want,\u201d says Nuwaysir. NimbleGen also hopes that an isothermal probe-selection strategy will set it apart from the competition. Rather than fix the oligo length, as most companies do, NimbleGen fixes their melting temperatures at 76 \u00b0C across the entire set. As such, says Nuwaysir, the probes are optimized to perform equivalently in all genomic regions, including AT- and GC-rich regions. Agilent introduced an updated version of its microarray-based CGH platform in August. The company already offers a microarray for the genome-wide scanning of chromosomal gains and losses on a single chip. Now, researchers will be able to tap into Agilent's database of approximately 4 million validated CGH probes and use its web-based DNA microarray design tool, eArray, to create custom CGH microarrays for high-resolution tiling of regions of interest. The company also recently launched a single-slide CGH micro-array for the genome-wide profiling of DNA copy-number changes in mouse. \n               Location, location, location \n             A second expanding research area now being adapted to a microarray format is chromatin immunoprecipitation (chIP) analysis. Also referred to as \u2018location analysis\u2019, chIP followed by microarray analysis of the immunoprecipitated genomic DNA, the so-called chIP\u2013chip methodology, can be used to identify the binding sites on chromosomes for DNA-binding proteins such as histones, polymerases and transcription factors, as well as studying DNA modification and chromatin-remodelling. NimbleGen offers a microarray service for chIP\u2013chip analysis. Researchers can either select from off-the-shelf array designs, which include a whole-genome survey set with 390,000 features per array and two array designs aimed at known promoter regions, or can create their own customized tiling chIP\u2013chip arrays tailored to particular genomic regions. NimbleGen is also pushing the idea of array re-use, and currently guarantees three-time use of its chIP\u2013chip products. \u201cOur goal is to have a platform that is ten times re-usable in the next cycle,\u201d says Nuwaysir. Agilent has also thrown its hat into this particular ring and launched its own chIP\u2013chip platform last month for analysing activity at regulatory genomic regions. In the future it expects to offer a variety of custom and catalogue ChIP\u2013chip products, as the company acquired Computational Biology of Cambridge, Massachusetts, in January. This firm was founded by Richard Young of the Whitehead Institute at the Massachusetts Institute of Technology in Boston and has key intellectual property in this area. In a recent publication in  Cell , Young's group used a chIP\u2013chip approach to produce high-resolution genome-wide maps of acetylation and methylation in yeast. \n               Splice-variant analysis \n             Microarray analysis may have produced a mountain of gene-expression data but the contribution of alternative splicing has largely been overlooked until now. The market for splice arrays is now heating up, and companies such as ExonHit of Paris, France, and Jivan Biologics of Berkeley, California, are focused entirely in this area. Most human genes are thought to undergo alternative splicing, the process by which individual genes can produce multiple messenger RNA and protein products. These so-called splice isoforms can have different, and even opposing, functions in the cell. With the recent commercial availability of splice-variant arrays, traditional gene-by-gene studies of alternative splicing are now taking a back seat to genome-wide methods. Further study in this area should provide a better \u2014 and more complete \u2014 understanding of the functional relevance of splice variants and of disease mechanisms. ExonHit offers its SpliceArrays on a service basis, but from this September they can also be purchased directly from Agilent. Validation of the ExonHit approach, which involves the use of both exon- and junction-derived probes to follow every splice event associated with a given gene, was featured in a recent publication in  Nucleic Acids Research . The company offers both custom and catalogue SpliceArrays focused on specific gene families that are of particular therapeutic interest \u2014 cytokine and apoptosis pathways, nuclear receptors and co-regulators, G-protein-coupled receptors (GPCRs) and ion channels. \u201cWe are also in the process of expanding our line into mouse,\u201d says Laurent Bracco, ExonHit's vice-president of research and technology development, with products expected around the turn of the year. Jivan has been working in this area for the past four years and offers its suite of TransExpress splice-variant microarrays, which are manufactured by Agilent. The company's products include a genome-wide splice-variant array and a suite of arrays focused on gene families such as cytochrome P450, GPCRs, ion channels, kinases, phosphatases, phospho-diesterases, proteases and proteinases. Unlike ExonHit, Jivan's splice arrays do not include exon probes. \u201cExon probes are neither necessary nor sufficient to measure RNA splicing and so we do not include them in our TransExpress product line. Using junction probes, however, all splicing events can be detected,\u201d says Jonathan Bingham, Jivan's chief technology officer. The company also makes arrays to user specifications, and now offers a splice-variant microarray service through MOgene of St Louis, Missouri. \u201cThe next product will be an oncology array consisting of about 2,000 genes implicated in cancer along with their splice variants,\u201d says Bingham. At the high-density end of the market, earlier this month Affymetrix rolled out its exon-only array with a million exons on a single chip. This Human Exon 1.0 ST (sense target) array offers whole-genome, exon-level expression profiling on a single array and includes all annotated exons, as well as computationally predicted and empirically identified exon content. As such, the company says, researchers will be able to study known splicing events, as well as discover novel splice variants. GeneChip mouse and rat exon arrays are planned for later this year. Microarrays are now a widely used technology for studying gene expression and regulation on a global scale and at high-throughput. Other applications for this technology include single-nucleotide polymorphism discovery and validation (see  Nature ,  422 , 917\u2013922; 200310.1038/422917a ) and comparative genome sequencing. The use of microarrays is also moving downstream as the first microarray-based diagnostic tests begin to trickle into the marketplace (see \u2018Microarrays move downstream\u2019,  page 1196 ). The future indeed looks bright. Has it really been only ten years? Reprints and Permissions"},
{"file_id": "4371199a", "url": "https://www.nature.com/articles/4371199a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Reprints and Permissions"},
{"file_id": "437780a", "url": "https://www.nature.com/articles/437780a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Reprints and Permissions"},
{"file_id": "435236a", "url": "https://www.nature.com/articles/435236a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "When target amplification is not needed, northern blotting and other methods based on nucleic acid hybridization are convenient for detecting and measuring specific RNAs. Such methods include the Quantikine range for measuring specific cytokine mRNAs from R&D Systems of Minneapolis, Minnesota. The problem with direct hybridization is generating a strong signal from a few target molecules. Chad Mirkin, director of the Northwestern University Institute for Nanotechnology, at Evanston, Illinois, thinks he has cracked the problem. He is co-founder of Nanosphere in Northbrook, Illinois, which produces BioBarcode, a sensitive detection system that can detect DNA sequences, but is proving to be just as good at spotting specific proteins. \u201cPCR is amazing because it takes what you are trying to detect and duplicates a portion of it so that you have enough to detect. If you could do that for proteins, I would argue that you could have as big or a bigger impact, especially if you could do it without needing to use enzymes,\u201d he says. Mirkin hopes to make that impact with BioBarcode, which works as a two-component immunological sandwich assay with some novel twists. Antibody molecules specific for one site on the target protein are tagged with 13-nm diameter gold nanoparticles, while larger paramagnetic particles are coated in a second antibody that recognizes a separate site on the target. If present, the target protein will grab both probes, and the complexes can be isolated by magnetic separation. So far, not too unconventional. In Mirkin's system, however, the gold nanoparticle is smothered in hundreds or thousands of identical oligonucleotides, each strand hybridized to a short sequence that acts as a molecular barcode. Nanoparticles with different antibodies carry different barcodes, allowing multiplexing. After separation, the DNA barcodes are released and their identity determined by scanning on a biochip. The initial signal is thus amplified hundreds to thousands of times, allowing as few as 10 molecules of protein to be detected. Randy Lewis at the University of Wyoming is using BioBarcodes to search for prions associated with the elk version of mad cow disease. \u201cBioBarcodes give us an assay that is 1,000 times more sensitive than anything else,\u201d he says. \u201cWe should now be able to detect early onset and environmental contamination at lower levels than could be done before.\u201d \n               P.M. \n             Reprints and Permissions"},
{"file_id": "435995a", "url": "https://www.nature.com/articles/435995a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Reprints and Permissions"},
{"file_id": "435991a", "url": "https://www.nature.com/articles/435991a", "year": 2005, "authors": [{"name": "Caitlin Smith"}], "parsed_as_year": "2006_or_before", "body": "MicroRNAs that tweak gene expression, single nucleotide polymorphisms in population genetics, and individual genome sequencing: Caitlin Smith takes a look at three fast-moving areas in genomics. Over the past few years, genomics researchers have been getting to grips with a \u2018new\u2019 genome element \u2014 microRNA (miRNA). Although a small number of miRNAs have been familiar to developmental biologists for years, a plethora of miRNAs has recently been discovered in animal and plant genomes. More than 200 miRNAs have been identified in mammalian genomes, but their functions mostly remain a mystery. Silencing gene expression in a similar way to small interfering RNAs (see  Nature   431 , 350; 2004), mammalian miRNAs are implicated in the control of cell and tissue differentiation, apoptosis, insulin secretion, fat metabolism and cancer. \u201cWe are now aware that there is substantially more transcription from human chromosomes than can be accounted for by the current predictions of human genes,\u201d says Frank Slack at Yale University, New Haven, Connecticut. Slack is studying the apparent involvement of the miRNA  let-7  in lung cancer and the implications of its ability to suppress translation of the oncogene  RAS . \u201cMany miRNAs are mapping to disease loci where previously a gene was not found,\u201d he says. miRNA research is a typical microcosm of the variety of disciplines and techniques that are required to make sense of the genome \u2014 computational biology, bioinformatics and comparative genomics to predict candidate miRNAs, followed by classic \u2018wet biology\u2019 to validate the candidates and study their expression and function. And as more labs are gearing up to study miRNAs, commercial products tailored to help them are coming onto the market. The technical problems of detecting miRNAs in total cellular RNA stem from their small size and often low abundance. Produced from a larger precursor molecule, mature miRNAs are RNA hairpins of 17\u201323 nucleotides, which bind to complementary sequences in their target messenger RNAs (mRNAs) and prevent translation. The general techniques for detecting and isolating miRNAs from cellular RNA are those used for other small RNAs. A first step could be spin- column fractionation of RNA to remove larger RNAs, using columns such as the Amicon YM-100 from Millipore of Bedford, Massachusetts, which will remove RNAs of more than 75 bases, or the PureLink miRNA isolation kit from Invitrogen of Carlsbad, California, with a 200-nucleotide limit. Qiagen of Valencia, California, has a small RNA protocol for their widely used RNeasy system, which will remove RNAs of more than 200 bases from total cellular RNA. To get even closer to mature miRNA length, RNA specialists Ambion of Austin, Texas, sells a flashPage, a gel-based fractionation machine for the rapid isolation of small nucleic acids of around 40 bases. After initial preparation, specific miRNAs in the sample can be detected by techniques such as northern analysis, PCR and micro-arrays. But how do you know what you're looking for? Much of the groundwork in miRNA identification has been laid by large-scale genomics projects that used computational techniques to predict miRNA genes followed by cloning and validation of the predicted sequence. The public miRNA registry currently holds around 1,650 entries for published predicted miRNAs. The big projects now under way are to determine which genes the miRNAs are targeting (see \u2018Big tasks for small molecules\u2019,  page 991 ). Northern analysis is still the standard for detecting and quantifying miRNA expression. \u201cNorthern blotting, even if time consuming, is by far the best technique to study miRNA expression because of its sensitivity and quantitativity,\u201d says Jiahuai Han at the Scripps Research Institute, La Jolla, California, who is looking at the mechanisms by which miRNAs affect the stability of their target mRNAs. \u201cPrimer extension has the advantage of being quicker but, unfortunately, is less quantitative,\u201d he says. Integrated DNA Technologies (IDT) of Coralville, Iowa, sells miRNA tools to increase the sensitivity of northern analysis. Its StarFire kit for probe labelling makes labels composed of 10  32 P-alpha-dATPs rather than the more usual single  32 P-gamma-ATP. \u201cWe use a special template and reaction conditions that give a 10-base tail with almost no heterogeneity,\u201d explains Mark Behlke, vice president of molecular genetics at IDT, \u201cso all probe molecules are the same \u2014 it is very different from other tailing procedures.\u201d Manufacturers are also gearing up to make miRNA-specific probes; miRCURY LNA (locked nucleic acid) detection probes for all known miRNAs are available from Exiqon of Vedbaek, Denmark, for example, and can be used for  in situ  hybridization, northern analysis, PCR and gene knockdown. Another choice for miRNA detection is Ambion's mirVana miRNA detection kit. Ambion claims that its assay is 100\u2013500 times more sensitive than northern analysis, as the radiolabelled probes are hybridized in solution instead of on a membrane as in northern blotting. The company claims that this method gives the researcher a better shot at detecting and quantifying low-abundance miRNAs because the probe and target have more opportunities to bind when in solution. Taking the PCR road, Applied Biosystems of Foster City, California, is soon to launch a new TaqMan microRNA assay for miRNA detection and quantitation, which the company claims will detect only mature miRNAs and not precursors. According to Marcum Bell, product manager of gene-expression assays at Applied Biosystems, the assay \u201cuses specific stem-looped primers for reverse transcription of the mature miRNA, followed by quantitative real-time PCR.\u201d A claimed advantage of the new assay is its wide dynamic range of up to 7 log units, enabling detection of both low- and high-abundance miRNAs. For an alternative to PCR-based miRNA assays, US Genomics of Woburn, Massachusetts, recently unveiled its Trilogy 2020 Single Molecule Analyzer for the high-throughput detection and quantitation of single molecules of nucleic acid without amplification. The Trilogy 2020 can be used along with the company's Direct miRNA Assays for miRNA work. The assay includes two fluorescently tagged probes (tags can be red, blue or green) that are designed to hybridize to the miRNA of interest. Specificity relies on the very high likelihood that only the target miRNA will hybridize to both probes. After hybridization, the sample is moved by microfluidics through a glass capillary, where lasers excite the probes at different wavelengths. A target miRNA molecule is counted when photons of both colours are emitted simultaneously. Both conventional microarrays and bead-based multiplex assay platforms such as xMAP from Luminex of Austin, Texas, can be used to study miRNA expression, and a number of companies offer miRNA products designed for use with microarray systems. PerkinElmer of Boston, Massachusetts, sells a MICROMAX ASAP labeling kit for miRNAs for detection by the tyramide signal amplification (TSA) method, while the Array 900miRNA labeling kits from Genisphere of Hatfield, Pennsylania, are designed to label miRNAs and other small RNAs with Genisphere's 3DNA dendrimers. If you don't want to do it yourself, companies such as molecular diagnostics specialists Genaco of Huntsville, Alabama, and genetic services company DNAVision of Charleroi, Belgium, offer miRNA expression profiling and quantitation using Luminex xMAP technology. LC Sciences of Houston, Texas and Icoria of Research Triangle Park offer microarray-based miRNA detection covering all miRNAs currently listed in the public miRNA registry. \n               Differences matter \n             If miRNAs are the new kid on the block in genomics, single nucleotide polymorphisms (SNPs) are already big business (see \u2018 Genotyping gets up to speed \u2019). Your DNA is 99.9% identical to that of another unrelated human, but it is that last 0.1% that interests researchers. Much of the difference is made up of SNPs, which are sites in DNA that differ by a single base. Groups of SNPs close to one another on a chromosome are called blocks, and are usually inherited together as a haplotype, thus providing a convenient marker for the other genes in the block. The HapMap project, run by the International HapMap Consortium, aims to create a map of these haplotypes and their SNP tags for future research (see \u2018 SNPs and human disease \u2019). Using SNP tags, scientists can more efficiently scan an individual's genome for association with phenotypes, such as disease susceptibility, or reactions to drugs or vaccines. Launched in October 2002, the HapMap project hoped to complete the mapping of one million SNP markers by September 2005. When it achieved this goal months ahead of schedule, the consortium announced this February that it will step up its efforts in the second phase to create an improved map that is five times denser than the first draft. This will enable geneticists to zero in on smaller areas of the genome, locating targets more precisely by using more SNP signposts, increasing coverage from one SNP every 3,000 bases (at present) to one every 600 bases. Vital to phase 2 is Perlegen Sciences of Mountain View, California, which is testing 4.6 million SNPs from public databases for addition to the HapMap. Last September, funded by a grant from the US National Human Genome Research Institute, Perlegen began using high-density oligonucleotide array technology from Affymetrix of Santa Clara, California, to genotype more than 2.25 million unique SNPs from the four HapMap study populations. Perlegen's original goal was to catalogue 600 million genotypes; the new funding in phase 2 should result in more than a billion. The human genome is thought to contain about 10 million SNPs, but not all of these will be useful predictors of disease. David Cox and his colleagues at Perlegen aim to narrow the field. They have analysed the most common SNPs by mapping 1.5 million SNPs for 71 people from three different ethnic groups: European American, African American and Han Chinese American. The aim is to obtain a high-quality subset of SNPs for disease prediction, and to make these subsets more useful by learning more about the frequencies of alleles and how they are correlated with one another. \n               The $1,000 genome? \n             As Illumina closes in on the million-SNP assay (see \u2018Genotyping gets up to speed\u2019,  page 992 ), others are striving for the $1,000 genome \u2014 a quick and cheap method of sequencing individual genomes. This somewhat arbitrary goal has caught the fancy of scientists and is being competitively pursued by companies \u2014 fuelled in part by a $500,000 cash prize offered by the J. Craig Ventner Science Foundation to whoever gets there first. For this goal to become reality, a new method must replace the much-loved Sanger method and its offspring. The leading alternative is single-molecule-based sequencing, also known as sequencing by synthesis. VisiGen Biotechnologies in Houston, Texas, uses this method with single-pair fluorescence resonance energy transfer (spFRET) as the detection technology. The donor fluorophore is attached to a DNA polymerase that sits on the template, while a colour-coded acceptor fluorophore is attached to the gamma-phosphate of a nucleoside triphosphate. When the nucleotide is incorporated into DNA, the donor fluorophore stimulates the acceptor to emit a characteristic fluorescent signal (measured as emission wavelength and intensity) that indicates its base identity \u2014 each base is a different colour. \u201cThe donor fluorophore acts as a punctuation mark between nucleotide incorporation events,\u201d explains Susan Hardin, president and chief executive of VisiGen. Massively parallel arrays of these reactions produce a high-throughput sequencing system without the need for electrophoresis, cloning or PCR. Hardin points out that using a donor label on an immobilized polymerase \u201cminimizes background, increases consistency of the signal during the extension, and increases read length.\u201d The advantage of labeling the nucleotide on its terminal gamma phosphate is that the fluorophore does not become part of the nascent DNA strand. The sequencing by synthesis method of Solexa, based in Little Chesterford, UK, (which recently merged with Lynx Therapeutics of Hayward, California) differs from that of VisiGen mainly in the detection method. In the Solexa technology, the different types of fluorescently labelled nucleotide incorporated into the DNA strand are detected by excitation with an external light source. The cycle of nucleotide incorporation, detection and identification is repeated about 25 times to read the first 25 bases in each oligonucleotide in an array of millions of single-stranded genomic DNA fragments. According to Simon Bennett, Solexa's business development director, one advantage of the company's system is the small sample volume required \u2014 only a few picograms. \u201cBiobanks may need to seriously reconsider how to collect and store samples, and may wish to explore cheaper options,\u201d says Bennett. \u201cWith the emerging technologies the cost of analysing samples, and how much sample is needed for each subject, is almost certain to reduce dramatically.\u201d He also remarks that the short sequence read lengths of 25\u201330 nucleotides in Solexa's method may allow a degraded sample to be resequenced, rendering a previously useless sample once again viable. A stab at the $1,000 genome is also being taken by 454 Life Sciences, a subsidiary of Curagen in Branford, Connecticut. The 454 whole-genome sequencing system, a prototype of which was recently installed at the Broad Institute in Cambridge, Massachusetts, uses the patented light-emitting \u2018pyrosequencing\u2019 chemistry developed by Pyrosequencing of Uppsala, Sweden, (now renamed Biotage after its recent takeover of that company) and microfluidics nanotechnology developed by 454. The pyrosequencing technique was exclusively licensed to 454 in 2003 for the purposes of developing it for whole-genome sequencing. Biotage retains the rights to use the technology in its gene-analysis products, such as the PyroMark range of genetic tests launched earlier this year. Last month, Roche Applied Science signed an exclusive licence with 454 to develop and sell the 454 whole-genome sequencer. So when can we expect the first $1,000 genome? \u201c2010 to 2012,\u201d says Hardin. Bennett is less definite, but thinks that Solexa will be offering a $1,000 genome product before 2016, and \u201cprobably before the end of this decade.\u201d \n               Future prospects \n             Looking to what's next on the genomics agenda, Carrington settles for understanding the mechanisms of genome evolution and adaptation, especially the evolution of new functions. He cites the recent discovery of possible \u201cmultigenerational sequence caches to restore lost information from a genome,\u201d in which plants have been shown to inherit DNA sequences not apparently present in parental genomes yet found in previous generations; one explanation might be caches of RNA. \u201cUnderstanding the mechanisms of formation and adaptation of new miRNA genes, and more broadly, the derivation and deployment of small RNA-based regulation at the transcriptional and post- transcriptional levels, represent a major set of questions under the umbrella of genome evolution,\u201d he adds. On the biomedical front, Hardin points out that geneticists will soon be facing serious ethical considerations. \u201cWho should have access to an individual's genome sequence?\u201d she asks. \u201cWhat should one be told about (potential) defects in one's genome sequence? When? How can we best safeguard the privacy of genome-sequence information?\u201d Given the rapid advance of genomics, scientists will be having to answer these questions sooner than they might have thought. \n                     miRNA Registry \n                   \n                     International HapMap Consortium \n                   Reprints and Permissions"},
{"file_id": "435235b", "url": "https://www.nature.com/articles/435235b", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Isolated from the heat-loving bacterium  Thermus aquaticus , Taq DNA polymerase launched PCR. It was great, and versions of the original recombinant Taq are still widely used \u2014 but its error rate of between 1 in 10,000 and 1 in 50,000 base pairs (bp) is too high for some applications, such as the detection of single-nucleotide mutations. You can now take your pick from a plethora of Taq-based polymerases engineered to have higher fidelity and to go faster. And if damaged DNA is the problem, Restorase from Sigma-Aldrich of St Louis, Missouri, is a mixture of Sigma's AccuTaq blend and a repair enzyme, and works with fragment lengths from 200 to 20,000 bp. Developers have also gone back to the planet's hot springs and hydrothermal vents to find a new generation of thermostable polymerases with the 3\u2032\u20135\u2032 exonuclease proofreading capacity that makes for higher accuracy. The archaeal genus  Pyrococcus  has been mined for high-fidelity DNA polymerases with accuracies some 40 to 50 times greater than Taq.  P. abyssi  is the source of the Isis proofreading DNA polymerase from Qbiogene of Irvine, California, with an error rate of one mismatched base per 1.5 million bases per duplication. Other hot offerings come from Stratagene, of La Jolla, California, which claims an error rate of 1 in around 660,000 for its  Pfu  DNA polymerase from  P. furiosus , while Bio-Rad of Hercules, California, has the highly processive iProof High-Fidelity DNA polymerase, a  Pyrococcus -type polymerase fused to a double-stranded DNA-binding protein to give additional grip, which the company claims is 50 times more accurate than Taq. As well as a DNA polymerase isolated from  P. woesi , Roche Applied Science of Indianapolis, Indiana, offers a thermostable reverse transcriptase from  Carboxydothermus hydrogenoformans  for RT-PCR, and Toyobo Company of Osaka, Japan, supplies a very fast DNA polymerase from  P. kodakaraensis  (now renamed  Thermococcus ). Proofreading enzymes are generally more finicky than Taq or enzyme blends. To address this problem, Invitrogen's AccuPrime  Pfx  DNA polymerase is a  P. kodakaraensis  polymerase in a mix containing the company's proprietary AccuPrime accessory proteins (also available as a mix with the company's Taq polymerase), which improve specificity by ensuring that primers only bind to their complementary sequence. The QuantiTect Multiplex PCR kits from Qiagen, of Hilden, Germany, also aim to provide trouble-free multiplex PCR by including a novel reaction chemistry in the buffer that helps avoid competition between PCR products and ensures efficient primer hybridization. \n               P.M. \n             Reprints and Permissions"},
{"file_id": "435238a", "url": "https://www.nature.com/articles/435238a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "The conventional wisdom on probe-based real-time PCR assays says that if you have 10,000 genes to detect you will need 10,000 different probes to detect the PCR products. And to provide the required specificity, the probes need to be at least 18 nucleotides long. A team of researchers and bioinformaticians at Exiqon in Vedbaek, Denmark, is challenging this dogma. By scanning the genomes of key species they have come up with a set of 90 locked nucleic acid (LNA) 8- and 9-mer probes that they claim can be used to identify every gene on which you will ever work. Because of the greater rigidity of LNAs, even a single mismatch with the potential target will seriously affect binding and prevent generation of signal, thus giving the same specificity as a longer regular oligonucleotide probe. The probes come to life when used with Exiqon's software, which for each target gene designs an optimum primer pair in combination with a specific probe. \u201cThe short LNA probes enable the technology, but the software is the key,\u201d says Exiqon's new technology-development manager, Peter Mouritzen. To identify the most specific combination, the software performs what Exiqon calls  in silico  PCR. This checks primer\u2013probe predictions against the entire genome and transcriptome of the organism, minimizing the risk of possible mispriming which could produce a false-positive signal from a real-time PCR assay. For RT-PCR you want to look at the transcribed sequence and not the genomic DNA, which could contaminate the sample, so the software increases specificity by choosing a section where the primers span an exon\u2013exon splice junction. While the primer could hit the genomic DNA, it will not generate a signal, because the intron is likely to make the product so long that it will not be amplified efficiently. Users buy the LNA probes from Exiqon but can get their primers from any supplier. The assay design software is free online. \u201cNormally people spend hours designing a PCR assay, and this thing does it in seconds,\u201d comments Mouritzen. Roy Bicknell at the Weatherall Institute of Molecular Medicine at the University of Oxford, UK, agrees. \u201cWe look for new genes expressed on tumour vasculature as anticancer targets, so when we identify them by bioinformatics we have to do a lot of validation. Because we are looking at many genes we need to keep making new primers \u2014 and that is the beauty of the Exiqon system \u2014 it's for people who want to look at lots of different genes,\u201d he says. \n               P.M. \n             Reprints and Permissions"},
{"file_id": "435237a", "url": "https://www.nature.com/articles/435237a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Rather than amplifying just the DNA between two primers, many researchers want to amplify entire genomes, to make archive copies of the total DNA from a unique biopsy sample, for example. \u201cIf you have a piece of paper with valuable information on it, obviously you don't want to lose the paper, but instead photocopy it many times, store some copies appropriately and use others,\u201d says Andy Betera vice-president of product management of GE Healthcare, based in Little Chalfont, UK. Whole-genome amplification (WGA) systems aim to act as photocopiers for DNA. \u201cFrom the point of view of the molecular epidemiologist or molecular geneticist, the overwhelming potential advantage of the newer methods of WGA is the possibility of producing additional genomic DNA, or amplified WGA DNA, for genotyping, sequencing or other types of genetic analysis like loss of heterozygosity (LOH),\u201d says Andrew Bergen, staff scientist at the National Cancer Institute in Bethesda, Maryland. \u201cFor the past 12 years there have been PCR-based methods of WGA with about a 10 or 15% locus bias, meaning that 10 or 15% of the genetic loci in the genome would not be amplified,\u201d explains Bergen. Newer methods can avoid this loss in the right conditions. But problems really arise when you have only a very small sample from a slide or biopsy to play with. Bergen says colleagues who have almost exhausted the material from a particular sample ask him: \u201cCan this sample be rescued?\u201d And no WGA method is really effective with less than 10 ng of genomic DNA, he says. On the commercial front, GE Healthcare's GenomiPhi DNA amplification kit uses the highly processive single-strand displacing DNA polymerase from phage phi29. Short primers are bound randomly throughout the genome and the enzyme copies the DNA, starting from each primer and displacing the primer ahead of it. The result is a soup of genomic fragments of varying lengths, averaging around 10,000 bases. The phi29 method is able to efficiently amplify a whole genome with no loss of sequence if high molecular weight DNA is used as the starting material. The GenomePlex WGA kit from Sigma-Aldrich uses technology licensed from Rubicon Genomics of Ann Arbor, Michigan. In this method, the genomic DNA is initially broken up into fragments of around 400 bases long, which are then attached to an identical sequence. The collection is amplified by PCR using a primer that recognizes this sequence. Because short fragments are being copied, this method can cope with starting DNA of high or low molecular weight. \n               P.M. \n             Reprints and Permissions"},
{"file_id": "4371195b", "url": "https://www.nature.com/articles/4371195b", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "MicroRNAs (miRNAs) represent a new market opportunity for microarray companies (see  Nature   435 , 991\u2013996; 200510.1038/435991a ). \u201cMicroRNA is as hot as it could possibly be right now,\u201d says Scott Cole, head of genomics marketing at Agilent Technologies of Palo Alto, California, which expects to launch specific miRNA array-based products in 2006. Exiqon of Vedbaek, Denmark, is now focused on developing miRNA detection products based on its locked nucleic acid (LNA) technology. \u201cAn LNA oligo will bind tighter to a DNA than a DNA itself will, and even more so to an RNA,\u201d says Mikkel N\u00f8rholm, senior research scientist at Exiqon. \u201cBecause the affinity is higher you can use a shorter probe,\u201d he says. The company offers ready-to-spot oligonucleotide capture probes based on the latest information from the miRBASE sequence database ( http://microrna.sanger.ac.uk ). A pre-spotted array for microRNA detection in human and mouse will be available soon. Last month, Ambion of Austin, Texas, inked a deal with Rosetta Genomics of Rehovot, Israel, to access Rosetta's proprietary miRNA sequence database, which will add to its current range of microarrays targeting human, mouse and rat miRNAs from miRBASE. Ambion's mirVana miRNA Bioarrays are manufactured by GE Healthcare on its CodeLink platform, which uses a three-dimensional (3D) gel matrix to lift the probes off the slide surface. This is designed to maximize interaction between probe and target and enable the detection of low-abundance miRNAs. miRNA arrays from LC Sciences of Houston, Texas, are currently available on a service basis. The addressable microfluidics chip contains almost 4,000 picolitre-volume 3D chambers and stems from work at the University of Houston and the University of Michigan. At the heart of the system is the \u00b5 Paraflo microfluidic technology, which enables fast  in situ  parallel synthesis of large numbers of different oligos at high yield. In addition to probes based on sequences in miRBASE, researchers can add up to 100 custom sequences at no extra charge. miRNA arrays and services are also available from GenoSensor of Tempe, Arizona, and Paradigm Array Labs of Research Triangle Park, North Carolina, a service unit of Icoria. Kreatech Biotechnology of Amsterdam, The Netherlands, plans to extend its Universal Linkage System (ULS) direct labelling technology to miRNA research by offering a labelling kit optimized for small RNAs. According to Brent Keller, Kreatech's vice-president of commercial applications, ULS provides a fast and simple alternative to enzymatic labelling methods, which can be subject to 3\u2032-end bias. \u201cOur chemistry is independent of fragment length,\u201d says Keller, \u201cmaking it ideal for miRNA applications.\u201d \n               D.G. \n             Reprints and Permissions"},
{"file_id": "434796a", "url": "https://www.nature.com/articles/434796a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Magnetic beads have been used for protein separation since the 1980s, but the technology is now being adapted for new proteomic applications and use with automated platforms. The market leader in paramagnetic beads is Dynal Biotech based in Oslo, Norway, and recently acquired by life-sciences giant Invitrogen in Carlsbad, California. Dynal has just signed a co-marketing agreement for its Dynabead kits and Tecan's Freedom EVO automated platform, and has developed protocols for other platforms such as Beckman Coulter's Biomek FX and the KingFisher magnetic separation platform from Thermo Electron of Waltham, Massachusetts. \u201cThe main purpose of having magnetic beads is that you can automate the whole process,\u201d says Lars Korsnes, director of research and development at Dynal. \u201cThe bead technology has some advantages compared with standard chromatography systems \u2014 while it's not so easy to put a whole-blood sample into a chromatography column, with magnetic beads you can put the whole sample in.\u201d Dynabeads, like those from some other suppliers, are superparamagnetic, with no residual magnetism outside an applied magnetic field. They are also uniform in size, shape and surface properties. This all helps to prevent the beads clogging up an automated device, Korsnes notes. Bead technology is also more scaleable than chromatography columns, although Dynal is concentrating on more analytical or small-scale protein isolation and protein fractionation for different applications in proteomics. The firm is currently launching a new range of beads with functionalities such as ion-exchange groups, reverse-phase chromatography and hydrophobic chemistries. New owner Invitrogen plans to apply Dynal's surface technologies to a wider range of products. The beads are also showing promise in the challenging separation of membrane proteins. \u201cThere have been some publications where one can bind membrane proteins either before or after lysing the cells,\u201d Korsnes says. \u201cWhether we will develop a special protocol is a question for the future, but the technology is there already.\u201d \n               Tim Chapman \n             Reprints and Permissions"},
{"file_id": "435239a", "url": "https://www.nature.com/articles/435239a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Reprints and Permissions"},
{"file_id": "434795a", "url": "https://www.nature.com/articles/434795a", "year": 2005, "authors": [{"name": "Tim Chapman"}], "parsed_as_year": "2006_or_before", "body": "Protein purification is stepping into the limelight, as proteomics researchers demand faster ways to purify more proteins. Tim Chapman looks at what is around to help them. Protein isolation is one of the oldest \u2018biotechnologies\u2019, but the demands from proteomics for the purification of potentially vast numbers of proteins is driving new developments in long-established techniques. \u201cResearchers working in genomics are looking for the next step to fully understand the results of their sequence analysis \u2014 the proteins that the genome expresses \u2014 in the context of systems biology,\u201d says Anke Cassing, associate director for corporate strategy at Qiagen in Hilden, Germany. \u201cThe delicate interplay of proteins is, of course, also of extreme interest to pharmaceutical companies, which are always on the lookout for new drug targets.\u201d There is increasing demand from researchers producing biopharmaceuticals \u2014 antibodies and proteins used as drugs. \u201cThere's a driving force towards protein purification, separation and analysis,\u201d says Carsten Buhlmann, product manager at Agilent, based in Palo Alto, California. \u201cEspecially for the biopharmaceuticals, there's a high demand for purity of these proteins that are used for drugs and have to get through all the regulations.\u201d For virtually all applications, researchers need to maintain a protein's biological activity, which can rule out some purification processes. Proteins can be fragile and easily denatured, and many of the most important are insoluble in the most common media. \u201cIf you look at the average protein, it's quite complex, it's a buzzing, vibrating molecule \u2014 it's not a fixed structure,\u201d says Allan Simpson, vice-president for product development at the protein separations division of GE Healthcare Biosciences in Uppsala, Sweden. \u201cThey're very hard to handle, they're difficult to purify, they can aggregate easily \u2014 these are very hard things to manipulate.\u201d \n               Proteomics workhorse \n             With proteins taking centre stage in many laboratories, equipment developers are rolling out a new generation of automated systems to take the grind out of separating and purifying proteins of interest. Chromatographic separation is one of the basic protein-purification techniques and one platform that is emerging as a workhorse of the large proteomics lab is \u00c4KTAxpress. Made by GE Healthcare, this is a dedicated high-throughput multistep chromatography system for purifying histidine (His)- and glutathione- S -transferase (GST)-tagged recombinant proteins. GE began developing the platform in the late 1990s after realizing that there were not enough trained chromatographers to produce proteins in the quantities and varieties demanded by post-genomic researchers. \u201cWe decided to see if we could automate a system that would be better than the current technologies at solving that problem,\u201d Simpson says. \u201cInstead of taking a robot and automating the current system, we set out to develop a new one. A robot represents nothing more than a mechanical technician \u2014 it reproduces all the successes but also all the errors, so you don't move forward in your science.\u201d The company produced a high-throughput system that needs no specialized knowledge to operate and can be programmed to carry out up to four common purification steps starting with affinity purification. \u201cThe skill of chromatography is sitting within the system,\u201d says Simpson. The software is written as a series of wizards, each representing a single step. GE will shortly be launching a software package for the purification of monoclonal antibodies. The basic four-module set-up can purify up to 2,500 proteins a year, each module producing up to 50 mg of protein per run. A twin-pack version is aimed at smaller labs wanting to purify up to 1,000 proteins a year. The new protein-purification facility at Monash University in Melbourne, Australia, is deploying a 12-module \u00c4KTAxpress set-up for its ambitious development programme. \u201cI'm a structural biologist, so my interest is in producing large amounts of recombinant protein for structural and functional studies,\u201d says James Whisstock, scientific director of the facility. \u201cWhat's really important is that the cost of equipment is within reach of a normal university laboratory set-up. There are some very big structural biology institutes with between US$50 million and $100 million's worth of industrial-scale protein preparation equipment. From our point of view that's not achievable, but we're bringing in this technology, which is going to make a huge difference to our research.\u201d The ability to deal with many more proteins simultaneously will allow the lab to approach problems differently. \u201cIf you have a very challenging protein target and want to try 50 different constructs, at the moment it's really not feasible to do that manually one after the other,\u201d Whisstock points out. \u201cNow, you can try the same molecule from 50 different species. With parallel advances in expression technology, the whole process is simplified and really streamlined, and provides the capacity to perform that experiment. You're trying so many different things simultaneously, you're likely to get a result.\u201d \n               Automating innovation \n             Several companies are developing equipment and product ranges that can be used at different points in the proteomics pipeline, from raw cell extracts to mass spectrometry and beyond. Beckman Coulter in Fullerton, California, is rolling out its ProteomeLab family to help with everything from initial purification of cell extracts, through protein fractionation and characterization, to the ultimate steps of disease diagnosis. \u201cWe try to link technologies together to simplify the job for what takes place at the end, which is typically mass spectrometry,\u201d says John Hobbs, group product manager for ProteomeLab. \u201cTo get to that point, a lot of people have realized that it's garbage in, garbage out. If you put crap into a mass spectrometer, the results you get out will be the same.\u201d The ProteomeLab PF 2D Protein Fractionation System automates two-dimensional chromatographic fractionation, resolving proteins by isoelectric point and hydrophobicity. The emphasis is on standardizing the protocols and techniques used by researchers. \u201cBiologists want to be able to look at their results and see if they relate to someone else's,\u201d Hobbs notes. \u201cAs well as providing the instrument, we provide the methodology and buffers, but we do specify you have to use that method to get the full support. It's a little bit different from the normal research instrument approach, but we thought there was a need for that and it seems to be accepted.\u201d Beckman is also currently commercializing an innovative system of protein partitioning using affinity fractionation to decrease the unwanted complexity of protein mixtures before analysis. The aim is to remove not just very abundant proteins, for example serum albumin from blood plasma, but also other proteins that are already well characterized. The firm claims that up to 95% of the proteins in a cell lysate can be removed before the full fractionation stage with less risk than other purification procedures of losing the proteins you're interested in. \u201cThere's a growing interest in what might be going away with these large-abundance proteins \u2014 albumin is a binding protein, and possibly some interesting proteins go with it,\u201d Hobbs notes. Several big equipment producers have teamed up with smaller specialist firms to include cutting-edge reagents or media in application kits for their automated systems. Tecan in M\u00e4nnedorf, Switzerland, recently signed a licensing agreement to deploy the paramagnetic beads developed by Dynal Biotech in Oslo, Norway, on its Freedom EVO liquid-handling platform (see \u2018Attracting attention\u2019,  page 796 ). The Robopop protein purification kits from Novagen in Madison, Wisconsin, can also be used on Tecan's workstation and on the MultiPROBE liquid-handling workstation from PerkinElmer in Boston, Massachusetts. Caliper Life Sciences in Hopkinton, Massachusetts, has integrated into its Sciclone ALH3000 liquid-handling workstation a new column technology developed by PhyNexus based in San Jose, California (see \u2018Small-scale separation\u2019,  page 795 ). The combination allows researchers to purify and enrich small quantities of up to 96 engineered proteins in as little as 15 minutes. The market for protein purification systems has changed in the past six months, notes Mark Roskey, vice-president of marketing at Caliper, with more groups getting involved in larger-scale protein purification. \u201cIt's not at the industrial scale, but regular pharma and biotech R&D people are now trying to purify proteins in a more parallel situation. A lot of this stems from having all the genes and working with huge numbers of them to develop new drugs,\u201d he says. \n               Analysis and optimization \n             To maintain the benefits of high-throughput separation and purification, the proteins of interest must be able to pass smoothly into the next stage of the process. \u201cOnce you've got a relatively pure protein you need to determine whether it is pure, so there's issues with analysis as well,\u201d says Roskey. A common analysis method is SDS-polyacrylamide gel electrophoresis \u201cbut we feel that that is a bottleneck\u201d, Roskey adds. Although the established protocols of macroscale gel electrophoresis are being successfully automated (see \u2018Automation in two dimensions\u2019, below), many users are turning instead to microfluidic and lab-on-a-chip solutions. In January, Caliper launched the Protein Express Assay for its LabChip 90 automated electrophoresis system. \u201cIt's a microfluidic replacement for SDS-PAGE that automates the whole process,\u201d Roskey says. \u201cRather than putting samples on a gel, you get them off a multiwell plate, and it does integrated separation, detection and analysis. It can do an individual protein in around 30 seconds, so you can do 96 proteins in an hour with the same quality as SDS \u2014 in fact better, because the data are digital.\u201d Automated electrophoresis using chips developed with Caliper is the basis of two new systems \u2014 the bench-top Experion from Bio-Rad in Hercules, California, which analyses a single Pro260 chip carrying a maximum of 10 samples in 30 minutes for the medium-scale user, and the ultra-high-throughput 5100 Automated Lab-on-a-Chip system from Agilent in Palo Alto, California. The latter is aimed at pharmaceutical companies and other laboratories needing to separate, purify and analyse thousands of proteins a day. The fully automated 5100ALP using the Protein 200 Plus LabChip kit can take up to twelve 96- or 384-well plates for overnight analysis, with each chip capable of up to 6,000 sample runs. \u201cThe real innovation with the 5100 is that you have a complete unattended solution ending up with digital data,\u201d says Carsten Buhlmann, product manager for Agilent's microfluidics group. The 5100ALP has been deployed at the centralized protein-production facility for AstraZeneca in Alderley Park, UK. \u201cWe're developing a high-throughput protein-production platform and wanted a quantitative and qualitative data-analysis method for that process,\u201d says Paul Hawtin, senior research chemist at AstraZeneca's UK protein group. \u201cPreviously we used SDS-PAGE gels and although they get you the information you need, they're very cumbersome, especially when you're using the numbers that we're using.\u201d With high-throughput protein production, an integrated analysis capability is invaluable. \u201cWe were in the situation where we could do high-throughput molecular biology, high-throughput expression and also high-throughput production \u2014 once you've gone through that process and you're testing a number of variables, the numbers you've got coming out the back end are incredibly large,\u201d Hawtin notes. The AstraZeneca team also uses the \u00c4KTAxpress to follow up with larger-scale protein production. \n               Kits and columns \n             Researchers who don't need automation can choose from an increasing selection of specialized purification and fractionation kits. Kits for affinity purification of recombinant proteins tagged with His 6 , GST, streptactin-binding Strep-tag, streptavidin-binding peptide and other tags abound, and many incorporate magnetic bead technology. On the protein fractionation and preparation front, in January Qiagen launched a new line of protein fractionation kits under the Qproteome brand. The range features kits, including reagents, buffers and columns, for such common tasks as phosphoprotein purification, glycoprotein fractionation and albumin depletion. \u201cThe simplicity of the kits and procedures offers a gentle introduction to the world of protein science for molecular biologists who might be wary of having to learn new techniques or understand complex technologies,\u201d says Cassing. Many protein purification kits based on filtration are available in spin-column format, allowing faster processing. Vivascience, a subsidiary of Sartorius, based in Hanover, Germany, has developed a range of specialized spin-column purification kits, based on the firm's membrane matrix of stabilized regenerated cellulose. Because of the porous structure, the surface available for contact and binding is about 100 times that of the same volume of traditional bead-based resins, allowing parallel separation of proteins with high yields in less than 20 minutes. The new ProteoSpin line of spin column kits for protein clean up from Norgen Biotek in St Catharines, Ontario, is based on a patent-pending technology using modified silicon carbide (SiC) as the matrix rather than the usual silica (SiO 2 ). SiC has all the benefits of silica resin and more, says Yousef Haj-Ahmad, president and chief executive of Norgen Biotek. The hydrophobic and hydrophilic surfaces of SiC can be exploited directly rather than having to chemically add active sites, as with a silica matrix. \u201cThe lack of porosity is an advantage because it enables the purification of a wide size range of proteins,\u201d Haj-Ahmad notes. \u201cWith silica-based resins, even if they are ion-exchange type, one finds size restrictions for proteins because of the micropores.\u201d Also, the unique way that SiC's surface charges allow it to function as an ion exchanger means that salts are not needed to elute proteins in most cases. The first ProteoSpin kits are focused on protein preparation for downstream applications such as mass spectrometry. \n               The next challenge \n             Many of the large equipment providers are now concentrating on streamlining and speeding up the overall protein-processing workflow, from improving initial sample clarification through to a smoother transition to mass spectrometry, microarray technology or X-ray crystallography. Informatics at the back end also remains a challenge, in terms of analysing the results of large-scale analysis and feeding them back into the production process. More sophisticated successors to the His 6  and GST tags commonly used in protein purification are also being sought. \u201cMost people are still using the classic protein purification tags that have been around for many years,\u201d says Roskey. \u201cThere probably need to be some new advances in that area, better ways to grab hold of proteins as you express them. That's something that a lot of people are working on.\u201d But perhaps the biggest challenge is in applying the skills learned with soluble proteins to membrane proteins. \u201cThere's not a soluble protein that we can't purify for you,\u201d says Simpson. \u201cBut once you get to membrane proteins, which are particularly interesting for the pharma industry, they're a nightmare. They're probably key receptors for most drugs but they're designed to be insoluble in physiological structures. How to address membrane proteins is one of the critical bottlenecks. Everyone's putting so much effort into it that it will be solved, and whoever solves it will really hit the pot of gold because it will change the face of our industry and the way medicines are designed.\u201d Reprints and Permissions"},
{"file_id": "434795b", "url": "https://www.nature.com/articles/434795b", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Sometimes you can do more with less. Proprietary pipette tips developed by PhyNexus in San Jose, California, promise high performance in tiny volumes with minimum fuss. The key lies in encapsulating very small quantities \u2014 just 5\u201310 microlitres \u2014 of protein separation resin between hydrophilic screens in the very end of the pipette tip. \u201cThe whole sample is obliged to make highly intimate contact with that resin,\u201d says Chris Hanna, vice-president of business development. \u201cThat results in high trapping efficiency for the sample. We can get a 10\u201320-fold increase in the target protein sample from just a few hundred microlitres of sample, and get purities that are often over 95% with a single separation step.\u201d As well as the technical collaboration with Caliper of Hopkinton, Massachusetts, PhyNexus has designed its PhyTips to be compatible with liquid-handling robots from Tecan of M\u00e4nnedorf, Switzerland, Beckman Coulter of Fullerton, California, and PerkinElmer of Boston, Massachusetts. The firm has also agreed licences to use some of the most advanced resins in its tips, including Qiagen's Ni-NTA resin for purifying histidine-tagged proteins. The combination of tips, resins and platforms makes for exquisite control of the separation process, Hanna says. \u201cYou can control the number of cycles that go back and forth through the bed, the rate they do so, the composition of the washes. We can really make that microvolume of material dance and perform at its best,\u201d he says. \u201cTo be able to do that and maintain fully functional proteins at these very small scales gives you \u00c4KTA-type purification off a very small amount of starting sample. People can avoid scaling up.\u201d The tips are initially being deployed for rapid purification and enrichment of antibodies from small cultures of  Escherichia coli  for use in high-throughput cell-based assays, giving significant savings in time and money. \u201cPeople are wanting to get real biological information much earlier in their screening process, and to do that they have to have the stuff properly prepped,\u201d notes Hanna. Interest is also coming from protein engineering and biopharmaceutical companies looking to miniaturize their protein-expression systems. \n               Tim Chapman \n             Reprints and Permissions"},
{"file_id": "435235a", "url": "https://www.nature.com/articles/435235a", "year": 2005, "authors": [{"name": "Pete Moore"}], "parsed_as_year": "2006_or_before", "body": "PCR often gets taken for granted, but there are ways of making it faster, more accurate and easier to perform. Pete Moore investigates. As a means of rapidly copying a selected template sequence from a DNA mixture  in vitro , PCR by itself and in combination with other techniques has found a vast range of applications. These range from sequence detection and isolation for research, forensics and species identification to detecting mutations and polymorphisms and amplifying RNA-derived cDNAs for microarray analysis of gene expression. As well as standard PCR, the technique now comes in the form of real-time quantitative PCR (real-time PCR or qPCR). This uses fluorescent probes to monitor the amount of product at the end of each cycle, and real-time PCR machines look for the cycle at which they can first detect fluorescence. This relates to the number of copies of original template \u2014 the greater the number of starting copies, the fewer cycles are needed to reach fluorescence detection. PCR can also be used to monitor RNA by adding a reverse transcriptase enzyme at the beginning to generate a DNA template. This reverse transcription PCR (RT-PCR) can then be taken a step further by adding the quantification protocols, resulting in real time RT-PCR. There can be few life-science laboratories without a PCR thermal cycler tucked in a corner, happily churning out short DNA sequences to order with tried and tested protocols. But newer applications for PCR, such as single-nucleotide polymorphism (SNP) detection and screening, need faster throughput, and this is now achievable. One approach is to abandon the traditional 96-well plate in favour of 384 wells or more. The new high-throughput 7900HT fast real-time PCR system from Applied Biosystems in Foster City, California, takes 96- and 384-well plates and runs a full set of amplification cycles in about 35 minutes. \u201cOur new high-speed system can alleviate some of the burden of instrument sharing by reducing cycling time,\u201d says Peter Dansky, senior director and general manager of core PCR at Applied Biosystems. If you need more than 384 wells, more manufacturers are now making 1,536-well plates, including Corning, of Corning, New York, evotec technologies of Hamburg, Germany, and KBiosciences of Hoddesdon, UK. The problem with the larger plates is getting robotic support, but Victor Crew, sales manager at KBiosciences, says that it is possible to modify automated pipettors like the Plate-Mate from Matrix Technologies in Beverly, Massachusetts, to use them. The Equator HTS and Latitude pipetting systems from Deerac Fluidics in Dublin, Ireland, will also take 1,536-well plates and will fill one in less than 15 seconds. Throughput can also be increased by multiplexing \u2014 running more than one specific amplification reaction in a single tube. One approach is to use different colours of fluorigenic dyes to detect the different products. The new Mx3005P real-time PCR system from Stratagene of La Jolla, California, allows five different fluorigenic dyes to be used simultaneously. Using the company's FullVelocity probe-based real-time reagents, the machine will complete a 40-cycle two-step real-time PCR reaction in about 50 minutes. Cepheid of Sunnyville, California, make a real-time thermal cycler with four-colour optics and 96 independently programmable reaction holders that claims to get the job done in as little as 20 minutes. There is probably a limit to how many dyes can be added to a single reaction tube. \u201cOnce you have got to four colours you have four sets of primers and four probes, and you have to stop these cross-reacting with each other and forming primer dimers,\u201d says Chris Helps from the School of Clinical Veterinary Science at the University of Bristol. \u201cWhen you increase the number of targets the reactions become very complex \u2014 you also need spectrally distinct dyes to minimize cross-talk between channels.\u201d \n               Blowing hot and cold \n             How about really cutting the time down? The RapidCycler thermal cycler from Idaho Technology of Salt Lake City, Utah, blows blasts of hot and cold air through the reaction chamber, which gives near instantaneous temperature changes and rapid heat exchange with the samples. The RapidCycler 2 will do a 30-cycle run in 15 minutes, carrying 48 samples in either glass microcapillary tubes or the standard 1.5-mm reaction cuvettes that will also fit the widely used LightCycler, available from Roche Applied Science in Indianapolis, Indiana. And it is possible to go faster still. The PCRJet thermocycler developed by a multidisciplinary team under the brand name MegaBase Research Products, in Lincoln, Nebraska, drives a mixture of hot and cold gas through the reaction chamber at 45 miles per hour. \u201cThe velocity of the air stream is so high that we are definitely in the turbulent region, which ensures that the heat transfer to the sample-containing capillary tubes is maximal. We can do 30 cycles of PCR with amplicons of anything from 100 to 600 base pairs in 2 to 3 minutes,\u201d says Hendrik Viljoen of the department of chemical engineering at the University of Nebraska in Lincoln, one of the designers. \u201cGoing faster than 5 minutes doesn't really gain much for the working scientist, since it usually takes longer than that to mix the PCR reagents,\u201d says team member Michael Nelson, \u201cso we have backed off on speed and are now primarily concerned with system engineering for reliability and ease of use.\u201d The PCRJet takes eight samples of 20\u2013100 ml at a time. \u201cTalking to people in industry, we have found that in areas like infectious disease detection there is strong resistance to too small volumes. You need a big enough lump of sample because in the early stages of disease development there may be very few organisms present in a sample,\u201d says Viljoen. PCRJet needs a fast enzyme, and it uses KOD Pol from  Pyrococcus kodakaraensis  from Toyobo Company of Osaka, Japan. Toyobo's Hideki Hayami, who is collaborating with MegaBase, says this can copy DNA at a rate of around 300 nucleotides per second. Getting personal, Stratagene's Mx3000P is a four-colour optics real-time PCR machine for personal and small lab use, while the 46-well MJ Mini thermal cycler from Bio-Rad of Hercules, California (which recently acquired the manufacturers MJ Research) can be upgraded to a two-colour real-time machine with the retrofit of a MiniOpticon detection system. \n               Isothermal alternatives \n             Given that the physics of heating and cooling a PCR system can be problematic, a few pioneers are developing isothermal procedures \u2014 PCR at a uniform temperature \u2014 with an eye mainly on the clinical diagnostic market. One approach is known as the ramification amplifying method (RAM). Invented by David Zhang of Mount Sinai School of Medicine in New York in 1994, RAM is licensed to Hamilton Thorne Biosciences of Beverly, Massachusetts, by Mount Sinai, which was recently granted an additional US patent on the method. Target DNA is first isolated by capture probes linked to magnetic beads. A given target DNA is then detected by RAM, which employs a single-stranded DNA \u2018C-probe\u2019 that contains 3\u2032 and 5\u2032 sequences complementary to the target. If the C-probe hybridizes accurately with the target DNA, both ends of the probe bind close together and are joined by a ligase to form a circle. Once the circle is formed, this binds a primer at an internal site, which is extended by a strand-displacing DNA polymerase (for example, phi29 or Bst). As the polymerase travels around the circle it displaces the strand created on previous circuits, creating a long chain, which can itself can be duplicated by other primers and enzymes. As the displaced DNAs are single stranded, primers can bind at a consistent temperature, removing the need for any thermocycling during amplification. However, \u201ccircle formation does require annealing of the C-probe to the targets and for long double-stranded DNA targets, a denaturation step would be beneficial,\u201d explains David Lane, vice-president of research and development for Hamilton Thorne Biosciences. Binding is highly specific, making it a useful tool for SNP detection. \u201cSince RAM uses a universal primer, there is also no need for primer balancing, making high-level multiplexing as straightforward as adding multiple C-probes to an assay\u201d, says Lane. A completely different approach is that of Huimin Kong and colleagues, who came up with the idea of using a DNA helicase to separate the DNA strands rather than heat while working at New England Biolabs in Beverly, Massachusetts. \u201cWhile other so-called isothermal techniques need an initial 95 \u00b0C DNA denaturation step, helicase-dependent amplification (HDA) can be performed in true isothermal conditions,\u201d Kong says. Once the helicases have unwound the target, sequence-specific primers can bind to the single-stranded DNA and be extended, as in standard PCR. Along with former colleagues, Kong has founded BioHelix Corporation in Beverly, with the aim of commercializing HDA. BioHelix's first commercial product is a teaching kit, marketed by the Carolina Biological Supply Company in Burlington, North Carolina, for students to carry out molecular diagnosis of sickle-cell anaemia in the classroom, without the need for an expensive thermocycler. The IsoAmp tHDA DNA amplification kit for research is due to launch this month. \n               Primers and probes made easy \n             For real-time PCR, the combinations of specific primers and the fluorescent oligonucleotide probes that detect template amplification are key. Researchers who hate designing probes and primers can now turn to online databases. PrimerBank, developed by Xiaowei Wang of the department of molecular biology at Harvard University and Massachusetts General Hospital, Boston, contains over 300,000 predicted primers for human and mouse genes generated computationally by a design algorithm. They have tested over 1,000 primer pairs and found a design success greater than 99% as defined by single PCR products and reasonable amplification efficiency, says Wang. The Quantitative PCR Primer Database (QPPD), coordinated at the National Cancer Institute in Bethesda, Maryland, provides information about published primers and probes for quantitating human and mouse mRNA by RT-PCR. Another source of published primer\u2013probe sets for real-time PCR, with 3,376 entries so far, is RTprimerDB run by Jo Vandesompele and Filip Pattyn at the University of Ghent, Belgium, which can be searched by gene name, oligonucleotide sequence or NCBI's EntrezGene or SNP ID. \u201cIf people find the primer\u2013probe pair they want they can click through to the PubMed identifier, and it also contains the details of the person who submitted the sequence,\u201d says Vande-sompele. He hopes that coordinating the primer\u2013probe sets that people use should increase standardization between labs, making it easier to compare results. Vandesompele also sees perils in the common use of a single housekeeper gene to normalize results in gene-expression studies, and his free geNorm applet for Excel will determine how many housekeeper genes you need for an accurate analysis. But he laments the fact that most analysis software only allows one housekeeper gene to be entered. First described by Jesper Wengel in 1998, locked nucleic acids (LNA) are slowly making their way on to the PCR scene for use as probes. Their key advantage is their restricted conformational flexibility, which gives them great thermal stability and excellent mismatch discrimination when complexed with complementary DNA or RNA. At the Charit\u00e9 University Medical Centre in Berlin, Germany, Oliver Goldenberg and Lutz Hamann are using LNAs to quantify the species-specific 16S rDNA from multiple bacteria in a single PCR reaction. Their interest is in the intestinal flora that keep us healthy and they want a fast method of detecting the bacteria present without having to cultivate them. With a standard reporter dye such as SYBR Green, which fluoresces when it binds double-stranded DNA, only one specific feature can be assayed per sample \u2014 either a total bacterial count or identification of a single species. The widely used fluorescent resonance emission transfer (FRET)-based probes, such as the TaqMan system from Applied Biosystems of Foster City, California, aren't suitable either, as they require a recognition sequence of some 40 bases and \u201cyou will hardly find such long conserved regions in 16S rDNA,\u201d says Goldenberg. \u201cBut the higher melting point of LNAs means that specificity can be achieved with shorter sequences.\u201d Designing LNA probes can pose problems (see \u2018Simplifying the probe set\u2019). \u201cWe have been testing LNA probes for SNP detection and have found the design parameters to be significantly different to standard TaqMan probes,\u201d says Helps. He thinks the problem lies in the probe-design software: the most commonly used design software was written for the established fluorigenic probes but doesn't work as well for LNAs. PCR has its twentieth birthday this year and has stood the test of time. Like the DNA it analyses it is evolving, and the next 20 years should be equally exciting. Reprints and Permissions"},
{"file_id": "434797a", "url": "https://www.nature.com/articles/434797a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Microfluidic systems have taken over from two-dimensional (2D) gel electrophoresis techniques in some areas of protein separation and analysis, but the established methods are far from dead. Even though they can be slower and messier, the tried and tested 2D protocols still offer some advantages, especially if automation can take out most of the hassle. \u201cSome people will be claiming otherwise, but I think 2D still has the best levels of sensitivity when you're looking at complex samples,\u201d says Paul Orange, senior product manager at NextGen Sciences in Cambridge, UK. \u201cWith 2D you're seeing resolution of 2,000\u20133,000 spots on a gel \u2014 that's quite a lot of information, but people understand it. Also 2D is a very accessible technology \u2014 you can go and buy equipment relatively cheaply and get started if you're looking for a proteomics approach.\u201d In 2003, NextGen launched the first fully automated 2D electrophoresis platform, called a2DE. The firm has now brought out a spin-off system called the a2DEoptimizer which can improve 2D separations on a variety of commercial platforms. \u201cWe've not tried to reinvent the wheel,\u201d says Orange. \u201cWe know what people are using, and know that they have lots of data and experience, but we can help them out by automating key aspects of the process.\u201d The heart of the a2DEoptimizer is automated gel casting, allowing researchers to create customized gradient gel profiles with a minimum of fuss. \u201cEveryone knows casting a gradient gel gives you far superior spot resolution, separation and definition, but the problem is that these gradients can be quite tricky to pour, especially the more exotic ones,\u201d Orange says. \u201cThere's a very small number of people who can get good reproducible gels when they're pouring gradients. As we see 2D going forward, people are dealing with very small amounts of sample. They've got one or two gels they can run so they have to get the best data they can out of there.\u201d The system also has integrated power packs that can focus samples at high voltages and reduce the time for a separation run. And it has real-time monitoring of the electrical profile. \u201cThat's of particular importance, because when you're dealing with new samples, it's very important to look at the electrical profile and tell whether you've got some kind of issue with salt content or protein content,\u201d Orange notes. \u201cWhat we're doing is enabling people to get better data out, and also analyse what's going on in their system.\u201d \n               Tim Chapman \n             Reprints and Permissions"},
{"file_id": "434799a", "url": "https://www.nature.com/articles/434799a", "year": 2005, "authors": [], "parsed_as_year": "2006_or_before", "body": "Reprints and Permissions"}
]