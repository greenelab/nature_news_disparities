[
{"file_id": "513129a", "url": "https://www.nature.com/articles/513129a", "year": 2014, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Recommendation services claim to help researchers keep up with the most important papers without becoming overwhelmed. Casey Bergman\u2019s daily research routine used to include checking all his e-mails and web alerts to pick out fresh papers in his field. But he grew dissatisfied with table-of-contents alerts from journals, RSS (Rich Site Summary) feeds and automated e-mails from the PubMed database. The flow of content was manageable, but if he left it for more than a day, \u201cit became a burden\u201d, he says. So last year Bergman, a computational geneticist studying fruit flies ( Drosophila)  at the University of Manchester, UK, turned to a fresh approach: an automated Twitter account (or \u2018twitterbot\u2019) that he named FlyPapers. The bot trawls PubMed and the arXiv preprint server to find papers containing the word  Drosophila , and spits them out into its followers\u2019 feeds. Bergman finds it much easier to catch up with FlyPapers popping up in his Twitter feed \u2014 and his idea has spawned around 55\u00a0twitterbots in other disciplines. It is no surprise that academics are coming up with their own ways to keep on top of the flood of literature. \u201cIt\u2019s a common struggle,\u201d says Bergman. A staggering 6,000 papers are published every day \u2014 and although no one wants to be overloaded with recommendations, missing key papers is \u201cmortifying\u201d, says Sally Burn, a developmental geneticist at Columbia University in New York City. She uses a service called Scizzle, which regularly sends her the results of saved PubMed searches. \u201cUnless you have all day, and ten people working for you trawling the literature, I think it\u2019s the best situation you\u2019re going to get,\u201d she says. But a stream of papers based on keywords only scratches the surface of what is technologically possible. Emerging literature-recommendation engines promise not only to filter the flood of papers to a trickle, but also to learn from their users\u2019 interests to add personalized suggestions (see \u2018A guide to reading\u2019). \u201cIn spirit, it\u2019s similar to what Netflix or Amazon do,\u201d says Matthew Davis, a computational biologist at the University of Texas at Austin who wrote the algorithm for one such service, PubChase \u2014 now owned by ZappyLab, a firm in Berkeley, California, that makes web- and phone-based tools for scientists. \n               boxed-text \n             \n               If you like that, you\u2019ll like this \n             One of the first, and still best-known, services comes from Google Scholar. Its Updates tool suggests articles by applying a statistical model to a record of a researcher\u2019s authored papers and citations. \u201cThe recommendations are almost scarily good,\u201d says Roger Schonfeld, programme director at Ithaka S+R, a non-profit consultancy based in New York City that advises academia on digital technology. But graduate students may not have a sufficient body of work for the site to help, notes Patrick Mineault, a computational neuroscientist at the University of California, Los Angeles. PubChase suggests articles from PubMed on the basis of a user\u2019s publishing record, but it also learns from the articles that the user has read and stored in his or her online library. And it adds another machine-learning technique: comparing this library with other people\u2019s collections, with the logic that people with common research interests might benefit from each others\u2019 preferences. \u201cI\u2019ve been really impressed: nearly every article it has recommended has been relevant to my research,\u201d says Kelsey Wood, a geneticist at the University of California, Davis, who uses the service along with reference-manager tool Mendeley, owned by Amsterdam-based publisher Elsevier. Ross Mounce, an evolutionary biologist at the University of Bath, UK, says that PubChase is not useful for those whose interests fall outside the boundaries of PubMed. He prefers Sparrho, a fledgling London-based venture that generates recommendations with a keyword-based feed, and asks users to train the tool by flagging suggestions as relevant or irrelevant. It includes articles, grants, patents, posters and conference proceedings from all the sciences. \u201cThe breadth is a real strength,\u201d says Mounce. As with PubChase, recommendations are based on connections between similar users. \u201cWe\u2019re allowing intelligent curators, humans, to join the scattered dots,\u201d says chief executive Vivian Chan, who co-founded Sparrho after she struggled to keep up with the literature while studying for a biochemistry PhD at the University of Cambridge, UK. As start-ups seeking investment, PubChase and Sparrho are guarded about how many users they have. It is clear that numbers are small. (A  Nature  survey of more than 3,000 scientists found that only 8% had heard of PubChase, and fewer than 1% visited it regularly; see  Nature 512, 126\u2013129 (2014) .) But both say that their user base is growing quickly. \n               Back to basics \n             Bergman is wary of algorithm-based searches. A machine that learns and tailors recommendations can become like \u201cblinders on your intellectual scope\u201d, he says. And he has found that the interdisciplinary nature of his work, which melds genomics and text-mining, confused Google Scholar \u2014 the tool threw up irrelevant papers and missed important ones. But Davis says that this narrowing is counteracted by the new doors opened by recommendations based on the profiles of people with similar interests. Many researchers eschew algorithms altogether, and simply follow colleagues on social networks to find out what is worth reading. \u201cTwitter is the unsung hero of the paper-recommendation world,\u201d says Cassie Ettinger, a geneticist in the same research group as Wood. Other scientists check which papers rise to the top in online communities or among users of reference-management services such as Faculty of 1000 Prime and Mendeley. But the desire to share recommendations or upload libraries to find new papers is hardly universal. Derek Lowe, a chemist at Vertex Pharmaceuticals in Boston, Massachusetts, who writes the blog In the Pipeline, remains a fan of RSS feeds from journal websites. And Burn says that she does not have the time to train a recommendation engine. Mineault acknowledges that automated learning devices will never find all the papers a scientist wants, but he thinks that they will improve. Techniques for gleaning meaning from content will become more sophisticated, he says, and will eventually have a significant role in guiding scientists\u2019 reading choices. For Bergman, a lot of this is a matter of taste. His twitterbot has convened an online fruit-fly community; its suggestions have been retweeted by researchers in other disciplines, and even by non-scientists. Bergman has not ruled out trying further technologies, but he is sticking to FlyPapers for now. \u201cI haven\u2019t felt the need to try any others. It\u2019s working for me, and that\u2019s all that matters,\u201d he says. See Editorial  page 6 \n                     Online collaboration: Scientists and the social network 2014-Aug-13 \n                   \n                     Twitter buzz about papers does not mean citations later 2013-Dec-12 \n                   \n                     Computing giants launch free science metrics 2011-Aug-02 \n                   \n                     Peer review: Trial by Twitter 2011-Jan-19 \n                   \n                     Casey Bergman blog \n                   \n                     Scizzle \n                   \n                     GoogleScholar \n                   \n                     PubChase \n                   \n                     Sparrho \n                   \n                     ReadCube \n                   Reprints and Permissions"},
{"file_id": "515151a", "url": "https://www.nature.com/articles/515151a", "year": 2014, "authors": [{"name": "Helen Shen"}], "parsed_as_year": "2006_or_before", "body": "The free IPython notebook makes data analysis easier to record, understand and reproduce. Flying high above the Pacific Ocean, Titus Brown is taking a deep dive into his students' research code. The long journey from Michigan State University in East Lansing to a conference in Melbourne, Australia, provides the perfect chance for the bioinformatician to scrutinize his lab's new algorithm for removing errors from RNA sequencing data. Three years ago, Brown might have waited until he was back in his office. It is difficult to dig into other researchers' code without them being present to explain it, make changes and produce updated results. But these days, Brown can work with his lab from afar using a free, open-source software package called IPython, which helps researchers to keep a detailed lab notebook for their computational work. Brown's students write explanatory text and intersperse it with raw code and the charts and figures that their algorithms generate. Sitting in the aeroplane with an IPython notebook downloaded to his laptop, Brown can interact with the work. He tweaks and re-runs the code, which executes directly in the document he is reading \u2014 allowing him to see instantly whether his changes are improving the algorithm. \u201cI can go through their notebook, understand exactly what they did and modify it, explore different parameters and look at different views,\u201d he says. \u201cI can do this from anywhere in the world.\u201d Designed to make data analysis easier to share and reproduce, the IPython notebook is being used increasingly by scientists who want to keep detailed records of their work, devise teaching modules and collaborate with others. Some researchers are even publishing the notebooks to back up their research papers \u2014 and Brown, among others, is pushing to use the program as a new form of interactive science publishing. \n               boxed-text \n             \n               Better bookkeeping \n             The IPython notebook was developed in 2011 by a team of researchers led by Fernando P\u00e9rez, a data scientist at the University of California, Berkeley, and computational physicist Brian Granger at California Polytechnic State University in San Luis Obispo. \u201cWe built it by solving problems that we ourselves had as researchers and educators,\u201d says P\u00e9rez. P\u00e9rez and Granger saw that data scientists found it hard to share detailed but understandable descriptions of their raw code that would allow others to build on their research. That is partly because many scientists in computation-intensive fields write code in an iterative and piecemeal fashion as each analysis reveals new insight and spins off multiple lines of inquiry. Keeping track of the different versions of code that produce various figures, and linking those files with explanatory notes, is a headache. And what gets published is usually not detailed enough for the reader to follow up on. \u201cIn my own computational physics work,\u201d says Granger, \u201ca high-level description of the algorithm that goes into the paper is light years away from the details that are written in the code. Without those details, there is no way that someone could reproduce it in a reasonable time scale.\u201d The IPython notebook addresses both issues by helping scientists to keep track of their work, and by making it easy to share and for others to explore the code. The 'I' in IPython refers to an 'interactive' command window that helps users to run code, access variables, call up data analysis packages and view plots, while the Python refers to the popular programming language that the notebook is based on. (P\u00e9rez, Granger and their colleagues are now moving the notebook into a project called Jupyter, which aims to make IPython more compatible with other languages, including Julia and R). \n               Code chops \n             At the University of Texas at Austin, Tal Yarkoni uses the IPython notebook to run automated meta-analyses of brain imaging studies to uncover patterns of neural activity involved in language processing, emotion and other processes. The psychoinformatician plans to publish the notebooks as companions to his future journal articles. \u201cThe more complicated the analyses, the greater the benefits of being able to convey all that in one simple document,\u201d he says. Applications similar to the IPython notebook already exist for various programming languages. Mathematica and Maple \u2014 commercial analysis packages popular among mathematicians \u2014 include notebooks or notebook-like programs. MATLAB, a commercial package used heavily in signal processing, engineering and medical-imaging research, also supports a notebook application. Each of these notebooks is specialized for its corresponding proprietary programming language. A number of notebooks and notebook-like programs exist in the open-source world; knitr works with the R coding language, which is especially powerful for statistical analysis. And the Sage mathematical software system, which is also based on the Python language, supports its own notebook. Dexy is a notebook-like program that focuses on helping users to generate papers and presentations that incorporate prose, code, figures and other media. But the IPython notebook has become one of the most widely adopted programs of its kind, says Ana Nelson, the creator of Dexy. \u201cSo many people have heard of it who haven't heard of any other tool,\u201d she says. Granger and P\u00e9rez do not know how many people have tried their software, but say that traffic to the website suggests that roughly 500,000\u20131.5 million people actively use the program. Nelson says that it is the best-designed of the digital notebooks, and attracts many users because it is free and open source. The application also benefits from the popularity of the Python language, which boasts a robust scientific community that meets for an annual international conference, and is (relatively) easy for novice programmers to learn. Although a growing number of researchers are publishing their notebooks alongside papers (see  go.nature.com/mqonbm  for examples), it may still be some time before journals accept the documents as full journal articles. A handful of IPython notebooks have been published as books, and many professors use the program to make interactive curricula. But so far, the notebooks seem to have been published only as addenda to papers \u2014 often to provide analysis code and additional explanation in method sections. \u201cPublishers, I would say, still aren't convinced that they want to go the whole way,\u201d says Granger. The data format may be too new, he says, for journals to recognize the notebook as an official document format, such as html or pdf. But the IPython team has begun talks with a few publications. \n               Start from scratch \n             Most IPython notebook users are skilled programmers, but experts are helping to introduce beginners to coding through the software (see \u2018IPython for beginners\u2019). Yan Song, a postdoc at the University of California, San Diego, had no programming experience until about three months ago. She works on the 'wet' side of a cellular and molecular medicine lab, where she designs experiments and collects data that computational scientists \u2014 on the 'dry' side \u2014 help her to mine for information. \n               boxed-text \n             Song looks for changes in RNA expression in mouse and human stem cells as they differentiate into various types of neuron. In the past, she used Excel to compare expression patterns between groups of cells at different developmental stages. But earlier this year, she began to examine RNA sequencing data from single cells and her data sets exploded in size and complexity. Instead of analysing a few groups of cells, she had to compare hundreds of cells at once, and in each one she examined around 1,500 separate genes related to neural development. Olga Botvinnik, a bioinformatics graduate student in that lab, started to generate the results in an IPython notebook, so Song began playing with the analysis code \u2014 out of a mixture of curiosity and impatience, she says. \u201cIt seemed to be an easy interface. You can code one line and you can see whether it works right away.\u201d Within a few weeks, Song had picked up some basic IPython programming skills, finding support through online tutorials and message-boards. Botvinnik has also written some customized menus and widgets to let Song explore her data using different clustering algorithms. Song still relies on Botvinnik for help with intensive computational analyses, but says that she is now starting to explore the data on her own, using her biological knowledge to examine particular subsets of cells or genes, which she can suggest to Botvinnik as leads for further analysis. \u201cWe used to speak two different languages. I would talk about the biology and she would talk about coding. Now we have common ground; we can communicate to each other better. This accelerates our research,\u201d she says. \n                     My digital toolbox: Ecologist Ethan White on interactive notebooks 2014-Sep-30 \n                   \n                     'Boot camps' teach scientists computing skills 2014-Sep-03 \n                   \n                     Research tools: Jump off the page 2014-Mar-26 \n                   \n                     IPython \n                   \n                     Fernando Perez \n                   \n                     Brian Granger \n                   Reprints and Permissions"},
{"file_id": "516131a", "url": "https://www.nature.com/articles/516131a", "year": 2014, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Start-up firms say robotics and software that autonomously record every detail of an experiment can transform the efficiency and reliability of research. Max Hodak has spent much of his academic career fixing the ways that scientists collect data. As a biomedical engineering student at Duke University in Durham, North Carolina, it frustrated him that his laboratory recorded its experiments in paper notebooks, leaving researchers to scour through the pages to find relevant data. So in 2008, he indexed all the notebook data on a computer and wrote a program to allow users to query it. \u201cPeople were saying, 'Why are you wasting your time? That's not going to lead to publication,'\u201d he recalls. But a year-and-a-half later, he returned to the lab from a stint in Silicon Valley to find that many of those earlier sceptics were now using his system. To Hodak, it was a sign that he should pursue his quest for efficiency in the lab. \u201cI was always more interested in finding ways to do analysis more efficiently than in doing the actual analysis,\u201d he says. Today, a warehouse in California is the living embodiment of Hodak's dream to build an automated lab that conducts experiments and records the results, or what he calls a \u201cbiology data centre\u201d. His company, Transcriptic, founded in 2012, is the first of a crop of start-ups of this ilk, all with a similar claim: that advances in software and robotics will help to free researchers from manual drudgery, make their data easier to store and query, and ultimately lead to cheaper, more efficient and more reproducible science. Transcriptic and another California firm called Emerald Therapeutics are pinning their hopes on offering scientists control of a wet lab by remote computer. Many big biology labs already have automated machines to sequence or copy pieces of DNA. But these companies want to bring automation to other routine experiments, such as moving and separating proteins or fragments of DNA through a gel. They offer the capabilities to labs big and small. In Transcriptic's approach, customers first program an experiment using the company's application programming interface (API), which translates each step of an experimental protocol into machine-readable code. The customer's orders \u2014 and any physical samples \u2014 arrive at Transcriptic's warehouse in Menlo Park, and the experiment is carried out in a Plexiglas-enclosed station that contains a benchtop full of instruments guided by a computer, which receives the work order and runs the assemblage of machines. A robot on a gantry runs the length of the station, transferring plates from machine to machine \u2014 apparatus for the polymerase chain reaction (which amplifies DNA), plate readers, liquid handlers, a freezer and an incubator \u2014 to carry out the experiment. Users receive data from each step of the experiment in real time. Customers say that this frees them up to spend their time on science, rather than on grunt work. For example, synthetic biologist Justin Siegel heads a lab at the University of California, Davis, that designs, builds and tests new enzymes. Transcriptic now does the lab's molecular biology, liberating his students from the one-third of their time that used to be spent on copying and mutating DNA fragments (cloning and mutagenesis, respectively). Siegel credits Transcriptic with building a biosensor that detects the chemical profile of olive oil, for which his students won the grand prize at the 2014 International Genetically Engineered Machines competition on 3 November. \u201cIt's made us more efficient and a little bolder,\u201d he says. \u201cInstead of making just ten designs, they want to try a couple extra. They'll go a little bit farther out on a limb because all of a sudden they don't have to physically build the stuff.\u201d \n               Experiments to order \n             Emerald is testing what it calls the Emerald Cloud Laboratory, which the company says will be a one-stop online shop through which customers order experiments, analyse data and collaborate with others. Starting early in 2015, beta users will be able to order from a list of 40 common lab protocols, such as western blots for protein analysis, or high-performance liquid chromatography for separating components of a mixture. When an order comes in, a human operator will set up the experiment on one of the company's automated workstations at its lab in Menlo Park. Operators transfer sample plates from machine to machine to carry out the steps of the experiment, and the customer gets data back through the Emerald Cloud Laboratory. There, customers can analyse the results using text functions encoded in the Wolfram programming language. Users can review everything, from the controls and machine settings of the instruments used, to results from past experiments using the same reagents \u2014 even experiments from others who have granted permission for their data to be openly accessible. \u201cEverything we do is built by scientists for scientists,\u201d says Emerald co-founder Brian Frezza. In one sense, these models are similar to conventional contract-research organizations, but the automated systems and data collection offer scientists much finer detail and control over experimental design. One might think that the complicated equipment makes experiments more expensive to do. But Hodak says that Transcriptic offers protocols such as cloning and mutagenesis at about the same cost at which they could be run in an academic lab \u2014 or for less \u2014 and at about half the price offered by conventional research outsourcing firms, he says. That is partly because its stations can run without a human operator, and also because the firm makes a lot of its own hardware. When Hodak first went looking for an automated freezer, the cheapest he could find was US$400,000. So he hired mechanical engineers to build one for $40,000, and used the same basic design for automated incubators and refrigerators. Although these labs are powerful research aids, remote users are necessarily limited to a standard set of experiments and instruments, notes Roger Chen, an associate at the investment firm O'Reilly AlphaTech Ventures in San Francisco, California. \u201cI have a hard time believing that a centralized automated lab will give you the freedom and flexibility to experiment with all the parameters you need to do some innovation.\u201d Chen has therefore invested in Riffyn, another fledgling start-up, in Oakland, California. It wants to adapt individual research labs so that scientists can use automated data collection for their own custom experiments, albeit without robotic control. The firm (which will not launch until late 2015 at the earliest) is building a cloud-computing software platform integrated with devices that stream data from lab equipment. According to co-founder Timothy Gardner, the software will allow users to design workflows, analyse experimental data held on remote servers and thus change parameters (such as the temperatures or pressures at which an instrument operates) in response to the analysis of an experiment's performance. \u201cWe're trying to solve the problem of how you bring McDonald's-like efficiency to scientists without shackling them to McDonald's-like recipes,\u201d he says. \n               Communication is key \n             Current scientific instruments take instructions and record data in a variety of formats. Harmonizing their software will be an even harder technical challenge than building robotically controlled equipment, warns Frezza. Gardner acknowledges this, but says that momentum for a common, open set of standards and software is building. Meanwhile, he hopes that Riffyn's software will enable lab devices to talk to each other \u2014 and to scientists \u2014 more smoothly. The concept would not have been possible even a few years ago; only last year did computer giant Apple, for instance, release iBeacon, a system that enables nearby compatible devices to communicate with each other. Gardner's inspiration comes from his time running research operations at synthetic-biology pioneer Amyris Biotechnologies, in nearby Emeryville, which genetically engineers yeast to produce biofuels and speciality chemicals. In the early days it struggled to scale up basic processes to industrial quantities, because random variation \u2014 noise \u2014 in each step led to irreproducible results. The company started to analyse data from each step of the process to spot the weak points, and made dramatic improvements. Gardner says that research labs need that same kind of reproducibility. \u201cWe need to bring the pursuit of precision reliability to the academic world,\u201d agrees Douglas Crawford, associate director of the California Institute for Quantitative Biosciences (QB3), and one of Gardner's strongest supporters. Ultimately, Gardner and other backers of automated labs say that the immediate pay-off of their work might be to promote a general movement to boost the overall quality of research. Tools that make it easy for scientists to monitor and record every aspect of their experiment, they say, might help to deal with what some argue is a 'reproducibility crisis' in research \u2014 the sense that many experiments are too sloppily done, or that methods and data are recorded too imprecisely, for others to easily reproduce findings. Crawford thinks that changing this will require a cultural shift as much as a technical one. Gardner agrees, but hopes that companies such as his will remove one the roadblocks: \u201cI don't think you can get the cultural and educational changes to stick if you don't have tools that make it easy,\u201d he says. \n                     Organic synthesis: The robo-chemist 2014-Aug-06 \n                   \n                     Must try harder 2012-Mar-28 \n                   \n                     Underwater robot automates ocean testing 2010-Feb-24 \n                   \n                     Nature  special: Challenges in irreproducible research \n                   \n                     Emerald Cloud Laboratory \n                   \n                     Riffyn \n                   \n                     Transcriptic \n                   Reprints and Permissions"},
{"file_id": "517109a", "url": "https://www.nature.com/articles/517109a", "year": 2014, "authors": [{"name": "Sylvia Tippmann"}], "parsed_as_year": "2006_or_before", "body": "A guide to the popular, free statistics and visualization software that gives scientists control of their own data analysis. For years, geneticist Helene Royo used commercial software to analyse her work. She would extract DNA from the developing sperm cells of mice, send it for analysis and then fire up a package called GeneSpring to study the results. \u201cAs a scientist, I wanted to understand everything I was doing,\u201d she says. \u201cBut this kind of analysis didn\u2019t allow that: I just pressed buttons and got answers.\u201d And as Royo\u2019s studies comparing genetic activity on different chromosomes became more involved, she realized that the commercial tool could not keep up with her data-processing demands. With the results of her first genomic sequencing experiments in hand at the start of a new postdoc, Royo had a choice: pass the sequences over to the experts or learn to analyse the data herself. She took the plunge, and began learning how to parse data in the free, open-source software package R. It helped that the centre she had joined \u2014 the Friedrich Miescher Institute for Biomedical Research in Basel, Switzerland \u2014 ran regular courses on the software. But she was also following a wider trend: for many academics seeking to wean themselves off commercial software, R is the data-analysis tool of choice. Besides being free, R is popular partly because it presents different faces to different users. It is, first and foremost, a programming language \u2014 requiring input through a command line, which may seem forbidding to non-coders. But beginners can surf over the complexities and call up preset software packages, which come ready-made with commands for statistical analysis and data visualization. These packages create a welcoming middle ground between the comfort of commercial \u2018black-box\u2019 solutions and the expert world of code. \u201cR made it very easy,\u201d says Rojo. \u201cIt did everything for me.\u201d That, indeed, is what R\u2019s developers intended when they designed it in the 1990s. Ross Ihaka and Robert Gentleman, statisticians at the University of Auckland in New Zealand, had an interest in computing but lacked practical software for their needs. So they developed a programming language with which they could perform data analysis themselves. R got its name in part from its developers\u2019 initials, although it was also a reference to the most widely used coding language at the time, S. In the early days of the World Wide Web, R quickly attracted interest from scientists around the globe who needed statistical software and were willing to contribute ideas. Gentleman and Ihaka decided to make their source code accessible to everybody, and coding-literate scientists quickly developed packages of pre-programmed routines and commands for particular fields. \u201cI can write software that would be good for somebody doing astronomy,\u201d says Gentleman, \u201cbut it\u2019s a lot better if someone doing astronomy writes software for other people doing astronomy.\u201d \n               Mathematical solutions \n             Karline Soetaert, an oceanographer at the Royal Netherlands Institute for Sea Research in Yerseke, took up that idea when, in 2008, she wanted to check the health of zooplankton in the estuary of the river Scheldt. Soetaert wanted to calculate how fast zooplankton were dying, using measurements along the river, but R was not equipped for that. To tackle the problem, she worked with two ecologists to develop deSolve \u2014 the first package written in R to solve differential equations. \u201cOther software can do that, but it is expensive and closed source,\u201d she notes. Now deSolve is used by epidemiologists modelling infectious diseases, geneticists working on gene-regulatory networks and drug developers working on pharmaco\u00adkinetics (how compounds behave in living organisms). By 2003, 10 years after R\u2019s first release, scientists had developed more than 200 packages, and the first citations of the \u2018R Project\u2019 appeared. Today, nearly 6,000 packages exist for all kinds of specialized purposes (see \u2018R in science\u2019). They allow scientists to compare a human and a Neanderthal genome (using  Bioconductor ); to model population growth ( IPMpack ); predict equity prices ( quantmod ); and visualize the results in polished graphics ( ggplot2 ) in a few lines of code. Experts can use R to write up manuscripts, embedding raw code in them to be run by the reader ( knitr ). Nearly 1 in 100 scholarly articles indexed in Elsevier\u2019s Scopus database last year cites R or one of its packages \u2014 and in agricultural and environmental sciences, the share is even higher (see \u2018A rising tide of R\u2019). \n               boxed-text \n             \n               Statistical success \n             For many users, R\u2019s quality as statistics software stands out. The tool is on a par with commercial packages such as SPSS and SAS, says Robert Muenchen, a statistician at the University of Tennessee in Knoxville who analyses the popularity of software used in statistical computing. In the past decade, R has caught up with and overtaken the market leaders. \u201cMost likely, R became the top statistics package used during the summer of this year,\u201d he says. In genomics and molecular biology, a software project called Bioconductor was developed on the back of R. It helps scientists to process and compare huge numbers of genetic sequences, to query results against databases such as Gene Expression Omnibus and to upload data to the databases . It includes almost 1,000\u00a0packages, some of which help to link the millions of DNA snippets from next-generation sequencing experiments to annotated genes. For her dive into R, Royo had intensive training: under the supervision of Michael Stadler, head of the Friedrich Miescher Institute\u2019s bioinformatics group, she took about half a year to work on R and Bioconductor. But there are plentiful chances to learn, says Karthik Ram, an ecologist at the Berkeley Institute for Data Science in California who founded rOpenSci, an initiative that helps scientists to adopt and develop R (see \u2018An R starter kit\u2019). He and his colleagues teach free courses that do not require existing programming skills and are targeted towards scientists\u2019 specific problems. \n               boxed-text \n             One researcher who took that training is Megan Jennings, an ecologist at San Diego State University in California. She tracks bobcats, mountain lions and other wild animals, to understand their movements. Armed with more than 400,000 time-stamped photos to which she had appended species names \u2014 taken from 36\u00a0cameras running for almost a year \u2014 Jennings wanted to follow particular species at particular times of year. At first, she manually selected the photos she wanted and fed them into a black-box program called PRESENCE. But with Ram\u2019s help, she is creating an R package that reads in the tagged photos, cleans them up and then sends customized subsets of the data to a pre-existing modelling package in R. \u201cWhat took me one hour to do manually, I will now be able to do in five minutes,\u201d Jennings says. One of the greatest perks of R is its online support. Discussion forums about R-related topics outstrip online questions about any commercial statistics software says Muenchen. \u201cIt\u2019s common to see someone post a question and the person who developed the package answer within half an hour,\u201d he says. This rapid response is key for scientists in basic research. \u201cI can find an answer to almost any question online,\u201d says Royo. She can confidently do most of her day-to-day data analysis herself, and she helps out less proficient colleagues. Still, \u201cI google things every day\u201d, she adds. Learning R, says Royo, has not only taught her coding skills, but has also made her more critical about other scientists\u2019 analyses. Not every scientist is enthusiastic about learning the necessary programming \u2014 even though, says Ram, R is less intimidating than languages such as Python (let alone Perl or C). \u201cThere are going to be far more scientists that will be comfortable with click-and-drop interfaces than will ever learn to program at any time,\u201d Muenchen says. Geneticist Rabih Murr, for example, took the same R course as Royo when he was a postdoc, but preparing a paper for publication gave him little time to practise. To get started and develop research-specific skills in R definitely requires a commitment: \u201cIt\u2019s a matter of priorities,\u201d he says. But after becoming a lab head at the University of Geneva in Switzerland this year, he is planning to hire someone with R experience. Like any other skill, learning R cannot be done overnight. But Jennings says that it is worth it. \u201cMake that time. Set it aside as an investment: for saving time later, and for building skills that can be used across multiple problems we face as scientists.\u201d \n                     Interactive notebooks: Sharing the code 2014-Nov-05 \n                   \n                     My digital toolbox: Ecologist Ethan White on interactive notebooks 2014-Sep-30 \n                   \n                     'Boot camps' teach scientists computing skills 2014-Sep-03 \n                   \n                     Nature  Toolbox \n                   \n                     The Comprehensive R Archive Network (CRAN \n                   \n                     rOpenSci \n                   \n                     R4stats \n                   Reprints and Permissions"},
{"file_id": "514127a", "url": "https://www.nature.com/articles/514127a", "year": 2014, "authors": [{"name": "Jeffrey M. Perkel"}], "parsed_as_year": "2006_or_before", "body": "Collaborative browser-based tools aim to change the way researchers write and publish their papers. When Fernando Cagua was preparing to write up his findings on the economics of whale-shark tourism, he didn't fire up Microsoft Word. He opened his web browser. Cagua, an ecologist at King Abdullah University of Science and Technology in Thuwal, Saudi Arabia, was keen to try out an online writing environment that would allow him and his three co-authors to work on the same paper simultaneously. Over the past few years, a small cadre of tools have sprung up expressly for this purpose. Although the features vary, each is designed to ease a key difficulty in writing multi-authored research papers: handling collaboration. And some of the creators have wider ambitions \u2014 to fundamentally alter the way that scientific papers are written and published. Writing a paper is traditionally a stepwise process. One author shares drafts with colleagues and then waits for everyone to reply or moves forward independently, folding in revisions and queries as they arrive. The more co-authors, the more complicated this gets, says Russell Neches, a microbiology PhD student at the University of California, Davis. \u201cManaging that process can be more difficult, more time-consuming and more work than the research itself,\u201d he says. Collaborative tools simplify this process by allowing multiple authors to edit and format an online document at the same time. The most widely used general-purpose collaborative writing app is probably Google Docs \u2014 essentially a stripped-down, online version of Microsoft Word. But there are also more-technical tools designed specifically for researchers. These applications add options such as the ability to control a document's layout and to add citations in a way that suits scientific manuscripts. The tool that Cagua had his eye on, for instance,  writeLaTeX , was so named because it uses the typesetting computer language LaTeX \u2014 popular among physical scientists and mathematicians for rendering mathematical formulas, tables and figures. (The tool is produced by a company also called writeLaTeX, supported by Digital Science, a division of Macmillan, which publishes  Nature . In January, the firm relaunched the tool and renamed it Overleaf.) Other scholar-focused online writing apps include  shareLaTeX ,  Fidus Writer  and  Authorea . \n               Word of mouth \n             A minority of researchers use these apps, but their number is growing. In the past year, registered users of Overleaf have reached 100,000, says writeLaTeX co-founder John Hammersley, and they have created more than 1.4 million documents with the tool. Authorea has 10,000 users, according to its co-founder Alberto Pepe. Jenna Morgan Lang, a postdoc in the same group as Neches, says that she has one Authorea-written paper in preprint and six more in development. \u201cI do love it,\u201d she says, \u201cand I tell everyone who will listen that they should be using it, too.\u201d At the heart of the collaborative approach is the way the tools keep track of different versions of the same document. Authorea, for example, breaks documents into user-defined, paragraph-sized chunks that only one author can edit at a time, but multiple researchers can work on different sections of a document simultaneously. The system records every change in a document history. \u201cYou can go back and understand how a scientific paper evolved from the first word to the last,\u201d says Pepe. For Authorea, that concept is based on the software-management system Git, used by programmers to keep track of changes on collaborative code-writing projects, and by data scientists to record their analysis workflow. Other tools take different approaches: Google Docs and Fidus Writer allow all users access to the entire file simultaneously, and track changes more or less like Microsoft Word, but Fidus Writer, for example, does not record the detailed history of every single edit (although a user may save time-stamped document versions). Overleaf allows both a version history and a track-changes facility \u2014 but the latter is available only to paying subscribers. Although each tool offers a free account, only researchers willing to pay monthly fees (US$7\u201312 for Overleaf and $5\u201325 for Authorea) can access the advanced features, such as more storage space or private accounts. The tools are much more than just word processors and collaboration managers, however. Authorea allows users to build and format bibliographies by searching and importing references from PubMed or CrossRef, or using DOIs (digital object identifiers); Overleaf allows imports from reference managers Zotero and CiteULike. Authorea also enables users to export documents in any of about 40 different journal formats, including those of  Nature ,  Science  and  Proceedings of the National Academy of Sciences . By recasting the same data through different journal filters, \u201cit's a bit like Instagram for scientific papers\u201d, Pepe wrote in one blogpost. At writeLaTeX, Hammersley has ambitions to integrate the writing and publishing of articles even more closely. Users can click a button to transmit their article directly to journal editors; the company currently has arrangements with around a dozen journals, and many more will follow in the next few months, Hammersley says. However, Cagua says that he did not find the process particularly automatic with a paper he transmitted to  PeerJ ; he had to resubmit information in his original LaTeX file that was not automatically picked up by the journal. But Hammersley says that integration with journals is a work in progress. Ultimately, he hopes that a paper's author and its journal editor might collaborate on the article together in the browser window. \n               Familiar ground \n             Cagua also ended up writing most of his whale-shark paper in Google Docs, because his co-authors were not well versed in LaTeX and so found the original writeLaTeX \u201ctoo intimidating\u201d. A raw LaTeX file \u2014 text interspersed with code that tells typesetting programs how to display the prose and figures \u2014 can look off-putting to the uninitiated, or just ugly, like reading the HTML source code behind a web browser's display. In the relaunched version, Overleaf, a rich-text editing environment hides the code and makes writing friendlier for non-experts. Fidus Writer and Authorea also support LaTeX, as well as other computer languages for controlling the display of raw text, including HTML and Markdown. Authorea's \u201cfundamental mission\u201d, Pepe says, \u201cis to re-imagine the scientific article\u201d. Conceived to advance the open sharing of scientific research, the program supports software such as IPython notebooks, which allow readers to explore and manipulate the data underlying published figures. \u201cWe believe in the idea of an interactive, data-driven article,\u201d Pepe explains \u2014 an idea that he has explored in a prototype 'Paper of the future' (see  go.nature.com/plgshx ). A few journals are cautiously experimenting with interactive graphics and data in their articles, although for the most part, this is still rare. An Authorea-written document can double as both a readable paper and an online research notebook containing raw data, notes Alyssa Goodman, an astronomer at Harvard University who was Pepe's postdoctoral adviser when he developed the software. \u201cThe part you can read that looks like a paper is the tip of the iceberg that describes everything underneath,\u201d she explains. Using that feature, Neches collaborated with two researchers in Michigan who he chatted with on Twitter but has never met in person. Together, they studied whether materials printed with a 3D printer were sterile for use in bacterial culture experiments. Authorea, he says, provided a forum for team members to upload raw data and methods, from which they could co-assemble a manuscript online. \u201cIt was very much as though we had created a laboratory in which we worked together,\u201d he says. \u201cIt probably would not have happened at all without a tool like Authorea existing.\u201d \n                     The digital toolbox 2014-Sep-03 \n                   \n                     Research tools: Jump off the page 2014-Mar-26 \n                   \n                     Nature Toolbox hub \n                   \n                     WriteLaTeX \n                   \n                     Authorea \n                   \n                     Fidus Writer \n                   Reprints and Permissions"},
{"file_id": "515151ax", "url": "https://www.nature.com/articles/515151ax", "year": 2014, "authors": [{"name": "Helen Shen"}], "parsed_as_year": "2006_or_before", "body": "The free IPython notebook makes data analysis easier to record, understand and reproduce. Flying high above the Pacific Ocean, Titus Brown is taking a deep dive into his students' research code. The long journey from Michigan State University in East Lansing to a conference in Melbourne, Australia, provides the perfect chance for the bioinformatician to scrutinize his lab's new algorithm for removing errors from RNA sequencing data. Three years ago, Brown might have waited until he was back in his office. It is difficult to dig into other researchers' code without them being present to explain it, make changes and produce updated results. But these days, Brown can work with his lab from afar using a free, open-source software package called IPython, which helps researchers to keep a detailed lab notebook for their computational work. Brown's students write explanatory text and intersperse it with raw code and the charts and figures that their algorithms generate. Sitting in the aeroplane with an IPython notebook downloaded to his laptop, Brown can interact with the work. He tweaks and re-runs the code, which executes directly in the document he is reading \u2014 allowing him to see instantly whether his changes are improving the algorithm. \u201cI can go through their notebook, understand exactly what they did and modify it, explore different parameters and look at different views,\u201d he says. \u201cI can do this from anywhere in the world.\u201d Designed to make data analysis easier to share and reproduce, the IPython notebook is being used increasingly by scientists who want to keep detailed records of their work, devise teaching modules and collaborate with others. Some researchers are even publishing the notebooks to back up their research papers \u2014 and Brown, among others, is pushing to use the program as a new form of interactive science publishing. \n               boxed-text \n             \n               Better bookkeeping \n             The IPython notebook was developed in 2011 by a team of researchers led by Fernando P\u00e9rez, a data scientist at the University of California, Berkeley, and computational physicist Brian Granger at California Polytechnic State University in San Luis Obispo. \u201cWe built it by solving problems that we ourselves had as researchers and educators,\u201d says P\u00e9rez. P\u00e9rez and Granger saw that data scientists found it hard to share detailed but understandable descriptions of their raw code that would allow others to build on their research. That is partly because many scientists in computation-intensive fields write code in an iterative and piecemeal fashion as each analysis reveals new insight and spins off multiple lines of inquiry. Keeping track of the different versions of code that produce various figures, and linking those files with explanatory notes, is a headache. And what gets published is usually not detailed enough for the reader to follow up on. \u201cIn my own computational physics work,\u201d says Granger, \u201ca high-level description of the algorithm that goes into the paper is light years away from the details that are written in the code. Without those details, there is no way that someone could reproduce it in a reasonable time scale.\u201d The IPython notebook addresses both issues by helping scientists to keep track of their work, and by making it easy to share and for others to explore the code. The 'I' in IPython refers to an 'interactive' command window that helps users to run code, access variables, call up data analysis packages and view plots, while the Python refers to the popular programming language that the notebook is based on. (P\u00e9rez, Granger and their colleagues are now moving the notebook into a project called Jupyter, which aims to make IPython more compatible with other languages, including Julia and R). \n               Code chops \n             At the University of Texas at Austin, Tal Yarkoni uses the IPython notebook to run automated meta-analyses of brain imaging studies to uncover patterns of neural activity involved in language processing, emotion and other processes. The psychoinformatician plans to publish the notebooks as companions to his future journal articles. \u201cThe more complicated the analyses, the greater the benefits of being able to convey all that in one simple document,\u201d he says. Applications similar to the IPython notebook already exist for various programming languages. Mathematica and Maple \u2014 commercial analysis packages popular among mathematicians \u2014 include notebooks or notebook-like programs. MATLAB, a commercial package used heavily in signal processing, engineering and medical-imaging research, also supports a notebook application. Each of these notebooks is specialized for its corresponding proprietary programming language. A number of notebooks and notebook-like programs exist in the open-source world; knitr works with the R coding language, which is especially powerful for statistical analysis. And the Sage mathematical software system, which is also based on the Python language, supports its own notebook. Dexy is a notebook-like program that focuses on helping users to generate papers and presentations that incorporate prose, code, figures and other media. But the IPython notebook has become one of the most widely adopted programs of its kind, says Ana Nelson, the creator of Dexy. \u201cSo many people have heard of it who haven't heard of any other tool,\u201d she says. Granger and P\u00e9rez do not know how many people have tried their software, but say that traffic to the website suggests that roughly 500,000\u20131.5 million people actively use the program. Nelson says that it is the best-designed of the digital notebooks, and attracts many users because it is free and open source. The application also benefits from the popularity of the Python language, which boasts a robust scientific community that meets for an annual international conference, and is (relatively) easy for novice programmers to learn. Although a growing number of researchers are publishing their notebooks alongside papers (see  go.nature.com/mqonbm  for examples), it may still be some time before journals accept the documents as full journal articles. A handful of IPython notebooks have been published as books, and many professors use the program to make interactive curricula. But so far, the notebooks seem to have been published only as addenda to papers \u2014 often to provide analysis code and additional explanation in method sections. \u201cPublishers, I would say, still aren't convinced that they want to go the whole way,\u201d says Granger. The data format may be too new, he says, for journals to recognize the notebook as an official document format, such as html or pdf. But the IPython team has begun talks with a few publications. \n               Start from scratch \n             Most IPython notebook users are skilled programmers, but experts are helping to introduce beginners to coding through the software (see \u2018IPython for beginners\u2019). Yan Song, a postdoc at the University of California, San Diego, had no programming experience until about three months ago. She works on the 'wet' side of a cellular and molecular medicine lab, where she designs experiments and collects data that computational scientists \u2014 on the 'dry' side \u2014 help her to mine for information. \n               boxed-text \n             Song looks for changes in RNA expression in mouse and human stem cells as they differentiate into various types of neuron. In the past, she used Excel to compare expression patterns between groups of cells at different developmental stages. But earlier this year, she began to examine RNA sequencing data from single cells and her data sets exploded in size and complexity. Instead of analysing a few groups of cells, she had to compare hundreds of cells at once, and in each one she examined around 1,500 separate genes related to neural development. Olga Botvinnik, a bioinformatics graduate student in that lab, started to generate the results in an IPython notebook, so Song began playing with the analysis code \u2014 out of a mixture of curiosity and impatience, she says. \u201cIt seemed to be an easy interface. You can code one line and you can see whether it works right away.\u201d Within a few weeks, Song had picked up some basic IPython programming skills, finding support through online tutorials and message-boards. Botvinnik has also written some customized menus and widgets to let Song explore her data using different clustering algorithms. Song still relies on Botvinnik for help with intensive computational analyses, but says that she is now starting to explore the data on her own, using her biological knowledge to examine particular subsets of cells or genes, which she can suggest to Botvinnik as leads for further analysis. \u201cWe used to speak two different languages. I would talk about the biology and she would talk about coding. Now we have common ground; we can communicate to each other better. This accelerates our research,\u201d she says. \n                     My digital toolbox: Ecologist Ethan White on interactive notebooks 2014-Sep-30 \n                   \n                     'Boot camps' teach scientists computing skills 2014-Sep-03 \n                   \n                     Research tools: Jump off the page 2014-Mar-26 \n                   \n                     IPython \n                   \n                     Fernando Perez \n                   \n                     Brian Granger \n                   Reprints and Permissions"}
]