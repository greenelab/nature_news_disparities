[
{"file_id": "548123a", "url": "https://www.nature.com/articles/548123a", "year": 2017, "authors": [{"name": "Brian Owens"}], "parsed_as_year": "2006_or_before", "body": "Virtual private networks, tracking apps and 'burner' laptops: how to protect sensitive data when you take your research on the road. Mark Gerstein has had his fair share of scares when it comes to losing track of his electronic devices \u2014 and, along with them, access to his private information and research data. \u201cI'm very security conscious, but also a bit of an absent-minded professor,\u201d says Gerstein, a bioinformatician at Yale University in New Haven, Connecticut. He recalls one trip to Boston, Massachusetts, when he left his phone in a taxi, and watched it get farther and farther away on the tracking app on his iPad while he ran after the car in vain. Luckily, Gerstein was able to contact the taxi company, and eventually watched his phone make the return journey to his pocket. Gerstein's story had a happy ending, but all too often, hardware lost on the road is lost for good. And that's just one of the many threats travelling researchers must face. Outside the confines of the lab and its relatively secure IT infrastructure, data and hardware are vulnerable to dangers such as hacking and theft. Researchers need to be on their guard, not just to protect their work, but also to protect confidential patient data or intellectual property. Cybersecurity concerns can be particularly acute when crossing international borders. Some regions have a reputation for hacking, and border guards might insist on seeing files. What can researchers do to keep their data safe from prying eyes on the road? It depends on your data and the threats you're likely to face, says Morgan Marquis-Boire, director of security for First Look Media in San Francisco, California, who has experience helping government whistle-blowers travel with sensitive data. Are you concerned mostly about overzealous border guards, opportunistic theft or government-sponsored hacking? It's like chatting with a physician, he says. \u201cIf you ask a doctor how to be healthy, you'll get general advice. But it will be different if you're going to the jungle.\u201d Whatever the perceived threat, the first step in data protection, says Marquis-Boire, is encryption \u2014 rendering data unreadable by mathematically transforming them with an electronic key (see \u2018Dos and don'ts\u2019). This simple step can protect against casual theft and deter all but the most determined hackers. \u201cThe number one thing we push for is encryption of data, whole-disk encryption of portable devices especially,\u201d says John Southall, a data librarian at the University of Oxford, UK. \n               boxed-text \n             Most smartphones use whole-disk encryption by default, and there are many options for encrypting laptops. Particularly sensitive files should also be individually encrypted using the computer's built-in file-protection tool or freely available software such as VeraCrypt, BitLocker or 7-Zip. Your research institution may be able to help. Oxford's information-security department, for instance, will encrypt researchers' hardware. \u201cWe have an understanding of not only the necessary protections for research data, but also researchers themselves,\u201d says Southall. \n               Lost property \n             Researchers must also consider the physical security of their electronic devices, adds Southall. \u201cLaptops and other devices are high-value items. They attract theft. So make sure whatever is on them is not irreplaceable.\u201d A tracking app capable of remotely wiping a lost laptop or phone (such as Apple's Find My iPhone) can ensure that even if hardware is taken, data are not compromised, says Gerstein. A US ban on carrying laptops in the cabin on flights from various Middle Eastern airports, announced on 21 March, has introduced a new complication, says Jonathan Katz, who studies cybersecurity at the University of Maryland in College Park. \u201cIt's greatly increased the risk of your laptop being damaged, lost or stolen, and your data compromised.\u201d There is a similar ban in the United Kingdom, but may soon be lifted. Katz will soon be travelling to the Middle East for work. Although he will not be carrying anything particularly sensitive, he plans to ship the computer home using FedEx, rather than leaving it unattended in his checked baggage if the US ban is still in place. \n               Safety in the cloud \n             In many cases, tech-savvy researchers can avoid carrying their data at all. The data can be archived in cloud services such as Dropbox or Google Drive, and accessed from the researcher's destination. Although these services are encrypted and relatively secure, researchers should also encrypt files before uploading them in case the servers are hacked, or their account password is compromised. (Two-factor authentication, in which both a password and mobile-phone-generated key are required to access your account, adds an extra layer of security.) Because these services are often set up to provide automatic access, Marquis-Boire advises researchers travelling internationally to remove the app from their devices, log out of the service and clear their browser history before travel. Researchers should also consider using a virtual private network (VPN), says Southall. These allow users to establish secure network communications over an otherwise insecure Internet connection. Such services include IPVanish VPN, NordVPN and the colourfully named Hide My Ass, and many institutions can provide assistance in setting them up, he says. Gerstein notes he almost always uses a VPN to access his data when travelling, even when he isn't leaving the United States. In most places, a VPN is fairly easy to use, although it can get more complex in countries where the government exerts tight control over the Internet, such as China. Although VPNs are legal there, the government launched a crackdown on domestic VPN providers in January this year. As a result of the regulations, which require that all VPN apps gain government approval, computer giant Apple has removed as many as 60 apps from its Chinese store. It is not clear, however, what effect this will have on the VPNs that researchers are likely to use while overseas. And in Russia, President Vladimir Putin signed a law on 30 July that will ban VPNs and other technology that allows users to gain anonymous access to websites from 1 November. For many scientists, travel to China tops their list of mobile cybersecurity concerns, leading some to take extra precautions. The country has faced allegations of using cyber-espionage to speed technological advances (the US steel industry, for instance, accused Chinese hackers of stealing trade secrets in 2016), and has been accused of hacking researchers and scientific institutions in the past, including a 2014 cyberattack on Canada's National Research Council. Stephen Kingsmore, president of the Rady Children's Institute for Genomic Medicine in San Diego, California, says that some of his colleagues use a 'burner' laptop and phone (low-cost, disposable devices) when travelling to China. \n               Border troubles \n             In the past year, a new threat to data security has arisen for travellers, as the administration of US President Donald Trump works to harden US borders against potential terrorists. Border agents may sometimes ask travellers to provide their portable devices and passwords when they enter the country, and such searches are increasing. US National Public Radio reports that 24,000 devices were searched at the border in 2016, compared with 8,500 in 2015. Researchers are not exempt from this heightened scrutiny. As was widely reported in March, Sidd Bikkannavar, a US citizen and engineer at NASA's Jet Propulsion Laboratory (JPL) in Pasadena, California, was detained at the airport in Houston, Texas, while returning from a personal trip to South America. He was forced to hand over his NASA-issued phone and PIN. Citing the confidential data on the device, Bikkannavar initially refused, but ultimately relented. His phone was taken for 30 minutes and its data copied. Back at JPL, NASA had to run forensic tests on the device to determine what might have been taken, and whether anything had been installed. (Bikkannavar could not be reached for comment, and JPL declined to discuss its cybersecurity arrangements.) It can be tempting to try to hide information or use technological tricks such as 'duress passwords' that, if used instead of the genuine one, unlock the device but keep a portion of the data hidden and encrypted. But Jennifer Granick, who studies cybersecurity law at Stanford University in California, warns against such strategies. \u201cYou don't want to lie to a government agent. That can be a crime.\u201d And border guards are not likely to be sympathetic to the argument that a researcher has a legal duty to prevent anyone from seeing confidential data. \u201cMedical records, trade secrets \u2014 there are a lot of data that you have a legal obligation to protect. Border agents are not experts in these areas of law, they're not going to necessarily care about that,\u201d Granick says. \u201cSo you have to think about how you're going to protect your data.\u201d \n                 Tweet \n                 Follow @NatureNews \n               This online story contains additional information that could not be included in the print version owing to deadline constraints. \n                     'Ransomware' cyberattack highlights vulnerability of universities 2016-Jun-17 \n                   \n                     Secure cloud computing for genomic data 2016-Jun-09 \n                   \n                     How to hack the hackers: The human side of cybercrime 2016-May-11 \n                   \n                     Online security braces for quantum revolution 2015-Sep-08 \n                   \n                     How to catch a cloud 2015-Jun-03 \n                   \n                     Cybersecurity: How safe are your data? 2010-Apr-28 \n                   \n                     Nature Toolbox \n                   \n                     PCMag.com: The Best VPN Services of 2017 \n                   \n                     Medium.com: How to encrypt your entire life in less than an hour \n                   Reprints and Permissions"},
{"file_id": "542125a", "url": "https://www.nature.com/articles/542125a", "year": 2017, "authors": [{"name": "Jeffrey M. Perkel"}], "parsed_as_year": "2006_or_before", "body": "The system of connecting machines and sensors is finally making its way into the laboratory, giving researchers peace of mind and restoring their work\u2013life balance. Out of town for the US 4 July holiday, Kyle Turner got news that no lab manager wants to hear: his freezer was dying. \u201cI was in western Massachusetts and getting these alerts on my phone,\u201d says Turner, who manages an evolutionary-biology laboratory at Harvard University in Cambridge, Massachusetts. Freezers are where life-science laboratories house the fruits of their research; to lose them is to lose everything. Turner called the technicians at the Harvard University Operations Center and asked one of the lab members still in Cambridge to be on site in case precious samples needed to be moved. And then he watched the technicians' progress in real time, using his iPhone. \u201cI was giving feedback remotely on everything that they were trying to fix. 'Oh, we'll try this, we'll rearrange the boxes to promote air flow; we'll try this, we'll change the thermostat.' And I'm looking on my phone and saying, 'Hmm, that worked, that didn't work.'\u201d This remote monitoring was all thanks to a technology innovation that is sweeping the consumer marketplace and has now reached the research laboratory: the Internet of Things (IoT). The IoT is the idea that it is not just computers that can be hooked up to the Internet, but everyday objects as well. In so doing, they acquire new functionality, says Felix Wortmann, scientific director of the  Bosch IoT Lab  at the University of St Gallen in Switzerland, which studies the IoT and its impact on business. Add Wi-Fi and a motion sensor to a light bulb, he says, and you have a remote alarm system; add Wi-Fi to a stereo system, and you can control your music from your phone. In the consumer marketplace, the concept applies to web-connected devices such as thermostats, televisions and cars. But until a few years ago, laboratory equipment could not be linked in the same way. The emergence of connected instruments and equipment promises to untether researchers from the laboratory \u2014 letting them fine-tune experiments and analyse data remotely. It allows lab managers to monitor instrument use and catch potential equipment failures before they happen. But security and economic concerns, and the inevitable teething pains that are inherent in any evolving technology, are moderating enthusiasm. \n               Smart labs \n             Manufacturers have been offering remote freezer monitoring and automatic data logging for years. But the IoT allows the integration of different instruments, from different vendors, into a single integrated platform, says Andreas Hochberger, who is in charge of emerging technologies at Eppendorf AG in Hamburg, Germany. In 2015, Eppendorf was one of a dozen German companies that contributed to the  smartLAB project  \u2014 a model lab of the future based on the IoT. Another smartLAB is planned for the Labvolution 2017 conference to be held in Hanover in May. At the heart of the smartLAB, says project leader Sascha Beutel, who is at the Institute of Technical Chemistry of Leibniz University in Hanover, is a laboratory information system to which all lab components will be connected and controlled, from 'intelligent', self-cleaning lab benches to smart safety goggles that can project chemical safety information and augmented-reality displays. \u201cTo our knowledge, this is the first attempt ever made to make a whole laboratory digitally supported and interactive,\u201d says Beutel. Existing commercial implementations of the IoT are less comprehensive.  TetraScience , which was founded in 2014 and is supported, in part, by Digital Science (a consultancy in London operated by Holtzbrinck Publishing Group, which also has a share in  Nature 's publisher), has 60 academic and industry clients, says chief executive and co-founder Alok Tayi. At Harvard University, 19 labs use the service, which connects instruments to an online dashboard, says Quentin Gilly, senior coordinator of the Harvard University Office for Sustainability's Green Labs programme. The labs have connected more than 100 devices to the web, mostly incubators and freezers; Turner\u2019s lab has used the system to connect 11 of its instruments. Peter Girguis, who studies the biology of deep oceans, has five freezers and refrigerators at Harvard hooked up to the TetraScience grid. These units are stocked with irreplaceable samples collected during tours on research vessels stationed anywhere from the mid-Atlantic Ocean to the South Pacific. \u201cIt costs millions of dollars to get these samples,\u201d he says. Many of the lab's most precious samples are stored in \u221280 \u00b0C freezers, which are monitored using a system that automatically notifies Harvard's Operations Center when a freezer is over temperature. But the lab's \u221220 \u00b0C freezers and refrigerators are not compatible with the system, and so no one is alerted if they fail. When the opportunity arose to test the TetraScience system, the lab jumped at the chance, says Jennifer Delaney, who manages Girguis's lab. \u201cIt didn't take too much convincing.\u201d TetraScience uses a Wi-Fi module, about the size of a deck of playing cards, that can be hooked up either to an external sensor or through an instrument's data port. Sensors can monitor temperature, humidity, and carbon dioxide and oxygen levels, as well as vibration, light intensity and mass air flow. This type of equipment can supplement internal sensors to ensure that crucial hardware such as incubators and hypoxic chambers are performing as expected. Direct connection through an instrument's data port, allows devices such as balances, pH meters, and even high-performance liquid chromatography systems to be monitored or, in some cases, controlled. Not only can scientists monitor those instruments but they can also stream data to electronic lab notebooks, track the device's usage and workload, and control experimental workflows, Tayi says. \u201cThe goal is a holistic software platform which can tie together people, data and devices.\u201d TetraScience users access those data through a web browser. The page lists all connected devices and their status, and lab managers can set temperature thresholds and alarm options. The system also displays each sensor's history, so users can see, for instance, if a freezer has been slowly warming over several days \u2014 a sign, says Gilly, that it may require a service. Several TetraScience users have expressed frustration over dropped Wi-Fi connections, which sometimes need to be reset manually. The data aren't lost \u2014 the hardware can continue to log them for weeks, dumping them back into the system once connectivity returns \u2014 but according to Tayi, the company has updated its hardware to be \u201cfar more reliable in terms of connectivity\u201d and has added the option of sending data over Ethernet cables and mobile networks. \n               The cost of monitoring \n             Unfortunately for Girguis, his lab has 20 refrigerators and \u221220 \u00b0C freezers, but only 5 sensors. One of those that was not being watched was a small under-bench freezer storing an archive of water samples and DNA sequencing libraries, among other things. Several months ago, a student walked past the freezer and \u201cnoticed an odd smell\u201d, Delaney says. \u201cIt had thawed, everything was covered in mould, it was pretty disgusting, and yeah, everything had been lost.\u201d Girguis estimates that the value of the DNA sequencing libraries alone was about US$4,000. Girguis did consider buying more TetraScience sensors, but the introductory price he was quoted (about $400 per device per year), was beyond the lab's budget. Turner's lab has likewise decided to forgo TetraScience in favour of a consumer-grade IoT system from Wisconsin-based  La Crosse Technology , which costs $12 per freezer per year. Tayi says that TetraScience cannot comment on pricing. Larger firms are also embracing the IoT. US biotechnology company Illumina has the  BaseSpace Sequence Hub , which allows researchers to remotely monitor next-generation DNA sequencing runs, and US lab equipment company Thermo Fisher Scientific has  Thermo Fisher Connect , which can track and process data from six different types of equipment, including real-time and digital polymerase chain reaction (PCR) thermocyclers and mass spectrometers. The system will support a dozen more instruments, including ultralow temperature freezers and even a smart electronic pipette, by the end of 2017, says the company's chief technology officer Mark Field, who is based in Carlsbad, California. Researchers can create a pipetting programme online, which can then be pushed to the lab's pipettes. Such a device could precisely track what the user does, providing better experimental documentation and possibly reducing errors by, for example, indicating which plate well lab technicians should be pipetting into next. With users at more than 10,000 institutions, the Thermo Fisher system is free (although some analysis apps on the platform have a fee). Users can access the system through a web page, and monitor equipment using a dedicated iPhone or Android app called Instrument Connect. The app has a demo mode that allows users to 'track' a fictitious, real-time PCR run. For Jared Farrar, an MD\u2013PhD student at Virginia Commonwealth University in Richmond, who uses the Thermo Fisher system to monitor his real-time PCR runs, the technology allows him to spend more time with his family. At weekends, he says, he can drop into the lab, set up a few reactions, then monitor their progress from his phone to see when he needs to return to swap plates. \u201cThe greatest benefit is it takes me out of the lab,\u201d he says. Iain MacLeod, co-founder and chief scientific officer at Aldatu Biosciences in Boston, Massachusetts, which develops assays to monitor HIV drug resistance, uses Thermo Fisher Connect to monitor and troubleshoot real-time PCR runs in Boston and for field work in Botswana. MacLeod recalls analysing runs on his commute home, sharing screenshots with his co-founder en route. \u201cIt's very quick and easy to do,\u201d he says. But with that convenience comes safety and security concerns. By accessing an IoT-enabled thermostat, for example, a hacker may be able to work out when somebody is on holiday, possibly leaving them vulnerable to break-ins. In a laboratory, hackers could damage hardware or samples, for instance, by adjusting the settings on a freezer or incubator. Girguis says he would probably think twice before relying on an IoT device as the main means of protecting equipment that could be dangerous if misused. Still, for many researchers, those theoretical risks are likely to pale in comparison to the real threat of a freezer dying unexpectedly. From his hotel room, as Turner watched colleagues struggle with the troublesome freezer, it quickly became clear that their efforts were being wasted. He arranged to transfer the lab's samples to a backup freezer, averting catastrophe. \u201cIf we hadn't had these devices, we would have come in Tuesday morning and found a big puddle on the floor and a freezer full of thawed samples.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     The bandwidth bottleneck that is throttling the Internet 2016-Aug-10 \n                   \n                     At Your Command 2016-Jun-14 \n                   \n                     Society: Build digital democracy 2015-Nov-02 \n                   \n                     What could derail the wearables revolution? 2015-Sep-01 \n                   \n                     Power to the Internet of Things 2014-Nov-18 \n                   \n                     Bosch IoT Lab \n                   \n                     smartLAB \n                   \n                     Thermo Cloud Connect \n                   \n                     TetraScience \n                   \n                     Illumina BaseSpace Sequence Hub \n                   Reprints and Permissions"},
{"file_id": "550144a", "url": "https://www.nature.com/articles/550144a", "year": 2017, "authors": [], "parsed_as_year": "2006_or_before", "body": "Nature 's technology editor, Jeffrey Perkel, started blogging about workplace technology in science in 2016. Here are some highlights. \n               \n                   From stadiums to genomes \n                 \n             Most bioinformaticians are either biologists skilled in programming or programmers with an interest in biology. Mike Goodstadt, the programmer behind the 3D genome-visualization tool TADkit, took a different approach. In the early-to-mid 1990s, Goodstadt was a student at the University of Bath, UK. His course of study? Architecture, with an emphasis on 3D modelling. After graduation, he helped to design and build a 61,500-seat stadium. But a faltering economy and newly acquired programming skills helped to steer him towards biology. \n               \n                   Lorena Barba, reproducibility champion \n                 \n             Lorena Barba, a mechanical and aerospace engineer at George Washington University in Washington DC, has long championed research reproducibility. \u201cI've always believed that the open-source model is ideal for science, as it exposes the complete sequence of steps that produces a given result,\u201d she says. In January, she travelled to Chile to run a week-long course on reproducible research computing. The month before, she had been awarded a 2016 Leamer-Rosenthal Prize, which celebrates those \u201cworking to forward the values of openness and transparency in research\u201d. In this Q&A, she talks flying snakes, 'repro-packs' and copyright. \n               \n                   The sound of DNA \n                 \n             With an alphabet comprising just four letters, a DNA sequence isn't much to look at. So when sequence-analysis tools want to highlight key elements, they typically do so using colour or font, or by overlaying other types of information. In the not-too-distant future, there may be another option. Molecular biologist and part-time drummer Mark Temple at Western Sydney University, Australia, describes DNA sonification, \u201can auditory display tool\u201d for DNA: sequence in, audio out. \u201cI'm not saying audio by itself is the bees' knees for interpreting DNA sequence,\u201d Temple says, \u201cbut surely audio can contribute to your visual interpretation.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Nature Technology blog \n                   \n                     Nature Toolbox \n                   Reprints and Permissions"},
{"file_id": "541123a", "url": "https://www.nature.com/articles/541123a", "year": 2017, "authors": [{"name": "Jeffrey M. Perkel"}], "parsed_as_year": "2006_or_before", "body": "Eight ways labs benefit from the popular workplace messaging tool. When geneticist Daniel MacArthur checks into his lab, the first thing he does is fire up  Slack , a workplace messaging app. In the system, he zips through the hundreds of messages and files left in different channels by the lab's 23 scientists \u2014 some reporting on their projects, others requesting help. The lab's members have posted more than 400,000 messages on Slack since April 2014 \u2014 a rate of nearly 500 per day. For MacArthur, who works at the Broad Institute of MIT and Harvard in Cambridge, Massachusetts, the tool has rendered irrelevant many of the ways that his lab previously used to communicate about papers and projects \u2014 especially e-mail. E-mail, says MacArthur, is \u201cgenuinely awful\u201d and \u201cactually disastrous for group communication\u201d. His inbox, a jumble of vendor announcements, administration notices and other random requests, contains some 17,500 unread items. Slack, by contrast, is focused: because every post comes from a team member, the signal-to-noise ratio is high. Most days, MacArthur is able to clear all unread messages. \u201cI have a lot more discipline making sure I am up to date,\u201d he says. MacArthur's lab isn't the only scientific group that swears by Slack, which was launched just 3 years ago, but now boasts more than 3 million active daily users worldwide, and which has rapidly become popular with media organizations and technology firms. Billed as 'team communication for the twenty-first century', Slack is a platform on which groups can share files, data, news and jokes, and generally track their work. It provides base-level free accounts but charges users to store more than the latest 10,000 messages. As MacArthur's lab has done, users can set up their own invitation-only pages \u2014 say, at ' mylab.slack.com ' \u2014 and organize conversations into searchable public or private channels. The platform lends itself to much more informal, and thus easier, communication than e-mail, notes Konrad Karczewski, a geneticist and postdoc in MacArthur's lab. \u201cI'm just typing whatever comes into my head, as if we were having a face-to-face conversation, but online.\u201d That can be especially valuable for teams that are scattered across work sites or that work different shifts. Guillaume Delbergue, a computer engineer at IMS Bordeaux in France, says he sometimes works in the lab, sometimes from home, and occasionally from another city. Another member of his lab is based in Canada. Using  MatterMost  \u2014 an open-source Slack alternative, which Delbergue chose in order to assuage privacy concerns \u2014 those teammates can stay in constant contact. \u201cYou can easily bridge people on the shared chat tool,\u201d he says. Slack doesn't really do anything that other messenging apps cannot in part provide, MacArthur says. It has competitors such as MatterMost and Atlassian's  HipChat , as well as older messenging apps such as Google Chat. But a number of labs have fallen in love with Slack; researchers cite its simple and fluid user interface, and its ability to incorporate 'bots': automated scripts (also called plug-ins) that can import outside information into the platform or can launch other software if particular commands are typed. Here are eight ways that scientists are using Slack in their labs. \n               Honing research papers \n             Slack figured heavily in MacArthur and his colleagues' preparation of a  Nature  publication on the ExAC database, which involves some 60,000 human exome sequences ( M. Lek  et al. Nature   536,  285\u2013291; 2016 ). The team set up a dedicated channel for the in-development manuscript, allowing the entire group to weigh in on the text and figures. As graphs were generated, they were posted and refined on the basis of comments from the group, typically with five to ten iterations in under an hour, as people used Slack to suggest tweaks in formatting, legend text and statistical approaches. In the end, some 10,000 messages were posted to that channel alone, MacArthur says, and yet the process was still faster than if these changes had been discussed in, say, weekly meetings. \u201cIt's a remarkably quick way of building consensus around often pretty complicated and subtle scientific topics, and that was exactly what the ExAC paper was all about,\u201d he says. \n               Attending conferences \n             Nuclear engineer Clair Sullivan's lab at the University of Illinois in Urbana-Champaign has 28 people actively participating in Slack, including 9 graduate students, a postdoc, several undergraduates and a handful of lab alumni. The Slack is divided into seven channels. There's one for each of the lab's two main projects, channels for the lab's projects on the GitHub file repository and general lab business, a 'random' channel \u2014 for jokes or \u201coh, hey, half-off pizza\u201d \u2014 and a channel devoted to the lab's running team. The last channel, Sullivan says, is for conferences \u2014 a place for attendees to discuss talks, posters and social outings without clogging other feeds, and to keep interested lab members up to date about what's happening. Another benefit: Sullivan can update her presentations on the go. \u201cI could be in an airplane at 35,000 feet and people are giving me figures for my talk,\u201d she says. \n               Monitoring experiments \n             At Ginkgo Bioworks, a synthetic-biology firm in Boston, Massachusetts, each of the company's 100-plus employees uses Slack, mostly for \u201creal-time messaging and real-time updates\u201d. says software engineer Dan Cahoon. The team also uses Slack to monitor instrumentation runs, using a dedicated plug-in, in which messages to a special e-mail address result in posts to a particular Slack channel. The integration requires no special programming, as the company's liquid-handling robots, which form the core of its workflow, already have the ability to send an e-mail when a job status changes. By simply directing those systems to send their messages to the appropriate address, the team can track its jobs through the company Slack. A simple integration thus becomes exceptionally powerful, Cahoon says. \u201cWe don't need to write, say, a custom thing that understands what the robot is doing if they provide something that can then just be hooked up this way.\u201d \n               Building custom plug-ins \n             Slack offers an  extensive collection of plug-ins , but researchers can also build their own (see  go.nature.com/2htqpgx  for a detailed tutorial). Ginkgo Bioworks developers, for instance, created a custom bot that controls keycard-activated doorways in the company offices, to help users who inadvertently leave their ID card on their desk. \u201cThey can go into Slack, message the bot, 'open door 27 East, front door,' and then it'll open it for a minute, just like the card,\u201d Cahoon says. \n               Recognizing colleagues' input \n             Using the  Bonusly plug-in , members of computational biologist Casey Greene's team at the Perelman School of Medicine at the University of Pennsylvania, Philadelphia, can acknowledge colleagues' contributions by awarding points. Suppose one lab member posts a question to a given channel, and another answers it. The questioner can acknowledge that person by typing '/give [amount] [username] [reason] [#hashtag]' in Slack to award points. One lab member won points for encouraging their co-workers to get their flu vaccinations, says Greene (#herdimmunity). Bonusly points are usually used as credit towards a gift card; Greene uses them to buy the lab a free lunch. \u201cIt's nice to have a way to thank your peers and have the recognition be shared in our primary Slack channel,\u201d he says. \n               Creating lab-wide to-do lists \n             A number of Slack plug-ins (see  go.nature.com/2hifxps  for an example) allow labs to manage to-do lists on a per-channel and per-user basis. Nathan Clack, lead software developer at a brain-imaging firm, Vidrio Technologies in Ashburn, Virginia, uses a system that is baked into the programs. Just type '/remind me to check the incubator at 4 pm' and Slack will send a notification at the given time. Users can assign reminders to other team members or entire channels \u2014 '/remind @jeff to check the incubator at 4 pm' \u2014 and even direct the system to remind them to review a given post in, say, 24 hours. \u201cIt's super-useful,\u201d says Clack. \u201cI love that.\u201d \n               Briefing new lab members \n             Slack channels are searchable, which makes it easy to bring new lab members \u2014 or simply interested lab members working on other projects \u2014 up to speed on a particular study, says Gleb Kuznetsov, a PhD student studying genome engineering and bioinformatics in George Church's lab at Harvard Medical School in Boston. Just get them to join the appropriate channel and start reading. It's easier than searching through old e-mails or asking colleagues to forward key message threads, Kuznetsov says. \u201cWhether you're directly involved in the conversation or watching from afar or joining later on, you can get the level of awareness you need.\u201d \n               Blowing off steam \n             From a plug-in that searches the Giphy website for animated gifs matching a given keyword, to an assortment of baked-in and custom emoji \u2014 see, for instance,  Cult of the Party Parrot , a collection of animated bobbing parrot heads \u2014 many labs set up dedicated channels to contain their zaniness. Ginkgo Bioworks has a channel devoted to an offbeat Paul Rudd YouTube skit, called #zany-4D3D3D3. \u201cWe call that 'the place for whimsy',\u201d says Cahoon. MacArthur's lab has a #spiders channel \u2014 a home for \u201cparticularly horrifying\u201d animated spider pics. \u201cI'm not really sure why [the channel] exists,\u201d MacArthur admits \u2014 though he allows it could be his comfort with spiders that comes from an Australian upbringing \u2014 \u201cbut it is a thing that gives me tremendous pleasure every time I look at it, for reasons that I cannot articulate to anyone.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Lab-inventory management: Time to take stock 2015-Aug-03 \n                   \n                     The automated lab 2014-Dec-03 \n                   \n                     Scientific writing: the online cooperative 2014-Oct-01 \n                   \n                     \n                         Nature Toolbox \n                       \n                   \n                     Slack \n                   \n                     Mattermost \n                   \n                     Hipchat \n                   Reprints and Permissions"},
{"file_id": "550143a", "url": "https://www.nature.com/articles/550143a", "year": 2017, "authors": [{"name": "Andrew Silver"}], "parsed_as_year": "2006_or_before", "body": "Save time and protect critical code with 'continuous integration' services. Sebastian Neubert, a particle physicist at Heidelberg University in Germany, leads a group studying subatomic particles called pentaquarks. The six team members all have access to the software code used to run their multi-step analyses, and the programmers update it daily with new features and bug fixes. With each code change, however, they run the risk of introducing inadvertent errors that foul the underlying algorithms. To prevent that, the team checks and rechecks the analyses, and uses error-checking algorithms, functions they can call whenever a change is proposed, to ensure that their software works as intended. One test, for example, verifies that a noise-cancelling algorithm gives the correct output when it is run on practice data. In 2015, in an effort to save time and resources, the team took inspiration from the technology industry, automating their testing using a process called 'continuous integration'. In continuous integration, changes to software code automatically trigger repetitive tasks, such as error-checking. Fundamentally, the process simplifies a task that diligent coders already perform. Programmers usually write lists of tests that they will run periodically to ensure that their code still works, just as Neubert's team do. But a busy team might forget or lack the time to run them, allowing errors to creep in. Continuous integration automates that process so those checks run whenever a change is proposed, saving team members the time they would spend hunting down an error. A team running genomic analyses could spend more time at the bench, while a group developing climate-prediction software could better refine its models. That said, the resulting peace of mind is only as good as the tests themselves: a poorly designed test can still allow mistakes to pass undetected. The process is common in the commercial and open-source sectors. A  study  presented at the 2016 IEEE/ACM International Conference on Automated Software Engineering in Singapore found that about 40% of the 34,544 most-popular open-source projects hosted on the coding collaboration site GitHub used continuous integration in some form. Only a few of those open-source projects might be considered scientific software, but an increasing number of scientists are looking to continuous integration to automate all sorts of time-consuming tasks, from testing code to updating documents with the latest data. Researchers at institutions such as CERN, Europe's particle-accelerator laboratory near Geneva, Switzerland; the Pacific Northwest National Laboratory in Richland, Washington; and the Ontario Institute for Cancer Research in Toronto, Canada, have embraced the practice, but adoption in the scientific sector remains relatively sparse. For Neubert, continuous integration ensures that the pipeline's behaviour remains correct and consistent as his team refines its code, providing an \u201cincredibly valuable\u201d safeguard. \u201cThere is a real danger of just missing something or making a slight mistake,\u201d he says. \n               Exceptions \n             A variety of continuous integration services exist. These include the open-source Drone, and commercial options such as CircleCI, Codeship, GitLab, Shippable and Travis CI, all of which offer pricing tiers based on the desired testing behaviour, number of users and whether the project is public or private. Travis CI, for instance, is free for open-source projects; private projects cost from US$69 per month. Shippable offers a free basic service for public projects, but charges $25\u2013150 per month for support for private projects and greater computing power, among other features. Researchers should consider what is a suitable and worthwhile investment, however. Not every project needs continuous integration and setting up and configuring a service can be challenging. Further difficulties can arise if the services need to interact with software or data with legal restrictions on its use, says Daniel Himmelstein, a data-science postdoc at the University of Pennsylvania in Philadelphia. Also, code is often used only once, making the cost even less worthwhile. \u201cFor day-to-day research coding, the amount of code is not large enough to make continuous integration valuable,\u201d says Andrea Zonca, a specialist in high-performance computing at the University of California, San Diego. He uses Travis CI when publishing code, but most that he writes is for his own one-time use and is not executed again. Computing costs can also mount if code is being constantly updated and requires repeated testing, which is why Neubert's lab only tests its most critical data analyses after code changes. Despite these challenges, continuous integration services tend to improve code quality, says Bj\u00f6rn Gr\u00fcning, a bioinformatician at the University of Freiburg in Germany, especially on large projects such as Galaxy, a bioinformatics toolkit that Gr\u00fcning, along with about 160 others, contributes to. According to Gr\u00fcning, continuous integration has shortened the turnaround time for approving contributions to the Galaxy project and given programmers more confidence when submitting new features and fixes. Before these services were available, it was often impractical for researchers in such projects to test every new feature collaborators proposed because they didn't have the time, he says. Some researchers use continuous integration to automate non-programming tasks. In April, as part of a project studying how ecosystems change over time, Ethan White, an ecologist at the University of Florida in Gainesville, helped to configure Travis CI to update tables and plots automatically with new field or weather-station data, saving the research team up to 5 hours a month. Continuous integration helps Himmelstein automate revisions to scientific papers, citations and web pages following text or code updates. Without continuous integration, he says, human maintainers would probably \u201cget lazy and update the manuscript less frequently than every change\u201d. \n               Initializing \n             Whether hosted externally by a third party or on a user's own machine, the continuous integration service is controlled with a custom set of instructions. This configuration file defines the tasks to be run and sets up the server with the correct environment \u2014 the operating system and software libraries \u2014 required to run them. The service then executes those instructions at set times or on receipt of a code or data update. University of Pennsylvania bioinformatician Casey Greene, who uses continuous integration to rerun his data analyses, has tested many of today's most popular services. \u201cThe good news about all of these services is that they're quite similar,\u201d he says. Subtle differences do exist, for instance in the number of concurrent jobs users can run, or the amount of computing power available to run them. \u201cI'd encourage people to dig into the limits of each service to make sure they are compatible with their workflows,\u201d advises Greene. Although continuous integration adoption in science right now is small, it is growing, and more researchers should get on board, Greene says. Getting up to speed takes time, he acknowledges, but often, the effort is worth the reward. \u201cScientists analysing data should have it in their toolbox.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Toward standard practices for sharing computer code and programs in neuroscience 2017-May-25 \n                   \n                     Reproducibility of computational workflows is automated using continuous analysis 2017-Mar-13 \n                   \n                     OpenMS: a flexible open-source software platform for mass spectrometry data analysis 2016-Aug-30 \n                   \n                     Nature Toolbox\u00a0 \n                   \n                     Travis CI \n                   \n                     GitLab \n                   \n                     Shippable \n                   \n                     Drone \n                   \n                     CircleCI \n                   \n                     Codeship \n                   Reprints and Permissions"},
{"file_id": "549117a", "url": "https://www.nature.com/articles/549117a", "year": 2017, "authors": [{"name": "Jeffrey M. Perkel"}], "parsed_as_year": "2006_or_before", "body": "Inspired by Google Maps, a suite of tools is allowing researchers to chart the complex conformations of chromosomes. Chromatin does much more than just keep DNA neat and tidy. This complex of genomic DNA and protein assumes many different structures and conformations, which can affect the expression of the genes wrapped around it. In certain conformations, two sequences that are far apart in the linear DNA might actually be located next to each other and influence each other's activity; in other conformations, they might be far apart. Erez Aiden was a graduate student at the Massachusetts Institute of Technology in Cambridge when he co-developed a technology that, for the first time, revealed the landscape of chromosome folding on a genomic scale. Hi-C details the DNA loops and structural domains that influence gene expression, and can even help to piece together complex genomes. The data take the form of 2D matrices detailing chromatin contacts, but in 2009, Aiden had no easy way to explore them. So, he improvised. \u201cI would simply print out Hi-C matrices at multiple resolutions and I would use up hundreds of pages of paper,\u201d he recalls. \u201cI would find the biggest conference table I could and I'd just array printed pieces of paper in front of me in order to be able to see a big chunk of the matrix.\u201d \u201cIt was a great interface,\u201d Aiden says. Still, he concedes, a more environmentally sustainable \u2014 and sharable \u2014 approach was required. The result was  Juicebox , a Java-based desktop application that provides Google Maps-style exploration of chromatin-interaction data. It allows researchers to zoom from the genome level down to small structural features. Released in 2014, Juicebox has been downloaded some 14,000 times, Aiden says, and a  browser-based version  launched this year. Juicebox is just one of a range of freely available programs for exploring 2D interaction data: some focus on relatively narrow chromosomal loci, whereas others enable genome exploration. A growing subset infers 3D structures from 2D matrices. But all reflect the growing richness of chromatin-interaction data sets, not to mention the influence of funding initiatives such as the 4D Nucleome Project. \u201cBecause [the data] have become so complex, visualization just became a lot more important,\u201d says Peter Park, a bioinformatician at Harvard Medical School in Boston, Massachusetts. The University of California, Santa Cruz (UCSC)  Genome Browser  is one of the most popular portals for exploring genomic data. Like most genome browsers, it renders sequence data as a linear array of letters decorated with epigenetic features, such as histone modifications and methylation sites, displayed in 1D 'tracks'. Hi-C, however, generates 2D matrices. The technology identifies sequences that are far apart in the linear DNA sequence but close neighbours in 3D space. \u201cYou look at a pair of positions in the genome, and it tells you often they bump into one another,\u201d Aiden explains. Typically, those data are rendered as heat maps, with colour intensity reflecting the interaction frequency between two points. Aiden and his co-developers, including James Robinson of the University of California, San Diego (UCSD), took inspiration from Google Maps, in which users can seamlessly zoom from the global to the street level. The entire data set is massive, but Google doesn't deliver it all at once. Instead, the software \u201cdivides the world into tiles at different resolution\u201d, says Robinson. At any one time, users view just a handful of tiles, which are organized to make adjacent tiles easy to fetch. \u201cAs long as you can always get to the four you're looking at quickly, you can support an interactive map,\u201d he says. Similarly, Juicebox 'hic' files store precomputed tile sets for each possible chromosomal pair at multiple resolutions. A look-up table speeds access by allowing the software to retrieve data without having to search. As a result, Juicebox users can seamlessly explore an entire genome's worth of interactions, and then zoom in to view fine-scaled features. Users can access any of several hundred precomputed contact maps that the Aiden lab has made publicly available, or view their own. They can overlay those data with standard browser tracks, such as gene locations or histone marks, either from their own studies or from public repositories. Binding sites for the DNA-binding protein CTCF, for instance, highly correlate with chromosomal loops. And they can flag and record features of interest. \n               Genomes in sync \n             HiGlass , a web-based tool launched in March by biomedical informatician Nils Gehlenborg at Harvard Medical School, also provides a Google Maps-like experience. As with Juicebox, researchers can import genomic tracks to help make sense of what they're seeing, but HiGlass also allows them to open multiple HiGlass views in one browser window and synchronize them so that they always display the same region. That way, Gehlenborg says, researchers can compare chromatin conformations across different conditions or experiments. \u201cWe are enabling the investigators and the analysts to generate new hypotheses,\u201d he says. (The browser-based version of Juicebox also allows multiple synchronized views per window, Aiden says; users of the desktop Juicebox app can synchronize maps across different windows, but not in a single display.) Gehlenborg's team has established a HiGlass server for exploring publicly available data. Researchers who need to analyse custom data sets must install the software locally; a Docker container is available for that purpose. Both Juicebox's web version and HiGlass allow users to create sharable URLs that point to specific views of the data \u2014 a feature that Aiden calls his software's \u201ckiller app\u201d. Suppose a user notices that a genomic structure overlaps perfectly with particular 1D track, he says. \u201cYou just take that URL, copy it, and you can tweet it. And all the people who receive the tweet can just click on it and boom! They get the exact same configuration that you had now on their computers as well.\u201d Two other visualization options, the 3D Genome Browser and the WashU EpiGenome Browser, provide more localized views. Users select a locus of interest and the browsers display contacts in the area. Whereas Juicebox and HiGlass render heat maps as squares divided diagonally into two mirror images, these browsers show heat maps as triangles \u2014 that is, half of the square, without its mirror image. \u201cWe cut down the half that is redundant information,\u201d says genome biologist Bing Ren at UCSD. (The WashU browser can also display contact data as arcs connecting linked regions.) That change may sound trivial, but according to Feng Yue of Pennsylvania State University in Hershey, who developed his first 3D Genome Browser prototype as a postdoctoral researcher with Ren, it makes it easier to identify functional regions. The 3D Genome Browser, for instance, allows its users to align heat maps from two species, one atop the other, to assess the evolutionary conservation of folding architecture. A 'virtual-4C' mode allows users to query Hi-C data sets for sequences interacting with a specific genomic locus, providing a window into interactions between gene-regulatory regions. Another option is GIVE, released by bioengineer Sheng Zhong and his colleagues at UCSD. This allows researchers to incorporate a fully functional genome browser, including a 2D contact data viewer, into their personal or lab web pages with just a few lines of HTML code. Researchers can thus share data with colleagues, publish it alongside their manuscripts, or explore it themselves \u2014 all with about 20 minutes' work, says Zhong. Francesco Ferrari, a computational biologist at the FIRC Institute of Molecular Oncology in Milan, Italy, visualizes his Hi-C data using the R programming language and the Bioconductor software library. These text-based programs lack the interactivity of other software, but because the team already runs data analysis using R and Bioconductor, Ferrari explains, \u201cit's just more convenient\u201d to use them for visualization as well. The Bioconductor package  HiTC  provides Hi-C visualization tools, as does the  Python library HiCPlotter . \n               Going 3D \n             Ultimately, 2D contact matrices imply 3D structure. After all, if two regions interact, they are probably in close physical proximity. Increasingly, some researchers are using their 2D data to compute and visualize 3D structures directly. Csilla V\u00e1rnai, a postdoc at the Babraham Institute in Cambridge, UK, helped to produce the 3D models for a single-cell Hi-C study earlier this year ( T.\u00a0Nagano  et\u00a0al. Nature   547,  61\u201367; 2017 ). She used a generic molecular modelling package called Gromacs to model a chromosome as a string of beads \u2014 each representing about 100 kilobases \u2014 and then asked it to fold, using the Hi-C contacts as 'constraints' on that process. Other packages have been designed specifically to model chromatin structure. Chrom3D, developed by bioinformatician Jonas Paulsen at the University of Oslo blends Hi-C data with information on proximity to the nuclear envelope to model the position of chromosomes in the nucleus. \u201cThat matters a lot for gene regulation,\u201d Paulsen explains. Genes near the nuclear periphery tend to be repressed, whereas more centrally located genes are usually active. Another tool, TADkit, from Marc Mart\u00ed-Renom and Mike Goodstadt at the National Center for Genomic Analysis\u2013Center for Genomic Regulation in Barcelona, Spain, allows users to view 3D chromosome models alongside the corresponding 2D heat map and 1D tracks. Selecting a feature in one representation highlights overlapping features in the others. It remains to be seen what insights such 3D representations can provide that 2D heat maps cannot, especially as most Hi-C data sets represent millions of cells, rather than a single structure. Leonid Mirny, a bioinformatician at the Massachusetts Institute of Technology, likens the resulting data to averaging a batch of photographs to determine what a typical person looks like. \u201cIt's not going to be actually representative of anyone whom you take pictures of,\u201d he says. Also unclear is which tool, if any, will emerge as the de facto standard for genome visualization. Debate on that front is ongoing, says Zhong. When it comes to genome biology, says Ren, visualization is key. Analytical tools are based on statistics, he explains; sometimes they miss things, and sometimes they detect features that aren't there. \u201cAt the end of the day, nothing replaces looking at the data yourself.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Cell-cycle dynamics of chromosomal organization at single-cell resolution 2017-Jul-05 \n                   \n                     Comparison of computational methods for Hi-C data analysis 2017-Jun-12 \n                   \n                     DNA's secret weapon against knots and tangles 2017-Apr-19 \n                   \n                     Zika mosquito genome mapped \u2013 at last 2017-Mar-23 \n                   \n                     3D structures of individual mammalian genomes studied by single-cell Hi-C 2017-Mar-13 \n                   \n                     Massively multiplex single-cell Hi-C 2017-Jan-30 \n                   \n                     Nature Toolbox \n                   \n                     Epigenetics @ Nature Reviews Genetics \n                   \n                     Juicebox \n                   \n                     HiGlass \n                   \n                     3D Genome Browser \n                   \n                     WashU EpiGenome Browser \n                   \n                     4D Nucleome Project Software \n                   Reprints and Permissions"},
{"file_id": "d41586-017-05922-9", "url": "https://www.nature.com/articles/d41586-017-05922-9", "year": 2017, "authors": [{"name": "Dalmeet Singh Chawla"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "d41586-017-07833-1", "url": "https://www.nature.com/articles/d41586-017-07833-1", "year": 2017, "authors": [{"name": "W. Wayt Gibbs"}], "parsed_as_year": "2006_or_before", "body": ""},
{"file_id": "543137a", "url": "https://www.nature.com/articles/543137a", "year": 2017, "authors": [{"name": "Jeffrey M. Perkel"}], "parsed_as_year": "2006_or_before", "body": "Computational biologists are starting to develop user-friendly platforms for analysing and interpreting genetic-sequence data. For doctors trying to treat people who have symptoms that have no clear cause, gene-sequencing technologies might help in pointing them to a diagnosis. But the vast amount of data generated can make it hard to get to the answer quickly. Until a couple of years ago, doctors at US Naval Medical Research Unit-6 (NAMRU-6) in Lima had to send their sequence data to the United States for analysis, a process that could take weeks \u2014 much too long to make pressing decisions about treatment. \u201cIf all you could do was get the data that you then have to ship to the US, it's almost useless,\u201d says Mariana Leguia, who heads the centre's genomics and pathogen-discovery unit. But Leguia no longer has to wait for the analyses; she can get results in days or even hours \u2014 and she can do them in her own lab. Her unit makes use of EDGE (Empowering the Development of Genomics Expertise), a bioinformatics tool that hides common microbial-genomics tasks, such as sequence assembly and species identification, behind a slick interface that allows users to generate polished analyses. \u201cWe can have actionable information on site that allows us to make decisions very quickly about how to go forward,\u201d Leguia says. EDGE isn't the first tool to simplify informatics with a point-and-click interface. Indeed, it lacks much of the flexibility and scope of more established alternatives such as Galaxy and Illumina's BaseSpace platform. But its simplicity is drawing in users who might otherwise shun bioinformatics. \u201cPeople have used [EDGE] who would never have bothered learning command-line tools,\u201d says Clinton Paden, who uses EDGE in his work on virus pathogenesis at the US Centers for Disease Control and Prevention in Atlanta, Georgia. As such, it represents a case study in democratizing genome informatics \u2014 one that could help to accelerate uptake of the field by pure biologists. \n               Informatics in the field \n             Patrick Chain, who led the development of the software 1 , at Los Alamos National Laboratory (LANL) in New Mexico, says that EDGE was created to try to square the rapidly growing availability of low-cost DNA sequencers with the relative paucity of know-how required to make sense of the data. It is designed for use in facilities that lack expertise in bioinformatics, says Joe Anderson, a computational biologist who honed the software for military applications at the Biological Defense Research Directorate (BDRD) at the Naval Medical Research Center in Frederick, Maryland. It is also open-source, self-contained and provides end-to-end analyses for microbial genomics, from raw sequence reads to species identification and phylogeny in a single click. The system is also relatively cheap to run because the recommended hardware configuration (256 gigabytes of memory and 64 processors) can be bought for less than US$10,000, says Anderson. This means that most labs that can afford to run sequencing projects can afford the hardware. \u201cThat's not throw away money, but it's cheap enough,\u201d he says. It also helps that the set-up doesn't rely on an Internet connection and can be powered by a generator. Users with reliable network connections can install the system to a cloud network. Nicholas Loman, a bioinformatician at the University of Birmingham, UK, points to CLIMB, the Cloud Infrastructure for Microbial Bioinformatics, which he helped to develop. CLIMB is a free service specifically dedicated to academics in the United Kingdom who are working on microbial genomics. CLIMB was supported by \u00a38.4 million (US$10.5 million) from the UK Medical Research Council and incorporates several informatics tools, including sequence databases and an analysis workbench known as the Genomics Virtual Laboratory. \u201cI'm definitely thinking about having EDGE as a possible option on there as well,\u201d Loman says. Overall, EDGE has been officially installed at 18 US Department of Defense and partner-nation labs, and on every continent except Antarctica, says Theron Hamilton, who is head of genomics and bioinformatics at the BDRD. One of those is in Phnom Penh at the NAMRU-2 facility, which uses the system to track vector-borne diseases. \u201cIt's not traditionally the kind of place you would go to do bioinformatics,\u201d says Anderson. But EDGE is changing that. \u201cOne of the things I've realized is that, if you give [researchers] tools and get out of the way, they will amaze you,\u201d Anderson says. The latest version of EDGE \u2014 version 1.5, released last October \u2014 includes 54 third-party tools. All components, including algorithms, databases, visualization tools and reference genomes, are housed on a server that drives six interlocking analysis modules: sequence clean-up; assembly and annotation; comparison to reference genomes; taxonomic identification; evolutionary analysis; and PCR primer design. Additional modules, including RNA analysis and pathogen detection, are slated for the upcoming EDGE 2.0, Chain says. Last November, Chain and his colleagues demonstrated EDGE's capabilities in a study in which they used the platform to assemble, classify and map the evolutionary relationships in isolates of the bacteria  Bacillus anthracis  and  Yersinia pestis ; to untangle a mock human microbiome; and to analyse a series of human clinical samples, including cases of Ebola virus and  Escherichia coli  infection 1 . But the first published use of the system actually pre-dates that study by several months. Leguia's lab used EDGE to optimize methods for whole-genome sequencing of dengue virus \u2014 in a study published last June 2 . Users can explore those and other data sets using a free demo hosted on the LANL server. Researchers who wish to analyse their own sequences must install the software on their own systems. The code is freely downloadable from GitHub, and a Docker container and virtual machine image are available, but an information-technology expert will probably be required to handle the installation, says Chain. It is possible to tweak the source code to add other tools and workflows, but that's beyond the capabilities of many users, Chain acknowledges. A mechanism to simplify the process is in development, he says. Paden, who has a background in computer science, says that the tool's simplicity makes computational biology accessible to researchers who might otherwise be intimidated by the usual tool for bioinformatics work \u2014 the computer's text-based command line. But Titus Brown, a computational scientist at the University of California, Davis, warns that some of the benefits of EDGE are tempered by shortcomings that could limit the software's long-term use. He describes EDGE as an example of \u201copinionated software\u201d. \u201cIt gives you a small set of software to run that's been tuned to a specific set of examples,\u201d he says, \u201cand it gives nice graphical summaries and outputs.\u201d But, he notes, it isn't clear how other researchers might help to improve the tool, nor what will happen should its funding dry up. Chain says that the team made EDGE open-source partly because of concerns over future funding, which are also informing future development plans. \u201cSustainability is a question we have to think about,\u201d Chain says, \u201cwhich is why we're going to try to allow third-party implementers to much more easily plug-and-play their projects, most likely using Docker. \n               A galaxy of tools \n             EDGE is not the first bioinformatics system to offer a user-friendly interface. Galaxy, first published 3  in 2005, allows researchers to assemble informatics pipelines from a vast and flexible toolbox of free software offered through a web-based interface. Users can solve nearly any problem they can dream up by combining these tools in different ways. But Galaxy can be intimidating to use. And, unlike the graphical representations generated by EDGE, such as phylogenetic trees or interactive 'Krona' plots of taxonomic data in hierarchical pie charts, Galaxy's output tends to take the form of processed data files, which the user then needs to take elsewhere to visualize. \u201cGalaxy is more like a kitchen, but there's no dining room,\u201d says Jeremy Leipzig, a software developer in the Department of Biomedical and Health Informatics at the Children's Hospital of Philadelphia, Pennsylvania. \u201cThe system is not really there for coming up with a way of delivering that output in an appealing way,\u201d he says. \u201cWith EDGE, they've actually thought about what the reports should look like\u201d. Nathan Watson-Haigh, a bioinformatician at the University of Adelaide in Australia, says that EDGE could help to ease pressure on overworked bioinformaticians. But he cautions that it remains a complicated bioinformatics tool, and biologists who are inexperienced in computation would be wise to consult an expert before placing too much certainty in their results. As with any tool, they need to understand what the algorithms are doing, and how different parameters affect their output, adds Kathleen Fisch, interim director of the Center for Computational Biology and Bioinformatics at the University of California, San Diego. \u201cJust because you can run the tools doesn't mean that you should run the tools.\u201d Still, as bioinformatics tools get ever easier, informatics could lose some of its aura of complexity. And for biologists, that could lead to wider adoption \u2014 and democratization. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @j_perkel \n               \n                     Real-time, portable genome sequencing for Ebola surveillance 2016-Feb-03 \n                   \n                     Building the foundation for genomics in precision medicine 2015-Oct-14 \n                   \n                     Charting a course for genomic medicine from base pairs to bedside 2011-Feb-09 \n                   \n                     EDGE bioinformatics \n                   \n                     BaseSpace \n                   \n                     Galaxy \n                   Reprints and Permissions"},
{"file_id": "nature.2017.21765", "url": "https://www.nature.com/articles/nature.2017.21765", "year": 2017, "authors": [{"name": "Dalmeet Singh Chawla"}], "parsed_as_year": "2006_or_before", "body": "New tool joins a growing collection of software for accessing fee-for-view scientific literature. An online widget that trawls the Internet searching for free-to-read versions of paywalled papers has been installed more than 10,000 times since its  prerelease debut  on 10 March, its inventors say.\u00a0 Officially launched on 4 April,  Unpaywall  is a free web-browser extension that hunts for papers in more than 5,300 repositories worldwide, including preprint servers and institutional databases.Once installed in Google Chrome or Mozilla Firefox, Unpaywall brings up a green or grey tab on the side of the screen when a user hits a paywalled paper. A green \u2018unlock\u2019 sign means that a free version of the paper is available elsewhere, whereas a grey \u2018lock\u2019 icon means that the tool could not locate a free version.For researchers and librarians, Unpaywall and a growing collection of similar tools promise to simplify the process of finding freely accessible (and legal) copies of research articles.Holly Bik, a marine biologist at the University of California, Riverside, says Unpaywall is especially useful when she is off campus. \u201cI can quickly access and download PDFs of journal articles without having deal with the hassle [of] logging into a VPN connection to access my university journal subscriptions,\u201d she told  Nature . And author Nicola Twilley, a contributing writer to  The New Yorker  who is based in Brooklyn, New York,  took to Twitter on 23 March  to point out that Unpaywall found her a free version of a study half an hour after she installed it. \u201cI am constantly looking for ways to get hold of academic papers as source material,\u201d she wrote in an e-mail.Rick Anderson, associate dean for collections and scholarly communication at the University of Utah in Salt Lake City, says that Unpaywall could alter the calculus that librarians use when choosing subscriptions.\u201cFor years, libraries have had little expectation that the [open access] deposit of subscription articles would displace subscription access, mainly because locating those articles and providing access to them would be labor-intensive,\u201d Anderson says. \u201cBy making that process so much easier, Unpaywall could really change the game for us.\u201d \n             Bots galore \n           Of course, readers have had the ability to find article PDFs online for years, thanks to Google and Google Scholar. But these tools do not always retrieve free articles, says Jason Priem, Unpaywall's co-inventor. That's where Unpaywall and other services come in. At its heart, Unpaywall provides a simple interface into a database of digital object identifiers (DOIs) \u2014 some 86 million in all. In October 2016, Priem and co-inventor Heather Piwowar, who together founded the not-for-profit company Impactstory in Vancouver, Canada, launched  oaDOI , an 'application programming interface' (API), or set of programmatic instructions, that allows researchers to search that database for papers on the basis of their DOI. oaDOI is used more than a million times per week, according to Priem; it successfully finds an open-access version of a paper around 30% of the time. Unpaywall basically queries that same database automatically, flagging articles for which a free version is available. oaDOI, in turn, draws inspiration from  DOAI  (Digital Open Access Identifier), says Priem. DOAI is described on its homepage as an \u201calternate DOI resolver\u201d that redirects requests to the free version of an article, if available, and otherwise to the paywalled paper itself.According to Piwowar, both oaDOI and Unpaywall include a nimble title-matching feature, which uses an algorithm to compare titles, forgiving spacing and punctuation differences. The idea is to overcome the fact that titles change in different versions of manuscripts, she explains.More than 600 libraries worldwide are using oaDOI, Priem says. The National Library of Sweden, for instance, uses oaDOI in their SwePub analysis system, which integrates the metadata of research published at all of Sweden\u2019s research institutions.\u201cBy using oaDOI we have been able to increase our statistics on green open access by 38% and gold open access by 27%,\u201d says J\u00fcrgen Kerstna, formerly a system developer at the National Library of Sweden. (Green open-access, also called self-archiving, refers to authors depositing their papers in online repositories; gold open-access is when journal articles are made available by the publisher.)Other tools for mining the open-source literature have been or are being developed. These include the bibliographic databases  oaFindr and oaFindr+ ; the  Open Access Button , a web-browser extension that searches for open-access papers and allows users to e-mail authors when it cannot find one; and 'pirate' services such as  Sci-Hub . Joseph McArthur, who is assistant director of the Right to Research Coalition policy advocacy group in London, says Open Access Button, which he co-founded, has adopted oaDOI\u2019s freely available API as well as additional aggregators to expand its reach. \u201cWe're hoping our projects can work in tandem to provide the community with the best tools possible for legally getting around paywalls,\u201d he says.Another in-development tool,  OAbot  (Open Access Bot), will search the web for free-to-read versions of papers mentioned in references on Wikipedia pages, says Jake Orlowitz, head of the Wikipedia Library at the Wikimedia Foundation in the San Francisco Bay Area. Once fully launched, references on English Wikipedia pages will be marked with a green unlock icon when a free version of the paper is available. In time, Orlowitz notes, the team aims to use multiple icons to better reflect a paper\u2019s availability \u2014 namely, whether it is paywalled, not paywalled but requires registration, free to read but not free to reuse, or free to read as well as reuse.If publishers move toward an open-access model, Unpaywall and its ilk would no longer be needed. Priem, for one, would welcome that change, he says: \u201cI\u2019ll be pulling the plug with a great big smile on my face.\u201d Reprints and Permissions"},
{"file_id": "544125a", "url": "https://www.nature.com/articles/544125a", "year": 2017, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Cheap, stripped-down microcontrollers are allowing users to pack huge amounts of computing power into tiny spaces. A research subject watches a brush slowly stroking a rubber hand on a table in front of her, while her own hand \u2014 hidden from view \u2014 experiences the same stimulation. Eventually, the subject starts to think that rubber hand is her own. This rubber-hand illusion is a trick of the mind. But it is also a trick of design. Normally, the illusion is created by people who have carefully practised using brushes to stroke the real and rubber hands simultaneously. But Isa Rao, a psychology PhD student at the University of Glasgow, UK, who uses this set-up to gain insight into how people relate to their own bodies, has built an automated rig that delivers the stimuli without a trained assistant. At its heart is an Arduino microcontroller. Arduinos are one of a growing number of low-cost, stripped-down, and highly configurable computing devices that have transformed the field of homebrew and do-it-yourself electronics. Increasingly, they are transforming the research community too (see 'March of the mini-computers'). Available for as little as \u00a34 (US$5) for the basic circuit board, or about \u00a350 for a kit including power supply, case and cables, these systems have little in the way of bells and whistles, and the learning curve can be steep. Yet Arduinos and similar devices, such as the Raspberry Pi, pack considerable power on their diminutive boards, providing tremendous opportunities for automation, networking and data collection and analysis. For researchers, those features can translate into benefits both economic and practical. Users can shoehorn the systems into tiny spaces, deploy them without monitors or keyboards, buy them in bulk, and pack them into autonomous devices that need to be taken to (and transmit data from) remote field locations. All it takes is a little ingenuity. \n               No experience necessary \n             Although researchers have been customizing computers and integrating them into their experiments for decades, the market for small, cheap, 'single-board computers' has boomed in recent years. The Raspberry Pi \u2014 a fully fledged computer that can run the Linux operating system \u2014 appeared in 2012; by September 2016, 10 million had been sold. Arduinos \u2014 technically, programmable microcontrollers rather than computers \u2014 have been similarly popular since their launch in 2005. Off-the-shelf accessories for these devices include cameras, motion sensors, thermometers and Bluetooth adaptors. There's even an all-in-one system developed for an outreach project on the International Space Station; the system combines a gyroscope, an accelerometer, a magnetometer and sensors to measure temperature, barometric pressure and humidity. Here on Earth, Raspberry Pis, Arduinos and similar devices have been used to build  underwater sound recorders  for marine research, robots for  assembling gene-editing tools  and systems that can  rapidly identify drug-resistant pathogens  from human samples. Hakho Lee, who researches medical diagnostic systems at Harvard University in Cambridge, Massachusetts, and who has developed a system to  diagnose antibiotic-resistant bacterial infections , says he initially tried to build that system using smartphones as the central computers, but the phones were hard to break apart and reconfigure. By contrast, systems such as the Arduino and the Pi cry out for customization, making them ideal for integration into scientific sensors. \u201cThe Arduino system in this case is perfect,\u201d he says. \u201cThey already have so many different flavours and they're modular. Which means if I want to add Bluetooth, all I have to do is purchase that module and plug that into the motherboard.\u201d Although Lee has a long history with gadgetry and electronics, such a background isn't necessary; the plug-and-play nature of the devices has attracted researchers with no previous experience in electronics or programming. Turning the Raspberry Pi board into a functioning computer is as simple as slotting in an SD card preloaded with a Pi operating system, and plugging in a monitor, keyboard, mouse and power supply. Programming the device takes a bit more work, but detailed descriptions online should provide more than enough help for most people. Indeed, the Raspberry Pi was originally designed to teach children in British schools about programming. Pis and Arduinos speak languages based on C++, so a background in that programming language is useful, but not essential to getting started, says Takeo Katsuki, a researcher at the Kavli Institute for Brain and Mind, part of the University of California, San Diego. \u201cPick a project and start tinkering with it.\u201d (One possibility is a variant on the 'Hello, world!' exercise familiar to programmers. Usually, the goal is to display that message on the screen; here, the idea is to  direct the board's built-in LED to blink  on and off.) Katsuki placed an Arduino at the heart of a system he developed called  Flyception , which allows researchers to monitor brain activity in untethered  Drosophila  fruit flies in response to stimuli. The processor controls camera-triggering and other functions. \u201cThe ability to synchronize myriad mechanical and electronic devices with our imaging and behaviour recordings, in an easy-to-use package, makes [the Arduino] an attractive option,\u201d he says. \n               Money down \n             Before researchers can start building, they must decide what to buy \u2014 in what has become a bewilderingly crowded marketplace. Three generations of the standard Raspberry Pi are now available, plus a basic $5 'Pi Zero' version and a low-power version. Arduinos come in even more flavours. Then there are the Galileo and Edison boards from Intel, the open-source Banana Pi, the Odroid (based on the Android operating system) and more. Choosing a device involves thinking carefully about three variables, says Paulo De Souza, who works on microsensing technology and systems at Australia's Commonwealth Scientific and Industrial Research Organisation, a governmental research agency based in Canberra. These variables are cost, capability and size, he says. \u201cGenerally, you need to pick two of the three; it is difficult to get low cost, small size and high levels of capability in a single device.\u201d For example, De Souza has worked on autonomous machines, including submarines and rovers, that need to be power-efficient and able to process complex sensor data. His team picked the Odroid XU3 (now superseded by the $60 XU4), which is more expensive than a Pi, but much more powerful. But for a  project studying bees , he used an Intel Edison, which has lower power requirements and can even run on solar energy. Scientists also need to consider how their computer will talk to other elements in their experiment. Raspberry Pis connect to standard monitors, USB keyboards and mice. But as microprocessors, Arduinos must be linked to a computer using cables so that they can be programmed. Not all devices have the same capabilities. Most take micro-USB inputs, for instance, but some also have Bluetooth and Wi-Fi capabilities. These can become important if you want to build an experimental set-up that can transmit its data to another computer for analysis, for example, or that integrates with a camera or external sensor for more complicated studies. In De Souza's bee study, the bees were fitted with tiny radio-frequency-identification chips that trigger a scanner as the animals pass by. The Edison computer, located inside the hive, processes the resulting data and uploads them for analysis. \u201cConsider the options available and perhaps review the requirements to see what you might be able get away without,\u201d says De Souza. And be prepared to update your equipment as systems evolve. For his bee-monitoring project, for instance, De Souza has migrated from another single-board computer, made by a company called Ledato, to a Raspberry Pi; from there to a Galileo; and finally to an Edison. \n               Follow the beaten path \n             For those starting out, there are advantages to sticking to the most popular devices \u2014 namely the Raspberry Pi and Arduinos. User forums for both systems are extremely popular, with millions of posts and hundreds of thousands of members, providing a useful resource for novices. Researchers have turned to these forums for assistance with anything from using Arduinos to accurately calculate the girth of trees, to setting up temperature sensors. The foundation behind Raspberry Pi even has a series of videos and a list of common mistakes on its website, to help newcomers get up and running. \u201cWhat you really don't want to do is be fixing technical problems that people have already solved,\u201d says David White, a computer scientist at University College London who has worked extensively with Raspberry Pis. \u201cIt would save you a lot of time if you go with standard solutions. You can just harness the popularity of these devices \u2014 there's so much out there.\u201d Assistance does not have to come from the Internet, however. \u201cSit down with someone else who has worked with these beforehand,\u201d says White. Or, says De Souza, bring in postgraduate students with backgrounds in information technology. \u201cIT students are passionate about their area and are always up-to-date with the latest solutions,\u201d he says. Some researchers eventually find that their experiments demand too much of Pi or Arduino components. Katsuki switched to the myRIO controller from National Instruments when he found that the software clock in his Arduinos was not accurate enough for the Flyception system. Lee plans to upgrade to another device \u2014 the Jetson, from California-based firm NVIDIA \u2014 to gain greater processing power for future projects. But for many others, the humble, small and cheap Pi and Arduino devices are all they need. Certainly, that was Rao's experience. \u201cThe Arduino was really sent from heaven,\u201d she says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @DPCressey \n               \n                     The Internet of Things comes to the lab 2017-Jan-30 \n                   \n                     Flyception: imaging brain activity in freely walking fruit flies 2016-May-16 \n                   \n                     The automated lab 2014-Dec-03 \n                   \n                     Toolbox home page \n                   \n                     Blog post: Promoting shared hardware design \n                   \n                     Arduino \n                   \n                     Raspberry Pi \n                   \n                     Astro-Pi \n                   Reprints and Permissions"},
{"file_id": "545117a", "url": "https://www.nature.com/articles/545117a", "year": 2017, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Getting data off an ancient floppy disk or computer tape isn't easy, but it can be done with the help of clever software and hardware. In 2012, William Parker and his colleagues went hunting for a data set that tracked the growth of more than 50,000 carefully planted white spruce trees over a decade and a 1,500-kilometre range. They found a reel of computer tape, a relatively modern 3.5-inch diskette and a box of older 5.25-inch diskettes. These contained data from field trials in the late 1970s, which were set up to improve yields of commercial timber. Parker, who is at the Ontario Forest Research Institute in Sault Saint Marie, Canada, needed ways to evaluate how strategies such as 'assisted migration' might preserve forests on a warming planet, and this long-term systematic study was just the thing, he says. \u201cWhen we found it, it was like, 'Eureka! Hallelujah! We've finally got it!'.\u201d Not so fast. Parker booted up an old computer, but it could not read the newest disk. No one had equipment to even try the others. Parker's IT services referred him to a data-retrieval company. The older disks turned out to be 'flippies', double-sided disks written in formats that few drives can read. The specialists were ultimately able to read them using a carefully placed hole puncher, a bit of digital forensics and some programming that converted ancient software to modern spreadsheets. Parker's experience encapsulates the problems that many researchers encounter. Retrieving information from defunct data-storage media is like unlocking a series of cages, says Bertram Lyons, an archivist with AVPreserve in Madison, Wisconsin. \u201cScientists have information trapped in older formats. Some are physical barriers, some are encoded structures. Both can go obsolete.\u201d Scientists hoping to get data off old media first need to find a device that can read it and connect to a modern computer (see 'Old media'). But moving files to modern media is just the first step; the next is making sense of its contents, which requires another suite of tools.  \n               Going modern \n             When it comes to old hardware, a good place to start may be the local library. The Memory Lab at the Public Library in Washington DC offers a do-it-yourself station that allows people to transfer 3.5-inch floppies onto modern formats, for instance, and Stanford University Libraries offers a similar resource for 5.25-inch disks. Gavan McCarthy, director of the University of Melbourne's eScholarship Research Centre in Australia, has what he calls \u201cthe Museum of Redundant Technology\u201d, which can handle a range of formats. \u201cIf you have the tape, the disk and whatever it can fit into, we've got the plugs,\u201d he says. For a few dollars per disk, conversion service firms, such as FloppyDisk in Lake Forest, California, and RetroFloppy in Cary, North Carolina, can help. So, too, can data-recovery services, which specialize in damaged media. DriveSavers, a data-recovery firm based in Novato, California, has around 20,000 storage devices, the oldest being a Shugart ST-506 hard-disk drive from 1980. Parker used CBL Data Recovery in Toronto, Ontario, which subcontracted with Muller Media Services (now George Blood Audio in Manhasset, New York), to recover his data and paid about US$3,000. Success depends on the fragility of the media and how it was stored. 5.25-inch disks are easily damaged by oils and pressure, and Iomega Zip disks are unstable. But it's not just 'bitrot', or damage to media themselves, that makes old media unreadable says McCarthy. \u201cThe number of machines and the spare parts are falling off incredibly rapidly.\u201d Paper is, ironically, more stable. People who have the old drives and power cables may be tempted to set up their own do-it-yourself stations, only to find that new computers no longer contain the boards and interfaces required to make the connection. Some old Zip drives, for instance, plugged into a 'parallel' (printer) port \u2014 an interface that has largely disappeared today. But there are a range of adapters, mainly used by archivists and video-game enthusiasts, that can help. At the top end is the KryoFlux device, developed by the Software Preservation Society, which can transfer floppy-disk data through a USB interface. The KryoFlux Preservation Technology Group in Maidstone, UK, charges private users about $100 for the hardware. The operating systems on modern computers may also be unable to read files in old formats. Lori Emerson, director of the Media Archaeology Lab at the University of Colorado, Boulder, says that helping a local science museum to recover a mysterious file on a Zip disk depended on finding the right computer (a Power Macintosh 8100 from 1994 running OS 7) to read the file, which turned out to be a library from an old version of the citation manager EndNote. Guido Pauli, a medicinal chemist at the University of Illinois in Chicago, suggests that the best defence against data decay is staying current. Pauli maintains the NAPRALERT database, which lets researchers search for natural products (such as botanical extracts) and reported biological activities. It began on index cards organized by Guido's PhD adviser, and has since moved through magnetic tape and various disk formats, and is now in the cloud and on hard drives on two continents. \u201cI do have some of the old media, but I'm not dependent on reading them,\u201d Pauli says. \n               Diving into data \n             The next challenge in recovering old data is making sense of the data files themselves. For digital archivists, the first step in preservation is capturing a disk image \u2014 a bit-for-bit copy of all the digital data on a device, including overwritten and hidden files. That's the remit of digital forensics technologies, but commercial licences for such tools can cost thousands of dollars. Plus, with their focus on legal applications, they neglect certain functions important to archivists, such as redacting sensitive information. This led archivists to create BitCurator, an open-source 'virtual machine' that images a disk and guides people through the first steps in interpreting its contents, such as detecting how those bits and bytes are formatted into files readable by, for instance, the Windows NT operating system, Linux or DOS. The more obscure the format, the harder this is. Chris Muller, who founded Muller Media, has written software to unlock ancient files, but human clues can sometimes be more valuable, he says. Muller asks clients to e-mail a photograph of the original media early on in a potential project. Sometimes a few squiggles from a Sharpie that are meaningless to his client are letters or digits that let Muller deduce what formatting and software might have been used. The next step is accessing the files, explains Christopher Lee at the School of Information and Library Science at the University of North Carolina at Chapel Hill, and one of the main forces behind BitCurator. The files might be in an unrecognizable format, making it hard to know what program might open it, he says. \u201cThe software often is the barrier.\u201d Researchers can use computer programs known as Hex editors to show the raw binary content of such files. With luck, this might reveal what software a file was written in, or allow usable data to be extracted directly. BitCurator also interacts with the US National Institute of Standards and Technology's  Software Reference Library  to try to match files with the software that created them. With a few clues, researchers can often identify modern programs to open files from similar, older software and convert them to newer formats. An alternative, assuming the original software is available, is emulation: recreating the older operating-system platform within a modern machine. The Internet Archive, for example, has emulators for platforms such as MS-DOS that can run over an Internet browser. Emulation is more cost-effective when software is set up for highly specific tasks or visual renderings and cannot be easily migrated to contemporary formats, says Klaus Rechert of the Institute for Computer Science at the University of Freiburg in Germany. He recently set up an emulator to recreate analyses from a natural-language study that had produced custom language maps in the typesetting program LaTeX. Another option is 'digital archaeology', writing software to make old files intelligible. But that route is expensive, often futile, and usually requires a reasonable idea of what the file contains. In one relatively simple example, David Schmidt at RetroFloppy looked for sets of repeating codes that corresponded to letters in a client's name to craft a conversion matrix and recover data from an obscure IBM system stored on an 8-inch floppy. Firms such as George Blood and AVPreserve specialize in more-complex versions of these problems. The biggest hurdle is sometimes not technological but human, digital archivists say. It's not enough to extract a file just to learn that it has 6 columns and 100,000 rows; researchers need to know what the numbers mean. Archivists led by Amy Pienta at the Interuniversity Consortium for Political and Social Research in Ann Arbor, Michigan, for instance, bought a refurbished punch-card reader to retrieve data from a large, longitudinal study of retirement from the 1950s. But after physical punches were converted to ASCII numeric codes, they needed preserved codebooks to know what the numbers referred to \u2014 did a code of '1' mean yes or no? Parker's story has an interesting coda: the digital data contained only averaged values for groups of trees, but a lucky phone call revealed that paper records with measurements of individual trees had been kept. He took a few hours' drive to meet the original scientist and collect the data sheets. Says Melbourne's McCarthy, \u201cIf you want to preserve something, you've got to move while those people are still around.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     The trouble with reference rot 2015-May-04 \n                   \n                     Scientists losing data at a rapid rate 2013-Dec-19 \n                   \n                     Nature  Toolbox hub \n                   \n                     BitCurator \n                   \n                     KryoFlux \n                   \n                     Museum of Obsolete Media \n                   \n                     Internet Archive Software Library \n                   Reprints and Permissions"},
{"file_id": "547125a", "url": "https://www.nature.com/articles/547125a", "year": 2017, "authors": [{"name": "Jeffrey M. Perkel"}], "parsed_as_year": "2006_or_before", "body": "Data from thousands of single cells can be tricky to analyse, but software advances are making it easier. Single-cell biology is a hot topic these days. And at the cutting edge of the field is single-cell RNA sequencing (scRNA-seq). Conventional \u2018bulk\u2019 methods of RNA sequencing (RNA-seq) process hundreds of thousands of cells at a time and average out the differences. But no two cells are exactly alike, and scRNA-seq can reveal the subtle changes that make each one unique. It can even reveal entirely new cell types. For instance, after using scRNA-seq to probe some 2,400 immune-system cells, Aviv Regev of the Broad Institute in Cambridge, Massachusetts, and her colleagues came across some dendritic cells that had potent T-cell-stimulating activity (A.-C. Villani  et al .  Science   356 , eaah4573; 2017 ). Regev, who is profiled in a  News Feature , says that a vaccine to stimulate these cells could potentially boost the immune system and protect against cancer. But such discoveries are hard-won. It\u2019s much more difficult to manipulate individual cells than large populations, and because each cell yields only a tiny amount of RNA, there\u2019s no room for error. Another problem is analysing the enormous amounts of data that result \u2014 not least because the tools used can be unintuitive. Typically, RNA-seq data is analysed by laboriously typing commands into a Unix operating system. Data files are passed from one software package to the next, with each tool tackling one step in the process: genome alignment, quality control, variant calling and so on. The process is complicated. But for bulk RNA-seq, at least, a consensus has emerged as to which algorithms work best for each step and how they should be run. As a result, \u2018pipelines\u2019 now exist that are, if not exactly plug-and-play, at least tractable for non-experts. To analyse differences in gene expression, says Aaron Lun, a computational biologist at Cancer Research UK in Cambridge, bulk RNA-seq is \u201cpretty much a solved problem\u201d. The same cannot be said for scRNA-seq: researchers are still working out what they can do with the data sets and which algorithms are the most useful. But a range of online resources and tools are beginning to ease the process of scRNA-seq data analysis. One page at GitHub, called \u2018Awesome Single Cell\u2019 ( go.nature.com/2rmb1hp ), catalogues more than 70 tools and resources, covering every step of the analysis process. The field has spawned a cottage industry of computational-biology tools, says Cole Trapnell, a biologist at the University of Washington in Seattle. \n               Bespoke techniques \n             Lana Garmire, a bioinformatician at the University of Hawaii in Honolulu, laid out the basic steps of scRNA-seq data analysis (and some 48 tools to perform them) in a review published last year (O. B. Poirion  et al .  Front. Genet.   7 , 163; 2016 ). Although each experiment is unique, she says, most analysis pipelines follow the same steps to clean up and filter the sequencing data, work out which transcripts are expressed and correct for differences in amplification efficiency. Researchers then run one or more secondary analyses to detect subpopulations and other functions. In many cases, says Christina Kendziorski, a biostatistician at the University of Wisconsin\u2013Madison, the tools used in bulk RNA-seq can be applied to scRNA-seq. But fundamental differences in the data mean that this is not always possible. For one thing, single-cell data are noisier, says Lun. With so little RNA to work with, small changes in amplification and capture efficiencies can produce large differences from cell to cell and day to day that have nothing to do with biology. Researchers must therefore be vigilant for \u2018batch effects\u2019, in which seemingly identical cells prepared on different days differ for purely technical reasons, and for \u2018dropouts\u2019 \u2014 genes that are expressed in the cell but not picked up in the sequence data. Another challenge is the scale, says Joshua Ho, a bioinformatician at the Victor Chang Cardiac Research Institute in Sydney, Australia. A typical bulk RNA-seq experiment involves a handful of samples, but scRNA-seq studies can involve thousands. Tools that can handle a dozen samples often slow to a crawl when confronted with ten or a hundred times as many. (Ho\u2019s Falco software taps on-demand cloud-computing resources to address that problem.) Even the seemingly simple question of what constitutes a good cell preparation is complicated in the world of scRNA-seq. Lun\u2019s workflow assumes that most of the cells have approximately equivalent RNA abundances. But \u201cthat assumption isn\u2019t necessarily true\u201d, he says. For instance, he says, naive T cells, which have never been activated by an antigen and are relatively quiescent, tend to have less messenger RNA than other immune cells and could end up being removed during analysis because a program thinks there is insufficient RNA for processing. Perhaps most significantly, researchers performing scRNA-seq tend to ask different questions from those analysing bulk RNA. Bulk analyses typically investigate how gene expression differs between two or more treatment conditions. But researchers working with single cells are often aiming to identify new cell types or states or reconstruct developmental cellular pathways. \u201cBecause the aims are different, that necessarily requires a different set of tools to analyse the data,\u201d says Lun. One common type of single-cell analysis, for instance, is dimensionality reduction. This process simplifies data sets to facilitate the identification of similar cells. According to Martin Hemberg, a computational biologist at the Wellcome Trust Sanger Institute in Cambridge, UK, scRNA-seq data represent each cell as \u201ca list of 20,000 gene-expression values\u201d. Dimensionality-reduction algorithms such as principal component analysis (PCA) and t-distributed stochastic neighbour embedding (t-SNE) effectively project those shapes into two or three dimensions, making clusters of similar cells apparent. Another popular application is pseudo-time analysis. Trapnell developed the first such tool, called Monocle, in 2014. The software uses machine learning to infer from an scRNA-seq experiment the sequence of gene-expression changes that accompany cellular differentiation, much like inferring the path of a foot race by photographing the runners from the air, Trapnell says. Other tools address subpopulation detection (for instance, Pagoda, from Peter Kharchenko at Harvard Medical School in Boston, Massachusetts) and spatial positioning, which uses data on the distribution of gene expression in tissues to determine where in a tissue each transcriptome arose. Rahul Satija of the New York Genome Center in New York City, who developed one such tool, Seurat, as a postdoc with Regev, says that the software uses these data to position cells as points in 3D space. \u201cThat\u2019s why we named the package Seurat,\u201d he explains, \u201cbecause the dots reminded us of points on a pointillist painting.\u201d Although targeted to specific tasks, these tools often address multiple functions. Seurat, for instance, powered the cell-subpopulation analysis Regev\u2019s team performed to identify new classes of immune cells. Most scRNA-seq tools exist as Unix programs or packages in the programming language R. But relatively few biologists are comfortable working in those environments, says Gene Yeo, a bioinformatician at the University of California, San Diego. Even if they are, they may lack the time required to download and configure everything to make such tools work. Some ready-to-use pipelines have been developed. And there are end-to-end graphical tools too, including the commercial SeqGeq package from FlowJo, as well as a pair of open-source web tools: Granatum from Garmire\u2019s group, and ASAP (the Automated Single-cell Analysis Pipeline) from the lab of Bart Deplancke, a bioengineer at the Swiss Federal Institute of Technology in Lausanne. ASAP and Granatum use a web browser to provide relatively simple, interactive workflows that allow researchers to explore their data graphically. Users upload their data and the software walks them through the steps one by one. For ASAP, that means taking data through preprocessing, visualization, clustering and differential gene-expression analysis; Granatum allows pseudo-time analyses and the integration of protein-interaction data as well. According to both Garmire and Deplancke, ASAP and Granatum were designed to allow researchers and computational biologists to work together. Researchers \u201cused to think of [bioinformaticians] as magical creatures who just get the data and magically generate the result\u201d, says Xun Zhu, a PhD student at the University of Hawaii at Manoa, and lead developer on Granatum. \u201cNow they can participate a little bit in terms of tuning the parameters. And that\u2019s a good thing.\u201d \n               Approach with caution \n             The tools aren\u2019t perfect for every situation, of course. A pipeline that excels at identifying cell types, for instance, might stumble with pseudo-time analysis. Plus, appropriate methods are \u201cvery data-set dependent\u201d, says Sandrine Dudoit, a biostatistician at the University of California, Berkeley. The methods and tuning parameters may need to be adjusted to account for variables such as sequencing length. But John Marioni at Cancer Research UK in Cambridge says it\u2019s important not to put complete faith in the pipeline. \u201cJust because the satellite navigation tells you to drive into the river, you don\u2019t drive into the river,\u201d he says. For beginners, caution is warranted. Bioinformatics tools can almost always yield an answer; the question is, does that answer mean anything? Dudoit\u2019s advice is do some exploratory analysis, and verify that the assumptions underlying your chosen algorithms make sense. Some analytical tasks still remain challenging, says Satija, including comparing data sets across experimental conditions or organisms and integrating data from different \u2019omics. (A planned update to Seurat should address the former issue, he notes.) But enough tools exist to keep most researchers occupied. Kendziorski suggests that people who are interested just dive in. Each new tool can unveil another facet of biology; just keep your eyes on the science, and be judicious in your choice. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @j_perkel \n               \n                     Genetic screening enters the single-cell era 2017-Feb-28 \n                   \n                     How single cells do it 2016-Dec-29 \n                   \n                     Bioinformatics: Benchmarking transcript expression quantification 2016-May-09 \n                   \n                     Epigenomics: Parallel single-cell sequencing 2016-Jan-25 \n                   \n                     Integrated genome and transcriptome sequencing of the same cell 2015-Jan-19 \n                   \n                     Nature  Toolbox \n                   \n                     Online course on Analysis of single-cell RNA-seq data from Univ. Cambridge Bioinformatics Training Unit \n                   \n                     Marioni & Lun\u2019s scRNA-seq workflow \n                   \n                     Awesome single-cell GitHub page \n                   \n                     Granatum analysis pipeline \n                   \n                     Automated Single-cell Analysis Pipeline \n                   Reprints and Permissions"},
{"file_id": "546173a", "url": "https://www.nature.com/articles/546173a", "year": 2017, "authors": [{"name": "Andrew Silver"}], "parsed_as_year": "2006_or_before", "body": "Containerization technology takes the hassle out of setting up software and can boost the reproducibility of data-driven research. In 2015, geneticist Guy Reeves was trying to configure a free software system called Galaxy to get his bioinformatics projects off the ground. After a day or two of frustration, he asked members of his IT department for help. They installed Docker, a technology for simulating computational environments, which enabled him to use a special version of Galaxy that came packaged with everything he needed \u2014 called a container. A slight tweak to the Galaxy settings, and he was \u201cdone before lunch\u201d. Reeves, at the Max Planck Institute for Evolutionary Biology in Pl\u00f6n, Germany, is one of many scientists adopting containers. As science becomes ever more data intensive, more software is being written to extract knowledge from those data. But few researchers have the time and computational know-how to make full use of it. Containers, packages of software code and the computational environment to run it, can close that gap. They help researchers to use a wider array of software, accelerate experiments and promote reproducibility. Containers are essentially lightweight, configurable virtual machines \u2014 simulated versions of an operating system and its hardware, which allow software developers to share their computational environments. Researchers use them to distribute complicated scientific software systems, thereby allowing others to execute the software under the same conditions that its original developers used. In doing so, containers can remove one source of variability in computational biology. But whereas virtual machines are relatively resource-intensive and inflexible, containers are compact and configurable, says C. Titus Brown, a bioinformatician at the University of California, Davis. Although configuring the underlying containerization software can be tricky, containers can be modified to add or remove tools according to the user's need \u2014 flexibility that has boosted their popularity, he says. \u201cI liked the idea of having something that works out of the box,\u201d says Reeves. \n               What's inside \n             Lab-built tools rarely come ready to run. They often take the form of scripts or programming source code, which must be processed and configured. Much of the software requires additional tools and libraries, which the user may not have installed. Even if users can get the software to work, differences in computational environments, such as the installed versions of the tools it depends on, can subtly alter performance, affecting reproducibility. Containers reduce that complexity by packaging the key elements of the computational environment needed to run the desired software, including settings and add-ons, into a lightweight, virtual box. They don't alter the resources required to run it \u2014 if a tool needs a lot of memory, then so too will its container. But they make the software much easier to use, and the results easier to reproduce. Depending on the software used \u2014 Docker, Singularity and rkt are popular \u2014 containers can run on Windows, Mac OS X, Linux or in the cloud. They can package anything from a single process to a complex environment such as Galaxy. These tools can interact with each other, sharing data or building pipelines, for instance. Because each application resides in its own box, even tools that would ordinarily conflict with each other can run harmoniously. Docker uses executable packages, called images, which include the tool to be contained as well as the developer's computational environment. To create a Docker image, a developer creates a configuration file with instructions on how to download and build all the required tools inside it. He or she then 'runs' the file to create an executable package. All the user then needs to do is retrieve the package and run it. Other tools can also generate images. The Reprozip program, for example, assembles Docker-compatible packages by watching as software tools run and tracing the input files and software libraries that the tool requires. Deborah Bard, a computer scientist at the National Energy Research Scientific Computing Center in Berkeley, California, helps researchers to install their software on the lab's supercomputer. She recalls spending three or four days installing a complex software pipeline for telescope simulation and analysis. Using containers cut this time down to hours. \u201cYou can spend your time doing science instead of figuring out compiler versions,\u201d she says. For Nicola Mulder, a bioinformatician at the University of Cape Town in South Africa, containers help her to synchronize a cross-border bioinformatics network she runs in Africa, called H3ABioNet. Not all African institutions have access to the same computational resources, she explains, and Internet connectivity can be patchy. Containers allow researchers with limited resources to access the tools that they otherwise might not be able to. They also allow researchers with sensitive genomic data to collaborate and compare findings without actually sharing the underlying data, Mulder says. And, if researchers at one site obtain different results from their colleagues at another, the standardization the containers provide could eliminate one of the reasons why. \n               Obtaining containers \n             Although computer scientists have multiple options for container platforms, Docker, which is an open-source project launched in 2013, is perhaps the most popular among scientists. It has a large registry of prebuilt containers and an active online community that competitors have yet to match. But many administrators of high-performance computing systems preclude Docker use because it requires high-level administrative access privileges to run. This type of access may allow users to copy or damage anything on the system. An add-on to the fee-based enterprise edition allows users to sidestep that requirement, but it is not available with the free, community edition. They can, however, use a different containerization tool such as Shifter, which doesn't require full privileges, or root access, but still supports Docker images. The requirement for root access is the biggest obstacle to widespread adoption of Docker, Brown explains. Many academics run bioinformatics tools on high-performance computing clusters administered by their home institutions or the government. \u201cOf course, they don't have administrative privileges on most of those systems,\u201d he says. Brown spends about US$50,000 annually for cloud computing time on Amazon Web Services, but he says this represents just one-third of his computing work; the rest is carried out on a cluster at Michigan State University, where he lacks root-level access. As a result, Brown creates Docker containers of his tools for distribution, but can rarely use them himself. Researchers can access Docker images either from the platform's own hosting service, Docker Hub, or from registries of containers such as BioContainers and Dockstore, which allow the sharing of tools vetted by other scientists. Brian O'Connor at the University of California, Santa Cruz, who was the technical lead for the Dockstore registry, recommends that scientists look through container registries to find a tool that works for their project instead of trying to reinvent something that already exists. But actually getting the underlying Docker software to run properly can be challenging, says Simon Adar, chief executive of Code Ocean in New York, an online service that aims to simplify the process. \u201cIt's too technical, it was designed for developers to deploy complex systems.\u201d The service, launched in February, creates what Adar calls \u201ccompute capsules\u201d, which comprise code, data, results and the Docker container itself. Researchers upload their code and data, and then either execute it in a web browser or share it with others \u2014 no installation required. Adar likens the process to sharing a YouTube video. The company even offers a widget that enables users to embed executable code in web pages. Shakuntala Baichoo, a computer scientist at the University of Mauritius in Moka, learned about containers at a communal programming event, called a hackathon, organized by H3ABioNet. Previously, she spent hours helping collaborators install her tools. In making the tools easier to install, she says, containers not only free up her time, but they might also encourage scientists to test them and provide feedback. At CERN, the particle-physics laboratory near Geneva, Switzerland, scientists use containers to accelerate the publication process, says physicist Kyle Cranmer at New York University who works on CERN's ATLAS project, which searches for new elementary particles. When physicists run follow-up studies, they have to dig up code snippets and spend hours redoing old analyses; with containers, they can package ready-to-use data analysis workflows, simplifying and shortening the process. \n               Advancing reproducibility \n             Cranmer says that although much of the debate around reproducibility has focused on data and code, computing environments themselves also play a big part. \u201cIt's really essential,\u201d he says. One study of an anatomical analysis tool's performance in different computing environments, for example, found that the choice of operating system produced a small but measurable effect (  E. H. B. M. Gronenschild  et al .  PLoS ONE   7 , e38234; 2012). But containers are only as good as the tools they encapsulate, says Lorena Barba, a mechanical and aerospace engineer at George Washington University, Washington DC. \u201cIf researchers start stuffing their bad code into a container and pass it on, we are foredoomed to failure.\u201d And, says Brown, without pressure from funding agencies and journals, containers are unlikely to make researchers suddenly embrace computational reproducibility. Indeed, few researchers are using containers, says Victoria Stodden, a statistician at the University of Illinois at Urbana\u2013Champaign who studies computational reproducibility. In part that's because of a lack of need or awareness, but it is also because they might not have the computer skills needed to get going. Behind the scenes, however, that could be changing. Companies such as Google and Microsoft already run some software in containers, says Jonas Almeida, a bioinformatician at Stony Brook University, New York. Large-scale bioinformatics projects may not be far behind. The cloud-based version of Galaxy will eventually run inside containers by default, says Enis Afgan, a computer scientist at Johns Hopkins University in Baltimore, Maryland, who works on Galaxy. In 5\u201310 years, Almeida predicts, scientists will no longer have to worry about downloading and configuring software; tools will simply be containerized. \u201cIt's inevitable,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Nextflow enables reproducible computational workflows 2017-Apr-11 \n                   \n                     How bioinformatics tools are bringing genetic analysis to the masses 2017-Feb-28 \n                   \n                     Reviewing computational methods 2015-Dec-01 \n                   \n                     How to catch a cloud 2015-Jun-03 \n                   \n                     Rule rewrite aims to clean up scientific software 2015-Apr-14 \n                   \n                     Toolbox hub \n                   \n                     Docker \n                   \n                     Singularity \n                   \n                     rkt \n                   \n                     Biocontainers \n                   \n                     Dockstore \n                   \n                     Code Ocean \n                   \n                     Bio-Docklets: Virtualization Containers for Single-Step Execution of NGS Pipelines \n                   \n                     Visual Omics Explorer \n                   Reprints and Permissions"}
]