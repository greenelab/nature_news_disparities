---
title: "nature_news_disp"
author: "Natalie Davidson"
date: "12/16/2020"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

require(data.table)
require(here)
require(ggplot2)
require(caret)
require(ggrepel)

proj_dir = here()
source(paste(proj_dir, "/analysis_scripts/analysis_utils.R", sep=""))
source(paste(proj_dir, "/utils/plotting_utils.R", sep=""))
```

## Nature News Disparities -- gender + location

This document is a first attempt to analyze the Nature News content to see if there are differences in geographic and gender representation.
Currently, this work only looks at a benchmark dataset with 10 articles per year, for the years 2010, 2015, 2020.
The benchmark dataset currently consists of 2 files

1) `benchmark_quote_table_hand_annotated` contains mapping between the speaker and their name and gender
    + `benchmark_quote_table_raw` is the output from coreNLP which we will compare against
2) `benchmark_location_table_hand_annotated` contains a mapping between all found (organizations, states, provencces, countries) with a (normalized country name, UN region, and UN sub-region)
    + `benchmark_location_table_raw` is the output from coreNLP which we will compare against



**All analysis shown below depends on the functions described in `/analyze_benchmark_data/analyze_benchmark_data.R`**


## Quote Analysis

### reading in the quote data

```{r}

# get the project directory
proj_dir = here()

# get benchmark (bm) file and read it
bm_quote_file = paste(proj_dir, 
                    "/data/benchmark_data/benchmark_quote_table_hand_annotated.tsv", 
                    sep="")

bm_quote_df = read_benchmark_quote_file(bm_quote_file)


```

Lets look at what the file
```{r}

head(bm_quote_df)

```

Here we get the `file_id`, the true speaker of the quote, their true gender, and the quote in question.
Now lets find what we get out of coreNLP, which we will compare against

```{r}
# 
raw_quote_file = paste(proj_dir, 
                    "/data/benchmark_data/benchmark_quote_table_raw.tsv", 
                    sep="")

raw_quote_df = read_corenlp_quote_files(raw_quote_file)

head(raw_quote_df)

```

The main columns of interest are `est_gender` and `est_speaker`, which we will compare between lines that have the same `quote` and `file_id`.


### analyzing quote data

First, lets look at the *benchmark* data, to see if there exist any gender disparity evidence.
```{r fig.align='center', echo=FALSE, warning=FALSE, message=F}


    # filter out any places where the gender is NA
    # this can happen when a quote is from an unidentified i.e. spokesperson
    eval_df = subset(bm_quote_df, !is.na(true_gender))

    # lets see is trends change overtime.. need year indices
    year_idx_file = paste(proj_dir, 
                    "/data/benchmark_data/coreNLP_input/fileID_year.tsv", 
                    sep="")
    year_df = data.frame(fread(year_idx_file))
    eval_df = merge(year_df, eval_df)

    ## get per year stats

    ggplot(eval_df, aes(x=as.factor(year), fill=true_gender)) +
        geom_bar(position="fill") + theme_bw() + 
        xlab("Year of Article") + ylab("Male Quote Percentage") +
        ggtitle("Male Quote Percentage Over Time") + 
        scale_fill_brewer(palette="Set2")


```

Ok, so we see some signal. Now what does it look like for our estimated gender?

```{r fig.align='center', echo=FALSE, warning=FALSE, message=F}

    eval_df = subset(raw_quote_df, !is.na(est_gender))
    eval_df = merge(year_df, eval_df)

    ggplot(eval_df, aes(x=as.factor(year), fill=est_gender)) +
        geom_bar(position="fill") + theme_bw() + 
        xlab("Year of Article") + ylab("Male Quote Percentage") +
        ggtitle("Estimated Male Quote Percentage Over Time") + 
        scale_fill_brewer(palette="Set2")


```

Nice, it looks pretty close. Things called `NO_EST` are when a quote was found, but no gender was able to be estimated.
Let's take a closer look at the errors
```{r  fig.align='center', echo=FALSE, warning=FALSE, message=F}


    # join the df to make comparison
    compare_df = merge(bm_quote_df, raw_quote_df, by=c("file_id", "quote"), all.x=T)

    compare_df = subset(compare_df, true_gender != "NOT_CLEAR")
    compare_df = subset(compare_df, est_gender != "NO_EST")

    #compare per quote
    gender_idx = which(colnames(compare_df) == "est_gender")
    true_gender_idx = which(colnames(compare_df) == "true_gender")
    gender_match = apply(compare_df, 1, 
                        function(x) x[gender_idx] == x[true_gender_idx]) 
    
    compare_df$is_gender_correct = gender_match
  
    # write out confusion tables
    levels(compare_df$est_gender) = c("FEMALE", "MALE")
    levels(compare_df$true_gender) = c("FEMALE", "MALE")
    confusion_matrix <- confusionMatrix(as.factor(compare_df$est_gender),
                                        as.factor(compare_df$true_gender))

    draw_confusion_matrix(confusion_matrix, "FEMALE", "MALE", "Gender prediction Conf. Matr.")
    
        
    # also see if error changes by year

```

### analyzing location data

```{r }


# get benchmark (bm) file and read it
bm_loc_file = paste(proj_dir, 
                    "/data/benchmark_data/benchmark_location_table_hand_annotated.tsv", 
                    sep="")

bm_loc_df = read_benchmark_location_file(bm_loc_file)

raw_loc_file = paste(proj_dir, 
                    "/data/benchmark_data/benchmark_location_table_raw.tsv", 
                    sep="")

raw_loc_df = read_corenlp_location_files(raw_loc_file)


```

The location data tries to find an organization, state, province, or country.
After this it tries to tag it to a canonically named country, and UN defined regions.
Let's take a look.

```{r}
head(bm_loc_df)
head(raw_loc_df)
```

Similar to before we will match columns baed on their names, in `raw_loc_df` it has `est_` columns and in `bm_loc_df` is has matching `true_` columns

Now lets first look at the benchmark data
```{r echo=F, fig.width=15}

    # filter out any places where the gender is NA
    # this can happen when a quote is from an unidentified i.e. spokesperson
    eval_df = subset(bm_loc_df, !is.na(true_country))

    eval_df = merge(year_df, eval_df)
    
    # we only care if a country was mentioned once or not at all
    eval_df = eval_df[,c("file_id", "true_country", "true_un_region", 
                         "true_un_subregion", "year")]

    eval_df = unique(eval_df)
    
    ## plot per year stats
    country_agg = data.frame(table(eval_df[,c("true_country", "year")]))
    ggplot(country_agg, aes(x=year, y=Freq, color=true_country, group=true_country)) +
        geom_line() + geom_point() + theme_bw() + 
        xlab("Year of Article") + 
        ylab("Number of Articles (10 articles/year) with \n at least one Country Mention") +
        ylim(c(0, 10)) +
        ggtitle("Country Mention by Year")

    subregion_agg = data.frame(table(eval_df[,c("true_un_subregion", "year")]))
    ggplot(subregion_agg, aes(x=year, y=Freq, color=true_un_subregion, group=true_un_subregion)) +
        geom_line() + geom_point() + theme_bw() + 
        xlab("Year of Article") + 
        ylab("Number of Articles (10 articles/year) with \n at least one UN Subregion Mention") +
        ggtitle("Subregion Mention by Year")

    region_agg = data.frame(table(eval_df[,c("true_un_region", "year")]))
    ggplot(region_agg, aes(x=year, y=Freq, color=true_un_region, group=true_un_region)) +
        geom_line() + geom_point() + theme_bw() + 
        xlab("Year of Article") + 
        ylab("Number of Articles (10 articles/year) with \n at least one UN Region Mention") +
        ggtitle("Region Mention by Year")
    
```

Let's take a closer look at the errors in predicting at first the highest
granularity: country

```{r  fig.align='center', fig.width = 15, fig.height = 15, echo=FALSE, warning=FALSE, message=F}


    # join the df to make comparison
    bm_loc_df$text = tolower(bm_loc_df$text)
    raw_loc_df$text = tolower(raw_loc_df$text)
    compare_df = merge(bm_loc_df, raw_loc_df, by=c("file_id", "text"), all.x=T)

    # now we only count ONCE per article
    compare_df = subset(compare_df, select = -c(text))
    compare_df = unique(compare_df)
    
    #compare per country
    country_idx = which(colnames(compare_df) == "est_country_code")
    true_country_idx = which(colnames(compare_df) == "true_country_code")
    country_match = apply(compare_df, 1, 
                        function(x) x[country_idx] == x[true_country_idx]) 
    
    compare_df$is_country_correct = country_match
  
    # write out confusion tables
    a = table(compare_df$est_country_code, compare_df$true_country_code)
    all_levels = unique(c(compare_df$est_country_code, compare_df$true_country_code))
    
    compare_df$est_country_code = as.factor(compare_df$est_country_code)
    missing_levels = setdiff(all_levels, levels(compare_df$est_country_code))
    levels(compare_df$est_country_code) = 
        c(levels(compare_df$est_country_code), missing_levels)
    
    compare_df$true_country_code = as.factor(compare_df$true_country_code)
    missing_levels = setdiff(all_levels, levels(compare_df$true_country_code))
    levels(compare_df$true_country_code) = 
        c(levels(compare_df$true_country_code), missing_levels)

    confusion_matrix <- confusionMatrix(compare_df$est_country_code, 
                                        compare_df$true_country_code)
    gg_conf = prettyConfused(compare_df$true_country_code, compare_df$est_country_code, text.scl = 0)
    gg_conf = gg_conf + ggtitle(paste("Country Prediction Kappa:", 
                                      round(confusion_matrix$overall['Kappa'], 4))) +
              theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))

    gg_conf
    
    

```

what we want to see is that these are more or less correlated

```{r  echo=FALSE,  out.width="50%", warning=FALSE, message=F}

    pred_freq = as.data.frame(table(compare_df$est_country_code))
    colnames(pred_freq) = c("country", "Pred_Freq")

    true_freq = as.data.frame(table(compare_df$true_country_code))
    colnames(true_freq) = c("country", "True_Freq")

    freq_df = merge(pred_freq, true_freq, all=T)
    freq_df = subset(freq_df, !country %in% c("NOT_COUNTRY", "NOT_FOUND"))
    
    gg_corr_all = ggplot(freq_df, aes(x=Pred_Freq, y=True_Freq, label=country)) +
                geom_point() + geom_abline(intercept = 0, slope = 1) +
                theme_bw() + geom_text_repel() +
                xlab("Predicted Frequency") + 
                ylab("True Frequency") +
                ggtitle("Pred. vs. True Country Frequencies")
                
     gg_corr_subset = ggplot(subset(freq_df, Pred_Freq < 20),
                             aes(x=Pred_Freq, y=True_Freq, label=country)) +
                geom_point() + geom_abline(intercept = 0, slope = 1) +
                theme_bw() + geom_text_repel() +
                xlab("Predicted Frequency") + 
                ylab("True Frequency") +
                ggtitle("Excluding top 2: Pred. vs. True Country Frequencies")
     
       gg_corr_all    
       gg_corr_subset

```
Let's look at if subregions is any better/worse:

```{r  echo=FALSE,  out.width="50%", warning=FALSE, message=F}

    pred_freq = as.data.frame(table(compare_df$est_un_subregion))
    colnames(pred_freq) = c("un_subregion", "Pred_Freq")

    true_freq = as.data.frame(table(compare_df$true_un_subregion))
    colnames(true_freq) = c("un_subregion", "True_Freq")

    freq_df = merge(pred_freq, true_freq, all=T)
    freq_df = subset(freq_df, un_subregion != "NO_EST")
    freq_df[is.na(freq_df)] = 0
    
    gg_corr_all = ggplot(freq_df, aes(x=Pred_Freq, y=True_Freq, label=un_subregion)) +
                geom_point() + geom_abline(intercept = 0, slope = 1) +
                theme_bw() + geom_text_repel() +
                xlab("Predicted Frequency") + 
                ylab("True Frequency") +
                ggtitle("Pred. vs. True UN Subregion Frequencies")
                
     gg_corr_subset = ggplot(subset(freq_df, Pred_Freq < 60),
                             aes(x=Pred_Freq, y=True_Freq, label=un_subregion)) +
                geom_point() + geom_abline(intercept = 0, slope = 1) +
                theme_bw() + geom_text_repel() +
                xlab("Predicted Frequency") + 
                ylab("True Frequency") +
                ggtitle("Excluding top 1: Pred. vs. True  UN Subregion Frequencies")
     
       gg_corr_all    
       gg_corr_subset

```

Now, finally large regions:

```{r  echo=FALSE,  out.width="50%", warning=FALSE, message=F}

    pred_freq = as.data.frame(table(compare_df$est_un_region))
    colnames(pred_freq) = c("un_region", "Pred_Freq")

    true_freq = as.data.frame(table(compare_df$true_un_region))
    colnames(true_freq) = c("un_region", "True_Freq")

    freq_df = merge(pred_freq, true_freq, all=T)
    freq_df = subset(freq_df, un_region != "NO_EST")
    freq_df[is.na(freq_df)] = 0
    
    gg_corr_all = ggplot(freq_df, aes(x=Pred_Freq, y=True_Freq, label=un_region)) +
                geom_point() + geom_abline(intercept = 0, slope = 1) +
                theme_bw() + geom_text_repel() +
                xlab("Predicted Frequency") + 
                ylab("True Frequency") +
                xlim(c(0,110)) + ylim(c(0,110)) + 
                ggtitle("Pred. vs. True UN Region Frequencies")
                
     gg_corr_subset = ggplot(subset(freq_df, Pred_Freq < 60),
                             aes(x=Pred_Freq, y=True_Freq, label=un_region)) +
                geom_point() + geom_abline(intercept = 0, slope = 1) +
                theme_bw() + geom_text_repel() +
                xlab("Predicted Frequency") + 
                ylab("True Frequency") +
                xlim(c(0,60)) + ylim(c(0,60)) + 
                ggtitle("Excluding top 1: Pred. vs. True  UN Region Frequencies")
     
       gg_corr_all    
       gg_corr_subset

```