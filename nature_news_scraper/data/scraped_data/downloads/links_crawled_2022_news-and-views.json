[
{"file_id": "d41586-022-04449-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-04164-8", "year": 2022, "body": ""},
{"file_id": "d41586-022-04354-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-04356-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-04351-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-04348-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-04167-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-04353-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-04171-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-04355-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-04138-w", "year": 2022, "body": "Knowing how COVID-19 affects global mortality rates is crucial if we are to understand the factors that govern its spread and severity, and to be able to evaluate the effectiveness of government responses to the pandemic. In May, a team of researchers led by the World Health Organization (WHO) and the United Nations Department of Economic and Social Affairs published the first results from their attempt to estimate global, COVID-19-related death rates.  Writing in  Nature , Msemburi  et   al . 1  present these estimates in more detail. \n  \n   Read the paper: The WHO estimates of excess mortality associated with the COVID-19 pandemic \n  Many deaths from COVID-19 went undetected in official reports from 2020 and 2021, because of limited testing capacity and misclassification of causes of death. This lack of data makes it challenging to quantify the mortality toll of short-term events, such as wars and natural disasters, as well as pandemics. For this reason, excess mortality \u2014 defined as the difference between all observed and expected deaths in a given period \u2014 is considered the gold-standard approach for estimating the mortality toll of short-term events 2 , 3 . But it is hard to find a universally effective way to measure excess mortality 4 , 5 , because there are substantial variations in underlying mortality trends and data availability across populations. Msemburi and colleagues set out to estimate excess deaths from COVID-19 for every country in the world. The authors report that there were between 13.2 million and 16.6 million more deaths than expected in 2020 and 2021. This death toll was between 2.4 and 3.1 times higher than the officially reported number of COVID-19-related deaths. Four out of five excess deaths occurred in middle-income countries (Fig. 1), with some of the worst affected in Latin America. In both years combined, the observed mortality in Peru was double the expected level, and it was between 41% and 51% higher than expected in Mexico, Bolivia and Ecuador. Low-income countries had fewer deaths, mostly because they account for only 9% of the global population, and have younger populations, on average, than do higher-income countries. Compared with the published data, Msemburi  et   al . present more-detailed methods and more-refined estimates, by adjusting the way in which underlying mortality trends were forecast for several countries 6 . However, the authors\u2019 estimates must be interpreted with extreme caution. This is because only 37% of countries had complete data for the number of people who died from any cause in each month of 2020 and 2021 \u2014 an essential figure for accurately calculating excess mortality. There were no data at all for 43% of countries; 2% of countries had data for only some regions; 5% had only annual data; and 13% had incomplete monthly series. The availability of data is heavily correlated with income. For example, only 2% of European countries had no data for 2020, whereas for African countries this figure was 87%. As a result, the authors had to make some problematic inferences. First, for countries that lacked data in some regions, they had to scale death counts from subnational to national levels. This assumes a constant share of deaths between regions before and during the pandemic. But the spread, timing and severity of COVID-19 within countries was far from uniform 7 , 8 . \n  \n   Precise mapping reveals gaps in global measles vaccination coverage \n  Second, the researchers had to infer the number of expected and excess deaths in countries with no mortality data (mostly low-income countries) by extrapolating patterns from those with more-complete data (mostly high-income countries that have robust health-care systems). The researchers adjusted the patterns seen across the latter group to make estimates for the former using country-specific proxies for socio-economic conditions, the intensity of the pandemic, each country\u2019s susceptibility to COVID-19 and its capacity to respond to the crisis. As such, half of global excess deaths were estimated without data on mortality, or by using data from subnational regions (Fig. 1). There are other factors to consider when interpreting Msemburi and colleagues\u2019 findings, including \u2018avoided\u2019 and \u2018displaced\u2019 mortality. The former refers to expected deaths that did not occur \u2014 for instance, influenza-related deaths that were avoided in 2020 and 2021, owing to changes in people\u2019s behaviour and social-isolation measures 9 . The latter refers to deaths of frail or sick people that were expected to occur during the observation period, but were brought forward by COVID-19, producing a temporary surplus in mortality followed by a deficit, and consequently ignored when calculating cumulative excess deaths. Msemburi  et   al . did not adjust for these factors, because they aimed to identify all changes in mortality during the pandemic. Nevertheless, adjusting estimates for these numbers is essential if the goal is to understand COVID-19 fatality better. There are already models available that can adjust for influenza-related avoided mortality 10 , and new approaches have been proposed for use in the context of the COVID-19 pandemic 11 . For displaced mortality, partial adjustments can be made by excluding mortality deficits when computing the cumulative number of excess deaths over the months of the observation period. (The adjustment is only partial because COVID-19 deaths that occur during periods of overall deficit remain uncounted.) \n  \n   A reconstruction of early cryptic COVID spread \n  Although the inferences made by Msemburi and colleagues are not ideal, there is no obvious alternative. However speculative these estimates, most are surely closer to the truth than are officially reported numbers of deaths from COVID-19. To rely on confirmed deaths would imply that the pandemic spared low-income and lower-middle-income countries \u2014 vulnerable populations that have limited capacity for testing and response. This assumption is highly implausible, and even irresponsible. Nonetheless, the complexity of the task is apparent from the fact that similar attempts to estimate the effect of the pandemic on global mortality have given different results. For the same period, the University of Washington\u2019s Institute for Health Metrics and Evaluation in Seattle 12  estimated 18.2 million excess deaths, and  The   Economist  magazine estimated 16 million (see  go.nature.com/3uykedp ). This makes the WHO estimate the most conservative of the three. Compared with these other studies, the approach adopted by Msemburi  et   al . is simpler, and their estimation of uncertainties is more rigorous. A sensible next step for Msemburi and colleagues \u2014 and one currently under way (see  go.nature.com/3vhmybu ) \u2014 is to include information on age in their data. The risk of COVID-19 death increases with age 13 . Because the authors calculated excess mortality for entire populations, any difference between countries is affected by variations in their age compositions. There have been some attempts to rank countries\u2019 response to the pandemic (including one in the current study) by estimated overall death toll, but without data on age, any assessments of differences in pandemic severity or the effectiveness of responses will be biased. Finally, the complexity of estimating the effect of the pandemic on global mortality underscores the urgent need to build robust, centralized systems that allow for real-time monitoring of global mortality. The construction of such systems will require considerable global efforts to strengthen civil registration and crucial statistics systems worldwide, especially in low- and middle-income countries. But, once built, they will serve as an essential early warning for future pandemics and health crises."},
{"file_id": "d41586-022-04169-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-04349-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-04429-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-04352-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-04430-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-04448-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-04445-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-04165-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-04450-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-04447-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-03669-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-03732-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-03770-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-03371-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-03342-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-03769-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-03767-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-03768-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-03832-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-03703-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-03681-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-03800-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-03834-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-03692-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-03833-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-03364-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-03367-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-03343-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-03458-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-03457-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-03366-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-03365-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-03459-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-03456-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-03563-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-03559-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-03557-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-03561-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-02234-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-03455-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-02977-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-03029-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-03078-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-03174-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-03175-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-03050-7", "year": 2022, "body": "Data sets are essential for training and validating machine-learning algorithms. But these data are typically sourced from the Internet, so they encode all the stereotypes, inequalities and power asymmetries that exist in society. These biases are exacerbated by the algorithmic systems that use them, which means that the output of the systems is discriminatory by nature, and will remain problematic and potentially harmful until the data sets are audited and somehow corrected. Although this has long been the case, the first major steps towards overcoming the issue were taken only four years ago, when Joy Buolamwini and Timnit Gebru 1  published a report that kick-started sweeping changes in the ethics of artificial intelligence (AI). \n  \n   Read the paper: Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification \n  As a graduate student in computer science, Buolamwini was frustrated that commercial facial-recognition systems failed to identify her face in photographs and video footage. She hypothesized that this was due, in part, to the fact that dark-skinned faces were not represented in the data sets that were used to train the computer programs she was studying. This insight led Buolamwini and her collaborator Gebru to undertake a systematic audit of commercial facial-analysis systems, and to demonstrate that such systems perform differently depending on the skin colour and gender of the person in the image. The work became known as the Gender Shades audit. The authors began by using a skin-type classification system, approved by dermatologists, to assess the composition of two image banks, known as IJB-A and Adience, that were widely used at the time to train facial-recognition software. They found that individuals with light-coloured skin were the subject of 79.6% of the images in IJB-A and of 86.2% of those in Adience. This prompted Buolamwini and Gebru to compile their own set of images \u2014 one that offered a broader range of skin tones than did either of the existing options, as well as including similar numbers of men and women (commercial algorithms are typically not capable of dealing with non-binary classifications). To do so, they turned to photographs of politicians from countries with gender parity in their national parliaments. The resulting data set, known as the Pilot Parliaments Benchmark (Fig. 1), contains images of 1,270 individuals from Rwanda, Senegal, South Africa, Iceland, Finland and Sweden. Buolamwini and Gebru then used their benchmark set to evaluate three commercial gender-classification systems developed by the technology companies Microsoft, Face++ and IBM. Rather than assessing the accuracy of these systems on the basis of gender or of skin type, the authors compared the performance of the classifiers on four intersectional groups that they termed darker female, darker male, lighter female and lighter male. They found that women with darker skin were the most likely to be misclassified, with a maximum classification error rate of 34.7%; by contrast, the maximum error rate for men with lighter skin was 0.8%. All three systems consistently showed poor accuracy for women with dark skin and performed substantially better on white men. \n  Impactful research isn\u2019t always understood and acknowledged at first glance, especially when it challenges conventional thinking. At the time of publication, Buolamwini and Gebru\u2019s paper was considered an outlier \u2014 not only in the field of computer vision (the study of how computers can be made to automate tasks performed by the human visual system), but also in AI ethics. Since then, a lot has changed, and algorithmic auditing has rapidly become a crucial practice, prompting academic journals and conferences to highlight audit studies. The downstream effect of the Gender Shades audit in research can also be found in curation practices for large-scale data sets. For instance, an initiative reported earlier this year suggests that faces in large image banks, such as the popular ImageNet ( go.nature.com/3qukjkn ), should be obscured to protect individuals\u2019 privacy 2 . The study showed that blurring or mosaicking faces in an image had little effect on the accuracy of software designed to recognize other elements of the image. But the authors also noted that this work must be done through crowdsourcing, rather than using commercial software, to avoid the racial bias revealed by the Gender Shades study. \n  \n   Skin colour affects the accuracy of medical oxygen sensors \n  Although there was resistance to Buolamwini and Gebru\u2019s paper at first, the vendors of the facial-recognition software that they audited eventually responded positively. IBM and Microsoft, for example, pledged to test their facial-recognition algorithms and diversify their training data sets (see, for example,  go.nature.com/3rmbo17 ). Around a year after the paper was published, a follow-up audit found that Microsoft, IBM and Face++ had all succeeded in reducing the performance error of their facial-analysis products 3 . The most noteworthy improvement was a 30.4% reduction in the error with which the Face++ software recognized darker female faces in the Pilot Parliaments Benchmark set, with the Microsoft and IBM algorithms improving by 19.28% and 17.73%, respectively, on this task. But none of these systems has yet overcome racial bias entirely, and many companies have discontinued or temporarily halted facial-recognition technologies. Evidence continues to emerge that AI models mistakenly associate images of Black people with animal classes such as \u2018gorilla\u2019 or \u2018chimpanzee\u2019 more often than they do for images of people who aren\u2019t Black 4 . The study also influenced how facial-analysis technology is regulated. In the United States, the 2019 Algorithmic Accountability Act authorized the Federal Trade Commission (the agency tasked with promoting and enforcing consumer protection) to regulate automated decision systems ( go.nature.com/3xguff7 ). US cities such as San Francisco in California, Boston, Massachusetts, and Portland, Oregon, have banned the use of facial recognition by police, citing biased misidentification that disproportionately affects communities of colour. In Europe, civil-society organizations, activists and technologists have come together to call for a ban on facial-recognition analysis ( go.nature.com/3qwzmnq ) and on biometric technology in general (g o.nature.com/3f7jrka ). And the first draft of the European Union\u2019s Artificial Intelligence Act ( go.nature.com/3dtgh4x ), released in April 2021, indicates that real-time use of facial recognition in public places might be restricted. Regulations and the risk of liability impel large corporations to change their practices, but even minimal regulations are being undermined ( go.nature.com/3yb96kq ). Although such deterrents can result in measurably improved outcomes, given the prevalence of facial-analysis technology, the changes that have the most long-term impact are likely to come from shifting public attitudes \u2014 something that I think Buolamwini and Gebru\u2019s study has influenced both directly and indirectly. The work even became the subject of the 2020 documentary film  Coded Bias  ( go.nature.com/3fashnf ). Unfortunately, the authors (like many other Black female scholars) have also been overlooked by mainstream media: a 2021 television segment on racial bias in facial-analysis technologies, for example, failed to recognize their work and that of their collaborators ( go.nature.com/3satrp8 ). Over the past few years, the conversation initiated by this work has shifted from a focus on the accuracy and performance of facial-recognition algorithms to larger and more-fundamental questions around surveillance technology. The question of accuracy becomes meaningless when this technology is used to supposedly measure internal behaviours from outward appearances. In fact, \u2018accurate\u2019 representation boils down to reducing these behaviours to outdated social stereotypes 5 . Algorithms that claim to detect emotions, predict gender or gauge someone\u2019s trustworthiness have been dubbed \u2018AI snake oil\u2019 by some ( go.nature.com/3rh7cfp ), because such sociocultural attributes cannot reliably be inferred from faces, expressions or gestures 6 . Others have called for a blanket ban on facial-recognition algorithms, saying that the technology resurrects the pseudosciences of physiognomy and phrenology 7 . The ImageNet data set, a large-scale collection of images that is considered the gold standard in computer vision, has had a pivotal role in positioning computer-vision research at the core of the \u2018deep-learning revolution\u2019 of the past decade. Facial-recognition technology has subsequently become mainstream and is prevalent in almost all social and public spaces, including concert venues, schools, airports, neighbourhoods and public squares \u2014 seriously undermining privacy and enabling worrying surveillance practices. Even if new algorithms are designed on the basis of diverse image sets such as the Pilot Parliaments Benchmark, they are still vulnerable to being used for inherently harmful and oppressive purposes, such as the surveillance of minority communities. Facial-recognition technology has expanded into other fields of research, such as studies designed to predict facial characteristics from the analysis of DNA 8 , and others that aim to automate medical diagnoses from images of faces alone 9 . Given the racial biases inherent in facial-recognition algorithms, these are concerning developments. Amid what can feel like overwhelming public enthusiasm for new AI technologies, Buolamwini and Gebru instigated a body of critical work that has exposed the bias, discrimination and oppressive nature of facial-analysis algorithms. Their audit was ground-breaking four years ago, and remains an influential reference point to counter the rapid progress of this technology and the threat it poses."},
{"file_id": "d41586-022-02238-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-03177-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-03178-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-03079-8", "year": 2022, "body": ""},
{"file_id": "d41586-022-03173-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-03219-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-03218-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-02952-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-02889-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-02231-8", "year": 2022, "body": ""},
{"file_id": "d41586-022-02949-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-02890-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-02892-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-02948-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-02950-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-02951-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-02972-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-02974-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-02973-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-02953-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-02927-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-03065-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-03075-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-02224-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-01794-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-02225-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-02349-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-02186-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-02117-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-02347-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-02345-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-02343-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-02348-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-02226-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-02342-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-02341-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-02346-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-02340-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-02344-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-01843-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-02321-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-02187-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-02032-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-01988-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-01925-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-01855-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-02104-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-02108-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-02031-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-01995-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-02107-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01641-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-02001-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-01826-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-01866-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01865-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-01840-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-01842-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-01841-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-01640-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-01596-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-01941-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-01994-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-01642-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01942-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-01940-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-01943-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-02040-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-01570-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-01321-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-02041-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-01532-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-01568-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-01636-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-01569-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-01639-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-01571-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-01635-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-01091-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-01634-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01739-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-01740-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-01738-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-01731-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01741-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-01788-8", "year": 2022, "body": ""},
{"file_id": "d41586-022-01786-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-01732-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-01479-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-01375-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01243-8", "year": 2022, "body": ""},
{"file_id": "d41586-022-01306-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-01366-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-01474-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-01365-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-01477-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-01480-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01305-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01304-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-01528-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-01476-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-01129-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-01531-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-01419-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-01534-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-01126-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-01364-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-01127-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01402-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01255-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-00860-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-01300-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-01257-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-01125-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-01080-9", "year": 2022, "body": ""},
{"file_id": "d41586-022-01128-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-01256-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-01299-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-01301-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-01237-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-01298-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-01212-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-01368-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-00974-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-00972-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-00975-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01036-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-00976-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-01035-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-00874-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-00973-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-01030-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-01028-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-01029-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-00769-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-00689-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-00700-8", "year": 2022, "body": ""},
{"file_id": "d41586-022-00872-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-00768-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-00691-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-00854-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-00852-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-00855-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-00849-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-00856-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-00519-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-00853-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-00869-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-00873-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-00836-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-00868-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-00871-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-00688-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-00690-7", "year": 2022, "body": ""},
{"file_id": "d41586-022-00773-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-01078-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-00870-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-00840-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01077-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-00466-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-00468-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-00465-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-00544-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-00546-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-00152-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-00503-x", "year": 2022, "body": "Myriad neuropsychiatric symptoms have been attributed to infection with the SARS-CoV-2 virus 1 , 2 , from lost sense of smell and taste to headaches, memory problems and more. Knowing precisely how the brain is changed by infection would help us to understand these debilitating symptoms. Large-scale brain-imaging studies can provide quantitative measures of subtle changes \u2014 but conducting these studies presents a formidable challenge.  Writing in  Nature , Douaud  et al. 3  describe 785 sets of brain scans that mark the first step in tackling this challenge head-on. \n  \n   Read the paper: SARS-CoV-2 is associated with changes in brain structure in UK Biobank \n  The UK Biobank is a large-scale biomedical database and research resource that gathers and shares genetic and health-related information for about half a million people (www.ukbiobank.ac.uk). Of those, 100,000 participants have undergone, or will undergo, a magnetic resonance imaging (MRI) session 4 . In 2020, the biobank launched a COVID-19 repeat-imaging study (see  go.nature.com/3gvj6qe ) in which participants who had completed their medical-imaging session before the start of the pandemic returned for an identical, second scan session. The biobank has released the data from 785 sets of these \u2018before and after\u2019 scans, from people between the ages of 51 and 81; 401 of the participants had tested positive for COVID-19 between the two sessions, and 384 had not. The variant that infected each person was unknown, but the scans were conducted before the emergence of the Omicron variant. Douaud  et al.  explored these data, comparing scans pre- and post-pandemic to distinguish the effects of infection from those caused by pre-existing conditions. Viral effects on the brain are likely to be so subtle that they can only just be detected by current imaging methods. It was essential that the UK Biobank\u2019s brain MRI scans were consistently gathered, well calibrated and of high quality 4 , 5 . All of the biobank\u2019s imaging centres have identical MRI machines and methods for using them to collect the brain scans 4 . In addition, Douaud and colleagues used benchmark data from a separate group of biobank participants who had undergone longitudinal brain scans before the pandemic 6 . That the researchers adhered to such high standards is important because \u2014 unlike established medical tests, such as those that measure blood glucose levels \u2014 industry standards for capturing and analysing complex brain-imaging measurements are still evolving. \n  \n   Clues that natural killer cells help to control COVID \n  The UK Biobank neuroimaging session includes six types of MRI scan, each of which reveals distinct features of brain structure and function 5 . An automated processing pipeline extracts specific features called imaging-derived phenotypes (IDPs) from the scans 5 . Each IDP conveys different information \u2014 the volume or microstructural tissue properties of distinct brain structures, for instance, or the strength of neural connectivity between pairs of brain regions. More than 2,000 IDPs are generated for each person from each scan session. In addition, Douaud  et al.  developed a set of IDPs to test the hypothesis that areas of the brain involved in taste and smell would be altered, given that these senses are often impaired in COVID-19. They used computational models from a previous biobank imaging study 7  to help disentangle any brain changes related to COVID-19 infection from ageing-related changes in brain structure and function that occurred between scans. These heroic efforts revealed significant differences between the people who had tested positive for SARS-CoV-2 (the case group) and those who had not (the control group). For instance, those in the case group exhibited a decrease in thickness and tissue contrast in some areas of the brain cortex compared with those in the control group (Fig. 1); such changes are often associated with worsening brain health. The case group also displayed increases in markers of tissue damage in brain regions connected to the smell and taste systems. No differences were detectable between the groups\u2019 primary olfactory pathways, but this is to be expected \u2014 these are notoriously challenging regions for MRI owing to imaging artefacts that occur at air\u2013tissue interfaces. Whole-brain analyses confirmed these results and showed diffuse atrophy in other brain regions. It is surprising that Douaud and colleagues identified these brain changes, given that most people in the case group experienced mild to moderate symptoms of COVID-19. Even when the authors excluded from their analysis the small number of people who required hospitalization, the results did not change. The researchers provide supporting evidence for the specificity of their findings by showing that similar changes did not occur in a group from the benchmark repeat-imaging study who contracted non-COVID-19-related pneumonia between scan sessions. One of the greatest challenges in a study of this kind is appropriately matching people in the case group with people in the control group. This is crucial because case\u2013control mismatch could contribute to a false-positive outcome, whereby infection is ascribed as the causal factor for a change when, in fact, there are other co-varying causes at play \u2014 circumstances that increased the changes of people in the case group contracting COVID-19, for example, or baseline differences in their brains. Complicating matters further, participants could be misclassified, owing to false-positive COVID-19 tests in the case group, or asymptomatic infection and false-negative tests in the control group. However, such misclassification should skew the results towards smaller differences between the two groups, rather than exaggerating differences. \n  \n   Neuroimaging results altered by varying analysis pipelines \n  Douaud and colleagues addressed this challenge head-on. When participants were first recruited, the authors assessed whether those who had tested positive and those who had not were matched in terms of sex, ethnicity, date of birth, and location and date of the first imaging-assessment clinic. The researchers then reassessed these criteria in their final cohorts after excluding all participants who had incomplete data. They also assessed whether the groups were matched in terms of time lapse between the two scan sessions, socio-economic status and relevant pre-COVID-19 health assessments, such as blood pressure, body-mass index and alcohol intake. They did confounder analyses using the extensive, non-imaging characterization data available in the UK Biobank \u2014 indices of neuropsychiatric disease, for instance \u2014 to show that, both individually and using a clustered approach, no differences between the case group and the control group, in terms of pre-existing characteristics, could account for the reported brain changes. The authors also carefully showed that no differences between IDPs in the baseline imaging session could account for their findings. However, there is no way to exclude the possibility that the reported differences are due to some other, unconsidered differences between the groups. There is much more work to be done to extract all the useful information from this valuable data set. The COVID-19 repeat-imaging study is ongoing, with 2,000 scans due to be released overall. It is to be hoped that participant-specific health information about acute and chronic COVID-19 symptoms will become available at that time \u2014 this could help researchers begin to explore how brain changes relate to specific COVID-19 symptoms. Nonetheless, the UK Biobank\u2019s data sharing and Douaud and colleagues\u2019 release of their analysis code (see  go.nature.com/3uu4r5k ) serve as an open invitation to join the effort to understand what is causing neuropsychiatric symptoms in COVID-19, and how we might prevent and recover from them."},
{"file_id": "d41586-022-00383-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-00206-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-00639-w", "year": 2022, "body": ""},
{"file_id": "d41586-022-00642-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-00640-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-00637-y", "year": 2022, "body": ""},
{"file_id": "d41586-022-00384-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-00641-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-00692-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-00508-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-00638-x", "year": 2022, "body": ""},
{"file_id": "d41586-022-01021-6", "year": 2022, "body": ""},
{"file_id": "d41586-022-00790-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-00126-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-00052-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-00051-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-00124-4", "year": 2022, "body": ""},
{"file_id": "d41586-022-00050-5", "year": 2022, "body": ""},
{"file_id": "d41586-022-00123-5", "year": 2022, "body": ""},
{"file_id": "d41586-021-03800-z", "year": 2022, "body": ""},
{"file_id": "d41586-022-00125-3", "year": 2022, "body": ""},
{"file_id": "d41586-022-00190-8", "year": 2022, "body": ""},
{"file_id": "d41586-022-00188-2", "year": 2022, "body": ""},
{"file_id": "d41586-022-00306-0", "year": 2022, "body": ""},
{"file_id": "d41586-022-00305-1", "year": 2022, "body": ""},
{"file_id": "d41586-022-00382-2", "year": 2022, "body": ""}